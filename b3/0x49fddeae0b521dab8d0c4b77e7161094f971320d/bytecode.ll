; ModuleID = 'b3/0x49fddeae0b521dab8d0c4b77e7161094f971320d/Dice.bin'
source_filename = "b3/0x49fddeae0b521dab8d0c4b77e7161094f971320d/Dice.bin"
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v16:16:16-v32:32:32-v64:64:64-v128:128:128-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

@SELFADDRESS = private unnamed_addr addrspace(4) global i160 0, align 32
@ORIGIN = private unnamed_addr addrspace(4) global i160 0, align 32
@TIMESTAMP = private unnamed_addr addrspace(4) global i256 0
@BLOCKNUM = private unnamed_addr addrspace(4) global i256 0
@BALANCECALLER = private unnamed_addr addrspace(1) global i256 -57896044618658097711785492504343953926634992332820282019728792003956564819968
@__evmCode = unnamed_addr addrspace(4) global [32769 x i8] c"`\80`@Ra\08\FC`\02U`\00`\05U`\00`\06U`\00`\0DU`\00`\0EU4\80\15b\00\00+W`\00\80\FD[Pb\00\00\8E`\01\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02`\10\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\17b\00\01\16d\01\00\00\00\00\02d\01\00\00\00\00\90\04V[3`\07`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP3`\08`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UPb\00\05>V[`\00\80`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15b\00\01tWb\00\01r`\00b\00\03id\01\00\00\00\00\02d\01\00\00\00\00\90\04V[P[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15b\00\01\FAW`\00\80\FD[PZ\F1\15\80\15b\00\02\0FW=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15b\00\02&W`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP`\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16ch\8D\CF\D7\82`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\82~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\81R` \01\91PP`\00`@Q\80\83\03\81`\00\87\80;\15\80\15b\00\03MW`\00\80\FD[PZ\F1\15\80\15b\00\03bW=`\00\80>=`\00\FD[PPPPPV[`\00\80b\00\03\9As\1D;&8\A7\CC\9F,\B3\D2\98\A3\DAz\90\B6~U\06\EDb\00\053d\01\00\00\00\00\02d\01\00\00\00\00\90\04V[\11\15b\00\03\FFWs\1D;&8\A7\CC\9F,\B3\D2\98\A3\DAz\90\B6~U\06\ED`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90Pb\00\05.V[`\00b\00\04/s\C0:&\15\D5\EF\AF_I\F6\0B{\B6X>\AE\C2\12\FD\F1b\00\053d\01\00\00\00\00\02d\01\00\00\00\00\90\04V[\11\15b\00\04\94Ws\C0:&\15\D5\EF\AF_I\F6\0B{\B6X>\AE\C2\12\FD\F1`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90Pb\00\05.V[`\00b\00\04\C4sQ\EF\AFL\8B<\9A\FB\D5\AB\9FK\BC\82xJ\B6\EF\8F\AAb\00\053d\01\00\00\00\00\02d\01\00\00\00\00\90\04V[\11\15b\00\05)WsQ\EF\AFL\8B<\9A\FB\D5\AB\9FK\BC\82xJ\B6\EF\8F\AA`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90Pb\00\05.V[`\00\90P[\91\90PV[`\00\81;\90P\91\90PV[aK\EF\80b\00\05N`\009`\00\F3\00`\80`@R`\046\10a\01\F9W`\005|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04c\FF\FF\FF\FF\16\80c\05\8A\AC\E1\14a\02\03W\80c\06\1EIO\14a\02\1AW\80c\0D\1F\CEB\14a\02\95W\80c\11a\0C%\14a\02\C0W\80c\11ln\AB\14a\02\CAW\80c\12%:l\14a\03!W\80c\13*\E5\E9\14a\038W\80c\15\14\EAT\14a\03cW\80c\18zb\D5\14a\03\BAW\80c\1E\FB\17\EE\14a\03\E9W\80c#%#\E8\14a\04,W\80c'\DC)~\14a\04CW\80c8\BB\FAP\14a\04\BAW\80c?h;j\14a\05wW\80c?\EB_+\14a\05\A6W\80c@\A4\9A\96\14a\06%W\80cFq\E6^\14a\06PW\80cNi\D5`\14a\06\93W\80cQ%yj\14a\06\EFW\80cQ@L\BE\14a\07>W\80cQ\84\96\B2\14a\07\81W\80cU\0E\D1\F0\14a\07\DFW\80ca(\A4\F3\14a\08\0AW\80cf\AE\E0\FC\14a\085W\80ck\E8\0D\E7\14a\08`W\80cq\D0\ED\05\14a\08\B7W\80crJ\E9\D0\14a\09\00W\80c\82\A5(]\14a\09+W\80c\85\EA\C0_\14a\09VW\80c\8D\A5\CB[\14a\09\99W\80c\A4\BE\FF\A7\14a\09\F0W\80c\C4\BC]\A5\14a\09\FAW\80c\C9\02\C3\AE\14a\0A\11W\80c\CA\FB\22\02\14a\0A\90W\80c\D2\1DyP\14a\0A\BBW\80c\D7\CE\E3\1E\14a\0A\E8W\80c\DA\0B\BA{\14a\0B?W\80c\DF\06\F9\06\14a\0BpW\80c\F4\99;\BD\14a\0B\9BW\80c\F8\B2\CBO\14a\0B\B2W\80c\FB\09\9C\84\14a\0C\09W[a\02\01a\0C\13V[\00[4\80\15a\02\0FW`\00\80\FD[Pa\02\18a\0F\F7V[\00[4\80\15a\02&W`\00\80\FD[Pa\02E`\04\806\03\81\01\90\80\805\90` \01\90\92\91\90PPPa\10OV[`@Q\80\84s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\83\81R` \01\82\81R` \01\93PPPP`@Q\80\91\03\90\F3[4\80\15a\02\A1W`\00\80\FD[Pa\02\AAa\11\0FV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[a\02\C8a\0C\13V[\00[4\80\15a\02\D6W`\00\80\FD[Pa\03\0B`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\11[V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\03-W`\00\80\FD[Pa\036a\11\CBV[\00[4\80\15a\03DW`\00\80\FD[Pa\03Ma\12pV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\03oW`\00\80\FD[Pa\03\A4`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\12vV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\03\C6W`\00\80\FD[Pa\03\E7`\04\806\03\81\01\90\80\805\15\15\90` \01\90\92\91\90PPPa\12\E6V[\00[4\80\15a\03\F5W`\00\80\FD[Pa\04*`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\14vV[\00[4\80\15a\048W`\00\80\FD[Pa\04Aa\16\09V[\00[4\80\15a\04OW`\00\80\FD[Pa\04\B8`\04\806\03\81\01\90\80\805`\00\19\16\90` \01\90\92\91\90\805\90` \01\90\82\01\805\90` \01\90\80\80`\1F\01` \80\91\04\02` \01`@Q\90\81\01`@R\80\93\92\91\90\81\81R` \01\83\83\80\82\847\82\01\91PPPPPP\91\92\91\92\90PPPa\16\CCV[\00[4\80\15a\04\C6W`\00\80\FD[Pa\05u`\04\806\03\81\01\90\80\805`\00\19\16\90` \01\90\92\91\90\805\90` \01\90\82\01\805\90` \01\90\80\80`\1F\01` \80\91\04\02` \01`@Q\90\81\01`@R\80\93\92\91\90\81\81R` \01\83\83\80\82\847\82\01\91PPPPPP\91\92\91\92\90\805\90` \01\90\82\01\805\90` \01\90\80\80`\1F\01` \80\91\04\02` \01`@Q\90\81\01`@R\80\93\92\91\90\81\81R` \01\83\83\80\82\847\82\01\91PPPPPP\91\92\91\92\90PPPa\17\0FV[\00[4\80\15a\05\83W`\00\80\FD[Pa\05\8Ca\1BvV[`@Q\80\82\15\15\15\15\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\05\B2W`\00\80\FD[Pa\05\D1`\04\806\03\81\01\90\80\805\90` \01\90\92\91\90PPPa\1B\89V[`@Q\80\84s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\83\81R` \01\82\15\15\15\15\81R` \01\93PPPP`@Q\80\91\03\90\F3[4\80\15a\061W`\00\80\FD[Pa\06:a\1B\E0V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\06\\W`\00\80\FD[Pa\06\91`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\1C\96V[\00[4\80\15a\06\9FW`\00\80\FD[Pa\06\A8a\1E\03V[`@Q\80\89\81R` \01\88\81R` \01\87\81R` \01\86\81R` \01\85\81R` \01\84\81R` \01\83\81R` \01\82\81R` \01\98PPPPPPPPP`@Q\80\91\03\90\F3[4\80\15a\06\FBW`\00\80\FD[Pa\07<`\04\806\03\81\01\90\80\805~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\90` \01\90\92\91\90PPPa\1EaV[\00[4\80\15a\07JW`\00\80\FD[Pa\07\7F`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\1F@V[\00[4\80\15a\07\8DW`\00\80\FD[Pa\07\96a\1F\F7V[`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\F3[4\80\15a\07\EBW`\00\80\FD[Pa\07\F4a )V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\08\16W`\00\80\FD[Pa\08\1Fa\22\0CV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\08AW`\00\80\FD[Pa\08Ja\22\12V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\08lW`\00\80\FD[Pa\08\A1`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa\22\18V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\08\C3W`\00\80\FD[Pa\08\E2`\04\806\03\81\01\90\80\805\90` \01\90\92\91\90PPPa\220V[`@Q\80\82`\00\19\16`\00\19\16\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\09\0CW`\00\80\FD[Pa\09\15a\22SV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\097W`\00\80\FD[Pa\09@a\22\BAV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\09bW`\00\80\FD[Pa\09\97`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa$yV[\00[4\80\15a\09\A5W`\00\80\FD[Pa\09\AEa&\0CV[`@Q\80\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\91PP`@Q\80\91\03\90\F3[a\09\F8a&2V[\00[4\80\15a\0A\06W`\00\80\FD[Pa\0A\0Fa'$V[\00[4\80\15a\0A\1DW`\00\80\FD[Pa\0A@`\04\806\03\81\01\90\80\805`\00\19\16\90` \01\90\92\91\90PPPa'\C9V[`@Q\80\84s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\83\81R` \01\82\81R` \01\93PPPP`@Q\80\91\03\90\F3[4\80\15a\0A\9CW`\00\80\FD[Pa\0A\A5a(\13V[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\0A\C7W`\00\80\FD[Pa\0A\E6`\04\806\03\81\01\90\80\805\90` \01\90\92\91\90PPPa(\19V[\00[4\80\15a\0A\F4W`\00\80\FD[Pa\0A\FDa(\E6V[`@Q\80\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\0BKW`\00\80\FD[Pa\0Bn`\04\806\03\81\01\90\80\805`\00\19\16\90` \01\90\92\91\90PPPa)\0CV[\00[4\80\15a\0B|W`\00\80\FD[Pa\0B\85a)tV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[4\80\15a\0B\A7W`\00\80\FD[Pa\0B\B0a)\81V[\00[4\80\15a\0B\BEW`\00\80\FD[Pa\0B\F3`\04\806\03\81\01\90\80\805s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90` \01\90\92\91\90PPPa,\9AV[`@Q\80\82\81R` \01\91PP`@Q\80\91\03\90\F3[a\0C\11a-IV[\00[`\00\80`\00`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15a\0C2W`\00\80\FD[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a\0C\B7W`\00\80\FD[PZ\F1\15\80\15a\0C\CBW=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a\0C\E1W`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPPs\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c.\F3\AC\CC`\02Tb\02\AB\98\01`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\80` \01\83\81R` \01\82\81\03\82R`\03\81R` \01\80\7FURL\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\81RP` \01\92PPP` `@Q\80\83\03\81`\00\87\80;\15\80\15a\0D\A0W`\00\80\FD[PZ\F1\15\80\15a\0D\B4W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a\0D\CAW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\92P4\83\10\15\15a\0D\EBW`\00\80\FD[\824\03\91Pa'\10a\0D\FBa\11\0FV[`d\02\81\15\15a\0E\07W\FE[\04a\1DL\80`\BEa'\10\03\03\84\02\81\15\15a\0E\1EW\FE[\04\11\15\80\15a\0E5WPg\02\C6\8A\F0\BB\14\00\00\82\10\15[\15a\0F\EDW\7F\A3\94\17\F9&\ED\80kG],\D7@\83\81\95Qan\7F\DB?[\B7\AB\F8\E8\93\EA\E2D\B43\83`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1a\0F\08`@\80Q\90\81\01`@R\80`\06\81R` \01\7Fnested\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\81RPa\01\C0`@Q\90\81\01`@R\80a\01\89\81R` \01aJ;a\01\89\919`\02Tb\02\AB\98\01a.cV[\90P```@Q\90\81\01`@R\803s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\83\81R` \01`\00\81RP`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\00\82\01Q\81`\00\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP` \82\01Q\81`\01\01U`@\82\01Q\81`\02\01U\90PP`\0C\81\90\80`\01\81T\01\80\82U\80\91PP\90`\01\82\03\90`\00R` `\00 \01`\00\90\91\92\90\91\90\91P\90`\00\19\16\90UPa\0F\F2V[`\00\80\FD[PPPV[`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\14\15a\10DW`\00\80\FD[a\10M3a2\C8V[V[`\00\80`\00\80`\0C\80T\90P\85\10\15a\11\06W`\0C\85\81T\81\10\15\15a\10qW\FE[\90`\00R` `\00 \01T\90P`\0B`\00\82`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\01\01T`\0B`\00\84`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01T\93P\93P\93Pa\11\07V[[P\91\93\90\92PV[`\00`\0DT`\06T\10\80a\11*WP`\06T`\0DT`\06T\01\10[\80a\11<WP`\0ET`\0DT`\06T\01\10[\15a\11JW`\00\90Pa\11XV[`\0ET`\0DT`\06T\01\03\90P[\90V[`\00`\06T`\0DT`\04`\00`\03`\00\87s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\81R` \01\90\81R` \01`\00 `\01\01T\02\81\15\15a\11\C3W\FE[\04\90P\91\90PV[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\12'W`\00\80\FD[`\01`\08`\14a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\7F;\B5KL\ED\11/\E0\D4\FA~\FDB\B2\9A\0A\906\FD\E6\E2\06\DEB\90\C4\FF\02\D2\DC,\\`@Q`@Q\80\91\03\90\A1V[`\05T\81V[`\00`\06T`\0ET`\04`\00`\03`\00\87s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\81R` \01\90\81R` \01`\00 `\01\01T\02\81\15\15a\12\DEW\FE[\04\90P\91\90PV[`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\14\15a\133W`\00\80\FD[`\00`\09`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a\13|W`\00\80\FD[`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15\15a\13\97W`\00\80\FD[\80`\04`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\81R` \01\90\81R` \01`\00 `\02\01`\00a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\7F\EA\22\EE\15\DE\9C8Z\BE\FF\07+#\D6\E0\DE^\BD\A8\C5\90\98\F5X_E\E8+\9F\AAWb3\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\15\15\15\15\81R` \01\92PPP`@Q\80\91\03\90\A1PV[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\14\D2W`\00\80\FD[`\00s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a\15\0CW`\00\80\FD[\80`\08`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP\7F\B7P\AC\85K\12\11@s\B8\C7m\CF\E5\FB\88\9B0\DB]=`\E0z\BC\8A\E6l4\9Dzh`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\92PPP`@Q\80\91\03\90\A1PV[`\00\803s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\16hW`\00\80\FD[`\05T\91P`\01\90P[\81\81\11\15\15a\16\C8Wa\16\BB`\04`\00`\01\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a2\C8V[\80\80`\01\01\91PPa\16rV[PPV[a\17\0B\82\82`\00`@Q\90\80\82R\80`\1F\01`\1F\19\16` \01\82\01`@R\80\15a\17\05W\81` \01` \82\02\808\839\80\82\01\91PP\90P[Pa\17\0FV[PPV[`\00a\17\19a6\D1V[s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\163s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\17RW`\00\80\FD[\83`\00s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a\17\CBW`\00\80\FD[\84`\00`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01T\11\15a\17\F8W`\00\80\FD[\85\85`\00a\18\05\82a8\E4V[\90P`\01\81\10\80a\18\17WPa'\10\81\11[\80\15a\18AWP`\00`\0B`\00\85`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01T\14[\15a\18\D7Wb\01\86\9F`\0B`\00\85`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01\81\90UPa\18\D2`\0B`\00\85`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\0B`\00\86`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\01\01Ta8\F8V[a\1BkV[\88a'\10a\18\E3a\11\0FV[`d\02\81\15\15a\18\EFW\FE[\04a\1DL\80`\BEa'\10\03\03`\0B`\00\85`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\01\01T\02\81\15\15a\19$W\FE[\04\11\15\80\15a\19YWPg\02\C6\8A\F0\BB\14\00\00`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\01\01T\10\15[\15a\1A\D7Wa\19g\89a8\E4V[\96P\86`\0B`\00\8C`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01\81\90UPa\1A&`\0B`\00\8C`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 ```@Q\90\81\01`@R\90\81`\00\82\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01`\01\82\01T\81R` \01`\02\82\01T\81RPP\88a;\D2V[a\1A\C0`\0B`\00\8C`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 ```@Q\90\81\01`@R\90\81`\00\82\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01`\01\82\01T\81R` \01`\02\82\01T\81RPP\88a<\C4V[`\0F`\00a\01\00\0A\81T\90`\FF\02\19\16\90Ua\1BhV[b\01\86\9F`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\02\01\81\90UPa\1Bc`\0B`\00\83`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\0B`\00\84`\00\19\16`\00\19\16\81R` \01\90\81R` \01`\00 `\01\01Ta8\F8V[a\1BiV[[P[PPPPPPPPPV[`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\81V[`\04` R\80`\00R`@`\00 `\00\91P\90P\80`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90\80`\01\01T\90\80`\02\01`\00\90T\90a\01\00\0A\90\04`\FF\16\90P\83V[`\00\80`\00`\01\91P`\01\90P[`\05T\81\11\15\15a\1C\8EWa\1C8`\04`\00\84\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a,\9AV[a\1Cw`\04`\00\84\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a,\9AV[\10\15a\1C\81W\80\91P[\80\80`\01\01\91PPa\1B\EEV[\81\92PPP\90V[`\00`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15\15a\1C\B3W`\00\80\FD[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\1D\0FW`\00\80\FD[`\01\90P[`\05T\81\11\15\15a\1DRW`\04`\00\82\81R` \01\90\81R` \01`\00 `\02\01`\00a\01\00\0A\81T\90`\FF\02\19\16\90U\80\80`\01\01\91PPa\1D\14V[`@\80Q\90\81\01`@R\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01B\81RP`\09`\00\82\01Q\81`\00\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP` \82\01Q\81`\01\01U\90PP\7Fl\0E\B5o\12\14\18\F1n\AE\BB\E0\1C\B2iH\97\B8W\8B;\1CT\9EcJ\1BwS\ED-\8B`@Q`@Q\80\91\03\90\A1PPV[`\00\80`\00\80`\00\80`\00\80`\00\80a\1E\1Aa\11\0FV[\91Pa\1E$a\22SV[\90P\81a\1DL`\BE`dg\02\C6\8A\F0\BB\14\00\00`\0ET`\0DT\03\86`\0C\80T\90P\99P\99P\99P\99P\99P\99P\99P\99PPP\90\91\92\93\94\95\96\97V[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\1E\BDW`\00\80\FD[`\00\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\14\15a\1F\0FW`\00\80\FD[a\1F=`\01\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\82\17a>\04V[PV[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a\1F\9CW`\00\80\FD[`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15\15a\1F\B7W`\00\80\FD[a\1F\C0\81a2\C8V[`\09`\00\80\82\01`\00a\01\00\0A\81T\90s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90U`\01\82\01`\00\90UPPPV[`\09\80`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90\80`\01\01T\90P\82V[`\00\80`\00\80`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a \B3W`\00\80\FD[PZ\F1\15\80\15a \C7W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a \DDW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPPs\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c.\F3\AC\CC`\02Tb\02\AB\98\01`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\80` \01\83\81R` \01\82\81\03\82R`\03\81R` \01\80\7FURL\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\81RP` \01\92PPP` `@Q\80\83\03\81`\00\87\80;\15\80\15a!\9CW`\00\80\FD[PZ\F1\15\80\15a!\B0W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a!\C6W`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\91Pa\1DL`\BEa'\10\03\03a'\10\02a\1DLa!\F2a\11\0FV[`d\02\02\81\15\15a!\FFW\FE[\04\90P\81\81\01\92PPP\90V[`\0ET\81V[`\0DT\81V[`\03` R\80`\00R`@`\00 `\00\91P\90PT\81V[`\0C\81\81T\81\10\15\15a\22?W\FE[\90`\00R` `\00 \01`\00\91P\90PT\81V[`\00\80`\0A`\05T\14\15a\22\B1Wa\22ia\1B\E0V[\90Pa\22\AA`\04`\00\83\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a,\9AV[\91Pa\22\B6V[`\00\91P[P\90V[`\00\80`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a#BW`\00\80\FD[PZ\F1\15\80\15a#VW=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a#lW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPPs\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c.\F3\AC\CC`\02Tb\02\AB\98\01`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\80` \01\83\81R` \01\82\81\03\82R`\03\81R` \01\80\7FURL\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\81RP` \01\92PPP` `@Q\80\83\03\81`\00\87\80;\15\80\15a$+W`\00\80\FD[PZ\F1\15\80\15a$?W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a$UW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\90Pg\02\C6\8A\F0\BB\14\00\00\81\01\91PP\90V[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a$\D5W`\00\80\FD[`\00s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a%\0FW`\00\80\FD[\80`\07`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP\7FOg\FE\22;\CAi\F2+\F2ERc\8F<\95\BF\B9\E9v<J3\A3\AAg\A4d\84\D8\1C+`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\92PPP`@Q\80\91\03\90\A1PV[`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81V[`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15a&LW`\00\80\FD[`\004\14\15a&ZW`\00\80\FD[`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\14\15a&\A7W`\00\80\FD[a&\AFa@@V[4`\04`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\81R` \01\90\81R` \01`\00 `\01\01`\00\82\82T\01\92PP\81\90UP4`\06`\00\82\82T\01\92PP\81\90UPV[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a'\80W`\00\80\FD[`\00`\08`\14a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\7F\AD\F8\F7\9D\D5\08\A8\E1\88\1E<\CAg\A5\AF\02\A2\1F\97\19%\C3\A6\A6\CB\8F\C1e\D0~4c`@Q`@Q\80\91\03\90\A1V[`\0B` R\80`\00R`@`\00 `\00\91P\90P\80`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\90\80`\01\01T\90\80`\02\01T\90P\83V[`\06T\81V[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a(uW`\00\80\FD[\80b\02\AB\98\81b\02\AB\98\01\10\15a(\8BW`\00\80\FD[aa\A8\81\10\15a(\9AW`\00\80\FD[\81`\02\81\90UP\7F\B5\E4\EC\E1\F9l\C1h\FD\DC\EA\D7\EE \9F\96\9A\93`r8\C5\85v~\A8\0F\AD_\E8\84\B2`\02T\83`@Q\80\83\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1PPV[`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81V[3s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a)hW`\00\80\FD[a)q\81aBxV[PV[`\00`\0C\80T\90P\90P\90V[`\00\80`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\07`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a)\E2W`\00\80\FD[`\00`\09`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a*+W`\00\80\FD[`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15\15a*FW`\00\80\FD[Bb\03\F4\80`\09`\01\01T\01\11\15a*]W`\00\80\FD[0s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\161\91P`\01\90P[`\05T\81\11\15\15a*\F3W`\01\15\15`\04`\00\83\81R` \01\90\81R` \01`\00 `\02\01`\00\90T\90a\01\00\0A\90\04`\FF\16\15\15\14\15a*\E6W\82\80`\01\01\93PP`\04`\00\82\81R` \01\90\81R` \01`\00 `\02\01`\00a\01\00\0A\81T\90`\FF\02\19\16\90U[\80\80`\01\01\91PPa*|V[`d`\05T`\0A\02\81\15\15a+\04W\FE[\04\83\10\15\15a,\90W`\09`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a\08\FC\83\90\81\15\02\90`@Q`\00`@Q\80\83\03\81\85\88\88\F1\93PPPP\15\15a+\FAW\7F\0F\D1\EDx;\F9P^?\C2TZ\18\E0\22\B8\BD\04\8D$\0D\98\A3\C9Ydl\CE\BDV\9B9`\09`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`@Q\80\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\91PP`@Q\80\91\03\90\A1a,\8BV[\7F\E07nt\0D\F2\8Dl\BD\EFF\88\0B7\13k\C7^\02wf\E3)]J\F8\A4LUz\E72`\09`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\83`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1[a,\95V[`\00\80\FD[PPPV[`\00\80`\00\80`\04`\00`\03`\00\88s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\81R` \01\90\81R` \01`\00 `\01\01T\92Pa-\01\85a\11[V[\91Pa-\0C\85a\12vV[\90P\81\82\84\01\10\80a-\1FWP\82\82\84\01\10[\80a-+WP\80\82\84\01\10[\15a-9W`\00\93Pa-AV[\80\82\84\01\03\93P[PPP\91\90PV[`\00`\08`\14\90T\90a\01\00\0A\90\04`\FF\16\15a-eW`\00\80\FD[`\004\14\15a-sW`\00\80\FD[`\00`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\14\15\15a-\C1W`\00\80\FD[a-\C9a\22SV[4\11\15\15a-\D6W`\00\80\FD[a-\DEa@@V[`\0A`\05T\14\15a.3Wa-\F1a\1B\E0V[\90Pa.2`\04`\00\83\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16a2\C8V[[`\05`\00\81T\80\92\91\90`\01\01\91\90PUPa.P`\05TaDxV[`\0A`\05T\11\15a.`W`\00\80\FD[PV[`\00\80`\00\80`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a.\B2Wa.\B0`\00aE\AAV[P[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a/7W`\00\80\FD[PZ\F1\15\80\15a/KW=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a/aW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP`\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c.\F3\AC\CC\86\85`@Q\83c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\80` \01\83\81R` \01\82\81\03\82R\84\81\81Q\81R` \01\91P\80Q\90` \01\90\80\83\83`\00[\83\81\10\15a0cW\80\82\01Q\81\84\01R` \81\01\90Pa0HV[PPPP\90P\90\81\01\90`\1F\16\80\15a0\90W\80\82\03\80Q`\01\83` \03a\01\00\0A\03\19\16\81R` \01\91P[P\93PPPP` `@Q\80\83\03\81`\00\87\80;\15\80\15a0\B0W`\00\80\FD[PZ\F1\15\80\15a0\C4W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a0\DAW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\90P\82:\02g\0D\E0\B6\B3\A7d\00\00\01\81\11\15a1\0DW`\00`\01\02\91Pa2\C0V[`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c\C5\1B\E9\0F\82`\00\88\88\88`@Q\86c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\85\81R` \01\80` \01\80` \01\84\81R` \01\83\81\03\83R\86\81\81Q\81R` \01\91P\80Q\90` \01\90\80\83\83`\00[\83\81\10\15a1\CCW\80\82\01Q\81\84\01R` \81\01\90Pa1\B1V[PPPP\90P\90\81\01\90`\1F\16\80\15a1\F9W\80\82\03\80Q`\01\83` \03a\01\00\0A\03\19\16\81R` \01\91P[P\83\81\03\82R\85\81\81Q\81R` \01\91P\80Q\90` \01\90\80\83\83`\00[\83\81\10\15a22W\80\82\01Q\81\84\01R` \81\01\90Pa2\17V[PPPP\90P\90\81\01\90`\1F\16\80\15a2_W\80\82\03\80Q`\01\83` \03a\01\00\0A\03\19\16\81R` \01\91P[P\96PPPPPPP` `@Q\80\83\03\81\85\88\80;\15\80\15a2\81W`\00\80\FD[PZ\F1\15\80\15a2\95W=`\00\80>=`\00\FD[PPPPP`@Q=` \81\10\15a2\ACW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\91P[P\93\92PPPV[`\00\80`\00\80a2\D6a@@V[`\03`\00\86s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 T\93Pa3!\85a,\9AV[\92P`\04`\00\85\81R` \01\90\81R` \01`\00 `\01\01T`\06T\10\15\15a6rW`\04`\00\85\81R` \01\90\81R` \01`\00 `\01\01T`\06`\00\82\82T\03\92PP\81\90UPa'\10`2\84\02\81\15\15a3zW\FE[\04\91P\81\83\03\92P`\04`\00\85\81R` \01\90\81R` \01`\00 `\00\80\82\01`\00a\01\00\0A\81T\90s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90U`\01\82\01`\00\90U`\02\82\01`\00a\01\00\0A\81T\90`\FF\02\19\16\90UPP`\03`\00\86s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 `\00\90U`\05T\84\14\15\15a5\B9W`\04`\00`\05T\81R` \01\90\81R` \01`\00 \90P\83`\03`\00\83`\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 \81\90UP\80`\04`\00\86\81R` \01\90\81R` \01`\00 `\00\82\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81`\00\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\82\01T\81`\01\01U`\02\82\01`\00\90T\90a\01\00\0A\90\04`\FF\16\81`\02\01`\00a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\90PP`\04`\00`\05T\81R` \01\90\81R` \01`\00 `\00\80\82\01`\00a\01\00\0A\81T\90s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90U`\01\82\01`\00\90U`\02\82\01`\00a\01\00\0A\81T\90`\FF\02\19\16\90UPP[`\05`\00\81T\80\92\91\90`\01\90\03\91\90PUPa5\D6\85\84a8\F8V[a6\02`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\83a8\F8V[\7F0&\A1(CD\9D~sw\F8\93*@\BD\B5\D1\B1\12^\FB\FB\E1G\13 \16\F8\BE\AC\0F4\85\84`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1a6\BAV[`\01`\08`\14a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\7FR\E5x\AD\17\DC\8F\E0\FFEo\DF\1F\81Qo})\EB\85\FF\F3\01GZ:)\D0\E8K\B3\1A`@Q`@Q\80\91\03\90\A1[`\0A`\05T\11\15a6\CAW`\00\80\FD[PPPPPV[`\00\80`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a7\1EWa7\1C`\00aE\AAV[P[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a7\A3W`\00\80\FD[PZ\F1\15\80\15a7\B7W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a7\CDW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP`\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c\C2\81\D1\9E`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a8\A4W`\00\80\FD[PZ\F1\15\80\15a8\B8W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a8\CEW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP\90P\90V[`\00a8\F1\82`\00aG;V[\90P\91\90PV[`\00\81\14\15a92W\7FGc\E3\FE\EFP\16z\E1\95z \BA+u\B5\F4\090b9.\81\D5\E3Q\B7\09\B1\D8&\1F`@Q`@Q\80\91\03\90\A1a;\CEV[\800s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\161\10\15a9\82W\7FPK\0A\E8\9B\95w\92b\E9\92C\87\0E\B96\18\0A\8C3\B4D\F1\7F\01\80|@\A2\0Cz\A7`@Q`@Q\80\91\03\90\A1a;\CEV[\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\02T\82`@Q`\00`@Q\80\83\03\81\85\88\88\F1\93PPPP\15\15a;bW\7F\94\92\01\D7\8CP\A6\B4S\F7\06\8E\D1\9A\\}t\AA\A0|\12\CA\DF\D3\85SW\A0\B0\F4t\05\82\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\82s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15\15a;aW`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16`\02T\82`@Q`\00`@Q\80\83\03\81\85\88\88\F1\93PPPP\15\15a;`W\7F\94\92\01\D7\8CP\A6\B4S\F7\06\8E\D1\9A\\}t\AA\A0|\12\CA\DF\D3\85SW\A0\B0\F4t\05`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1[[[\7F\C7\E4\16\C5h]\89qU\88@\F0\\^c\E0%u\B2\99\97\D8\DAk\9B\A4M\C1\0D\A6\A3p\82\82`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1[PPV[`\00\81a\1DL`\01\82\03\10\15a<\BEWa\1DL`\BEa'\10\03\85` \01Q\02\81\15\15a;\FAW\FE[\04\91P\7F\A5\AC\B0\22rm\98\0B$\9D\DC!/I\92\AD\87\F2\8C\095P#/\CCH\BD\8A\F8\03\F2\D5\84`\00\01Q\84\84`@Q\80\84s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\83\81R` \01\82\81R` \01\93PPPP`@Q\80\91\03\90\A1a<\82\84`\00\01Q\83a8\F8V[`\0ET\82`\0ET\01\10\80a<\9DWP\83` \01Q\82`\0ET\01\10[\15a<\A7W`\00\80\FD[\83` \01Q\82\03`\0E`\00\82\82T\01\92PP\81\90UP[PPPPV[`\00\80\82a\1DL`\01\82\03\10\15\15a=\FDW\7F\F6\DB+\AC\E4\AC\82w8ES\AD\96\03\D0E\22\0A\91\FB$H\ABa0\D7\A6\F0D\F9\A8\CF\85`\00\01Q\85`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1a=T\85`\00\01Q`\01a8\F8V[`\0DT\85` \01Q`\0DT\01\10\80a=wWP\84` \01Q\85` \01Q`\0DT\01\10[\80a=\86WP`\01\85` \01Q\14[\15a=\90W`\00\80\FD[`\01\85` \01Q\03`\0DT\01\92Pa'\10`Za'\10\03`\01\87` \01Q\03\02\81\15\15a=\B9W\FE[\04`\0D`\00\82\82T\01\92PP\81\90UP`\0DT\83\03\91Pa=\FC`\08`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\83a8\F8V[[PPPPPV[`\00\80`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15a>PWa>N`\00aE\AAV[P[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15a>\D5W`\00\80\FD[PZ\F1\15\80\15a>\E9W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15a>\FFW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP`\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16ch\8D\CF\D7\82`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\82~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\81R` \01\91PP`\00`@Q\80\83\03\81`\00\87\80;\15\80\15a@%W`\00\80\FD[PZ\F1\15\80\15a@9W=`\00\80>=`\00\FD[PPPPPV[`\00\80`\00\80`\00`\0F`\00\90T\90a\01\00\0A\90\04`\FF\16\15\15aBqW`\01\93P[`\05T\84\11\15\15aBBW`\04`\00\85\81R` \01\90\81R` \01`\00 `\00\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\92Pa@\B0\83a\11[V[\91Pa@\BB\83a\12vV[\90P`\04`\00\85\81R` \01\90\81R` \01`\00 `\01\01T\82`\04`\00\87\81R` \01\90\81R` \01`\00 `\01\01T\01\10\15\80\15aA\13WP\80\82`\04`\00\87\81R` \01\90\81R` \01`\00 `\01\01T\01\10\15[\15aA\B0W\80\82\03`\04`\00\86\81R` \01\90\81R` \01`\00 `\01\01`\00\82\82T\01\92PP\81\90UP\7F\8F\F4\93G\DA\904\AA\B5+y\ACk+\A8\CF\17\D2!Qh4\AF^_\A0K\EF\1D\F4\D7\CD\83\82\84\03`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1aA\F8V[`\01`\08`\14a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP\7FR\E5x\AD\17\DC\8F\E0\FFEo\DF\1F\81Qo})\EB\85\FF\F3\01GZ:)\D0\E8K\B3\1A`@Q`@Q\80\91\03\90\A1[\84`\04`\00\86\81R` \01\90\81R` \01`\00 `\01\01T\86\01\10\15\15aB5W`\04`\00\85\81R` \01\90\81R` \01`\00 `\01\01T\85\01\94P[\83\80`\01\01\94PPa@cV[`\0D`\00\90U`\0E`\00\90U\84`\06\81\90UP`\01`\0F`\00a\01\00\0A\81T\81`\FF\02\19\16\90\83\15\15\02\17\90UP[PPPPPV[`\00\80`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\14\15aB\C4WaB\C2`\00aE\AAV[P[`\00\80\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c8\CCH1`@Q\81c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01` `@Q\80\83\03\81`\00\87\80;\15\80\15aCIW`\00\80\FD[PZ\F1\15\80\15aC]W=`\00\80>=`\00\FD[PPPP`@Q=` \81\10\15aCsW`\00\80\FD[\81\01\90\80\80Q\90` \01\90\92\91\90PPP`\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01`\00\90T\90a\01\00\0A\90\04s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16c\E8\A5(-\82`@Q\82c\FF\FF\FF\FF\16|\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\81R`\04\01\80\82`\00\19\16`\00\19\16\81R` \01\91PP`\00`@Q\80\83\03\81`\00\87\80;\15\80\15aD]W`\00\80\FD[PZ\F1\15\80\15aDqW=`\00\80>=`\00\FD[PPPPPV[\80`\03`\003s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\90\81R` \01`\00 \81\90UP3`\04`\00\83\81R` \01\90\81R` \01`\00 `\00\01`\00a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP4`\04`\00\83\81R` \01\90\81R` \01`\00 `\01\01\81\90UP4`\06`\00\82\82T\01\92PP\81\90UP\7F\A4\A4oE\C9\99lx2\0A\E4pqO\93\0A\CB\A6S\B0\22\FD\DE\C1s\\\14\00 \97\80\E434`@Q\80\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\81R` \01\82\81R` \01\92PPP`@Q\80\91\03\90\A1PV[`\00\80aE\CAs\1D;&8\A7\CC\9F,\B3\D2\98\A3\DAz\90\B6~U\06\EDaJ/V[\11\15aF-Ws\1D;&8\A7\CC\9F,\B3\D2\98\A3\DAz\90\B6~U\06\ED`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90PaG6V[`\00aFLs\C0:&\15\D5\EF\AF_I\F6\0B{\B6X>\AE\C2\12\FD\F1aJ/V[\11\15aF\AFWs\C0:&\15\D5\EF\AF_I\F6\0B{\B6X>\AE\C2\12\FD\F1`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90PaG6V[`\00aF\CEsQ\EF\AFL\8B<\9A\FB\D5\AB\9FK\BC\82xJ\B6\EF\8F\AAaJ/V[\11\15aG1WsQ\EF\AFL\8B<\9A\FB\D5\AB\9FK\BC\82xJ\B6\EF\8F\AA`\00\80a\01\00\0A\81T\81s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\02\19\16\90\83s\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\16\02\17\90UP`\01\90PaG6V[`\00\90P[\91\90PV[`\00```\00\80`\00\86\93P`\00\92P`\00\91P`\00\90P[\83Q\81\10\15aJ\10W`0\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\84\82\81Q\81\10\15\15aG\8FW\FE[\90` \01\01Q\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\10\15\80\15aH\A7WP`9\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\84\82\81Q\81\10\15\15aH7W\FE[\90` \01\01Q\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\11\15[\15aIXW\81\15aH\CAW`\00\86\14\15aH\C0WaJ\10V[\85\80`\01\90\03\96PP[`\0A\83\02\92P`0\84\82\81Q\81\10\15\15aH\E0W\FE[\90` \01\01Q\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04\03\83\01\92PaJ\03V[`.\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02\84\82\81Q\81\10\15\15aI\8AW\FE[\90` \01\01Q\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\90\04\7F\01\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\02~\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\FF\19\16\14\15aJ\02W`\01\91P[[\80\80`\01\01\91PPaGTV[`\00\86\11\15aJ\22W\85`\0A\0A\83\02\92P[\82\94PPPPP\92\91PPV[`\00\81;\90P\91\90PV\00[URL] ['json(https://api.random.org/json-rpc/1/invoke).result.random.data.0', '\\n{\22jsonrpc\22:\222.0\22,\22method\22:\22generateSignedIntegers\22,\22params\22:{\22apiKey\22:${[decrypt] BMmkEKUccgE4/k+IKb650CLwQ/ACeowJ6a0erQDDqXn1XoTiKRXkw0T3ddPc5l6yUJ8/lEUd3DVG7nwvC/N9jY5NGgeNU4Xvi6HpWjqrevinSkadL3RL0v2w9fr87hd/sURn77W7W8WPoxVH+K8E74+0XHf5vak=},\22n\22:1,\22min\22:1,\22max\22:10000${[identity] \22}\22},\22id\22:1${[identity] \22}\22}']\A1ebzzr0X ,0&;\BB<\BA|\D1\F7\E3 0\0A=\E7\92\FB?Z\E3\F9N!U\83\ED\A2\19\15\88\BE\00)\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@__evmCodeSize = unnamed_addr addrspace(4) global i32 20797

define internal i32 @get_thread_id() {
  %1 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %2 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
  %4 = mul i32 %2, %3
  %5 = add i32 %1, %4
  ret i32 %5
}

; Function Attrs: nounwind readnone
declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() #0

; Function Attrs: nounwind readnone
declare i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #0

; Function Attrs: nounwind readnone
declare i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #0

declare void @updateBits(i64 addrspace(1)*)

declare void @parallel_mutate(i8 addrspace(1)*, i32)

define i32 @contract(i256* %0, i256* %1, i8* %2, i32 %3, i8 addrspace(1)* %4) {
Entry:
  %__afl_prev_loc = alloca i32, align 4
  store i32 0, i32* %__afl_prev_loc, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %5, align 4
  %6 = alloca i32, align 4
  store i32 0, i32* %6, align 4
  %7 = alloca i32, align 4
  store i32 0, i32* %7, align 4
  %8 = alloca i32, align 4
  store i32 0, i32* %8, align 4
  %9 = alloca i32, align 4
  store i32 0, i32* %9, align 4
  %10 = alloca i32, align 4
  store i32 0, i32* %10, align 4
  %11 = alloca i32, align 4
  store i32 0, i32* %11, align 4
  %12 = alloca i32, align 4
  store i32 0, i32* %12, align 4
  %13 = alloca i32, align 4
  store i32 0, i32* %13, align 4
  %14 = alloca i32, align 4
  store i32 0, i32* %14, align 4
  %15 = alloca i32, align 4
  store i32 0, i32* %15, align 4
  %16 = alloca i32, align 4
  store i32 0, i32* %16, align 4
  %17 = alloca i32, align 4
  store i32 0, i32* %17, align 4
  %18 = alloca i32, align 4
  store i32 0, i32* %18, align 4
  %19 = alloca i32, align 4
  store i32 0, i32* %19, align 4
  %20 = alloca i32, align 4
  store i32 0, i32* %20, align 4
  %21 = alloca i32, align 4
  store i32 0, i32* %21, align 4
  %22 = alloca i32, align 4
  store i32 0, i32* %22, align 4
  %23 = alloca i32, align 4
  store i32 0, i32* %23, align 4
  %24 = alloca i32, align 4
  store i32 0, i32* %24, align 4
  %25 = alloca i32, align 4
  store i32 0, i32* %25, align 4
  %26 = alloca i32, align 4
  store i32 0, i32* %26, align 4
  %27 = alloca i32, align 4
  store i32 0, i32* %27, align 4
  %28 = alloca i32, align 4
  store i32 0, i32* %28, align 4
  %29 = alloca i32, align 4
  store i32 0, i32* %29, align 4
  %30 = alloca i32, align 4
  store i32 0, i32* %30, align 4
  %31 = alloca i32, align 4
  store i32 0, i32* %31, align 4
  %32 = alloca i32, align 4
  store i32 0, i32* %32, align 4
  %33 = alloca i32, align 4
  store i32 0, i32* %33, align 4
  %34 = alloca i32, align 4
  store i32 0, i32* %34, align 4
  %35 = alloca i32, align 4
  store i32 0, i32* %35, align 4
  %36 = alloca i32, align 4
  store i32 0, i32* %36, align 4
  %37 = alloca i32, align 4
  store i32 0, i32* %37, align 4
  %38 = alloca i32, align 4
  store i32 0, i32* %38, align 4
  %39 = alloca i32, align 4
  store i32 0, i32* %39, align 4
  %40 = alloca i32, align 4
  store i32 0, i32* %40, align 4
  %41 = alloca i32, align 4
  store i32 0, i32* %41, align 4
  %42 = alloca i32, align 4
  store i32 0, i32* %42, align 4
  %43 = alloca i32, align 4
  store i32 0, i32* %43, align 4
  %44 = alloca i32, align 4
  store i32 0, i32* %44, align 4
  %45 = alloca i32, align 4
  store i32 0, i32* %45, align 4
  %46 = alloca i32, align 4
  store i32 0, i32* %46, align 4
  %47 = alloca i32, align 4
  store i32 0, i32* %47, align 4
  %48 = alloca i32, align 4
  store i32 0, i32* %48, align 4
  %49 = alloca i32, align 4
  store i32 0, i32* %49, align 4
  %50 = alloca i32, align 4
  store i32 0, i32* %50, align 4
  %51 = alloca i32, align 4
  store i32 0, i32* %51, align 4
  %52 = alloca i32, align 4
  store i32 0, i32* %52, align 4
  %53 = alloca i32, align 4
  store i32 0, i32* %53, align 4
  %54 = alloca i32, align 4
  store i32 0, i32* %54, align 4
  %55 = alloca i32, align 4
  store i32 0, i32* %55, align 4
  %56 = alloca i32, align 4
  store i32 0, i32* %56, align 4
  %57 = alloca i32, align 4
  store i32 0, i32* %57, align 4
  %58 = alloca i32, align 4
  store i32 0, i32* %58, align 4
  %59 = alloca i32, align 4
  store i32 0, i32* %59, align 4
  %60 = alloca i32, align 4
  store i32 0, i32* %60, align 4
  %61 = alloca i32, align 4
  store i32 0, i32* %61, align 4
  %62 = alloca i32, align 4
  store i32 0, i32* %62, align 4
  %remaing_gas = alloca i64, align 8
  store i64 210000, i64* %remaing_gas, align 4
  %MEMORY = call i8* @malloc(i64 728)
  %63 = call i8* @malloc(i64 8192)
  %STACK = bitcast i8* %63 to i256*
  %STACK_DEP_PTR = alloca i64, align 8
  store i64 0, i64* %STACK_DEP_PTR, align 4
  %JMP_TARGET_PTR = alloca i64, align 8
  store i64 0, i64* %JMP_TARGET_PTR, align 4
  br label %.0

.0:                                               ; preds = %Entry
  %64 = load i64, i64* %remaing_gas, align 4
  %65 = icmp ugt i64 88, %64
  br i1 %65, label %Abort, label %66

66:                                               ; preds = %.0
  %67 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %68 = xor i32 %67, 1383
  %69 = urem i32 %68, 4096
  %70 = getelementptr i8, i8 addrspace(1)* %4, i32 %69
  %71 = load i8, i8 addrspace(1)* %70, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %70, align 1, !nosanitize !3
  store i32 691, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %72 = sub i64 %64, 88
  store i64 %72, i64* %remaing_gas, align 4
  %73 = trunc i256 64 to i64
  %74 = alloca i256, align 8
  store i256 128, i256* %74, align 4
  %75 = bitcast i256* %74 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %73, i8* %75, i64 32)
  %76 = zext i32 %3 to i256
  %77 = icmp ult i256 %76, 4
  %78 = trunc i256 505 to i64
  %jump.check = icmp ne i1 %77, false
  br i1 %jump.check, label %.505, label %.13, !EVMBB !4

.13:                                              ; preds = %66
  %79 = load i64, i64* %remaing_gas, align 4
  %80 = icmp ugt i64 192, %79
  br i1 %80, label %Abort, label %81

81:                                               ; preds = %.13
  %82 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %83 = xor i32 %82, 966
  %84 = urem i32 %83, 4096
  %85 = getelementptr i8, i8 addrspace(1)* %4, i32 %84
  %86 = load i8, i8 addrspace(1)* %85, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %85, align 1, !nosanitize !3
  store i32 483, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %87 = sub i64 %79, 192
  store i64 %87, i64* %remaing_gas, align 4
  %88 = trunc i256 0 to i64
  %89 = alloca i256, align 8
  %90 = bitcast i256* %89 to i8*
  call void @__device_calldataload(i8* %90, i8* %2, i64 %88)
  %91 = load i256, i256* %89, align 4
  %92 = alloca i256, align 8
  store i256 %91, i256* %92, align 4
  %93 = alloca i256, align 8
  store i256 26959946667150639794667015087019630673637144422540572481103610249216, i256* %93, align 4
  %94 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %92, i256* %93, i256* %94), !pc !5, !intsan !6
  %95 = load i256, i256* %94, align 4
  %96 = and i256 4294967295, %95
  %97 = icmp eq i256 92974305, %96
  %98 = trunc i256 515 to i64
  %jump.check1 = icmp ne i1 %97, false
  %99 = load i64, i64* %STACK_DEP_PTR, align 4
  %100 = add i64 %99, 1
  store i64 %100, i64* %STACK_DEP_PTR, align 4
  %101 = load i64, i64* %STACK_DEP_PTR, align 4
  %102 = getelementptr i256, i256* %STACK, i64 %101
  store i256 %96, i256* %102, align 4
  br i1 %jump.check1, label %.515, label %.65, !EVMBB !4

.65:                                              ; preds = %81
  %103 = load i64, i64* %remaing_gas, align 4
  %104 = icmp ugt i64 112, %103
  br i1 %104, label %Abort, label %105

105:                                              ; preds = %.65
  %106 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %107 = xor i32 %106, 2153
  %108 = urem i32 %107, 4096
  %109 = getelementptr i8, i8 addrspace(1)* %4, i32 %108
  %110 = load i8, i8 addrspace(1)* %109, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %109, align 1, !nosanitize !3
  store i32 1076, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %111 = sub i64 %103, 112
  store i64 %111, i64* %remaing_gas, align 4
  %112 = load i64, i64* %STACK_DEP_PTR, align 4
  %113 = sub i64 %112, 1
  store i64 %113, i64* %STACK_DEP_PTR, align 4
  %114 = icmp eq i256 102648143, %96
  %115 = trunc i256 538 to i64
  %jump.check2 = icmp ne i1 %114, false
  %116 = load i64, i64* %STACK_DEP_PTR, align 4
  %117 = add i64 %116, 1
  store i64 %117, i64* %STACK_DEP_PTR, align 4
  %118 = load i64, i64* %STACK_DEP_PTR, align 4
  %119 = getelementptr i256, i256* %STACK, i64 %118
  store i256 %96, i256* %119, align 4
  br i1 %jump.check2, label %.538, label %.76, !EVMBB !4

.76:                                              ; preds = %105
  %120 = load i64, i64* %remaing_gas, align 4
  %121 = icmp ugt i64 112, %120
  br i1 %121, label %Abort, label %122

122:                                              ; preds = %.76
  %123 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %124 = xor i32 %123, 2163
  %125 = urem i32 %124, 4096
  %126 = getelementptr i8, i8 addrspace(1)* %4, i32 %125
  %127 = load i8, i8 addrspace(1)* %126, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %126, align 1, !nosanitize !3
  store i32 1081, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %128 = sub i64 %120, 112
  store i64 %128, i64* %remaing_gas, align 4
  %129 = load i64, i64* %STACK_DEP_PTR, align 4
  %130 = sub i64 %129, 1
  store i64 %130, i64* %STACK_DEP_PTR, align 4
  %131 = icmp eq i256 220188226, %96
  %132 = trunc i256 661 to i64
  %jump.check5 = icmp ne i1 %131, false
  %133 = load i64, i64* %STACK_DEP_PTR, align 4
  %134 = add i64 %133, 1
  store i64 %134, i64* %STACK_DEP_PTR, align 4
  %135 = load i64, i64* %STACK_DEP_PTR, align 4
  %136 = getelementptr i256, i256* %STACK, i64 %135
  store i256 %96, i256* %136, align 4
  br i1 %jump.check5, label %.661, label %.87, !EVMBB !4

.87:                                              ; preds = %122
  %137 = load i64, i64* %remaing_gas, align 4
  %138 = icmp ugt i64 112, %137
  br i1 %138, label %Abort, label %139

139:                                              ; preds = %.87
  %140 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %141 = xor i32 %140, 3153
  %142 = urem i32 %141, 4096
  %143 = getelementptr i8, i8 addrspace(1)* %4, i32 %142
  %144 = load i8, i8 addrspace(1)* %143, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %143, align 1, !nosanitize !3
  store i32 1576, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %145 = sub i64 %137, 112
  store i64 %145, i64* %remaing_gas, align 4
  %146 = load i64, i64* %STACK_DEP_PTR, align 4
  %147 = sub i64 %146, 1
  store i64 %147, i64* %STACK_DEP_PTR, align 4
  %148 = icmp eq i256 291572773, %96
  %149 = trunc i256 704 to i64
  %jump.check8 = icmp ne i1 %148, false
  %150 = load i64, i64* %STACK_DEP_PTR, align 4
  %151 = add i64 %150, 1
  store i64 %151, i64* %STACK_DEP_PTR, align 4
  %152 = load i64, i64* %STACK_DEP_PTR, align 4
  %153 = getelementptr i256, i256* %STACK, i64 %152
  store i256 %96, i256* %153, align 4
  br i1 %jump.check8, label %.704, label %.98, !EVMBB !4

.98:                                              ; preds = %139
  %154 = load i64, i64* %remaing_gas, align 4
  %155 = icmp ugt i64 112, %154
  br i1 %155, label %Abort, label %156

156:                                              ; preds = %.98
  %157 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %158 = xor i32 %157, 3327
  %159 = urem i32 %158, 4096
  %160 = getelementptr i8, i8 addrspace(1)* %4, i32 %159
  %161 = load i8, i8 addrspace(1)* %160, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %160, align 1, !nosanitize !3
  store i32 1663, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %162 = sub i64 %154, 112
  store i64 %162, i64* %remaing_gas, align 4
  %163 = load i64, i64* %STACK_DEP_PTR, align 4
  %164 = sub i64 %163, 1
  store i64 %164, i64* %STACK_DEP_PTR, align 4
  %165 = icmp eq i256 292318891, %96
  %166 = trunc i256 714 to i64
  %jump.check12 = icmp ne i1 %165, false
  %167 = load i64, i64* %STACK_DEP_PTR, align 4
  %168 = add i64 %167, 1
  store i64 %168, i64* %STACK_DEP_PTR, align 4
  %169 = load i64, i64* %STACK_DEP_PTR, align 4
  %170 = getelementptr i256, i256* %STACK, i64 %169
  store i256 %96, i256* %170, align 4
  br i1 %jump.check12, label %.714, label %.109, !EVMBB !4

.109:                                             ; preds = %156
  %171 = load i64, i64* %remaing_gas, align 4
  %172 = icmp ugt i64 112, %171
  br i1 %172, label %Abort, label %173

173:                                              ; preds = %.109
  %174 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %175 = xor i32 %174, 1098
  %176 = urem i32 %175, 4096
  %177 = getelementptr i8, i8 addrspace(1)* %4, i32 %176
  %178 = load i8, i8 addrspace(1)* %177, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %177, align 1, !nosanitize !3
  store i32 549, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %179 = sub i64 %171, 112
  store i64 %179, i64* %remaing_gas, align 4
  %180 = load i64, i64* %STACK_DEP_PTR, align 4
  %181 = sub i64 %180, 1
  store i64 %181, i64* %STACK_DEP_PTR, align 4
  %182 = icmp eq i256 304429676, %96
  %183 = trunc i256 801 to i64
  %jump.check15 = icmp ne i1 %182, false
  %184 = load i64, i64* %STACK_DEP_PTR, align 4
  %185 = add i64 %184, 1
  store i64 %185, i64* %STACK_DEP_PTR, align 4
  %186 = load i64, i64* %STACK_DEP_PTR, align 4
  %187 = getelementptr i256, i256* %STACK, i64 %186
  store i256 %96, i256* %187, align 4
  br i1 %jump.check15, label %.801, label %.120, !EVMBB !4

.120:                                             ; preds = %173
  %188 = load i64, i64* %remaing_gas, align 4
  %189 = icmp ugt i64 112, %188
  br i1 %189, label %Abort, label %190

190:                                              ; preds = %.120
  %191 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %192 = xor i32 %191, 2284
  %193 = urem i32 %192, 4096
  %194 = getelementptr i8, i8 addrspace(1)* %4, i32 %193
  %195 = load i8, i8 addrspace(1)* %194, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %194, align 1, !nosanitize !3
  store i32 1142, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %196 = sub i64 %188, 112
  store i64 %196, i64* %remaing_gas, align 4
  %197 = load i64, i64* %STACK_DEP_PTR, align 4
  %198 = sub i64 %197, 1
  store i64 %198, i64* %STACK_DEP_PTR, align 4
  %199 = icmp eq i256 321578473, %96
  %200 = trunc i256 824 to i64
  %jump.check20 = icmp ne i1 %199, false
  %201 = load i64, i64* %STACK_DEP_PTR, align 4
  %202 = add i64 %201, 1
  store i64 %202, i64* %STACK_DEP_PTR, align 4
  %203 = load i64, i64* %STACK_DEP_PTR, align 4
  %204 = getelementptr i256, i256* %STACK, i64 %203
  store i256 %96, i256* %204, align 4
  br i1 %jump.check20, label %.824, label %.131, !EVMBB !4

.131:                                             ; preds = %190
  %205 = load i64, i64* %remaing_gas, align 4
  %206 = icmp ugt i64 112, %205
  br i1 %206, label %Abort, label %207

207:                                              ; preds = %.131
  %208 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %209 = xor i32 %208, 3881
  %210 = urem i32 %209, 4096
  %211 = getelementptr i8, i8 addrspace(1)* %4, i32 %210
  %212 = load i8, i8 addrspace(1)* %211, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %211, align 1, !nosanitize !3
  store i32 1940, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %213 = sub i64 %205, 112
  store i64 %213, i64* %remaing_gas, align 4
  %214 = load i64, i64* %STACK_DEP_PTR, align 4
  %215 = sub i64 %214, 1
  store i64 %215, i64* %STACK_DEP_PTR, align 4
  %216 = icmp eq i256 353692244, %96
  %217 = trunc i256 867 to i64
  %jump.check25 = icmp ne i1 %216, false
  %218 = load i64, i64* %STACK_DEP_PTR, align 4
  %219 = add i64 %218, 1
  store i64 %219, i64* %STACK_DEP_PTR, align 4
  %220 = load i64, i64* %STACK_DEP_PTR, align 4
  %221 = getelementptr i256, i256* %STACK, i64 %220
  store i256 %96, i256* %221, align 4
  br i1 %jump.check25, label %.867, label %.142, !EVMBB !4

.142:                                             ; preds = %207
  %222 = load i64, i64* %remaing_gas, align 4
  %223 = icmp ugt i64 112, %222
  br i1 %223, label %Abort, label %224

224:                                              ; preds = %.142
  %225 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %226 = xor i32 %225, 3277
  %227 = urem i32 %226, 4096
  %228 = getelementptr i8, i8 addrspace(1)* %4, i32 %227
  %229 = load i8, i8 addrspace(1)* %228, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %228, align 1, !nosanitize !3
  store i32 1638, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %230 = sub i64 %222, 112
  store i64 %230, i64* %remaing_gas, align 4
  %231 = load i64, i64* %STACK_DEP_PTR, align 4
  %232 = sub i64 %231, 1
  store i64 %232, i64* %STACK_DEP_PTR, align 4
  %233 = icmp eq i256 410673877, %96
  %234 = trunc i256 954 to i64
  %jump.check30 = icmp ne i1 %233, false
  %235 = load i64, i64* %STACK_DEP_PTR, align 4
  %236 = add i64 %235, 1
  store i64 %236, i64* %STACK_DEP_PTR, align 4
  %237 = load i64, i64* %STACK_DEP_PTR, align 4
  %238 = getelementptr i256, i256* %STACK, i64 %237
  store i256 %96, i256* %238, align 4
  br i1 %jump.check30, label %.954, label %.153, !EVMBB !4

.153:                                             ; preds = %224
  %239 = load i64, i64* %remaing_gas, align 4
  %240 = icmp ugt i64 112, %239
  br i1 %240, label %Abort, label %241

241:                                              ; preds = %.153
  %242 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %243 = xor i32 %242, 2234
  %244 = urem i32 %243, 4096
  %245 = getelementptr i8, i8 addrspace(1)* %4, i32 %244
  %246 = load i8, i8 addrspace(1)* %245, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %245, align 1, !nosanitize !3
  store i32 1117, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %247 = sub i64 %239, 112
  store i64 %247, i64* %remaing_gas, align 4
  %248 = load i64, i64* %STACK_DEP_PTR, align 4
  %249 = sub i64 %248, 1
  store i64 %249, i64* %STACK_DEP_PTR, align 4
  %250 = icmp eq i256 519772142, %96
  %251 = trunc i256 1001 to i64
  %jump.check34 = icmp ne i1 %250, false
  %252 = load i64, i64* %STACK_DEP_PTR, align 4
  %253 = add i64 %252, 1
  store i64 %253, i64* %STACK_DEP_PTR, align 4
  %254 = load i64, i64* %STACK_DEP_PTR, align 4
  %255 = getelementptr i256, i256* %STACK, i64 %254
  store i256 %96, i256* %255, align 4
  br i1 %jump.check34, label %.1001, label %.164, !EVMBB !4

.164:                                             ; preds = %241
  %256 = load i64, i64* %remaing_gas, align 4
  %257 = icmp ugt i64 112, %256
  br i1 %257, label %Abort, label %258

258:                                              ; preds = %.164
  %259 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %260 = xor i32 %259, 1963
  %261 = urem i32 %260, 4096
  %262 = getelementptr i8, i8 addrspace(1)* %4, i32 %261
  %263 = load i8, i8 addrspace(1)* %262, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %262, align 1, !nosanitize !3
  store i32 981, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %264 = sub i64 %256, 112
  store i64 %264, i64* %remaing_gas, align 4
  %265 = load i64, i64* %STACK_DEP_PTR, align 4
  %266 = sub i64 %265, 1
  store i64 %266, i64* %STACK_DEP_PTR, align 4
  %267 = icmp eq i256 589636584, %96
  %268 = trunc i256 1068 to i64
  %jump.check36 = icmp ne i1 %267, false
  %269 = load i64, i64* %STACK_DEP_PTR, align 4
  %270 = add i64 %269, 1
  store i64 %270, i64* %STACK_DEP_PTR, align 4
  %271 = load i64, i64* %STACK_DEP_PTR, align 4
  %272 = getelementptr i256, i256* %STACK, i64 %271
  store i256 %96, i256* %272, align 4
  br i1 %jump.check36, label %.1068, label %.175, !EVMBB !4

.175:                                             ; preds = %258
  %273 = load i64, i64* %remaing_gas, align 4
  %274 = icmp ugt i64 112, %273
  br i1 %274, label %Abort, label %275

275:                                              ; preds = %.175
  %276 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %277 = xor i32 %276, 498
  %278 = urem i32 %277, 4096
  %279 = getelementptr i8, i8 addrspace(1)* %4, i32 %278
  %280 = load i8, i8 addrspace(1)* %279, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %279, align 1, !nosanitize !3
  store i32 249, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %281 = sub i64 %273, 112
  store i64 %281, i64* %remaing_gas, align 4
  %282 = load i64, i64* %STACK_DEP_PTR, align 4
  %283 = sub i64 %282, 1
  store i64 %283, i64* %STACK_DEP_PTR, align 4
  %284 = icmp eq i256 668739966, %96
  %285 = trunc i256 1091 to i64
  %jump.check40 = icmp ne i1 %284, false
  %286 = load i64, i64* %STACK_DEP_PTR, align 4
  %287 = add i64 %286, 1
  store i64 %287, i64* %STACK_DEP_PTR, align 4
  %288 = load i64, i64* %STACK_DEP_PTR, align 4
  %289 = getelementptr i256, i256* %STACK, i64 %288
  store i256 %96, i256* %289, align 4
  br i1 %jump.check40, label %.1091, label %.186, !EVMBB !4

.186:                                             ; preds = %275
  %290 = load i64, i64* %remaing_gas, align 4
  %291 = icmp ugt i64 112, %290
  br i1 %291, label %Abort, label %292

292:                                              ; preds = %.186
  %293 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %294 = xor i32 %293, 3835
  %295 = urem i32 %294, 4096
  %296 = getelementptr i8, i8 addrspace(1)* %4, i32 %295
  %297 = load i8, i8 addrspace(1)* %296, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %296, align 1, !nosanitize !3
  store i32 1917, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %298 = sub i64 %290, 112
  store i64 %298, i64* %remaing_gas, align 4
  %299 = load i64, i64* %STACK_DEP_PTR, align 4
  %300 = sub i64 %299, 1
  store i64 %300, i64* %STACK_DEP_PTR, align 4
  %301 = icmp eq i256 951843408, %96
  %302 = trunc i256 1210 to i64
  %jump.check44 = icmp ne i1 %301, false
  %303 = load i64, i64* %STACK_DEP_PTR, align 4
  %304 = add i64 %303, 1
  store i64 %304, i64* %STACK_DEP_PTR, align 4
  %305 = load i64, i64* %STACK_DEP_PTR, align 4
  %306 = getelementptr i256, i256* %STACK, i64 %305
  store i256 %96, i256* %306, align 4
  br i1 %jump.check44, label %.1210, label %.197, !EVMBB !4

.197:                                             ; preds = %292
  %307 = load i64, i64* %remaing_gas, align 4
  %308 = icmp ugt i64 112, %307
  br i1 %308, label %Abort, label %309

309:                                              ; preds = %.197
  %310 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %311 = xor i32 %310, 2531
  %312 = urem i32 %311, 4096
  %313 = getelementptr i8, i8 addrspace(1)* %4, i32 %312
  %314 = load i8, i8 addrspace(1)* %313, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %313, align 1, !nosanitize !3
  store i32 1265, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %315 = sub i64 %307, 112
  store i64 %315, i64* %remaing_gas, align 4
  %316 = load i64, i64* %STACK_DEP_PTR, align 4
  %317 = sub i64 %316, 1
  store i64 %317, i64* %STACK_DEP_PTR, align 4
  %318 = icmp eq i256 1063795562, %96
  %319 = trunc i256 1399 to i64
  %jump.check50 = icmp ne i1 %318, false
  %320 = load i64, i64* %STACK_DEP_PTR, align 4
  %321 = add i64 %320, 1
  store i64 %321, i64* %STACK_DEP_PTR, align 4
  %322 = load i64, i64* %STACK_DEP_PTR, align 4
  %323 = getelementptr i256, i256* %STACK, i64 %322
  store i256 %96, i256* %323, align 4
  br i1 %jump.check50, label %.1399, label %.208, !EVMBB !4

.208:                                             ; preds = %309
  %324 = load i64, i64* %remaing_gas, align 4
  %325 = icmp ugt i64 112, %324
  br i1 %325, label %Abort, label %326

326:                                              ; preds = %.208
  %327 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %328 = xor i32 %327, 326
  %329 = urem i32 %328, 4096
  %330 = getelementptr i8, i8 addrspace(1)* %4, i32 %329
  %331 = load i8, i8 addrspace(1)* %330, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %330, align 1, !nosanitize !3
  store i32 163, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %332 = sub i64 %324, 112
  store i64 %332, i64* %remaing_gas, align 4
  %333 = load i64, i64* %STACK_DEP_PTR, align 4
  %334 = sub i64 %333, 1
  store i64 %334, i64* %STACK_DEP_PTR, align 4
  %335 = icmp eq i256 1072389931, %96
  %336 = trunc i256 1446 to i64
  %jump.check57 = icmp ne i1 %335, false
  %337 = load i64, i64* %STACK_DEP_PTR, align 4
  %338 = add i64 %337, 1
  store i64 %338, i64* %STACK_DEP_PTR, align 4
  %339 = load i64, i64* %STACK_DEP_PTR, align 4
  %340 = getelementptr i256, i256* %STACK, i64 %339
  store i256 %96, i256* %340, align 4
  br i1 %jump.check57, label %.1446, label %.219, !EVMBB !4

.219:                                             ; preds = %326
  %341 = load i64, i64* %remaing_gas, align 4
  %342 = icmp ugt i64 112, %341
  br i1 %342, label %Abort, label %343

343:                                              ; preds = %.219
  %344 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %345 = xor i32 %344, 124
  %346 = urem i32 %345, 4096
  %347 = getelementptr i8, i8 addrspace(1)* %4, i32 %346
  %348 = load i8, i8 addrspace(1)* %347, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %347, align 1, !nosanitize !3
  store i32 62, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %349 = sub i64 %341, 112
  store i64 %349, i64* %remaing_gas, align 4
  %350 = load i64, i64* %STACK_DEP_PTR, align 4
  %351 = sub i64 %350, 1
  store i64 %351, i64* %STACK_DEP_PTR, align 4
  %352 = icmp eq i256 1084529302, %96
  %353 = trunc i256 1573 to i64
  %jump.check61 = icmp ne i1 %352, false
  %354 = load i64, i64* %STACK_DEP_PTR, align 4
  %355 = add i64 %354, 1
  store i64 %355, i64* %STACK_DEP_PTR, align 4
  %356 = load i64, i64* %STACK_DEP_PTR, align 4
  %357 = getelementptr i256, i256* %STACK, i64 %356
  store i256 %96, i256* %357, align 4
  br i1 %jump.check61, label %.1573, label %.230, !EVMBB !4

.230:                                             ; preds = %343
  %358 = load i64, i64* %remaing_gas, align 4
  %359 = icmp ugt i64 112, %358
  br i1 %359, label %Abort, label %360

360:                                              ; preds = %.230
  %361 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %362 = xor i32 %361, 706
  %363 = urem i32 %362, 4096
  %364 = getelementptr i8, i8 addrspace(1)* %4, i32 %363
  %365 = load i8, i8 addrspace(1)* %364, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %364, align 1, !nosanitize !3
  store i32 353, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %366 = sub i64 %358, 112
  store i64 %366, i64* %remaing_gas, align 4
  %367 = load i64, i64* %STACK_DEP_PTR, align 4
  %368 = sub i64 %367, 1
  store i64 %368, i64* %STACK_DEP_PTR, align 4
  %369 = icmp eq i256 1181869662, %96
  %370 = trunc i256 1616 to i64
  %jump.check64 = icmp ne i1 %369, false
  %371 = load i64, i64* %STACK_DEP_PTR, align 4
  %372 = add i64 %371, 1
  store i64 %372, i64* %STACK_DEP_PTR, align 4
  %373 = load i64, i64* %STACK_DEP_PTR, align 4
  %374 = getelementptr i256, i256* %STACK, i64 %373
  store i256 %96, i256* %374, align 4
  br i1 %jump.check64, label %.1616, label %.241, !EVMBB !4

.241:                                             ; preds = %360
  %375 = load i64, i64* %remaing_gas, align 4
  %376 = icmp ugt i64 112, %375
  br i1 %376, label %Abort, label %377

377:                                              ; preds = %.241
  %378 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %379 = xor i32 %378, 2132
  %380 = urem i32 %379, 4096
  %381 = getelementptr i8, i8 addrspace(1)* %4, i32 %380
  %382 = load i8, i8 addrspace(1)* %381, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %381, align 1, !nosanitize !3
  store i32 1066, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %383 = sub i64 %375, 112
  store i64 %383, i64* %remaing_gas, align 4
  %384 = load i64, i64* %STACK_DEP_PTR, align 4
  %385 = sub i64 %384, 1
  store i64 %385, i64* %STACK_DEP_PTR, align 4
  %386 = icmp eq i256 1315558752, %96
  %387 = trunc i256 1683 to i64
  %jump.check68 = icmp ne i1 %386, false
  %388 = load i64, i64* %STACK_DEP_PTR, align 4
  %389 = add i64 %388, 1
  store i64 %389, i64* %STACK_DEP_PTR, align 4
  %390 = load i64, i64* %STACK_DEP_PTR, align 4
  %391 = getelementptr i256, i256* %STACK, i64 %390
  store i256 %96, i256* %391, align 4
  br i1 %jump.check68, label %.1683, label %.252, !EVMBB !4

.252:                                             ; preds = %377
  %392 = load i64, i64* %remaing_gas, align 4
  %393 = icmp ugt i64 112, %392
  br i1 %393, label %Abort, label %394

394:                                              ; preds = %.252
  %395 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %396 = xor i32 %395, 2040
  %397 = urem i32 %396, 4096
  %398 = getelementptr i8, i8 addrspace(1)* %4, i32 %397
  %399 = load i8, i8 addrspace(1)* %398, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %398, align 1, !nosanitize !3
  store i32 1020, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %400 = sub i64 %392, 112
  store i64 %400, i64* %remaing_gas, align 4
  %401 = load i64, i64* %STACK_DEP_PTR, align 4
  %402 = sub i64 %401, 1
  store i64 %402, i64* %STACK_DEP_PTR, align 4
  %403 = icmp eq i256 1361410410, %96
  %404 = trunc i256 1775 to i64
  %jump.check73 = icmp ne i1 %403, false
  %405 = load i64, i64* %STACK_DEP_PTR, align 4
  %406 = add i64 %405, 1
  store i64 %406, i64* %STACK_DEP_PTR, align 4
  %407 = load i64, i64* %STACK_DEP_PTR, align 4
  %408 = getelementptr i256, i256* %STACK, i64 %407
  store i256 %96, i256* %408, align 4
  br i1 %jump.check73, label %.1775, label %.263, !EVMBB !4

.263:                                             ; preds = %394
  %409 = load i64, i64* %remaing_gas, align 4
  %410 = icmp ugt i64 112, %409
  br i1 %410, label %Abort, label %411

411:                                              ; preds = %.263
  %412 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %413 = xor i32 %412, 795
  %414 = urem i32 %413, 4096
  %415 = getelementptr i8, i8 addrspace(1)* %4, i32 %414
  %416 = load i8, i8 addrspace(1)* %415, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %415, align 1, !nosanitize !3
  store i32 397, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %417 = sub i64 %409, 112
  store i64 %417, i64* %remaing_gas, align 4
  %418 = load i64, i64* %STACK_DEP_PTR, align 4
  %419 = sub i64 %418, 1
  store i64 %419, i64* %STACK_DEP_PTR, align 4
  %420 = icmp eq i256 1363168446, %96
  %421 = trunc i256 1854 to i64
  %jump.check78 = icmp ne i1 %420, false
  %422 = load i64, i64* %STACK_DEP_PTR, align 4
  %423 = add i64 %422, 1
  store i64 %423, i64* %STACK_DEP_PTR, align 4
  %424 = load i64, i64* %STACK_DEP_PTR, align 4
  %425 = getelementptr i256, i256* %STACK, i64 %424
  store i256 %96, i256* %425, align 4
  br i1 %jump.check78, label %.1854, label %.274, !EVMBB !4

.274:                                             ; preds = %411
  %426 = load i64, i64* %remaing_gas, align 4
  %427 = icmp ugt i64 112, %426
  br i1 %427, label %Abort, label %428

428:                                              ; preds = %.274
  %429 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %430 = xor i32 %429, 2536
  %431 = urem i32 %430, 4096
  %432 = getelementptr i8, i8 addrspace(1)* %4, i32 %431
  %433 = load i8, i8 addrspace(1)* %432, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %432, align 1, !nosanitize !3
  store i32 1268, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %434 = sub i64 %426, 112
  store i64 %434, i64* %remaing_gas, align 4
  %435 = load i64, i64* %STACK_DEP_PTR, align 4
  %436 = sub i64 %435, 1
  store i64 %436, i64* %STACK_DEP_PTR, align 4
  %437 = icmp eq i256 1367643826, %96
  %438 = trunc i256 1921 to i64
  %jump.check84 = icmp ne i1 %437, false
  %439 = load i64, i64* %STACK_DEP_PTR, align 4
  %440 = add i64 %439, 1
  store i64 %440, i64* %STACK_DEP_PTR, align 4
  %441 = load i64, i64* %STACK_DEP_PTR, align 4
  %442 = getelementptr i256, i256* %STACK, i64 %441
  store i256 %96, i256* %442, align 4
  br i1 %jump.check84, label %.1921, label %.285, !EVMBB !4

.285:                                             ; preds = %428
  %443 = load i64, i64* %remaing_gas, align 4
  %444 = icmp ugt i64 112, %443
  br i1 %444, label %Abort, label %445

445:                                              ; preds = %.285
  %446 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %447 = xor i32 %446, 3559
  %448 = urem i32 %447, 4096
  %449 = getelementptr i8, i8 addrspace(1)* %4, i32 %448
  %450 = load i8, i8 addrspace(1)* %449, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %449, align 1, !nosanitize !3
  store i32 1779, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %451 = sub i64 %443, 112
  store i64 %451, i64* %remaing_gas, align 4
  %452 = load i64, i64* %STACK_DEP_PTR, align 4
  %453 = sub i64 %452, 1
  store i64 %453, i64* %STACK_DEP_PTR, align 4
  %454 = icmp eq i256 1427034608, %96
  %455 = trunc i256 2015 to i64
  %jump.check88 = icmp ne i1 %454, false
  %456 = load i64, i64* %STACK_DEP_PTR, align 4
  %457 = add i64 %456, 1
  store i64 %457, i64* %STACK_DEP_PTR, align 4
  %458 = load i64, i64* %STACK_DEP_PTR, align 4
  %459 = getelementptr i256, i256* %STACK, i64 %458
  store i256 %96, i256* %459, align 4
  br i1 %jump.check88, label %.2015, label %.296, !EVMBB !4

.296:                                             ; preds = %445
  %460 = load i64, i64* %remaing_gas, align 4
  %461 = icmp ugt i64 112, %460
  br i1 %461, label %Abort, label %462

462:                                              ; preds = %.296
  %463 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %464 = xor i32 %463, 909
  %465 = urem i32 %464, 4096
  %466 = getelementptr i8, i8 addrspace(1)* %4, i32 %465
  %467 = load i8, i8 addrspace(1)* %466, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %466, align 1, !nosanitize !3
  store i32 454, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %468 = sub i64 %460, 112
  store i64 %468, i64* %remaing_gas, align 4
  %469 = load i64, i64* %STACK_DEP_PTR, align 4
  %470 = sub i64 %469, 1
  store i64 %470, i64* %STACK_DEP_PTR, align 4
  %471 = icmp eq i256 1630053619, %96
  %472 = trunc i256 2058 to i64
  %jump.check93 = icmp ne i1 %471, false
  %473 = load i64, i64* %STACK_DEP_PTR, align 4
  %474 = add i64 %473, 1
  store i64 %474, i64* %STACK_DEP_PTR, align 4
  %475 = load i64, i64* %STACK_DEP_PTR, align 4
  %476 = getelementptr i256, i256* %STACK, i64 %475
  store i256 %96, i256* %476, align 4
  br i1 %jump.check93, label %.2058, label %.307, !EVMBB !4

.307:                                             ; preds = %462
  %477 = load i64, i64* %remaing_gas, align 4
  %478 = icmp ugt i64 112, %477
  br i1 %478, label %Abort, label %479

479:                                              ; preds = %.307
  %480 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %481 = xor i32 %480, 3958
  %482 = urem i32 %481, 4096
  %483 = getelementptr i8, i8 addrspace(1)* %4, i32 %482
  %484 = load i8, i8 addrspace(1)* %483, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %483, align 1, !nosanitize !3
  store i32 1979, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %485 = sub i64 %477, 112
  store i64 %485, i64* %remaing_gas, align 4
  %486 = load i64, i64* %STACK_DEP_PTR, align 4
  %487 = sub i64 %486, 1
  store i64 %487, i64* %STACK_DEP_PTR, align 4
  %488 = icmp eq i256 1722736892, %96
  %489 = trunc i256 2101 to i64
  %jump.check99 = icmp ne i1 %488, false
  %490 = load i64, i64* %STACK_DEP_PTR, align 4
  %491 = add i64 %490, 1
  store i64 %491, i64* %STACK_DEP_PTR, align 4
  %492 = load i64, i64* %STACK_DEP_PTR, align 4
  %493 = getelementptr i256, i256* %STACK, i64 %492
  store i256 %96, i256* %493, align 4
  br i1 %jump.check99, label %.2101, label %.318, !EVMBB !4

.318:                                             ; preds = %479
  %494 = load i64, i64* %remaing_gas, align 4
  %495 = icmp ugt i64 112, %494
  br i1 %495, label %Abort, label %496

496:                                              ; preds = %.318
  %497 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %498 = xor i32 %497, 1370
  %499 = urem i32 %498, 4096
  %500 = getelementptr i8, i8 addrspace(1)* %4, i32 %499
  %501 = load i8, i8 addrspace(1)* %500, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %500, align 1, !nosanitize !3
  store i32 685, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %502 = sub i64 %494, 112
  store i64 %502, i64* %remaing_gas, align 4
  %503 = load i64, i64* %STACK_DEP_PTR, align 4
  %504 = sub i64 %503, 1
  store i64 %504, i64* %STACK_DEP_PTR, align 4
  %505 = icmp eq i256 1810370023, %96
  %506 = trunc i256 2144 to i64
  %jump.check103 = icmp ne i1 %505, false
  %507 = load i64, i64* %STACK_DEP_PTR, align 4
  %508 = add i64 %507, 1
  store i64 %508, i64* %STACK_DEP_PTR, align 4
  %509 = load i64, i64* %STACK_DEP_PTR, align 4
  %510 = getelementptr i256, i256* %STACK, i64 %509
  store i256 %96, i256* %510, align 4
  br i1 %jump.check103, label %.2144, label %.329, !EVMBB !4

.329:                                             ; preds = %496
  %511 = load i64, i64* %remaing_gas, align 4
  %512 = icmp ugt i64 112, %511
  br i1 %512, label %Abort, label %513

513:                                              ; preds = %.329
  %514 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %515 = xor i32 %514, 2350
  %516 = urem i32 %515, 4096
  %517 = getelementptr i8, i8 addrspace(1)* %4, i32 %516
  %518 = load i8, i8 addrspace(1)* %517, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %517, align 1, !nosanitize !3
  store i32 1175, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %519 = sub i64 %511, 112
  store i64 %519, i64* %remaing_gas, align 4
  %520 = load i64, i64* %STACK_DEP_PTR, align 4
  %521 = sub i64 %520, 1
  store i64 %521, i64* %STACK_DEP_PTR, align 4
  %522 = icmp eq i256 1909517573, %96
  %523 = trunc i256 2231 to i64
  %jump.check109 = icmp ne i1 %522, false
  %524 = load i64, i64* %STACK_DEP_PTR, align 4
  %525 = add i64 %524, 1
  store i64 %525, i64* %STACK_DEP_PTR, align 4
  %526 = load i64, i64* %STACK_DEP_PTR, align 4
  %527 = getelementptr i256, i256* %STACK, i64 %526
  store i256 %96, i256* %527, align 4
  br i1 %jump.check109, label %.2231, label %.340, !EVMBB !4

.340:                                             ; preds = %513
  %528 = load i64, i64* %remaing_gas, align 4
  %529 = icmp ugt i64 112, %528
  br i1 %529, label %Abort, label %530

530:                                              ; preds = %.340
  %531 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %532 = xor i32 %531, 611
  %533 = urem i32 %532, 4096
  %534 = getelementptr i8, i8 addrspace(1)* %4, i32 %533
  %535 = load i8, i8 addrspace(1)* %534, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %534, align 1, !nosanitize !3
  store i32 305, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %536 = sub i64 %528, 112
  store i64 %536, i64* %remaing_gas, align 4
  %537 = load i64, i64* %STACK_DEP_PTR, align 4
  %538 = sub i64 %537, 1
  store i64 %538, i64* %STACK_DEP_PTR, align 4
  %539 = icmp eq i256 1917512144, %96
  %540 = trunc i256 2304 to i64
  %jump.check115 = icmp ne i1 %539, false
  %541 = load i64, i64* %STACK_DEP_PTR, align 4
  %542 = add i64 %541, 1
  store i64 %542, i64* %STACK_DEP_PTR, align 4
  %543 = load i64, i64* %STACK_DEP_PTR, align 4
  %544 = getelementptr i256, i256* %STACK, i64 %543
  store i256 %96, i256* %544, align 4
  br i1 %jump.check115, label %.2304, label %.351, !EVMBB !4

.351:                                             ; preds = %530
  %545 = load i64, i64* %remaing_gas, align 4
  %546 = icmp ugt i64 112, %545
  br i1 %546, label %Abort, label %547

547:                                              ; preds = %.351
  %548 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %549 = xor i32 %548, 563
  %550 = urem i32 %549, 4096
  %551 = getelementptr i8, i8 addrspace(1)* %4, i32 %550
  %552 = load i8, i8 addrspace(1)* %551, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %551, align 1, !nosanitize !3
  store i32 281, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %553 = sub i64 %545, 112
  store i64 %553, i64* %remaing_gas, align 4
  %554 = load i64, i64* %STACK_DEP_PTR, align 4
  %555 = sub i64 %554, 1
  store i64 %555, i64* %STACK_DEP_PTR, align 4
  %556 = icmp eq i256 2191861853, %96
  %557 = trunc i256 2347 to i64
  %jump.check120 = icmp ne i1 %556, false
  %558 = load i64, i64* %STACK_DEP_PTR, align 4
  %559 = add i64 %558, 1
  store i64 %559, i64* %STACK_DEP_PTR, align 4
  %560 = load i64, i64* %STACK_DEP_PTR, align 4
  %561 = getelementptr i256, i256* %STACK, i64 %560
  store i256 %96, i256* %561, align 4
  br i1 %jump.check120, label %.2347, label %.362, !EVMBB !4

.362:                                             ; preds = %547
  %562 = load i64, i64* %remaing_gas, align 4
  %563 = icmp ugt i64 112, %562
  br i1 %563, label %Abort, label %564

564:                                              ; preds = %.362
  %565 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %566 = xor i32 %565, 1951
  %567 = urem i32 %566, 4096
  %568 = getelementptr i8, i8 addrspace(1)* %4, i32 %567
  %569 = load i8, i8 addrspace(1)* %568, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %568, align 1, !nosanitize !3
  store i32 975, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %570 = sub i64 %562, 112
  store i64 %570, i64* %remaing_gas, align 4
  %571 = load i64, i64* %STACK_DEP_PTR, align 4
  %572 = sub i64 %571, 1
  store i64 %572, i64* %STACK_DEP_PTR, align 4
  %573 = icmp eq i256 2246754399, %96
  %574 = trunc i256 2390 to i64
  %jump.check124 = icmp ne i1 %573, false
  %575 = load i64, i64* %STACK_DEP_PTR, align 4
  %576 = add i64 %575, 1
  store i64 %576, i64* %STACK_DEP_PTR, align 4
  %577 = load i64, i64* %STACK_DEP_PTR, align 4
  %578 = getelementptr i256, i256* %STACK, i64 %577
  store i256 %96, i256* %578, align 4
  br i1 %jump.check124, label %.2390, label %.373, !EVMBB !4

.373:                                             ; preds = %564
  %579 = load i64, i64* %remaing_gas, align 4
  %580 = icmp ugt i64 112, %579
  br i1 %580, label %Abort, label %581

581:                                              ; preds = %.373
  %582 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %583 = xor i32 %582, 1225
  %584 = urem i32 %583, 4096
  %585 = getelementptr i8, i8 addrspace(1)* %4, i32 %584
  %586 = load i8, i8 addrspace(1)* %585, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %585, align 1, !nosanitize !3
  store i32 612, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %587 = sub i64 %579, 112
  store i64 %587, i64* %remaing_gas, align 4
  %588 = load i64, i64* %STACK_DEP_PTR, align 4
  %589 = sub i64 %588, 1
  store i64 %589, i64* %STACK_DEP_PTR, align 4
  %590 = icmp eq i256 2376452955, %96
  %591 = trunc i256 2457 to i64
  %jump.check129 = icmp ne i1 %590, false
  %592 = load i64, i64* %STACK_DEP_PTR, align 4
  %593 = add i64 %592, 1
  store i64 %593, i64* %STACK_DEP_PTR, align 4
  %594 = load i64, i64* %STACK_DEP_PTR, align 4
  %595 = getelementptr i256, i256* %STACK, i64 %594
  store i256 %96, i256* %595, align 4
  br i1 %jump.check129, label %.2457, label %.384, !EVMBB !4

.384:                                             ; preds = %581
  %596 = load i64, i64* %remaing_gas, align 4
  %597 = icmp ugt i64 112, %596
  br i1 %597, label %Abort, label %598

598:                                              ; preds = %.384
  %599 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %600 = xor i32 %599, 1946
  %601 = urem i32 %600, 4096
  %602 = getelementptr i8, i8 addrspace(1)* %4, i32 %601
  %603 = load i8, i8 addrspace(1)* %602, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %602, align 1, !nosanitize !3
  store i32 973, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %604 = sub i64 %596, 112
  store i64 %604, i64* %remaing_gas, align 4
  %605 = load i64, i64* %STACK_DEP_PTR, align 4
  %606 = sub i64 %605, 1
  store i64 %606, i64* %STACK_DEP_PTR, align 4
  %607 = icmp eq i256 2763980711, %96
  %608 = trunc i256 2544 to i64
  %jump.check134 = icmp ne i1 %607, false
  %609 = load i64, i64* %STACK_DEP_PTR, align 4
  %610 = add i64 %609, 1
  store i64 %610, i64* %STACK_DEP_PTR, align 4
  %611 = load i64, i64* %STACK_DEP_PTR, align 4
  %612 = getelementptr i256, i256* %STACK, i64 %611
  store i256 %96, i256* %612, align 4
  br i1 %jump.check134, label %.2544, label %.395, !EVMBB !4

.395:                                             ; preds = %598
  %613 = load i64, i64* %remaing_gas, align 4
  %614 = icmp ugt i64 112, %613
  br i1 %614, label %Abort, label %615

615:                                              ; preds = %.395
  %616 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %617 = xor i32 %616, 2918
  %618 = urem i32 %617, 4096
  %619 = getelementptr i8, i8 addrspace(1)* %4, i32 %618
  %620 = load i8, i8 addrspace(1)* %619, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %619, align 1, !nosanitize !3
  store i32 1459, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %621 = sub i64 %613, 112
  store i64 %621, i64* %remaing_gas, align 4
  %622 = load i64, i64* %STACK_DEP_PTR, align 4
  %623 = sub i64 %622, 1
  store i64 %623, i64* %STACK_DEP_PTR, align 4
  %624 = icmp eq i256 3300679077, %96
  %625 = trunc i256 2554 to i64
  %jump.check137 = icmp ne i1 %624, false
  %626 = load i64, i64* %STACK_DEP_PTR, align 4
  %627 = add i64 %626, 1
  store i64 %627, i64* %STACK_DEP_PTR, align 4
  %628 = load i64, i64* %STACK_DEP_PTR, align 4
  %629 = getelementptr i256, i256* %STACK, i64 %628
  store i256 %96, i256* %629, align 4
  br i1 %jump.check137, label %.2554, label %.406, !EVMBB !4

.406:                                             ; preds = %615
  %630 = load i64, i64* %remaing_gas, align 4
  %631 = icmp ugt i64 112, %630
  br i1 %631, label %Abort, label %632

632:                                              ; preds = %.406
  %633 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %634 = xor i32 %633, 3378
  %635 = urem i32 %634, 4096
  %636 = getelementptr i8, i8 addrspace(1)* %4, i32 %635
  %637 = load i8, i8 addrspace(1)* %636, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %636, align 1, !nosanitize !3
  store i32 1689, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %638 = sub i64 %630, 112
  store i64 %638, i64* %remaing_gas, align 4
  %639 = load i64, i64* %STACK_DEP_PTR, align 4
  %640 = sub i64 %639, 1
  store i64 %640, i64* %STACK_DEP_PTR, align 4
  %641 = icmp eq i256 3372401582, %96
  %642 = trunc i256 2577 to i64
  %jump.check140 = icmp ne i1 %641, false
  %643 = load i64, i64* %STACK_DEP_PTR, align 4
  %644 = add i64 %643, 1
  store i64 %644, i64* %STACK_DEP_PTR, align 4
  %645 = load i64, i64* %STACK_DEP_PTR, align 4
  %646 = getelementptr i256, i256* %STACK, i64 %645
  store i256 %96, i256* %646, align 4
  br i1 %jump.check140, label %.2577, label %.417, !EVMBB !4

.417:                                             ; preds = %632
  %647 = load i64, i64* %remaing_gas, align 4
  %648 = icmp ugt i64 112, %647
  br i1 %648, label %Abort, label %649

649:                                              ; preds = %.417
  %650 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %651 = xor i32 %650, 13
  %652 = urem i32 %651, 4096
  %653 = getelementptr i8, i8 addrspace(1)* %4, i32 %652
  %654 = load i8, i8 addrspace(1)* %653, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %653, align 1, !nosanitize !3
  store i32 6, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %655 = sub i64 %647, 112
  store i64 %655, i64* %remaing_gas, align 4
  %656 = load i64, i64* %STACK_DEP_PTR, align 4
  %657 = sub i64 %656, 1
  store i64 %657, i64* %STACK_DEP_PTR, align 4
  %658 = icmp eq i256 3405455874, %96
  %659 = trunc i256 2704 to i64
  %jump.check145 = icmp ne i1 %658, false
  %660 = load i64, i64* %STACK_DEP_PTR, align 4
  %661 = add i64 %660, 1
  store i64 %661, i64* %STACK_DEP_PTR, align 4
  %662 = load i64, i64* %STACK_DEP_PTR, align 4
  %663 = getelementptr i256, i256* %STACK, i64 %662
  store i256 %96, i256* %663, align 4
  br i1 %jump.check145, label %.2704, label %.428, !EVMBB !4

.428:                                             ; preds = %649
  %664 = load i64, i64* %remaing_gas, align 4
  %665 = icmp ugt i64 112, %664
  br i1 %665, label %Abort, label %666

666:                                              ; preds = %.428
  %667 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %668 = xor i32 %667, 1975
  %669 = urem i32 %668, 4096
  %670 = getelementptr i8, i8 addrspace(1)* %4, i32 %669
  %671 = load i8, i8 addrspace(1)* %670, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %670, align 1, !nosanitize !3
  store i32 987, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %672 = sub i64 %664, 112
  store i64 %672, i64* %remaing_gas, align 4
  %673 = load i64, i64* %STACK_DEP_PTR, align 4
  %674 = sub i64 %673, 1
  store i64 %674, i64* %STACK_DEP_PTR, align 4
  %675 = icmp eq i256 3525146960, %96
  %676 = trunc i256 2747 to i64
  %jump.check149 = icmp ne i1 %675, false
  %677 = load i64, i64* %STACK_DEP_PTR, align 4
  %678 = add i64 %677, 1
  store i64 %678, i64* %STACK_DEP_PTR, align 4
  %679 = load i64, i64* %STACK_DEP_PTR, align 4
  %680 = getelementptr i256, i256* %STACK, i64 %679
  store i256 %96, i256* %680, align 4
  br i1 %jump.check149, label %.2747, label %.439, !EVMBB !4

.439:                                             ; preds = %666
  %681 = load i64, i64* %remaing_gas, align 4
  %682 = icmp ugt i64 112, %681
  br i1 %682, label %Abort, label %683

683:                                              ; preds = %.439
  %684 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %685 = xor i32 %684, 2609
  %686 = urem i32 %685, 4096
  %687 = getelementptr i8, i8 addrspace(1)* %4, i32 %686
  %688 = load i8, i8 addrspace(1)* %687, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %687, align 1, !nosanitize !3
  store i32 1304, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %689 = sub i64 %681, 112
  store i64 %689, i64* %remaing_gas, align 4
  %690 = load i64, i64* %STACK_DEP_PTR, align 4
  %691 = sub i64 %690, 1
  store i64 %691, i64* %STACK_DEP_PTR, align 4
  %692 = icmp eq i256 3620659998, %96
  %693 = trunc i256 2792 to i64
  %jump.check154 = icmp ne i1 %692, false
  %694 = load i64, i64* %STACK_DEP_PTR, align 4
  %695 = add i64 %694, 1
  store i64 %695, i64* %STACK_DEP_PTR, align 4
  %696 = load i64, i64* %STACK_DEP_PTR, align 4
  %697 = getelementptr i256, i256* %STACK, i64 %696
  store i256 %96, i256* %697, align 4
  br i1 %jump.check154, label %.2792, label %.450, !EVMBB !4

.450:                                             ; preds = %683
  %698 = load i64, i64* %remaing_gas, align 4
  %699 = icmp ugt i64 112, %698
  br i1 %699, label %Abort, label %700

700:                                              ; preds = %.450
  %701 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %702 = xor i32 %701, 1112
  %703 = urem i32 %702, 4096
  %704 = getelementptr i8, i8 addrspace(1)* %4, i32 %703
  %705 = load i8, i8 addrspace(1)* %704, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %704, align 1, !nosanitize !3
  store i32 556, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %706 = sub i64 %698, 112
  store i64 %706, i64* %remaing_gas, align 4
  %707 = load i64, i64* %STACK_DEP_PTR, align 4
  %708 = sub i64 %707, 1
  store i64 %708, i64* %STACK_DEP_PTR, align 4
  %709 = icmp eq i256 3658201723, %96
  %710 = trunc i256 2879 to i64
  %jump.check157 = icmp ne i1 %709, false
  %711 = load i64, i64* %STACK_DEP_PTR, align 4
  %712 = add i64 %711, 1
  store i64 %712, i64* %STACK_DEP_PTR, align 4
  %713 = load i64, i64* %STACK_DEP_PTR, align 4
  %714 = getelementptr i256, i256* %STACK, i64 %713
  store i256 %96, i256* %714, align 4
  br i1 %jump.check157, label %.2879, label %.461, !EVMBB !4

.461:                                             ; preds = %700
  %715 = load i64, i64* %remaing_gas, align 4
  %716 = icmp ugt i64 112, %715
  br i1 %716, label %Abort, label %717

717:                                              ; preds = %.461
  %718 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %719 = xor i32 %718, 163
  %720 = urem i32 %719, 4096
  %721 = getelementptr i8, i8 addrspace(1)* %4, i32 %720
  %722 = load i8, i8 addrspace(1)* %721, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %721, align 1, !nosanitize !3
  store i32 81, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %723 = sub i64 %715, 112
  store i64 %723, i64* %remaing_gas, align 4
  %724 = load i64, i64* %STACK_DEP_PTR, align 4
  %725 = sub i64 %724, 1
  store i64 %725, i64* %STACK_DEP_PTR, align 4
  %726 = icmp eq i256 3741776134, %96
  %727 = trunc i256 2928 to i64
  %jump.check159 = icmp ne i1 %726, false
  %728 = load i64, i64* %STACK_DEP_PTR, align 4
  %729 = add i64 %728, 1
  store i64 %729, i64* %STACK_DEP_PTR, align 4
  %730 = load i64, i64* %STACK_DEP_PTR, align 4
  %731 = getelementptr i256, i256* %STACK, i64 %730
  store i256 %96, i256* %731, align 4
  br i1 %jump.check159, label %.2928, label %.472, !EVMBB !4

.472:                                             ; preds = %717
  %732 = load i64, i64* %remaing_gas, align 4
  %733 = icmp ugt i64 112, %732
  br i1 %733, label %Abort, label %734

734:                                              ; preds = %.472
  %735 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %736 = xor i32 %735, 2394
  %737 = urem i32 %736, 4096
  %738 = getelementptr i8, i8 addrspace(1)* %4, i32 %737
  %739 = load i8, i8 addrspace(1)* %738, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %738, align 1, !nosanitize !3
  store i32 1197, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %740 = sub i64 %732, 112
  store i64 %740, i64* %remaing_gas, align 4
  %741 = load i64, i64* %STACK_DEP_PTR, align 4
  %742 = sub i64 %741, 1
  store i64 %742, i64* %STACK_DEP_PTR, align 4
  %743 = icmp eq i256 4103683005, %96
  %744 = trunc i256 2971 to i64
  %jump.check162 = icmp ne i1 %743, false
  %745 = load i64, i64* %STACK_DEP_PTR, align 4
  %746 = add i64 %745, 1
  store i64 %746, i64* %STACK_DEP_PTR, align 4
  %747 = load i64, i64* %STACK_DEP_PTR, align 4
  %748 = getelementptr i256, i256* %STACK, i64 %747
  store i256 %96, i256* %748, align 4
  br i1 %jump.check162, label %.2971, label %.483, !EVMBB !4

.483:                                             ; preds = %734
  %749 = load i64, i64* %remaing_gas, align 4
  %750 = icmp ugt i64 112, %749
  br i1 %750, label %Abort, label %751

751:                                              ; preds = %.483
  %752 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %753 = xor i32 %752, 293
  %754 = urem i32 %753, 4096
  %755 = getelementptr i8, i8 addrspace(1)* %4, i32 %754
  %756 = load i8, i8 addrspace(1)* %755, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %755, align 1, !nosanitize !3
  store i32 146, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %757 = sub i64 %749, 112
  store i64 %757, i64* %remaing_gas, align 4
  %758 = load i64, i64* %STACK_DEP_PTR, align 4
  %759 = sub i64 %758, 1
  store i64 %759, i64* %STACK_DEP_PTR, align 4
  %760 = icmp eq i256 4172467023, %96
  %761 = trunc i256 2994 to i64
  %jump.check165 = icmp ne i1 %760, false
  %762 = load i64, i64* %STACK_DEP_PTR, align 4
  %763 = add i64 %762, 1
  store i64 %763, i64* %STACK_DEP_PTR, align 4
  %764 = load i64, i64* %STACK_DEP_PTR, align 4
  %765 = getelementptr i256, i256* %STACK, i64 %764
  store i256 %96, i256* %765, align 4
  br i1 %jump.check165, label %.2994, label %.494, !EVMBB !4

.494:                                             ; preds = %751
  %766 = load i64, i64* %remaing_gas, align 4
  %767 = icmp ugt i64 112, %766
  br i1 %767, label %Abort, label %768

768:                                              ; preds = %.494
  %769 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %770 = xor i32 %769, 2397
  %771 = urem i32 %770, 4096
  %772 = getelementptr i8, i8 addrspace(1)* %4, i32 %771
  %773 = load i8, i8 addrspace(1)* %772, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %772, align 1, !nosanitize !3
  store i32 1198, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %774 = sub i64 %766, 112
  store i64 %774, i64* %remaing_gas, align 4
  %775 = load i64, i64* %STACK_DEP_PTR, align 4
  %776 = sub i64 %775, 1
  store i64 %776, i64* %STACK_DEP_PTR, align 4
  %777 = icmp eq i256 4211711108, %96
  %778 = trunc i256 3081 to i64
  %jump.check169 = icmp ne i1 %777, false
  %779 = load i64, i64* %STACK_DEP_PTR, align 4
  %780 = add i64 %779, 1
  store i64 %780, i64* %STACK_DEP_PTR, align 4
  %781 = load i64, i64* %STACK_DEP_PTR, align 4
  %782 = getelementptr i256, i256* %STACK, i64 %781
  store i256 %96, i256* %782, align 4
  br i1 %jump.check169, label %.3081, label %.505, !EVMBB !4

.505:                                             ; preds = %768, %66, %JumpTable
  %783 = load i64, i64* %remaing_gas, align 4
  %784 = icmp ugt i64 72, %783
  br i1 %784, label %Abort, label %785

785:                                              ; preds = %.505
  %786 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %787 = xor i32 %786, 261
  %788 = urem i32 %787, 4096
  %789 = getelementptr i8, i8 addrspace(1)* %4, i32 %788
  %790 = load i8, i8 addrspace(1)* %789, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %789, align 1, !nosanitize !3
  store i32 130, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %791 = sub i64 %783, 72
  store i64 %791, i64* %remaing_gas, align 4
  %792 = trunc i256 3091 to i64
  %793 = load i64, i64* %STACK_DEP_PTR, align 4
  %794 = add i64 %793, 1
  store i64 %794, i64* %STACK_DEP_PTR, align 4
  %795 = load i64, i64* %STACK_DEP_PTR, align 4
  %796 = getelementptr i256, i256* %STACK, i64 %795
  store i256 513, i256* %796, align 4
  br label %.3091, !EVMBB !4

.513:                                             ; preds = %JumpTable
  %797 = load i64, i64* %remaing_gas, align 4
  %798 = icmp ugt i64 16, %797
  br i1 %798, label %Abort, label %799

799:                                              ; preds = %.513
  %800 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %801 = xor i32 %800, 791
  %802 = urem i32 %801, 4096
  %803 = getelementptr i8, i8 addrspace(1)* %4, i32 %802
  %804 = load i8, i8 addrspace(1)* %803, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %803, align 1, !nosanitize !3
  store i32 395, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %805 = sub i64 %797, 16
  store i64 %805, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.515:                                             ; preds = %81, %JumpTable
  %806 = load i64, i64* %remaing_gas, align 4
  %807 = icmp ugt i64 96, %806
  br i1 %807, label %Abort, label %808

808:                                              ; preds = %.515
  %809 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %810 = xor i32 %809, 2136
  %811 = urem i32 %810, 4096
  %812 = getelementptr i8, i8 addrspace(1)* %4, i32 %811
  %813 = load i8, i8 addrspace(1)* %812, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %812, align 1, !nosanitize !3
  store i32 1068, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %814 = sub i64 %806, 96
  store i64 %814, i64* %remaing_gas, align 4
  %815 = load i256, i256* %1, align 4
  %816 = icmp eq i256 %815, 0
  %817 = trunc i256 527 to i64
  %jump.check3 = icmp ne i1 %816, false
  %818 = load i64, i64* %STACK_DEP_PTR, align 4
  %819 = add i64 %818, 1
  store i64 %819, i64* %STACK_DEP_PTR, align 4
  %820 = load i64, i64* %STACK_DEP_PTR, align 4
  %821 = getelementptr i256, i256* %STACK, i64 %820
  store i256 %815, i256* %821, align 4
  br i1 %jump.check3, label %.527, label %.523, !EVMBB !4

.523:                                             ; preds = %808
  %822 = load i64, i64* %remaing_gas, align 4
  %823 = icmp ugt i64 40, %822
  br i1 %823, label %Abort, label %824

824:                                              ; preds = %.523
  %825 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %826 = xor i32 %825, 2793
  %827 = urem i32 %826, 4096
  %828 = getelementptr i8, i8 addrspace(1)* %4, i32 %827
  %829 = load i8, i8 addrspace(1)* %828, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %828, align 1, !nosanitize !3
  store i32 1396, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %830 = sub i64 %822, 40
  store i64 %830, i64* %remaing_gas, align 4
  %831 = load i64, i64* %STACK_DEP_PTR, align 4
  %832 = sub i64 %831, 0
  store i64 %832, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.527:                                             ; preds = %808, %JumpTable
  %833 = load i64, i64* %remaing_gas, align 4
  %834 = icmp ugt i64 120, %833
  br i1 %834, label %Abort, label %835

835:                                              ; preds = %.527
  %836 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %837 = xor i32 %836, 1118
  %838 = urem i32 %837, 4096
  %839 = getelementptr i8, i8 addrspace(1)* %4, i32 %838
  %840 = load i8, i8 addrspace(1)* %839, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %839, align 1, !nosanitize !3
  store i32 559, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %841 = sub i64 %833, 120
  store i64 %841, i64* %remaing_gas, align 4
  %842 = load i64, i64* %STACK_DEP_PTR, align 4
  %843 = getelementptr i256, i256* %STACK, i64 %842
  %844 = load i256, i256* %843, align 4
  %845 = load i64, i64* %STACK_DEP_PTR, align 4
  %846 = sub i64 %845, 1
  store i64 %846, i64* %STACK_DEP_PTR, align 4
  %847 = trunc i256 4087 to i64
  %848 = load i64, i64* %STACK_DEP_PTR, align 4
  %849 = add i64 %848, 1
  store i64 %849, i64* %STACK_DEP_PTR, align 4
  %850 = load i64, i64* %STACK_DEP_PTR, align 4
  %851 = getelementptr i256, i256* %STACK, i64 %850
  store i256 536, i256* %851, align 4
  br label %.4087, !EVMBB !4

.536:                                             ; preds = %JumpTable
  %852 = load i64, i64* %remaing_gas, align 4
  %853 = icmp ugt i64 16, %852
  br i1 %853, label %Abort, label %854

854:                                              ; preds = %.536
  %855 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %856 = xor i32 %855, 2260
  %857 = urem i32 %856, 4096
  %858 = getelementptr i8, i8 addrspace(1)* %4, i32 %857
  %859 = load i8, i8 addrspace(1)* %858, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %858, align 1, !nosanitize !3
  store i32 1130, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %860 = sub i64 %852, 16
  store i64 %860, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.538:                                             ; preds = %105, %JumpTable
  %861 = load i64, i64* %remaing_gas, align 4
  %862 = icmp ugt i64 96, %861
  br i1 %862, label %Abort, label %863

863:                                              ; preds = %.538
  %864 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %865 = xor i32 %864, 3499
  %866 = urem i32 %865, 4096
  %867 = getelementptr i8, i8 addrspace(1)* %4, i32 %866
  %868 = load i8, i8 addrspace(1)* %867, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %867, align 1, !nosanitize !3
  store i32 1749, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %869 = sub i64 %861, 96
  store i64 %869, i64* %remaing_gas, align 4
  %870 = load i256, i256* %1, align 4
  %871 = icmp eq i256 %870, 0
  %872 = trunc i256 550 to i64
  %jump.check6 = icmp ne i1 %871, false
  %873 = load i64, i64* %STACK_DEP_PTR, align 4
  %874 = add i64 %873, 1
  store i64 %874, i64* %STACK_DEP_PTR, align 4
  %875 = load i64, i64* %STACK_DEP_PTR, align 4
  %876 = getelementptr i256, i256* %STACK, i64 %875
  store i256 %870, i256* %876, align 4
  br i1 %jump.check6, label %.550, label %.546, !EVMBB !4

.546:                                             ; preds = %863
  %877 = load i64, i64* %remaing_gas, align 4
  %878 = icmp ugt i64 40, %877
  br i1 %878, label %Abort, label %879

879:                                              ; preds = %.546
  %880 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %881 = xor i32 %880, 3250
  %882 = urem i32 %881, 4096
  %883 = getelementptr i8, i8 addrspace(1)* %4, i32 %882
  %884 = load i8, i8 addrspace(1)* %883, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %883, align 1, !nosanitize !3
  store i32 1625, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %885 = sub i64 %877, 40
  store i64 %885, i64* %remaing_gas, align 4
  %886 = load i64, i64* %STACK_DEP_PTR, align 4
  %887 = sub i64 %886, 0
  store i64 %887, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.550:                                             ; preds = %863, %JumpTable
  %888 = load i64, i64* %remaing_gas, align 4
  %889 = icmp ugt i64 240, %888
  br i1 %889, label %Abort, label %890

890:                                              ; preds = %.550
  %891 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %892 = xor i32 %891, 205
  %893 = urem i32 %892, 4096
  %894 = getelementptr i8, i8 addrspace(1)* %4, i32 %893
  %895 = load i8, i8 addrspace(1)* %894, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %894, align 1, !nosanitize !3
  store i32 102, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %896 = sub i64 %888, 240
  store i64 %896, i64* %remaing_gas, align 4
  %897 = load i64, i64* %STACK_DEP_PTR, align 4
  %898 = getelementptr i256, i256* %STACK, i64 %897
  %899 = load i256, i256* %898, align 4
  %900 = load i64, i64* %STACK_DEP_PTR, align 4
  %901 = sub i64 %900, 1
  store i64 %901, i64* %STACK_DEP_PTR, align 4
  %902 = zext i32 %3 to i256
  %903 = sub i256 %902, 4, !pc !7, !intsan !8
  %904 = add i256 4, %903, !pc !9, !intsan !10
  %905 = trunc i256 4 to i64
  %906 = alloca i256, align 8
  %907 = bitcast i256* %906 to i8*
  call void @__device_calldataload(i8* %907, i8* %2, i64 %905)
  %908 = load i256, i256* %906, align 4
  %909 = add i256 32, 4, !pc !11, !intsan !10
  %910 = trunc i256 4175 to i64
  %911 = load i64, i64* %STACK_DEP_PTR, align 4
  %912 = add i64 %911, 1
  store i64 %912, i64* %STACK_DEP_PTR, align 4
  %913 = load i64, i64* %STACK_DEP_PTR, align 4
  %914 = getelementptr i256, i256* %STACK, i64 %913
  store i256 581, i256* %914, align 4
  %915 = load i64, i64* %STACK_DEP_PTR, align 4
  %916 = add i64 %915, 1
  store i64 %916, i64* %STACK_DEP_PTR, align 4
  %917 = load i64, i64* %STACK_DEP_PTR, align 4
  %918 = getelementptr i256, i256* %STACK, i64 %917
  store i256 %908, i256* %918, align 4
  br label %.4175, !EVMBB !4

.581:                                             ; preds = %JumpTable
  %919 = load i64, i64* %remaing_gas, align 4
  %920 = icmp ugt i64 392, %919
  br i1 %920, label %Abort, label %921

921:                                              ; preds = %.581
  %922 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %923 = xor i32 %922, 198
  %924 = urem i32 %923, 4096
  %925 = getelementptr i8, i8 addrspace(1)* %4, i32 %924
  %926 = load i8, i8 addrspace(1)* %925, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %925, align 1, !nosanitize !3
  store i32 99, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %927 = sub i64 %919, 392
  store i64 %927, i64* %remaing_gas, align 4
  %928 = load i64, i64* %STACK_DEP_PTR, align 4
  %929 = getelementptr i256, i256* %STACK, i64 %928
  %930 = load i256, i256* %929, align 4
  %931 = load i64, i64* %STACK_DEP_PTR, align 4
  %932 = sub i64 %931, 1
  store i64 %932, i64* %STACK_DEP_PTR, align 4
  %933 = load i64, i64* %STACK_DEP_PTR, align 4
  %934 = getelementptr i256, i256* %STACK, i64 %933
  %935 = load i256, i256* %934, align 4
  %936 = load i64, i64* %STACK_DEP_PTR, align 4
  %937 = sub i64 %936, 1
  store i64 %937, i64* %STACK_DEP_PTR, align 4
  %938 = load i64, i64* %STACK_DEP_PTR, align 4
  %939 = getelementptr i256, i256* %STACK, i64 %938
  %940 = load i256, i256* %939, align 4
  %941 = load i64, i64* %STACK_DEP_PTR, align 4
  %942 = sub i64 %941, 1
  store i64 %942, i64* %STACK_DEP_PTR, align 4
  %943 = trunc i256 64 to i64
  %944 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %943, i256* %944)
  %945 = load i256, i256* %944, align 4
  %946 = and i256 1461501637330902918203684832716283019655932542975, %940
  %947 = and i256 1461501637330902918203684832716283019655932542975, %946
  %948 = trunc i256 %945 to i64
  %949 = alloca i256, align 8
  store i256 %947, i256* %949, align 4
  %950 = bitcast i256* %949 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %948, i8* %950, i64 32)
  %951 = add i256 32, %945, !pc !12, !intsan !10
  %952 = trunc i256 %951 to i64
  %953 = alloca i256, align 8
  store i256 %935, i256* %953, align 4
  %954 = bitcast i256* %953 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %952, i8* %954, i64 32)
  %955 = add i256 32, %951, !pc !13, !intsan !10
  %956 = trunc i256 %955 to i64
  %957 = alloca i256, align 8
  store i256 %930, i256* %957, align 4
  %958 = bitcast i256* %957 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %956, i8* %958, i64 32)
  %959 = add i256 32, %955, !pc !14, !intsan !10
  %960 = trunc i256 64 to i64
  %961 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %960, i256* %961)
  %962 = load i256, i256* %961, align 4
  %963 = sub i256 %959, %962, !pc !15, !intsan !8
  br label %Exit, !EVMBB !4

.661:                                             ; preds = %122, %JumpTable
  %964 = load i64, i64* %remaing_gas, align 4
  %965 = icmp ugt i64 96, %964
  br i1 %965, label %Abort, label %966

966:                                              ; preds = %.661
  %967 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %968 = xor i32 %967, 1691
  %969 = urem i32 %968, 4096
  %970 = getelementptr i8, i8 addrspace(1)* %4, i32 %969
  %971 = load i8, i8 addrspace(1)* %970, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %970, align 1, !nosanitize !3
  store i32 845, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %972 = sub i64 %964, 96
  store i64 %972, i64* %remaing_gas, align 4
  %973 = load i256, i256* %1, align 4
  %974 = icmp eq i256 %973, 0
  %975 = trunc i256 673 to i64
  %jump.check9 = icmp ne i1 %974, false
  %976 = load i64, i64* %STACK_DEP_PTR, align 4
  %977 = add i64 %976, 1
  store i64 %977, i64* %STACK_DEP_PTR, align 4
  %978 = load i64, i64* %STACK_DEP_PTR, align 4
  %979 = getelementptr i256, i256* %STACK, i64 %978
  store i256 %973, i256* %979, align 4
  br i1 %jump.check9, label %.673, label %.669, !EVMBB !4

.669:                                             ; preds = %966
  %980 = load i64, i64* %remaing_gas, align 4
  %981 = icmp ugt i64 40, %980
  br i1 %981, label %Abort, label %982

982:                                              ; preds = %.669
  %983 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %984 = xor i32 %983, 3764
  %985 = urem i32 %984, 4096
  %986 = getelementptr i8, i8 addrspace(1)* %4, i32 %985
  %987 = load i8, i8 addrspace(1)* %986, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %986, align 1, !nosanitize !3
  store i32 1882, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %988 = sub i64 %980, 40
  store i64 %988, i64* %remaing_gas, align 4
  %989 = load i64, i64* %STACK_DEP_PTR, align 4
  %990 = sub i64 %989, 0
  store i64 %990, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.673:                                             ; preds = %966, %JumpTable
  %991 = load i64, i64* %remaing_gas, align 4
  %992 = icmp ugt i64 120, %991
  br i1 %992, label %Abort, label %993

993:                                              ; preds = %.673
  %994 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %995 = xor i32 %994, 1108
  %996 = urem i32 %995, 4096
  %997 = getelementptr i8, i8 addrspace(1)* %4, i32 %996
  %998 = load i8, i8 addrspace(1)* %997, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %997, align 1, !nosanitize !3
  store i32 554, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %999 = sub i64 %991, 120
  store i64 %999, i64* %remaing_gas, align 4
  %1000 = load i64, i64* %STACK_DEP_PTR, align 4
  %1001 = getelementptr i256, i256* %STACK, i64 %1000
  %1002 = load i256, i256* %1001, align 4
  %1003 = load i64, i64* %STACK_DEP_PTR, align 4
  %1004 = sub i64 %1003, 1
  store i64 %1004, i64* %STACK_DEP_PTR, align 4
  %1005 = trunc i256 4367 to i64
  %1006 = load i64, i64* %STACK_DEP_PTR, align 4
  %1007 = add i64 %1006, 1
  store i64 %1007, i64* %STACK_DEP_PTR, align 4
  %1008 = load i64, i64* %STACK_DEP_PTR, align 4
  %1009 = getelementptr i256, i256* %STACK, i64 %1008
  store i256 682, i256* %1009, align 4
  br label %.4367, !EVMBB !4

.682:                                             ; preds = %JumpTable
  %1010 = load i64, i64* %remaing_gas, align 4
  %1011 = icmp ugt i64 184, %1010
  br i1 %1011, label %Abort, label %1012

1012:                                             ; preds = %.682
  %1013 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1014 = xor i32 %1013, 1553
  %1015 = urem i32 %1014, 4096
  %1016 = getelementptr i8, i8 addrspace(1)* %4, i32 %1015
  %1017 = load i8, i8 addrspace(1)* %1016, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1016, align 1, !nosanitize !3
  store i32 776, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1018 = sub i64 %1010, 184
  store i64 %1018, i64* %remaing_gas, align 4
  %1019 = load i64, i64* %STACK_DEP_PTR, align 4
  %1020 = getelementptr i256, i256* %STACK, i64 %1019
  %1021 = load i256, i256* %1020, align 4
  %1022 = load i64, i64* %STACK_DEP_PTR, align 4
  %1023 = sub i64 %1022, 1
  store i64 %1023, i64* %STACK_DEP_PTR, align 4
  %1024 = trunc i256 64 to i64
  %1025 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1024, i256* %1025)
  %1026 = load i256, i256* %1025, align 4
  %1027 = trunc i256 %1026 to i64
  %1028 = alloca i256, align 8
  store i256 %1021, i256* %1028, align 4
  %1029 = bitcast i256* %1028 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1027, i8* %1029, i64 32)
  %1030 = add i256 32, %1026, !pc !16, !intsan !10
  %1031 = trunc i256 64 to i64
  %1032 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1031, i256* %1032)
  %1033 = load i256, i256* %1032, align 4
  %1034 = sub i256 %1030, %1033, !pc !17, !intsan !8
  br label %Exit, !EVMBB !4

.704:                                             ; preds = %139, %JumpTable
  %1035 = load i64, i64* %remaing_gas, align 4
  %1036 = icmp ugt i64 72, %1035
  br i1 %1036, label %Abort, label %1037

1037:                                             ; preds = %.704
  %1038 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1039 = xor i32 %1038, 1038
  %1040 = urem i32 %1039, 4096
  %1041 = getelementptr i8, i8 addrspace(1)* %4, i32 %1040
  %1042 = load i8, i8 addrspace(1)* %1041, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1041, align 1, !nosanitize !3
  store i32 519, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1043 = sub i64 %1035, 72
  store i64 %1043, i64* %remaing_gas, align 4
  %1044 = trunc i256 3091 to i64
  %1045 = load i64, i64* %STACK_DEP_PTR, align 4
  %1046 = add i64 %1045, 1
  store i64 %1046, i64* %STACK_DEP_PTR, align 4
  %1047 = load i64, i64* %STACK_DEP_PTR, align 4
  %1048 = getelementptr i256, i256* %STACK, i64 %1047
  store i256 712, i256* %1048, align 4
  br label %.3091, !EVMBB !4

.712:                                             ; preds = %JumpTable
  %1049 = load i64, i64* %remaing_gas, align 4
  %1050 = icmp ugt i64 16, %1049
  br i1 %1050, label %Abort, label %1051

1051:                                             ; preds = %.712
  %1052 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1053 = xor i32 %1052, 3458
  %1054 = urem i32 %1053, 4096
  %1055 = getelementptr i8, i8 addrspace(1)* %4, i32 %1054
  %1056 = load i8, i8 addrspace(1)* %1055, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1055, align 1, !nosanitize !3
  store i32 1729, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1057 = sub i64 %1049, 16
  store i64 %1057, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.714:                                             ; preds = %156, %JumpTable
  %1058 = load i64, i64* %remaing_gas, align 4
  %1059 = icmp ugt i64 96, %1058
  br i1 %1059, label %Abort, label %1060

1060:                                             ; preds = %.714
  %1061 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1062 = xor i32 %1061, 2164
  %1063 = urem i32 %1062, 4096
  %1064 = getelementptr i8, i8 addrspace(1)* %4, i32 %1063
  %1065 = load i8, i8 addrspace(1)* %1064, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1064, align 1, !nosanitize !3
  store i32 1082, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1066 = sub i64 %1058, 96
  store i64 %1066, i64* %remaing_gas, align 4
  %1067 = load i256, i256* %1, align 4
  %1068 = icmp eq i256 %1067, 0
  %1069 = trunc i256 726 to i64
  %jump.check16 = icmp ne i1 %1068, false
  %1070 = load i64, i64* %STACK_DEP_PTR, align 4
  %1071 = add i64 %1070, 1
  store i64 %1071, i64* %STACK_DEP_PTR, align 4
  %1072 = load i64, i64* %STACK_DEP_PTR, align 4
  %1073 = getelementptr i256, i256* %STACK, i64 %1072
  store i256 %1067, i256* %1073, align 4
  br i1 %jump.check16, label %.726, label %.722, !EVMBB !4

.722:                                             ; preds = %1060
  %1074 = load i64, i64* %remaing_gas, align 4
  %1075 = icmp ugt i64 40, %1074
  br i1 %1075, label %Abort, label %1076

1076:                                             ; preds = %.722
  %1077 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1078 = xor i32 %1077, 1601
  %1079 = urem i32 %1078, 4096
  %1080 = getelementptr i8, i8 addrspace(1)* %4, i32 %1079
  %1081 = load i8, i8 addrspace(1)* %1080, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1080, align 1, !nosanitize !3
  store i32 800, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1082 = sub i64 %1074, 40
  store i64 %1082, i64* %remaing_gas, align 4
  %1083 = load i64, i64* %STACK_DEP_PTR, align 4
  %1084 = sub i64 %1083, 0
  store i64 %1084, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.726:                                             ; preds = %1060, %JumpTable
  %1085 = load i64, i64* %remaing_gas, align 4
  %1086 = icmp ugt i64 248, %1085
  br i1 %1086, label %Abort, label %1087

1087:                                             ; preds = %.726
  %1088 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1089 = xor i32 %1088, 1313
  %1090 = urem i32 %1089, 4096
  %1091 = getelementptr i8, i8 addrspace(1)* %4, i32 %1090
  %1092 = load i8, i8 addrspace(1)* %1091, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1091, align 1, !nosanitize !3
  store i32 656, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1093 = sub i64 %1085, 248
  store i64 %1093, i64* %remaing_gas, align 4
  %1094 = load i64, i64* %STACK_DEP_PTR, align 4
  %1095 = getelementptr i256, i256* %STACK, i64 %1094
  %1096 = load i256, i256* %1095, align 4
  %1097 = load i64, i64* %STACK_DEP_PTR, align 4
  %1098 = sub i64 %1097, 1
  store i64 %1098, i64* %STACK_DEP_PTR, align 4
  %1099 = zext i32 %3 to i256
  %1100 = sub i256 %1099, 4, !pc !18, !intsan !8
  %1101 = add i256 4, %1100, !pc !19, !intsan !10
  %1102 = trunc i256 4 to i64
  %1103 = alloca i256, align 8
  %1104 = bitcast i256* %1103 to i8*
  call void @__device_calldataload(i8* %1104, i8* %2, i64 %1102)
  %1105 = load i256, i256* %1103, align 4
  %1106 = and i256 1461501637330902918203684832716283019655932542975, %1105
  %1107 = add i256 32, 4, !pc !20, !intsan !10
  %1108 = trunc i256 4443 to i64
  %1109 = load i64, i64* %STACK_DEP_PTR, align 4
  %1110 = add i64 %1109, 1
  store i64 %1110, i64* %STACK_DEP_PTR, align 4
  %1111 = load i64, i64* %STACK_DEP_PTR, align 4
  %1112 = getelementptr i256, i256* %STACK, i64 %1111
  store i256 779, i256* %1112, align 4
  %1113 = load i64, i64* %STACK_DEP_PTR, align 4
  %1114 = add i64 %1113, 1
  store i64 %1114, i64* %STACK_DEP_PTR, align 4
  %1115 = load i64, i64* %STACK_DEP_PTR, align 4
  %1116 = getelementptr i256, i256* %STACK, i64 %1115
  store i256 %1106, i256* %1116, align 4
  br label %.4443, !EVMBB !4

.779:                                             ; preds = %JumpTable
  %1117 = load i64, i64* %remaing_gas, align 4
  %1118 = icmp ugt i64 184, %1117
  br i1 %1118, label %Abort, label %1119

1119:                                             ; preds = %.779
  %1120 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1121 = xor i32 %1120, 3389
  %1122 = urem i32 %1121, 4096
  %1123 = getelementptr i8, i8 addrspace(1)* %4, i32 %1122
  %1124 = load i8, i8 addrspace(1)* %1123, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1123, align 1, !nosanitize !3
  store i32 1694, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1125 = sub i64 %1117, 184
  store i64 %1125, i64* %remaing_gas, align 4
  %1126 = load i64, i64* %STACK_DEP_PTR, align 4
  %1127 = getelementptr i256, i256* %STACK, i64 %1126
  %1128 = load i256, i256* %1127, align 4
  %1129 = load i64, i64* %STACK_DEP_PTR, align 4
  %1130 = sub i64 %1129, 1
  store i64 %1130, i64* %STACK_DEP_PTR, align 4
  %1131 = trunc i256 64 to i64
  %1132 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1131, i256* %1132)
  %1133 = load i256, i256* %1132, align 4
  %1134 = trunc i256 %1133 to i64
  %1135 = alloca i256, align 8
  store i256 %1128, i256* %1135, align 4
  %1136 = bitcast i256* %1135 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1134, i8* %1136, i64 32)
  %1137 = add i256 32, %1133, !pc !21, !intsan !10
  %1138 = trunc i256 64 to i64
  %1139 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1138, i256* %1139)
  %1140 = load i256, i256* %1139, align 4
  %1141 = sub i256 %1137, %1140, !pc !22, !intsan !8
  br label %Exit, !EVMBB !4

.801:                                             ; preds = %173, %JumpTable
  %1142 = load i64, i64* %remaing_gas, align 4
  %1143 = icmp ugt i64 96, %1142
  br i1 %1143, label %Abort, label %1144

1144:                                             ; preds = %.801
  %1145 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1146 = xor i32 %1145, 3548
  %1147 = urem i32 %1146, 4096
  %1148 = getelementptr i8, i8 addrspace(1)* %4, i32 %1147
  %1149 = load i8, i8 addrspace(1)* %1148, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1148, align 1, !nosanitize !3
  store i32 1774, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1150 = sub i64 %1142, 96
  store i64 %1150, i64* %remaing_gas, align 4
  %1151 = load i256, i256* %1, align 4
  %1152 = icmp eq i256 %1151, 0
  %1153 = trunc i256 813 to i64
  %jump.check21 = icmp ne i1 %1152, false
  %1154 = load i64, i64* %STACK_DEP_PTR, align 4
  %1155 = add i64 %1154, 1
  store i64 %1155, i64* %STACK_DEP_PTR, align 4
  %1156 = load i64, i64* %STACK_DEP_PTR, align 4
  %1157 = getelementptr i256, i256* %STACK, i64 %1156
  store i256 %1151, i256* %1157, align 4
  br i1 %jump.check21, label %.813, label %.809, !EVMBB !4

.809:                                             ; preds = %1144
  %1158 = load i64, i64* %remaing_gas, align 4
  %1159 = icmp ugt i64 40, %1158
  br i1 %1159, label %Abort, label %1160

1160:                                             ; preds = %.809
  %1161 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1162 = xor i32 %1161, 135
  %1163 = urem i32 %1162, 4096
  %1164 = getelementptr i8, i8 addrspace(1)* %4, i32 %1163
  %1165 = load i8, i8 addrspace(1)* %1164, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1164, align 1, !nosanitize !3
  store i32 67, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1166 = sub i64 %1158, 40
  store i64 %1166, i64* %remaing_gas, align 4
  %1167 = load i64, i64* %STACK_DEP_PTR, align 4
  %1168 = sub i64 %1167, 0
  store i64 %1168, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.813:                                             ; preds = %1144, %JumpTable
  %1169 = load i64, i64* %remaing_gas, align 4
  %1170 = icmp ugt i64 120, %1169
  br i1 %1170, label %Abort, label %1171

1171:                                             ; preds = %.813
  %1172 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1173 = xor i32 %1172, 2672
  %1174 = urem i32 %1173, 4096
  %1175 = getelementptr i8, i8 addrspace(1)* %4, i32 %1174
  %1176 = load i8, i8 addrspace(1)* %1175, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1175, align 1, !nosanitize !3
  store i32 1336, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1177 = sub i64 %1169, 120
  store i64 %1177, i64* %remaing_gas, align 4
  %1178 = load i64, i64* %STACK_DEP_PTR, align 4
  %1179 = getelementptr i256, i256* %STACK, i64 %1178
  %1180 = load i256, i256* %1179, align 4
  %1181 = load i64, i64* %STACK_DEP_PTR, align 4
  %1182 = sub i64 %1181, 1
  store i64 %1182, i64* %STACK_DEP_PTR, align 4
  %1183 = trunc i256 4555 to i64
  %1184 = load i64, i64* %STACK_DEP_PTR, align 4
  %1185 = add i64 %1184, 1
  store i64 %1185, i64* %STACK_DEP_PTR, align 4
  %1186 = load i64, i64* %STACK_DEP_PTR, align 4
  %1187 = getelementptr i256, i256* %STACK, i64 %1186
  store i256 822, i256* %1187, align 4
  br label %.4555, !EVMBB !4

.822:                                             ; preds = %JumpTable
  %1188 = load i64, i64* %remaing_gas, align 4
  %1189 = icmp ugt i64 16, %1188
  br i1 %1189, label %Abort, label %1190

1190:                                             ; preds = %.822
  %1191 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1192 = xor i32 %1191, 3561
  %1193 = urem i32 %1192, 4096
  %1194 = getelementptr i8, i8 addrspace(1)* %4, i32 %1193
  %1195 = load i8, i8 addrspace(1)* %1194, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1194, align 1, !nosanitize !3
  store i32 1780, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1196 = sub i64 %1188, 16
  store i64 %1196, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.824:                                             ; preds = %190, %JumpTable
  %1197 = load i64, i64* %remaing_gas, align 4
  %1198 = icmp ugt i64 96, %1197
  br i1 %1198, label %Abort, label %1199

1199:                                             ; preds = %.824
  %1200 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1201 = xor i32 %1200, 2110
  %1202 = urem i32 %1201, 4096
  %1203 = getelementptr i8, i8 addrspace(1)* %4, i32 %1202
  %1204 = load i8, i8 addrspace(1)* %1203, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1203, align 1, !nosanitize !3
  store i32 1055, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1205 = sub i64 %1197, 96
  store i64 %1205, i64* %remaing_gas, align 4
  %1206 = load i256, i256* %1, align 4
  %1207 = icmp eq i256 %1206, 0
  %1208 = trunc i256 836 to i64
  %jump.check26 = icmp ne i1 %1207, false
  %1209 = load i64, i64* %STACK_DEP_PTR, align 4
  %1210 = add i64 %1209, 1
  store i64 %1210, i64* %STACK_DEP_PTR, align 4
  %1211 = load i64, i64* %STACK_DEP_PTR, align 4
  %1212 = getelementptr i256, i256* %STACK, i64 %1211
  store i256 %1206, i256* %1212, align 4
  br i1 %jump.check26, label %.836, label %.832, !EVMBB !4

.832:                                             ; preds = %1199
  %1213 = load i64, i64* %remaing_gas, align 4
  %1214 = icmp ugt i64 40, %1213
  br i1 %1214, label %Abort, label %1215

1215:                                             ; preds = %.832
  %1216 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1217 = xor i32 %1216, 1185
  %1218 = urem i32 %1217, 4096
  %1219 = getelementptr i8, i8 addrspace(1)* %4, i32 %1218
  %1220 = load i8, i8 addrspace(1)* %1219, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1219, align 1, !nosanitize !3
  store i32 592, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1221 = sub i64 %1213, 40
  store i64 %1221, i64* %remaing_gas, align 4
  %1222 = load i64, i64* %STACK_DEP_PTR, align 4
  %1223 = sub i64 %1222, 0
  store i64 %1223, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.836:                                             ; preds = %1199, %JumpTable
  %1224 = load i64, i64* %remaing_gas, align 4
  %1225 = icmp ugt i64 120, %1224
  br i1 %1225, label %Abort, label %1226

1226:                                             ; preds = %.836
  %1227 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1228 = xor i32 %1227, 577
  %1229 = urem i32 %1228, 4096
  %1230 = getelementptr i8, i8 addrspace(1)* %4, i32 %1229
  %1231 = load i8, i8 addrspace(1)* %1230, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1230, align 1, !nosanitize !3
  store i32 288, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1232 = sub i64 %1224, 120
  store i64 %1232, i64* %remaing_gas, align 4
  %1233 = load i64, i64* %STACK_DEP_PTR, align 4
  %1234 = getelementptr i256, i256* %STACK, i64 %1233
  %1235 = load i256, i256* %1234, align 4
  %1236 = load i64, i64* %STACK_DEP_PTR, align 4
  %1237 = sub i64 %1236, 1
  store i64 %1237, i64* %STACK_DEP_PTR, align 4
  %1238 = trunc i256 4720 to i64
  %1239 = load i64, i64* %STACK_DEP_PTR, align 4
  %1240 = add i64 %1239, 1
  store i64 %1240, i64* %STACK_DEP_PTR, align 4
  %1241 = load i64, i64* %STACK_DEP_PTR, align 4
  %1242 = getelementptr i256, i256* %STACK, i64 %1241
  store i256 845, i256* %1242, align 4
  br label %.4720, !EVMBB !4

.845:                                             ; preds = %JumpTable
  %1243 = load i64, i64* %remaing_gas, align 4
  %1244 = icmp ugt i64 184, %1243
  br i1 %1244, label %Abort, label %1245

1245:                                             ; preds = %.845
  %1246 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1247 = xor i32 %1246, 2273
  %1248 = urem i32 %1247, 4096
  %1249 = getelementptr i8, i8 addrspace(1)* %4, i32 %1248
  %1250 = load i8, i8 addrspace(1)* %1249, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1249, align 1, !nosanitize !3
  store i32 1136, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1251 = sub i64 %1243, 184
  store i64 %1251, i64* %remaing_gas, align 4
  %1252 = load i64, i64* %STACK_DEP_PTR, align 4
  %1253 = getelementptr i256, i256* %STACK, i64 %1252
  %1254 = load i256, i256* %1253, align 4
  %1255 = load i64, i64* %STACK_DEP_PTR, align 4
  %1256 = sub i64 %1255, 1
  store i64 %1256, i64* %STACK_DEP_PTR, align 4
  %1257 = trunc i256 64 to i64
  %1258 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1257, i256* %1258)
  %1259 = load i256, i256* %1258, align 4
  %1260 = trunc i256 %1259 to i64
  %1261 = alloca i256, align 8
  store i256 %1254, i256* %1261, align 4
  %1262 = bitcast i256* %1261 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1260, i8* %1262, i64 32)
  %1263 = add i256 32, %1259, !pc !23, !intsan !10
  %1264 = trunc i256 64 to i64
  %1265 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1264, i256* %1265)
  %1266 = load i256, i256* %1265, align 4
  %1267 = sub i256 %1263, %1266, !pc !24, !intsan !8
  br label %Exit, !EVMBB !4

.867:                                             ; preds = %207, %JumpTable
  %1268 = load i64, i64* %remaing_gas, align 4
  %1269 = icmp ugt i64 96, %1268
  br i1 %1269, label %Abort, label %1270

1270:                                             ; preds = %.867
  %1271 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1272 = xor i32 %1271, 3580
  %1273 = urem i32 %1272, 4096
  %1274 = getelementptr i8, i8 addrspace(1)* %4, i32 %1273
  %1275 = load i8, i8 addrspace(1)* %1274, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1274, align 1, !nosanitize !3
  store i32 1790, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1276 = sub i64 %1268, 96
  store i64 %1276, i64* %remaing_gas, align 4
  %1277 = load i256, i256* %1, align 4
  %1278 = icmp eq i256 %1277, 0
  %1279 = trunc i256 879 to i64
  %jump.check31 = icmp ne i1 %1278, false
  %1280 = load i64, i64* %STACK_DEP_PTR, align 4
  %1281 = add i64 %1280, 1
  store i64 %1281, i64* %STACK_DEP_PTR, align 4
  %1282 = load i64, i64* %STACK_DEP_PTR, align 4
  %1283 = getelementptr i256, i256* %STACK, i64 %1282
  store i256 %1277, i256* %1283, align 4
  br i1 %jump.check31, label %.879, label %.875, !EVMBB !4

.875:                                             ; preds = %1270
  %1284 = load i64, i64* %remaing_gas, align 4
  %1285 = icmp ugt i64 40, %1284
  br i1 %1285, label %Abort, label %1286

1286:                                             ; preds = %.875
  %1287 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1288 = xor i32 %1287, 871
  %1289 = urem i32 %1288, 4096
  %1290 = getelementptr i8, i8 addrspace(1)* %4, i32 %1289
  %1291 = load i8, i8 addrspace(1)* %1290, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1290, align 1, !nosanitize !3
  store i32 435, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1292 = sub i64 %1284, 40
  store i64 %1292, i64* %remaing_gas, align 4
  %1293 = load i64, i64* %STACK_DEP_PTR, align 4
  %1294 = sub i64 %1293, 0
  store i64 %1294, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.879:                                             ; preds = %1270, %JumpTable
  %1295 = load i64, i64* %remaing_gas, align 4
  %1296 = icmp ugt i64 248, %1295
  br i1 %1296, label %Abort, label %1297

1297:                                             ; preds = %.879
  %1298 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1299 = xor i32 %1298, 574
  %1300 = urem i32 %1299, 4096
  %1301 = getelementptr i8, i8 addrspace(1)* %4, i32 %1300
  %1302 = load i8, i8 addrspace(1)* %1301, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1301, align 1, !nosanitize !3
  store i32 287, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1303 = sub i64 %1295, 248
  store i64 %1303, i64* %remaing_gas, align 4
  %1304 = load i64, i64* %STACK_DEP_PTR, align 4
  %1305 = getelementptr i256, i256* %STACK, i64 %1304
  %1306 = load i256, i256* %1305, align 4
  %1307 = load i64, i64* %STACK_DEP_PTR, align 4
  %1308 = sub i64 %1307, 1
  store i64 %1308, i64* %STACK_DEP_PTR, align 4
  %1309 = zext i32 %3 to i256
  %1310 = sub i256 %1309, 4, !pc !25, !intsan !8
  %1311 = add i256 4, %1310, !pc !26, !intsan !10
  %1312 = trunc i256 4 to i64
  %1313 = alloca i256, align 8
  %1314 = bitcast i256* %1313 to i8*
  call void @__device_calldataload(i8* %1314, i8* %2, i64 %1312)
  %1315 = load i256, i256* %1313, align 4
  %1316 = and i256 1461501637330902918203684832716283019655932542975, %1315
  %1317 = add i256 32, 4, !pc !27, !intsan !10
  %1318 = trunc i256 4726 to i64
  %1319 = load i64, i64* %STACK_DEP_PTR, align 4
  %1320 = add i64 %1319, 1
  store i64 %1320, i64* %STACK_DEP_PTR, align 4
  %1321 = load i64, i64* %STACK_DEP_PTR, align 4
  %1322 = getelementptr i256, i256* %STACK, i64 %1321
  store i256 932, i256* %1322, align 4
  %1323 = load i64, i64* %STACK_DEP_PTR, align 4
  %1324 = add i64 %1323, 1
  store i64 %1324, i64* %STACK_DEP_PTR, align 4
  %1325 = load i64, i64* %STACK_DEP_PTR, align 4
  %1326 = getelementptr i256, i256* %STACK, i64 %1325
  store i256 %1316, i256* %1326, align 4
  br label %.4726, !EVMBB !4

.932:                                             ; preds = %JumpTable
  %1327 = load i64, i64* %remaing_gas, align 4
  %1328 = icmp ugt i64 184, %1327
  br i1 %1328, label %Abort, label %1329

1329:                                             ; preds = %.932
  %1330 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1331 = xor i32 %1330, 3841
  %1332 = urem i32 %1331, 4096
  %1333 = getelementptr i8, i8 addrspace(1)* %4, i32 %1332
  %1334 = load i8, i8 addrspace(1)* %1333, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1333, align 1, !nosanitize !3
  store i32 1920, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1335 = sub i64 %1327, 184
  store i64 %1335, i64* %remaing_gas, align 4
  %1336 = load i64, i64* %STACK_DEP_PTR, align 4
  %1337 = getelementptr i256, i256* %STACK, i64 %1336
  %1338 = load i256, i256* %1337, align 4
  %1339 = load i64, i64* %STACK_DEP_PTR, align 4
  %1340 = sub i64 %1339, 1
  store i64 %1340, i64* %STACK_DEP_PTR, align 4
  %1341 = trunc i256 64 to i64
  %1342 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1341, i256* %1342)
  %1343 = load i256, i256* %1342, align 4
  %1344 = trunc i256 %1343 to i64
  %1345 = alloca i256, align 8
  store i256 %1338, i256* %1345, align 4
  %1346 = bitcast i256* %1345 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1344, i8* %1346, i64 32)
  %1347 = add i256 32, %1343, !pc !28, !intsan !10
  %1348 = trunc i256 64 to i64
  %1349 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1348, i256* %1349)
  %1350 = load i256, i256* %1349, align 4
  %1351 = sub i256 %1347, %1350, !pc !29, !intsan !8
  br label %Exit, !EVMBB !4

.954:                                             ; preds = %224, %JumpTable
  %1352 = load i64, i64* %remaing_gas, align 4
  %1353 = icmp ugt i64 96, %1352
  br i1 %1353, label %Abort, label %1354

1354:                                             ; preds = %.954
  %1355 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1356 = xor i32 %1355, 1662
  %1357 = urem i32 %1356, 4096
  %1358 = getelementptr i8, i8 addrspace(1)* %4, i32 %1357
  %1359 = load i8, i8 addrspace(1)* %1358, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1358, align 1, !nosanitize !3
  store i32 831, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1360 = sub i64 %1352, 96
  store i64 %1360, i64* %remaing_gas, align 4
  %1361 = load i256, i256* %1, align 4
  %1362 = icmp eq i256 %1361, 0
  %1363 = trunc i256 966 to i64
  %jump.check35 = icmp ne i1 %1362, false
  %1364 = load i64, i64* %STACK_DEP_PTR, align 4
  %1365 = add i64 %1364, 1
  store i64 %1365, i64* %STACK_DEP_PTR, align 4
  %1366 = load i64, i64* %STACK_DEP_PTR, align 4
  %1367 = getelementptr i256, i256* %STACK, i64 %1366
  store i256 %1361, i256* %1367, align 4
  br i1 %jump.check35, label %.966, label %.962, !EVMBB !4

.962:                                             ; preds = %1354
  %1368 = load i64, i64* %remaing_gas, align 4
  %1369 = icmp ugt i64 40, %1368
  br i1 %1369, label %Abort, label %1370

1370:                                             ; preds = %.962
  %1371 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1372 = xor i32 %1371, 2711
  %1373 = urem i32 %1372, 4096
  %1374 = getelementptr i8, i8 addrspace(1)* %4, i32 %1373
  %1375 = load i8, i8 addrspace(1)* %1374, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1374, align 1, !nosanitize !3
  store i32 1355, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1376 = sub i64 %1368, 40
  store i64 %1376, i64* %remaing_gas, align 4
  %1377 = load i64, i64* %STACK_DEP_PTR, align 4
  %1378 = sub i64 %1377, 0
  store i64 %1378, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.966:                                             ; preds = %1354, %JumpTable
  %1379 = load i64, i64* %remaing_gas, align 4
  %1380 = icmp ugt i64 264, %1379
  br i1 %1380, label %Abort, label %1381

1381:                                             ; preds = %.966
  %1382 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1383 = xor i32 %1382, 2538
  %1384 = urem i32 %1383, 4096
  %1385 = getelementptr i8, i8 addrspace(1)* %4, i32 %1384
  %1386 = load i8, i8 addrspace(1)* %1385, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1385, align 1, !nosanitize !3
  store i32 1269, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1387 = sub i64 %1379, 264
  store i64 %1387, i64* %remaing_gas, align 4
  %1388 = load i64, i64* %STACK_DEP_PTR, align 4
  %1389 = getelementptr i256, i256* %STACK, i64 %1388
  %1390 = load i256, i256* %1389, align 4
  %1391 = load i64, i64* %STACK_DEP_PTR, align 4
  %1392 = sub i64 %1391, 1
  store i64 %1392, i64* %STACK_DEP_PTR, align 4
  %1393 = zext i32 %3 to i256
  %1394 = sub i256 %1393, 4, !pc !30, !intsan !8
  %1395 = add i256 4, %1394, !pc !31, !intsan !10
  %1396 = trunc i256 4 to i64
  %1397 = alloca i256, align 8
  %1398 = bitcast i256* %1397 to i8*
  call void @__device_calldataload(i8* %1398, i8* %2, i64 %1396)
  %1399 = load i256, i256* %1397, align 4
  %1400 = icmp eq i256 %1399, 0
  %1401 = icmp eq i1 %1400, false
  %1402 = add i256 32, 4, !pc !32, !intsan !10
  %1403 = trunc i256 4838 to i64
  %1404 = load i64, i64* %STACK_DEP_PTR, align 4
  %1405 = add i64 %1404, 1
  store i64 %1405, i64* %STACK_DEP_PTR, align 4
  %1406 = load i64, i64* %STACK_DEP_PTR, align 4
  %1407 = getelementptr i256, i256* %STACK, i64 %1406
  store i256 999, i256* %1407, align 4
  %1408 = load i64, i64* %STACK_DEP_PTR, align 4
  %1409 = add i64 %1408, 1
  store i64 %1409, i64* %STACK_DEP_PTR, align 4
  %1410 = zext i1 %1401 to i256
  %1411 = load i64, i64* %STACK_DEP_PTR, align 4
  %1412 = getelementptr i256, i256* %STACK, i64 %1411
  store i256 %1410, i256* %1412, align 4
  br label %.4838, !EVMBB !4

.999:                                             ; preds = %JumpTable
  %1413 = load i64, i64* %remaing_gas, align 4
  %1414 = icmp ugt i64 16, %1413
  br i1 %1414, label %Abort, label %1415

1415:                                             ; preds = %.999
  %1416 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1417 = xor i32 %1416, 2780
  %1418 = urem i32 %1417, 4096
  %1419 = getelementptr i8, i8 addrspace(1)* %4, i32 %1418
  %1420 = load i8, i8 addrspace(1)* %1419, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1419, align 1, !nosanitize !3
  store i32 1390, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1421 = sub i64 %1413, 16
  store i64 %1421, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1001:                                            ; preds = %241, %JumpTable
  %1422 = load i64, i64* %remaing_gas, align 4
  %1423 = icmp ugt i64 96, %1422
  br i1 %1423, label %Abort, label %1424

1424:                                             ; preds = %.1001
  %1425 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1426 = xor i32 %1425, 875
  %1427 = urem i32 %1426, 4096
  %1428 = getelementptr i8, i8 addrspace(1)* %4, i32 %1427
  %1429 = load i8, i8 addrspace(1)* %1428, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1428, align 1, !nosanitize !3
  store i32 437, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1430 = sub i64 %1422, 96
  store i64 %1430, i64* %remaing_gas, align 4
  %1431 = load i256, i256* %1, align 4
  %1432 = icmp eq i256 %1431, 0
  %1433 = trunc i256 1013 to i64
  %jump.check37 = icmp ne i1 %1432, false
  %1434 = load i64, i64* %STACK_DEP_PTR, align 4
  %1435 = add i64 %1434, 1
  store i64 %1435, i64* %STACK_DEP_PTR, align 4
  %1436 = load i64, i64* %STACK_DEP_PTR, align 4
  %1437 = getelementptr i256, i256* %STACK, i64 %1436
  store i256 %1431, i256* %1437, align 4
  br i1 %jump.check37, label %.1013, label %.1009, !EVMBB !4

.1009:                                            ; preds = %1424
  %1438 = load i64, i64* %remaing_gas, align 4
  %1439 = icmp ugt i64 40, %1438
  br i1 %1439, label %Abort, label %1440

1440:                                             ; preds = %.1009
  %1441 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1442 = xor i32 %1441, 1942
  %1443 = urem i32 %1442, 4096
  %1444 = getelementptr i8, i8 addrspace(1)* %4, i32 %1443
  %1445 = load i8, i8 addrspace(1)* %1444, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1444, align 1, !nosanitize !3
  store i32 971, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1446 = sub i64 %1438, 40
  store i64 %1446, i64* %remaing_gas, align 4
  %1447 = load i64, i64* %STACK_DEP_PTR, align 4
  %1448 = sub i64 %1447, 0
  store i64 %1448, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1013:                                            ; preds = %1424, %JumpTable
  %1449 = load i64, i64* %remaing_gas, align 4
  %1450 = icmp ugt i64 248, %1449
  br i1 %1450, label %Abort, label %1451

1451:                                             ; preds = %.1013
  %1452 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1453 = xor i32 %1452, 1935
  %1454 = urem i32 %1453, 4096
  %1455 = getelementptr i8, i8 addrspace(1)* %4, i32 %1454
  %1456 = load i8, i8 addrspace(1)* %1455, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1455, align 1, !nosanitize !3
  store i32 967, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1457 = sub i64 %1449, 248
  store i64 %1457, i64* %remaing_gas, align 4
  %1458 = load i64, i64* %STACK_DEP_PTR, align 4
  %1459 = getelementptr i256, i256* %STACK, i64 %1458
  %1460 = load i256, i256* %1459, align 4
  %1461 = load i64, i64* %STACK_DEP_PTR, align 4
  %1462 = sub i64 %1461, 1
  store i64 %1462, i64* %STACK_DEP_PTR, align 4
  %1463 = zext i32 %3 to i256
  %1464 = sub i256 %1463, 4, !pc !33, !intsan !8
  %1465 = add i256 4, %1464, !pc !34, !intsan !10
  %1466 = trunc i256 4 to i64
  %1467 = alloca i256, align 8
  %1468 = bitcast i256* %1467 to i8*
  call void @__device_calldataload(i8* %1468, i8* %2, i64 %1466)
  %1469 = load i256, i256* %1467, align 4
  %1470 = and i256 1461501637330902918203684832716283019655932542975, %1469
  %1471 = add i256 32, 4, !pc !35, !intsan !10
  %1472 = trunc i256 5238 to i64
  %1473 = load i64, i64* %STACK_DEP_PTR, align 4
  %1474 = add i64 %1473, 1
  store i64 %1474, i64* %STACK_DEP_PTR, align 4
  %1475 = load i64, i64* %STACK_DEP_PTR, align 4
  %1476 = getelementptr i256, i256* %STACK, i64 %1475
  store i256 1066, i256* %1476, align 4
  %1477 = load i64, i64* %STACK_DEP_PTR, align 4
  %1478 = add i64 %1477, 1
  store i64 %1478, i64* %STACK_DEP_PTR, align 4
  %1479 = load i64, i64* %STACK_DEP_PTR, align 4
  %1480 = getelementptr i256, i256* %STACK, i64 %1479
  store i256 %1470, i256* %1480, align 4
  br label %.5238, !EVMBB !4

.1066:                                            ; preds = %JumpTable
  %1481 = load i64, i64* %remaing_gas, align 4
  %1482 = icmp ugt i64 16, %1481
  br i1 %1482, label %Abort, label %1483

1483:                                             ; preds = %.1066
  %1484 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1485 = xor i32 %1484, 1080
  %1486 = urem i32 %1485, 4096
  %1487 = getelementptr i8, i8 addrspace(1)* %4, i32 %1486
  %1488 = load i8, i8 addrspace(1)* %1487, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1487, align 1, !nosanitize !3
  store i32 540, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1489 = sub i64 %1481, 16
  store i64 %1489, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1068:                                            ; preds = %258, %JumpTable
  %1490 = load i64, i64* %remaing_gas, align 4
  %1491 = icmp ugt i64 96, %1490
  br i1 %1491, label %Abort, label %1492

1492:                                             ; preds = %.1068
  %1493 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1494 = xor i32 %1493, 2140
  %1495 = urem i32 %1494, 4096
  %1496 = getelementptr i8, i8 addrspace(1)* %4, i32 %1495
  %1497 = load i8, i8 addrspace(1)* %1496, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1496, align 1, !nosanitize !3
  store i32 1070, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1498 = sub i64 %1490, 96
  store i64 %1498, i64* %remaing_gas, align 4
  %1499 = load i256, i256* %1, align 4
  %1500 = icmp eq i256 %1499, 0
  %1501 = trunc i256 1080 to i64
  %jump.check41 = icmp ne i1 %1500, false
  %1502 = load i64, i64* %STACK_DEP_PTR, align 4
  %1503 = add i64 %1502, 1
  store i64 %1503, i64* %STACK_DEP_PTR, align 4
  %1504 = load i64, i64* %STACK_DEP_PTR, align 4
  %1505 = getelementptr i256, i256* %STACK, i64 %1504
  store i256 %1499, i256* %1505, align 4
  br i1 %jump.check41, label %.1080, label %.1076, !EVMBB !4

.1076:                                            ; preds = %1492
  %1506 = load i64, i64* %remaing_gas, align 4
  %1507 = icmp ugt i64 40, %1506
  br i1 %1507, label %Abort, label %1508

1508:                                             ; preds = %.1076
  %1509 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1510 = xor i32 %1509, 3626
  %1511 = urem i32 %1510, 4096
  %1512 = getelementptr i8, i8 addrspace(1)* %4, i32 %1511
  %1513 = load i8, i8 addrspace(1)* %1512, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1512, align 1, !nosanitize !3
  store i32 1813, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1514 = sub i64 %1506, 40
  store i64 %1514, i64* %remaing_gas, align 4
  %1515 = load i64, i64* %STACK_DEP_PTR, align 4
  %1516 = sub i64 %1515, 0
  store i64 %1516, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1080:                                            ; preds = %1492, %JumpTable
  %1517 = load i64, i64* %remaing_gas, align 4
  %1518 = icmp ugt i64 120, %1517
  br i1 %1518, label %Abort, label %1519

1519:                                             ; preds = %.1080
  %1520 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1521 = xor i32 %1520, 748
  %1522 = urem i32 %1521, 4096
  %1523 = getelementptr i8, i8 addrspace(1)* %4, i32 %1522
  %1524 = load i8, i8 addrspace(1)* %1523, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1523, align 1, !nosanitize !3
  store i32 374, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1525 = sub i64 %1517, 120
  store i64 %1525, i64* %remaing_gas, align 4
  %1526 = load i64, i64* %STACK_DEP_PTR, align 4
  %1527 = getelementptr i256, i256* %STACK, i64 %1526
  %1528 = load i256, i256* %1527, align 4
  %1529 = load i64, i64* %STACK_DEP_PTR, align 4
  %1530 = sub i64 %1529, 1
  store i64 %1530, i64* %STACK_DEP_PTR, align 4
  %1531 = trunc i256 5641 to i64
  %1532 = load i64, i64* %STACK_DEP_PTR, align 4
  %1533 = add i64 %1532, 1
  store i64 %1533, i64* %STACK_DEP_PTR, align 4
  %1534 = load i64, i64* %STACK_DEP_PTR, align 4
  %1535 = getelementptr i256, i256* %STACK, i64 %1534
  store i256 1089, i256* %1535, align 4
  br label %.5641, !EVMBB !4

.1089:                                            ; preds = %JumpTable
  %1536 = load i64, i64* %remaing_gas, align 4
  %1537 = icmp ugt i64 16, %1536
  br i1 %1537, label %Abort, label %1538

1538:                                             ; preds = %.1089
  %1539 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1540 = xor i32 %1539, 3248
  %1541 = urem i32 %1540, 4096
  %1542 = getelementptr i8, i8 addrspace(1)* %4, i32 %1541
  %1543 = load i8, i8 addrspace(1)* %1542, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1542, align 1, !nosanitize !3
  store i32 1624, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1544 = sub i64 %1536, 16
  store i64 %1544, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1091:                                            ; preds = %275, %JumpTable
  %1545 = load i64, i64* %remaing_gas, align 4
  %1546 = icmp ugt i64 96, %1545
  br i1 %1546, label %Abort, label %1547

1547:                                             ; preds = %.1091
  %1548 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1549 = xor i32 %1548, 1083
  %1550 = urem i32 %1549, 4096
  %1551 = getelementptr i8, i8 addrspace(1)* %4, i32 %1550
  %1552 = load i8, i8 addrspace(1)* %1551, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1551, align 1, !nosanitize !3
  store i32 541, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1553 = sub i64 %1545, 96
  store i64 %1553, i64* %remaing_gas, align 4
  %1554 = load i256, i256* %1, align 4
  %1555 = icmp eq i256 %1554, 0
  %1556 = trunc i256 1103 to i64
  %jump.check45 = icmp ne i1 %1555, false
  %1557 = load i64, i64* %STACK_DEP_PTR, align 4
  %1558 = add i64 %1557, 1
  store i64 %1558, i64* %STACK_DEP_PTR, align 4
  %1559 = load i64, i64* %STACK_DEP_PTR, align 4
  %1560 = getelementptr i256, i256* %STACK, i64 %1559
  store i256 %1554, i256* %1560, align 4
  br i1 %jump.check45, label %.1103, label %.1099, !EVMBB !4

.1099:                                            ; preds = %1547
  %1561 = load i64, i64* %remaing_gas, align 4
  %1562 = icmp ugt i64 40, %1561
  br i1 %1562, label %Abort, label %1563

1563:                                             ; preds = %.1099
  %1564 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1565 = xor i32 %1564, 1787
  %1566 = urem i32 %1565, 4096
  %1567 = getelementptr i8, i8 addrspace(1)* %4, i32 %1566
  %1568 = load i8, i8 addrspace(1)* %1567, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1567, align 1, !nosanitize !3
  store i32 893, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1569 = sub i64 %1561, 40
  store i64 %1569, i64* %remaing_gas, align 4
  %1570 = load i64, i64* %STACK_DEP_PTR, align 4
  %1571 = sub i64 %1570, 0
  store i64 %1571, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1103:                                            ; preds = %1547, %JumpTable
  %1572 = load i64, i64* %remaing_gas, align 4
  %1573 = icmp ugt i64 656, %1572
  br i1 %1573, label %Abort, label %1574

1574:                                             ; preds = %.1103
  %1575 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1576 = xor i32 %1575, 2610
  %1577 = urem i32 %1576, 4096
  %1578 = getelementptr i8, i8 addrspace(1)* %4, i32 %1577
  %1579 = load i8, i8 addrspace(1)* %1578, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1578, align 1, !nosanitize !3
  store i32 1305, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1580 = sub i64 %1572, 656
  store i64 %1580, i64* %remaing_gas, align 4
  %1581 = load i64, i64* %STACK_DEP_PTR, align 4
  %1582 = getelementptr i256, i256* %STACK, i64 %1581
  %1583 = load i256, i256* %1582, align 4
  %1584 = load i64, i64* %STACK_DEP_PTR, align 4
  %1585 = sub i64 %1584, 1
  store i64 %1585, i64* %STACK_DEP_PTR, align 4
  %1586 = zext i32 %3 to i256
  %1587 = sub i256 %1586, 4, !pc !36, !intsan !8
  %1588 = add i256 4, %1587, !pc !37, !intsan !10
  %1589 = trunc i256 4 to i64
  %1590 = alloca i256, align 8
  %1591 = bitcast i256* %1590 to i8*
  call void @__device_calldataload(i8* %1591, i8* %2, i64 %1589)
  %1592 = load i256, i256* %1590, align 4
  %1593 = xor i256 0, -1
  %1594 = and i256 %1593, %1592
  %1595 = add i256 32, 4, !pc !38, !intsan !10
  %1596 = trunc i256 %1595 to i64
  %1597 = alloca i256, align 8
  %1598 = bitcast i256* %1597 to i8*
  call void @__device_calldataload(i8* %1598, i8* %2, i64 %1596)
  %1599 = load i256, i256* %1597, align 4
  %1600 = add i256 32, %1595, !pc !39, !intsan !10
  %1601 = add i256 4, %1599, !pc !40, !intsan !10
  %1602 = trunc i256 %1601 to i64
  %1603 = alloca i256, align 8
  %1604 = bitcast i256* %1603 to i8*
  call void @__device_calldataload(i8* %1604, i8* %2, i64 %1602)
  %1605 = load i256, i256* %1603, align 4
  %1606 = add i256 32, %1601, !pc !41, !intsan !10
  %1607 = add i256 31, %1605, !pc !42, !intsan !10
  %1608 = alloca i256, align 8
  store i256 %1607, i256* %1608, align 4
  %1609 = alloca i256, align 8
  store i256 32, i256* %1609, align 4
  %1610 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %1608, i256* %1609, i256* %1610), !pc !43, !intsan !6
  %1611 = load i256, i256* %1610, align 4
  %1612 = mul i256 %1611, 32, !pc !44, !intsan !45
  %1613 = add i256 32, %1612, !pc !46, !intsan !10
  %1614 = trunc i256 64 to i64
  %1615 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1614, i256* %1615)
  %1616 = load i256, i256* %1615, align 4
  %1617 = add i256 %1616, %1613, !pc !47, !intsan !10
  %1618 = trunc i256 64 to i64
  %1619 = alloca i256, align 8
  store i256 %1617, i256* %1619, align 4
  %1620 = bitcast i256* %1619 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1618, i8* %1620, i64 32)
  %1621 = trunc i256 %1616 to i64
  %1622 = alloca i256, align 8
  store i256 %1605, i256* %1622, align 4
  %1623 = bitcast i256* %1622 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1621, i8* %1623, i64 32)
  %1624 = add i256 32, %1616, !pc !48, !intsan !10
  %1625 = trunc i256 %1624 to i64
  %1626 = trunc i256 %1606 to i64
  %1627 = trunc i256 %1605 to i64
  call void @__device_calldatacpy(i8* %MEMORY, i64 %1625, i8* %2, i64 %1626, i64 %1627)
  %1628 = add i256 %1624, %1605, !pc !49, !intsan !10
  %1629 = trunc i256 5836 to i64
  %1630 = load i64, i64* %STACK_DEP_PTR, align 4
  %1631 = add i64 %1630, 1
  store i64 %1631, i64* %STACK_DEP_PTR, align 4
  %1632 = load i64, i64* %STACK_DEP_PTR, align 4
  %1633 = getelementptr i256, i256* %STACK, i64 %1632
  store i256 1208, i256* %1633, align 4
  %1634 = load i64, i64* %STACK_DEP_PTR, align 4
  %1635 = add i64 %1634, 1
  store i64 %1635, i64* %STACK_DEP_PTR, align 4
  %1636 = load i64, i64* %STACK_DEP_PTR, align 4
  %1637 = getelementptr i256, i256* %STACK, i64 %1636
  store i256 %1594, i256* %1637, align 4
  %1638 = load i64, i64* %STACK_DEP_PTR, align 4
  %1639 = add i64 %1638, 1
  store i64 %1639, i64* %STACK_DEP_PTR, align 4
  %1640 = load i64, i64* %STACK_DEP_PTR, align 4
  %1641 = getelementptr i256, i256* %STACK, i64 %1640
  store i256 %1616, i256* %1641, align 4
  br label %.5836, !EVMBB !4

.1208:                                            ; preds = %JumpTable
  %1642 = load i64, i64* %remaing_gas, align 4
  %1643 = icmp ugt i64 16, %1642
  br i1 %1643, label %Abort, label %1644

1644:                                             ; preds = %.1208
  %1645 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1646 = xor i32 %1645, 3247
  %1647 = urem i32 %1646, 4096
  %1648 = getelementptr i8, i8 addrspace(1)* %4, i32 %1647
  %1649 = load i8, i8 addrspace(1)* %1648, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1648, align 1, !nosanitize !3
  store i32 1623, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1650 = sub i64 %1642, 16
  store i64 %1650, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1210:                                            ; preds = %292, %JumpTable
  %1651 = load i64, i64* %remaing_gas, align 4
  %1652 = icmp ugt i64 96, %1651
  br i1 %1652, label %Abort, label %1653

1653:                                             ; preds = %.1210
  %1654 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1655 = xor i32 %1654, 3388
  %1656 = urem i32 %1655, 4096
  %1657 = getelementptr i8, i8 addrspace(1)* %4, i32 %1656
  %1658 = load i8, i8 addrspace(1)* %1657, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1657, align 1, !nosanitize !3
  store i32 1694, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1659 = sub i64 %1651, 96
  store i64 %1659, i64* %remaing_gas, align 4
  %1660 = load i256, i256* %1, align 4
  %1661 = icmp eq i256 %1660, 0
  %1662 = trunc i256 1222 to i64
  %jump.check51 = icmp ne i1 %1661, false
  %1663 = load i64, i64* %STACK_DEP_PTR, align 4
  %1664 = add i64 %1663, 1
  store i64 %1664, i64* %STACK_DEP_PTR, align 4
  %1665 = load i64, i64* %STACK_DEP_PTR, align 4
  %1666 = getelementptr i256, i256* %STACK, i64 %1665
  store i256 %1660, i256* %1666, align 4
  br i1 %jump.check51, label %.1222, label %.1218, !EVMBB !4

.1218:                                            ; preds = %1653
  %1667 = load i64, i64* %remaing_gas, align 4
  %1668 = icmp ugt i64 40, %1667
  br i1 %1668, label %Abort, label %1669

1669:                                             ; preds = %.1218
  %1670 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1671 = xor i32 %1670, 3924
  %1672 = urem i32 %1671, 4096
  %1673 = getelementptr i8, i8 addrspace(1)* %4, i32 %1672
  %1674 = load i8, i8 addrspace(1)* %1673, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1673, align 1, !nosanitize !3
  store i32 1962, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1675 = sub i64 %1667, 40
  store i64 %1675, i64* %remaing_gas, align 4
  %1676 = load i64, i64* %STACK_DEP_PTR, align 4
  %1677 = sub i64 %1676, 0
  store i64 %1677, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1222:                                            ; preds = %1653, %JumpTable
  %1678 = load i64, i64* %remaing_gas, align 4
  %1679 = icmp ugt i64 1056, %1678
  br i1 %1679, label %Abort, label %1680

1680:                                             ; preds = %.1222
  %1681 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1682 = xor i32 %1681, 2540
  %1683 = urem i32 %1682, 4096
  %1684 = getelementptr i8, i8 addrspace(1)* %4, i32 %1683
  %1685 = load i8, i8 addrspace(1)* %1684, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1684, align 1, !nosanitize !3
  store i32 1270, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1686 = sub i64 %1678, 1056
  store i64 %1686, i64* %remaing_gas, align 4
  %1687 = load i64, i64* %STACK_DEP_PTR, align 4
  %1688 = getelementptr i256, i256* %STACK, i64 %1687
  %1689 = load i256, i256* %1688, align 4
  %1690 = load i64, i64* %STACK_DEP_PTR, align 4
  %1691 = sub i64 %1690, 1
  store i64 %1691, i64* %STACK_DEP_PTR, align 4
  %1692 = zext i32 %3 to i256
  %1693 = sub i256 %1692, 4, !pc !50, !intsan !8
  %1694 = add i256 4, %1693, !pc !51, !intsan !10
  %1695 = trunc i256 4 to i64
  %1696 = alloca i256, align 8
  %1697 = bitcast i256* %1696 to i8*
  call void @__device_calldataload(i8* %1697, i8* %2, i64 %1695)
  %1698 = load i256, i256* %1696, align 4
  %1699 = xor i256 0, -1
  %1700 = and i256 %1699, %1698
  %1701 = add i256 32, 4, !pc !52, !intsan !10
  %1702 = trunc i256 %1701 to i64
  %1703 = alloca i256, align 8
  %1704 = bitcast i256* %1703 to i8*
  call void @__device_calldataload(i8* %1704, i8* %2, i64 %1702)
  %1705 = load i256, i256* %1703, align 4
  %1706 = add i256 32, %1701, !pc !53, !intsan !10
  %1707 = add i256 4, %1705, !pc !54, !intsan !10
  %1708 = trunc i256 %1707 to i64
  %1709 = alloca i256, align 8
  %1710 = bitcast i256* %1709 to i8*
  call void @__device_calldataload(i8* %1710, i8* %2, i64 %1708)
  %1711 = load i256, i256* %1709, align 4
  %1712 = add i256 32, %1707, !pc !55, !intsan !10
  %1713 = add i256 31, %1711, !pc !56, !intsan !10
  %1714 = alloca i256, align 8
  store i256 %1713, i256* %1714, align 4
  %1715 = alloca i256, align 8
  store i256 32, i256* %1715, align 4
  %1716 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %1714, i256* %1715, i256* %1716), !pc !57, !intsan !6
  %1717 = load i256, i256* %1716, align 4
  %1718 = mul i256 %1717, 32, !pc !58, !intsan !45
  %1719 = add i256 32, %1718, !pc !59, !intsan !10
  %1720 = trunc i256 64 to i64
  %1721 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1720, i256* %1721)
  %1722 = load i256, i256* %1721, align 4
  %1723 = add i256 %1722, %1719, !pc !60, !intsan !10
  %1724 = trunc i256 64 to i64
  %1725 = alloca i256, align 8
  store i256 %1723, i256* %1725, align 4
  %1726 = bitcast i256* %1725 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1724, i8* %1726, i64 32)
  %1727 = trunc i256 %1722 to i64
  %1728 = alloca i256, align 8
  store i256 %1711, i256* %1728, align 4
  %1729 = bitcast i256* %1728 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1727, i8* %1729, i64 32)
  %1730 = add i256 32, %1722, !pc !61, !intsan !10
  %1731 = trunc i256 %1730 to i64
  %1732 = trunc i256 %1712 to i64
  %1733 = trunc i256 %1711 to i64
  call void @__device_calldatacpy(i8* %MEMORY, i64 %1731, i8* %2, i64 %1732, i64 %1733)
  %1734 = add i256 %1730, %1711, !pc !62, !intsan !10
  %1735 = trunc i256 %1706 to i64
  %1736 = alloca i256, align 8
  %1737 = bitcast i256* %1736 to i8*
  call void @__device_calldataload(i8* %1737, i8* %2, i64 %1735)
  %1738 = load i256, i256* %1736, align 4
  %1739 = add i256 32, %1706, !pc !63, !intsan !10
  %1740 = add i256 4, %1738, !pc !64, !intsan !10
  %1741 = trunc i256 %1740 to i64
  %1742 = alloca i256, align 8
  %1743 = bitcast i256* %1742 to i8*
  call void @__device_calldataload(i8* %1743, i8* %2, i64 %1741)
  %1744 = load i256, i256* %1742, align 4
  %1745 = add i256 32, %1740, !pc !65, !intsan !10
  %1746 = add i256 31, %1744, !pc !66, !intsan !10
  %1747 = alloca i256, align 8
  store i256 %1746, i256* %1747, align 4
  %1748 = alloca i256, align 8
  store i256 32, i256* %1748, align 4
  %1749 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %1747, i256* %1748, i256* %1749), !pc !67, !intsan !6
  %1750 = load i256, i256* %1749, align 4
  %1751 = mul i256 %1750, 32, !pc !68, !intsan !45
  %1752 = add i256 32, %1751, !pc !69, !intsan !10
  %1753 = trunc i256 64 to i64
  %1754 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1753, i256* %1754)
  %1755 = load i256, i256* %1754, align 4
  %1756 = add i256 %1755, %1752, !pc !70, !intsan !10
  %1757 = trunc i256 64 to i64
  %1758 = alloca i256, align 8
  store i256 %1756, i256* %1758, align 4
  %1759 = bitcast i256* %1758 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1757, i8* %1759, i64 32)
  %1760 = trunc i256 %1755 to i64
  %1761 = alloca i256, align 8
  store i256 %1744, i256* %1761, align 4
  %1762 = bitcast i256* %1761 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1760, i8* %1762, i64 32)
  %1763 = add i256 32, %1755, !pc !71, !intsan !10
  %1764 = trunc i256 %1763 to i64
  %1765 = trunc i256 %1745 to i64
  %1766 = trunc i256 %1744 to i64
  call void @__device_calldatacpy(i8* %MEMORY, i64 %1764, i8* %2, i64 %1765, i64 %1766)
  %1767 = add i256 %1763, %1744, !pc !72, !intsan !10
  %1768 = trunc i256 5903 to i64
  %1769 = load i64, i64* %STACK_DEP_PTR, align 4
  %1770 = add i64 %1769, 1
  store i64 %1770, i64* %STACK_DEP_PTR, align 4
  %1771 = load i64, i64* %STACK_DEP_PTR, align 4
  %1772 = getelementptr i256, i256* %STACK, i64 %1771
  store i256 1397, i256* %1772, align 4
  %1773 = load i64, i64* %STACK_DEP_PTR, align 4
  %1774 = add i64 %1773, 1
  store i64 %1774, i64* %STACK_DEP_PTR, align 4
  %1775 = load i64, i64* %STACK_DEP_PTR, align 4
  %1776 = getelementptr i256, i256* %STACK, i64 %1775
  store i256 %1700, i256* %1776, align 4
  %1777 = load i64, i64* %STACK_DEP_PTR, align 4
  %1778 = add i64 %1777, 1
  store i64 %1778, i64* %STACK_DEP_PTR, align 4
  %1779 = load i64, i64* %STACK_DEP_PTR, align 4
  %1780 = getelementptr i256, i256* %STACK, i64 %1779
  store i256 %1722, i256* %1780, align 4
  %1781 = load i64, i64* %STACK_DEP_PTR, align 4
  %1782 = add i64 %1781, 1
  store i64 %1782, i64* %STACK_DEP_PTR, align 4
  %1783 = load i64, i64* %STACK_DEP_PTR, align 4
  %1784 = getelementptr i256, i256* %STACK, i64 %1783
  store i256 %1755, i256* %1784, align 4
  br label %.5903, !EVMBB !4

.1397:                                            ; preds = %JumpTable
  %1785 = load i64, i64* %remaing_gas, align 4
  %1786 = icmp ugt i64 16, %1785
  br i1 %1786, label %Abort, label %1787

1787:                                             ; preds = %.1397
  %1788 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1789 = xor i32 %1788, 2840
  %1790 = urem i32 %1789, 4096
  %1791 = getelementptr i8, i8 addrspace(1)* %4, i32 %1790
  %1792 = load i8, i8 addrspace(1)* %1791, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1791, align 1, !nosanitize !3
  store i32 1420, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1793 = sub i64 %1785, 16
  store i64 %1793, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1399:                                            ; preds = %309, %JumpTable
  %1794 = load i64, i64* %remaing_gas, align 4
  %1795 = icmp ugt i64 96, %1794
  br i1 %1795, label %Abort, label %1796

1796:                                             ; preds = %.1399
  %1797 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1798 = xor i32 %1797, 4059
  %1799 = urem i32 %1798, 4096
  %1800 = getelementptr i8, i8 addrspace(1)* %4, i32 %1799
  %1801 = load i8, i8 addrspace(1)* %1800, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1800, align 1, !nosanitize !3
  store i32 2029, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1802 = sub i64 %1794, 96
  store i64 %1802, i64* %remaing_gas, align 4
  %1803 = load i256, i256* %1, align 4
  %1804 = icmp eq i256 %1803, 0
  %1805 = trunc i256 1411 to i64
  %jump.check58 = icmp ne i1 %1804, false
  %1806 = load i64, i64* %STACK_DEP_PTR, align 4
  %1807 = add i64 %1806, 1
  store i64 %1807, i64* %STACK_DEP_PTR, align 4
  %1808 = load i64, i64* %STACK_DEP_PTR, align 4
  %1809 = getelementptr i256, i256* %STACK, i64 %1808
  store i256 %1803, i256* %1809, align 4
  br i1 %jump.check58, label %.1411, label %.1407, !EVMBB !4

.1407:                                            ; preds = %1796
  %1810 = load i64, i64* %remaing_gas, align 4
  %1811 = icmp ugt i64 40, %1810
  br i1 %1811, label %Abort, label %1812

1812:                                             ; preds = %.1407
  %1813 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1814 = xor i32 %1813, 1116
  %1815 = urem i32 %1814, 4096
  %1816 = getelementptr i8, i8 addrspace(1)* %4, i32 %1815
  %1817 = load i8, i8 addrspace(1)* %1816, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1816, align 1, !nosanitize !3
  store i32 558, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1818 = sub i64 %1810, 40
  store i64 %1818, i64* %remaing_gas, align 4
  %1819 = load i64, i64* %STACK_DEP_PTR, align 4
  %1820 = sub i64 %1819, 0
  store i64 %1820, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1411:                                            ; preds = %1796, %JumpTable
  %1821 = load i64, i64* %remaing_gas, align 4
  %1822 = icmp ugt i64 120, %1821
  br i1 %1822, label %Abort, label %1823

1823:                                             ; preds = %.1411
  %1824 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1825 = xor i32 %1824, 2306
  %1826 = urem i32 %1825, 4096
  %1827 = getelementptr i8, i8 addrspace(1)* %4, i32 %1826
  %1828 = load i8, i8 addrspace(1)* %1827, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1827, align 1, !nosanitize !3
  store i32 1153, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1829 = sub i64 %1821, 120
  store i64 %1829, i64* %remaing_gas, align 4
  %1830 = load i64, i64* %STACK_DEP_PTR, align 4
  %1831 = getelementptr i256, i256* %STACK, i64 %1830
  %1832 = load i256, i256* %1831, align 4
  %1833 = load i64, i64* %STACK_DEP_PTR, align 4
  %1834 = sub i64 %1833, 1
  store i64 %1834, i64* %STACK_DEP_PTR, align 4
  %1835 = trunc i256 7030 to i64
  %1836 = load i64, i64* %STACK_DEP_PTR, align 4
  %1837 = add i64 %1836, 1
  store i64 %1837, i64* %STACK_DEP_PTR, align 4
  %1838 = load i64, i64* %STACK_DEP_PTR, align 4
  %1839 = getelementptr i256, i256* %STACK, i64 %1838
  store i256 1420, i256* %1839, align 4
  br label %.7030, !EVMBB !4

.1420:                                            ; preds = %JumpTable
  %1840 = load i64, i64* %remaing_gas, align 4
  %1841 = icmp ugt i64 224, %1840
  br i1 %1841, label %Abort, label %1842

1842:                                             ; preds = %.1420
  %1843 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1844 = xor i32 %1843, 2074
  %1845 = urem i32 %1844, 4096
  %1846 = getelementptr i8, i8 addrspace(1)* %4, i32 %1845
  %1847 = load i8, i8 addrspace(1)* %1846, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1846, align 1, !nosanitize !3
  store i32 1037, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1848 = sub i64 %1840, 224
  store i64 %1848, i64* %remaing_gas, align 4
  %1849 = load i64, i64* %STACK_DEP_PTR, align 4
  %1850 = getelementptr i256, i256* %STACK, i64 %1849
  %1851 = load i256, i256* %1850, align 4
  %1852 = load i64, i64* %STACK_DEP_PTR, align 4
  %1853 = sub i64 %1852, 1
  store i64 %1853, i64* %STACK_DEP_PTR, align 4
  %1854 = trunc i256 64 to i64
  %1855 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1854, i256* %1855)
  %1856 = load i256, i256* %1855, align 4
  %1857 = icmp eq i256 %1851, 0
  %1858 = icmp eq i1 %1857, false
  %1859 = icmp eq i1 %1858, false
  %1860 = icmp eq i1 %1859, false
  %1861 = trunc i256 %1856 to i64
  %1862 = zext i1 %1860 to i256
  %1863 = alloca i256, align 8
  store i256 %1862, i256* %1863, align 4
  %1864 = bitcast i256* %1863 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1861, i8* %1864, i64 32)
  %1865 = add i256 32, %1856, !pc !73, !intsan !10
  %1866 = trunc i256 64 to i64
  %1867 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1866, i256* %1867)
  %1868 = load i256, i256* %1867, align 4
  %1869 = sub i256 %1865, %1868, !pc !74, !intsan !8
  br label %Exit, !EVMBB !4

.1446:                                            ; preds = %326, %JumpTable
  %1870 = load i64, i64* %remaing_gas, align 4
  %1871 = icmp ugt i64 96, %1870
  br i1 %1871, label %Abort, label %1872

1872:                                             ; preds = %.1446
  %1873 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1874 = xor i32 %1873, 2302
  %1875 = urem i32 %1874, 4096
  %1876 = getelementptr i8, i8 addrspace(1)* %4, i32 %1875
  %1877 = load i8, i8 addrspace(1)* %1876, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1876, align 1, !nosanitize !3
  store i32 1151, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1878 = sub i64 %1870, 96
  store i64 %1878, i64* %remaing_gas, align 4
  %1879 = load i256, i256* %1, align 4
  %1880 = icmp eq i256 %1879, 0
  %1881 = trunc i256 1458 to i64
  %jump.check62 = icmp ne i1 %1880, false
  %1882 = load i64, i64* %STACK_DEP_PTR, align 4
  %1883 = add i64 %1882, 1
  store i64 %1883, i64* %STACK_DEP_PTR, align 4
  %1884 = load i64, i64* %STACK_DEP_PTR, align 4
  %1885 = getelementptr i256, i256* %STACK, i64 %1884
  store i256 %1879, i256* %1885, align 4
  br i1 %jump.check62, label %.1458, label %.1454, !EVMBB !4

.1454:                                            ; preds = %1872
  %1886 = load i64, i64* %remaing_gas, align 4
  %1887 = icmp ugt i64 40, %1886
  br i1 %1887, label %Abort, label %1888

1888:                                             ; preds = %.1454
  %1889 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1890 = xor i32 %1889, 2883
  %1891 = urem i32 %1890, 4096
  %1892 = getelementptr i8, i8 addrspace(1)* %4, i32 %1891
  %1893 = load i8, i8 addrspace(1)* %1892, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1892, align 1, !nosanitize !3
  store i32 1441, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1894 = sub i64 %1886, 40
  store i64 %1894, i64* %remaing_gas, align 4
  %1895 = load i64, i64* %STACK_DEP_PTR, align 4
  %1896 = sub i64 %1895, 0
  store i64 %1896, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1458:                                            ; preds = %1872, %JumpTable
  %1897 = load i64, i64* %remaing_gas, align 4
  %1898 = icmp ugt i64 240, %1897
  br i1 %1898, label %Abort, label %1899

1899:                                             ; preds = %.1458
  %1900 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1901 = xor i32 %1900, 251
  %1902 = urem i32 %1901, 4096
  %1903 = getelementptr i8, i8 addrspace(1)* %4, i32 %1902
  %1904 = load i8, i8 addrspace(1)* %1903, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1903, align 1, !nosanitize !3
  store i32 125, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1905 = sub i64 %1897, 240
  store i64 %1905, i64* %remaing_gas, align 4
  %1906 = load i64, i64* %STACK_DEP_PTR, align 4
  %1907 = getelementptr i256, i256* %STACK, i64 %1906
  %1908 = load i256, i256* %1907, align 4
  %1909 = load i64, i64* %STACK_DEP_PTR, align 4
  %1910 = sub i64 %1909, 1
  store i64 %1910, i64* %STACK_DEP_PTR, align 4
  %1911 = zext i32 %3 to i256
  %1912 = sub i256 %1911, 4, !pc !75, !intsan !8
  %1913 = add i256 4, %1912, !pc !76, !intsan !10
  %1914 = trunc i256 4 to i64
  %1915 = alloca i256, align 8
  %1916 = bitcast i256* %1915 to i8*
  call void @__device_calldataload(i8* %1916, i8* %2, i64 %1914)
  %1917 = load i256, i256* %1915, align 4
  %1918 = add i256 32, 4, !pc !77, !intsan !10
  %1919 = trunc i256 7049 to i64
  %1920 = load i64, i64* %STACK_DEP_PTR, align 4
  %1921 = add i64 %1920, 1
  store i64 %1921, i64* %STACK_DEP_PTR, align 4
  %1922 = load i64, i64* %STACK_DEP_PTR, align 4
  %1923 = getelementptr i256, i256* %STACK, i64 %1922
  store i256 1489, i256* %1923, align 4
  %1924 = load i64, i64* %STACK_DEP_PTR, align 4
  %1925 = add i64 %1924, 1
  store i64 %1925, i64* %STACK_DEP_PTR, align 4
  %1926 = load i64, i64* %STACK_DEP_PTR, align 4
  %1927 = getelementptr i256, i256* %STACK, i64 %1926
  store i256 %1917, i256* %1927, align 4
  br label %.7049, !EVMBB !4

.1489:                                            ; preds = %JumpTable
  %1928 = load i64, i64* %remaing_gas, align 4
  %1929 = icmp ugt i64 432, %1928
  br i1 %1929, label %Abort, label %1930

1930:                                             ; preds = %.1489
  %1931 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1932 = xor i32 %1931, 1786
  %1933 = urem i32 %1932, 4096
  %1934 = getelementptr i8, i8 addrspace(1)* %4, i32 %1933
  %1935 = load i8, i8 addrspace(1)* %1934, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1934, align 1, !nosanitize !3
  store i32 893, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1936 = sub i64 %1928, 432
  store i64 %1936, i64* %remaing_gas, align 4
  %1937 = load i64, i64* %STACK_DEP_PTR, align 4
  %1938 = getelementptr i256, i256* %STACK, i64 %1937
  %1939 = load i256, i256* %1938, align 4
  %1940 = load i64, i64* %STACK_DEP_PTR, align 4
  %1941 = sub i64 %1940, 1
  store i64 %1941, i64* %STACK_DEP_PTR, align 4
  %1942 = load i64, i64* %STACK_DEP_PTR, align 4
  %1943 = getelementptr i256, i256* %STACK, i64 %1942
  %1944 = load i256, i256* %1943, align 4
  %1945 = load i64, i64* %STACK_DEP_PTR, align 4
  %1946 = sub i64 %1945, 1
  store i64 %1946, i64* %STACK_DEP_PTR, align 4
  %1947 = load i64, i64* %STACK_DEP_PTR, align 4
  %1948 = getelementptr i256, i256* %STACK, i64 %1947
  %1949 = load i256, i256* %1948, align 4
  %1950 = load i64, i64* %STACK_DEP_PTR, align 4
  %1951 = sub i64 %1950, 1
  store i64 %1951, i64* %STACK_DEP_PTR, align 4
  %1952 = trunc i256 64 to i64
  %1953 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1952, i256* %1953)
  %1954 = load i256, i256* %1953, align 4
  %1955 = and i256 1461501637330902918203684832716283019655932542975, %1949
  %1956 = and i256 1461501637330902918203684832716283019655932542975, %1955
  %1957 = trunc i256 %1954 to i64
  %1958 = alloca i256, align 8
  store i256 %1956, i256* %1958, align 4
  %1959 = bitcast i256* %1958 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1957, i8* %1959, i64 32)
  %1960 = add i256 32, %1954, !pc !78, !intsan !10
  %1961 = trunc i256 %1960 to i64
  %1962 = alloca i256, align 8
  store i256 %1944, i256* %1962, align 4
  %1963 = bitcast i256* %1962 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1961, i8* %1963, i64 32)
  %1964 = add i256 32, %1960, !pc !79, !intsan !10
  %1965 = icmp eq i256 %1939, 0
  %1966 = icmp eq i1 %1965, false
  %1967 = icmp eq i1 %1966, false
  %1968 = icmp eq i1 %1967, false
  %1969 = trunc i256 %1964 to i64
  %1970 = zext i1 %1968 to i256
  %1971 = alloca i256, align 8
  store i256 %1970, i256* %1971, align 4
  %1972 = bitcast i256* %1971 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %1969, i8* %1972, i64 32)
  %1973 = add i256 32, %1964, !pc !80, !intsan !10
  %1974 = trunc i256 64 to i64
  %1975 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %1974, i256* %1975)
  %1976 = load i256, i256* %1975, align 4
  %1977 = sub i256 %1973, %1976, !pc !81, !intsan !8
  br label %Exit, !EVMBB !4

.1573:                                            ; preds = %343, %JumpTable
  %1978 = load i64, i64* %remaing_gas, align 4
  %1979 = icmp ugt i64 96, %1978
  br i1 %1979, label %Abort, label %1980

1980:                                             ; preds = %.1573
  %1981 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1982 = xor i32 %1981, 3754
  %1983 = urem i32 %1982, 4096
  %1984 = getelementptr i8, i8 addrspace(1)* %4, i32 %1983
  %1985 = load i8, i8 addrspace(1)* %1984, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %1984, align 1, !nosanitize !3
  store i32 1877, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1986 = sub i64 %1978, 96
  store i64 %1986, i64* %remaing_gas, align 4
  %1987 = load i256, i256* %1, align 4
  %1988 = icmp eq i256 %1987, 0
  %1989 = trunc i256 1585 to i64
  %jump.check65 = icmp ne i1 %1988, false
  %1990 = load i64, i64* %STACK_DEP_PTR, align 4
  %1991 = add i64 %1990, 1
  store i64 %1991, i64* %STACK_DEP_PTR, align 4
  %1992 = load i64, i64* %STACK_DEP_PTR, align 4
  %1993 = getelementptr i256, i256* %STACK, i64 %1992
  store i256 %1987, i256* %1993, align 4
  br i1 %jump.check65, label %.1585, label %.1581, !EVMBB !4

.1581:                                            ; preds = %1980
  %1994 = load i64, i64* %remaing_gas, align 4
  %1995 = icmp ugt i64 40, %1994
  br i1 %1995, label %Abort, label %1996

1996:                                             ; preds = %.1581
  %1997 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %1998 = xor i32 %1997, 826
  %1999 = urem i32 %1998, 4096
  %2000 = getelementptr i8, i8 addrspace(1)* %4, i32 %1999
  %2001 = load i8, i8 addrspace(1)* %2000, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2000, align 1, !nosanitize !3
  store i32 413, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2002 = sub i64 %1994, 40
  store i64 %2002, i64* %remaing_gas, align 4
  %2003 = load i64, i64* %STACK_DEP_PTR, align 4
  %2004 = sub i64 %2003, 0
  store i64 %2004, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1585:                                            ; preds = %1980, %JumpTable
  %2005 = load i64, i64* %remaing_gas, align 4
  %2006 = icmp ugt i64 120, %2005
  br i1 %2006, label %Abort, label %2007

2007:                                             ; preds = %.1585
  %2008 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2009 = xor i32 %2008, 1531
  %2010 = urem i32 %2009, 4096
  %2011 = getelementptr i8, i8 addrspace(1)* %4, i32 %2010
  %2012 = load i8, i8 addrspace(1)* %2011, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2011, align 1, !nosanitize !3
  store i32 765, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2013 = sub i64 %2005, 120
  store i64 %2013, i64* %remaing_gas, align 4
  %2014 = load i64, i64* %STACK_DEP_PTR, align 4
  %2015 = getelementptr i256, i256* %STACK, i64 %2014
  %2016 = load i256, i256* %2015, align 4
  %2017 = load i64, i64* %STACK_DEP_PTR, align 4
  %2018 = sub i64 %2017, 1
  store i64 %2018, i64* %STACK_DEP_PTR, align 4
  %2019 = trunc i256 7136 to i64
  %2020 = load i64, i64* %STACK_DEP_PTR, align 4
  %2021 = add i64 %2020, 1
  store i64 %2021, i64* %STACK_DEP_PTR, align 4
  %2022 = load i64, i64* %STACK_DEP_PTR, align 4
  %2023 = getelementptr i256, i256* %STACK, i64 %2022
  store i256 1594, i256* %2023, align 4
  br label %.7136, !EVMBB !4

.1594:                                            ; preds = %JumpTable
  %2024 = load i64, i64* %remaing_gas, align 4
  %2025 = icmp ugt i64 184, %2024
  br i1 %2025, label %Abort, label %2026

2026:                                             ; preds = %.1594
  %2027 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2028 = xor i32 %2027, 1321
  %2029 = urem i32 %2028, 4096
  %2030 = getelementptr i8, i8 addrspace(1)* %4, i32 %2029
  %2031 = load i8, i8 addrspace(1)* %2030, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2030, align 1, !nosanitize !3
  store i32 660, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2032 = sub i64 %2024, 184
  store i64 %2032, i64* %remaing_gas, align 4
  %2033 = load i64, i64* %STACK_DEP_PTR, align 4
  %2034 = getelementptr i256, i256* %STACK, i64 %2033
  %2035 = load i256, i256* %2034, align 4
  %2036 = load i64, i64* %STACK_DEP_PTR, align 4
  %2037 = sub i64 %2036, 1
  store i64 %2037, i64* %STACK_DEP_PTR, align 4
  %2038 = trunc i256 64 to i64
  %2039 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2038, i256* %2039)
  %2040 = load i256, i256* %2039, align 4
  %2041 = trunc i256 %2040 to i64
  %2042 = alloca i256, align 8
  store i256 %2035, i256* %2042, align 4
  %2043 = bitcast i256* %2042 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2041, i8* %2043, i64 32)
  %2044 = add i256 32, %2040, !pc !82, !intsan !10
  %2045 = trunc i256 64 to i64
  %2046 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2045, i256* %2046)
  %2047 = load i256, i256* %2046, align 4
  %2048 = sub i256 %2044, %2047, !pc !83, !intsan !8
  br label %Exit, !EVMBB !4

.1616:                                            ; preds = %360, %JumpTable
  %2049 = load i64, i64* %remaing_gas, align 4
  %2050 = icmp ugt i64 96, %2049
  br i1 %2050, label %Abort, label %2051

2051:                                             ; preds = %.1616
  %2052 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2053 = xor i32 %2052, 3537
  %2054 = urem i32 %2053, 4096
  %2055 = getelementptr i8, i8 addrspace(1)* %4, i32 %2054
  %2056 = load i8, i8 addrspace(1)* %2055, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2055, align 1, !nosanitize !3
  store i32 1768, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2057 = sub i64 %2049, 96
  store i64 %2057, i64* %remaing_gas, align 4
  %2058 = load i256, i256* %1, align 4
  %2059 = icmp eq i256 %2058, 0
  %2060 = trunc i256 1628 to i64
  %jump.check69 = icmp ne i1 %2059, false
  %2061 = load i64, i64* %STACK_DEP_PTR, align 4
  %2062 = add i64 %2061, 1
  store i64 %2062, i64* %STACK_DEP_PTR, align 4
  %2063 = load i64, i64* %STACK_DEP_PTR, align 4
  %2064 = getelementptr i256, i256* %STACK, i64 %2063
  store i256 %2058, i256* %2064, align 4
  br i1 %jump.check69, label %.1628, label %.1624, !EVMBB !4

.1624:                                            ; preds = %2051
  %2065 = load i64, i64* %remaing_gas, align 4
  %2066 = icmp ugt i64 40, %2065
  br i1 %2066, label %Abort, label %2067

2067:                                             ; preds = %.1624
  %2068 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2069 = xor i32 %2068, 4070
  %2070 = urem i32 %2069, 4096
  %2071 = getelementptr i8, i8 addrspace(1)* %4, i32 %2070
  %2072 = load i8, i8 addrspace(1)* %2071, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2071, align 1, !nosanitize !3
  store i32 2035, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2073 = sub i64 %2065, 40
  store i64 %2073, i64* %remaing_gas, align 4
  %2074 = load i64, i64* %STACK_DEP_PTR, align 4
  %2075 = sub i64 %2074, 0
  store i64 %2075, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1628:                                            ; preds = %2051, %JumpTable
  %2076 = load i64, i64* %remaing_gas, align 4
  %2077 = icmp ugt i64 248, %2076
  br i1 %2077, label %Abort, label %2078

2078:                                             ; preds = %.1628
  %2079 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2080 = xor i32 %2079, 5
  %2081 = urem i32 %2080, 4096
  %2082 = getelementptr i8, i8 addrspace(1)* %4, i32 %2081
  %2083 = load i8, i8 addrspace(1)* %2082, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2082, align 1, !nosanitize !3
  store i32 2, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2084 = sub i64 %2076, 248
  store i64 %2084, i64* %remaing_gas, align 4
  %2085 = load i64, i64* %STACK_DEP_PTR, align 4
  %2086 = getelementptr i256, i256* %STACK, i64 %2085
  %2087 = load i256, i256* %2086, align 4
  %2088 = load i64, i64* %STACK_DEP_PTR, align 4
  %2089 = sub i64 %2088, 1
  store i64 %2089, i64* %STACK_DEP_PTR, align 4
  %2090 = zext i32 %3 to i256
  %2091 = sub i256 %2090, 4, !pc !84, !intsan !8
  %2092 = add i256 4, %2091, !pc !85, !intsan !10
  %2093 = trunc i256 4 to i64
  %2094 = alloca i256, align 8
  %2095 = bitcast i256* %2094 to i8*
  call void @__device_calldataload(i8* %2095, i8* %2, i64 %2093)
  %2096 = load i256, i256* %2094, align 4
  %2097 = and i256 1461501637330902918203684832716283019655932542975, %2096
  %2098 = add i256 32, 4, !pc !86, !intsan !10
  %2099 = trunc i256 7318 to i64
  %2100 = load i64, i64* %STACK_DEP_PTR, align 4
  %2101 = add i64 %2100, 1
  store i64 %2101, i64* %STACK_DEP_PTR, align 4
  %2102 = load i64, i64* %STACK_DEP_PTR, align 4
  %2103 = getelementptr i256, i256* %STACK, i64 %2102
  store i256 1681, i256* %2103, align 4
  %2104 = load i64, i64* %STACK_DEP_PTR, align 4
  %2105 = add i64 %2104, 1
  store i64 %2105, i64* %STACK_DEP_PTR, align 4
  %2106 = load i64, i64* %STACK_DEP_PTR, align 4
  %2107 = getelementptr i256, i256* %STACK, i64 %2106
  store i256 %2097, i256* %2107, align 4
  br label %.7318, !EVMBB !4

.1681:                                            ; preds = %JumpTable
  %2108 = load i64, i64* %remaing_gas, align 4
  %2109 = icmp ugt i64 16, %2108
  br i1 %2109, label %Abort, label %2110

2110:                                             ; preds = %.1681
  %2111 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2112 = xor i32 %2111, 316
  %2113 = urem i32 %2112, 4096
  %2114 = getelementptr i8, i8 addrspace(1)* %4, i32 %2113
  %2115 = load i8, i8 addrspace(1)* %2114, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2114, align 1, !nosanitize !3
  store i32 158, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2116 = sub i64 %2108, 16
  store i64 %2116, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1683:                                            ; preds = %377, %JumpTable
  %2117 = load i64, i64* %remaing_gas, align 4
  %2118 = icmp ugt i64 96, %2117
  br i1 %2118, label %Abort, label %2119

2119:                                             ; preds = %.1683
  %2120 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2121 = xor i32 %2120, 1916
  %2122 = urem i32 %2121, 4096
  %2123 = getelementptr i8, i8 addrspace(1)* %4, i32 %2122
  %2124 = load i8, i8 addrspace(1)* %2123, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2123, align 1, !nosanitize !3
  store i32 958, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2125 = sub i64 %2117, 96
  store i64 %2125, i64* %remaing_gas, align 4
  %2126 = load i256, i256* %1, align 4
  %2127 = icmp eq i256 %2126, 0
  %2128 = trunc i256 1695 to i64
  %jump.check74 = icmp ne i1 %2127, false
  %2129 = load i64, i64* %STACK_DEP_PTR, align 4
  %2130 = add i64 %2129, 1
  store i64 %2130, i64* %STACK_DEP_PTR, align 4
  %2131 = load i64, i64* %STACK_DEP_PTR, align 4
  %2132 = getelementptr i256, i256* %STACK, i64 %2131
  store i256 %2126, i256* %2132, align 4
  br i1 %jump.check74, label %.1695, label %.1691, !EVMBB !4

.1691:                                            ; preds = %2119
  %2133 = load i64, i64* %remaing_gas, align 4
  %2134 = icmp ugt i64 40, %2133
  br i1 %2134, label %Abort, label %2135

2135:                                             ; preds = %.1691
  %2136 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2137 = xor i32 %2136, 1940
  %2138 = urem i32 %2137, 4096
  %2139 = getelementptr i8, i8 addrspace(1)* %4, i32 %2138
  %2140 = load i8, i8 addrspace(1)* %2139, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2139, align 1, !nosanitize !3
  store i32 970, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2141 = sub i64 %2133, 40
  store i64 %2141, i64* %remaing_gas, align 4
  %2142 = load i64, i64* %STACK_DEP_PTR, align 4
  %2143 = sub i64 %2142, 0
  store i64 %2143, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1695:                                            ; preds = %2119, %JumpTable
  %2144 = load i64, i64* %remaing_gas, align 4
  %2145 = icmp ugt i64 120, %2144
  br i1 %2145, label %Abort, label %2146

2146:                                             ; preds = %.1695
  %2147 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2148 = xor i32 %2147, 1397
  %2149 = urem i32 %2148, 4096
  %2150 = getelementptr i8, i8 addrspace(1)* %4, i32 %2149
  %2151 = load i8, i8 addrspace(1)* %2150, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2150, align 1, !nosanitize !3
  store i32 698, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2152 = sub i64 %2144, 120
  store i64 %2152, i64* %remaing_gas, align 4
  %2153 = load i64, i64* %STACK_DEP_PTR, align 4
  %2154 = getelementptr i256, i256* %STACK, i64 %2153
  %2155 = load i256, i256* %2154, align 4
  %2156 = load i64, i64* %STACK_DEP_PTR, align 4
  %2157 = sub i64 %2156, 1
  store i64 %2157, i64* %STACK_DEP_PTR, align 4
  %2158 = trunc i256 7683 to i64
  %2159 = load i64, i64* %STACK_DEP_PTR, align 4
  %2160 = add i64 %2159, 1
  store i64 %2160, i64* %STACK_DEP_PTR, align 4
  %2161 = load i64, i64* %STACK_DEP_PTR, align 4
  %2162 = getelementptr i256, i256* %STACK, i64 %2161
  store i256 1704, i256* %2162, align 4
  br label %.7683, !EVMBB !4

.1704:                                            ; preds = %JumpTable
  %2163 = load i64, i64* %remaing_gas, align 4
  %2164 = icmp ugt i64 856, %2163
  br i1 %2164, label %Abort, label %2165

2165:                                             ; preds = %.1704
  %2166 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2167 = xor i32 %2166, 4056
  %2168 = urem i32 %2167, 4096
  %2169 = getelementptr i8, i8 addrspace(1)* %4, i32 %2168
  %2170 = load i8, i8 addrspace(1)* %2169, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2169, align 1, !nosanitize !3
  store i32 2028, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2171 = sub i64 %2163, 856
  store i64 %2171, i64* %remaing_gas, align 4
  %2172 = load i64, i64* %STACK_DEP_PTR, align 4
  %2173 = getelementptr i256, i256* %STACK, i64 %2172
  %2174 = load i256, i256* %2173, align 4
  %2175 = load i64, i64* %STACK_DEP_PTR, align 4
  %2176 = sub i64 %2175, 1
  store i64 %2176, i64* %STACK_DEP_PTR, align 4
  %2177 = load i64, i64* %STACK_DEP_PTR, align 4
  %2178 = getelementptr i256, i256* %STACK, i64 %2177
  %2179 = load i256, i256* %2178, align 4
  %2180 = load i64, i64* %STACK_DEP_PTR, align 4
  %2181 = sub i64 %2180, 1
  store i64 %2181, i64* %STACK_DEP_PTR, align 4
  %2182 = load i64, i64* %STACK_DEP_PTR, align 4
  %2183 = getelementptr i256, i256* %STACK, i64 %2182
  %2184 = load i256, i256* %2183, align 4
  %2185 = load i64, i64* %STACK_DEP_PTR, align 4
  %2186 = sub i64 %2185, 1
  store i64 %2186, i64* %STACK_DEP_PTR, align 4
  %2187 = load i64, i64* %STACK_DEP_PTR, align 4
  %2188 = getelementptr i256, i256* %STACK, i64 %2187
  %2189 = load i256, i256* %2188, align 4
  %2190 = load i64, i64* %STACK_DEP_PTR, align 4
  %2191 = sub i64 %2190, 1
  store i64 %2191, i64* %STACK_DEP_PTR, align 4
  %2192 = load i64, i64* %STACK_DEP_PTR, align 4
  %2193 = getelementptr i256, i256* %STACK, i64 %2192
  %2194 = load i256, i256* %2193, align 4
  %2195 = load i64, i64* %STACK_DEP_PTR, align 4
  %2196 = sub i64 %2195, 1
  store i64 %2196, i64* %STACK_DEP_PTR, align 4
  %2197 = load i64, i64* %STACK_DEP_PTR, align 4
  %2198 = getelementptr i256, i256* %STACK, i64 %2197
  %2199 = load i256, i256* %2198, align 4
  %2200 = load i64, i64* %STACK_DEP_PTR, align 4
  %2201 = sub i64 %2200, 1
  store i64 %2201, i64* %STACK_DEP_PTR, align 4
  %2202 = load i64, i64* %STACK_DEP_PTR, align 4
  %2203 = getelementptr i256, i256* %STACK, i64 %2202
  %2204 = load i256, i256* %2203, align 4
  %2205 = load i64, i64* %STACK_DEP_PTR, align 4
  %2206 = sub i64 %2205, 1
  store i64 %2206, i64* %STACK_DEP_PTR, align 4
  %2207 = load i64, i64* %STACK_DEP_PTR, align 4
  %2208 = getelementptr i256, i256* %STACK, i64 %2207
  %2209 = load i256, i256* %2208, align 4
  %2210 = load i64, i64* %STACK_DEP_PTR, align 4
  %2211 = sub i64 %2210, 1
  store i64 %2211, i64* %STACK_DEP_PTR, align 4
  %2212 = trunc i256 64 to i64
  %2213 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2212, i256* %2213)
  %2214 = load i256, i256* %2213, align 4
  %2215 = trunc i256 %2214 to i64
  %2216 = alloca i256, align 8
  store i256 %2209, i256* %2216, align 4
  %2217 = bitcast i256* %2216 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2215, i8* %2217, i64 32)
  %2218 = add i256 32, %2214, !pc !87, !intsan !10
  %2219 = trunc i256 %2218 to i64
  %2220 = alloca i256, align 8
  store i256 %2204, i256* %2220, align 4
  %2221 = bitcast i256* %2220 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2219, i8* %2221, i64 32)
  %2222 = add i256 32, %2218, !pc !88, !intsan !10
  %2223 = trunc i256 %2222 to i64
  %2224 = alloca i256, align 8
  store i256 %2199, i256* %2224, align 4
  %2225 = bitcast i256* %2224 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2223, i8* %2225, i64 32)
  %2226 = add i256 32, %2222, !pc !89, !intsan !10
  %2227 = trunc i256 %2226 to i64
  %2228 = alloca i256, align 8
  store i256 %2194, i256* %2228, align 4
  %2229 = bitcast i256* %2228 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2227, i8* %2229, i64 32)
  %2230 = add i256 32, %2226, !pc !90, !intsan !10
  %2231 = trunc i256 %2230 to i64
  %2232 = alloca i256, align 8
  store i256 %2189, i256* %2232, align 4
  %2233 = bitcast i256* %2232 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2231, i8* %2233, i64 32)
  %2234 = add i256 32, %2230, !pc !91, !intsan !10
  %2235 = trunc i256 %2234 to i64
  %2236 = alloca i256, align 8
  store i256 %2184, i256* %2236, align 4
  %2237 = bitcast i256* %2236 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2235, i8* %2237, i64 32)
  %2238 = add i256 32, %2234, !pc !92, !intsan !10
  %2239 = trunc i256 %2238 to i64
  %2240 = alloca i256, align 8
  store i256 %2179, i256* %2240, align 4
  %2241 = bitcast i256* %2240 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2239, i8* %2241, i64 32)
  %2242 = add i256 32, %2238, !pc !93, !intsan !10
  %2243 = trunc i256 %2242 to i64
  %2244 = alloca i256, align 8
  store i256 %2174, i256* %2244, align 4
  %2245 = bitcast i256* %2244 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2243, i8* %2245, i64 32)
  %2246 = add i256 32, %2242, !pc !94, !intsan !10
  %2247 = trunc i256 64 to i64
  %2248 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2247, i256* %2248)
  %2249 = load i256, i256* %2248, align 4
  %2250 = sub i256 %2246, %2249, !pc !95, !intsan !8
  br label %Exit, !EVMBB !4

.1775:                                            ; preds = %394, %JumpTable
  %2251 = load i64, i64* %remaing_gas, align 4
  %2252 = icmp ugt i64 96, %2251
  br i1 %2252, label %Abort, label %2253

2253:                                             ; preds = %.1775
  %2254 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2255 = xor i32 %2254, 1470
  %2256 = urem i32 %2255, 4096
  %2257 = getelementptr i8, i8 addrspace(1)* %4, i32 %2256
  %2258 = load i8, i8 addrspace(1)* %2257, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2257, align 1, !nosanitize !3
  store i32 735, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2259 = sub i64 %2251, 96
  store i64 %2259, i64* %remaing_gas, align 4
  %2260 = load i256, i256* %1, align 4
  %2261 = icmp eq i256 %2260, 0
  %2262 = trunc i256 1787 to i64
  %jump.check79 = icmp ne i1 %2261, false
  %2263 = load i64, i64* %STACK_DEP_PTR, align 4
  %2264 = add i64 %2263, 1
  store i64 %2264, i64* %STACK_DEP_PTR, align 4
  %2265 = load i64, i64* %STACK_DEP_PTR, align 4
  %2266 = getelementptr i256, i256* %STACK, i64 %2265
  store i256 %2260, i256* %2266, align 4
  br i1 %jump.check79, label %.1787, label %.1783, !EVMBB !4

.1783:                                            ; preds = %2253
  %2267 = load i64, i64* %remaing_gas, align 4
  %2268 = icmp ugt i64 40, %2267
  br i1 %2268, label %Abort, label %2269

2269:                                             ; preds = %.1783
  %2270 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2271 = xor i32 %2270, 2145
  %2272 = urem i32 %2271, 4096
  %2273 = getelementptr i8, i8 addrspace(1)* %4, i32 %2272
  %2274 = load i8, i8 addrspace(1)* %2273, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2273, align 1, !nosanitize !3
  store i32 1072, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2275 = sub i64 %2267, 40
  store i64 %2275, i64* %remaing_gas, align 4
  %2276 = load i64, i64* %STACK_DEP_PTR, align 4
  %2277 = sub i64 %2276, 0
  store i64 %2277, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1787:                                            ; preds = %2253, %JumpTable
  %2278 = load i64, i64* %remaing_gas, align 4
  %2279 = icmp ugt i64 256, %2278
  br i1 %2279, label %Abort, label %2280

2280:                                             ; preds = %.1787
  %2281 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2282 = xor i32 %2281, 3209
  %2283 = urem i32 %2282, 4096
  %2284 = getelementptr i8, i8 addrspace(1)* %4, i32 %2283
  %2285 = load i8, i8 addrspace(1)* %2284, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2284, align 1, !nosanitize !3
  store i32 1604, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2286 = sub i64 %2278, 256
  store i64 %2286, i64* %remaing_gas, align 4
  %2287 = load i64, i64* %STACK_DEP_PTR, align 4
  %2288 = getelementptr i256, i256* %STACK, i64 %2287
  %2289 = load i256, i256* %2288, align 4
  %2290 = load i64, i64* %STACK_DEP_PTR, align 4
  %2291 = sub i64 %2290, 1
  store i64 %2291, i64* %STACK_DEP_PTR, align 4
  %2292 = zext i32 %3 to i256
  %2293 = sub i256 %2292, 4, !pc !96, !intsan !8
  %2294 = add i256 4, %2293, !pc !97, !intsan !10
  %2295 = trunc i256 4 to i64
  %2296 = alloca i256, align 8
  %2297 = bitcast i256* %2296 to i8*
  call void @__device_calldataload(i8* %2297, i8* %2, i64 %2295)
  %2298 = load i256, i256* %2296, align 4
  %2299 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %2300 = and i256 %2299, %2298
  %2301 = add i256 32, 4, !pc !98, !intsan !10
  %2302 = trunc i256 7777 to i64
  %2303 = load i64, i64* %STACK_DEP_PTR, align 4
  %2304 = add i64 %2303, 1
  store i64 %2304, i64* %STACK_DEP_PTR, align 4
  %2305 = load i64, i64* %STACK_DEP_PTR, align 4
  %2306 = getelementptr i256, i256* %STACK, i64 %2305
  store i256 1852, i256* %2306, align 4
  %2307 = load i64, i64* %STACK_DEP_PTR, align 4
  %2308 = add i64 %2307, 1
  store i64 %2308, i64* %STACK_DEP_PTR, align 4
  %2309 = load i64, i64* %STACK_DEP_PTR, align 4
  %2310 = getelementptr i256, i256* %STACK, i64 %2309
  store i256 %2300, i256* %2310, align 4
  br label %.7777, !EVMBB !4

.1852:                                            ; preds = %JumpTable
  %2311 = load i64, i64* %remaing_gas, align 4
  %2312 = icmp ugt i64 16, %2311
  br i1 %2312, label %Abort, label %2313

2313:                                             ; preds = %.1852
  %2314 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2315 = xor i32 %2314, 2553
  %2316 = urem i32 %2315, 4096
  %2317 = getelementptr i8, i8 addrspace(1)* %4, i32 %2316
  %2318 = load i8, i8 addrspace(1)* %2317, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2317, align 1, !nosanitize !3
  store i32 1276, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2319 = sub i64 %2311, 16
  store i64 %2319, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1854:                                            ; preds = %411, %JumpTable
  %2320 = load i64, i64* %remaing_gas, align 4
  %2321 = icmp ugt i64 96, %2320
  br i1 %2321, label %Abort, label %2322

2322:                                             ; preds = %.1854
  %2323 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2324 = xor i32 %2323, 3932
  %2325 = urem i32 %2324, 4096
  %2326 = getelementptr i8, i8 addrspace(1)* %4, i32 %2325
  %2327 = load i8, i8 addrspace(1)* %2326, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2326, align 1, !nosanitize !3
  store i32 1966, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2328 = sub i64 %2320, 96
  store i64 %2328, i64* %remaing_gas, align 4
  %2329 = load i256, i256* %1, align 4
  %2330 = icmp eq i256 %2329, 0
  %2331 = trunc i256 1866 to i64
  %jump.check85 = icmp ne i1 %2330, false
  %2332 = load i64, i64* %STACK_DEP_PTR, align 4
  %2333 = add i64 %2332, 1
  store i64 %2333, i64* %STACK_DEP_PTR, align 4
  %2334 = load i64, i64* %STACK_DEP_PTR, align 4
  %2335 = getelementptr i256, i256* %STACK, i64 %2334
  store i256 %2329, i256* %2335, align 4
  br i1 %jump.check85, label %.1866, label %.1862, !EVMBB !4

.1862:                                            ; preds = %2322
  %2336 = load i64, i64* %remaing_gas, align 4
  %2337 = icmp ugt i64 40, %2336
  br i1 %2337, label %Abort, label %2338

2338:                                             ; preds = %.1862
  %2339 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2340 = xor i32 %2339, 1723
  %2341 = urem i32 %2340, 4096
  %2342 = getelementptr i8, i8 addrspace(1)* %4, i32 %2341
  %2343 = load i8, i8 addrspace(1)* %2342, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2342, align 1, !nosanitize !3
  store i32 861, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2344 = sub i64 %2336, 40
  store i64 %2344, i64* %remaing_gas, align 4
  %2345 = load i64, i64* %STACK_DEP_PTR, align 4
  %2346 = sub i64 %2345, 0
  store i64 %2346, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1866:                                            ; preds = %2322, %JumpTable
  %2347 = load i64, i64* %remaing_gas, align 4
  %2348 = icmp ugt i64 248, %2347
  br i1 %2348, label %Abort, label %2349

2349:                                             ; preds = %.1866
  %2350 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2351 = xor i32 %2350, 1704
  %2352 = urem i32 %2351, 4096
  %2353 = getelementptr i8, i8 addrspace(1)* %4, i32 %2352
  %2354 = load i8, i8 addrspace(1)* %2353, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2353, align 1, !nosanitize !3
  store i32 852, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2355 = sub i64 %2347, 248
  store i64 %2355, i64* %remaing_gas, align 4
  %2356 = load i64, i64* %STACK_DEP_PTR, align 4
  %2357 = getelementptr i256, i256* %STACK, i64 %2356
  %2358 = load i256, i256* %2357, align 4
  %2359 = load i64, i64* %STACK_DEP_PTR, align 4
  %2360 = sub i64 %2359, 1
  store i64 %2360, i64* %STACK_DEP_PTR, align 4
  %2361 = zext i32 %3 to i256
  %2362 = sub i256 %2361, 4, !pc !99, !intsan !8
  %2363 = add i256 4, %2362, !pc !100, !intsan !10
  %2364 = trunc i256 4 to i64
  %2365 = alloca i256, align 8
  %2366 = bitcast i256* %2365 to i8*
  call void @__device_calldataload(i8* %2366, i8* %2, i64 %2364)
  %2367 = load i256, i256* %2365, align 4
  %2368 = and i256 1461501637330902918203684832716283019655932542975, %2367
  %2369 = add i256 32, 4, !pc !101, !intsan !10
  %2370 = trunc i256 8000 to i64
  %2371 = load i64, i64* %STACK_DEP_PTR, align 4
  %2372 = add i64 %2371, 1
  store i64 %2372, i64* %STACK_DEP_PTR, align 4
  %2373 = load i64, i64* %STACK_DEP_PTR, align 4
  %2374 = getelementptr i256, i256* %STACK, i64 %2373
  store i256 1919, i256* %2374, align 4
  %2375 = load i64, i64* %STACK_DEP_PTR, align 4
  %2376 = add i64 %2375, 1
  store i64 %2376, i64* %STACK_DEP_PTR, align 4
  %2377 = load i64, i64* %STACK_DEP_PTR, align 4
  %2378 = getelementptr i256, i256* %STACK, i64 %2377
  store i256 %2368, i256* %2378, align 4
  br label %.8000, !EVMBB !4

.1919:                                            ; preds = %JumpTable
  %2379 = load i64, i64* %remaing_gas, align 4
  %2380 = icmp ugt i64 16, %2379
  br i1 %2380, label %Abort, label %2381

2381:                                             ; preds = %.1919
  %2382 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2383 = xor i32 %2382, 3225
  %2384 = urem i32 %2383, 4096
  %2385 = getelementptr i8, i8 addrspace(1)* %4, i32 %2384
  %2386 = load i8, i8 addrspace(1)* %2385, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2385, align 1, !nosanitize !3
  store i32 1612, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2387 = sub i64 %2379, 16
  store i64 %2387, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.1921:                                            ; preds = %428, %JumpTable
  %2388 = load i64, i64* %remaing_gas, align 4
  %2389 = icmp ugt i64 96, %2388
  br i1 %2389, label %Abort, label %2390

2390:                                             ; preds = %.1921
  %2391 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2392 = xor i32 %2391, 1551
  %2393 = urem i32 %2392, 4096
  %2394 = getelementptr i8, i8 addrspace(1)* %4, i32 %2393
  %2395 = load i8, i8 addrspace(1)* %2394, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2394, align 1, !nosanitize !3
  store i32 775, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2396 = sub i64 %2388, 96
  store i64 %2396, i64* %remaing_gas, align 4
  %2397 = load i256, i256* %1, align 4
  %2398 = icmp eq i256 %2397, 0
  %2399 = trunc i256 1933 to i64
  %jump.check89 = icmp ne i1 %2398, false
  %2400 = load i64, i64* %STACK_DEP_PTR, align 4
  %2401 = add i64 %2400, 1
  store i64 %2401, i64* %STACK_DEP_PTR, align 4
  %2402 = load i64, i64* %STACK_DEP_PTR, align 4
  %2403 = getelementptr i256, i256* %STACK, i64 %2402
  store i256 %2397, i256* %2403, align 4
  br i1 %jump.check89, label %.1933, label %.1929, !EVMBB !4

.1929:                                            ; preds = %2390
  %2404 = load i64, i64* %remaing_gas, align 4
  %2405 = icmp ugt i64 40, %2404
  br i1 %2405, label %Abort, label %2406

2406:                                             ; preds = %.1929
  %2407 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2408 = xor i32 %2407, 149
  %2409 = urem i32 %2408, 4096
  %2410 = getelementptr i8, i8 addrspace(1)* %4, i32 %2409
  %2411 = load i8, i8 addrspace(1)* %2410, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2410, align 1, !nosanitize !3
  store i32 74, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2412 = sub i64 %2404, 40
  store i64 %2412, i64* %remaing_gas, align 4
  %2413 = load i64, i64* %STACK_DEP_PTR, align 4
  %2414 = sub i64 %2413, 0
  store i64 %2414, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.1933:                                            ; preds = %2390, %JumpTable
  %2415 = load i64, i64* %remaing_gas, align 4
  %2416 = icmp ugt i64 120, %2415
  br i1 %2416, label %Abort, label %2417

2417:                                             ; preds = %.1933
  %2418 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2419 = xor i32 %2418, 1969
  %2420 = urem i32 %2419, 4096
  %2421 = getelementptr i8, i8 addrspace(1)* %4, i32 %2420
  %2422 = load i8, i8 addrspace(1)* %2421, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2421, align 1, !nosanitize !3
  store i32 984, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2423 = sub i64 %2415, 120
  store i64 %2423, i64* %remaing_gas, align 4
  %2424 = load i64, i64* %STACK_DEP_PTR, align 4
  %2425 = getelementptr i256, i256* %STACK, i64 %2424
  %2426 = load i256, i256* %2425, align 4
  %2427 = load i64, i64* %STACK_DEP_PTR, align 4
  %2428 = sub i64 %2427, 1
  store i64 %2428, i64* %STACK_DEP_PTR, align 4
  %2429 = trunc i256 8183 to i64
  %2430 = load i64, i64* %STACK_DEP_PTR, align 4
  %2431 = add i64 %2430, 1
  store i64 %2431, i64* %STACK_DEP_PTR, align 4
  %2432 = load i64, i64* %STACK_DEP_PTR, align 4
  %2433 = getelementptr i256, i256* %STACK, i64 %2432
  store i256 1942, i256* %2433, align 4
  br label %.8183, !EVMBB !4

.1942:                                            ; preds = %JumpTable
  %2434 = load i64, i64* %remaing_gas, align 4
  %2435 = icmp ugt i64 296, %2434
  br i1 %2435, label %Abort, label %2436

2436:                                             ; preds = %.1942
  %2437 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2438 = xor i32 %2437, 1515
  %2439 = urem i32 %2438, 4096
  %2440 = getelementptr i8, i8 addrspace(1)* %4, i32 %2439
  %2441 = load i8, i8 addrspace(1)* %2440, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2440, align 1, !nosanitize !3
  store i32 757, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2442 = sub i64 %2434, 296
  store i64 %2442, i64* %remaing_gas, align 4
  %2443 = load i64, i64* %STACK_DEP_PTR, align 4
  %2444 = getelementptr i256, i256* %STACK, i64 %2443
  %2445 = load i256, i256* %2444, align 4
  %2446 = load i64, i64* %STACK_DEP_PTR, align 4
  %2447 = sub i64 %2446, 1
  store i64 %2447, i64* %STACK_DEP_PTR, align 4
  %2448 = load i64, i64* %STACK_DEP_PTR, align 4
  %2449 = getelementptr i256, i256* %STACK, i64 %2448
  %2450 = load i256, i256* %2449, align 4
  %2451 = load i64, i64* %STACK_DEP_PTR, align 4
  %2452 = sub i64 %2451, 1
  store i64 %2452, i64* %STACK_DEP_PTR, align 4
  %2453 = trunc i256 64 to i64
  %2454 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2453, i256* %2454)
  %2455 = load i256, i256* %2454, align 4
  %2456 = and i256 1461501637330902918203684832716283019655932542975, %2450
  %2457 = and i256 1461501637330902918203684832716283019655932542975, %2456
  %2458 = trunc i256 %2455 to i64
  %2459 = alloca i256, align 8
  store i256 %2457, i256* %2459, align 4
  %2460 = bitcast i256* %2459 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2458, i8* %2460, i64 32)
  %2461 = add i256 32, %2455, !pc !102, !intsan !10
  %2462 = trunc i256 %2461 to i64
  %2463 = alloca i256, align 8
  store i256 %2445, i256* %2463, align 4
  %2464 = bitcast i256* %2463 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2462, i8* %2464, i64 32)
  %2465 = add i256 32, %2461, !pc !103, !intsan !10
  %2466 = trunc i256 64 to i64
  %2467 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2466, i256* %2467)
  %2468 = load i256, i256* %2467, align 4
  %2469 = sub i256 %2465, %2468, !pc !104, !intsan !8
  br label %Exit, !EVMBB !4

.2015:                                            ; preds = %445, %JumpTable
  %2470 = load i64, i64* %remaing_gas, align 4
  %2471 = icmp ugt i64 96, %2470
  br i1 %2471, label %Abort, label %2472

2472:                                             ; preds = %.2015
  %2473 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2474 = xor i32 %2473, 1265
  %2475 = urem i32 %2474, 4096
  %2476 = getelementptr i8, i8 addrspace(1)* %4, i32 %2475
  %2477 = load i8, i8 addrspace(1)* %2476, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2476, align 1, !nosanitize !3
  store i32 632, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2478 = sub i64 %2470, 96
  store i64 %2478, i64* %remaing_gas, align 4
  %2479 = load i256, i256* %1, align 4
  %2480 = icmp eq i256 %2479, 0
  %2481 = trunc i256 2027 to i64
  %jump.check94 = icmp ne i1 %2480, false
  %2482 = load i64, i64* %STACK_DEP_PTR, align 4
  %2483 = add i64 %2482, 1
  store i64 %2483, i64* %STACK_DEP_PTR, align 4
  %2484 = load i64, i64* %STACK_DEP_PTR, align 4
  %2485 = getelementptr i256, i256* %STACK, i64 %2484
  store i256 %2479, i256* %2485, align 4
  br i1 %jump.check94, label %.2027, label %.2023, !EVMBB !4

.2023:                                            ; preds = %2472
  %2486 = load i64, i64* %remaing_gas, align 4
  %2487 = icmp ugt i64 40, %2486
  br i1 %2487, label %Abort, label %2488

2488:                                             ; preds = %.2023
  %2489 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2490 = xor i32 %2489, 179
  %2491 = urem i32 %2490, 4096
  %2492 = getelementptr i8, i8 addrspace(1)* %4, i32 %2491
  %2493 = load i8, i8 addrspace(1)* %2492, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2492, align 1, !nosanitize !3
  store i32 89, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2494 = sub i64 %2486, 40
  store i64 %2494, i64* %remaing_gas, align 4
  %2495 = load i64, i64* %STACK_DEP_PTR, align 4
  %2496 = sub i64 %2495, 0
  store i64 %2496, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2027:                                            ; preds = %2472, %JumpTable
  %2497 = load i64, i64* %remaing_gas, align 4
  %2498 = icmp ugt i64 120, %2497
  br i1 %2498, label %Abort, label %2499

2499:                                             ; preds = %.2027
  %2500 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2501 = xor i32 %2500, 3589
  %2502 = urem i32 %2501, 4096
  %2503 = getelementptr i8, i8 addrspace(1)* %4, i32 %2502
  %2504 = load i8, i8 addrspace(1)* %2503, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2503, align 1, !nosanitize !3
  store i32 1794, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2505 = sub i64 %2497, 120
  store i64 %2505, i64* %remaing_gas, align 4
  %2506 = load i64, i64* %STACK_DEP_PTR, align 4
  %2507 = getelementptr i256, i256* %STACK, i64 %2506
  %2508 = load i256, i256* %2507, align 4
  %2509 = load i64, i64* %STACK_DEP_PTR, align 4
  %2510 = sub i64 %2509, 1
  store i64 %2510, i64* %STACK_DEP_PTR, align 4
  %2511 = trunc i256 8233 to i64
  %2512 = load i64, i64* %STACK_DEP_PTR, align 4
  %2513 = add i64 %2512, 1
  store i64 %2513, i64* %STACK_DEP_PTR, align 4
  %2514 = load i64, i64* %STACK_DEP_PTR, align 4
  %2515 = getelementptr i256, i256* %STACK, i64 %2514
  store i256 2036, i256* %2515, align 4
  br label %.8233, !EVMBB !4

.2036:                                            ; preds = %JumpTable
  %2516 = load i64, i64* %remaing_gas, align 4
  %2517 = icmp ugt i64 184, %2516
  br i1 %2517, label %Abort, label %2518

2518:                                             ; preds = %.2036
  %2519 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2520 = xor i32 %2519, 3567
  %2521 = urem i32 %2520, 4096
  %2522 = getelementptr i8, i8 addrspace(1)* %4, i32 %2521
  %2523 = load i8, i8 addrspace(1)* %2522, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2522, align 1, !nosanitize !3
  store i32 1783, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2524 = sub i64 %2516, 184
  store i64 %2524, i64* %remaing_gas, align 4
  %2525 = load i64, i64* %STACK_DEP_PTR, align 4
  %2526 = getelementptr i256, i256* %STACK, i64 %2525
  %2527 = load i256, i256* %2526, align 4
  %2528 = load i64, i64* %STACK_DEP_PTR, align 4
  %2529 = sub i64 %2528, 1
  store i64 %2529, i64* %STACK_DEP_PTR, align 4
  %2530 = trunc i256 64 to i64
  %2531 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2530, i256* %2531)
  %2532 = load i256, i256* %2531, align 4
  %2533 = trunc i256 %2532 to i64
  %2534 = alloca i256, align 8
  store i256 %2527, i256* %2534, align 4
  %2535 = bitcast i256* %2534 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2533, i8* %2535, i64 32)
  %2536 = add i256 32, %2532, !pc !105, !intsan !10
  %2537 = trunc i256 64 to i64
  %2538 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2537, i256* %2538)
  %2539 = load i256, i256* %2538, align 4
  %2540 = sub i256 %2536, %2539, !pc !106, !intsan !8
  br label %Exit, !EVMBB !4

.2058:                                            ; preds = %462, %JumpTable
  %2541 = load i64, i64* %remaing_gas, align 4
  %2542 = icmp ugt i64 96, %2541
  br i1 %2542, label %Abort, label %2543

2543:                                             ; preds = %.2058
  %2544 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2545 = xor i32 %2544, 3063
  %2546 = urem i32 %2545, 4096
  %2547 = getelementptr i8, i8 addrspace(1)* %4, i32 %2546
  %2548 = load i8, i8 addrspace(1)* %2547, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2547, align 1, !nosanitize !3
  store i32 1531, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2549 = sub i64 %2541, 96
  store i64 %2549, i64* %remaing_gas, align 4
  %2550 = load i256, i256* %1, align 4
  %2551 = icmp eq i256 %2550, 0
  %2552 = trunc i256 2070 to i64
  %jump.check100 = icmp ne i1 %2551, false
  %2553 = load i64, i64* %STACK_DEP_PTR, align 4
  %2554 = add i64 %2553, 1
  store i64 %2554, i64* %STACK_DEP_PTR, align 4
  %2555 = load i64, i64* %STACK_DEP_PTR, align 4
  %2556 = getelementptr i256, i256* %STACK, i64 %2555
  store i256 %2550, i256* %2556, align 4
  br i1 %jump.check100, label %.2070, label %.2066, !EVMBB !4

.2066:                                            ; preds = %2543
  %2557 = load i64, i64* %remaing_gas, align 4
  %2558 = icmp ugt i64 40, %2557
  br i1 %2558, label %Abort, label %2559

2559:                                             ; preds = %.2066
  %2560 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2561 = xor i32 %2560, 3840
  %2562 = urem i32 %2561, 4096
  %2563 = getelementptr i8, i8 addrspace(1)* %4, i32 %2562
  %2564 = load i8, i8 addrspace(1)* %2563, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2563, align 1, !nosanitize !3
  store i32 1920, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2565 = sub i64 %2557, 40
  store i64 %2565, i64* %remaing_gas, align 4
  %2566 = load i64, i64* %STACK_DEP_PTR, align 4
  %2567 = sub i64 %2566, 0
  store i64 %2567, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2070:                                            ; preds = %2543, %JumpTable
  %2568 = load i64, i64* %remaing_gas, align 4
  %2569 = icmp ugt i64 120, %2568
  br i1 %2569, label %Abort, label %2570

2570:                                             ; preds = %.2070
  %2571 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2572 = xor i32 %2571, 1257
  %2573 = urem i32 %2572, 4096
  %2574 = getelementptr i8, i8 addrspace(1)* %4, i32 %2573
  %2575 = load i8, i8 addrspace(1)* %2574, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2574, align 1, !nosanitize !3
  store i32 628, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2576 = sub i64 %2568, 120
  store i64 %2576, i64* %remaing_gas, align 4
  %2577 = load i64, i64* %STACK_DEP_PTR, align 4
  %2578 = getelementptr i256, i256* %STACK, i64 %2577
  %2579 = load i256, i256* %2578, align 4
  %2580 = load i64, i64* %STACK_DEP_PTR, align 4
  %2581 = sub i64 %2580, 1
  store i64 %2581, i64* %STACK_DEP_PTR, align 4
  %2582 = trunc i256 8716 to i64
  %2583 = load i64, i64* %STACK_DEP_PTR, align 4
  %2584 = add i64 %2583, 1
  store i64 %2584, i64* %STACK_DEP_PTR, align 4
  %2585 = load i64, i64* %STACK_DEP_PTR, align 4
  %2586 = getelementptr i256, i256* %STACK, i64 %2585
  store i256 2079, i256* %2586, align 4
  br label %.8716, !EVMBB !4

.2079:                                            ; preds = %JumpTable
  %2587 = load i64, i64* %remaing_gas, align 4
  %2588 = icmp ugt i64 184, %2587
  br i1 %2588, label %Abort, label %2589

2589:                                             ; preds = %.2079
  %2590 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2591 = xor i32 %2590, 2721
  %2592 = urem i32 %2591, 4096
  %2593 = getelementptr i8, i8 addrspace(1)* %4, i32 %2592
  %2594 = load i8, i8 addrspace(1)* %2593, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2593, align 1, !nosanitize !3
  store i32 1360, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2595 = sub i64 %2587, 184
  store i64 %2595, i64* %remaing_gas, align 4
  %2596 = load i64, i64* %STACK_DEP_PTR, align 4
  %2597 = getelementptr i256, i256* %STACK, i64 %2596
  %2598 = load i256, i256* %2597, align 4
  %2599 = load i64, i64* %STACK_DEP_PTR, align 4
  %2600 = sub i64 %2599, 1
  store i64 %2600, i64* %STACK_DEP_PTR, align 4
  %2601 = trunc i256 64 to i64
  %2602 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2601, i256* %2602)
  %2603 = load i256, i256* %2602, align 4
  %2604 = trunc i256 %2603 to i64
  %2605 = alloca i256, align 8
  store i256 %2598, i256* %2605, align 4
  %2606 = bitcast i256* %2605 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2604, i8* %2606, i64 32)
  %2607 = add i256 32, %2603, !pc !107, !intsan !10
  %2608 = trunc i256 64 to i64
  %2609 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2608, i256* %2609)
  %2610 = load i256, i256* %2609, align 4
  %2611 = sub i256 %2607, %2610, !pc !108, !intsan !8
  br label %Exit, !EVMBB !4

.2101:                                            ; preds = %479, %JumpTable
  %2612 = load i64, i64* %remaing_gas, align 4
  %2613 = icmp ugt i64 96, %2612
  br i1 %2613, label %Abort, label %2614

2614:                                             ; preds = %.2101
  %2615 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2616 = xor i32 %2615, 570
  %2617 = urem i32 %2616, 4096
  %2618 = getelementptr i8, i8 addrspace(1)* %4, i32 %2617
  %2619 = load i8, i8 addrspace(1)* %2618, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2618, align 1, !nosanitize !3
  store i32 285, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2620 = sub i64 %2612, 96
  store i64 %2620, i64* %remaing_gas, align 4
  %2621 = load i256, i256* %1, align 4
  %2622 = icmp eq i256 %2621, 0
  %2623 = trunc i256 2113 to i64
  %jump.check104 = icmp ne i1 %2622, false
  %2624 = load i64, i64* %STACK_DEP_PTR, align 4
  %2625 = add i64 %2624, 1
  store i64 %2625, i64* %STACK_DEP_PTR, align 4
  %2626 = load i64, i64* %STACK_DEP_PTR, align 4
  %2627 = getelementptr i256, i256* %STACK, i64 %2626
  store i256 %2621, i256* %2627, align 4
  br i1 %jump.check104, label %.2113, label %.2109, !EVMBB !4

.2109:                                            ; preds = %2614
  %2628 = load i64, i64* %remaing_gas, align 4
  %2629 = icmp ugt i64 40, %2628
  br i1 %2629, label %Abort, label %2630

2630:                                             ; preds = %.2109
  %2631 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2632 = xor i32 %2631, 2789
  %2633 = urem i32 %2632, 4096
  %2634 = getelementptr i8, i8 addrspace(1)* %4, i32 %2633
  %2635 = load i8, i8 addrspace(1)* %2634, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2634, align 1, !nosanitize !3
  store i32 1394, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2636 = sub i64 %2628, 40
  store i64 %2636, i64* %remaing_gas, align 4
  %2637 = load i64, i64* %STACK_DEP_PTR, align 4
  %2638 = sub i64 %2637, 0
  store i64 %2638, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2113:                                            ; preds = %2614, %JumpTable
  %2639 = load i64, i64* %remaing_gas, align 4
  %2640 = icmp ugt i64 120, %2639
  br i1 %2640, label %Abort, label %2641

2641:                                             ; preds = %.2113
  %2642 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2643 = xor i32 %2642, 4042
  %2644 = urem i32 %2643, 4096
  %2645 = getelementptr i8, i8 addrspace(1)* %4, i32 %2644
  %2646 = load i8, i8 addrspace(1)* %2645, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2645, align 1, !nosanitize !3
  store i32 2021, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2647 = sub i64 %2639, 120
  store i64 %2647, i64* %remaing_gas, align 4
  %2648 = load i64, i64* %STACK_DEP_PTR, align 4
  %2649 = getelementptr i256, i256* %STACK, i64 %2648
  %2650 = load i256, i256* %2649, align 4
  %2651 = load i64, i64* %STACK_DEP_PTR, align 4
  %2652 = sub i64 %2651, 1
  store i64 %2652, i64* %STACK_DEP_PTR, align 4
  %2653 = trunc i256 8722 to i64
  %2654 = load i64, i64* %STACK_DEP_PTR, align 4
  %2655 = add i64 %2654, 1
  store i64 %2655, i64* %STACK_DEP_PTR, align 4
  %2656 = load i64, i64* %STACK_DEP_PTR, align 4
  %2657 = getelementptr i256, i256* %STACK, i64 %2656
  store i256 2122, i256* %2657, align 4
  br label %.8722, !EVMBB !4

.2122:                                            ; preds = %JumpTable
  %2658 = load i64, i64* %remaing_gas, align 4
  %2659 = icmp ugt i64 184, %2658
  br i1 %2659, label %Abort, label %2660

2660:                                             ; preds = %.2122
  %2661 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2662 = xor i32 %2661, 11
  %2663 = urem i32 %2662, 4096
  %2664 = getelementptr i8, i8 addrspace(1)* %4, i32 %2663
  %2665 = load i8, i8 addrspace(1)* %2664, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2664, align 1, !nosanitize !3
  store i32 5, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2666 = sub i64 %2658, 184
  store i64 %2666, i64* %remaing_gas, align 4
  %2667 = load i64, i64* %STACK_DEP_PTR, align 4
  %2668 = getelementptr i256, i256* %STACK, i64 %2667
  %2669 = load i256, i256* %2668, align 4
  %2670 = load i64, i64* %STACK_DEP_PTR, align 4
  %2671 = sub i64 %2670, 1
  store i64 %2671, i64* %STACK_DEP_PTR, align 4
  %2672 = trunc i256 64 to i64
  %2673 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2672, i256* %2673)
  %2674 = load i256, i256* %2673, align 4
  %2675 = trunc i256 %2674 to i64
  %2676 = alloca i256, align 8
  store i256 %2669, i256* %2676, align 4
  %2677 = bitcast i256* %2676 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2675, i8* %2677, i64 32)
  %2678 = add i256 32, %2674, !pc !109, !intsan !10
  %2679 = trunc i256 64 to i64
  %2680 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2679, i256* %2680)
  %2681 = load i256, i256* %2680, align 4
  %2682 = sub i256 %2678, %2681, !pc !110, !intsan !8
  br label %Exit, !EVMBB !4

.2144:                                            ; preds = %496, %JumpTable
  %2683 = load i64, i64* %remaing_gas, align 4
  %2684 = icmp ugt i64 96, %2683
  br i1 %2684, label %Abort, label %2685

2685:                                             ; preds = %.2144
  %2686 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2687 = xor i32 %2686, 2763
  %2688 = urem i32 %2687, 4096
  %2689 = getelementptr i8, i8 addrspace(1)* %4, i32 %2688
  %2690 = load i8, i8 addrspace(1)* %2689, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2689, align 1, !nosanitize !3
  store i32 1381, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2691 = sub i64 %2683, 96
  store i64 %2691, i64* %remaing_gas, align 4
  %2692 = load i256, i256* %1, align 4
  %2693 = icmp eq i256 %2692, 0
  %2694 = trunc i256 2156 to i64
  %jump.check110 = icmp ne i1 %2693, false
  %2695 = load i64, i64* %STACK_DEP_PTR, align 4
  %2696 = add i64 %2695, 1
  store i64 %2696, i64* %STACK_DEP_PTR, align 4
  %2697 = load i64, i64* %STACK_DEP_PTR, align 4
  %2698 = getelementptr i256, i256* %STACK, i64 %2697
  store i256 %2692, i256* %2698, align 4
  br i1 %jump.check110, label %.2156, label %.2152, !EVMBB !4

.2152:                                            ; preds = %2685
  %2699 = load i64, i64* %remaing_gas, align 4
  %2700 = icmp ugt i64 40, %2699
  br i1 %2700, label %Abort, label %2701

2701:                                             ; preds = %.2152
  %2702 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2703 = xor i32 %2702, 4048
  %2704 = urem i32 %2703, 4096
  %2705 = getelementptr i8, i8 addrspace(1)* %4, i32 %2704
  %2706 = load i8, i8 addrspace(1)* %2705, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2705, align 1, !nosanitize !3
  store i32 2024, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2707 = sub i64 %2699, 40
  store i64 %2707, i64* %remaing_gas, align 4
  %2708 = load i64, i64* %STACK_DEP_PTR, align 4
  %2709 = sub i64 %2708, 0
  store i64 %2709, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2156:                                            ; preds = %2685, %JumpTable
  %2710 = load i64, i64* %remaing_gas, align 4
  %2711 = icmp ugt i64 248, %2710
  br i1 %2711, label %Abort, label %2712

2712:                                             ; preds = %.2156
  %2713 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2714 = xor i32 %2713, 328
  %2715 = urem i32 %2714, 4096
  %2716 = getelementptr i8, i8 addrspace(1)* %4, i32 %2715
  %2717 = load i8, i8 addrspace(1)* %2716, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2716, align 1, !nosanitize !3
  store i32 164, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2718 = sub i64 %2710, 248
  store i64 %2718, i64* %remaing_gas, align 4
  %2719 = load i64, i64* %STACK_DEP_PTR, align 4
  %2720 = getelementptr i256, i256* %STACK, i64 %2719
  %2721 = load i256, i256* %2720, align 4
  %2722 = load i64, i64* %STACK_DEP_PTR, align 4
  %2723 = sub i64 %2722, 1
  store i64 %2723, i64* %STACK_DEP_PTR, align 4
  %2724 = zext i32 %3 to i256
  %2725 = sub i256 %2724, 4, !pc !111, !intsan !8
  %2726 = add i256 4, %2725, !pc !112, !intsan !10
  %2727 = trunc i256 4 to i64
  %2728 = alloca i256, align 8
  %2729 = bitcast i256* %2728 to i8*
  call void @__device_calldataload(i8* %2729, i8* %2, i64 %2727)
  %2730 = load i256, i256* %2728, align 4
  %2731 = and i256 1461501637330902918203684832716283019655932542975, %2730
  %2732 = add i256 32, 4, !pc !113, !intsan !10
  %2733 = trunc i256 8728 to i64
  %2734 = load i64, i64* %STACK_DEP_PTR, align 4
  %2735 = add i64 %2734, 1
  store i64 %2735, i64* %STACK_DEP_PTR, align 4
  %2736 = load i64, i64* %STACK_DEP_PTR, align 4
  %2737 = getelementptr i256, i256* %STACK, i64 %2736
  store i256 2209, i256* %2737, align 4
  %2738 = load i64, i64* %STACK_DEP_PTR, align 4
  %2739 = add i64 %2738, 1
  store i64 %2739, i64* %STACK_DEP_PTR, align 4
  %2740 = load i64, i64* %STACK_DEP_PTR, align 4
  %2741 = getelementptr i256, i256* %STACK, i64 %2740
  store i256 %2731, i256* %2741, align 4
  br label %.8728, !EVMBB !4

.2209:                                            ; preds = %JumpTable
  %2742 = load i64, i64* %remaing_gas, align 4
  %2743 = icmp ugt i64 184, %2742
  br i1 %2743, label %Abort, label %2744

2744:                                             ; preds = %.2209
  %2745 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2746 = xor i32 %2745, 583
  %2747 = urem i32 %2746, 4096
  %2748 = getelementptr i8, i8 addrspace(1)* %4, i32 %2747
  %2749 = load i8, i8 addrspace(1)* %2748, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2748, align 1, !nosanitize !3
  store i32 291, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2750 = sub i64 %2742, 184
  store i64 %2750, i64* %remaing_gas, align 4
  %2751 = load i64, i64* %STACK_DEP_PTR, align 4
  %2752 = getelementptr i256, i256* %STACK, i64 %2751
  %2753 = load i256, i256* %2752, align 4
  %2754 = load i64, i64* %STACK_DEP_PTR, align 4
  %2755 = sub i64 %2754, 1
  store i64 %2755, i64* %STACK_DEP_PTR, align 4
  %2756 = trunc i256 64 to i64
  %2757 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2756, i256* %2757)
  %2758 = load i256, i256* %2757, align 4
  %2759 = trunc i256 %2758 to i64
  %2760 = alloca i256, align 8
  store i256 %2753, i256* %2760, align 4
  %2761 = bitcast i256* %2760 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2759, i8* %2761, i64 32)
  %2762 = add i256 32, %2758, !pc !114, !intsan !10
  %2763 = trunc i256 64 to i64
  %2764 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2763, i256* %2764)
  %2765 = load i256, i256* %2764, align 4
  %2766 = sub i256 %2762, %2765, !pc !115, !intsan !8
  br label %Exit, !EVMBB !4

.2231:                                            ; preds = %513, %JumpTable
  %2767 = load i64, i64* %remaing_gas, align 4
  %2768 = icmp ugt i64 96, %2767
  br i1 %2768, label %Abort, label %2769

2769:                                             ; preds = %.2231
  %2770 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2771 = xor i32 %2770, 1892
  %2772 = urem i32 %2771, 4096
  %2773 = getelementptr i8, i8 addrspace(1)* %4, i32 %2772
  %2774 = load i8, i8 addrspace(1)* %2773, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2773, align 1, !nosanitize !3
  store i32 946, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2775 = sub i64 %2767, 96
  store i64 %2775, i64* %remaing_gas, align 4
  %2776 = load i256, i256* %1, align 4
  %2777 = icmp eq i256 %2776, 0
  %2778 = trunc i256 2243 to i64
  %jump.check116 = icmp ne i1 %2777, false
  %2779 = load i64, i64* %STACK_DEP_PTR, align 4
  %2780 = add i64 %2779, 1
  store i64 %2780, i64* %STACK_DEP_PTR, align 4
  %2781 = load i64, i64* %STACK_DEP_PTR, align 4
  %2782 = getelementptr i256, i256* %STACK, i64 %2781
  store i256 %2776, i256* %2782, align 4
  br i1 %jump.check116, label %.2243, label %.2239, !EVMBB !4

.2239:                                            ; preds = %2769
  %2783 = load i64, i64* %remaing_gas, align 4
  %2784 = icmp ugt i64 40, %2783
  br i1 %2784, label %Abort, label %2785

2785:                                             ; preds = %.2239
  %2786 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2787 = xor i32 %2786, 1725
  %2788 = urem i32 %2787, 4096
  %2789 = getelementptr i8, i8 addrspace(1)* %4, i32 %2788
  %2790 = load i8, i8 addrspace(1)* %2789, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2789, align 1, !nosanitize !3
  store i32 862, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2791 = sub i64 %2783, 40
  store i64 %2791, i64* %remaing_gas, align 4
  %2792 = load i64, i64* %STACK_DEP_PTR, align 4
  %2793 = sub i64 %2792, 0
  store i64 %2793, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2243:                                            ; preds = %2769, %JumpTable
  %2794 = load i64, i64* %remaing_gas, align 4
  %2795 = icmp ugt i64 240, %2794
  br i1 %2795, label %Abort, label %2796

2796:                                             ; preds = %.2243
  %2797 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2798 = xor i32 %2797, 543
  %2799 = urem i32 %2798, 4096
  %2800 = getelementptr i8, i8 addrspace(1)* %4, i32 %2799
  %2801 = load i8, i8 addrspace(1)* %2800, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2800, align 1, !nosanitize !3
  store i32 271, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2802 = sub i64 %2794, 240
  store i64 %2802, i64* %remaing_gas, align 4
  %2803 = load i64, i64* %STACK_DEP_PTR, align 4
  %2804 = getelementptr i256, i256* %STACK, i64 %2803
  %2805 = load i256, i256* %2804, align 4
  %2806 = load i64, i64* %STACK_DEP_PTR, align 4
  %2807 = sub i64 %2806, 1
  store i64 %2807, i64* %STACK_DEP_PTR, align 4
  %2808 = zext i32 %3 to i256
  %2809 = sub i256 %2808, 4, !pc !116, !intsan !8
  %2810 = add i256 4, %2809, !pc !117, !intsan !10
  %2811 = trunc i256 4 to i64
  %2812 = alloca i256, align 8
  %2813 = bitcast i256* %2812 to i8*
  call void @__device_calldataload(i8* %2813, i8* %2, i64 %2811)
  %2814 = load i256, i256* %2812, align 4
  %2815 = add i256 32, 4, !pc !118, !intsan !10
  %2816 = trunc i256 8752 to i64
  %2817 = load i64, i64* %STACK_DEP_PTR, align 4
  %2818 = add i64 %2817, 1
  store i64 %2818, i64* %STACK_DEP_PTR, align 4
  %2819 = load i64, i64* %STACK_DEP_PTR, align 4
  %2820 = getelementptr i256, i256* %STACK, i64 %2819
  store i256 2274, i256* %2820, align 4
  %2821 = load i64, i64* %STACK_DEP_PTR, align 4
  %2822 = add i64 %2821, 1
  store i64 %2822, i64* %STACK_DEP_PTR, align 4
  %2823 = load i64, i64* %STACK_DEP_PTR, align 4
  %2824 = getelementptr i256, i256* %STACK, i64 %2823
  store i256 %2814, i256* %2824, align 4
  br label %.8752, !EVMBB !4

.2274:                                            ; preds = %JumpTable
  %2825 = load i64, i64* %remaing_gas, align 4
  %2826 = icmp ugt i64 216, %2825
  br i1 %2826, label %Abort, label %2827

2827:                                             ; preds = %.2274
  %2828 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2829 = xor i32 %2828, 3363
  %2830 = urem i32 %2829, 4096
  %2831 = getelementptr i8, i8 addrspace(1)* %4, i32 %2830
  %2832 = load i8, i8 addrspace(1)* %2831, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2831, align 1, !nosanitize !3
  store i32 1681, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2833 = sub i64 %2825, 216
  store i64 %2833, i64* %remaing_gas, align 4
  %2834 = load i64, i64* %STACK_DEP_PTR, align 4
  %2835 = getelementptr i256, i256* %STACK, i64 %2834
  %2836 = load i256, i256* %2835, align 4
  %2837 = load i64, i64* %STACK_DEP_PTR, align 4
  %2838 = sub i64 %2837, 1
  store i64 %2838, i64* %STACK_DEP_PTR, align 4
  %2839 = trunc i256 64 to i64
  %2840 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2839, i256* %2840)
  %2841 = load i256, i256* %2840, align 4
  %2842 = xor i256 0, -1
  %2843 = and i256 %2842, %2836
  %2844 = xor i256 0, -1
  %2845 = and i256 %2844, %2843
  %2846 = trunc i256 %2841 to i64
  %2847 = alloca i256, align 8
  store i256 %2845, i256* %2847, align 4
  %2848 = bitcast i256* %2847 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2846, i8* %2848, i64 32)
  %2849 = add i256 32, %2841, !pc !119, !intsan !10
  %2850 = trunc i256 64 to i64
  %2851 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2850, i256* %2851)
  %2852 = load i256, i256* %2851, align 4
  %2853 = sub i256 %2849, %2852, !pc !120, !intsan !8
  br label %Exit, !EVMBB !4

.2304:                                            ; preds = %530, %JumpTable
  %2854 = load i64, i64* %remaing_gas, align 4
  %2855 = icmp ugt i64 96, %2854
  br i1 %2855, label %Abort, label %2856

2856:                                             ; preds = %.2304
  %2857 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2858 = xor i32 %2857, 3870
  %2859 = urem i32 %2858, 4096
  %2860 = getelementptr i8, i8 addrspace(1)* %4, i32 %2859
  %2861 = load i8, i8 addrspace(1)* %2860, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2860, align 1, !nosanitize !3
  store i32 1935, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2862 = sub i64 %2854, 96
  store i64 %2862, i64* %remaing_gas, align 4
  %2863 = load i256, i256* %1, align 4
  %2864 = icmp eq i256 %2863, 0
  %2865 = trunc i256 2316 to i64
  %jump.check121 = icmp ne i1 %2864, false
  %2866 = load i64, i64* %STACK_DEP_PTR, align 4
  %2867 = add i64 %2866, 1
  store i64 %2867, i64* %STACK_DEP_PTR, align 4
  %2868 = load i64, i64* %STACK_DEP_PTR, align 4
  %2869 = getelementptr i256, i256* %STACK, i64 %2868
  store i256 %2863, i256* %2869, align 4
  br i1 %jump.check121, label %.2316, label %.2312, !EVMBB !4

.2312:                                            ; preds = %2856
  %2870 = load i64, i64* %remaing_gas, align 4
  %2871 = icmp ugt i64 40, %2870
  br i1 %2871, label %Abort, label %2872

2872:                                             ; preds = %.2312
  %2873 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2874 = xor i32 %2873, 3752
  %2875 = urem i32 %2874, 4096
  %2876 = getelementptr i8, i8 addrspace(1)* %4, i32 %2875
  %2877 = load i8, i8 addrspace(1)* %2876, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2876, align 1, !nosanitize !3
  store i32 1876, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2878 = sub i64 %2870, 40
  store i64 %2878, i64* %remaing_gas, align 4
  %2879 = load i64, i64* %STACK_DEP_PTR, align 4
  %2880 = sub i64 %2879, 0
  store i64 %2880, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2316:                                            ; preds = %2856, %JumpTable
  %2881 = load i64, i64* %remaing_gas, align 4
  %2882 = icmp ugt i64 120, %2881
  br i1 %2882, label %Abort, label %2883

2883:                                             ; preds = %.2316
  %2884 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2885 = xor i32 %2884, 1820
  %2886 = urem i32 %2885, 4096
  %2887 = getelementptr i8, i8 addrspace(1)* %4, i32 %2886
  %2888 = load i8, i8 addrspace(1)* %2887, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2887, align 1, !nosanitize !3
  store i32 910, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2889 = sub i64 %2881, 120
  store i64 %2889, i64* %remaing_gas, align 4
  %2890 = load i64, i64* %STACK_DEP_PTR, align 4
  %2891 = getelementptr i256, i256* %STACK, i64 %2890
  %2892 = load i256, i256* %2891, align 4
  %2893 = load i64, i64* %STACK_DEP_PTR, align 4
  %2894 = sub i64 %2893, 1
  store i64 %2894, i64* %STACK_DEP_PTR, align 4
  %2895 = trunc i256 8787 to i64
  %2896 = load i64, i64* %STACK_DEP_PTR, align 4
  %2897 = add i64 %2896, 1
  store i64 %2897, i64* %STACK_DEP_PTR, align 4
  %2898 = load i64, i64* %STACK_DEP_PTR, align 4
  %2899 = getelementptr i256, i256* %STACK, i64 %2898
  store i256 2325, i256* %2899, align 4
  br label %.8787, !EVMBB !4

.2325:                                            ; preds = %JumpTable
  %2900 = load i64, i64* %remaing_gas, align 4
  %2901 = icmp ugt i64 184, %2900
  br i1 %2901, label %Abort, label %2902

2902:                                             ; preds = %.2325
  %2903 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2904 = xor i32 %2903, 3707
  %2905 = urem i32 %2904, 4096
  %2906 = getelementptr i8, i8 addrspace(1)* %4, i32 %2905
  %2907 = load i8, i8 addrspace(1)* %2906, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2906, align 1, !nosanitize !3
  store i32 1853, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2908 = sub i64 %2900, 184
  store i64 %2908, i64* %remaing_gas, align 4
  %2909 = load i64, i64* %STACK_DEP_PTR, align 4
  %2910 = getelementptr i256, i256* %STACK, i64 %2909
  %2911 = load i256, i256* %2910, align 4
  %2912 = load i64, i64* %STACK_DEP_PTR, align 4
  %2913 = sub i64 %2912, 1
  store i64 %2913, i64* %STACK_DEP_PTR, align 4
  %2914 = trunc i256 64 to i64
  %2915 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2914, i256* %2915)
  %2916 = load i256, i256* %2915, align 4
  %2917 = trunc i256 %2916 to i64
  %2918 = alloca i256, align 8
  store i256 %2911, i256* %2918, align 4
  %2919 = bitcast i256* %2918 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2917, i8* %2919, i64 32)
  %2920 = add i256 32, %2916, !pc !121, !intsan !10
  %2921 = trunc i256 64 to i64
  %2922 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2921, i256* %2922)
  %2923 = load i256, i256* %2922, align 4
  %2924 = sub i256 %2920, %2923, !pc !122, !intsan !8
  br label %Exit, !EVMBB !4

.2347:                                            ; preds = %547, %JumpTable
  %2925 = load i64, i64* %remaing_gas, align 4
  %2926 = icmp ugt i64 96, %2925
  br i1 %2926, label %Abort, label %2927

2927:                                             ; preds = %.2347
  %2928 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2929 = xor i32 %2928, 1380
  %2930 = urem i32 %2929, 4096
  %2931 = getelementptr i8, i8 addrspace(1)* %4, i32 %2930
  %2932 = load i8, i8 addrspace(1)* %2931, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2931, align 1, !nosanitize !3
  store i32 690, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2933 = sub i64 %2925, 96
  store i64 %2933, i64* %remaing_gas, align 4
  %2934 = load i256, i256* %1, align 4
  %2935 = icmp eq i256 %2934, 0
  %2936 = trunc i256 2359 to i64
  %jump.check125 = icmp ne i1 %2935, false
  %2937 = load i64, i64* %STACK_DEP_PTR, align 4
  %2938 = add i64 %2937, 1
  store i64 %2938, i64* %STACK_DEP_PTR, align 4
  %2939 = load i64, i64* %STACK_DEP_PTR, align 4
  %2940 = getelementptr i256, i256* %STACK, i64 %2939
  store i256 %2934, i256* %2940, align 4
  br i1 %jump.check125, label %.2359, label %.2355, !EVMBB !4

.2355:                                            ; preds = %2927
  %2941 = load i64, i64* %remaing_gas, align 4
  %2942 = icmp ugt i64 40, %2941
  br i1 %2942, label %Abort, label %2943

2943:                                             ; preds = %.2355
  %2944 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2945 = xor i32 %2944, 3525
  %2946 = urem i32 %2945, 4096
  %2947 = getelementptr i8, i8 addrspace(1)* %4, i32 %2946
  %2948 = load i8, i8 addrspace(1)* %2947, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2947, align 1, !nosanitize !3
  store i32 1762, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2949 = sub i64 %2941, 40
  store i64 %2949, i64* %remaing_gas, align 4
  %2950 = load i64, i64* %STACK_DEP_PTR, align 4
  %2951 = sub i64 %2950, 0
  store i64 %2951, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2359:                                            ; preds = %2927, %JumpTable
  %2952 = load i64, i64* %remaing_gas, align 4
  %2953 = icmp ugt i64 120, %2952
  br i1 %2953, label %Abort, label %2954

2954:                                             ; preds = %.2359
  %2955 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2956 = xor i32 %2955, 2836
  %2957 = urem i32 %2956, 4096
  %2958 = getelementptr i8, i8 addrspace(1)* %4, i32 %2957
  %2959 = load i8, i8 addrspace(1)* %2958, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2958, align 1, !nosanitize !3
  store i32 1418, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2960 = sub i64 %2952, 120
  store i64 %2960, i64* %remaing_gas, align 4
  %2961 = load i64, i64* %STACK_DEP_PTR, align 4
  %2962 = getelementptr i256, i256* %STACK, i64 %2961
  %2963 = load i256, i256* %2962, align 4
  %2964 = load i64, i64* %STACK_DEP_PTR, align 4
  %2965 = sub i64 %2964, 1
  store i64 %2965, i64* %STACK_DEP_PTR, align 4
  %2966 = trunc i256 8890 to i64
  %2967 = load i64, i64* %STACK_DEP_PTR, align 4
  %2968 = add i64 %2967, 1
  store i64 %2968, i64* %STACK_DEP_PTR, align 4
  %2969 = load i64, i64* %STACK_DEP_PTR, align 4
  %2970 = getelementptr i256, i256* %STACK, i64 %2969
  store i256 2368, i256* %2970, align 4
  br label %.8890, !EVMBB !4

.2368:                                            ; preds = %JumpTable
  %2971 = load i64, i64* %remaing_gas, align 4
  %2972 = icmp ugt i64 184, %2971
  br i1 %2972, label %Abort, label %2973

2973:                                             ; preds = %.2368
  %2974 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2975 = xor i32 %2974, 2931
  %2976 = urem i32 %2975, 4096
  %2977 = getelementptr i8, i8 addrspace(1)* %4, i32 %2976
  %2978 = load i8, i8 addrspace(1)* %2977, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %2977, align 1, !nosanitize !3
  store i32 1465, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %2979 = sub i64 %2971, 184
  store i64 %2979, i64* %remaing_gas, align 4
  %2980 = load i64, i64* %STACK_DEP_PTR, align 4
  %2981 = getelementptr i256, i256* %STACK, i64 %2980
  %2982 = load i256, i256* %2981, align 4
  %2983 = load i64, i64* %STACK_DEP_PTR, align 4
  %2984 = sub i64 %2983, 1
  store i64 %2984, i64* %STACK_DEP_PTR, align 4
  %2985 = trunc i256 64 to i64
  %2986 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2985, i256* %2986)
  %2987 = load i256, i256* %2986, align 4
  %2988 = trunc i256 %2987 to i64
  %2989 = alloca i256, align 8
  store i256 %2982, i256* %2989, align 4
  %2990 = bitcast i256* %2989 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %2988, i8* %2990, i64 32)
  %2991 = add i256 32, %2987, !pc !123, !intsan !10
  %2992 = trunc i256 64 to i64
  %2993 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %2992, i256* %2993)
  %2994 = load i256, i256* %2993, align 4
  %2995 = sub i256 %2991, %2994, !pc !124, !intsan !8
  br label %Exit, !EVMBB !4

.2390:                                            ; preds = %564, %JumpTable
  %2996 = load i64, i64* %remaing_gas, align 4
  %2997 = icmp ugt i64 96, %2996
  br i1 %2997, label %Abort, label %2998

2998:                                             ; preds = %.2390
  %2999 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3000 = xor i32 %2999, 3674
  %3001 = urem i32 %3000, 4096
  %3002 = getelementptr i8, i8 addrspace(1)* %4, i32 %3001
  %3003 = load i8, i8 addrspace(1)* %3002, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3002, align 1, !nosanitize !3
  store i32 1837, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3004 = sub i64 %2996, 96
  store i64 %3004, i64* %remaing_gas, align 4
  %3005 = load i256, i256* %1, align 4
  %3006 = icmp eq i256 %3005, 0
  %3007 = trunc i256 2402 to i64
  %jump.check130 = icmp ne i1 %3006, false
  %3008 = load i64, i64* %STACK_DEP_PTR, align 4
  %3009 = add i64 %3008, 1
  store i64 %3009, i64* %STACK_DEP_PTR, align 4
  %3010 = load i64, i64* %STACK_DEP_PTR, align 4
  %3011 = getelementptr i256, i256* %STACK, i64 %3010
  store i256 %3005, i256* %3011, align 4
  br i1 %jump.check130, label %.2402, label %.2398, !EVMBB !4

.2398:                                            ; preds = %2998
  %3012 = load i64, i64* %remaing_gas, align 4
  %3013 = icmp ugt i64 40, %3012
  br i1 %3013, label %Abort, label %3014

3014:                                             ; preds = %.2398
  %3015 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3016 = xor i32 %3015, 709
  %3017 = urem i32 %3016, 4096
  %3018 = getelementptr i8, i8 addrspace(1)* %4, i32 %3017
  %3019 = load i8, i8 addrspace(1)* %3018, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3018, align 1, !nosanitize !3
  store i32 354, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3020 = sub i64 %3012, 40
  store i64 %3020, i64* %remaing_gas, align 4
  %3021 = load i64, i64* %STACK_DEP_PTR, align 4
  %3022 = sub i64 %3021, 0
  store i64 %3022, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2402:                                            ; preds = %2998, %JumpTable
  %3023 = load i64, i64* %remaing_gas, align 4
  %3024 = icmp ugt i64 248, %3023
  br i1 %3024, label %Abort, label %3025

3025:                                             ; preds = %.2402
  %3026 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3027 = xor i32 %3026, 350
  %3028 = urem i32 %3027, 4096
  %3029 = getelementptr i8, i8 addrspace(1)* %4, i32 %3028
  %3030 = load i8, i8 addrspace(1)* %3029, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3029, align 1, !nosanitize !3
  store i32 175, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3031 = sub i64 %3023, 248
  store i64 %3031, i64* %remaing_gas, align 4
  %3032 = load i64, i64* %STACK_DEP_PTR, align 4
  %3033 = getelementptr i256, i256* %STACK, i64 %3032
  %3034 = load i256, i256* %3033, align 4
  %3035 = load i64, i64* %STACK_DEP_PTR, align 4
  %3036 = sub i64 %3035, 1
  store i64 %3036, i64* %STACK_DEP_PTR, align 4
  %3037 = zext i32 %3 to i256
  %3038 = sub i256 %3037, 4, !pc !125, !intsan !8
  %3039 = add i256 4, %3038, !pc !126, !intsan !10
  %3040 = trunc i256 4 to i64
  %3041 = alloca i256, align 8
  %3042 = bitcast i256* %3041 to i8*
  call void @__device_calldataload(i8* %3042, i8* %2, i64 %3040)
  %3043 = load i256, i256* %3041, align 4
  %3044 = and i256 1461501637330902918203684832716283019655932542975, %3043
  %3045 = add i256 32, 4, !pc !127, !intsan !10
  %3046 = trunc i256 9337 to i64
  %3047 = load i64, i64* %STACK_DEP_PTR, align 4
  %3048 = add i64 %3047, 1
  store i64 %3048, i64* %STACK_DEP_PTR, align 4
  %3049 = load i64, i64* %STACK_DEP_PTR, align 4
  %3050 = getelementptr i256, i256* %STACK, i64 %3049
  store i256 2455, i256* %3050, align 4
  %3051 = load i64, i64* %STACK_DEP_PTR, align 4
  %3052 = add i64 %3051, 1
  store i64 %3052, i64* %STACK_DEP_PTR, align 4
  %3053 = load i64, i64* %STACK_DEP_PTR, align 4
  %3054 = getelementptr i256, i256* %STACK, i64 %3053
  store i256 %3044, i256* %3054, align 4
  br label %.9337, !EVMBB !4

.2455:                                            ; preds = %JumpTable
  %3055 = load i64, i64* %remaing_gas, align 4
  %3056 = icmp ugt i64 16, %3055
  br i1 %3056, label %Abort, label %3057

3057:                                             ; preds = %.2455
  %3058 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3059 = xor i32 %3058, 843
  %3060 = urem i32 %3059, 4096
  %3061 = getelementptr i8, i8 addrspace(1)* %4, i32 %3060
  %3062 = load i8, i8 addrspace(1)* %3061, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3061, align 1, !nosanitize !3
  store i32 421, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3063 = sub i64 %3055, 16
  store i64 %3063, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2457:                                            ; preds = %581, %JumpTable
  %3064 = load i64, i64* %remaing_gas, align 4
  %3065 = icmp ugt i64 96, %3064
  br i1 %3065, label %Abort, label %3066

3066:                                             ; preds = %.2457
  %3067 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3068 = xor i32 %3067, 889
  %3069 = urem i32 %3068, 4096
  %3070 = getelementptr i8, i8 addrspace(1)* %4, i32 %3069
  %3071 = load i8, i8 addrspace(1)* %3070, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3070, align 1, !nosanitize !3
  store i32 444, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3072 = sub i64 %3064, 96
  store i64 %3072, i64* %remaing_gas, align 4
  %3073 = load i256, i256* %1, align 4
  %3074 = icmp eq i256 %3073, 0
  %3075 = trunc i256 2469 to i64
  %jump.check135 = icmp ne i1 %3074, false
  %3076 = load i64, i64* %STACK_DEP_PTR, align 4
  %3077 = add i64 %3076, 1
  store i64 %3077, i64* %STACK_DEP_PTR, align 4
  %3078 = load i64, i64* %STACK_DEP_PTR, align 4
  %3079 = getelementptr i256, i256* %STACK, i64 %3078
  store i256 %3073, i256* %3079, align 4
  br i1 %jump.check135, label %.2469, label %.2465, !EVMBB !4

.2465:                                            ; preds = %3066
  %3080 = load i64, i64* %remaing_gas, align 4
  %3081 = icmp ugt i64 40, %3080
  br i1 %3081, label %Abort, label %3082

3082:                                             ; preds = %.2465
  %3083 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3084 = xor i32 %3083, 3939
  %3085 = urem i32 %3084, 4096
  %3086 = getelementptr i8, i8 addrspace(1)* %4, i32 %3085
  %3087 = load i8, i8 addrspace(1)* %3086, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3086, align 1, !nosanitize !3
  store i32 1969, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3088 = sub i64 %3080, 40
  store i64 %3088, i64* %remaing_gas, align 4
  %3089 = load i64, i64* %STACK_DEP_PTR, align 4
  %3090 = sub i64 %3089, 0
  store i64 %3090, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2469:                                            ; preds = %3066, %JumpTable
  %3091 = load i64, i64* %remaing_gas, align 4
  %3092 = icmp ugt i64 120, %3091
  br i1 %3092, label %Abort, label %3093

3093:                                             ; preds = %.2469
  %3094 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3095 = xor i32 %3094, 315
  %3096 = urem i32 %3095, 4096
  %3097 = getelementptr i8, i8 addrspace(1)* %4, i32 %3096
  %3098 = load i8, i8 addrspace(1)* %3097, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3097, align 1, !nosanitize !3
  store i32 157, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3099 = sub i64 %3091, 120
  store i64 %3099, i64* %remaing_gas, align 4
  %3100 = load i64, i64* %STACK_DEP_PTR, align 4
  %3101 = getelementptr i256, i256* %STACK, i64 %3100
  %3102 = load i256, i256* %3101, align 4
  %3103 = load i64, i64* %STACK_DEP_PTR, align 4
  %3104 = sub i64 %3103, 1
  store i64 %3104, i64* %STACK_DEP_PTR, align 4
  %3105 = trunc i256 9740 to i64
  %3106 = load i64, i64* %STACK_DEP_PTR, align 4
  %3107 = add i64 %3106, 1
  store i64 %3107, i64* %STACK_DEP_PTR, align 4
  %3108 = load i64, i64* %STACK_DEP_PTR, align 4
  %3109 = getelementptr i256, i256* %STACK, i64 %3108
  store i256 2478, i256* %3109, align 4
  br label %.9740, !EVMBB !4

.2478:                                            ; preds = %JumpTable
  %3110 = load i64, i64* %remaing_gas, align 4
  %3111 = icmp ugt i64 200, %3110
  br i1 %3111, label %Abort, label %3112

3112:                                             ; preds = %.2478
  %3113 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3114 = xor i32 %3113, 3952
  %3115 = urem i32 %3114, 4096
  %3116 = getelementptr i8, i8 addrspace(1)* %4, i32 %3115
  %3117 = load i8, i8 addrspace(1)* %3116, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3116, align 1, !nosanitize !3
  store i32 1976, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3118 = sub i64 %3110, 200
  store i64 %3118, i64* %remaing_gas, align 4
  %3119 = load i64, i64* %STACK_DEP_PTR, align 4
  %3120 = getelementptr i256, i256* %STACK, i64 %3119
  %3121 = load i256, i256* %3120, align 4
  %3122 = load i64, i64* %STACK_DEP_PTR, align 4
  %3123 = sub i64 %3122, 1
  store i64 %3123, i64* %STACK_DEP_PTR, align 4
  %3124 = trunc i256 64 to i64
  %3125 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3124, i256* %3125)
  %3126 = load i256, i256* %3125, align 4
  %3127 = and i256 1461501637330902918203684832716283019655932542975, %3121
  %3128 = and i256 1461501637330902918203684832716283019655932542975, %3127
  %3129 = trunc i256 %3126 to i64
  %3130 = alloca i256, align 8
  store i256 %3128, i256* %3130, align 4
  %3131 = bitcast i256* %3130 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3129, i8* %3131, i64 32)
  %3132 = add i256 32, %3126, !pc !128, !intsan !10
  %3133 = trunc i256 64 to i64
  %3134 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3133, i256* %3134)
  %3135 = load i256, i256* %3134, align 4
  %3136 = sub i256 %3132, %3135, !pc !129, !intsan !8
  br label %Exit, !EVMBB !4

.2544:                                            ; preds = %598, %JumpTable
  %3137 = load i64, i64* %remaing_gas, align 4
  %3138 = icmp ugt i64 72, %3137
  br i1 %3138, label %Abort, label %3139

3139:                                             ; preds = %.2544
  %3140 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3141 = xor i32 %3140, 3684
  %3142 = urem i32 %3141, 4096
  %3143 = getelementptr i8, i8 addrspace(1)* %4, i32 %3142
  %3144 = load i8, i8 addrspace(1)* %3143, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3143, align 1, !nosanitize !3
  store i32 1842, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3145 = sub i64 %3137, 72
  store i64 %3145, i64* %remaing_gas, align 4
  %3146 = trunc i256 9778 to i64
  %3147 = load i64, i64* %STACK_DEP_PTR, align 4
  %3148 = add i64 %3147, 1
  store i64 %3148, i64* %STACK_DEP_PTR, align 4
  %3149 = load i64, i64* %STACK_DEP_PTR, align 4
  %3150 = getelementptr i256, i256* %STACK, i64 %3149
  store i256 2552, i256* %3150, align 4
  br label %.9778, !EVMBB !4

.2552:                                            ; preds = %JumpTable
  %3151 = load i64, i64* %remaing_gas, align 4
  %3152 = icmp ugt i64 16, %3151
  br i1 %3152, label %Abort, label %3153

3153:                                             ; preds = %.2552
  %3154 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3155 = xor i32 %3154, 1572
  %3156 = urem i32 %3155, 4096
  %3157 = getelementptr i8, i8 addrspace(1)* %4, i32 %3156
  %3158 = load i8, i8 addrspace(1)* %3157, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3157, align 1, !nosanitize !3
  store i32 786, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3159 = sub i64 %3151, 16
  store i64 %3159, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2554:                                            ; preds = %615, %JumpTable
  %3160 = load i64, i64* %remaing_gas, align 4
  %3161 = icmp ugt i64 96, %3160
  br i1 %3161, label %Abort, label %3162

3162:                                             ; preds = %.2554
  %3163 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3164 = xor i32 %3163, 2577
  %3165 = urem i32 %3164, 4096
  %3166 = getelementptr i8, i8 addrspace(1)* %4, i32 %3165
  %3167 = load i8, i8 addrspace(1)* %3166, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3166, align 1, !nosanitize !3
  store i32 1288, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3168 = sub i64 %3160, 96
  store i64 %3168, i64* %remaing_gas, align 4
  %3169 = load i256, i256* %1, align 4
  %3170 = icmp eq i256 %3169, 0
  %3171 = trunc i256 2566 to i64
  %jump.check141 = icmp ne i1 %3170, false
  %3172 = load i64, i64* %STACK_DEP_PTR, align 4
  %3173 = add i64 %3172, 1
  store i64 %3173, i64* %STACK_DEP_PTR, align 4
  %3174 = load i64, i64* %STACK_DEP_PTR, align 4
  %3175 = getelementptr i256, i256* %STACK, i64 %3174
  store i256 %3169, i256* %3175, align 4
  br i1 %jump.check141, label %.2566, label %.2562, !EVMBB !4

.2562:                                            ; preds = %3162
  %3176 = load i64, i64* %remaing_gas, align 4
  %3177 = icmp ugt i64 40, %3176
  br i1 %3177, label %Abort, label %3178

3178:                                             ; preds = %.2562
  %3179 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3180 = xor i32 %3179, 158
  %3181 = urem i32 %3180, 4096
  %3182 = getelementptr i8, i8 addrspace(1)* %4, i32 %3181
  %3183 = load i8, i8 addrspace(1)* %3182, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3182, align 1, !nosanitize !3
  store i32 79, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3184 = sub i64 %3176, 40
  store i64 %3184, i64* %remaing_gas, align 4
  %3185 = load i64, i64* %STACK_DEP_PTR, align 4
  %3186 = sub i64 %3185, 0
  store i64 %3186, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2566:                                            ; preds = %3162, %JumpTable
  %3187 = load i64, i64* %remaing_gas, align 4
  %3188 = icmp ugt i64 120, %3187
  br i1 %3188, label %Abort, label %3189

3189:                                             ; preds = %.2566
  %3190 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3191 = xor i32 %3190, 265
  %3192 = urem i32 %3191, 4096
  %3193 = getelementptr i8, i8 addrspace(1)* %4, i32 %3192
  %3194 = load i8, i8 addrspace(1)* %3193, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3193, align 1, !nosanitize !3
  store i32 132, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3195 = sub i64 %3187, 120
  store i64 %3195, i64* %remaing_gas, align 4
  %3196 = load i64, i64* %STACK_DEP_PTR, align 4
  %3197 = getelementptr i256, i256* %STACK, i64 %3196
  %3198 = load i256, i256* %3197, align 4
  %3199 = load i64, i64* %STACK_DEP_PTR, align 4
  %3200 = sub i64 %3199, 1
  store i64 %3200, i64* %STACK_DEP_PTR, align 4
  %3201 = trunc i256 10020 to i64
  %3202 = load i64, i64* %STACK_DEP_PTR, align 4
  %3203 = add i64 %3202, 1
  store i64 %3203, i64* %STACK_DEP_PTR, align 4
  %3204 = load i64, i64* %STACK_DEP_PTR, align 4
  %3205 = getelementptr i256, i256* %STACK, i64 %3204
  store i256 2575, i256* %3205, align 4
  br label %.10020, !EVMBB !4

.2575:                                            ; preds = %JumpTable
  %3206 = load i64, i64* %remaing_gas, align 4
  %3207 = icmp ugt i64 16, %3206
  br i1 %3207, label %Abort, label %3208

3208:                                             ; preds = %.2575
  %3209 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3210 = xor i32 %3209, 2524
  %3211 = urem i32 %3210, 4096
  %3212 = getelementptr i8, i8 addrspace(1)* %4, i32 %3211
  %3213 = load i8, i8 addrspace(1)* %3212, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3212, align 1, !nosanitize !3
  store i32 1262, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3214 = sub i64 %3206, 16
  store i64 %3214, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2577:                                            ; preds = %632, %JumpTable
  %3215 = load i64, i64* %remaing_gas, align 4
  %3216 = icmp ugt i64 96, %3215
  br i1 %3216, label %Abort, label %3217

3217:                                             ; preds = %.2577
  %3218 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3219 = xor i32 %3218, 170
  %3220 = urem i32 %3219, 4096
  %3221 = getelementptr i8, i8 addrspace(1)* %4, i32 %3220
  %3222 = load i8, i8 addrspace(1)* %3221, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3221, align 1, !nosanitize !3
  store i32 85, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3223 = sub i64 %3215, 96
  store i64 %3223, i64* %remaing_gas, align 4
  %3224 = load i256, i256* %1, align 4
  %3225 = icmp eq i256 %3224, 0
  %3226 = trunc i256 2589 to i64
  %jump.check146 = icmp ne i1 %3225, false
  %3227 = load i64, i64* %STACK_DEP_PTR, align 4
  %3228 = add i64 %3227, 1
  store i64 %3228, i64* %STACK_DEP_PTR, align 4
  %3229 = load i64, i64* %STACK_DEP_PTR, align 4
  %3230 = getelementptr i256, i256* %STACK, i64 %3229
  store i256 %3224, i256* %3230, align 4
  br i1 %jump.check146, label %.2589, label %.2585, !EVMBB !4

.2585:                                            ; preds = %3217
  %3231 = load i64, i64* %remaing_gas, align 4
  %3232 = icmp ugt i64 40, %3231
  br i1 %3232, label %Abort, label %3233

3233:                                             ; preds = %.2585
  %3234 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3235 = xor i32 %3234, 3028
  %3236 = urem i32 %3235, 4096
  %3237 = getelementptr i8, i8 addrspace(1)* %4, i32 %3236
  %3238 = load i8, i8 addrspace(1)* %3237, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3237, align 1, !nosanitize !3
  store i32 1514, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3239 = sub i64 %3231, 40
  store i64 %3239, i64* %remaing_gas, align 4
  %3240 = load i64, i64* %STACK_DEP_PTR, align 4
  %3241 = sub i64 %3240, 0
  store i64 %3241, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2589:                                            ; preds = %3217, %JumpTable
  %3242 = load i64, i64* %remaing_gas, align 4
  %3243 = icmp ugt i64 256, %3242
  br i1 %3243, label %Abort, label %3244

3244:                                             ; preds = %.2589
  %3245 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3246 = xor i32 %3245, 2476
  %3247 = urem i32 %3246, 4096
  %3248 = getelementptr i8, i8 addrspace(1)* %4, i32 %3247
  %3249 = load i8, i8 addrspace(1)* %3248, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3248, align 1, !nosanitize !3
  store i32 1238, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3250 = sub i64 %3242, 256
  store i64 %3250, i64* %remaing_gas, align 4
  %3251 = load i64, i64* %STACK_DEP_PTR, align 4
  %3252 = getelementptr i256, i256* %STACK, i64 %3251
  %3253 = load i256, i256* %3252, align 4
  %3254 = load i64, i64* %STACK_DEP_PTR, align 4
  %3255 = sub i64 %3254, 1
  store i64 %3255, i64* %STACK_DEP_PTR, align 4
  %3256 = zext i32 %3 to i256
  %3257 = sub i256 %3256, 4, !pc !130, !intsan !8
  %3258 = add i256 4, %3257, !pc !131, !intsan !10
  %3259 = trunc i256 4 to i64
  %3260 = alloca i256, align 8
  %3261 = bitcast i256* %3260 to i8*
  call void @__device_calldataload(i8* %3261, i8* %2, i64 %3259)
  %3262 = load i256, i256* %3260, align 4
  %3263 = xor i256 0, -1
  %3264 = and i256 %3263, %3262
  %3265 = add i256 32, 4, !pc !132, !intsan !10
  %3266 = trunc i256 10185 to i64
  %3267 = load i64, i64* %STACK_DEP_PTR, align 4
  %3268 = add i64 %3267, 1
  store i64 %3268, i64* %STACK_DEP_PTR, align 4
  %3269 = load i64, i64* %STACK_DEP_PTR, align 4
  %3270 = getelementptr i256, i256* %STACK, i64 %3269
  store i256 2624, i256* %3270, align 4
  %3271 = load i64, i64* %STACK_DEP_PTR, align 4
  %3272 = add i64 %3271, 1
  store i64 %3272, i64* %STACK_DEP_PTR, align 4
  %3273 = load i64, i64* %STACK_DEP_PTR, align 4
  %3274 = getelementptr i256, i256* %STACK, i64 %3273
  store i256 %3264, i256* %3274, align 4
  br label %.10185, !EVMBB !4

.2624:                                            ; preds = %JumpTable
  %3275 = load i64, i64* %remaing_gas, align 4
  %3276 = icmp ugt i64 392, %3275
  br i1 %3276, label %Abort, label %3277

3277:                                             ; preds = %.2624
  %3278 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3279 = xor i32 %3278, 498
  %3280 = urem i32 %3279, 4096
  %3281 = getelementptr i8, i8 addrspace(1)* %4, i32 %3280
  %3282 = load i8, i8 addrspace(1)* %3281, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3281, align 1, !nosanitize !3
  store i32 249, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3283 = sub i64 %3275, 392
  store i64 %3283, i64* %remaing_gas, align 4
  %3284 = load i64, i64* %STACK_DEP_PTR, align 4
  %3285 = getelementptr i256, i256* %STACK, i64 %3284
  %3286 = load i256, i256* %3285, align 4
  %3287 = load i64, i64* %STACK_DEP_PTR, align 4
  %3288 = sub i64 %3287, 1
  store i64 %3288, i64* %STACK_DEP_PTR, align 4
  %3289 = load i64, i64* %STACK_DEP_PTR, align 4
  %3290 = getelementptr i256, i256* %STACK, i64 %3289
  %3291 = load i256, i256* %3290, align 4
  %3292 = load i64, i64* %STACK_DEP_PTR, align 4
  %3293 = sub i64 %3292, 1
  store i64 %3293, i64* %STACK_DEP_PTR, align 4
  %3294 = load i64, i64* %STACK_DEP_PTR, align 4
  %3295 = getelementptr i256, i256* %STACK, i64 %3294
  %3296 = load i256, i256* %3295, align 4
  %3297 = load i64, i64* %STACK_DEP_PTR, align 4
  %3298 = sub i64 %3297, 1
  store i64 %3298, i64* %STACK_DEP_PTR, align 4
  %3299 = trunc i256 64 to i64
  %3300 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3299, i256* %3300)
  %3301 = load i256, i256* %3300, align 4
  %3302 = and i256 1461501637330902918203684832716283019655932542975, %3296
  %3303 = and i256 1461501637330902918203684832716283019655932542975, %3302
  %3304 = trunc i256 %3301 to i64
  %3305 = alloca i256, align 8
  store i256 %3303, i256* %3305, align 4
  %3306 = bitcast i256* %3305 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3304, i8* %3306, i64 32)
  %3307 = add i256 32, %3301, !pc !133, !intsan !10
  %3308 = trunc i256 %3307 to i64
  %3309 = alloca i256, align 8
  store i256 %3291, i256* %3309, align 4
  %3310 = bitcast i256* %3309 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3308, i8* %3310, i64 32)
  %3311 = add i256 32, %3307, !pc !134, !intsan !10
  %3312 = trunc i256 %3311 to i64
  %3313 = alloca i256, align 8
  store i256 %3286, i256* %3313, align 4
  %3314 = bitcast i256* %3313 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3312, i8* %3314, i64 32)
  %3315 = add i256 32, %3311, !pc !135, !intsan !10
  %3316 = trunc i256 64 to i64
  %3317 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3316, i256* %3317)
  %3318 = load i256, i256* %3317, align 4
  %3319 = sub i256 %3315, %3318, !pc !136, !intsan !8
  br label %Exit, !EVMBB !4

.2704:                                            ; preds = %649, %JumpTable
  %3320 = load i64, i64* %remaing_gas, align 4
  %3321 = icmp ugt i64 96, %3320
  br i1 %3321, label %Abort, label %3322

3322:                                             ; preds = %.2704
  %3323 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3324 = xor i32 %3323, 3611
  %3325 = urem i32 %3324, 4096
  %3326 = getelementptr i8, i8 addrspace(1)* %4, i32 %3325
  %3327 = load i8, i8 addrspace(1)* %3326, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3326, align 1, !nosanitize !3
  store i32 1805, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3328 = sub i64 %3320, 96
  store i64 %3328, i64* %remaing_gas, align 4
  %3329 = load i256, i256* %1, align 4
  %3330 = icmp eq i256 %3329, 0
  %3331 = trunc i256 2716 to i64
  %jump.check150 = icmp ne i1 %3330, false
  %3332 = load i64, i64* %STACK_DEP_PTR, align 4
  %3333 = add i64 %3332, 1
  store i64 %3333, i64* %STACK_DEP_PTR, align 4
  %3334 = load i64, i64* %STACK_DEP_PTR, align 4
  %3335 = getelementptr i256, i256* %STACK, i64 %3334
  store i256 %3329, i256* %3335, align 4
  br i1 %jump.check150, label %.2716, label %.2712, !EVMBB !4

.2712:                                            ; preds = %3322
  %3336 = load i64, i64* %remaing_gas, align 4
  %3337 = icmp ugt i64 40, %3336
  br i1 %3337, label %Abort, label %3338

3338:                                             ; preds = %.2712
  %3339 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3340 = xor i32 %3339, 272
  %3341 = urem i32 %3340, 4096
  %3342 = getelementptr i8, i8 addrspace(1)* %4, i32 %3341
  %3343 = load i8, i8 addrspace(1)* %3342, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3342, align 1, !nosanitize !3
  store i32 136, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3344 = sub i64 %3336, 40
  store i64 %3344, i64* %remaing_gas, align 4
  %3345 = load i64, i64* %STACK_DEP_PTR, align 4
  %3346 = sub i64 %3345, 0
  store i64 %3346, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2716:                                            ; preds = %3322, %JumpTable
  %3347 = load i64, i64* %remaing_gas, align 4
  %3348 = icmp ugt i64 120, %3347
  br i1 %3348, label %Abort, label %3349

3349:                                             ; preds = %.2716
  %3350 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3351 = xor i32 %3350, 2223
  %3352 = urem i32 %3351, 4096
  %3353 = getelementptr i8, i8 addrspace(1)* %4, i32 %3352
  %3354 = load i8, i8 addrspace(1)* %3353, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3353, align 1, !nosanitize !3
  store i32 1111, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3355 = sub i64 %3347, 120
  store i64 %3355, i64* %remaing_gas, align 4
  %3356 = load i64, i64* %STACK_DEP_PTR, align 4
  %3357 = getelementptr i256, i256* %STACK, i64 %3356
  %3358 = load i256, i256* %3357, align 4
  %3359 = load i64, i64* %STACK_DEP_PTR, align 4
  %3360 = sub i64 %3359, 1
  store i64 %3360, i64* %STACK_DEP_PTR, align 4
  %3361 = trunc i256 10259 to i64
  %3362 = load i64, i64* %STACK_DEP_PTR, align 4
  %3363 = add i64 %3362, 1
  store i64 %3363, i64* %STACK_DEP_PTR, align 4
  %3364 = load i64, i64* %STACK_DEP_PTR, align 4
  %3365 = getelementptr i256, i256* %STACK, i64 %3364
  store i256 2725, i256* %3365, align 4
  br label %.10259, !EVMBB !4

.2725:                                            ; preds = %JumpTable
  %3366 = load i64, i64* %remaing_gas, align 4
  %3367 = icmp ugt i64 184, %3366
  br i1 %3367, label %Abort, label %3368

3368:                                             ; preds = %.2725
  %3369 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3370 = xor i32 %3369, 59
  %3371 = urem i32 %3370, 4096
  %3372 = getelementptr i8, i8 addrspace(1)* %4, i32 %3371
  %3373 = load i8, i8 addrspace(1)* %3372, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3372, align 1, !nosanitize !3
  store i32 29, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3374 = sub i64 %3366, 184
  store i64 %3374, i64* %remaing_gas, align 4
  %3375 = load i64, i64* %STACK_DEP_PTR, align 4
  %3376 = getelementptr i256, i256* %STACK, i64 %3375
  %3377 = load i256, i256* %3376, align 4
  %3378 = load i64, i64* %STACK_DEP_PTR, align 4
  %3379 = sub i64 %3378, 1
  store i64 %3379, i64* %STACK_DEP_PTR, align 4
  %3380 = trunc i256 64 to i64
  %3381 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3380, i256* %3381)
  %3382 = load i256, i256* %3381, align 4
  %3383 = trunc i256 %3382 to i64
  %3384 = alloca i256, align 8
  store i256 %3377, i256* %3384, align 4
  %3385 = bitcast i256* %3384 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3383, i8* %3385, i64 32)
  %3386 = add i256 32, %3382, !pc !137, !intsan !10
  %3387 = trunc i256 64 to i64
  %3388 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3387, i256* %3388)
  %3389 = load i256, i256* %3388, align 4
  %3390 = sub i256 %3386, %3389, !pc !138, !intsan !8
  br label %Exit, !EVMBB !4

.2747:                                            ; preds = %666, %JumpTable
  %3391 = load i64, i64* %remaing_gas, align 4
  %3392 = icmp ugt i64 96, %3391
  br i1 %3392, label %Abort, label %3393

3393:                                             ; preds = %.2747
  %3394 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3395 = xor i32 %3394, 3635
  %3396 = urem i32 %3395, 4096
  %3397 = getelementptr i8, i8 addrspace(1)* %4, i32 %3396
  %3398 = load i8, i8 addrspace(1)* %3397, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3397, align 1, !nosanitize !3
  store i32 1817, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3399 = sub i64 %3391, 96
  store i64 %3399, i64* %remaing_gas, align 4
  %3400 = load i256, i256* %1, align 4
  %3401 = icmp eq i256 %3400, 0
  %3402 = trunc i256 2759 to i64
  %jump.check155 = icmp ne i1 %3401, false
  %3403 = load i64, i64* %STACK_DEP_PTR, align 4
  %3404 = add i64 %3403, 1
  store i64 %3404, i64* %STACK_DEP_PTR, align 4
  %3405 = load i64, i64* %STACK_DEP_PTR, align 4
  %3406 = getelementptr i256, i256* %STACK, i64 %3405
  store i256 %3400, i256* %3406, align 4
  br i1 %jump.check155, label %.2759, label %.2755, !EVMBB !4

.2755:                                            ; preds = %3393
  %3407 = load i64, i64* %remaing_gas, align 4
  %3408 = icmp ugt i64 40, %3407
  br i1 %3408, label %Abort, label %3409

3409:                                             ; preds = %.2755
  %3410 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3411 = xor i32 %3410, 1997
  %3412 = urem i32 %3411, 4096
  %3413 = getelementptr i8, i8 addrspace(1)* %4, i32 %3412
  %3414 = load i8, i8 addrspace(1)* %3413, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3413, align 1, !nosanitize !3
  store i32 998, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3415 = sub i64 %3407, 40
  store i64 %3415, i64* %remaing_gas, align 4
  %3416 = load i64, i64* %STACK_DEP_PTR, align 4
  %3417 = sub i64 %3416, 0
  store i64 %3417, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2759:                                            ; preds = %3393, %JumpTable
  %3418 = load i64, i64* %remaing_gas, align 4
  %3419 = icmp ugt i64 240, %3418
  br i1 %3419, label %Abort, label %3420

3420:                                             ; preds = %.2759
  %3421 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3422 = xor i32 %3421, 3811
  %3423 = urem i32 %3422, 4096
  %3424 = getelementptr i8, i8 addrspace(1)* %4, i32 %3423
  %3425 = load i8, i8 addrspace(1)* %3424, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3424, align 1, !nosanitize !3
  store i32 1905, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3426 = sub i64 %3418, 240
  store i64 %3426, i64* %remaing_gas, align 4
  %3427 = load i64, i64* %STACK_DEP_PTR, align 4
  %3428 = getelementptr i256, i256* %STACK, i64 %3427
  %3429 = load i256, i256* %3428, align 4
  %3430 = load i64, i64* %STACK_DEP_PTR, align 4
  %3431 = sub i64 %3430, 1
  store i64 %3431, i64* %STACK_DEP_PTR, align 4
  %3432 = zext i32 %3 to i256
  %3433 = sub i256 %3432, 4, !pc !139, !intsan !8
  %3434 = add i256 4, %3433, !pc !140, !intsan !10
  %3435 = trunc i256 4 to i64
  %3436 = alloca i256, align 8
  %3437 = bitcast i256* %3436 to i8*
  call void @__device_calldataload(i8* %3437, i8* %2, i64 %3435)
  %3438 = load i256, i256* %3436, align 4
  %3439 = add i256 32, 4, !pc !141, !intsan !10
  %3440 = trunc i256 10265 to i64
  %3441 = load i64, i64* %STACK_DEP_PTR, align 4
  %3442 = add i64 %3441, 1
  store i64 %3442, i64* %STACK_DEP_PTR, align 4
  %3443 = load i64, i64* %STACK_DEP_PTR, align 4
  %3444 = getelementptr i256, i256* %STACK, i64 %3443
  store i256 2790, i256* %3444, align 4
  %3445 = load i64, i64* %STACK_DEP_PTR, align 4
  %3446 = add i64 %3445, 1
  store i64 %3446, i64* %STACK_DEP_PTR, align 4
  %3447 = load i64, i64* %STACK_DEP_PTR, align 4
  %3448 = getelementptr i256, i256* %STACK, i64 %3447
  store i256 %3438, i256* %3448, align 4
  br label %.10265, !EVMBB !4

.2790:                                            ; preds = %JumpTable
  %3449 = load i64, i64* %remaing_gas, align 4
  %3450 = icmp ugt i64 16, %3449
  br i1 %3450, label %Abort, label %3451

3451:                                             ; preds = %.2790
  %3452 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3453 = xor i32 %3452, 1360
  %3454 = urem i32 %3453, 4096
  %3455 = getelementptr i8, i8 addrspace(1)* %4, i32 %3454
  %3456 = load i8, i8 addrspace(1)* %3455, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3455, align 1, !nosanitize !3
  store i32 680, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3457 = sub i64 %3449, 16
  store i64 %3457, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2792:                                            ; preds = %683, %JumpTable
  %3458 = load i64, i64* %remaing_gas, align 4
  %3459 = icmp ugt i64 96, %3458
  br i1 %3459, label %Abort, label %3460

3460:                                             ; preds = %.2792
  %3461 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3462 = xor i32 %3461, 1608
  %3463 = urem i32 %3462, 4096
  %3464 = getelementptr i8, i8 addrspace(1)* %4, i32 %3463
  %3465 = load i8, i8 addrspace(1)* %3464, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3464, align 1, !nosanitize !3
  store i32 804, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3466 = sub i64 %3458, 96
  store i64 %3466, i64* %remaing_gas, align 4
  %3467 = load i256, i256* %1, align 4
  %3468 = icmp eq i256 %3467, 0
  %3469 = trunc i256 2804 to i64
  %jump.check158 = icmp ne i1 %3468, false
  %3470 = load i64, i64* %STACK_DEP_PTR, align 4
  %3471 = add i64 %3470, 1
  store i64 %3471, i64* %STACK_DEP_PTR, align 4
  %3472 = load i64, i64* %STACK_DEP_PTR, align 4
  %3473 = getelementptr i256, i256* %STACK, i64 %3472
  store i256 %3467, i256* %3473, align 4
  br i1 %jump.check158, label %.2804, label %.2800, !EVMBB !4

.2800:                                            ; preds = %3460
  %3474 = load i64, i64* %remaing_gas, align 4
  %3475 = icmp ugt i64 40, %3474
  br i1 %3475, label %Abort, label %3476

3476:                                             ; preds = %.2800
  %3477 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3478 = xor i32 %3477, 1095
  %3479 = urem i32 %3478, 4096
  %3480 = getelementptr i8, i8 addrspace(1)* %4, i32 %3479
  %3481 = load i8, i8 addrspace(1)* %3480, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3480, align 1, !nosanitize !3
  store i32 547, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3482 = sub i64 %3474, 40
  store i64 %3482, i64* %remaing_gas, align 4
  %3483 = load i64, i64* %STACK_DEP_PTR, align 4
  %3484 = sub i64 %3483, 0
  store i64 %3484, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2804:                                            ; preds = %3460, %JumpTable
  %3485 = load i64, i64* %remaing_gas, align 4
  %3486 = icmp ugt i64 120, %3485
  br i1 %3486, label %Abort, label %3487

3487:                                             ; preds = %.2804
  %3488 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3489 = xor i32 %3488, 789
  %3490 = urem i32 %3489, 4096
  %3491 = getelementptr i8, i8 addrspace(1)* %4, i32 %3490
  %3492 = load i8, i8 addrspace(1)* %3491, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3491, align 1, !nosanitize !3
  store i32 394, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3493 = sub i64 %3485, 120
  store i64 %3493, i64* %remaing_gas, align 4
  %3494 = load i64, i64* %STACK_DEP_PTR, align 4
  %3495 = getelementptr i256, i256* %STACK, i64 %3494
  %3496 = load i256, i256* %3495, align 4
  %3497 = load i64, i64* %STACK_DEP_PTR, align 4
  %3498 = sub i64 %3497, 1
  store i64 %3498, i64* %STACK_DEP_PTR, align 4
  %3499 = trunc i256 10470 to i64
  %3500 = load i64, i64* %STACK_DEP_PTR, align 4
  %3501 = add i64 %3500, 1
  store i64 %3501, i64* %STACK_DEP_PTR, align 4
  %3502 = load i64, i64* %STACK_DEP_PTR, align 4
  %3503 = getelementptr i256, i256* %STACK, i64 %3502
  store i256 2813, i256* %3503, align 4
  br label %.10470, !EVMBB !4

.2813:                                            ; preds = %JumpTable
  %3504 = load i64, i64* %remaing_gas, align 4
  %3505 = icmp ugt i64 200, %3504
  br i1 %3505, label %Abort, label %3506

3506:                                             ; preds = %.2813
  %3507 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3508 = xor i32 %3507, 348
  %3509 = urem i32 %3508, 4096
  %3510 = getelementptr i8, i8 addrspace(1)* %4, i32 %3509
  %3511 = load i8, i8 addrspace(1)* %3510, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3510, align 1, !nosanitize !3
  store i32 174, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3512 = sub i64 %3504, 200
  store i64 %3512, i64* %remaing_gas, align 4
  %3513 = load i64, i64* %STACK_DEP_PTR, align 4
  %3514 = getelementptr i256, i256* %STACK, i64 %3513
  %3515 = load i256, i256* %3514, align 4
  %3516 = load i64, i64* %STACK_DEP_PTR, align 4
  %3517 = sub i64 %3516, 1
  store i64 %3517, i64* %STACK_DEP_PTR, align 4
  %3518 = trunc i256 64 to i64
  %3519 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3518, i256* %3519)
  %3520 = load i256, i256* %3519, align 4
  %3521 = and i256 1461501637330902918203684832716283019655932542975, %3515
  %3522 = and i256 1461501637330902918203684832716283019655932542975, %3521
  %3523 = trunc i256 %3520 to i64
  %3524 = alloca i256, align 8
  store i256 %3522, i256* %3524, align 4
  %3525 = bitcast i256* %3524 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3523, i8* %3525, i64 32)
  %3526 = add i256 32, %3520, !pc !142, !intsan !10
  %3527 = trunc i256 64 to i64
  %3528 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3527, i256* %3528)
  %3529 = load i256, i256* %3528, align 4
  %3530 = sub i256 %3526, %3529, !pc !143, !intsan !8
  br label %Exit, !EVMBB !4

.2879:                                            ; preds = %700, %JumpTable
  %3531 = load i64, i64* %remaing_gas, align 4
  %3532 = icmp ugt i64 96, %3531
  br i1 %3532, label %Abort, label %3533

3533:                                             ; preds = %.2879
  %3534 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3535 = xor i32 %3534, 4027
  %3536 = urem i32 %3535, 4096
  %3537 = getelementptr i8, i8 addrspace(1)* %4, i32 %3536
  %3538 = load i8, i8 addrspace(1)* %3537, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3537, align 1, !nosanitize !3
  store i32 2013, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3539 = sub i64 %3531, 96
  store i64 %3539, i64* %remaing_gas, align 4
  %3540 = load i256, i256* %1, align 4
  %3541 = icmp eq i256 %3540, 0
  %3542 = trunc i256 2891 to i64
  %jump.check160 = icmp ne i1 %3541, false
  %3543 = load i64, i64* %STACK_DEP_PTR, align 4
  %3544 = add i64 %3543, 1
  store i64 %3544, i64* %STACK_DEP_PTR, align 4
  %3545 = load i64, i64* %STACK_DEP_PTR, align 4
  %3546 = getelementptr i256, i256* %STACK, i64 %3545
  store i256 %3540, i256* %3546, align 4
  br i1 %jump.check160, label %.2891, label %.2887, !EVMBB !4

.2887:                                            ; preds = %3533
  %3547 = load i64, i64* %remaing_gas, align 4
  %3548 = icmp ugt i64 40, %3547
  br i1 %3548, label %Abort, label %3549

3549:                                             ; preds = %.2887
  %3550 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3551 = xor i32 %3550, 367
  %3552 = urem i32 %3551, 4096
  %3553 = getelementptr i8, i8 addrspace(1)* %4, i32 %3552
  %3554 = load i8, i8 addrspace(1)* %3553, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3553, align 1, !nosanitize !3
  store i32 183, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3555 = sub i64 %3547, 40
  store i64 %3555, i64* %remaing_gas, align 4
  %3556 = load i64, i64* %STACK_DEP_PTR, align 4
  %3557 = sub i64 %3556, 0
  store i64 %3557, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2891:                                            ; preds = %3533, %JumpTable
  %3558 = load i64, i64* %remaing_gas, align 4
  %3559 = icmp ugt i64 256, %3558
  br i1 %3559, label %Abort, label %3560

3560:                                             ; preds = %.2891
  %3561 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3562 = xor i32 %3561, 1058
  %3563 = urem i32 %3562, 4096
  %3564 = getelementptr i8, i8 addrspace(1)* %4, i32 %3563
  %3565 = load i8, i8 addrspace(1)* %3564, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3564, align 1, !nosanitize !3
  store i32 529, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3566 = sub i64 %3558, 256
  store i64 %3566, i64* %remaing_gas, align 4
  %3567 = load i64, i64* %STACK_DEP_PTR, align 4
  %3568 = getelementptr i256, i256* %STACK, i64 %3567
  %3569 = load i256, i256* %3568, align 4
  %3570 = load i64, i64* %STACK_DEP_PTR, align 4
  %3571 = sub i64 %3570, 1
  store i64 %3571, i64* %STACK_DEP_PTR, align 4
  %3572 = zext i32 %3 to i256
  %3573 = sub i256 %3572, 4, !pc !144, !intsan !8
  %3574 = add i256 4, %3573, !pc !145, !intsan !10
  %3575 = trunc i256 4 to i64
  %3576 = alloca i256, align 8
  %3577 = bitcast i256* %3576 to i8*
  call void @__device_calldataload(i8* %3577, i8* %2, i64 %3575)
  %3578 = load i256, i256* %3576, align 4
  %3579 = xor i256 0, -1
  %3580 = and i256 %3579, %3578
  %3581 = add i256 32, 4, !pc !146, !intsan !10
  %3582 = trunc i256 10508 to i64
  %3583 = load i64, i64* %STACK_DEP_PTR, align 4
  %3584 = add i64 %3583, 1
  store i64 %3584, i64* %STACK_DEP_PTR, align 4
  %3585 = load i64, i64* %STACK_DEP_PTR, align 4
  %3586 = getelementptr i256, i256* %STACK, i64 %3585
  store i256 2926, i256* %3586, align 4
  %3587 = load i64, i64* %STACK_DEP_PTR, align 4
  %3588 = add i64 %3587, 1
  store i64 %3588, i64* %STACK_DEP_PTR, align 4
  %3589 = load i64, i64* %STACK_DEP_PTR, align 4
  %3590 = getelementptr i256, i256* %STACK, i64 %3589
  store i256 %3580, i256* %3590, align 4
  br label %.10508, !EVMBB !4

.2926:                                            ; preds = %JumpTable
  %3591 = load i64, i64* %remaing_gas, align 4
  %3592 = icmp ugt i64 16, %3591
  br i1 %3592, label %Abort, label %3593

3593:                                             ; preds = %.2926
  %3594 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3595 = xor i32 %3594, 281
  %3596 = urem i32 %3595, 4096
  %3597 = getelementptr i8, i8 addrspace(1)* %4, i32 %3596
  %3598 = load i8, i8 addrspace(1)* %3597, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3597, align 1, !nosanitize !3
  store i32 140, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3599 = sub i64 %3591, 16
  store i64 %3599, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2928:                                            ; preds = %717, %JumpTable
  %3600 = load i64, i64* %remaing_gas, align 4
  %3601 = icmp ugt i64 96, %3600
  br i1 %3601, label %Abort, label %3602

3602:                                             ; preds = %.2928
  %3603 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3604 = xor i32 %3603, 1210
  %3605 = urem i32 %3604, 4096
  %3606 = getelementptr i8, i8 addrspace(1)* %4, i32 %3605
  %3607 = load i8, i8 addrspace(1)* %3606, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3606, align 1, !nosanitize !3
  store i32 605, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3608 = sub i64 %3600, 96
  store i64 %3608, i64* %remaing_gas, align 4
  %3609 = load i256, i256* %1, align 4
  %3610 = icmp eq i256 %3609, 0
  %3611 = trunc i256 2940 to i64
  %jump.check163 = icmp ne i1 %3610, false
  %3612 = load i64, i64* %STACK_DEP_PTR, align 4
  %3613 = add i64 %3612, 1
  store i64 %3613, i64* %STACK_DEP_PTR, align 4
  %3614 = load i64, i64* %STACK_DEP_PTR, align 4
  %3615 = getelementptr i256, i256* %STACK, i64 %3614
  store i256 %3609, i256* %3615, align 4
  br i1 %jump.check163, label %.2940, label %.2936, !EVMBB !4

.2936:                                            ; preds = %3602
  %3616 = load i64, i64* %remaing_gas, align 4
  %3617 = icmp ugt i64 40, %3616
  br i1 %3617, label %Abort, label %3618

3618:                                             ; preds = %.2936
  %3619 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3620 = xor i32 %3619, 1947
  %3621 = urem i32 %3620, 4096
  %3622 = getelementptr i8, i8 addrspace(1)* %4, i32 %3621
  %3623 = load i8, i8 addrspace(1)* %3622, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3622, align 1, !nosanitize !3
  store i32 973, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3624 = sub i64 %3616, 40
  store i64 %3624, i64* %remaing_gas, align 4
  %3625 = load i64, i64* %STACK_DEP_PTR, align 4
  %3626 = sub i64 %3625, 0
  store i64 %3626, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2940:                                            ; preds = %3602, %JumpTable
  %3627 = load i64, i64* %remaing_gas, align 4
  %3628 = icmp ugt i64 120, %3627
  br i1 %3628, label %Abort, label %3629

3629:                                             ; preds = %.2940
  %3630 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3631 = xor i32 %3630, 125
  %3632 = urem i32 %3631, 4096
  %3633 = getelementptr i8, i8 addrspace(1)* %4, i32 %3632
  %3634 = load i8, i8 addrspace(1)* %3633, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3633, align 1, !nosanitize !3
  store i32 62, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3635 = sub i64 %3627, 120
  store i64 %3635, i64* %remaing_gas, align 4
  %3636 = load i64, i64* %STACK_DEP_PTR, align 4
  %3637 = getelementptr i256, i256* %STACK, i64 %3636
  %3638 = load i256, i256* %3637, align 4
  %3639 = load i64, i64* %STACK_DEP_PTR, align 4
  %3640 = sub i64 %3639, 1
  store i64 %3640, i64* %STACK_DEP_PTR, align 4
  %3641 = trunc i256 10612 to i64
  %3642 = load i64, i64* %STACK_DEP_PTR, align 4
  %3643 = add i64 %3642, 1
  store i64 %3643, i64* %STACK_DEP_PTR, align 4
  %3644 = load i64, i64* %STACK_DEP_PTR, align 4
  %3645 = getelementptr i256, i256* %STACK, i64 %3644
  store i256 2949, i256* %3645, align 4
  br label %.10612, !EVMBB !4

.2949:                                            ; preds = %JumpTable
  %3646 = load i64, i64* %remaing_gas, align 4
  %3647 = icmp ugt i64 184, %3646
  br i1 %3647, label %Abort, label %3648

3648:                                             ; preds = %.2949
  %3649 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3650 = xor i32 %3649, 1525
  %3651 = urem i32 %3650, 4096
  %3652 = getelementptr i8, i8 addrspace(1)* %4, i32 %3651
  %3653 = load i8, i8 addrspace(1)* %3652, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3652, align 1, !nosanitize !3
  store i32 762, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3654 = sub i64 %3646, 184
  store i64 %3654, i64* %remaing_gas, align 4
  %3655 = load i64, i64* %STACK_DEP_PTR, align 4
  %3656 = getelementptr i256, i256* %STACK, i64 %3655
  %3657 = load i256, i256* %3656, align 4
  %3658 = load i64, i64* %STACK_DEP_PTR, align 4
  %3659 = sub i64 %3658, 1
  store i64 %3659, i64* %STACK_DEP_PTR, align 4
  %3660 = trunc i256 64 to i64
  %3661 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3660, i256* %3661)
  %3662 = load i256, i256* %3661, align 4
  %3663 = trunc i256 %3662 to i64
  %3664 = alloca i256, align 8
  store i256 %3657, i256* %3664, align 4
  %3665 = bitcast i256* %3664 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3663, i8* %3665, i64 32)
  %3666 = add i256 32, %3662, !pc !147, !intsan !10
  %3667 = trunc i256 64 to i64
  %3668 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3667, i256* %3668)
  %3669 = load i256, i256* %3668, align 4
  %3670 = sub i256 %3666, %3669, !pc !148, !intsan !8
  br label %Exit, !EVMBB !4

.2971:                                            ; preds = %734, %JumpTable
  %3671 = load i64, i64* %remaing_gas, align 4
  %3672 = icmp ugt i64 96, %3671
  br i1 %3672, label %Abort, label %3673

3673:                                             ; preds = %.2971
  %3674 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3675 = xor i32 %3674, 1803
  %3676 = urem i32 %3675, 4096
  %3677 = getelementptr i8, i8 addrspace(1)* %4, i32 %3676
  %3678 = load i8, i8 addrspace(1)* %3677, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3677, align 1, !nosanitize !3
  store i32 901, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3679 = sub i64 %3671, 96
  store i64 %3679, i64* %remaing_gas, align 4
  %3680 = load i256, i256* %1, align 4
  %3681 = icmp eq i256 %3680, 0
  %3682 = trunc i256 2983 to i64
  %jump.check166 = icmp ne i1 %3681, false
  %3683 = load i64, i64* %STACK_DEP_PTR, align 4
  %3684 = add i64 %3683, 1
  store i64 %3684, i64* %STACK_DEP_PTR, align 4
  %3685 = load i64, i64* %STACK_DEP_PTR, align 4
  %3686 = getelementptr i256, i256* %STACK, i64 %3685
  store i256 %3680, i256* %3686, align 4
  br i1 %jump.check166, label %.2983, label %.2979, !EVMBB !4

.2979:                                            ; preds = %3673
  %3687 = load i64, i64* %remaing_gas, align 4
  %3688 = icmp ugt i64 40, %3687
  br i1 %3688, label %Abort, label %3689

3689:                                             ; preds = %.2979
  %3690 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3691 = xor i32 %3690, 3809
  %3692 = urem i32 %3691, 4096
  %3693 = getelementptr i8, i8 addrspace(1)* %4, i32 %3692
  %3694 = load i8, i8 addrspace(1)* %3693, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3693, align 1, !nosanitize !3
  store i32 1904, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3695 = sub i64 %3687, 40
  store i64 %3695, i64* %remaing_gas, align 4
  %3696 = load i64, i64* %STACK_DEP_PTR, align 4
  %3697 = sub i64 %3696, 0
  store i64 %3697, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.2983:                                            ; preds = %3673, %JumpTable
  %3698 = load i64, i64* %remaing_gas, align 4
  %3699 = icmp ugt i64 120, %3698
  br i1 %3699, label %Abort, label %3700

3700:                                             ; preds = %.2983
  %3701 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3702 = xor i32 %3701, 3098
  %3703 = urem i32 %3702, 4096
  %3704 = getelementptr i8, i8 addrspace(1)* %4, i32 %3703
  %3705 = load i8, i8 addrspace(1)* %3704, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3704, align 1, !nosanitize !3
  store i32 1549, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3706 = sub i64 %3698, 120
  store i64 %3706, i64* %remaing_gas, align 4
  %3707 = load i64, i64* %STACK_DEP_PTR, align 4
  %3708 = getelementptr i256, i256* %STACK, i64 %3707
  %3709 = load i256, i256* %3708, align 4
  %3710 = load i64, i64* %STACK_DEP_PTR, align 4
  %3711 = sub i64 %3710, 1
  store i64 %3711, i64* %STACK_DEP_PTR, align 4
  %3712 = trunc i256 10625 to i64
  %3713 = load i64, i64* %STACK_DEP_PTR, align 4
  %3714 = add i64 %3713, 1
  store i64 %3714, i64* %STACK_DEP_PTR, align 4
  %3715 = load i64, i64* %STACK_DEP_PTR, align 4
  %3716 = getelementptr i256, i256* %STACK, i64 %3715
  store i256 2992, i256* %3716, align 4
  br label %.10625, !EVMBB !4

.2992:                                            ; preds = %JumpTable
  %3717 = load i64, i64* %remaing_gas, align 4
  %3718 = icmp ugt i64 16, %3717
  br i1 %3718, label %Abort, label %3719

3719:                                             ; preds = %.2992
  %3720 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3721 = xor i32 %3720, 284
  %3722 = urem i32 %3721, 4096
  %3723 = getelementptr i8, i8 addrspace(1)* %4, i32 %3722
  %3724 = load i8, i8 addrspace(1)* %3723, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3723, align 1, !nosanitize !3
  store i32 142, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3725 = sub i64 %3717, 16
  store i64 %3725, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.2994:                                            ; preds = %751, %JumpTable
  %3726 = load i64, i64* %remaing_gas, align 4
  %3727 = icmp ugt i64 96, %3726
  br i1 %3727, label %Abort, label %3728

3728:                                             ; preds = %.2994
  %3729 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3730 = xor i32 %3729, 3967
  %3731 = urem i32 %3730, 4096
  %3732 = getelementptr i8, i8 addrspace(1)* %4, i32 %3731
  %3733 = load i8, i8 addrspace(1)* %3732, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3732, align 1, !nosanitize !3
  store i32 1983, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3734 = sub i64 %3726, 96
  store i64 %3734, i64* %remaing_gas, align 4
  %3735 = load i256, i256* %1, align 4
  %3736 = icmp eq i256 %3735, 0
  %3737 = trunc i256 3006 to i64
  %jump.check170 = icmp ne i1 %3736, false
  %3738 = load i64, i64* %STACK_DEP_PTR, align 4
  %3739 = add i64 %3738, 1
  store i64 %3739, i64* %STACK_DEP_PTR, align 4
  %3740 = load i64, i64* %STACK_DEP_PTR, align 4
  %3741 = getelementptr i256, i256* %STACK, i64 %3740
  store i256 %3735, i256* %3741, align 4
  br i1 %jump.check170, label %.3006, label %.3002, !EVMBB !4

.3002:                                            ; preds = %3728
  %3742 = load i64, i64* %remaing_gas, align 4
  %3743 = icmp ugt i64 40, %3742
  br i1 %3743, label %Abort, label %3744

3744:                                             ; preds = %.3002
  %3745 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3746 = xor i32 %3745, 3363
  %3747 = urem i32 %3746, 4096
  %3748 = getelementptr i8, i8 addrspace(1)* %4, i32 %3747
  %3749 = load i8, i8 addrspace(1)* %3748, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3748, align 1, !nosanitize !3
  store i32 1681, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3750 = sub i64 %3742, 40
  store i64 %3750, i64* %remaing_gas, align 4
  %3751 = load i64, i64* %STACK_DEP_PTR, align 4
  %3752 = sub i64 %3751, 0
  store i64 %3752, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3006:                                            ; preds = %3728, %JumpTable
  %3753 = load i64, i64* %remaing_gas, align 4
  %3754 = icmp ugt i64 248, %3753
  br i1 %3754, label %Abort, label %3755

3755:                                             ; preds = %.3006
  %3756 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3757 = xor i32 %3756, 2808
  %3758 = urem i32 %3757, 4096
  %3759 = getelementptr i8, i8 addrspace(1)* %4, i32 %3758
  %3760 = load i8, i8 addrspace(1)* %3759, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3759, align 1, !nosanitize !3
  store i32 1404, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3761 = sub i64 %3753, 248
  store i64 %3761, i64* %remaing_gas, align 4
  %3762 = load i64, i64* %STACK_DEP_PTR, align 4
  %3763 = getelementptr i256, i256* %STACK, i64 %3762
  %3764 = load i256, i256* %3763, align 4
  %3765 = load i64, i64* %STACK_DEP_PTR, align 4
  %3766 = sub i64 %3765, 1
  store i64 %3766, i64* %STACK_DEP_PTR, align 4
  %3767 = zext i32 %3 to i256
  %3768 = sub i256 %3767, 4, !pc !149, !intsan !8
  %3769 = add i256 4, %3768, !pc !150, !intsan !10
  %3770 = trunc i256 4 to i64
  %3771 = alloca i256, align 8
  %3772 = bitcast i256* %3771 to i8*
  call void @__device_calldataload(i8* %3772, i8* %2, i64 %3770)
  %3773 = load i256, i256* %3771, align 4
  %3774 = and i256 1461501637330902918203684832716283019655932542975, %3773
  %3775 = add i256 32, 4, !pc !151, !intsan !10
  %3776 = trunc i256 11418 to i64
  %3777 = load i64, i64* %STACK_DEP_PTR, align 4
  %3778 = add i64 %3777, 1
  store i64 %3778, i64* %STACK_DEP_PTR, align 4
  %3779 = load i64, i64* %STACK_DEP_PTR, align 4
  %3780 = getelementptr i256, i256* %STACK, i64 %3779
  store i256 3059, i256* %3780, align 4
  %3781 = load i64, i64* %STACK_DEP_PTR, align 4
  %3782 = add i64 %3781, 1
  store i64 %3782, i64* %STACK_DEP_PTR, align 4
  %3783 = load i64, i64* %STACK_DEP_PTR, align 4
  %3784 = getelementptr i256, i256* %STACK, i64 %3783
  store i256 %3774, i256* %3784, align 4
  br label %.11418, !EVMBB !4

.3059:                                            ; preds = %JumpTable
  %3785 = load i64, i64* %remaing_gas, align 4
  %3786 = icmp ugt i64 184, %3785
  br i1 %3786, label %Abort, label %3787

3787:                                             ; preds = %.3059
  %3788 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3789 = xor i32 %3788, 41
  %3790 = urem i32 %3789, 4096
  %3791 = getelementptr i8, i8 addrspace(1)* %4, i32 %3790
  %3792 = load i8, i8 addrspace(1)* %3791, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3791, align 1, !nosanitize !3
  store i32 20, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3793 = sub i64 %3785, 184
  store i64 %3793, i64* %remaing_gas, align 4
  %3794 = load i64, i64* %STACK_DEP_PTR, align 4
  %3795 = getelementptr i256, i256* %STACK, i64 %3794
  %3796 = load i256, i256* %3795, align 4
  %3797 = load i64, i64* %STACK_DEP_PTR, align 4
  %3798 = sub i64 %3797, 1
  store i64 %3798, i64* %STACK_DEP_PTR, align 4
  %3799 = trunc i256 64 to i64
  %3800 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3799, i256* %3800)
  %3801 = load i256, i256* %3800, align 4
  %3802 = trunc i256 %3801 to i64
  %3803 = alloca i256, align 8
  store i256 %3796, i256* %3803, align 4
  %3804 = bitcast i256* %3803 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %3802, i8* %3804, i64 32)
  %3805 = add i256 32, %3801, !pc !152, !intsan !10
  %3806 = trunc i256 64 to i64
  %3807 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %3806, i256* %3807)
  %3808 = load i256, i256* %3807, align 4
  %3809 = sub i256 %3805, %3808, !pc !153, !intsan !8
  br label %Exit, !EVMBB !4

.3081:                                            ; preds = %768, %JumpTable
  %3810 = load i64, i64* %remaing_gas, align 4
  %3811 = icmp ugt i64 72, %3810
  br i1 %3811, label %Abort, label %3812

3812:                                             ; preds = %.3081
  %3813 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3814 = xor i32 %3813, 2296
  %3815 = urem i32 %3814, 4096
  %3816 = getelementptr i8, i8 addrspace(1)* %4, i32 %3815
  %3817 = load i8, i8 addrspace(1)* %3816, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3816, align 1, !nosanitize !3
  store i32 1148, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3818 = sub i64 %3810, 72
  store i64 %3818, i64* %remaing_gas, align 4
  %3819 = trunc i256 11593 to i64
  %3820 = load i64, i64* %STACK_DEP_PTR, align 4
  %3821 = add i64 %3820, 1
  store i64 %3821, i64* %STACK_DEP_PTR, align 4
  %3822 = load i64, i64* %STACK_DEP_PTR, align 4
  %3823 = getelementptr i256, i256* %STACK, i64 %3822
  store i256 3089, i256* %3823, align 4
  br label %.11593, !EVMBB !4

.3089:                                            ; preds = %JumpTable
  %3824 = load i64, i64* %remaing_gas, align 4
  %3825 = icmp ugt i64 16, %3824
  br i1 %3825, label %Abort, label %3826

3826:                                             ; preds = %.3089
  %3827 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3828 = xor i32 %3827, 1188
  %3829 = urem i32 %3828, 4096
  %3830 = getelementptr i8, i8 addrspace(1)* %4, i32 %3829
  %3831 = load i8, i8 addrspace(1)* %3830, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3830, align 1, !nosanitize !3
  store i32 594, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3832 = sub i64 %3824, 16
  store i64 %3832, i64* %remaing_gas, align 4
  br label %Exit, !EVMBB !4

.3091:                                            ; preds = %1037, %785, %JumpTable
  %3833 = load i64, i64* %remaing_gas, align 4
  %3834 = icmp ugt i64 288, %3833
  br i1 %3834, label %Abort, label %3835

3835:                                             ; preds = %.3091
  %3836 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3837 = xor i32 %3836, 539
  %3838 = urem i32 %3837, 4096
  %3839 = getelementptr i8, i8 addrspace(1)* %4, i32 %3838
  %3840 = load i8, i8 addrspace(1)* %3839, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %3839, align 1, !nosanitize !3
  store i32 269, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %3841 = sub i64 %3833, 288
  store i64 %3841, i64* %remaing_gas, align 4
  %3842 = alloca i256, align 8
  store i256 8, i256* %3842, align 4
  %3843 = alloca i256, align 8
  call void @__device_sload(i256* %3842, i256* %3843)
  %3844 = call i32 @__hashword(i256* %3842)
  %3845 = load i32, i32* %5, align 4
  %3846 = icmp eq i32 %3844, %3845
  %3847 = or i1 false, %3846
  %3848 = load i32, i32* %6, align 4
  %3849 = icmp eq i32 %3844, %3848
  %3850 = or i1 %3847, %3849
  %3851 = load i32, i32* %7, align 4
  %3852 = icmp eq i32 %3844, %3851
  %3853 = or i1 %3850, %3852
  %3854 = load i32, i32* %8, align 4
  %3855 = icmp eq i32 %3844, %3854
  %3856 = or i1 %3853, %3855
  %3857 = load i32, i32* %9, align 4
  %3858 = icmp eq i32 %3844, %3857
  %3859 = or i1 %3856, %3858
  %3860 = load i32, i32* %10, align 4
  %3861 = icmp eq i32 %3844, %3860
  %3862 = or i1 %3859, %3861
  %3863 = load i32, i32* %11, align 4
  %3864 = icmp eq i32 %3844, %3863
  %3865 = or i1 %3862, %3864
  %3866 = load i32, i32* %12, align 4
  %3867 = icmp eq i32 %3844, %3866
  %3868 = or i1 %3865, %3867
  %3869 = load i32, i32* %13, align 4
  %3870 = icmp eq i32 %3844, %3869
  %3871 = or i1 %3868, %3870
  %3872 = load i32, i32* %14, align 4
  %3873 = icmp eq i32 %3844, %3872
  %3874 = or i1 %3871, %3873
  %3875 = load i32, i32* %15, align 4
  %3876 = icmp eq i32 %3844, %3875
  %3877 = or i1 %3874, %3876
  %3878 = load i32, i32* %16, align 4
  %3879 = icmp eq i32 %3844, %3878
  %3880 = or i1 %3877, %3879
  %3881 = load i32, i32* %17, align 4
  %3882 = icmp eq i32 %3844, %3881
  %3883 = or i1 %3880, %3882
  %3884 = load i32, i32* %18, align 4
  %3885 = icmp eq i32 %3844, %3884
  %3886 = or i1 %3883, %3885
  %3887 = load i32, i32* %19, align 4
  %3888 = icmp eq i32 %3844, %3887
  %3889 = or i1 %3886, %3888
  %3890 = load i32, i32* %20, align 4
  %3891 = icmp eq i32 %3844, %3890
  %3892 = or i1 %3889, %3891
  %3893 = load i32, i32* %21, align 4
  %3894 = icmp eq i32 %3844, %3893
  %3895 = or i1 %3892, %3894
  %3896 = load i32, i32* %22, align 4
  %3897 = icmp eq i32 %3844, %3896
  %3898 = or i1 %3895, %3897
  %3899 = load i32, i32* %23, align 4
  %3900 = icmp eq i32 %3844, %3899
  %3901 = or i1 %3898, %3900
  %3902 = load i32, i32* %24, align 4
  %3903 = icmp eq i32 %3844, %3902
  %3904 = or i1 %3901, %3903
  %3905 = load i32, i32* %25, align 4
  %3906 = icmp eq i32 %3844, %3905
  %3907 = or i1 %3904, %3906
  %3908 = load i32, i32* %26, align 4
  %3909 = icmp eq i32 %3844, %3908
  %3910 = or i1 %3907, %3909
  %3911 = load i32, i32* %27, align 4
  %3912 = icmp eq i32 %3844, %3911
  %3913 = or i1 %3910, %3912
  %3914 = load i32, i32* %28, align 4
  %3915 = icmp eq i32 %3844, %3914
  %3916 = or i1 %3913, %3915
  %3917 = load i32, i32* %29, align 4
  %3918 = icmp eq i32 %3844, %3917
  %3919 = or i1 %3916, %3918
  %3920 = load i32, i32* %30, align 4
  %3921 = icmp eq i32 %3844, %3920
  %3922 = or i1 %3919, %3921
  %3923 = load i32, i32* %31, align 4
  %3924 = icmp eq i32 %3844, %3923
  %3925 = or i1 %3922, %3924
  %3926 = load i32, i32* %32, align 4
  %3927 = icmp eq i32 %3844, %3926
  %3928 = or i1 %3925, %3927
  %3929 = load i32, i32* %33, align 4
  %3930 = icmp eq i32 %3844, %3929
  %3931 = or i1 %3928, %3930
  %3932 = load i32, i32* %34, align 4
  %3933 = icmp eq i32 %3844, %3932
  %3934 = or i1 %3931, %3933
  %3935 = load i32, i32* %35, align 4
  %3936 = icmp eq i32 %3844, %3935
  %3937 = or i1 %3934, %3936
  %3938 = load i32, i32* %36, align 4
  %3939 = icmp eq i32 %3844, %3938
  %3940 = or i1 %3937, %3939
  %3941 = load i32, i32* %37, align 4
  %3942 = icmp eq i32 %3844, %3941
  %3943 = or i1 %3940, %3942
  %3944 = load i32, i32* %38, align 4
  %3945 = icmp eq i32 %3844, %3944
  %3946 = or i1 %3943, %3945
  %3947 = load i32, i32* %39, align 4
  %3948 = icmp eq i32 %3844, %3947
  %3949 = or i1 %3946, %3948
  %3950 = load i32, i32* %40, align 4
  %3951 = icmp eq i32 %3844, %3950
  %3952 = or i1 %3949, %3951
  %3953 = load i32, i32* %41, align 4
  %3954 = icmp eq i32 %3844, %3953
  %3955 = or i1 %3952, %3954
  %3956 = load i32, i32* %42, align 4
  %3957 = icmp eq i32 %3844, %3956
  %3958 = or i1 %3955, %3957
  %3959 = load i32, i32* %43, align 4
  %3960 = icmp eq i32 %3844, %3959
  %3961 = or i1 %3958, %3960
  %3962 = load i32, i32* %44, align 4
  %3963 = icmp eq i32 %3844, %3962
  %3964 = or i1 %3961, %3963
  %3965 = load i32, i32* %45, align 4
  %3966 = icmp eq i32 %3844, %3965
  %3967 = or i1 %3964, %3966
  %3968 = load i32, i32* %46, align 4
  %3969 = icmp eq i32 %3844, %3968
  %3970 = or i1 %3967, %3969
  %3971 = load i32, i32* %47, align 4
  %3972 = icmp eq i32 %3844, %3971
  %3973 = or i1 %3970, %3972
  %3974 = load i32, i32* %48, align 4
  %3975 = icmp eq i32 %3844, %3974
  %3976 = or i1 %3973, %3975
  %3977 = load i32, i32* %49, align 4
  %3978 = icmp eq i32 %3844, %3977
  %3979 = or i1 %3976, %3978
  %3980 = load i32, i32* %50, align 4
  %3981 = icmp eq i32 %3844, %3980
  %3982 = or i1 %3979, %3981
  %3983 = load i32, i32* %51, align 4
  %3984 = icmp eq i32 %3844, %3983
  %3985 = or i1 %3982, %3984
  %3986 = load i32, i32* %52, align 4
  %3987 = icmp eq i32 %3844, %3986
  %3988 = or i1 %3985, %3987
  %3989 = load i32, i32* %53, align 4
  %3990 = icmp eq i32 %3844, %3989
  %3991 = or i1 %3988, %3990
  %3992 = load i32, i32* %54, align 4
  %3993 = icmp eq i32 %3844, %3992
  %3994 = or i1 %3991, %3993
  %3995 = load i32, i32* %55, align 4
  %3996 = icmp eq i32 %3844, %3995
  %3997 = or i1 %3994, %3996
  %3998 = load i32, i32* %56, align 4
  %3999 = icmp eq i32 %3844, %3998
  %4000 = or i1 %3997, %3999
  %4001 = load i32, i32* %57, align 4
  %4002 = icmp eq i32 %3844, %4001
  %4003 = or i1 %4000, %4002
  %4004 = load i32, i32* %58, align 4
  %4005 = icmp eq i32 %3844, %4004
  %4006 = or i1 %4003, %4005
  %4007 = load i32, i32* %59, align 4
  %4008 = icmp eq i32 %3844, %4007
  %4009 = or i1 %4006, %4008
  %4010 = load i32, i32* %60, align 4
  %4011 = icmp eq i32 %3844, %4010
  %4012 = or i1 %4009, %4011
  %4013 = load i32, i32* %61, align 4
  %4014 = icmp eq i32 %3844, %4013
  %4015 = or i1 %4012, %4014
  %4016 = load i32, i32* %62, align 4
  %4017 = icmp eq i32 %3844, %4016
  %4018 = or i1 %4015, %4017
  %4019 = getelementptr i8, i8 addrspace(1)* %4, i32 0
  %4020 = zext i1 %4018 to i8
  store i8 %4020, i8 addrspace(1)* %4019, align 1, !nosanitize !3
  %4021 = load i256, i256* %3843, align 4
  %4022 = alloca i256, align 8
  store i256 %4021, i256* %4022, align 4
  %4023 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %4023, align 4
  %4024 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %4022, i256* %4023, i256* %4024), !pc !154, !intsan !6
  %4025 = load i256, i256* %4024, align 4
  %4026 = and i256 255, %4025
  %4027 = icmp eq i256 %4026, 0
  %4028 = trunc i256 3122 to i64
  %jump.check4 = icmp ne i1 %4027, false
  %4029 = load i64, i64* %STACK_DEP_PTR, align 4
  %4030 = add i64 %4029, 1
  store i64 %4030, i64* %STACK_DEP_PTR, align 4
  %4031 = load i64, i64* %STACK_DEP_PTR, align 4
  %4032 = getelementptr i256, i256* %STACK, i64 %4031
  store i256 0, i256* %4032, align 4
  %4033 = load i64, i64* %STACK_DEP_PTR, align 4
  %4034 = add i64 %4033, 1
  store i64 %4034, i64* %STACK_DEP_PTR, align 4
  %4035 = load i64, i64* %STACK_DEP_PTR, align 4
  %4036 = getelementptr i256, i256* %STACK, i64 %4035
  store i256 0, i256* %4036, align 4
  %4037 = load i64, i64* %STACK_DEP_PTR, align 4
  %4038 = add i64 %4037, 1
  store i64 %4038, i64* %STACK_DEP_PTR, align 4
  %4039 = load i64, i64* %STACK_DEP_PTR, align 4
  %4040 = getelementptr i256, i256* %STACK, i64 %4039
  store i256 0, i256* %4040, align 4
  br i1 %jump.check4, label %.3122, label %.3118, !EVMBB !4

.3118:                                            ; preds = %3835
  %4041 = load i64, i64* %remaing_gas, align 4
  %4042 = icmp ugt i64 40, %4041
  br i1 %4042, label %Abort, label %4043

4043:                                             ; preds = %.3118
  %4044 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4045 = xor i32 %4044, 1811
  %4046 = urem i32 %4045, 4096
  %4047 = getelementptr i8, i8 addrspace(1)* %4, i32 %4046
  %4048 = load i8, i8 addrspace(1)* %4047, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4047, align 1, !nosanitize !3
  store i32 905, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4049 = sub i64 %4041, 40
  store i64 %4049, i64* %remaing_gas, align 4
  %4050 = load i64, i64* %STACK_DEP_PTR, align 4
  %4051 = sub i64 %4050, 0
  store i64 %4051, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3122:                                            ; preds = %3835, %JumpTable
  %4052 = load i64, i64* %remaing_gas, align 4
  %4053 = icmp ugt i64 784, %4052
  br i1 %4053, label %Abort, label %4054

4054:                                             ; preds = %.3122
  %4055 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4056 = xor i32 %4055, 1461
  %4057 = urem i32 %4056, 4096
  %4058 = getelementptr i8, i8 addrspace(1)* %4, i32 %4057
  %4059 = load i8, i8 addrspace(1)* %4058, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4058, align 1, !nosanitize !3
  store i32 730, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4060 = sub i64 %4052, 784
  store i64 %4060, i64* %remaing_gas, align 4
  %4061 = alloca i256, align 8
  store i256 0, i256* %4061, align 4
  %4062 = alloca i256, align 8
  call void @__device_sload(i256* %4061, i256* %4062)
  %4063 = call i32 @__hashword(i256* %4061)
  %4064 = load i32, i32* %5, align 4
  %4065 = icmp eq i32 %4063, %4064
  %4066 = or i1 false, %4065
  %4067 = load i32, i32* %6, align 4
  %4068 = icmp eq i32 %4063, %4067
  %4069 = or i1 %4066, %4068
  %4070 = load i32, i32* %7, align 4
  %4071 = icmp eq i32 %4063, %4070
  %4072 = or i1 %4069, %4071
  %4073 = load i32, i32* %8, align 4
  %4074 = icmp eq i32 %4063, %4073
  %4075 = or i1 %4072, %4074
  %4076 = load i32, i32* %9, align 4
  %4077 = icmp eq i32 %4063, %4076
  %4078 = or i1 %4075, %4077
  %4079 = load i32, i32* %10, align 4
  %4080 = icmp eq i32 %4063, %4079
  %4081 = or i1 %4078, %4080
  %4082 = load i32, i32* %11, align 4
  %4083 = icmp eq i32 %4063, %4082
  %4084 = or i1 %4081, %4083
  %4085 = load i32, i32* %12, align 4
  %4086 = icmp eq i32 %4063, %4085
  %4087 = or i1 %4084, %4086
  %4088 = load i32, i32* %13, align 4
  %4089 = icmp eq i32 %4063, %4088
  %4090 = or i1 %4087, %4089
  %4091 = load i32, i32* %14, align 4
  %4092 = icmp eq i32 %4063, %4091
  %4093 = or i1 %4090, %4092
  %4094 = load i32, i32* %15, align 4
  %4095 = icmp eq i32 %4063, %4094
  %4096 = or i1 %4093, %4095
  %4097 = load i32, i32* %16, align 4
  %4098 = icmp eq i32 %4063, %4097
  %4099 = or i1 %4096, %4098
  %4100 = load i32, i32* %17, align 4
  %4101 = icmp eq i32 %4063, %4100
  %4102 = or i1 %4099, %4101
  %4103 = load i32, i32* %18, align 4
  %4104 = icmp eq i32 %4063, %4103
  %4105 = or i1 %4102, %4104
  %4106 = load i32, i32* %19, align 4
  %4107 = icmp eq i32 %4063, %4106
  %4108 = or i1 %4105, %4107
  %4109 = load i32, i32* %20, align 4
  %4110 = icmp eq i32 %4063, %4109
  %4111 = or i1 %4108, %4110
  %4112 = load i32, i32* %21, align 4
  %4113 = icmp eq i32 %4063, %4112
  %4114 = or i1 %4111, %4113
  %4115 = load i32, i32* %22, align 4
  %4116 = icmp eq i32 %4063, %4115
  %4117 = or i1 %4114, %4116
  %4118 = load i32, i32* %23, align 4
  %4119 = icmp eq i32 %4063, %4118
  %4120 = or i1 %4117, %4119
  %4121 = load i32, i32* %24, align 4
  %4122 = icmp eq i32 %4063, %4121
  %4123 = or i1 %4120, %4122
  %4124 = load i32, i32* %25, align 4
  %4125 = icmp eq i32 %4063, %4124
  %4126 = or i1 %4123, %4125
  %4127 = load i32, i32* %26, align 4
  %4128 = icmp eq i32 %4063, %4127
  %4129 = or i1 %4126, %4128
  %4130 = load i32, i32* %27, align 4
  %4131 = icmp eq i32 %4063, %4130
  %4132 = or i1 %4129, %4131
  %4133 = load i32, i32* %28, align 4
  %4134 = icmp eq i32 %4063, %4133
  %4135 = or i1 %4132, %4134
  %4136 = load i32, i32* %29, align 4
  %4137 = icmp eq i32 %4063, %4136
  %4138 = or i1 %4135, %4137
  %4139 = load i32, i32* %30, align 4
  %4140 = icmp eq i32 %4063, %4139
  %4141 = or i1 %4138, %4140
  %4142 = load i32, i32* %31, align 4
  %4143 = icmp eq i32 %4063, %4142
  %4144 = or i1 %4141, %4143
  %4145 = load i32, i32* %32, align 4
  %4146 = icmp eq i32 %4063, %4145
  %4147 = or i1 %4144, %4146
  %4148 = load i32, i32* %33, align 4
  %4149 = icmp eq i32 %4063, %4148
  %4150 = or i1 %4147, %4149
  %4151 = load i32, i32* %34, align 4
  %4152 = icmp eq i32 %4063, %4151
  %4153 = or i1 %4150, %4152
  %4154 = load i32, i32* %35, align 4
  %4155 = icmp eq i32 %4063, %4154
  %4156 = or i1 %4153, %4155
  %4157 = load i32, i32* %36, align 4
  %4158 = icmp eq i32 %4063, %4157
  %4159 = or i1 %4156, %4158
  %4160 = load i32, i32* %37, align 4
  %4161 = icmp eq i32 %4063, %4160
  %4162 = or i1 %4159, %4161
  %4163 = load i32, i32* %38, align 4
  %4164 = icmp eq i32 %4063, %4163
  %4165 = or i1 %4162, %4164
  %4166 = load i32, i32* %39, align 4
  %4167 = icmp eq i32 %4063, %4166
  %4168 = or i1 %4165, %4167
  %4169 = load i32, i32* %40, align 4
  %4170 = icmp eq i32 %4063, %4169
  %4171 = or i1 %4168, %4170
  %4172 = load i32, i32* %41, align 4
  %4173 = icmp eq i32 %4063, %4172
  %4174 = or i1 %4171, %4173
  %4175 = load i32, i32* %42, align 4
  %4176 = icmp eq i32 %4063, %4175
  %4177 = or i1 %4174, %4176
  %4178 = load i32, i32* %43, align 4
  %4179 = icmp eq i32 %4063, %4178
  %4180 = or i1 %4177, %4179
  %4181 = load i32, i32* %44, align 4
  %4182 = icmp eq i32 %4063, %4181
  %4183 = or i1 %4180, %4182
  %4184 = load i32, i32* %45, align 4
  %4185 = icmp eq i32 %4063, %4184
  %4186 = or i1 %4183, %4185
  %4187 = load i32, i32* %46, align 4
  %4188 = icmp eq i32 %4063, %4187
  %4189 = or i1 %4186, %4188
  %4190 = load i32, i32* %47, align 4
  %4191 = icmp eq i32 %4063, %4190
  %4192 = or i1 %4189, %4191
  %4193 = load i32, i32* %48, align 4
  %4194 = icmp eq i32 %4063, %4193
  %4195 = or i1 %4192, %4194
  %4196 = load i32, i32* %49, align 4
  %4197 = icmp eq i32 %4063, %4196
  %4198 = or i1 %4195, %4197
  %4199 = load i32, i32* %50, align 4
  %4200 = icmp eq i32 %4063, %4199
  %4201 = or i1 %4198, %4200
  %4202 = load i32, i32* %51, align 4
  %4203 = icmp eq i32 %4063, %4202
  %4204 = or i1 %4201, %4203
  %4205 = load i32, i32* %52, align 4
  %4206 = icmp eq i32 %4063, %4205
  %4207 = or i1 %4204, %4206
  %4208 = load i32, i32* %53, align 4
  %4209 = icmp eq i32 %4063, %4208
  %4210 = or i1 %4207, %4209
  %4211 = load i32, i32* %54, align 4
  %4212 = icmp eq i32 %4063, %4211
  %4213 = or i1 %4210, %4212
  %4214 = load i32, i32* %55, align 4
  %4215 = icmp eq i32 %4063, %4214
  %4216 = or i1 %4213, %4215
  %4217 = load i32, i32* %56, align 4
  %4218 = icmp eq i32 %4063, %4217
  %4219 = or i1 %4216, %4218
  %4220 = load i32, i32* %57, align 4
  %4221 = icmp eq i32 %4063, %4220
  %4222 = or i1 %4219, %4221
  %4223 = load i32, i32* %58, align 4
  %4224 = icmp eq i32 %4063, %4223
  %4225 = or i1 %4222, %4224
  %4226 = load i32, i32* %59, align 4
  %4227 = icmp eq i32 %4063, %4226
  %4228 = or i1 %4225, %4227
  %4229 = load i32, i32* %60, align 4
  %4230 = icmp eq i32 %4063, %4229
  %4231 = or i1 %4228, %4230
  %4232 = load i32, i32* %61, align 4
  %4233 = icmp eq i32 %4063, %4232
  %4234 = or i1 %4231, %4233
  %4235 = load i32, i32* %62, align 4
  %4236 = icmp eq i32 %4063, %4235
  %4237 = or i1 %4234, %4236
  %4238 = getelementptr i8, i8 addrspace(1)* %4, i32 1
  %4239 = zext i1 %4237 to i8
  store i8 %4239, i8 addrspace(1)* %4238, align 1, !nosanitize !3
  %4240 = load i256, i256* %4062, align 4
  %4241 = alloca i256, align 8
  store i256 %4240, i256* %4241, align 4
  %4242 = alloca i256, align 8
  store i256 1, i256* %4242, align 4
  %4243 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %4241, i256* %4242, i256* %4243), !pc !155, !intsan !6
  %4244 = load i256, i256* %4243, align 4
  %4245 = and i256 1461501637330902918203684832716283019655932542975, %4244
  %4246 = and i256 1461501637330902918203684832716283019655932542975, %4245
  %4247 = trunc i256 64 to i64
  %4248 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4247, i256* %4248)
  %4249 = load i256, i256* %4248, align 4
  %4250 = and i256 4294967295, 952911921
  %4251 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %4250, !pc !156, !intsan !45
  %4252 = trunc i256 %4249 to i64
  %4253 = alloca i256, align 8
  store i256 %4251, i256* %4253, align 4
  %4254 = bitcast i256* %4253 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4252, i8* %4254, i64 32)
  %4255 = add i256 4, %4249, !pc !157, !intsan !10
  %4256 = trunc i256 64 to i64
  %4257 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4256, i256* %4257)
  %4258 = load i256, i256* %4257, align 4
  %4259 = sub i256 %4255, %4258, !pc !158, !intsan !8
  %4260 = icmp eq i256 1, 0
  %4261 = icmp eq i1 %4260, false
  %4262 = trunc i256 3255 to i64
  %jump.check7 = icmp ne i1 %4261, false
  %4263 = load i64, i64* %STACK_DEP_PTR, align 4
  %4264 = add i64 %4263, 1
  store i64 %4264, i64* %STACK_DEP_PTR, align 4
  %4265 = load i64, i64* %STACK_DEP_PTR, align 4
  %4266 = getelementptr i256, i256* %STACK, i64 %4265
  store i256 %4246, i256* %4266, align 4
  %4267 = load i64, i64* %STACK_DEP_PTR, align 4
  %4268 = add i64 %4267, 1
  store i64 %4268, i64* %STACK_DEP_PTR, align 4
  %4269 = load i64, i64* %STACK_DEP_PTR, align 4
  %4270 = getelementptr i256, i256* %STACK, i64 %4269
  store i256 952911921, i256* %4270, align 4
  %4271 = load i64, i64* %STACK_DEP_PTR, align 4
  %4272 = add i64 %4271, 1
  store i64 %4272, i64* %STACK_DEP_PTR, align 4
  %4273 = load i64, i64* %STACK_DEP_PTR, align 4
  %4274 = getelementptr i256, i256* %STACK, i64 %4273
  store i256 %4255, i256* %4274, align 4
  %4275 = load i64, i64* %STACK_DEP_PTR, align 4
  %4276 = add i64 %4275, 1
  store i64 %4276, i64* %STACK_DEP_PTR, align 4
  %4277 = load i64, i64* %STACK_DEP_PTR, align 4
  %4278 = getelementptr i256, i256* %STACK, i64 %4277
  store i256 32, i256* %4278, align 4
  %4279 = load i64, i64* %STACK_DEP_PTR, align 4
  %4280 = add i64 %4279, 1
  store i64 %4280, i64* %STACK_DEP_PTR, align 4
  %4281 = load i64, i64* %STACK_DEP_PTR, align 4
  %4282 = getelementptr i256, i256* %STACK, i64 %4281
  store i256 %4258, i256* %4282, align 4
  %4283 = load i64, i64* %STACK_DEP_PTR, align 4
  %4284 = add i64 %4283, 1
  store i64 %4284, i64* %STACK_DEP_PTR, align 4
  %4285 = load i64, i64* %STACK_DEP_PTR, align 4
  %4286 = getelementptr i256, i256* %STACK, i64 %4285
  store i256 %4259, i256* %4286, align 4
  %4287 = load i64, i64* %STACK_DEP_PTR, align 4
  %4288 = add i64 %4287, 1
  store i64 %4288, i64* %STACK_DEP_PTR, align 4
  %4289 = load i64, i64* %STACK_DEP_PTR, align 4
  %4290 = getelementptr i256, i256* %STACK, i64 %4289
  store i256 %4258, i256* %4290, align 4
  %4291 = load i64, i64* %STACK_DEP_PTR, align 4
  %4292 = add i64 %4291, 1
  store i64 %4292, i64* %STACK_DEP_PTR, align 4
  %4293 = load i64, i64* %STACK_DEP_PTR, align 4
  %4294 = getelementptr i256, i256* %STACK, i64 %4293
  store i256 0, i256* %4294, align 4
  %4295 = load i64, i64* %STACK_DEP_PTR, align 4
  %4296 = add i64 %4295, 1
  store i64 %4296, i64* %STACK_DEP_PTR, align 4
  %4297 = load i64, i64* %STACK_DEP_PTR, align 4
  %4298 = getelementptr i256, i256* %STACK, i64 %4297
  store i256 %4246, i256* %4298, align 4
  %4299 = load i64, i64* %STACK_DEP_PTR, align 4
  %4300 = add i64 %4299, 1
  store i64 %4300, i64* %STACK_DEP_PTR, align 4
  %4301 = zext i1 %4260 to i256
  %4302 = load i64, i64* %STACK_DEP_PTR, align 4
  %4303 = getelementptr i256, i256* %STACK, i64 %4302
  store i256 %4301, i256* %4303, align 4
  br i1 %jump.check7, label %.3255, label %.3251, !EVMBB !4

.3251:                                            ; preds = %4054
  %4304 = load i64, i64* %remaing_gas, align 4
  %4305 = icmp ugt i64 40, %4304
  br i1 %4305, label %Abort, label %4306

4306:                                             ; preds = %.3251
  %4307 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4308 = xor i32 %4307, 2762
  %4309 = urem i32 %4308, 4096
  %4310 = getelementptr i8, i8 addrspace(1)* %4, i32 %4309
  %4311 = load i8, i8 addrspace(1)* %4310, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4310, align 1, !nosanitize !3
  store i32 1381, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4312 = sub i64 %4304, 40
  store i64 %4312, i64* %remaing_gas, align 4
  %4313 = load i64, i64* %STACK_DEP_PTR, align 4
  %4314 = sub i64 %4313, 0
  store i64 %4314, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3255:                                            ; preds = %4054, %JumpTable
  %4315 = load i64, i64* %remaing_gas, align 4
  %4316 = icmp ugt i64 456, %4315
  br i1 %4316, label %Abort, label %4317

4317:                                             ; preds = %.3255
  %4318 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4319 = xor i32 %4318, 1870
  %4320 = urem i32 %4319, 4096
  %4321 = getelementptr i8, i8 addrspace(1)* %4, i32 %4320
  %4322 = load i8, i8 addrspace(1)* %4321, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4321, align 1, !nosanitize !3
  store i32 935, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4323 = sub i64 %4315, 456
  store i64 %4323, i64* %remaing_gas, align 4
  %4324 = load i64, i64* %STACK_DEP_PTR, align 4
  %4325 = getelementptr i256, i256* %STACK, i64 %4324
  %4326 = load i256, i256* %4325, align 4
  %4327 = load i64, i64* %STACK_DEP_PTR, align 4
  %4328 = sub i64 %4327, 1
  store i64 %4328, i64* %STACK_DEP_PTR, align 4
  %4329 = load i64, i64* %STACK_DEP_PTR, align 4
  %4330 = getelementptr i256, i256* %STACK, i64 %4329
  %4331 = load i256, i256* %4330, align 4
  %4332 = load i64, i64* %STACK_DEP_PTR, align 4
  %4333 = sub i64 %4332, 1
  store i64 %4333, i64* %STACK_DEP_PTR, align 4
  %4334 = load i64, i64* %STACK_DEP_PTR, align 4
  %4335 = getelementptr i256, i256* %STACK, i64 %4334
  %4336 = load i256, i256* %4335, align 4
  %4337 = load i64, i64* %STACK_DEP_PTR, align 4
  %4338 = sub i64 %4337, 1
  store i64 %4338, i64* %STACK_DEP_PTR, align 4
  %4339 = load i64, i64* %STACK_DEP_PTR, align 4
  %4340 = getelementptr i256, i256* %STACK, i64 %4339
  %4341 = load i256, i256* %4340, align 4
  %4342 = load i64, i64* %STACK_DEP_PTR, align 4
  %4343 = sub i64 %4342, 1
  store i64 %4343, i64* %STACK_DEP_PTR, align 4
  %4344 = load i64, i64* %STACK_DEP_PTR, align 4
  %4345 = getelementptr i256, i256* %STACK, i64 %4344
  %4346 = load i256, i256* %4345, align 4
  %4347 = load i64, i64* %STACK_DEP_PTR, align 4
  %4348 = sub i64 %4347, 1
  store i64 %4348, i64* %STACK_DEP_PTR, align 4
  %4349 = load i64, i64* %STACK_DEP_PTR, align 4
  %4350 = getelementptr i256, i256* %STACK, i64 %4349
  %4351 = load i256, i256* %4350, align 4
  %4352 = load i64, i64* %STACK_DEP_PTR, align 4
  %4353 = sub i64 %4352, 1
  store i64 %4353, i64* %STACK_DEP_PTR, align 4
  %4354 = load i64, i64* %STACK_DEP_PTR, align 4
  %4355 = getelementptr i256, i256* %STACK, i64 %4354
  %4356 = load i256, i256* %4355, align 4
  %4357 = load i64, i64* %STACK_DEP_PTR, align 4
  %4358 = sub i64 %4357, 1
  store i64 %4358, i64* %STACK_DEP_PTR, align 4
  %4359 = trunc i256 %4331 to i160
  %4360 = call i1 @solidity_call(), !pc !159
  %4361 = icmp eq i1 %4360, false
  %4362 = icmp eq i1 %4361, false
  %4363 = trunc i256 3275 to i64
  %jump.check11 = icmp ne i1 %4362, false
  %4364 = load i64, i64* %STACK_DEP_PTR, align 4
  %4365 = add i64 %4364, 1
  store i64 %4365, i64* %STACK_DEP_PTR, align 4
  %4366 = zext i1 %4361 to i256
  %4367 = load i64, i64* %STACK_DEP_PTR, align 4
  %4368 = getelementptr i256, i256* %STACK, i64 %4367
  store i256 %4366, i256* %4368, align 4
  br i1 %jump.check11, label %.3275, label %.3266, !EVMBB !4

.3266:                                            ; preds = %4317
  %4369 = load i64, i64* %remaing_gas, align 4
  %4370 = icmp ugt i64 40, %4369
  br i1 %4370, label %Abort, label %4371

4371:                                             ; preds = %.3266
  %4372 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4373 = xor i32 %4372, 1000
  %4374 = urem i32 %4373, 4096
  %4375 = getelementptr i8, i8 addrspace(1)* %4, i32 %4374
  %4376 = load i8, i8 addrspace(1)* %4375, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4375, align 1, !nosanitize !3
  store i32 500, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4377 = sub i64 %4369, 40
  store i64 %4377, i64* %remaing_gas, align 4
  %4378 = load i64, i64* %STACK_DEP_PTR, align 4
  %4379 = sub i64 %4378, 0
  store i64 %4379, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3275:                                            ; preds = %4317, %JumpTable
  %4380 = load i64, i64* %remaing_gas, align 4
  %4381 = icmp ugt i64 384, %4380
  br i1 %4381, label %Abort, label %4382

4382:                                             ; preds = %.3275
  %4383 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4384 = xor i32 %4383, 664
  %4385 = urem i32 %4384, 4096
  %4386 = getelementptr i8, i8 addrspace(1)* %4, i32 %4385
  %4387 = load i8, i8 addrspace(1)* %4386, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4386, align 1, !nosanitize !3
  store i32 332, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4388 = sub i64 %4380, 384
  store i64 %4388, i64* %remaing_gas, align 4
  %4389 = load i64, i64* %STACK_DEP_PTR, align 4
  %4390 = getelementptr i256, i256* %STACK, i64 %4389
  %4391 = load i256, i256* %4390, align 4
  %4392 = load i64, i64* %STACK_DEP_PTR, align 4
  %4393 = sub i64 %4392, 1
  store i64 %4393, i64* %STACK_DEP_PTR, align 4
  %4394 = load i64, i64* %STACK_DEP_PTR, align 4
  %4395 = getelementptr i256, i256* %STACK, i64 %4394
  %4396 = load i256, i256* %4395, align 4
  %4397 = load i64, i64* %STACK_DEP_PTR, align 4
  %4398 = sub i64 %4397, 1
  store i64 %4398, i64* %STACK_DEP_PTR, align 4
  %4399 = load i64, i64* %STACK_DEP_PTR, align 4
  %4400 = getelementptr i256, i256* %STACK, i64 %4399
  %4401 = load i256, i256* %4400, align 4
  %4402 = load i64, i64* %STACK_DEP_PTR, align 4
  %4403 = sub i64 %4402, 1
  store i64 %4403, i64* %STACK_DEP_PTR, align 4
  %4404 = load i64, i64* %STACK_DEP_PTR, align 4
  %4405 = getelementptr i256, i256* %STACK, i64 %4404
  %4406 = load i256, i256* %4405, align 4
  %4407 = load i64, i64* %STACK_DEP_PTR, align 4
  %4408 = sub i64 %4407, 1
  store i64 %4408, i64* %STACK_DEP_PTR, align 4
  %4409 = trunc i256 64 to i64
  %4410 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4409, i256* %4410)
  %4411 = load i256, i256* %4410, align 4
  %4412 = zext i64 0 to i256
  %4413 = icmp ult i256 %4412, 32
  %4414 = icmp eq i1 %4413, false
  %4415 = trunc i256 3297 to i64
  %jump.check14 = icmp ne i1 %4414, false
  %4416 = load i64, i64* %STACK_DEP_PTR, align 4
  %4417 = add i64 %4416, 1
  store i64 %4417, i64* %STACK_DEP_PTR, align 4
  %4418 = load i64, i64* %STACK_DEP_PTR, align 4
  %4419 = getelementptr i256, i256* %STACK, i64 %4418
  store i256 %4411, i256* %4419, align 4
  %4420 = load i64, i64* %STACK_DEP_PTR, align 4
  %4421 = add i64 %4420, 1
  store i64 %4421, i64* %STACK_DEP_PTR, align 4
  %4422 = zext i64 0 to i256
  %4423 = load i64, i64* %STACK_DEP_PTR, align 4
  %4424 = getelementptr i256, i256* %STACK, i64 %4423
  store i256 %4422, i256* %4424, align 4
  br i1 %jump.check14, label %.3297, label %.3293, !EVMBB !4

.3293:                                            ; preds = %4382
  %4425 = load i64, i64* %remaing_gas, align 4
  %4426 = icmp ugt i64 40, %4425
  br i1 %4426, label %Abort, label %4427

4427:                                             ; preds = %.3293
  %4428 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4429 = xor i32 %4428, 1586
  %4430 = urem i32 %4429, 4096
  %4431 = getelementptr i8, i8 addrspace(1)* %4, i32 %4430
  %4432 = load i8, i8 addrspace(1)* %4431, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4431, align 1, !nosanitize !3
  store i32 793, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4433 = sub i64 %4425, 40
  store i64 %4433, i64* %remaing_gas, align 4
  %4434 = load i64, i64* %STACK_DEP_PTR, align 4
  %4435 = sub i64 %4434, 0
  store i64 %4435, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3297:                                            ; preds = %4382, %JumpTable
  %4436 = load i64, i64* %remaing_gas, align 4
  %4437 = icmp ugt i64 1072, %4436
  br i1 %4437, label %Abort, label %4438

4438:                                             ; preds = %.3297
  %4439 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4440 = xor i32 %4439, 2360
  %4441 = urem i32 %4440, 4096
  %4442 = getelementptr i8, i8 addrspace(1)* %4, i32 %4441
  %4443 = load i8, i8 addrspace(1)* %4442, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4442, align 1, !nosanitize !3
  store i32 1180, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4444 = sub i64 %4436, 1072
  store i64 %4444, i64* %remaing_gas, align 4
  %4445 = load i64, i64* %STACK_DEP_PTR, align 4
  %4446 = getelementptr i256, i256* %STACK, i64 %4445
  %4447 = load i256, i256* %4446, align 4
  %4448 = load i64, i64* %STACK_DEP_PTR, align 4
  %4449 = sub i64 %4448, 1
  store i64 %4449, i64* %STACK_DEP_PTR, align 4
  %4450 = load i64, i64* %STACK_DEP_PTR, align 4
  %4451 = getelementptr i256, i256* %STACK, i64 %4450
  %4452 = load i256, i256* %4451, align 4
  %4453 = load i64, i64* %STACK_DEP_PTR, align 4
  %4454 = sub i64 %4453, 1
  store i64 %4454, i64* %STACK_DEP_PTR, align 4
  %4455 = add i256 %4452, %4447, !pc !160, !intsan !10
  %4456 = trunc i256 %4452 to i64
  %4457 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4456, i256* %4457)
  %4458 = load i256, i256* %4457, align 4
  %4459 = add i256 32, %4452, !pc !161, !intsan !10
  %4460 = and i256 1461501637330902918203684832716283019655932542975, %4458
  %4461 = alloca i256, align 8
  store i256 2, i256* %4461, align 4
  %4462 = alloca i256, align 8
  call void @__device_sload(i256* %4461, i256* %4462)
  %4463 = call i32 @__hashword(i256* %4461)
  %4464 = load i32, i32* %5, align 4
  %4465 = icmp eq i32 %4463, %4464
  %4466 = or i1 false, %4465
  %4467 = load i32, i32* %6, align 4
  %4468 = icmp eq i32 %4463, %4467
  %4469 = or i1 %4466, %4468
  %4470 = load i32, i32* %7, align 4
  %4471 = icmp eq i32 %4463, %4470
  %4472 = or i1 %4469, %4471
  %4473 = load i32, i32* %8, align 4
  %4474 = icmp eq i32 %4463, %4473
  %4475 = or i1 %4472, %4474
  %4476 = load i32, i32* %9, align 4
  %4477 = icmp eq i32 %4463, %4476
  %4478 = or i1 %4475, %4477
  %4479 = load i32, i32* %10, align 4
  %4480 = icmp eq i32 %4463, %4479
  %4481 = or i1 %4478, %4480
  %4482 = load i32, i32* %11, align 4
  %4483 = icmp eq i32 %4463, %4482
  %4484 = or i1 %4481, %4483
  %4485 = load i32, i32* %12, align 4
  %4486 = icmp eq i32 %4463, %4485
  %4487 = or i1 %4484, %4486
  %4488 = load i32, i32* %13, align 4
  %4489 = icmp eq i32 %4463, %4488
  %4490 = or i1 %4487, %4489
  %4491 = load i32, i32* %14, align 4
  %4492 = icmp eq i32 %4463, %4491
  %4493 = or i1 %4490, %4492
  %4494 = load i32, i32* %15, align 4
  %4495 = icmp eq i32 %4463, %4494
  %4496 = or i1 %4493, %4495
  %4497 = load i32, i32* %16, align 4
  %4498 = icmp eq i32 %4463, %4497
  %4499 = or i1 %4496, %4498
  %4500 = load i32, i32* %17, align 4
  %4501 = icmp eq i32 %4463, %4500
  %4502 = or i1 %4499, %4501
  %4503 = load i32, i32* %18, align 4
  %4504 = icmp eq i32 %4463, %4503
  %4505 = or i1 %4502, %4504
  %4506 = load i32, i32* %19, align 4
  %4507 = icmp eq i32 %4463, %4506
  %4508 = or i1 %4505, %4507
  %4509 = load i32, i32* %20, align 4
  %4510 = icmp eq i32 %4463, %4509
  %4511 = or i1 %4508, %4510
  %4512 = load i32, i32* %21, align 4
  %4513 = icmp eq i32 %4463, %4512
  %4514 = or i1 %4511, %4513
  %4515 = load i32, i32* %22, align 4
  %4516 = icmp eq i32 %4463, %4515
  %4517 = or i1 %4514, %4516
  %4518 = load i32, i32* %23, align 4
  %4519 = icmp eq i32 %4463, %4518
  %4520 = or i1 %4517, %4519
  %4521 = load i32, i32* %24, align 4
  %4522 = icmp eq i32 %4463, %4521
  %4523 = or i1 %4520, %4522
  %4524 = load i32, i32* %25, align 4
  %4525 = icmp eq i32 %4463, %4524
  %4526 = or i1 %4523, %4525
  %4527 = load i32, i32* %26, align 4
  %4528 = icmp eq i32 %4463, %4527
  %4529 = or i1 %4526, %4528
  %4530 = load i32, i32* %27, align 4
  %4531 = icmp eq i32 %4463, %4530
  %4532 = or i1 %4529, %4531
  %4533 = load i32, i32* %28, align 4
  %4534 = icmp eq i32 %4463, %4533
  %4535 = or i1 %4532, %4534
  %4536 = load i32, i32* %29, align 4
  %4537 = icmp eq i32 %4463, %4536
  %4538 = or i1 %4535, %4537
  %4539 = load i32, i32* %30, align 4
  %4540 = icmp eq i32 %4463, %4539
  %4541 = or i1 %4538, %4540
  %4542 = load i32, i32* %31, align 4
  %4543 = icmp eq i32 %4463, %4542
  %4544 = or i1 %4541, %4543
  %4545 = load i32, i32* %32, align 4
  %4546 = icmp eq i32 %4463, %4545
  %4547 = or i1 %4544, %4546
  %4548 = load i32, i32* %33, align 4
  %4549 = icmp eq i32 %4463, %4548
  %4550 = or i1 %4547, %4549
  %4551 = load i32, i32* %34, align 4
  %4552 = icmp eq i32 %4463, %4551
  %4553 = or i1 %4550, %4552
  %4554 = load i32, i32* %35, align 4
  %4555 = icmp eq i32 %4463, %4554
  %4556 = or i1 %4553, %4555
  %4557 = load i32, i32* %36, align 4
  %4558 = icmp eq i32 %4463, %4557
  %4559 = or i1 %4556, %4558
  %4560 = load i32, i32* %37, align 4
  %4561 = icmp eq i32 %4463, %4560
  %4562 = or i1 %4559, %4561
  %4563 = load i32, i32* %38, align 4
  %4564 = icmp eq i32 %4463, %4563
  %4565 = or i1 %4562, %4564
  %4566 = load i32, i32* %39, align 4
  %4567 = icmp eq i32 %4463, %4566
  %4568 = or i1 %4565, %4567
  %4569 = load i32, i32* %40, align 4
  %4570 = icmp eq i32 %4463, %4569
  %4571 = or i1 %4568, %4570
  %4572 = load i32, i32* %41, align 4
  %4573 = icmp eq i32 %4463, %4572
  %4574 = or i1 %4571, %4573
  %4575 = load i32, i32* %42, align 4
  %4576 = icmp eq i32 %4463, %4575
  %4577 = or i1 %4574, %4576
  %4578 = load i32, i32* %43, align 4
  %4579 = icmp eq i32 %4463, %4578
  %4580 = or i1 %4577, %4579
  %4581 = load i32, i32* %44, align 4
  %4582 = icmp eq i32 %4463, %4581
  %4583 = or i1 %4580, %4582
  %4584 = load i32, i32* %45, align 4
  %4585 = icmp eq i32 %4463, %4584
  %4586 = or i1 %4583, %4585
  %4587 = load i32, i32* %46, align 4
  %4588 = icmp eq i32 %4463, %4587
  %4589 = or i1 %4586, %4588
  %4590 = load i32, i32* %47, align 4
  %4591 = icmp eq i32 %4463, %4590
  %4592 = or i1 %4589, %4591
  %4593 = load i32, i32* %48, align 4
  %4594 = icmp eq i32 %4463, %4593
  %4595 = or i1 %4592, %4594
  %4596 = load i32, i32* %49, align 4
  %4597 = icmp eq i32 %4463, %4596
  %4598 = or i1 %4595, %4597
  %4599 = load i32, i32* %50, align 4
  %4600 = icmp eq i32 %4463, %4599
  %4601 = or i1 %4598, %4600
  %4602 = load i32, i32* %51, align 4
  %4603 = icmp eq i32 %4463, %4602
  %4604 = or i1 %4601, %4603
  %4605 = load i32, i32* %52, align 4
  %4606 = icmp eq i32 %4463, %4605
  %4607 = or i1 %4604, %4606
  %4608 = load i32, i32* %53, align 4
  %4609 = icmp eq i32 %4463, %4608
  %4610 = or i1 %4607, %4609
  %4611 = load i32, i32* %54, align 4
  %4612 = icmp eq i32 %4463, %4611
  %4613 = or i1 %4610, %4612
  %4614 = load i32, i32* %55, align 4
  %4615 = icmp eq i32 %4463, %4614
  %4616 = or i1 %4613, %4615
  %4617 = load i32, i32* %56, align 4
  %4618 = icmp eq i32 %4463, %4617
  %4619 = or i1 %4616, %4618
  %4620 = load i32, i32* %57, align 4
  %4621 = icmp eq i32 %4463, %4620
  %4622 = or i1 %4619, %4621
  %4623 = load i32, i32* %58, align 4
  %4624 = icmp eq i32 %4463, %4623
  %4625 = or i1 %4622, %4624
  %4626 = load i32, i32* %59, align 4
  %4627 = icmp eq i32 %4463, %4626
  %4628 = or i1 %4625, %4627
  %4629 = load i32, i32* %60, align 4
  %4630 = icmp eq i32 %4463, %4629
  %4631 = or i1 %4628, %4630
  %4632 = load i32, i32* %61, align 4
  %4633 = icmp eq i32 %4463, %4632
  %4634 = or i1 %4631, %4633
  %4635 = load i32, i32* %62, align 4
  %4636 = icmp eq i32 %4463, %4635
  %4637 = or i1 %4634, %4636
  %4638 = getelementptr i8, i8 addrspace(1)* %4, i32 2
  %4639 = zext i1 %4637 to i8
  store i8 %4639, i8 addrspace(1)* %4638, align 1, !nosanitize !3
  %4640 = load i256, i256* %4462, align 4
  %4641 = add i256 175000, %4640, !pc !162, !intsan !10
  %4642 = trunc i256 64 to i64
  %4643 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4642, i256* %4643)
  %4644 = load i256, i256* %4643, align 4
  %4645 = and i256 4294967295, 787721420
  %4646 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %4645, !pc !163, !intsan !45
  %4647 = trunc i256 %4644 to i64
  %4648 = alloca i256, align 8
  store i256 %4646, i256* %4648, align 4
  %4649 = bitcast i256* %4648 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4647, i8* %4649, i64 32)
  %4650 = add i256 4, %4644, !pc !164, !intsan !10
  %4651 = add i256 32, %4650, !pc !165, !intsan !10
  %4652 = trunc i256 %4651 to i64
  %4653 = alloca i256, align 8
  store i256 %4641, i256* %4653, align 4
  %4654 = bitcast i256* %4653 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4652, i8* %4654, i64 32)
  %4655 = add i256 32, %4651, !pc !166, !intsan !10
  %4656 = sub i256 %4655, %4650, !pc !167, !intsan !8
  %4657 = trunc i256 %4650 to i64
  %4658 = alloca i256, align 8
  store i256 %4656, i256* %4658, align 4
  %4659 = bitcast i256* %4658 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4657, i8* %4659, i64 32)
  %4660 = trunc i256 %4655 to i64
  %4661 = alloca i256, align 8
  store i256 3, i256* %4661, align 4
  %4662 = bitcast i256* %4661 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4660, i8* %4662, i64 32)
  %4663 = add i256 32, %4655, !pc !168, !intsan !10
  %4664 = trunc i256 %4663 to i64
  %4665 = alloca i256, align 8
  store i256 38591998121611826609606229052672359276638289559839154232670315000474409893888, i256* %4665, align 4
  %4666 = bitcast i256* %4665 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %4664, i8* %4666, i64 32)
  %4667 = add i256 32, %4663, !pc !169, !intsan !10
  %4668 = trunc i256 64 to i64
  %4669 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4668, i256* %4669)
  %4670 = load i256, i256* %4669, align 4
  %4671 = sub i256 %4667, %4670, !pc !170, !intsan !8
  %4672 = icmp eq i256 1, 0
  %4673 = icmp eq i1 %4672, false
  %4674 = trunc i256 3488 to i64
  %jump.check19 = icmp ne i1 %4673, false
  %4675 = load i64, i64* %STACK_DEP_PTR, align 4
  %4676 = add i64 %4675, 1
  store i64 %4676, i64* %STACK_DEP_PTR, align 4
  %4677 = load i64, i64* %STACK_DEP_PTR, align 4
  %4678 = getelementptr i256, i256* %STACK, i64 %4677
  store i256 %4460, i256* %4678, align 4
  %4679 = load i64, i64* %STACK_DEP_PTR, align 4
  %4680 = add i64 %4679, 1
  store i64 %4680, i64* %STACK_DEP_PTR, align 4
  %4681 = load i64, i64* %STACK_DEP_PTR, align 4
  %4682 = getelementptr i256, i256* %STACK, i64 %4681
  store i256 787721420, i256* %4682, align 4
  %4683 = load i64, i64* %STACK_DEP_PTR, align 4
  %4684 = add i64 %4683, 1
  store i64 %4684, i64* %STACK_DEP_PTR, align 4
  %4685 = load i64, i64* %STACK_DEP_PTR, align 4
  %4686 = getelementptr i256, i256* %STACK, i64 %4685
  store i256 %4667, i256* %4686, align 4
  %4687 = load i64, i64* %STACK_DEP_PTR, align 4
  %4688 = add i64 %4687, 1
  store i64 %4688, i64* %STACK_DEP_PTR, align 4
  %4689 = load i64, i64* %STACK_DEP_PTR, align 4
  %4690 = getelementptr i256, i256* %STACK, i64 %4689
  store i256 32, i256* %4690, align 4
  %4691 = load i64, i64* %STACK_DEP_PTR, align 4
  %4692 = add i64 %4691, 1
  store i64 %4692, i64* %STACK_DEP_PTR, align 4
  %4693 = load i64, i64* %STACK_DEP_PTR, align 4
  %4694 = getelementptr i256, i256* %STACK, i64 %4693
  store i256 %4670, i256* %4694, align 4
  %4695 = load i64, i64* %STACK_DEP_PTR, align 4
  %4696 = add i64 %4695, 1
  store i64 %4696, i64* %STACK_DEP_PTR, align 4
  %4697 = load i64, i64* %STACK_DEP_PTR, align 4
  %4698 = getelementptr i256, i256* %STACK, i64 %4697
  store i256 %4671, i256* %4698, align 4
  %4699 = load i64, i64* %STACK_DEP_PTR, align 4
  %4700 = add i64 %4699, 1
  store i64 %4700, i64* %STACK_DEP_PTR, align 4
  %4701 = load i64, i64* %STACK_DEP_PTR, align 4
  %4702 = getelementptr i256, i256* %STACK, i64 %4701
  store i256 %4670, i256* %4702, align 4
  %4703 = load i64, i64* %STACK_DEP_PTR, align 4
  %4704 = add i64 %4703, 1
  store i64 %4704, i64* %STACK_DEP_PTR, align 4
  %4705 = load i64, i64* %STACK_DEP_PTR, align 4
  %4706 = getelementptr i256, i256* %STACK, i64 %4705
  store i256 0, i256* %4706, align 4
  %4707 = load i64, i64* %STACK_DEP_PTR, align 4
  %4708 = add i64 %4707, 1
  store i64 %4708, i64* %STACK_DEP_PTR, align 4
  %4709 = load i64, i64* %STACK_DEP_PTR, align 4
  %4710 = getelementptr i256, i256* %STACK, i64 %4709
  store i256 %4460, i256* %4710, align 4
  %4711 = load i64, i64* %STACK_DEP_PTR, align 4
  %4712 = add i64 %4711, 1
  store i64 %4712, i64* %STACK_DEP_PTR, align 4
  %4713 = zext i1 %4672 to i256
  %4714 = load i64, i64* %STACK_DEP_PTR, align 4
  %4715 = getelementptr i256, i256* %STACK, i64 %4714
  store i256 %4713, i256* %4715, align 4
  br i1 %jump.check19, label %.3488, label %.3484, !EVMBB !4

.3484:                                            ; preds = %4438
  %4716 = load i64, i64* %remaing_gas, align 4
  %4717 = icmp ugt i64 40, %4716
  br i1 %4717, label %Abort, label %4718

4718:                                             ; preds = %.3484
  %4719 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4720 = xor i32 %4719, 2272
  %4721 = urem i32 %4720, 4096
  %4722 = getelementptr i8, i8 addrspace(1)* %4, i32 %4721
  %4723 = load i8, i8 addrspace(1)* %4722, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4722, align 1, !nosanitize !3
  store i32 1136, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4724 = sub i64 %4716, 40
  store i64 %4724, i64* %remaing_gas, align 4
  %4725 = load i64, i64* %STACK_DEP_PTR, align 4
  %4726 = sub i64 %4725, 0
  store i64 %4726, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3488:                                            ; preds = %4438, %JumpTable
  %4727 = load i64, i64* %remaing_gas, align 4
  %4728 = icmp ugt i64 456, %4727
  br i1 %4728, label %Abort, label %4729

4729:                                             ; preds = %.3488
  %4730 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4731 = xor i32 %4730, 2681
  %4732 = urem i32 %4731, 4096
  %4733 = getelementptr i8, i8 addrspace(1)* %4, i32 %4732
  %4734 = load i8, i8 addrspace(1)* %4733, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4733, align 1, !nosanitize !3
  store i32 1340, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4735 = sub i64 %4727, 456
  store i64 %4735, i64* %remaing_gas, align 4
  %4736 = load i64, i64* %STACK_DEP_PTR, align 4
  %4737 = getelementptr i256, i256* %STACK, i64 %4736
  %4738 = load i256, i256* %4737, align 4
  %4739 = load i64, i64* %STACK_DEP_PTR, align 4
  %4740 = sub i64 %4739, 1
  store i64 %4740, i64* %STACK_DEP_PTR, align 4
  %4741 = load i64, i64* %STACK_DEP_PTR, align 4
  %4742 = getelementptr i256, i256* %STACK, i64 %4741
  %4743 = load i256, i256* %4742, align 4
  %4744 = load i64, i64* %STACK_DEP_PTR, align 4
  %4745 = sub i64 %4744, 1
  store i64 %4745, i64* %STACK_DEP_PTR, align 4
  %4746 = load i64, i64* %STACK_DEP_PTR, align 4
  %4747 = getelementptr i256, i256* %STACK, i64 %4746
  %4748 = load i256, i256* %4747, align 4
  %4749 = load i64, i64* %STACK_DEP_PTR, align 4
  %4750 = sub i64 %4749, 1
  store i64 %4750, i64* %STACK_DEP_PTR, align 4
  %4751 = load i64, i64* %STACK_DEP_PTR, align 4
  %4752 = getelementptr i256, i256* %STACK, i64 %4751
  %4753 = load i256, i256* %4752, align 4
  %4754 = load i64, i64* %STACK_DEP_PTR, align 4
  %4755 = sub i64 %4754, 1
  store i64 %4755, i64* %STACK_DEP_PTR, align 4
  %4756 = load i64, i64* %STACK_DEP_PTR, align 4
  %4757 = getelementptr i256, i256* %STACK, i64 %4756
  %4758 = load i256, i256* %4757, align 4
  %4759 = load i64, i64* %STACK_DEP_PTR, align 4
  %4760 = sub i64 %4759, 1
  store i64 %4760, i64* %STACK_DEP_PTR, align 4
  %4761 = load i64, i64* %STACK_DEP_PTR, align 4
  %4762 = getelementptr i256, i256* %STACK, i64 %4761
  %4763 = load i256, i256* %4762, align 4
  %4764 = load i64, i64* %STACK_DEP_PTR, align 4
  %4765 = sub i64 %4764, 1
  store i64 %4765, i64* %STACK_DEP_PTR, align 4
  %4766 = load i64, i64* %STACK_DEP_PTR, align 4
  %4767 = getelementptr i256, i256* %STACK, i64 %4766
  %4768 = load i256, i256* %4767, align 4
  %4769 = load i64, i64* %STACK_DEP_PTR, align 4
  %4770 = sub i64 %4769, 1
  store i64 %4770, i64* %STACK_DEP_PTR, align 4
  %4771 = trunc i256 %4743 to i160
  %4772 = call i1 @solidity_call(), !pc !171
  %4773 = icmp eq i1 %4772, false
  %4774 = icmp eq i1 %4773, false
  %4775 = trunc i256 3508 to i64
  %jump.check24 = icmp ne i1 %4774, false
  %4776 = load i64, i64* %STACK_DEP_PTR, align 4
  %4777 = add i64 %4776, 1
  store i64 %4777, i64* %STACK_DEP_PTR, align 4
  %4778 = zext i1 %4773 to i256
  %4779 = load i64, i64* %STACK_DEP_PTR, align 4
  %4780 = getelementptr i256, i256* %STACK, i64 %4779
  store i256 %4778, i256* %4780, align 4
  br i1 %jump.check24, label %.3508, label %.3499, !EVMBB !4

.3499:                                            ; preds = %4729
  %4781 = load i64, i64* %remaing_gas, align 4
  %4782 = icmp ugt i64 40, %4781
  br i1 %4782, label %Abort, label %4783

4783:                                             ; preds = %.3499
  %4784 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4785 = xor i32 %4784, 3149
  %4786 = urem i32 %4785, 4096
  %4787 = getelementptr i8, i8 addrspace(1)* %4, i32 %4786
  %4788 = load i8, i8 addrspace(1)* %4787, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4787, align 1, !nosanitize !3
  store i32 1574, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4789 = sub i64 %4781, 40
  store i64 %4789, i64* %remaing_gas, align 4
  %4790 = load i64, i64* %STACK_DEP_PTR, align 4
  %4791 = sub i64 %4790, 0
  store i64 %4791, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3508:                                            ; preds = %4729, %JumpTable
  %4792 = load i64, i64* %remaing_gas, align 4
  %4793 = icmp ugt i64 384, %4792
  br i1 %4793, label %Abort, label %4794

4794:                                             ; preds = %.3508
  %4795 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4796 = xor i32 %4795, 2621
  %4797 = urem i32 %4796, 4096
  %4798 = getelementptr i8, i8 addrspace(1)* %4, i32 %4797
  %4799 = load i8, i8 addrspace(1)* %4798, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4798, align 1, !nosanitize !3
  store i32 1310, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4800 = sub i64 %4792, 384
  store i64 %4800, i64* %remaing_gas, align 4
  %4801 = load i64, i64* %STACK_DEP_PTR, align 4
  %4802 = getelementptr i256, i256* %STACK, i64 %4801
  %4803 = load i256, i256* %4802, align 4
  %4804 = load i64, i64* %STACK_DEP_PTR, align 4
  %4805 = sub i64 %4804, 1
  store i64 %4805, i64* %STACK_DEP_PTR, align 4
  %4806 = load i64, i64* %STACK_DEP_PTR, align 4
  %4807 = getelementptr i256, i256* %STACK, i64 %4806
  %4808 = load i256, i256* %4807, align 4
  %4809 = load i64, i64* %STACK_DEP_PTR, align 4
  %4810 = sub i64 %4809, 1
  store i64 %4810, i64* %STACK_DEP_PTR, align 4
  %4811 = load i64, i64* %STACK_DEP_PTR, align 4
  %4812 = getelementptr i256, i256* %STACK, i64 %4811
  %4813 = load i256, i256* %4812, align 4
  %4814 = load i64, i64* %STACK_DEP_PTR, align 4
  %4815 = sub i64 %4814, 1
  store i64 %4815, i64* %STACK_DEP_PTR, align 4
  %4816 = load i64, i64* %STACK_DEP_PTR, align 4
  %4817 = getelementptr i256, i256* %STACK, i64 %4816
  %4818 = load i256, i256* %4817, align 4
  %4819 = load i64, i64* %STACK_DEP_PTR, align 4
  %4820 = sub i64 %4819, 1
  store i64 %4820, i64* %STACK_DEP_PTR, align 4
  %4821 = trunc i256 64 to i64
  %4822 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4821, i256* %4822)
  %4823 = load i256, i256* %4822, align 4
  %4824 = zext i64 0 to i256
  %4825 = icmp ult i256 %4824, 32
  %4826 = icmp eq i1 %4825, false
  %4827 = trunc i256 3530 to i64
  %jump.check29 = icmp ne i1 %4826, false
  %4828 = load i64, i64* %STACK_DEP_PTR, align 4
  %4829 = add i64 %4828, 1
  store i64 %4829, i64* %STACK_DEP_PTR, align 4
  %4830 = load i64, i64* %STACK_DEP_PTR, align 4
  %4831 = getelementptr i256, i256* %STACK, i64 %4830
  store i256 %4823, i256* %4831, align 4
  %4832 = load i64, i64* %STACK_DEP_PTR, align 4
  %4833 = add i64 %4832, 1
  store i64 %4833, i64* %STACK_DEP_PTR, align 4
  %4834 = zext i64 0 to i256
  %4835 = load i64, i64* %STACK_DEP_PTR, align 4
  %4836 = getelementptr i256, i256* %STACK, i64 %4835
  store i256 %4834, i256* %4836, align 4
  br i1 %jump.check29, label %.3530, label %.3526, !EVMBB !4

.3526:                                            ; preds = %4794
  %4837 = load i64, i64* %remaing_gas, align 4
  %4838 = icmp ugt i64 40, %4837
  br i1 %4838, label %Abort, label %4839

4839:                                             ; preds = %.3526
  %4840 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4841 = xor i32 %4840, 2612
  %4842 = urem i32 %4841, 4096
  %4843 = getelementptr i8, i8 addrspace(1)* %4, i32 %4842
  %4844 = load i8, i8 addrspace(1)* %4843, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4843, align 1, !nosanitize !3
  store i32 1306, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4845 = sub i64 %4837, 40
  store i64 %4845, i64* %remaing_gas, align 4
  %4846 = load i64, i64* %STACK_DEP_PTR, align 4
  %4847 = sub i64 %4846, 0
  store i64 %4847, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3530:                                            ; preds = %4794, %JumpTable
  %4848 = load i64, i64* %remaing_gas, align 4
  %4849 = icmp ugt i64 496, %4848
  br i1 %4849, label %Abort, label %4850

4850:                                             ; preds = %.3530
  %4851 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4852 = xor i32 %4851, 3516
  %4853 = urem i32 %4852, 4096
  %4854 = getelementptr i8, i8 addrspace(1)* %4, i32 %4853
  %4855 = load i8, i8 addrspace(1)* %4854, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4854, align 1, !nosanitize !3
  store i32 1758, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4856 = sub i64 %4848, 496
  store i64 %4856, i64* %remaing_gas, align 4
  %4857 = load i64, i64* %STACK_DEP_PTR, align 4
  %4858 = getelementptr i256, i256* %STACK, i64 %4857
  %4859 = load i256, i256* %4858, align 4
  %4860 = load i64, i64* %STACK_DEP_PTR, align 4
  %4861 = sub i64 %4860, 1
  store i64 %4861, i64* %STACK_DEP_PTR, align 4
  %4862 = load i64, i64* %STACK_DEP_PTR, align 4
  %4863 = getelementptr i256, i256* %STACK, i64 %4862
  %4864 = load i256, i256* %4863, align 4
  %4865 = load i64, i64* %STACK_DEP_PTR, align 4
  %4866 = sub i64 %4865, 1
  store i64 %4866, i64* %STACK_DEP_PTR, align 4
  %4867 = load i64, i64* %STACK_DEP_PTR, align 4
  %4868 = getelementptr i256, i256* %STACK, i64 %4867
  %4869 = load i256, i256* %4868, align 4
  %4870 = load i64, i64* %STACK_DEP_PTR, align 4
  %4871 = sub i64 %4870, 1
  store i64 %4871, i64* %STACK_DEP_PTR, align 4
  %4872 = load i64, i64* %STACK_DEP_PTR, align 4
  %4873 = getelementptr i256, i256* %STACK, i64 %4872
  %4874 = load i256, i256* %4873, align 4
  %4875 = load i64, i64* %STACK_DEP_PTR, align 4
  %4876 = sub i64 %4875, 1
  store i64 %4876, i64* %STACK_DEP_PTR, align 4
  %4877 = load i64, i64* %STACK_DEP_PTR, align 4
  %4878 = getelementptr i256, i256* %STACK, i64 %4877
  %4879 = load i256, i256* %4878, align 4
  %4880 = load i64, i64* %STACK_DEP_PTR, align 4
  %4881 = sub i64 %4880, 1
  store i64 %4881, i64* %STACK_DEP_PTR, align 4
  %4882 = add i256 %4864, %4859, !pc !172, !intsan !10
  %4883 = trunc i256 %4864 to i64
  %4884 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %4883, i256* %4884)
  %4885 = load i256, i256* %4884, align 4
  %4886 = add i256 32, %4864, !pc !173, !intsan !10
  %4887 = load i256, i256* %1, align 4
  %4888 = icmp ult i256 %4885, %4887
  %4889 = icmp eq i1 %4888, false
  %4890 = icmp eq i1 %4889, false
  %4891 = trunc i256 3563 to i64
  %jump.check33 = icmp ne i1 %4890, false
  %4892 = load i64, i64* %STACK_DEP_PTR, align 4
  %4893 = add i64 %4892, 1
  store i64 %4893, i64* %STACK_DEP_PTR, align 4
  %4894 = load i64, i64* %STACK_DEP_PTR, align 4
  %4895 = getelementptr i256, i256* %STACK, i64 %4894
  store i256 %4885, i256* %4895, align 4
  %4896 = load i64, i64* %STACK_DEP_PTR, align 4
  %4897 = add i64 %4896, 1
  store i64 %4897, i64* %STACK_DEP_PTR, align 4
  %4898 = load i64, i64* %STACK_DEP_PTR, align 4
  %4899 = getelementptr i256, i256* %STACK, i64 %4898
  store i256 %4874, i256* %4899, align 4
  %4900 = load i64, i64* %STACK_DEP_PTR, align 4
  %4901 = add i64 %4900, 1
  store i64 %4901, i64* %STACK_DEP_PTR, align 4
  %4902 = load i64, i64* %STACK_DEP_PTR, align 4
  %4903 = getelementptr i256, i256* %STACK, i64 %4902
  store i256 %4869, i256* %4903, align 4
  br i1 %jump.check33, label %.3563, label %.3559, !EVMBB !4

.3559:                                            ; preds = %4850
  %4904 = load i64, i64* %remaing_gas, align 4
  %4905 = icmp ugt i64 40, %4904
  br i1 %4905, label %Abort, label %4906

4906:                                             ; preds = %.3559
  %4907 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4908 = xor i32 %4907, 3679
  %4909 = urem i32 %4908, 4096
  %4910 = getelementptr i8, i8 addrspace(1)* %4, i32 %4909
  %4911 = load i8, i8 addrspace(1)* %4910, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4910, align 1, !nosanitize !3
  store i32 1839, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4912 = sub i64 %4904, 40
  store i64 %4912, i64* %remaing_gas, align 4
  %4913 = load i64, i64* %STACK_DEP_PTR, align 4
  %4914 = sub i64 %4913, 0
  store i64 %4914, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.3563:                                            ; preds = %4850, %JumpTable
  %4915 = load i64, i64* %remaing_gas, align 4
  %4916 = icmp ugt i64 424, %4915
  br i1 %4916, label %Abort, label %4917

4917:                                             ; preds = %.3563
  %4918 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4919 = xor i32 %4918, 2894
  %4920 = urem i32 %4919, 4096
  %4921 = getelementptr i8, i8 addrspace(1)* %4, i32 %4920
  %4922 = load i8, i8 addrspace(1)* %4921, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4921, align 1, !nosanitize !3
  store i32 1447, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4923 = sub i64 %4915, 424
  store i64 %4923, i64* %remaing_gas, align 4
  %4924 = load i64, i64* %STACK_DEP_PTR, align 4
  %4925 = getelementptr i256, i256* %STACK, i64 %4924
  %4926 = load i256, i256* %4925, align 4
  %4927 = load i64, i64* %STACK_DEP_PTR, align 4
  %4928 = sub i64 %4927, 1
  store i64 %4928, i64* %STACK_DEP_PTR, align 4
  %4929 = load i64, i64* %STACK_DEP_PTR, align 4
  %4930 = getelementptr i256, i256* %STACK, i64 %4929
  %4931 = load i256, i256* %4930, align 4
  %4932 = load i64, i64* %STACK_DEP_PTR, align 4
  %4933 = sub i64 %4932, 1
  store i64 %4933, i64* %STACK_DEP_PTR, align 4
  %4934 = load i64, i64* %STACK_DEP_PTR, align 4
  %4935 = getelementptr i256, i256* %STACK, i64 %4934
  %4936 = load i256, i256* %4935, align 4
  %4937 = load i64, i64* %STACK_DEP_PTR, align 4
  %4938 = sub i64 %4937, 1
  store i64 %4938, i64* %STACK_DEP_PTR, align 4
  %4939 = load i256, i256* %1, align 4
  %4940 = sub i256 %4939, %4936, !pc !174, !intsan !8
  %4941 = trunc i256 4367 to i64
  %4942 = load i64, i64* %STACK_DEP_PTR, align 4
  %4943 = add i64 %4942, 1
  store i64 %4943, i64* %STACK_DEP_PTR, align 4
  %4944 = load i64, i64* %STACK_DEP_PTR, align 4
  %4945 = getelementptr i256, i256* %STACK, i64 %4944
  store i256 %4936, i256* %4945, align 4
  %4946 = load i64, i64* %STACK_DEP_PTR, align 4
  %4947 = add i64 %4946, 1
  store i64 %4947, i64* %STACK_DEP_PTR, align 4
  %4948 = load i64, i64* %STACK_DEP_PTR, align 4
  %4949 = getelementptr i256, i256* %STACK, i64 %4948
  store i256 %4940, i256* %4949, align 4
  %4950 = load i64, i64* %STACK_DEP_PTR, align 4
  %4951 = add i64 %4950, 1
  store i64 %4951, i64* %STACK_DEP_PTR, align 4
  %4952 = load i64, i64* %STACK_DEP_PTR, align 4
  %4953 = getelementptr i256, i256* %STACK, i64 %4952
  store i256 %4926, i256* %4953, align 4
  %4954 = load i64, i64* %STACK_DEP_PTR, align 4
  %4955 = add i64 %4954, 1
  store i64 %4955, i64* %STACK_DEP_PTR, align 4
  %4956 = load i64, i64* %STACK_DEP_PTR, align 4
  %4957 = getelementptr i256, i256* %STACK, i64 %4956
  store i256 10000, i256* %4957, align 4
  %4958 = load i64, i64* %STACK_DEP_PTR, align 4
  %4959 = add i64 %4958, 1
  store i64 %4959, i64* %STACK_DEP_PTR, align 4
  %4960 = load i64, i64* %STACK_DEP_PTR, align 4
  %4961 = getelementptr i256, i256* %STACK, i64 %4960
  store i256 3579, i256* %4961, align 4
  br label %.4367, !EVMBB !4

.3579:                                            ; preds = %JumpTable
  %4962 = load i64, i64* %remaing_gas, align 4
  %4963 = icmp ugt i64 248, %4962
  br i1 %4963, label %Abort, label %4964

4964:                                             ; preds = %.3579
  %4965 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4966 = xor i32 %4965, 631
  %4967 = urem i32 %4966, 4096
  %4968 = getelementptr i8, i8 addrspace(1)* %4, i32 %4967
  %4969 = load i8, i8 addrspace(1)* %4968, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4968, align 1, !nosanitize !3
  store i32 315, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4970 = sub i64 %4962, 248
  store i64 %4970, i64* %remaing_gas, align 4
  %4971 = load i64, i64* %STACK_DEP_PTR, align 4
  %4972 = getelementptr i256, i256* %STACK, i64 %4971
  %4973 = load i256, i256* %4972, align 4
  %4974 = load i64, i64* %STACK_DEP_PTR, align 4
  %4975 = sub i64 %4974, 1
  store i64 %4975, i64* %STACK_DEP_PTR, align 4
  %4976 = load i64, i64* %STACK_DEP_PTR, align 4
  %4977 = getelementptr i256, i256* %STACK, i64 %4976
  %4978 = load i256, i256* %4977, align 4
  %4979 = load i64, i64* %STACK_DEP_PTR, align 4
  %4980 = sub i64 %4979, 1
  store i64 %4980, i64* %STACK_DEP_PTR, align 4
  %4981 = mul i256 100, %4973, !pc !175, !intsan !45
  %4982 = icmp eq i256 %4978, 0
  %4983 = icmp eq i1 %4982, false
  %4984 = trunc i256 3591 to i64
  %jump.check39 = icmp ne i1 %4983, false
  %4985 = load i64, i64* %STACK_DEP_PTR, align 4
  %4986 = add i64 %4985, 1
  store i64 %4986, i64* %STACK_DEP_PTR, align 4
  %4987 = load i64, i64* %STACK_DEP_PTR, align 4
  %4988 = getelementptr i256, i256* %STACK, i64 %4987
  store i256 %4978, i256* %4988, align 4
  %4989 = load i64, i64* %STACK_DEP_PTR, align 4
  %4990 = add i64 %4989, 1
  store i64 %4990, i64* %STACK_DEP_PTR, align 4
  %4991 = load i64, i64* %STACK_DEP_PTR, align 4
  %4992 = getelementptr i256, i256* %STACK, i64 %4991
  store i256 %4981, i256* %4992, align 4
  br i1 %jump.check39, label %.3591, label %.3590, !EVMBB !4

.3590:                                            ; preds = %4964
  %4993 = load i64, i64* %remaing_gas, align 4
  %4994 = icmp ugt i64 16, %4993
  br i1 %4994, label %Abort, label %4995

4995:                                             ; preds = %.3590
  %4996 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %4997 = xor i32 %4996, 1530
  %4998 = urem i32 %4997, 4096
  %4999 = getelementptr i8, i8 addrspace(1)* %4, i32 %4998
  %5000 = load i8, i8 addrspace(1)* %4999, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %4999, align 1, !nosanitize !3
  store i32 765, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5001 = sub i64 %4993, 16
  store i64 %5001, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.3591:                                            ; preds = %4964, %JumpTable
  %5002 = load i64, i64* %remaing_gas, align 4
  %5003 = icmp ugt i64 560, %5002
  br i1 %5003, label %Abort, label %5004

5004:                                             ; preds = %.3591
  %5005 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5006 = xor i32 %5005, 3019
  %5007 = urem i32 %5006, 4096
  %5008 = getelementptr i8, i8 addrspace(1)* %4, i32 %5007
  %5009 = load i8, i8 addrspace(1)* %5008, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5008, align 1, !nosanitize !3
  store i32 1509, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5010 = sub i64 %5002, 560
  store i64 %5010, i64* %remaing_gas, align 4
  %5011 = load i64, i64* %STACK_DEP_PTR, align 4
  %5012 = getelementptr i256, i256* %STACK, i64 %5011
  %5013 = load i256, i256* %5012, align 4
  %5014 = load i64, i64* %STACK_DEP_PTR, align 4
  %5015 = sub i64 %5014, 1
  store i64 %5015, i64* %STACK_DEP_PTR, align 4
  %5016 = load i64, i64* %STACK_DEP_PTR, align 4
  %5017 = getelementptr i256, i256* %STACK, i64 %5016
  %5018 = load i256, i256* %5017, align 4
  %5019 = load i64, i64* %STACK_DEP_PTR, align 4
  %5020 = sub i64 %5019, 1
  store i64 %5020, i64* %STACK_DEP_PTR, align 4
  %5021 = load i64, i64* %STACK_DEP_PTR, align 4
  %5022 = getelementptr i256, i256* %STACK, i64 %5021
  %5023 = load i256, i256* %5022, align 4
  %5024 = load i64, i64* %STACK_DEP_PTR, align 4
  %5025 = sub i64 %5024, 1
  store i64 %5025, i64* %STACK_DEP_PTR, align 4
  %5026 = load i64, i64* %STACK_DEP_PTR, align 4
  %5027 = getelementptr i256, i256* %STACK, i64 %5026
  %5028 = load i256, i256* %5027, align 4
  %5029 = load i64, i64* %STACK_DEP_PTR, align 4
  %5030 = sub i64 %5029, 1
  store i64 %5030, i64* %STACK_DEP_PTR, align 4
  %5031 = alloca i256, align 8
  store i256 %5013, i256* %5031, align 4
  %5032 = alloca i256, align 8
  store i256 %5018, i256* %5032, align 4
  %5033 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %5031, i256* %5032, i256* %5033), !pc !176, !intsan !6
  %5034 = load i256, i256* %5033, align 4
  %5035 = sub i256 10000, 190, !pc !177, !intsan !8
  %5036 = sub i256 %5035, 7500, !pc !178, !intsan !8
  %5037 = mul i256 %5028, %5036, !pc !179, !intsan !45
  %5038 = icmp eq i256 7500, 0
  %5039 = icmp eq i1 %5038, false
  %5040 = trunc i256 3614 to i64
  %jump.check43 = icmp ne i1 %5039, false
  %5041 = load i64, i64* %STACK_DEP_PTR, align 4
  %5042 = add i64 %5041, 1
  store i64 %5042, i64* %STACK_DEP_PTR, align 4
  %5043 = load i64, i64* %STACK_DEP_PTR, align 4
  %5044 = getelementptr i256, i256* %STACK, i64 %5043
  store i256 %5028, i256* %5044, align 4
  %5045 = load i64, i64* %STACK_DEP_PTR, align 4
  %5046 = add i64 %5045, 1
  store i64 %5046, i64* %STACK_DEP_PTR, align 4
  %5047 = load i64, i64* %STACK_DEP_PTR, align 4
  %5048 = getelementptr i256, i256* %STACK, i64 %5047
  store i256 %5023, i256* %5048, align 4
  %5049 = load i64, i64* %STACK_DEP_PTR, align 4
  %5050 = add i64 %5049, 1
  store i64 %5050, i64* %STACK_DEP_PTR, align 4
  %5051 = load i64, i64* %STACK_DEP_PTR, align 4
  %5052 = getelementptr i256, i256* %STACK, i64 %5051
  store i256 %5034, i256* %5052, align 4
  %5053 = load i64, i64* %STACK_DEP_PTR, align 4
  %5054 = add i64 %5053, 1
  store i64 %5054, i64* %STACK_DEP_PTR, align 4
  %5055 = load i64, i64* %STACK_DEP_PTR, align 4
  %5056 = getelementptr i256, i256* %STACK, i64 %5055
  store i256 7500, i256* %5056, align 4
  %5057 = load i64, i64* %STACK_DEP_PTR, align 4
  %5058 = add i64 %5057, 1
  store i64 %5058, i64* %STACK_DEP_PTR, align 4
  %5059 = load i64, i64* %STACK_DEP_PTR, align 4
  %5060 = getelementptr i256, i256* %STACK, i64 %5059
  store i256 %5037, i256* %5060, align 4
  br i1 %jump.check43, label %.3614, label %.3613, !EVMBB !4

.3613:                                            ; preds = %5004
  %5061 = load i64, i64* %remaing_gas, align 4
  %5062 = icmp ugt i64 16, %5061
  br i1 %5062, label %Abort, label %5063

5063:                                             ; preds = %.3613
  %5064 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5065 = xor i32 %5064, 2156
  %5066 = urem i32 %5065, 4096
  %5067 = getelementptr i8, i8 addrspace(1)* %4, i32 %5066
  %5068 = load i8, i8 addrspace(1)* %5067, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5067, align 1, !nosanitize !3
  store i32 1078, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5069 = sub i64 %5061, 16
  store i64 %5069, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.3614:                                            ; preds = %5004, %JumpTable
  %5070 = load i64, i64* %remaing_gas, align 4
  %5071 = icmp ugt i64 312, %5070
  br i1 %5071, label %Abort, label %5072

5072:                                             ; preds = %.3614
  %5073 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5074 = xor i32 %5073, 3333
  %5075 = urem i32 %5074, 4096
  %5076 = getelementptr i8, i8 addrspace(1)* %4, i32 %5075
  %5077 = load i8, i8 addrspace(1)* %5076, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5076, align 1, !nosanitize !3
  store i32 1666, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5078 = sub i64 %5070, 312
  store i64 %5078, i64* %remaing_gas, align 4
  %5079 = load i64, i64* %STACK_DEP_PTR, align 4
  %5080 = getelementptr i256, i256* %STACK, i64 %5079
  %5081 = load i256, i256* %5080, align 4
  %5082 = load i64, i64* %STACK_DEP_PTR, align 4
  %5083 = sub i64 %5082, 1
  store i64 %5083, i64* %STACK_DEP_PTR, align 4
  %5084 = load i64, i64* %STACK_DEP_PTR, align 4
  %5085 = getelementptr i256, i256* %STACK, i64 %5084
  %5086 = load i256, i256* %5085, align 4
  %5087 = load i64, i64* %STACK_DEP_PTR, align 4
  %5088 = sub i64 %5087, 1
  store i64 %5088, i64* %STACK_DEP_PTR, align 4
  %5089 = load i64, i64* %STACK_DEP_PTR, align 4
  %5090 = getelementptr i256, i256* %STACK, i64 %5089
  %5091 = load i256, i256* %5090, align 4
  %5092 = load i64, i64* %STACK_DEP_PTR, align 4
  %5093 = sub i64 %5092, 1
  store i64 %5093, i64* %STACK_DEP_PTR, align 4
  %5094 = alloca i256, align 8
  store i256 %5081, i256* %5094, align 4
  %5095 = alloca i256, align 8
  store i256 %5086, i256* %5095, align 4
  %5096 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %5094, i256* %5095, i256* %5096), !pc !180, !intsan !6
  %5097 = load i256, i256* %5096, align 4
  %5098 = icmp ugt i256 %5097, %5091
  %5099 = icmp eq i1 %5098, false
  %5100 = icmp eq i1 %5099, false
  %5101 = trunc i256 3637 to i64
  %jump.check49 = icmp ne i1 %5100, false
  %5102 = load i64, i64* %STACK_DEP_PTR, align 4
  %5103 = add i64 %5102, 1
  store i64 %5103, i64* %STACK_DEP_PTR, align 4
  %5104 = zext i1 %5099 to i256
  %5105 = load i64, i64* %STACK_DEP_PTR, align 4
  %5106 = getelementptr i256, i256* %STACK, i64 %5105
  store i256 %5104, i256* %5106, align 4
  br i1 %jump.check49, label %.3637, label %.3624, !EVMBB !4

.3624:                                            ; preds = %5072
  %5107 = load i64, i64* %STACK_DEP_PTR, align 4
  %5108 = sub i64 %5107, 1
  store i64 %5108, i64* %STACK_DEP_PTR, align 4
  %5109 = load i64, i64* %STACK_DEP_PTR, align 4
  %5110 = getelementptr i256, i256* %STACK, i64 %5109
  %5111 = load i256, i256* %5110, align 4
  %5112 = load i64, i64* %STACK_DEP_PTR, align 4
  %5113 = sub i64 %5112, 1
  store i64 %5113, i64* %STACK_DEP_PTR, align 4
  %5114 = load i64, i64* %STACK_DEP_PTR, align 4
  %5115 = getelementptr i256, i256* %STACK, i64 %5114
  %5116 = load i256, i256* %5115, align 4
  %5117 = load i64, i64* %STACK_DEP_PTR, align 4
  %5118 = sub i64 %5117, 1
  store i64 %5118, i64* %STACK_DEP_PTR, align 4
  %5119 = icmp ult i256 %5116, 200000000000000000
  %5120 = icmp eq i1 %5119, false
  %5121 = load i64, i64* %STACK_DEP_PTR, align 4
  %5122 = add i64 %5121, 1
  store i64 %5122, i64* %STACK_DEP_PTR, align 4
  %5123 = load i64, i64* %STACK_DEP_PTR, align 4
  %5124 = getelementptr i256, i256* %STACK, i64 %5123
  store i256 %5116, i256* %5124, align 4
  %5125 = load i64, i64* %STACK_DEP_PTR, align 4
  %5126 = add i64 %5125, 1
  store i64 %5126, i64* %STACK_DEP_PTR, align 4
  %5127 = load i64, i64* %STACK_DEP_PTR, align 4
  %5128 = getelementptr i256, i256* %STACK, i64 %5127
  store i256 %5111, i256* %5128, align 4
  %5129 = load i64, i64* %STACK_DEP_PTR, align 4
  %5130 = add i64 %5129, 1
  store i64 %5130, i64* %STACK_DEP_PTR, align 4
  %5131 = zext i1 %5120 to i256
  %5132 = load i64, i64* %STACK_DEP_PTR, align 4
  %5133 = getelementptr i256, i256* %STACK, i64 %5132
  store i256 %5131, i256* %5133, align 4
  br label %.3637

.3637:                                            ; preds = %.3624, %5072, %JumpTable
  %5134 = load i64, i64* %remaing_gas, align 4
  %5135 = icmp ugt i64 88, %5134
  br i1 %5135, label %Abort, label %5136

5136:                                             ; preds = %.3637
  %5137 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5138 = xor i32 %5137, 2732
  %5139 = urem i32 %5138, 4096
  %5140 = getelementptr i8, i8 addrspace(1)* %4, i32 %5139
  %5141 = load i8, i8 addrspace(1)* %5140, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5140, align 1, !nosanitize !3
  store i32 1366, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5142 = sub i64 %5134, 88
  store i64 %5142, i64* %remaing_gas, align 4
  %5143 = load i64, i64* %STACK_DEP_PTR, align 4
  %5144 = getelementptr i256, i256* %STACK, i64 %5143
  %5145 = load i256, i256* %5144, align 4
  %5146 = load i64, i64* %STACK_DEP_PTR, align 4
  %5147 = sub i64 %5146, 1
  store i64 %5147, i64* %STACK_DEP_PTR, align 4
  %5148 = icmp eq i256 %5145, 0
  %5149 = trunc i256 4077 to i64
  %jump.check56 = icmp ne i1 %5148, false
  br i1 %jump.check56, label %.4077, label %.3643, !EVMBB !4

.3643:                                            ; preds = %5136
  %5150 = load i64, i64* %remaing_gas, align 4
  %5151 = icmp ugt i64 1096, %5150
  br i1 %5151, label %Abort, label %5152

5152:                                             ; preds = %.3643
  %5153 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5154 = xor i32 %5153, 1158
  %5155 = urem i32 %5154, 4096
  %5156 = getelementptr i8, i8 addrspace(1)* %4, i32 %5155
  %5157 = load i8, i8 addrspace(1)* %5156, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5156, align 1, !nosanitize !3
  store i32 579, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5158 = sub i64 %5150, 1096
  store i64 %5158, i64* %remaing_gas, align 4
  %5159 = load i64, i64* %STACK_DEP_PTR, align 4
  %5160 = getelementptr i256, i256* %STACK, i64 %5159
  %5161 = load i256, i256* %5160, align 4
  %5162 = load i64, i64* %STACK_DEP_PTR, align 4
  %5163 = sub i64 %5162, 1
  store i64 %5163, i64* %STACK_DEP_PTR, align 4
  %5164 = load i64, i64* %STACK_DEP_PTR, align 4
  %5165 = getelementptr i256, i256* %STACK, i64 %5164
  %5166 = load i256, i256* %5165, align 4
  %5167 = load i64, i64* %STACK_DEP_PTR, align 4
  %5168 = sub i64 %5167, 1
  store i64 %5168, i64* %STACK_DEP_PTR, align 4
  %5169 = load i256, i256* %0, align 4
  %5170 = trunc i256 64 to i64
  %5171 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5170, i256* %5171)
  %5172 = load i256, i256* %5171, align 4
  %5173 = and i256 1461501637330902918203684832716283019655932542975, %5169
  %5174 = and i256 1461501637330902918203684832716283019655932542975, %5173
  %5175 = trunc i256 %5172 to i64
  %5176 = alloca i256, align 8
  store i256 %5174, i256* %5176, align 4
  %5177 = bitcast i256* %5176 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5175, i8* %5177, i64 32)
  %5178 = add i256 32, %5172, !pc !181, !intsan !10
  %5179 = trunc i256 %5178 to i64
  %5180 = alloca i256, align 8
  store i256 %5166, i256* %5180, align 4
  %5181 = bitcast i256* %5180 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5179, i8* %5181, i64 32)
  %5182 = add i256 32, %5178, !pc !182, !intsan !10
  %5183 = trunc i256 64 to i64
  %5184 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5183, i256* %5184)
  %5185 = load i256, i256* %5184, align 4
  %5186 = sub i256 %5182, %5185, !pc !183, !intsan !8
  %5187 = trunc i256 -41803436095364307344568554264756649228613784845191042397155399734293010692940 to i64
  call void @addBugSet(i64 %5187)
  %5188 = trunc i256 64 to i64
  %5189 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5188, i256* %5189)
  %5190 = load i256, i256* %5189, align 4
  %5191 = add i256 %5190, 64, !pc !184, !intsan !10
  %5192 = trunc i256 64 to i64
  %5193 = alloca i256, align 8
  store i256 %5191, i256* %5193, align 4
  %5194 = bitcast i256* %5193 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5192, i8* %5194, i64 32)
  %5195 = trunc i256 %5190 to i64
  %5196 = alloca i256, align 8
  store i256 6, i256* %5196, align 4
  %5197 = bitcast i256* %5196 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5195, i8* %5197, i64 32)
  %5198 = add i256 32, %5190, !pc !185, !intsan !10
  %5199 = trunc i256 %5198 to i64
  %5200 = alloca i256, align 8
  store i256 49933661736563292915120647854337127153619359855875393016731264086304377274368, i256* %5200, align 4
  %5201 = bitcast i256* %5200 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5199, i8* %5201, i64 32)
  %5202 = trunc i256 64 to i64
  %5203 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5202, i256* %5203)
  %5204 = load i256, i256* %5203, align 4
  %5205 = add i256 %5204, 448, !pc !186, !intsan !10
  %5206 = trunc i256 64 to i64
  %5207 = alloca i256, align 8
  store i256 %5205, i256* %5207, align 4
  %5208 = bitcast i256* %5207 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5206, i8* %5208, i64 32)
  %5209 = trunc i256 %5204 to i64
  %5210 = alloca i256, align 8
  store i256 393, i256* %5210, align 4
  %5211 = bitcast i256* %5210 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5209, i8* %5211, i64 32)
  %5212 = add i256 32, %5204, !pc !187, !intsan !10
  %5213 = trunc i256 %5212 to i32
  %5214 = trunc i256 393 to i32
  %5215 = trunc i256 19003 to i32
  %5216 = urem i32 %5213, 728
  %5217 = getelementptr i8, i8* %MEMORY, i32 %5216
  %5218 = add i32 1358, %5215
  %5219 = load i32, i32 addrspace(4)* @__evmCodeSize, align 4
  %5220 = urem i32 %5218, %5219
  %5221 = urem i32 %5214, %5219
  %5222 = add i32 %5220, %5221
  %5223 = icmp ugt i32 %5222, %5219
  %5224 = select i1 %5223, i32 0, i32 %5221
  %5225 = add i32 %5216, %5224
  %5226 = icmp ugt i32 %5225, 728
  %5227 = select i1 %5226, i32 0, i32 %5224
  %5228 = getelementptr [32769 x i8], [32769 x i8] addrspace(4)* @__evmCode, i32 0, i32 %5220
  call void @llvm.memcpy.p0i8.p4i8.i32(i8* %5217, i8 addrspace(4)* %5228, i32 %5227, i1 false)
  %5229 = alloca i256, align 8
  store i256 2, i256* %5229, align 4
  %5230 = alloca i256, align 8
  call void @__device_sload(i256* %5229, i256* %5230)
  %5231 = call i32 @__hashword(i256* %5229)
  %5232 = load i32, i32* %5, align 4
  %5233 = icmp eq i32 %5231, %5232
  %5234 = or i1 false, %5233
  %5235 = load i32, i32* %6, align 4
  %5236 = icmp eq i32 %5231, %5235
  %5237 = or i1 %5234, %5236
  %5238 = load i32, i32* %7, align 4
  %5239 = icmp eq i32 %5231, %5238
  %5240 = or i1 %5237, %5239
  %5241 = load i32, i32* %8, align 4
  %5242 = icmp eq i32 %5231, %5241
  %5243 = or i1 %5240, %5242
  %5244 = load i32, i32* %9, align 4
  %5245 = icmp eq i32 %5231, %5244
  %5246 = or i1 %5243, %5245
  %5247 = load i32, i32* %10, align 4
  %5248 = icmp eq i32 %5231, %5247
  %5249 = or i1 %5246, %5248
  %5250 = load i32, i32* %11, align 4
  %5251 = icmp eq i32 %5231, %5250
  %5252 = or i1 %5249, %5251
  %5253 = load i32, i32* %12, align 4
  %5254 = icmp eq i32 %5231, %5253
  %5255 = or i1 %5252, %5254
  %5256 = load i32, i32* %13, align 4
  %5257 = icmp eq i32 %5231, %5256
  %5258 = or i1 %5255, %5257
  %5259 = load i32, i32* %14, align 4
  %5260 = icmp eq i32 %5231, %5259
  %5261 = or i1 %5258, %5260
  %5262 = load i32, i32* %15, align 4
  %5263 = icmp eq i32 %5231, %5262
  %5264 = or i1 %5261, %5263
  %5265 = load i32, i32* %16, align 4
  %5266 = icmp eq i32 %5231, %5265
  %5267 = or i1 %5264, %5266
  %5268 = load i32, i32* %17, align 4
  %5269 = icmp eq i32 %5231, %5268
  %5270 = or i1 %5267, %5269
  %5271 = load i32, i32* %18, align 4
  %5272 = icmp eq i32 %5231, %5271
  %5273 = or i1 %5270, %5272
  %5274 = load i32, i32* %19, align 4
  %5275 = icmp eq i32 %5231, %5274
  %5276 = or i1 %5273, %5275
  %5277 = load i32, i32* %20, align 4
  %5278 = icmp eq i32 %5231, %5277
  %5279 = or i1 %5276, %5278
  %5280 = load i32, i32* %21, align 4
  %5281 = icmp eq i32 %5231, %5280
  %5282 = or i1 %5279, %5281
  %5283 = load i32, i32* %22, align 4
  %5284 = icmp eq i32 %5231, %5283
  %5285 = or i1 %5282, %5284
  %5286 = load i32, i32* %23, align 4
  %5287 = icmp eq i32 %5231, %5286
  %5288 = or i1 %5285, %5287
  %5289 = load i32, i32* %24, align 4
  %5290 = icmp eq i32 %5231, %5289
  %5291 = or i1 %5288, %5290
  %5292 = load i32, i32* %25, align 4
  %5293 = icmp eq i32 %5231, %5292
  %5294 = or i1 %5291, %5293
  %5295 = load i32, i32* %26, align 4
  %5296 = icmp eq i32 %5231, %5295
  %5297 = or i1 %5294, %5296
  %5298 = load i32, i32* %27, align 4
  %5299 = icmp eq i32 %5231, %5298
  %5300 = or i1 %5297, %5299
  %5301 = load i32, i32* %28, align 4
  %5302 = icmp eq i32 %5231, %5301
  %5303 = or i1 %5300, %5302
  %5304 = load i32, i32* %29, align 4
  %5305 = icmp eq i32 %5231, %5304
  %5306 = or i1 %5303, %5305
  %5307 = load i32, i32* %30, align 4
  %5308 = icmp eq i32 %5231, %5307
  %5309 = or i1 %5306, %5308
  %5310 = load i32, i32* %31, align 4
  %5311 = icmp eq i32 %5231, %5310
  %5312 = or i1 %5309, %5311
  %5313 = load i32, i32* %32, align 4
  %5314 = icmp eq i32 %5231, %5313
  %5315 = or i1 %5312, %5314
  %5316 = load i32, i32* %33, align 4
  %5317 = icmp eq i32 %5231, %5316
  %5318 = or i1 %5315, %5317
  %5319 = load i32, i32* %34, align 4
  %5320 = icmp eq i32 %5231, %5319
  %5321 = or i1 %5318, %5320
  %5322 = load i32, i32* %35, align 4
  %5323 = icmp eq i32 %5231, %5322
  %5324 = or i1 %5321, %5323
  %5325 = load i32, i32* %36, align 4
  %5326 = icmp eq i32 %5231, %5325
  %5327 = or i1 %5324, %5326
  %5328 = load i32, i32* %37, align 4
  %5329 = icmp eq i32 %5231, %5328
  %5330 = or i1 %5327, %5329
  %5331 = load i32, i32* %38, align 4
  %5332 = icmp eq i32 %5231, %5331
  %5333 = or i1 %5330, %5332
  %5334 = load i32, i32* %39, align 4
  %5335 = icmp eq i32 %5231, %5334
  %5336 = or i1 %5333, %5335
  %5337 = load i32, i32* %40, align 4
  %5338 = icmp eq i32 %5231, %5337
  %5339 = or i1 %5336, %5338
  %5340 = load i32, i32* %41, align 4
  %5341 = icmp eq i32 %5231, %5340
  %5342 = or i1 %5339, %5341
  %5343 = load i32, i32* %42, align 4
  %5344 = icmp eq i32 %5231, %5343
  %5345 = or i1 %5342, %5344
  %5346 = load i32, i32* %43, align 4
  %5347 = icmp eq i32 %5231, %5346
  %5348 = or i1 %5345, %5347
  %5349 = load i32, i32* %44, align 4
  %5350 = icmp eq i32 %5231, %5349
  %5351 = or i1 %5348, %5350
  %5352 = load i32, i32* %45, align 4
  %5353 = icmp eq i32 %5231, %5352
  %5354 = or i1 %5351, %5353
  %5355 = load i32, i32* %46, align 4
  %5356 = icmp eq i32 %5231, %5355
  %5357 = or i1 %5354, %5356
  %5358 = load i32, i32* %47, align 4
  %5359 = icmp eq i32 %5231, %5358
  %5360 = or i1 %5357, %5359
  %5361 = load i32, i32* %48, align 4
  %5362 = icmp eq i32 %5231, %5361
  %5363 = or i1 %5360, %5362
  %5364 = load i32, i32* %49, align 4
  %5365 = icmp eq i32 %5231, %5364
  %5366 = or i1 %5363, %5365
  %5367 = load i32, i32* %50, align 4
  %5368 = icmp eq i32 %5231, %5367
  %5369 = or i1 %5366, %5368
  %5370 = load i32, i32* %51, align 4
  %5371 = icmp eq i32 %5231, %5370
  %5372 = or i1 %5369, %5371
  %5373 = load i32, i32* %52, align 4
  %5374 = icmp eq i32 %5231, %5373
  %5375 = or i1 %5372, %5374
  %5376 = load i32, i32* %53, align 4
  %5377 = icmp eq i32 %5231, %5376
  %5378 = or i1 %5375, %5377
  %5379 = load i32, i32* %54, align 4
  %5380 = icmp eq i32 %5231, %5379
  %5381 = or i1 %5378, %5380
  %5382 = load i32, i32* %55, align 4
  %5383 = icmp eq i32 %5231, %5382
  %5384 = or i1 %5381, %5383
  %5385 = load i32, i32* %56, align 4
  %5386 = icmp eq i32 %5231, %5385
  %5387 = or i1 %5384, %5386
  %5388 = load i32, i32* %57, align 4
  %5389 = icmp eq i32 %5231, %5388
  %5390 = or i1 %5387, %5389
  %5391 = load i32, i32* %58, align 4
  %5392 = icmp eq i32 %5231, %5391
  %5393 = or i1 %5390, %5392
  %5394 = load i32, i32* %59, align 4
  %5395 = icmp eq i32 %5231, %5394
  %5396 = or i1 %5393, %5395
  %5397 = load i32, i32* %60, align 4
  %5398 = icmp eq i32 %5231, %5397
  %5399 = or i1 %5396, %5398
  %5400 = load i32, i32* %61, align 4
  %5401 = icmp eq i32 %5231, %5400
  %5402 = or i1 %5399, %5401
  %5403 = load i32, i32* %62, align 4
  %5404 = icmp eq i32 %5231, %5403
  %5405 = or i1 %5402, %5404
  %5406 = getelementptr i8, i8 addrspace(1)* %4, i32 3
  %5407 = zext i1 %5405 to i8
  store i8 %5407, i8 addrspace(1)* %5406, align 1, !nosanitize !3
  %5408 = load i256, i256* %5230, align 4
  %5409 = add i256 175000, %5408, !pc !188, !intsan !10
  %5410 = trunc i256 11875 to i64
  %5411 = load i64, i64* %STACK_DEP_PTR, align 4
  %5412 = add i64 %5411, 1
  store i64 %5412, i64* %STACK_DEP_PTR, align 4
  %5413 = load i64, i64* %STACK_DEP_PTR, align 4
  %5414 = getelementptr i256, i256* %STACK, i64 %5413
  store i256 %5166, i256* %5414, align 4
  %5415 = load i64, i64* %STACK_DEP_PTR, align 4
  %5416 = add i64 %5415, 1
  store i64 %5416, i64* %STACK_DEP_PTR, align 4
  %5417 = load i64, i64* %STACK_DEP_PTR, align 4
  %5418 = getelementptr i256, i256* %STACK, i64 %5417
  store i256 %5161, i256* %5418, align 4
  %5419 = load i64, i64* %STACK_DEP_PTR, align 4
  %5420 = add i64 %5419, 1
  store i64 %5420, i64* %STACK_DEP_PTR, align 4
  %5421 = load i64, i64* %STACK_DEP_PTR, align 4
  %5422 = getelementptr i256, i256* %STACK, i64 %5421
  store i256 3848, i256* %5422, align 4
  %5423 = load i64, i64* %STACK_DEP_PTR, align 4
  %5424 = add i64 %5423, 1
  store i64 %5424, i64* %STACK_DEP_PTR, align 4
  %5425 = load i64, i64* %STACK_DEP_PTR, align 4
  %5426 = getelementptr i256, i256* %STACK, i64 %5425
  store i256 %5190, i256* %5426, align 4
  %5427 = load i64, i64* %STACK_DEP_PTR, align 4
  %5428 = add i64 %5427, 1
  store i64 %5428, i64* %STACK_DEP_PTR, align 4
  %5429 = load i64, i64* %STACK_DEP_PTR, align 4
  %5430 = getelementptr i256, i256* %STACK, i64 %5429
  store i256 %5204, i256* %5430, align 4
  %5431 = load i64, i64* %STACK_DEP_PTR, align 4
  %5432 = add i64 %5431, 1
  store i64 %5432, i64* %STACK_DEP_PTR, align 4
  %5433 = load i64, i64* %STACK_DEP_PTR, align 4
  %5434 = getelementptr i256, i256* %STACK, i64 %5433
  store i256 %5409, i256* %5434, align 4
  br label %.11875, !EVMBB !4

.3848:                                            ; preds = %JumpTable
  %5435 = load i64, i64* %remaing_gas, align 4
  %5436 = icmp ugt i64 1288, %5435
  br i1 %5436, label %Abort, label %5437

5437:                                             ; preds = %.3848
  %5438 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5439 = xor i32 %5438, 3617
  %5440 = urem i32 %5439, 4096
  %5441 = getelementptr i8, i8 addrspace(1)* %4, i32 %5440
  %5442 = load i8, i8 addrspace(1)* %5441, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5441, align 1, !nosanitize !3
  store i32 1808, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5443 = sub i64 %5435, 1288
  store i64 %5443, i64* %remaing_gas, align 4
  %5444 = load i64, i64* %STACK_DEP_PTR, align 4
  %5445 = getelementptr i256, i256* %STACK, i64 %5444
  %5446 = load i256, i256* %5445, align 4
  %5447 = load i64, i64* %STACK_DEP_PTR, align 4
  %5448 = sub i64 %5447, 1
  store i64 %5448, i64* %STACK_DEP_PTR, align 4
  %5449 = load i64, i64* %STACK_DEP_PTR, align 4
  %5450 = getelementptr i256, i256* %STACK, i64 %5449
  %5451 = load i256, i256* %5450, align 4
  %5452 = load i64, i64* %STACK_DEP_PTR, align 4
  %5453 = sub i64 %5452, 1
  store i64 %5453, i64* %STACK_DEP_PTR, align 4
  %5454 = load i64, i64* %STACK_DEP_PTR, align 4
  %5455 = getelementptr i256, i256* %STACK, i64 %5454
  %5456 = load i256, i256* %5455, align 4
  %5457 = load i64, i64* %STACK_DEP_PTR, align 4
  %5458 = sub i64 %5457, 1
  store i64 %5458, i64* %STACK_DEP_PTR, align 4
  %5459 = trunc i256 64 to i64
  %5460 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5459, i256* %5460)
  %5461 = load i256, i256* %5460, align 4
  %5462 = add i256 %5461, 96, !pc !189, !intsan !10
  %5463 = trunc i256 64 to i64
  %5464 = alloca i256, align 8
  store i256 %5462, i256* %5464, align 4
  %5465 = bitcast i256* %5464 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5463, i8* %5465, i64 32)
  %5466 = load i256, i256* %0, align 4
  %5467 = and i256 1461501637330902918203684832716283019655932542975, %5466
  %5468 = trunc i256 %5461 to i64
  %5469 = alloca i256, align 8
  store i256 %5467, i256* %5469, align 4
  %5470 = bitcast i256* %5469 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5468, i8* %5470, i64 32)
  %5471 = add i256 32, %5461, !pc !190, !intsan !10
  %5472 = trunc i256 %5471 to i64
  %5473 = alloca i256, align 8
  store i256 %5456, i256* %5473, align 4
  %5474 = bitcast i256* %5473 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5472, i8* %5474, i64 32)
  %5475 = add i256 32, %5471, !pc !191, !intsan !10
  %5476 = trunc i256 %5475 to i64
  %5477 = alloca i256, align 8
  store i256 0, i256* %5477, align 4
  %5478 = bitcast i256* %5477 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5476, i8* %5478, i64 32)
  %5479 = xor i256 0, -1
  %5480 = and i256 %5479, %5446
  %5481 = xor i256 0, -1
  %5482 = and i256 %5481, %5480
  %5483 = trunc i256 0 to i64
  %5484 = alloca i256, align 8
  store i256 %5482, i256* %5484, align 4
  %5485 = bitcast i256* %5484 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5483, i8* %5485, i64 32)
  %5486 = add i256 32, 0, !pc !192, !intsan !10
  %5487 = trunc i256 %5486 to i64
  %5488 = alloca i256, align 8
  store i256 11, i256* %5488, align 4
  %5489 = bitcast i256* %5488 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5487, i8* %5489, i64 32)
  %5490 = add i256 32, %5486, !pc !193, !intsan !10
  %5491 = trunc i256 0 to i32
  %5492 = trunc i256 %5490 to i32
  %5493 = getelementptr inbounds i8, i8* %MEMORY, i32 %5491
  %5494 = alloca i256, align 8
  %5495 = bitcast i256* %5494 to i8*
  call void @__device_sha3(i8* %5493, i32 %5492, i8* %5495)
  %5496 = load i256, i256* %5494, align 4
  %5497 = add i256 %5461, 0, !pc !194, !intsan !10
  %5498 = trunc i256 %5497 to i64
  %5499 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5498, i256* %5499)
  %5500 = load i256, i256* %5499, align 4
  %5501 = add i256 0, %5496, !pc !195, !intsan !10
  %5502 = alloca i256, align 8
  store i256 %5501, i256* %5502, align 4
  %5503 = alloca i256, align 8
  call void @__device_sload(i256* %5502, i256* %5503)
  %5504 = call i32 @__hashword(i256* %5502)
  %5505 = load i32, i32* %5, align 4
  %5506 = icmp eq i32 %5504, %5505
  %5507 = or i1 false, %5506
  %5508 = load i32, i32* %6, align 4
  %5509 = icmp eq i32 %5504, %5508
  %5510 = or i1 %5507, %5509
  %5511 = load i32, i32* %7, align 4
  %5512 = icmp eq i32 %5504, %5511
  %5513 = or i1 %5510, %5512
  %5514 = load i32, i32* %8, align 4
  %5515 = icmp eq i32 %5504, %5514
  %5516 = or i1 %5513, %5515
  %5517 = load i32, i32* %9, align 4
  %5518 = icmp eq i32 %5504, %5517
  %5519 = or i1 %5516, %5518
  %5520 = load i32, i32* %10, align 4
  %5521 = icmp eq i32 %5504, %5520
  %5522 = or i1 %5519, %5521
  %5523 = load i32, i32* %11, align 4
  %5524 = icmp eq i32 %5504, %5523
  %5525 = or i1 %5522, %5524
  %5526 = load i32, i32* %12, align 4
  %5527 = icmp eq i32 %5504, %5526
  %5528 = or i1 %5525, %5527
  %5529 = load i32, i32* %13, align 4
  %5530 = icmp eq i32 %5504, %5529
  %5531 = or i1 %5528, %5530
  %5532 = load i32, i32* %14, align 4
  %5533 = icmp eq i32 %5504, %5532
  %5534 = or i1 %5531, %5533
  %5535 = load i32, i32* %15, align 4
  %5536 = icmp eq i32 %5504, %5535
  %5537 = or i1 %5534, %5536
  %5538 = load i32, i32* %16, align 4
  %5539 = icmp eq i32 %5504, %5538
  %5540 = or i1 %5537, %5539
  %5541 = load i32, i32* %17, align 4
  %5542 = icmp eq i32 %5504, %5541
  %5543 = or i1 %5540, %5542
  %5544 = load i32, i32* %18, align 4
  %5545 = icmp eq i32 %5504, %5544
  %5546 = or i1 %5543, %5545
  %5547 = load i32, i32* %19, align 4
  %5548 = icmp eq i32 %5504, %5547
  %5549 = or i1 %5546, %5548
  %5550 = load i32, i32* %20, align 4
  %5551 = icmp eq i32 %5504, %5550
  %5552 = or i1 %5549, %5551
  %5553 = load i32, i32* %21, align 4
  %5554 = icmp eq i32 %5504, %5553
  %5555 = or i1 %5552, %5554
  %5556 = load i32, i32* %22, align 4
  %5557 = icmp eq i32 %5504, %5556
  %5558 = or i1 %5555, %5557
  %5559 = load i32, i32* %23, align 4
  %5560 = icmp eq i32 %5504, %5559
  %5561 = or i1 %5558, %5560
  %5562 = load i32, i32* %24, align 4
  %5563 = icmp eq i32 %5504, %5562
  %5564 = or i1 %5561, %5563
  %5565 = load i32, i32* %25, align 4
  %5566 = icmp eq i32 %5504, %5565
  %5567 = or i1 %5564, %5566
  %5568 = load i32, i32* %26, align 4
  %5569 = icmp eq i32 %5504, %5568
  %5570 = or i1 %5567, %5569
  %5571 = load i32, i32* %27, align 4
  %5572 = icmp eq i32 %5504, %5571
  %5573 = or i1 %5570, %5572
  %5574 = load i32, i32* %28, align 4
  %5575 = icmp eq i32 %5504, %5574
  %5576 = or i1 %5573, %5575
  %5577 = load i32, i32* %29, align 4
  %5578 = icmp eq i32 %5504, %5577
  %5579 = or i1 %5576, %5578
  %5580 = load i32, i32* %30, align 4
  %5581 = icmp eq i32 %5504, %5580
  %5582 = or i1 %5579, %5581
  %5583 = load i32, i32* %31, align 4
  %5584 = icmp eq i32 %5504, %5583
  %5585 = or i1 %5582, %5584
  %5586 = load i32, i32* %32, align 4
  %5587 = icmp eq i32 %5504, %5586
  %5588 = or i1 %5585, %5587
  %5589 = load i32, i32* %33, align 4
  %5590 = icmp eq i32 %5504, %5589
  %5591 = or i1 %5588, %5590
  %5592 = load i32, i32* %34, align 4
  %5593 = icmp eq i32 %5504, %5592
  %5594 = or i1 %5591, %5593
  %5595 = load i32, i32* %35, align 4
  %5596 = icmp eq i32 %5504, %5595
  %5597 = or i1 %5594, %5596
  %5598 = load i32, i32* %36, align 4
  %5599 = icmp eq i32 %5504, %5598
  %5600 = or i1 %5597, %5599
  %5601 = load i32, i32* %37, align 4
  %5602 = icmp eq i32 %5504, %5601
  %5603 = or i1 %5600, %5602
  %5604 = load i32, i32* %38, align 4
  %5605 = icmp eq i32 %5504, %5604
  %5606 = or i1 %5603, %5605
  %5607 = load i32, i32* %39, align 4
  %5608 = icmp eq i32 %5504, %5607
  %5609 = or i1 %5606, %5608
  %5610 = load i32, i32* %40, align 4
  %5611 = icmp eq i32 %5504, %5610
  %5612 = or i1 %5609, %5611
  %5613 = load i32, i32* %41, align 4
  %5614 = icmp eq i32 %5504, %5613
  %5615 = or i1 %5612, %5614
  %5616 = load i32, i32* %42, align 4
  %5617 = icmp eq i32 %5504, %5616
  %5618 = or i1 %5615, %5617
  %5619 = load i32, i32* %43, align 4
  %5620 = icmp eq i32 %5504, %5619
  %5621 = or i1 %5618, %5620
  %5622 = load i32, i32* %44, align 4
  %5623 = icmp eq i32 %5504, %5622
  %5624 = or i1 %5621, %5623
  %5625 = load i32, i32* %45, align 4
  %5626 = icmp eq i32 %5504, %5625
  %5627 = or i1 %5624, %5626
  %5628 = load i32, i32* %46, align 4
  %5629 = icmp eq i32 %5504, %5628
  %5630 = or i1 %5627, %5629
  %5631 = load i32, i32* %47, align 4
  %5632 = icmp eq i32 %5504, %5631
  %5633 = or i1 %5630, %5632
  %5634 = load i32, i32* %48, align 4
  %5635 = icmp eq i32 %5504, %5634
  %5636 = or i1 %5633, %5635
  %5637 = load i32, i32* %49, align 4
  %5638 = icmp eq i32 %5504, %5637
  %5639 = or i1 %5636, %5638
  %5640 = load i32, i32* %50, align 4
  %5641 = icmp eq i32 %5504, %5640
  %5642 = or i1 %5639, %5641
  %5643 = load i32, i32* %51, align 4
  %5644 = icmp eq i32 %5504, %5643
  %5645 = or i1 %5642, %5644
  %5646 = load i32, i32* %52, align 4
  %5647 = icmp eq i32 %5504, %5646
  %5648 = or i1 %5645, %5647
  %5649 = load i32, i32* %53, align 4
  %5650 = icmp eq i32 %5504, %5649
  %5651 = or i1 %5648, %5650
  %5652 = load i32, i32* %54, align 4
  %5653 = icmp eq i32 %5504, %5652
  %5654 = or i1 %5651, %5653
  %5655 = load i32, i32* %55, align 4
  %5656 = icmp eq i32 %5504, %5655
  %5657 = or i1 %5654, %5656
  %5658 = load i32, i32* %56, align 4
  %5659 = icmp eq i32 %5504, %5658
  %5660 = or i1 %5657, %5659
  %5661 = load i32, i32* %57, align 4
  %5662 = icmp eq i32 %5504, %5661
  %5663 = or i1 %5660, %5662
  %5664 = load i32, i32* %58, align 4
  %5665 = icmp eq i32 %5504, %5664
  %5666 = or i1 %5663, %5665
  %5667 = load i32, i32* %59, align 4
  %5668 = icmp eq i32 %5504, %5667
  %5669 = or i1 %5666, %5668
  %5670 = load i32, i32* %60, align 4
  %5671 = icmp eq i32 %5504, %5670
  %5672 = or i1 %5669, %5671
  %5673 = load i32, i32* %61, align 4
  %5674 = icmp eq i32 %5504, %5673
  %5675 = or i1 %5672, %5674
  %5676 = load i32, i32* %62, align 4
  %5677 = icmp eq i32 %5504, %5676
  %5678 = or i1 %5675, %5677
  %5679 = getelementptr i8, i8 addrspace(1)* %4, i32 4
  %5680 = zext i1 %5678 to i8
  store i8 %5680, i8 addrspace(1)* %5679, align 1, !nosanitize !3
  %5681 = load i256, i256* %5503, align 4
  %5682 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !196, !intsan !45
  %5683 = xor i256 %5682, -1
  %5684 = and i256 %5683, %5681
  %5685 = and i256 1461501637330902918203684832716283019655932542975, %5500
  %5686 = mul i256 %5685, 1, !pc !197, !intsan !45
  %5687 = or i256 %5686, %5684
  %5688 = alloca i256, align 8
  store i256 %5501, i256* %5688, align 4
  %5689 = alloca i256, align 8
  store i256 %5687, i256* %5689, align 4
  call void @__device_sstore(i256* %5688, i256* %5689)
  %5690 = call i32 @__hashword(i256* %5688)
  store i32 %5690, i32* %30, align 4, !nosanitize !3
  %5691 = add i256 %5461, 32, !pc !198, !intsan !10
  %5692 = trunc i256 %5691 to i64
  %5693 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5692, i256* %5693)
  %5694 = load i256, i256* %5693, align 4
  %5695 = add i256 1, %5496, !pc !199, !intsan !10
  %5696 = alloca i256, align 8
  store i256 %5695, i256* %5696, align 4
  %5697 = alloca i256, align 8
  store i256 %5694, i256* %5697, align 4
  call void @__device_sstore(i256* %5696, i256* %5697)
  %5698 = call i32 @__hashword(i256* %5696)
  store i32 %5698, i32* %31, align 4, !nosanitize !3
  %5699 = add i256 %5461, 64, !pc !200, !intsan !10
  %5700 = trunc i256 %5699 to i64
  %5701 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %5700, i256* %5701)
  %5702 = load i256, i256* %5701, align 4
  %5703 = add i256 2, %5496, !pc !201, !intsan !10
  %5704 = alloca i256, align 8
  store i256 %5703, i256* %5704, align 4
  %5705 = alloca i256, align 8
  store i256 %5702, i256* %5705, align 4
  call void @__device_sstore(i256* %5704, i256* %5705)
  %5706 = call i32 @__hashword(i256* %5704)
  store i32 %5706, i32* %32, align 4, !nosanitize !3
  %5707 = alloca i256, align 8
  store i256 12, i256* %5707, align 4
  %5708 = alloca i256, align 8
  call void @__device_sload(i256* %5707, i256* %5708)
  %5709 = call i32 @__hashword(i256* %5707)
  %5710 = load i32, i32* %5, align 4
  %5711 = icmp eq i32 %5709, %5710
  %5712 = or i1 false, %5711
  %5713 = load i32, i32* %6, align 4
  %5714 = icmp eq i32 %5709, %5713
  %5715 = or i1 %5712, %5714
  %5716 = load i32, i32* %7, align 4
  %5717 = icmp eq i32 %5709, %5716
  %5718 = or i1 %5715, %5717
  %5719 = load i32, i32* %8, align 4
  %5720 = icmp eq i32 %5709, %5719
  %5721 = or i1 %5718, %5720
  %5722 = load i32, i32* %9, align 4
  %5723 = icmp eq i32 %5709, %5722
  %5724 = or i1 %5721, %5723
  %5725 = load i32, i32* %10, align 4
  %5726 = icmp eq i32 %5709, %5725
  %5727 = or i1 %5724, %5726
  %5728 = load i32, i32* %11, align 4
  %5729 = icmp eq i32 %5709, %5728
  %5730 = or i1 %5727, %5729
  %5731 = load i32, i32* %12, align 4
  %5732 = icmp eq i32 %5709, %5731
  %5733 = or i1 %5730, %5732
  %5734 = load i32, i32* %13, align 4
  %5735 = icmp eq i32 %5709, %5734
  %5736 = or i1 %5733, %5735
  %5737 = load i32, i32* %14, align 4
  %5738 = icmp eq i32 %5709, %5737
  %5739 = or i1 %5736, %5738
  %5740 = load i32, i32* %15, align 4
  %5741 = icmp eq i32 %5709, %5740
  %5742 = or i1 %5739, %5741
  %5743 = load i32, i32* %16, align 4
  %5744 = icmp eq i32 %5709, %5743
  %5745 = or i1 %5742, %5744
  %5746 = load i32, i32* %17, align 4
  %5747 = icmp eq i32 %5709, %5746
  %5748 = or i1 %5745, %5747
  %5749 = load i32, i32* %18, align 4
  %5750 = icmp eq i32 %5709, %5749
  %5751 = or i1 %5748, %5750
  %5752 = load i32, i32* %19, align 4
  %5753 = icmp eq i32 %5709, %5752
  %5754 = or i1 %5751, %5753
  %5755 = load i32, i32* %20, align 4
  %5756 = icmp eq i32 %5709, %5755
  %5757 = or i1 %5754, %5756
  %5758 = load i32, i32* %21, align 4
  %5759 = icmp eq i32 %5709, %5758
  %5760 = or i1 %5757, %5759
  %5761 = load i32, i32* %22, align 4
  %5762 = icmp eq i32 %5709, %5761
  %5763 = or i1 %5760, %5762
  %5764 = load i32, i32* %23, align 4
  %5765 = icmp eq i32 %5709, %5764
  %5766 = or i1 %5763, %5765
  %5767 = load i32, i32* %24, align 4
  %5768 = icmp eq i32 %5709, %5767
  %5769 = or i1 %5766, %5768
  %5770 = load i32, i32* %25, align 4
  %5771 = icmp eq i32 %5709, %5770
  %5772 = or i1 %5769, %5771
  %5773 = load i32, i32* %26, align 4
  %5774 = icmp eq i32 %5709, %5773
  %5775 = or i1 %5772, %5774
  %5776 = load i32, i32* %27, align 4
  %5777 = icmp eq i32 %5709, %5776
  %5778 = or i1 %5775, %5777
  %5779 = load i32, i32* %28, align 4
  %5780 = icmp eq i32 %5709, %5779
  %5781 = or i1 %5778, %5780
  %5782 = load i32, i32* %29, align 4
  %5783 = icmp eq i32 %5709, %5782
  %5784 = or i1 %5781, %5783
  %5785 = load i32, i32* %30, align 4
  %5786 = icmp eq i32 %5709, %5785
  %5787 = or i1 %5784, %5786
  %5788 = load i32, i32* %31, align 4
  %5789 = icmp eq i32 %5709, %5788
  %5790 = or i1 %5787, %5789
  %5791 = load i32, i32* %32, align 4
  %5792 = icmp eq i32 %5709, %5791
  %5793 = or i1 %5790, %5792
  %5794 = load i32, i32* %33, align 4
  %5795 = icmp eq i32 %5709, %5794
  %5796 = or i1 %5793, %5795
  %5797 = load i32, i32* %34, align 4
  %5798 = icmp eq i32 %5709, %5797
  %5799 = or i1 %5796, %5798
  %5800 = load i32, i32* %35, align 4
  %5801 = icmp eq i32 %5709, %5800
  %5802 = or i1 %5799, %5801
  %5803 = load i32, i32* %36, align 4
  %5804 = icmp eq i32 %5709, %5803
  %5805 = or i1 %5802, %5804
  %5806 = load i32, i32* %37, align 4
  %5807 = icmp eq i32 %5709, %5806
  %5808 = or i1 %5805, %5807
  %5809 = load i32, i32* %38, align 4
  %5810 = icmp eq i32 %5709, %5809
  %5811 = or i1 %5808, %5810
  %5812 = load i32, i32* %39, align 4
  %5813 = icmp eq i32 %5709, %5812
  %5814 = or i1 %5811, %5813
  %5815 = load i32, i32* %40, align 4
  %5816 = icmp eq i32 %5709, %5815
  %5817 = or i1 %5814, %5816
  %5818 = load i32, i32* %41, align 4
  %5819 = icmp eq i32 %5709, %5818
  %5820 = or i1 %5817, %5819
  %5821 = load i32, i32* %42, align 4
  %5822 = icmp eq i32 %5709, %5821
  %5823 = or i1 %5820, %5822
  %5824 = load i32, i32* %43, align 4
  %5825 = icmp eq i32 %5709, %5824
  %5826 = or i1 %5823, %5825
  %5827 = load i32, i32* %44, align 4
  %5828 = icmp eq i32 %5709, %5827
  %5829 = or i1 %5826, %5828
  %5830 = load i32, i32* %45, align 4
  %5831 = icmp eq i32 %5709, %5830
  %5832 = or i1 %5829, %5831
  %5833 = load i32, i32* %46, align 4
  %5834 = icmp eq i32 %5709, %5833
  %5835 = or i1 %5832, %5834
  %5836 = load i32, i32* %47, align 4
  %5837 = icmp eq i32 %5709, %5836
  %5838 = or i1 %5835, %5837
  %5839 = load i32, i32* %48, align 4
  %5840 = icmp eq i32 %5709, %5839
  %5841 = or i1 %5838, %5840
  %5842 = load i32, i32* %49, align 4
  %5843 = icmp eq i32 %5709, %5842
  %5844 = or i1 %5841, %5843
  %5845 = load i32, i32* %50, align 4
  %5846 = icmp eq i32 %5709, %5845
  %5847 = or i1 %5844, %5846
  %5848 = load i32, i32* %51, align 4
  %5849 = icmp eq i32 %5709, %5848
  %5850 = or i1 %5847, %5849
  %5851 = load i32, i32* %52, align 4
  %5852 = icmp eq i32 %5709, %5851
  %5853 = or i1 %5850, %5852
  %5854 = load i32, i32* %53, align 4
  %5855 = icmp eq i32 %5709, %5854
  %5856 = or i1 %5853, %5855
  %5857 = load i32, i32* %54, align 4
  %5858 = icmp eq i32 %5709, %5857
  %5859 = or i1 %5856, %5858
  %5860 = load i32, i32* %55, align 4
  %5861 = icmp eq i32 %5709, %5860
  %5862 = or i1 %5859, %5861
  %5863 = load i32, i32* %56, align 4
  %5864 = icmp eq i32 %5709, %5863
  %5865 = or i1 %5862, %5864
  %5866 = load i32, i32* %57, align 4
  %5867 = icmp eq i32 %5709, %5866
  %5868 = or i1 %5865, %5867
  %5869 = load i32, i32* %58, align 4
  %5870 = icmp eq i32 %5709, %5869
  %5871 = or i1 %5868, %5870
  %5872 = load i32, i32* %59, align 4
  %5873 = icmp eq i32 %5709, %5872
  %5874 = or i1 %5871, %5873
  %5875 = load i32, i32* %60, align 4
  %5876 = icmp eq i32 %5709, %5875
  %5877 = or i1 %5874, %5876
  %5878 = load i32, i32* %61, align 4
  %5879 = icmp eq i32 %5709, %5878
  %5880 = or i1 %5877, %5879
  %5881 = load i32, i32* %62, align 4
  %5882 = icmp eq i32 %5709, %5881
  %5883 = or i1 %5880, %5882
  %5884 = getelementptr i8, i8 addrspace(1)* %4, i32 5
  %5885 = zext i1 %5883 to i8
  store i8 %5885, i8 addrspace(1)* %5884, align 1, !nosanitize !3
  %5886 = load i256, i256* %5708, align 4
  %5887 = add i256 %5886, 1, !pc !202, !intsan !10
  %5888 = alloca i256, align 8
  store i256 12, i256* %5888, align 4
  %5889 = alloca i256, align 8
  store i256 %5887, i256* %5889, align 4
  call void @__device_sstore(i256* %5888, i256* %5889)
  %5890 = call i32 @__hashword(i256* %5888)
  store i32 %5890, i32* %33, align 4, !nosanitize !3
  %5891 = sub i256 %5887, 1, !pc !203, !intsan !8
  %5892 = trunc i256 0 to i64
  %5893 = alloca i256, align 8
  store i256 12, i256* %5893, align 4
  %5894 = bitcast i256* %5893 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5892, i8* %5894, i64 32)
  %5895 = trunc i256 0 to i32
  %5896 = trunc i256 32 to i32
  %5897 = getelementptr inbounds i8, i8* %MEMORY, i32 %5895
  %5898 = alloca i256, align 8
  %5899 = bitcast i256* %5898 to i8*
  call void @__device_sha3(i8* %5897, i32 %5896, i8* %5899)
  %5900 = load i256, i256* %5898, align 4
  %5901 = add i256 %5900, %5891, !pc !204, !intsan !10
  %5902 = xor i256 0, -1
  %5903 = and i256 %5902, %5446
  %5904 = alloca i256, align 8
  store i256 %5901, i256* %5904, align 4
  %5905 = alloca i256, align 8
  store i256 %5903, i256* %5905, align 4
  call void @__device_sstore(i256* %5904, i256* %5905)
  %5906 = call i32 @__hashword(i256* %5904)
  store i32 %5906, i32* %34, align 4, !nosanitize !3
  %5907 = trunc i256 4082 to i64
  %5908 = load i64, i64* %STACK_DEP_PTR, align 4
  %5909 = add i64 %5908, 1
  store i64 %5909, i64* %STACK_DEP_PTR, align 4
  %5910 = load i64, i64* %STACK_DEP_PTR, align 4
  %5911 = getelementptr i256, i256* %STACK, i64 %5910
  store i256 %5456, i256* %5911, align 4
  %5912 = load i64, i64* %STACK_DEP_PTR, align 4
  %5913 = add i64 %5912, 1
  store i64 %5913, i64* %STACK_DEP_PTR, align 4
  %5914 = load i64, i64* %STACK_DEP_PTR, align 4
  %5915 = getelementptr i256, i256* %STACK, i64 %5914
  store i256 %5446, i256* %5915, align 4
  br label %.4082, !EVMBB !4

.4077:                                            ; preds = %5136, %JumpTable
  %5916 = load i64, i64* %remaing_gas, align 4
  %5917 = icmp ugt i64 16, %5916
  br i1 %5917, label %Abort, label %5918

5918:                                             ; preds = %.4077
  %5919 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5920 = xor i32 %5919, 2603
  %5921 = urem i32 %5920, 4096
  %5922 = getelementptr i8, i8 addrspace(1)* %4, i32 %5921
  %5923 = load i8, i8 addrspace(1)* %5922, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5922, align 1, !nosanitize !3
  store i32 1301, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5924 = sub i64 %5916, 16
  store i64 %5924, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4082:                                            ; preds = %5437, %JumpTable
  %5925 = load i64, i64* %remaing_gas, align 4
  %5926 = icmp ugt i64 224, %5925
  br i1 %5926, label %Abort, label %5927

5927:                                             ; preds = %.4082
  %5928 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5929 = xor i32 %5928, 426
  %5930 = urem i32 %5929, 4096
  %5931 = getelementptr i8, i8 addrspace(1)* %4, i32 %5930
  %5932 = load i8, i8 addrspace(1)* %5931, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5931, align 1, !nosanitize !3
  store i32 213, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5933 = sub i64 %5925, 224
  store i64 %5933, i64* %remaing_gas, align 4
  %5934 = load i64, i64* %STACK_DEP_PTR, align 4
  %5935 = getelementptr i256, i256* %STACK, i64 %5934
  %5936 = load i256, i256* %5935, align 4
  %5937 = load i64, i64* %STACK_DEP_PTR, align 4
  %5938 = sub i64 %5937, 1
  store i64 %5938, i64* %STACK_DEP_PTR, align 4
  %5939 = load i64, i64* %STACK_DEP_PTR, align 4
  %5940 = getelementptr i256, i256* %STACK, i64 %5939
  %5941 = load i256, i256* %5940, align 4
  %5942 = load i64, i64* %STACK_DEP_PTR, align 4
  %5943 = sub i64 %5942, 1
  store i64 %5943, i64* %STACK_DEP_PTR, align 4
  %5944 = load i64, i64* %STACK_DEP_PTR, align 4
  %5945 = getelementptr i256, i256* %STACK, i64 %5944
  %5946 = load i256, i256* %5945, align 4
  %5947 = load i64, i64* %STACK_DEP_PTR, align 4
  %5948 = sub i64 %5947, 1
  store i64 %5948, i64* %STACK_DEP_PTR, align 4
  %5949 = load i64, i64* %STACK_DEP_PTR, align 4
  %5950 = getelementptr i256, i256* %STACK, i64 %5949
  %5951 = load i256, i256* %5950, align 4
  %5952 = load i64, i64* %STACK_DEP_PTR, align 4
  %5953 = sub i64 %5952, 1
  store i64 %5953, i64* %STACK_DEP_PTR, align 4
  %5954 = trunc i256 %5951 to i64
  store i64 %5954, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.4087:                                            ; preds = %835, %JumpTable
  %5955 = load i64, i64* %remaing_gas, align 4
  %5956 = icmp ugt i64 264, %5955
  br i1 %5956, label %Abort, label %5957

5957:                                             ; preds = %.4087
  %5958 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5959 = xor i32 %5958, 2330
  %5960 = urem i32 %5959, 4096
  %5961 = getelementptr i8, i8 addrspace(1)* %4, i32 %5960
  %5962 = load i8, i8 addrspace(1)* %5961, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %5961, align 1, !nosanitize !3
  store i32 1165, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %5963 = sub i64 %5955, 264
  store i64 %5963, i64* %remaing_gas, align 4
  %5964 = load i256, i256* %0, align 4
  %5965 = and i256 1461501637330902918203684832716283019655932542975, %5964
  %5966 = and i256 1461501637330902918203684832716283019655932542975, %5965
  %5967 = trunc i256 0 to i64
  %5968 = alloca i256, align 8
  store i256 %5966, i256* %5968, align 4
  %5969 = bitcast i256* %5968 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5967, i8* %5969, i64 32)
  %5970 = add i256 32, 0, !pc !205, !intsan !10
  %5971 = trunc i256 %5970 to i64
  %5972 = alloca i256, align 8
  store i256 3, i256* %5972, align 4
  %5973 = bitcast i256* %5972 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %5971, i8* %5973, i64 32)
  %5974 = add i256 32, %5970, !pc !206, !intsan !10
  %5975 = trunc i256 0 to i32
  %5976 = trunc i256 %5974 to i32
  %5977 = getelementptr inbounds i8, i8* %MEMORY, i32 %5975
  %5978 = alloca i256, align 8
  %5979 = bitcast i256* %5978 to i8*
  call void @__device_sha3(i8* %5977, i32 %5976, i8* %5979)
  %5980 = load i256, i256* %5978, align 4
  %5981 = alloca i256, align 8
  store i256 %5980, i256* %5981, align 4
  %5982 = alloca i256, align 8
  call void @__device_sload(i256* %5981, i256* %5982)
  %5983 = call i32 @__hashword(i256* %5981)
  %5984 = load i32, i32* %5, align 4
  %5985 = icmp eq i32 %5983, %5984
  %5986 = or i1 false, %5985
  %5987 = load i32, i32* %6, align 4
  %5988 = icmp eq i32 %5983, %5987
  %5989 = or i1 %5986, %5988
  %5990 = load i32, i32* %7, align 4
  %5991 = icmp eq i32 %5983, %5990
  %5992 = or i1 %5989, %5991
  %5993 = load i32, i32* %8, align 4
  %5994 = icmp eq i32 %5983, %5993
  %5995 = or i1 %5992, %5994
  %5996 = load i32, i32* %9, align 4
  %5997 = icmp eq i32 %5983, %5996
  %5998 = or i1 %5995, %5997
  %5999 = load i32, i32* %10, align 4
  %6000 = icmp eq i32 %5983, %5999
  %6001 = or i1 %5998, %6000
  %6002 = load i32, i32* %11, align 4
  %6003 = icmp eq i32 %5983, %6002
  %6004 = or i1 %6001, %6003
  %6005 = load i32, i32* %12, align 4
  %6006 = icmp eq i32 %5983, %6005
  %6007 = or i1 %6004, %6006
  %6008 = load i32, i32* %13, align 4
  %6009 = icmp eq i32 %5983, %6008
  %6010 = or i1 %6007, %6009
  %6011 = load i32, i32* %14, align 4
  %6012 = icmp eq i32 %5983, %6011
  %6013 = or i1 %6010, %6012
  %6014 = load i32, i32* %15, align 4
  %6015 = icmp eq i32 %5983, %6014
  %6016 = or i1 %6013, %6015
  %6017 = load i32, i32* %16, align 4
  %6018 = icmp eq i32 %5983, %6017
  %6019 = or i1 %6016, %6018
  %6020 = load i32, i32* %17, align 4
  %6021 = icmp eq i32 %5983, %6020
  %6022 = or i1 %6019, %6021
  %6023 = load i32, i32* %18, align 4
  %6024 = icmp eq i32 %5983, %6023
  %6025 = or i1 %6022, %6024
  %6026 = load i32, i32* %19, align 4
  %6027 = icmp eq i32 %5983, %6026
  %6028 = or i1 %6025, %6027
  %6029 = load i32, i32* %20, align 4
  %6030 = icmp eq i32 %5983, %6029
  %6031 = or i1 %6028, %6030
  %6032 = load i32, i32* %21, align 4
  %6033 = icmp eq i32 %5983, %6032
  %6034 = or i1 %6031, %6033
  %6035 = load i32, i32* %22, align 4
  %6036 = icmp eq i32 %5983, %6035
  %6037 = or i1 %6034, %6036
  %6038 = load i32, i32* %23, align 4
  %6039 = icmp eq i32 %5983, %6038
  %6040 = or i1 %6037, %6039
  %6041 = load i32, i32* %24, align 4
  %6042 = icmp eq i32 %5983, %6041
  %6043 = or i1 %6040, %6042
  %6044 = load i32, i32* %25, align 4
  %6045 = icmp eq i32 %5983, %6044
  %6046 = or i1 %6043, %6045
  %6047 = load i32, i32* %26, align 4
  %6048 = icmp eq i32 %5983, %6047
  %6049 = or i1 %6046, %6048
  %6050 = load i32, i32* %27, align 4
  %6051 = icmp eq i32 %5983, %6050
  %6052 = or i1 %6049, %6051
  %6053 = load i32, i32* %28, align 4
  %6054 = icmp eq i32 %5983, %6053
  %6055 = or i1 %6052, %6054
  %6056 = load i32, i32* %29, align 4
  %6057 = icmp eq i32 %5983, %6056
  %6058 = or i1 %6055, %6057
  %6059 = load i32, i32* %30, align 4
  %6060 = icmp eq i32 %5983, %6059
  %6061 = or i1 %6058, %6060
  %6062 = load i32, i32* %31, align 4
  %6063 = icmp eq i32 %5983, %6062
  %6064 = or i1 %6061, %6063
  %6065 = load i32, i32* %32, align 4
  %6066 = icmp eq i32 %5983, %6065
  %6067 = or i1 %6064, %6066
  %6068 = load i32, i32* %33, align 4
  %6069 = icmp eq i32 %5983, %6068
  %6070 = or i1 %6067, %6069
  %6071 = load i32, i32* %34, align 4
  %6072 = icmp eq i32 %5983, %6071
  %6073 = or i1 %6070, %6072
  %6074 = load i32, i32* %35, align 4
  %6075 = icmp eq i32 %5983, %6074
  %6076 = or i1 %6073, %6075
  %6077 = load i32, i32* %36, align 4
  %6078 = icmp eq i32 %5983, %6077
  %6079 = or i1 %6076, %6078
  %6080 = load i32, i32* %37, align 4
  %6081 = icmp eq i32 %5983, %6080
  %6082 = or i1 %6079, %6081
  %6083 = load i32, i32* %38, align 4
  %6084 = icmp eq i32 %5983, %6083
  %6085 = or i1 %6082, %6084
  %6086 = load i32, i32* %39, align 4
  %6087 = icmp eq i32 %5983, %6086
  %6088 = or i1 %6085, %6087
  %6089 = load i32, i32* %40, align 4
  %6090 = icmp eq i32 %5983, %6089
  %6091 = or i1 %6088, %6090
  %6092 = load i32, i32* %41, align 4
  %6093 = icmp eq i32 %5983, %6092
  %6094 = or i1 %6091, %6093
  %6095 = load i32, i32* %42, align 4
  %6096 = icmp eq i32 %5983, %6095
  %6097 = or i1 %6094, %6096
  %6098 = load i32, i32* %43, align 4
  %6099 = icmp eq i32 %5983, %6098
  %6100 = or i1 %6097, %6099
  %6101 = load i32, i32* %44, align 4
  %6102 = icmp eq i32 %5983, %6101
  %6103 = or i1 %6100, %6102
  %6104 = load i32, i32* %45, align 4
  %6105 = icmp eq i32 %5983, %6104
  %6106 = or i1 %6103, %6105
  %6107 = load i32, i32* %46, align 4
  %6108 = icmp eq i32 %5983, %6107
  %6109 = or i1 %6106, %6108
  %6110 = load i32, i32* %47, align 4
  %6111 = icmp eq i32 %5983, %6110
  %6112 = or i1 %6109, %6111
  %6113 = load i32, i32* %48, align 4
  %6114 = icmp eq i32 %5983, %6113
  %6115 = or i1 %6112, %6114
  %6116 = load i32, i32* %49, align 4
  %6117 = icmp eq i32 %5983, %6116
  %6118 = or i1 %6115, %6117
  %6119 = load i32, i32* %50, align 4
  %6120 = icmp eq i32 %5983, %6119
  %6121 = or i1 %6118, %6120
  %6122 = load i32, i32* %51, align 4
  %6123 = icmp eq i32 %5983, %6122
  %6124 = or i1 %6121, %6123
  %6125 = load i32, i32* %52, align 4
  %6126 = icmp eq i32 %5983, %6125
  %6127 = or i1 %6124, %6126
  %6128 = load i32, i32* %53, align 4
  %6129 = icmp eq i32 %5983, %6128
  %6130 = or i1 %6127, %6129
  %6131 = load i32, i32* %54, align 4
  %6132 = icmp eq i32 %5983, %6131
  %6133 = or i1 %6130, %6132
  %6134 = load i32, i32* %55, align 4
  %6135 = icmp eq i32 %5983, %6134
  %6136 = or i1 %6133, %6135
  %6137 = load i32, i32* %56, align 4
  %6138 = icmp eq i32 %5983, %6137
  %6139 = or i1 %6136, %6138
  %6140 = load i32, i32* %57, align 4
  %6141 = icmp eq i32 %5983, %6140
  %6142 = or i1 %6139, %6141
  %6143 = load i32, i32* %58, align 4
  %6144 = icmp eq i32 %5983, %6143
  %6145 = or i1 %6142, %6144
  %6146 = load i32, i32* %59, align 4
  %6147 = icmp eq i32 %5983, %6146
  %6148 = or i1 %6145, %6147
  %6149 = load i32, i32* %60, align 4
  %6150 = icmp eq i32 %5983, %6149
  %6151 = or i1 %6148, %6150
  %6152 = load i32, i32* %61, align 4
  %6153 = icmp eq i32 %5983, %6152
  %6154 = or i1 %6151, %6153
  %6155 = load i32, i32* %62, align 4
  %6156 = icmp eq i32 %5983, %6155
  %6157 = or i1 %6154, %6156
  %6158 = getelementptr i8, i8 addrspace(1)* %4, i32 6
  %6159 = zext i1 %6157 to i8
  store i8 %6159, i8 addrspace(1)* %6158, align 1, !nosanitize !3
  %6160 = load i256, i256* %5982, align 4
  %6161 = icmp eq i256 %6160, 0
  %6162 = icmp eq i1 %6161, false
  %6163 = trunc i256 4164 to i64
  %jump.check10 = icmp ne i1 %6162, false
  br i1 %jump.check10, label %.4164, label %.4160, !EVMBB !4

.4160:                                            ; preds = %5957
  %6164 = load i64, i64* %remaing_gas, align 4
  %6165 = icmp ugt i64 16, %6164
  br i1 %6165, label %Abort, label %6166

6166:                                             ; preds = %.4160
  %6167 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6168 = xor i32 %6167, 2645
  %6169 = urem i32 %6168, 4096
  %6170 = getelementptr i8, i8 addrspace(1)* %4, i32 %6169
  %6171 = load i8, i8 addrspace(1)* %6170, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6170, align 1, !nosanitize !3
  store i32 1322, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6172 = sub i64 %6164, 16
  store i64 %6172, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4164:                                            ; preds = %5957, %JumpTable
  %6173 = load i64, i64* %remaing_gas, align 4
  %6174 = icmp ugt i64 128, %6173
  br i1 %6174, label %Abort, label %6175

6175:                                             ; preds = %.4164
  %6176 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6177 = xor i32 %6176, 2722
  %6178 = urem i32 %6177, 4096
  %6179 = getelementptr i8, i8 addrspace(1)* %4, i32 %6178
  %6180 = load i8, i8 addrspace(1)* %6179, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6179, align 1, !nosanitize !3
  store i32 1361, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6181 = sub i64 %6173, 128
  store i64 %6181, i64* %remaing_gas, align 4
  %6182 = load i256, i256* %0, align 4
  %6183 = trunc i256 13000 to i64
  %6184 = load i64, i64* %STACK_DEP_PTR, align 4
  %6185 = add i64 %6184, 1
  store i64 %6185, i64* %STACK_DEP_PTR, align 4
  %6186 = load i64, i64* %STACK_DEP_PTR, align 4
  %6187 = getelementptr i256, i256* %STACK, i64 %6186
  store i256 4173, i256* %6187, align 4
  %6188 = load i64, i64* %STACK_DEP_PTR, align 4
  %6189 = add i64 %6188, 1
  store i64 %6189, i64* %STACK_DEP_PTR, align 4
  %6190 = load i64, i64* %STACK_DEP_PTR, align 4
  %6191 = getelementptr i256, i256* %STACK, i64 %6190
  store i256 %6182, i256* %6191, align 4
  br label %.13000, !EVMBB !4

.4173:                                            ; preds = %JumpTable
  %6192 = load i64, i64* %remaing_gas, align 4
  %6193 = icmp ugt i64 80, %6192
  br i1 %6193, label %Abort, label %6194

6194:                                             ; preds = %.4173
  %6195 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6196 = xor i32 %6195, 3518
  %6197 = urem i32 %6196, 4096
  %6198 = getelementptr i8, i8 addrspace(1)* %4, i32 %6197
  %6199 = load i8, i8 addrspace(1)* %6198, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6198, align 1, !nosanitize !3
  store i32 1759, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6200 = sub i64 %6192, 80
  store i64 %6200, i64* %remaing_gas, align 4
  %6201 = load i64, i64* %STACK_DEP_PTR, align 4
  %6202 = getelementptr i256, i256* %STACK, i64 %6201
  %6203 = load i256, i256* %6202, align 4
  %6204 = load i64, i64* %STACK_DEP_PTR, align 4
  %6205 = sub i64 %6204, 1
  store i64 %6205, i64* %STACK_DEP_PTR, align 4
  %6206 = trunc i256 %6203 to i64
  store i64 %6206, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.4175:                                            ; preds = %890, %JumpTable
  %6207 = load i64, i64* %remaing_gas, align 4
  %6208 = icmp ugt i64 376, %6207
  br i1 %6208, label %Abort, label %6209

6209:                                             ; preds = %.4175
  %6210 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6211 = xor i32 %6210, 3184
  %6212 = urem i32 %6211, 4096
  %6213 = getelementptr i8, i8 addrspace(1)* %4, i32 %6212
  %6214 = load i8, i8 addrspace(1)* %6213, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6213, align 1, !nosanitize !3
  store i32 1592, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6215 = sub i64 %6207, 376
  store i64 %6215, i64* %remaing_gas, align 4
  %6216 = load i64, i64* %STACK_DEP_PTR, align 4
  %6217 = getelementptr i256, i256* %STACK, i64 %6216
  %6218 = load i256, i256* %6217, align 4
  %6219 = load i64, i64* %STACK_DEP_PTR, align 4
  %6220 = sub i64 %6219, 1
  store i64 %6220, i64* %STACK_DEP_PTR, align 4
  %6221 = alloca i256, align 8
  store i256 12, i256* %6221, align 4
  %6222 = alloca i256, align 8
  call void @__device_sload(i256* %6221, i256* %6222)
  %6223 = call i32 @__hashword(i256* %6221)
  %6224 = load i32, i32* %5, align 4
  %6225 = icmp eq i32 %6223, %6224
  %6226 = or i1 false, %6225
  %6227 = load i32, i32* %6, align 4
  %6228 = icmp eq i32 %6223, %6227
  %6229 = or i1 %6226, %6228
  %6230 = load i32, i32* %7, align 4
  %6231 = icmp eq i32 %6223, %6230
  %6232 = or i1 %6229, %6231
  %6233 = load i32, i32* %8, align 4
  %6234 = icmp eq i32 %6223, %6233
  %6235 = or i1 %6232, %6234
  %6236 = load i32, i32* %9, align 4
  %6237 = icmp eq i32 %6223, %6236
  %6238 = or i1 %6235, %6237
  %6239 = load i32, i32* %10, align 4
  %6240 = icmp eq i32 %6223, %6239
  %6241 = or i1 %6238, %6240
  %6242 = load i32, i32* %11, align 4
  %6243 = icmp eq i32 %6223, %6242
  %6244 = or i1 %6241, %6243
  %6245 = load i32, i32* %12, align 4
  %6246 = icmp eq i32 %6223, %6245
  %6247 = or i1 %6244, %6246
  %6248 = load i32, i32* %13, align 4
  %6249 = icmp eq i32 %6223, %6248
  %6250 = or i1 %6247, %6249
  %6251 = load i32, i32* %14, align 4
  %6252 = icmp eq i32 %6223, %6251
  %6253 = or i1 %6250, %6252
  %6254 = load i32, i32* %15, align 4
  %6255 = icmp eq i32 %6223, %6254
  %6256 = or i1 %6253, %6255
  %6257 = load i32, i32* %16, align 4
  %6258 = icmp eq i32 %6223, %6257
  %6259 = or i1 %6256, %6258
  %6260 = load i32, i32* %17, align 4
  %6261 = icmp eq i32 %6223, %6260
  %6262 = or i1 %6259, %6261
  %6263 = load i32, i32* %18, align 4
  %6264 = icmp eq i32 %6223, %6263
  %6265 = or i1 %6262, %6264
  %6266 = load i32, i32* %19, align 4
  %6267 = icmp eq i32 %6223, %6266
  %6268 = or i1 %6265, %6267
  %6269 = load i32, i32* %20, align 4
  %6270 = icmp eq i32 %6223, %6269
  %6271 = or i1 %6268, %6270
  %6272 = load i32, i32* %21, align 4
  %6273 = icmp eq i32 %6223, %6272
  %6274 = or i1 %6271, %6273
  %6275 = load i32, i32* %22, align 4
  %6276 = icmp eq i32 %6223, %6275
  %6277 = or i1 %6274, %6276
  %6278 = load i32, i32* %23, align 4
  %6279 = icmp eq i32 %6223, %6278
  %6280 = or i1 %6277, %6279
  %6281 = load i32, i32* %24, align 4
  %6282 = icmp eq i32 %6223, %6281
  %6283 = or i1 %6280, %6282
  %6284 = load i32, i32* %25, align 4
  %6285 = icmp eq i32 %6223, %6284
  %6286 = or i1 %6283, %6285
  %6287 = load i32, i32* %26, align 4
  %6288 = icmp eq i32 %6223, %6287
  %6289 = or i1 %6286, %6288
  %6290 = load i32, i32* %27, align 4
  %6291 = icmp eq i32 %6223, %6290
  %6292 = or i1 %6289, %6291
  %6293 = load i32, i32* %28, align 4
  %6294 = icmp eq i32 %6223, %6293
  %6295 = or i1 %6292, %6294
  %6296 = load i32, i32* %29, align 4
  %6297 = icmp eq i32 %6223, %6296
  %6298 = or i1 %6295, %6297
  %6299 = load i32, i32* %30, align 4
  %6300 = icmp eq i32 %6223, %6299
  %6301 = or i1 %6298, %6300
  %6302 = load i32, i32* %31, align 4
  %6303 = icmp eq i32 %6223, %6302
  %6304 = or i1 %6301, %6303
  %6305 = load i32, i32* %32, align 4
  %6306 = icmp eq i32 %6223, %6305
  %6307 = or i1 %6304, %6306
  %6308 = load i32, i32* %33, align 4
  %6309 = icmp eq i32 %6223, %6308
  %6310 = or i1 %6307, %6309
  %6311 = load i32, i32* %34, align 4
  %6312 = icmp eq i32 %6223, %6311
  %6313 = or i1 %6310, %6312
  %6314 = load i32, i32* %35, align 4
  %6315 = icmp eq i32 %6223, %6314
  %6316 = or i1 %6313, %6315
  %6317 = load i32, i32* %36, align 4
  %6318 = icmp eq i32 %6223, %6317
  %6319 = or i1 %6316, %6318
  %6320 = load i32, i32* %37, align 4
  %6321 = icmp eq i32 %6223, %6320
  %6322 = or i1 %6319, %6321
  %6323 = load i32, i32* %38, align 4
  %6324 = icmp eq i32 %6223, %6323
  %6325 = or i1 %6322, %6324
  %6326 = load i32, i32* %39, align 4
  %6327 = icmp eq i32 %6223, %6326
  %6328 = or i1 %6325, %6327
  %6329 = load i32, i32* %40, align 4
  %6330 = icmp eq i32 %6223, %6329
  %6331 = or i1 %6328, %6330
  %6332 = load i32, i32* %41, align 4
  %6333 = icmp eq i32 %6223, %6332
  %6334 = or i1 %6331, %6333
  %6335 = load i32, i32* %42, align 4
  %6336 = icmp eq i32 %6223, %6335
  %6337 = or i1 %6334, %6336
  %6338 = load i32, i32* %43, align 4
  %6339 = icmp eq i32 %6223, %6338
  %6340 = or i1 %6337, %6339
  %6341 = load i32, i32* %44, align 4
  %6342 = icmp eq i32 %6223, %6341
  %6343 = or i1 %6340, %6342
  %6344 = load i32, i32* %45, align 4
  %6345 = icmp eq i32 %6223, %6344
  %6346 = or i1 %6343, %6345
  %6347 = load i32, i32* %46, align 4
  %6348 = icmp eq i32 %6223, %6347
  %6349 = or i1 %6346, %6348
  %6350 = load i32, i32* %47, align 4
  %6351 = icmp eq i32 %6223, %6350
  %6352 = or i1 %6349, %6351
  %6353 = load i32, i32* %48, align 4
  %6354 = icmp eq i32 %6223, %6353
  %6355 = or i1 %6352, %6354
  %6356 = load i32, i32* %49, align 4
  %6357 = icmp eq i32 %6223, %6356
  %6358 = or i1 %6355, %6357
  %6359 = load i32, i32* %50, align 4
  %6360 = icmp eq i32 %6223, %6359
  %6361 = or i1 %6358, %6360
  %6362 = load i32, i32* %51, align 4
  %6363 = icmp eq i32 %6223, %6362
  %6364 = or i1 %6361, %6363
  %6365 = load i32, i32* %52, align 4
  %6366 = icmp eq i32 %6223, %6365
  %6367 = or i1 %6364, %6366
  %6368 = load i32, i32* %53, align 4
  %6369 = icmp eq i32 %6223, %6368
  %6370 = or i1 %6367, %6369
  %6371 = load i32, i32* %54, align 4
  %6372 = icmp eq i32 %6223, %6371
  %6373 = or i1 %6370, %6372
  %6374 = load i32, i32* %55, align 4
  %6375 = icmp eq i32 %6223, %6374
  %6376 = or i1 %6373, %6375
  %6377 = load i32, i32* %56, align 4
  %6378 = icmp eq i32 %6223, %6377
  %6379 = or i1 %6376, %6378
  %6380 = load i32, i32* %57, align 4
  %6381 = icmp eq i32 %6223, %6380
  %6382 = or i1 %6379, %6381
  %6383 = load i32, i32* %58, align 4
  %6384 = icmp eq i32 %6223, %6383
  %6385 = or i1 %6382, %6384
  %6386 = load i32, i32* %59, align 4
  %6387 = icmp eq i32 %6223, %6386
  %6388 = or i1 %6385, %6387
  %6389 = load i32, i32* %60, align 4
  %6390 = icmp eq i32 %6223, %6389
  %6391 = or i1 %6388, %6390
  %6392 = load i32, i32* %61, align 4
  %6393 = icmp eq i32 %6223, %6392
  %6394 = or i1 %6391, %6393
  %6395 = load i32, i32* %62, align 4
  %6396 = icmp eq i32 %6223, %6395
  %6397 = or i1 %6394, %6396
  %6398 = getelementptr i8, i8 addrspace(1)* %4, i32 7
  %6399 = zext i1 %6397 to i8
  store i8 %6399, i8 addrspace(1)* %6398, align 1, !nosanitize !3
  %6400 = load i256, i256* %6222, align 4
  %6401 = icmp ult i256 %6218, %6400
  %6402 = icmp eq i1 %6401, false
  %6403 = trunc i256 4358 to i64
  %jump.check13 = icmp ne i1 %6402, false
  %6404 = load i64, i64* %STACK_DEP_PTR, align 4
  %6405 = add i64 %6404, 1
  store i64 %6405, i64* %STACK_DEP_PTR, align 4
  %6406 = load i64, i64* %STACK_DEP_PTR, align 4
  %6407 = getelementptr i256, i256* %STACK, i64 %6406
  store i256 %6218, i256* %6407, align 4
  %6408 = load i64, i64* %STACK_DEP_PTR, align 4
  %6409 = add i64 %6408, 1
  store i64 %6409, i64* %STACK_DEP_PTR, align 4
  %6410 = load i64, i64* %STACK_DEP_PTR, align 4
  %6411 = getelementptr i256, i256* %STACK, i64 %6410
  store i256 0, i256* %6411, align 4
  %6412 = load i64, i64* %STACK_DEP_PTR, align 4
  %6413 = add i64 %6412, 1
  store i64 %6413, i64* %STACK_DEP_PTR, align 4
  %6414 = load i64, i64* %STACK_DEP_PTR, align 4
  %6415 = getelementptr i256, i256* %STACK, i64 %6414
  store i256 0, i256* %6415, align 4
  %6416 = load i64, i64* %STACK_DEP_PTR, align 4
  %6417 = add i64 %6416, 1
  store i64 %6417, i64* %STACK_DEP_PTR, align 4
  %6418 = load i64, i64* %STACK_DEP_PTR, align 4
  %6419 = getelementptr i256, i256* %STACK, i64 %6418
  store i256 0, i256* %6419, align 4
  %6420 = load i64, i64* %STACK_DEP_PTR, align 4
  %6421 = add i64 %6420, 1
  store i64 %6421, i64* %STACK_DEP_PTR, align 4
  %6422 = load i64, i64* %STACK_DEP_PTR, align 4
  %6423 = getelementptr i256, i256* %STACK, i64 %6422
  store i256 0, i256* %6423, align 4
  br i1 %jump.check13, label %.4358, label %.4195, !EVMBB !4

.4195:                                            ; preds = %6209
  %6424 = load i64, i64* %remaing_gas, align 4
  %6425 = icmp ugt i64 456, %6424
  br i1 %6425, label %Abort, label %6426

6426:                                             ; preds = %.4195
  %6427 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6428 = xor i32 %6427, 437
  %6429 = urem i32 %6428, 4096
  %6430 = getelementptr i8, i8 addrspace(1)* %4, i32 %6429
  %6431 = load i8, i8 addrspace(1)* %6430, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6430, align 1, !nosanitize !3
  store i32 218, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6432 = sub i64 %6424, 456
  store i64 %6432, i64* %remaing_gas, align 4
  %6433 = load i64, i64* %STACK_DEP_PTR, align 4
  %6434 = sub i64 %6433, 5
  store i64 %6434, i64* %STACK_DEP_PTR, align 4
  %6435 = alloca i256, align 8
  store i256 12, i256* %6435, align 4
  %6436 = alloca i256, align 8
  call void @__device_sload(i256* %6435, i256* %6436)
  %6437 = call i32 @__hashword(i256* %6435)
  %6438 = load i32, i32* %5, align 4
  %6439 = icmp eq i32 %6437, %6438
  %6440 = or i1 false, %6439
  %6441 = load i32, i32* %6, align 4
  %6442 = icmp eq i32 %6437, %6441
  %6443 = or i1 %6440, %6442
  %6444 = load i32, i32* %7, align 4
  %6445 = icmp eq i32 %6437, %6444
  %6446 = or i1 %6443, %6445
  %6447 = load i32, i32* %8, align 4
  %6448 = icmp eq i32 %6437, %6447
  %6449 = or i1 %6446, %6448
  %6450 = load i32, i32* %9, align 4
  %6451 = icmp eq i32 %6437, %6450
  %6452 = or i1 %6449, %6451
  %6453 = load i32, i32* %10, align 4
  %6454 = icmp eq i32 %6437, %6453
  %6455 = or i1 %6452, %6454
  %6456 = load i32, i32* %11, align 4
  %6457 = icmp eq i32 %6437, %6456
  %6458 = or i1 %6455, %6457
  %6459 = load i32, i32* %12, align 4
  %6460 = icmp eq i32 %6437, %6459
  %6461 = or i1 %6458, %6460
  %6462 = load i32, i32* %13, align 4
  %6463 = icmp eq i32 %6437, %6462
  %6464 = or i1 %6461, %6463
  %6465 = load i32, i32* %14, align 4
  %6466 = icmp eq i32 %6437, %6465
  %6467 = or i1 %6464, %6466
  %6468 = load i32, i32* %15, align 4
  %6469 = icmp eq i32 %6437, %6468
  %6470 = or i1 %6467, %6469
  %6471 = load i32, i32* %16, align 4
  %6472 = icmp eq i32 %6437, %6471
  %6473 = or i1 %6470, %6472
  %6474 = load i32, i32* %17, align 4
  %6475 = icmp eq i32 %6437, %6474
  %6476 = or i1 %6473, %6475
  %6477 = load i32, i32* %18, align 4
  %6478 = icmp eq i32 %6437, %6477
  %6479 = or i1 %6476, %6478
  %6480 = load i32, i32* %19, align 4
  %6481 = icmp eq i32 %6437, %6480
  %6482 = or i1 %6479, %6481
  %6483 = load i32, i32* %20, align 4
  %6484 = icmp eq i32 %6437, %6483
  %6485 = or i1 %6482, %6484
  %6486 = load i32, i32* %21, align 4
  %6487 = icmp eq i32 %6437, %6486
  %6488 = or i1 %6485, %6487
  %6489 = load i32, i32* %22, align 4
  %6490 = icmp eq i32 %6437, %6489
  %6491 = or i1 %6488, %6490
  %6492 = load i32, i32* %23, align 4
  %6493 = icmp eq i32 %6437, %6492
  %6494 = or i1 %6491, %6493
  %6495 = load i32, i32* %24, align 4
  %6496 = icmp eq i32 %6437, %6495
  %6497 = or i1 %6494, %6496
  %6498 = load i32, i32* %25, align 4
  %6499 = icmp eq i32 %6437, %6498
  %6500 = or i1 %6497, %6499
  %6501 = load i32, i32* %26, align 4
  %6502 = icmp eq i32 %6437, %6501
  %6503 = or i1 %6500, %6502
  %6504 = load i32, i32* %27, align 4
  %6505 = icmp eq i32 %6437, %6504
  %6506 = or i1 %6503, %6505
  %6507 = load i32, i32* %28, align 4
  %6508 = icmp eq i32 %6437, %6507
  %6509 = or i1 %6506, %6508
  %6510 = load i32, i32* %29, align 4
  %6511 = icmp eq i32 %6437, %6510
  %6512 = or i1 %6509, %6511
  %6513 = load i32, i32* %30, align 4
  %6514 = icmp eq i32 %6437, %6513
  %6515 = or i1 %6512, %6514
  %6516 = load i32, i32* %31, align 4
  %6517 = icmp eq i32 %6437, %6516
  %6518 = or i1 %6515, %6517
  %6519 = load i32, i32* %32, align 4
  %6520 = icmp eq i32 %6437, %6519
  %6521 = or i1 %6518, %6520
  %6522 = load i32, i32* %33, align 4
  %6523 = icmp eq i32 %6437, %6522
  %6524 = or i1 %6521, %6523
  %6525 = load i32, i32* %34, align 4
  %6526 = icmp eq i32 %6437, %6525
  %6527 = or i1 %6524, %6526
  %6528 = load i32, i32* %35, align 4
  %6529 = icmp eq i32 %6437, %6528
  %6530 = or i1 %6527, %6529
  %6531 = load i32, i32* %36, align 4
  %6532 = icmp eq i32 %6437, %6531
  %6533 = or i1 %6530, %6532
  %6534 = load i32, i32* %37, align 4
  %6535 = icmp eq i32 %6437, %6534
  %6536 = or i1 %6533, %6535
  %6537 = load i32, i32* %38, align 4
  %6538 = icmp eq i32 %6437, %6537
  %6539 = or i1 %6536, %6538
  %6540 = load i32, i32* %39, align 4
  %6541 = icmp eq i32 %6437, %6540
  %6542 = or i1 %6539, %6541
  %6543 = load i32, i32* %40, align 4
  %6544 = icmp eq i32 %6437, %6543
  %6545 = or i1 %6542, %6544
  %6546 = load i32, i32* %41, align 4
  %6547 = icmp eq i32 %6437, %6546
  %6548 = or i1 %6545, %6547
  %6549 = load i32, i32* %42, align 4
  %6550 = icmp eq i32 %6437, %6549
  %6551 = or i1 %6548, %6550
  %6552 = load i32, i32* %43, align 4
  %6553 = icmp eq i32 %6437, %6552
  %6554 = or i1 %6551, %6553
  %6555 = load i32, i32* %44, align 4
  %6556 = icmp eq i32 %6437, %6555
  %6557 = or i1 %6554, %6556
  %6558 = load i32, i32* %45, align 4
  %6559 = icmp eq i32 %6437, %6558
  %6560 = or i1 %6557, %6559
  %6561 = load i32, i32* %46, align 4
  %6562 = icmp eq i32 %6437, %6561
  %6563 = or i1 %6560, %6562
  %6564 = load i32, i32* %47, align 4
  %6565 = icmp eq i32 %6437, %6564
  %6566 = or i1 %6563, %6565
  %6567 = load i32, i32* %48, align 4
  %6568 = icmp eq i32 %6437, %6567
  %6569 = or i1 %6566, %6568
  %6570 = load i32, i32* %49, align 4
  %6571 = icmp eq i32 %6437, %6570
  %6572 = or i1 %6569, %6571
  %6573 = load i32, i32* %50, align 4
  %6574 = icmp eq i32 %6437, %6573
  %6575 = or i1 %6572, %6574
  %6576 = load i32, i32* %51, align 4
  %6577 = icmp eq i32 %6437, %6576
  %6578 = or i1 %6575, %6577
  %6579 = load i32, i32* %52, align 4
  %6580 = icmp eq i32 %6437, %6579
  %6581 = or i1 %6578, %6580
  %6582 = load i32, i32* %53, align 4
  %6583 = icmp eq i32 %6437, %6582
  %6584 = or i1 %6581, %6583
  %6585 = load i32, i32* %54, align 4
  %6586 = icmp eq i32 %6437, %6585
  %6587 = or i1 %6584, %6586
  %6588 = load i32, i32* %55, align 4
  %6589 = icmp eq i32 %6437, %6588
  %6590 = or i1 %6587, %6589
  %6591 = load i32, i32* %56, align 4
  %6592 = icmp eq i32 %6437, %6591
  %6593 = or i1 %6590, %6592
  %6594 = load i32, i32* %57, align 4
  %6595 = icmp eq i32 %6437, %6594
  %6596 = or i1 %6593, %6595
  %6597 = load i32, i32* %58, align 4
  %6598 = icmp eq i32 %6437, %6597
  %6599 = or i1 %6596, %6598
  %6600 = load i32, i32* %59, align 4
  %6601 = icmp eq i32 %6437, %6600
  %6602 = or i1 %6599, %6601
  %6603 = load i32, i32* %60, align 4
  %6604 = icmp eq i32 %6437, %6603
  %6605 = or i1 %6602, %6604
  %6606 = load i32, i32* %61, align 4
  %6607 = icmp eq i32 %6437, %6606
  %6608 = or i1 %6605, %6607
  %6609 = load i32, i32* %62, align 4
  %6610 = icmp eq i32 %6437, %6609
  %6611 = or i1 %6608, %6610
  %6612 = getelementptr i8, i8 addrspace(1)* %4, i32 8
  %6613 = zext i1 %6611 to i8
  store i8 %6613, i8 addrspace(1)* %6612, align 1, !nosanitize !3
  %6614 = load i256, i256* %6436, align 4
  %6615 = icmp ult i256 %6218, %6614
  %6616 = icmp eq i1 %6615, false
  %6617 = icmp eq i1 %6616, false
  %6618 = trunc i256 4209 to i64
  %jump.check18 = icmp ne i1 %6617, false
  %6619 = load i64, i64* %STACK_DEP_PTR, align 4
  %6620 = add i64 %6619, 1
  store i64 %6620, i64* %STACK_DEP_PTR, align 4
  %6621 = load i64, i64* %STACK_DEP_PTR, align 4
  %6622 = getelementptr i256, i256* %STACK, i64 %6621
  store i256 %6218, i256* %6622, align 4
  %6623 = load i64, i64* %STACK_DEP_PTR, align 4
  %6624 = add i64 %6623, 1
  store i64 %6624, i64* %STACK_DEP_PTR, align 4
  %6625 = load i64, i64* %STACK_DEP_PTR, align 4
  %6626 = getelementptr i256, i256* %STACK, i64 %6625
  store i256 0, i256* %6626, align 4
  %6627 = load i64, i64* %STACK_DEP_PTR, align 4
  %6628 = add i64 %6627, 1
  store i64 %6628, i64* %STACK_DEP_PTR, align 4
  %6629 = load i64, i64* %STACK_DEP_PTR, align 4
  %6630 = getelementptr i256, i256* %STACK, i64 %6629
  store i256 0, i256* %6630, align 4
  %6631 = load i64, i64* %STACK_DEP_PTR, align 4
  %6632 = add i64 %6631, 1
  store i64 %6632, i64* %STACK_DEP_PTR, align 4
  %6633 = load i64, i64* %STACK_DEP_PTR, align 4
  %6634 = getelementptr i256, i256* %STACK, i64 %6633
  store i256 0, i256* %6634, align 4
  %6635 = load i64, i64* %STACK_DEP_PTR, align 4
  %6636 = add i64 %6635, 1
  store i64 %6636, i64* %STACK_DEP_PTR, align 4
  %6637 = load i64, i64* %STACK_DEP_PTR, align 4
  %6638 = getelementptr i256, i256* %STACK, i64 %6637
  store i256 0, i256* %6638, align 4
  %6639 = load i64, i64* %STACK_DEP_PTR, align 4
  %6640 = add i64 %6639, 1
  store i64 %6640, i64* %STACK_DEP_PTR, align 4
  %6641 = load i64, i64* %STACK_DEP_PTR, align 4
  %6642 = getelementptr i256, i256* %STACK, i64 %6641
  store i256 12, i256* %6642, align 4
  %6643 = load i64, i64* %STACK_DEP_PTR, align 4
  %6644 = add i64 %6643, 1
  store i64 %6644, i64* %STACK_DEP_PTR, align 4
  %6645 = load i64, i64* %STACK_DEP_PTR, align 4
  %6646 = getelementptr i256, i256* %STACK, i64 %6645
  store i256 %6218, i256* %6646, align 4
  br i1 %jump.check18, label %.4209, label %.4208, !EVMBB !4

.4208:                                            ; preds = %6426
  %6647 = load i64, i64* %remaing_gas, align 4
  %6648 = icmp ugt i64 16, %6647
  br i1 %6648, label %Abort, label %6649

6649:                                             ; preds = %.4208
  %6650 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6651 = xor i32 %6650, 883
  %6652 = urem i32 %6651, 4096
  %6653 = getelementptr i8, i8 addrspace(1)* %4, i32 %6652
  %6654 = load i8, i8 addrspace(1)* %6653, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6653, align 1, !nosanitize !3
  store i32 441, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6655 = sub i64 %6647, 16
  store i64 %6655, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4209:                                            ; preds = %6426, %JumpTable
  %6656 = load i64, i64* %remaing_gas, align 4
  %6657 = icmp ugt i64 1408, %6656
  br i1 %6657, label %Abort, label %6658

6658:                                             ; preds = %.4209
  %6659 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6660 = xor i32 %6659, 1851
  %6661 = urem i32 %6660, 4096
  %6662 = getelementptr i8, i8 addrspace(1)* %4, i32 %6661
  %6663 = load i8, i8 addrspace(1)* %6662, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %6662, align 1, !nosanitize !3
  store i32 925, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %6664 = sub i64 %6656, 1408
  store i64 %6664, i64* %remaing_gas, align 4
  %6665 = load i64, i64* %STACK_DEP_PTR, align 4
  %6666 = getelementptr i256, i256* %STACK, i64 %6665
  %6667 = load i256, i256* %6666, align 4
  %6668 = load i64, i64* %STACK_DEP_PTR, align 4
  %6669 = sub i64 %6668, 1
  store i64 %6669, i64* %STACK_DEP_PTR, align 4
  %6670 = load i64, i64* %STACK_DEP_PTR, align 4
  %6671 = getelementptr i256, i256* %STACK, i64 %6670
  %6672 = load i256, i256* %6671, align 4
  %6673 = load i64, i64* %STACK_DEP_PTR, align 4
  %6674 = sub i64 %6673, 1
  store i64 %6674, i64* %STACK_DEP_PTR, align 4
  %6675 = load i64, i64* %STACK_DEP_PTR, align 4
  %6676 = getelementptr i256, i256* %STACK, i64 %6675
  %6677 = load i256, i256* %6676, align 4
  %6678 = load i64, i64* %STACK_DEP_PTR, align 4
  %6679 = sub i64 %6678, 1
  store i64 %6679, i64* %STACK_DEP_PTR, align 4
  %6680 = load i64, i64* %STACK_DEP_PTR, align 4
  %6681 = getelementptr i256, i256* %STACK, i64 %6680
  %6682 = load i256, i256* %6681, align 4
  %6683 = load i64, i64* %STACK_DEP_PTR, align 4
  %6684 = sub i64 %6683, 1
  store i64 %6684, i64* %STACK_DEP_PTR, align 4
  %6685 = load i64, i64* %STACK_DEP_PTR, align 4
  %6686 = getelementptr i256, i256* %STACK, i64 %6685
  %6687 = load i256, i256* %6686, align 4
  %6688 = load i64, i64* %STACK_DEP_PTR, align 4
  %6689 = sub i64 %6688, 1
  store i64 %6689, i64* %STACK_DEP_PTR, align 4
  %6690 = load i64, i64* %STACK_DEP_PTR, align 4
  %6691 = getelementptr i256, i256* %STACK, i64 %6690
  %6692 = load i256, i256* %6691, align 4
  %6693 = load i64, i64* %STACK_DEP_PTR, align 4
  %6694 = sub i64 %6693, 1
  store i64 %6694, i64* %STACK_DEP_PTR, align 4
  %6695 = trunc i256 0 to i64
  %6696 = alloca i256, align 8
  store i256 %6672, i256* %6696, align 4
  %6697 = bitcast i256* %6696 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %6695, i8* %6697, i64 32)
  %6698 = trunc i256 0 to i32
  %6699 = trunc i256 32 to i32
  %6700 = getelementptr inbounds i8, i8* %MEMORY, i32 %6698
  %6701 = alloca i256, align 8
  %6702 = bitcast i256* %6701 to i8*
  call void @__device_sha3(i8* %6700, i32 %6699, i8* %6702)
  %6703 = load i256, i256* %6701, align 4
  %6704 = add i256 %6703, %6667, !pc !207, !intsan !10
  %6705 = alloca i256, align 8
  store i256 %6704, i256* %6705, align 4
  %6706 = alloca i256, align 8
  call void @__device_sload(i256* %6705, i256* %6706)
  %6707 = call i32 @__hashword(i256* %6705)
  %6708 = load i32, i32* %5, align 4
  %6709 = icmp eq i32 %6707, %6708
  %6710 = or i1 false, %6709
  %6711 = load i32, i32* %6, align 4
  %6712 = icmp eq i32 %6707, %6711
  %6713 = or i1 %6710, %6712
  %6714 = load i32, i32* %7, align 4
  %6715 = icmp eq i32 %6707, %6714
  %6716 = or i1 %6713, %6715
  %6717 = load i32, i32* %8, align 4
  %6718 = icmp eq i32 %6707, %6717
  %6719 = or i1 %6716, %6718
  %6720 = load i32, i32* %9, align 4
  %6721 = icmp eq i32 %6707, %6720
  %6722 = or i1 %6719, %6721
  %6723 = load i32, i32* %10, align 4
  %6724 = icmp eq i32 %6707, %6723
  %6725 = or i1 %6722, %6724
  %6726 = load i32, i32* %11, align 4
  %6727 = icmp eq i32 %6707, %6726
  %6728 = or i1 %6725, %6727
  %6729 = load i32, i32* %12, align 4
  %6730 = icmp eq i32 %6707, %6729
  %6731 = or i1 %6728, %6730
  %6732 = load i32, i32* %13, align 4
  %6733 = icmp eq i32 %6707, %6732
  %6734 = or i1 %6731, %6733
  %6735 = load i32, i32* %14, align 4
  %6736 = icmp eq i32 %6707, %6735
  %6737 = or i1 %6734, %6736
  %6738 = load i32, i32* %15, align 4
  %6739 = icmp eq i32 %6707, %6738
  %6740 = or i1 %6737, %6739
  %6741 = load i32, i32* %16, align 4
  %6742 = icmp eq i32 %6707, %6741
  %6743 = or i1 %6740, %6742
  %6744 = load i32, i32* %17, align 4
  %6745 = icmp eq i32 %6707, %6744
  %6746 = or i1 %6743, %6745
  %6747 = load i32, i32* %18, align 4
  %6748 = icmp eq i32 %6707, %6747
  %6749 = or i1 %6746, %6748
  %6750 = load i32, i32* %19, align 4
  %6751 = icmp eq i32 %6707, %6750
  %6752 = or i1 %6749, %6751
  %6753 = load i32, i32* %20, align 4
  %6754 = icmp eq i32 %6707, %6753
  %6755 = or i1 %6752, %6754
  %6756 = load i32, i32* %21, align 4
  %6757 = icmp eq i32 %6707, %6756
  %6758 = or i1 %6755, %6757
  %6759 = load i32, i32* %22, align 4
  %6760 = icmp eq i32 %6707, %6759
  %6761 = or i1 %6758, %6760
  %6762 = load i32, i32* %23, align 4
  %6763 = icmp eq i32 %6707, %6762
  %6764 = or i1 %6761, %6763
  %6765 = load i32, i32* %24, align 4
  %6766 = icmp eq i32 %6707, %6765
  %6767 = or i1 %6764, %6766
  %6768 = load i32, i32* %25, align 4
  %6769 = icmp eq i32 %6707, %6768
  %6770 = or i1 %6767, %6769
  %6771 = load i32, i32* %26, align 4
  %6772 = icmp eq i32 %6707, %6771
  %6773 = or i1 %6770, %6772
  %6774 = load i32, i32* %27, align 4
  %6775 = icmp eq i32 %6707, %6774
  %6776 = or i1 %6773, %6775
  %6777 = load i32, i32* %28, align 4
  %6778 = icmp eq i32 %6707, %6777
  %6779 = or i1 %6776, %6778
  %6780 = load i32, i32* %29, align 4
  %6781 = icmp eq i32 %6707, %6780
  %6782 = or i1 %6779, %6781
  %6783 = load i32, i32* %30, align 4
  %6784 = icmp eq i32 %6707, %6783
  %6785 = or i1 %6782, %6784
  %6786 = load i32, i32* %31, align 4
  %6787 = icmp eq i32 %6707, %6786
  %6788 = or i1 %6785, %6787
  %6789 = load i32, i32* %32, align 4
  %6790 = icmp eq i32 %6707, %6789
  %6791 = or i1 %6788, %6790
  %6792 = load i32, i32* %33, align 4
  %6793 = icmp eq i32 %6707, %6792
  %6794 = or i1 %6791, %6793
  %6795 = load i32, i32* %34, align 4
  %6796 = icmp eq i32 %6707, %6795
  %6797 = or i1 %6794, %6796
  %6798 = load i32, i32* %35, align 4
  %6799 = icmp eq i32 %6707, %6798
  %6800 = or i1 %6797, %6799
  %6801 = load i32, i32* %36, align 4
  %6802 = icmp eq i32 %6707, %6801
  %6803 = or i1 %6800, %6802
  %6804 = load i32, i32* %37, align 4
  %6805 = icmp eq i32 %6707, %6804
  %6806 = or i1 %6803, %6805
  %6807 = load i32, i32* %38, align 4
  %6808 = icmp eq i32 %6707, %6807
  %6809 = or i1 %6806, %6808
  %6810 = load i32, i32* %39, align 4
  %6811 = icmp eq i32 %6707, %6810
  %6812 = or i1 %6809, %6811
  %6813 = load i32, i32* %40, align 4
  %6814 = icmp eq i32 %6707, %6813
  %6815 = or i1 %6812, %6814
  %6816 = load i32, i32* %41, align 4
  %6817 = icmp eq i32 %6707, %6816
  %6818 = or i1 %6815, %6817
  %6819 = load i32, i32* %42, align 4
  %6820 = icmp eq i32 %6707, %6819
  %6821 = or i1 %6818, %6820
  %6822 = load i32, i32* %43, align 4
  %6823 = icmp eq i32 %6707, %6822
  %6824 = or i1 %6821, %6823
  %6825 = load i32, i32* %44, align 4
  %6826 = icmp eq i32 %6707, %6825
  %6827 = or i1 %6824, %6826
  %6828 = load i32, i32* %45, align 4
  %6829 = icmp eq i32 %6707, %6828
  %6830 = or i1 %6827, %6829
  %6831 = load i32, i32* %46, align 4
  %6832 = icmp eq i32 %6707, %6831
  %6833 = or i1 %6830, %6832
  %6834 = load i32, i32* %47, align 4
  %6835 = icmp eq i32 %6707, %6834
  %6836 = or i1 %6833, %6835
  %6837 = load i32, i32* %48, align 4
  %6838 = icmp eq i32 %6707, %6837
  %6839 = or i1 %6836, %6838
  %6840 = load i32, i32* %49, align 4
  %6841 = icmp eq i32 %6707, %6840
  %6842 = or i1 %6839, %6841
  %6843 = load i32, i32* %50, align 4
  %6844 = icmp eq i32 %6707, %6843
  %6845 = or i1 %6842, %6844
  %6846 = load i32, i32* %51, align 4
  %6847 = icmp eq i32 %6707, %6846
  %6848 = or i1 %6845, %6847
  %6849 = load i32, i32* %52, align 4
  %6850 = icmp eq i32 %6707, %6849
  %6851 = or i1 %6848, %6850
  %6852 = load i32, i32* %53, align 4
  %6853 = icmp eq i32 %6707, %6852
  %6854 = or i1 %6851, %6853
  %6855 = load i32, i32* %54, align 4
  %6856 = icmp eq i32 %6707, %6855
  %6857 = or i1 %6854, %6856
  %6858 = load i32, i32* %55, align 4
  %6859 = icmp eq i32 %6707, %6858
  %6860 = or i1 %6857, %6859
  %6861 = load i32, i32* %56, align 4
  %6862 = icmp eq i32 %6707, %6861
  %6863 = or i1 %6860, %6862
  %6864 = load i32, i32* %57, align 4
  %6865 = icmp eq i32 %6707, %6864
  %6866 = or i1 %6863, %6865
  %6867 = load i32, i32* %58, align 4
  %6868 = icmp eq i32 %6707, %6867
  %6869 = or i1 %6866, %6868
  %6870 = load i32, i32* %59, align 4
  %6871 = icmp eq i32 %6707, %6870
  %6872 = or i1 %6869, %6871
  %6873 = load i32, i32* %60, align 4
  %6874 = icmp eq i32 %6707, %6873
  %6875 = or i1 %6872, %6874
  %6876 = load i32, i32* %61, align 4
  %6877 = icmp eq i32 %6707, %6876
  %6878 = or i1 %6875, %6877
  %6879 = load i32, i32* %62, align 4
  %6880 = icmp eq i32 %6707, %6879
  %6881 = or i1 %6878, %6880
  %6882 = getelementptr i8, i8 addrspace(1)* %4, i32 9
  %6883 = zext i1 %6881 to i8
  store i8 %6883, i8 addrspace(1)* %6882, align 1, !nosanitize !3
  %6884 = load i256, i256* %6706, align 4
  %6885 = xor i256 0, -1
  %6886 = and i256 %6885, %6884
  %6887 = xor i256 0, -1
  %6888 = and i256 %6887, %6886
  %6889 = trunc i256 0 to i64
  %6890 = alloca i256, align 8
  store i256 %6888, i256* %6890, align 4
  %6891 = bitcast i256* %6890 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %6889, i8* %6891, i64 32)
  %6892 = add i256 32, 0, !pc !208, !intsan !10
  %6893 = trunc i256 %6892 to i64
  %6894 = alloca i256, align 8
  store i256 11, i256* %6894, align 4
  %6895 = bitcast i256* %6894 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %6893, i8* %6895, i64 32)
  %6896 = add i256 32, %6892, !pc !209, !intsan !10
  %6897 = trunc i256 0 to i32
  %6898 = trunc i256 %6896 to i32
  %6899 = getelementptr inbounds i8, i8* %MEMORY, i32 %6897
  %6900 = alloca i256, align 8
  %6901 = bitcast i256* %6900 to i8*
  call void @__device_sha3(i8* %6899, i32 %6898, i8* %6901)
  %6902 = load i256, i256* %6900, align 4
  %6903 = add i256 0, %6902, !pc !210, !intsan !10
  %6904 = alloca i256, align 8
  store i256 %6903, i256* %6904, align 4
  %6905 = alloca i256, align 8
  call void @__device_sload(i256* %6904, i256* %6905)
  %6906 = call i32 @__hashword(i256* %6904)
  %6907 = load i32, i32* %5, align 4
  %6908 = icmp eq i32 %6906, %6907
  %6909 = or i1 false, %6908
  %6910 = load i32, i32* %6, align 4
  %6911 = icmp eq i32 %6906, %6910
  %6912 = or i1 %6909, %6911
  %6913 = load i32, i32* %7, align 4
  %6914 = icmp eq i32 %6906, %6913
  %6915 = or i1 %6912, %6914
  %6916 = load i32, i32* %8, align 4
  %6917 = icmp eq i32 %6906, %6916
  %6918 = or i1 %6915, %6917
  %6919 = load i32, i32* %9, align 4
  %6920 = icmp eq i32 %6906, %6919
  %6921 = or i1 %6918, %6920
  %6922 = load i32, i32* %10, align 4
  %6923 = icmp eq i32 %6906, %6922
  %6924 = or i1 %6921, %6923
  %6925 = load i32, i32* %11, align 4
  %6926 = icmp eq i32 %6906, %6925
  %6927 = or i1 %6924, %6926
  %6928 = load i32, i32* %12, align 4
  %6929 = icmp eq i32 %6906, %6928
  %6930 = or i1 %6927, %6929
  %6931 = load i32, i32* %13, align 4
  %6932 = icmp eq i32 %6906, %6931
  %6933 = or i1 %6930, %6932
  %6934 = load i32, i32* %14, align 4
  %6935 = icmp eq i32 %6906, %6934
  %6936 = or i1 %6933, %6935
  %6937 = load i32, i32* %15, align 4
  %6938 = icmp eq i32 %6906, %6937
  %6939 = or i1 %6936, %6938
  %6940 = load i32, i32* %16, align 4
  %6941 = icmp eq i32 %6906, %6940
  %6942 = or i1 %6939, %6941
  %6943 = load i32, i32* %17, align 4
  %6944 = icmp eq i32 %6906, %6943
  %6945 = or i1 %6942, %6944
  %6946 = load i32, i32* %18, align 4
  %6947 = icmp eq i32 %6906, %6946
  %6948 = or i1 %6945, %6947
  %6949 = load i32, i32* %19, align 4
  %6950 = icmp eq i32 %6906, %6949
  %6951 = or i1 %6948, %6950
  %6952 = load i32, i32* %20, align 4
  %6953 = icmp eq i32 %6906, %6952
  %6954 = or i1 %6951, %6953
  %6955 = load i32, i32* %21, align 4
  %6956 = icmp eq i32 %6906, %6955
  %6957 = or i1 %6954, %6956
  %6958 = load i32, i32* %22, align 4
  %6959 = icmp eq i32 %6906, %6958
  %6960 = or i1 %6957, %6959
  %6961 = load i32, i32* %23, align 4
  %6962 = icmp eq i32 %6906, %6961
  %6963 = or i1 %6960, %6962
  %6964 = load i32, i32* %24, align 4
  %6965 = icmp eq i32 %6906, %6964
  %6966 = or i1 %6963, %6965
  %6967 = load i32, i32* %25, align 4
  %6968 = icmp eq i32 %6906, %6967
  %6969 = or i1 %6966, %6968
  %6970 = load i32, i32* %26, align 4
  %6971 = icmp eq i32 %6906, %6970
  %6972 = or i1 %6969, %6971
  %6973 = load i32, i32* %27, align 4
  %6974 = icmp eq i32 %6906, %6973
  %6975 = or i1 %6972, %6974
  %6976 = load i32, i32* %28, align 4
  %6977 = icmp eq i32 %6906, %6976
  %6978 = or i1 %6975, %6977
  %6979 = load i32, i32* %29, align 4
  %6980 = icmp eq i32 %6906, %6979
  %6981 = or i1 %6978, %6980
  %6982 = load i32, i32* %30, align 4
  %6983 = icmp eq i32 %6906, %6982
  %6984 = or i1 %6981, %6983
  %6985 = load i32, i32* %31, align 4
  %6986 = icmp eq i32 %6906, %6985
  %6987 = or i1 %6984, %6986
  %6988 = load i32, i32* %32, align 4
  %6989 = icmp eq i32 %6906, %6988
  %6990 = or i1 %6987, %6989
  %6991 = load i32, i32* %33, align 4
  %6992 = icmp eq i32 %6906, %6991
  %6993 = or i1 %6990, %6992
  %6994 = load i32, i32* %34, align 4
  %6995 = icmp eq i32 %6906, %6994
  %6996 = or i1 %6993, %6995
  %6997 = load i32, i32* %35, align 4
  %6998 = icmp eq i32 %6906, %6997
  %6999 = or i1 %6996, %6998
  %7000 = load i32, i32* %36, align 4
  %7001 = icmp eq i32 %6906, %7000
  %7002 = or i1 %6999, %7001
  %7003 = load i32, i32* %37, align 4
  %7004 = icmp eq i32 %6906, %7003
  %7005 = or i1 %7002, %7004
  %7006 = load i32, i32* %38, align 4
  %7007 = icmp eq i32 %6906, %7006
  %7008 = or i1 %7005, %7007
  %7009 = load i32, i32* %39, align 4
  %7010 = icmp eq i32 %6906, %7009
  %7011 = or i1 %7008, %7010
  %7012 = load i32, i32* %40, align 4
  %7013 = icmp eq i32 %6906, %7012
  %7014 = or i1 %7011, %7013
  %7015 = load i32, i32* %41, align 4
  %7016 = icmp eq i32 %6906, %7015
  %7017 = or i1 %7014, %7016
  %7018 = load i32, i32* %42, align 4
  %7019 = icmp eq i32 %6906, %7018
  %7020 = or i1 %7017, %7019
  %7021 = load i32, i32* %43, align 4
  %7022 = icmp eq i32 %6906, %7021
  %7023 = or i1 %7020, %7022
  %7024 = load i32, i32* %44, align 4
  %7025 = icmp eq i32 %6906, %7024
  %7026 = or i1 %7023, %7025
  %7027 = load i32, i32* %45, align 4
  %7028 = icmp eq i32 %6906, %7027
  %7029 = or i1 %7026, %7028
  %7030 = load i32, i32* %46, align 4
  %7031 = icmp eq i32 %6906, %7030
  %7032 = or i1 %7029, %7031
  %7033 = load i32, i32* %47, align 4
  %7034 = icmp eq i32 %6906, %7033
  %7035 = or i1 %7032, %7034
  %7036 = load i32, i32* %48, align 4
  %7037 = icmp eq i32 %6906, %7036
  %7038 = or i1 %7035, %7037
  %7039 = load i32, i32* %49, align 4
  %7040 = icmp eq i32 %6906, %7039
  %7041 = or i1 %7038, %7040
  %7042 = load i32, i32* %50, align 4
  %7043 = icmp eq i32 %6906, %7042
  %7044 = or i1 %7041, %7043
  %7045 = load i32, i32* %51, align 4
  %7046 = icmp eq i32 %6906, %7045
  %7047 = or i1 %7044, %7046
  %7048 = load i32, i32* %52, align 4
  %7049 = icmp eq i32 %6906, %7048
  %7050 = or i1 %7047, %7049
  %7051 = load i32, i32* %53, align 4
  %7052 = icmp eq i32 %6906, %7051
  %7053 = or i1 %7050, %7052
  %7054 = load i32, i32* %54, align 4
  %7055 = icmp eq i32 %6906, %7054
  %7056 = or i1 %7053, %7055
  %7057 = load i32, i32* %55, align 4
  %7058 = icmp eq i32 %6906, %7057
  %7059 = or i1 %7056, %7058
  %7060 = load i32, i32* %56, align 4
  %7061 = icmp eq i32 %6906, %7060
  %7062 = or i1 %7059, %7061
  %7063 = load i32, i32* %57, align 4
  %7064 = icmp eq i32 %6906, %7063
  %7065 = or i1 %7062, %7064
  %7066 = load i32, i32* %58, align 4
  %7067 = icmp eq i32 %6906, %7066
  %7068 = or i1 %7065, %7067
  %7069 = load i32, i32* %59, align 4
  %7070 = icmp eq i32 %6906, %7069
  %7071 = or i1 %7068, %7070
  %7072 = load i32, i32* %60, align 4
  %7073 = icmp eq i32 %6906, %7072
  %7074 = or i1 %7071, %7073
  %7075 = load i32, i32* %61, align 4
  %7076 = icmp eq i32 %6906, %7075
  %7077 = or i1 %7074, %7076
  %7078 = load i32, i32* %62, align 4
  %7079 = icmp eq i32 %6906, %7078
  %7080 = or i1 %7077, %7079
  %7081 = getelementptr i8, i8 addrspace(1)* %4, i32 10
  %7082 = zext i1 %7080 to i8
  store i8 %7082, i8 addrspace(1)* %7081, align 1, !nosanitize !3
  %7083 = load i256, i256* %6905, align 4
  %7084 = alloca i256, align 8
  store i256 %7083, i256* %7084, align 4
  %7085 = alloca i256, align 8
  store i256 1, i256* %7085, align 4
  %7086 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %7084, i256* %7085, i256* %7086), !pc !211, !intsan !6
  %7087 = load i256, i256* %7086, align 4
  %7088 = and i256 1461501637330902918203684832716283019655932542975, %7087
  %7089 = xor i256 0, -1
  %7090 = and i256 %7089, %6884
  %7091 = xor i256 0, -1
  %7092 = and i256 %7091, %7090
  %7093 = trunc i256 0 to i64
  %7094 = alloca i256, align 8
  store i256 %7092, i256* %7094, align 4
  %7095 = bitcast i256* %7094 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %7093, i8* %7095, i64 32)
  %7096 = add i256 32, 0, !pc !212, !intsan !10
  %7097 = trunc i256 %7096 to i64
  %7098 = alloca i256, align 8
  store i256 11, i256* %7098, align 4
  %7099 = bitcast i256* %7098 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %7097, i8* %7099, i64 32)
  %7100 = add i256 32, %7096, !pc !213, !intsan !10
  %7101 = trunc i256 0 to i32
  %7102 = trunc i256 %7100 to i32
  %7103 = getelementptr inbounds i8, i8* %MEMORY, i32 %7101
  %7104 = alloca i256, align 8
  %7105 = bitcast i256* %7104 to i8*
  call void @__device_sha3(i8* %7103, i32 %7102, i8* %7105)
  %7106 = load i256, i256* %7104, align 4
  %7107 = add i256 1, %7106, !pc !214, !intsan !10
  %7108 = alloca i256, align 8
  store i256 %7107, i256* %7108, align 4
  %7109 = alloca i256, align 8
  call void @__device_sload(i256* %7108, i256* %7109)
  %7110 = call i32 @__hashword(i256* %7108)
  %7111 = load i32, i32* %5, align 4
  %7112 = icmp eq i32 %7110, %7111
  %7113 = or i1 false, %7112
  %7114 = load i32, i32* %6, align 4
  %7115 = icmp eq i32 %7110, %7114
  %7116 = or i1 %7113, %7115
  %7117 = load i32, i32* %7, align 4
  %7118 = icmp eq i32 %7110, %7117
  %7119 = or i1 %7116, %7118
  %7120 = load i32, i32* %8, align 4
  %7121 = icmp eq i32 %7110, %7120
  %7122 = or i1 %7119, %7121
  %7123 = load i32, i32* %9, align 4
  %7124 = icmp eq i32 %7110, %7123
  %7125 = or i1 %7122, %7124
  %7126 = load i32, i32* %10, align 4
  %7127 = icmp eq i32 %7110, %7126
  %7128 = or i1 %7125, %7127
  %7129 = load i32, i32* %11, align 4
  %7130 = icmp eq i32 %7110, %7129
  %7131 = or i1 %7128, %7130
  %7132 = load i32, i32* %12, align 4
  %7133 = icmp eq i32 %7110, %7132
  %7134 = or i1 %7131, %7133
  %7135 = load i32, i32* %13, align 4
  %7136 = icmp eq i32 %7110, %7135
  %7137 = or i1 %7134, %7136
  %7138 = load i32, i32* %14, align 4
  %7139 = icmp eq i32 %7110, %7138
  %7140 = or i1 %7137, %7139
  %7141 = load i32, i32* %15, align 4
  %7142 = icmp eq i32 %7110, %7141
  %7143 = or i1 %7140, %7142
  %7144 = load i32, i32* %16, align 4
  %7145 = icmp eq i32 %7110, %7144
  %7146 = or i1 %7143, %7145
  %7147 = load i32, i32* %17, align 4
  %7148 = icmp eq i32 %7110, %7147
  %7149 = or i1 %7146, %7148
  %7150 = load i32, i32* %18, align 4
  %7151 = icmp eq i32 %7110, %7150
  %7152 = or i1 %7149, %7151
  %7153 = load i32, i32* %19, align 4
  %7154 = icmp eq i32 %7110, %7153
  %7155 = or i1 %7152, %7154
  %7156 = load i32, i32* %20, align 4
  %7157 = icmp eq i32 %7110, %7156
  %7158 = or i1 %7155, %7157
  %7159 = load i32, i32* %21, align 4
  %7160 = icmp eq i32 %7110, %7159
  %7161 = or i1 %7158, %7160
  %7162 = load i32, i32* %22, align 4
  %7163 = icmp eq i32 %7110, %7162
  %7164 = or i1 %7161, %7163
  %7165 = load i32, i32* %23, align 4
  %7166 = icmp eq i32 %7110, %7165
  %7167 = or i1 %7164, %7166
  %7168 = load i32, i32* %24, align 4
  %7169 = icmp eq i32 %7110, %7168
  %7170 = or i1 %7167, %7169
  %7171 = load i32, i32* %25, align 4
  %7172 = icmp eq i32 %7110, %7171
  %7173 = or i1 %7170, %7172
  %7174 = load i32, i32* %26, align 4
  %7175 = icmp eq i32 %7110, %7174
  %7176 = or i1 %7173, %7175
  %7177 = load i32, i32* %27, align 4
  %7178 = icmp eq i32 %7110, %7177
  %7179 = or i1 %7176, %7178
  %7180 = load i32, i32* %28, align 4
  %7181 = icmp eq i32 %7110, %7180
  %7182 = or i1 %7179, %7181
  %7183 = load i32, i32* %29, align 4
  %7184 = icmp eq i32 %7110, %7183
  %7185 = or i1 %7182, %7184
  %7186 = load i32, i32* %30, align 4
  %7187 = icmp eq i32 %7110, %7186
  %7188 = or i1 %7185, %7187
  %7189 = load i32, i32* %31, align 4
  %7190 = icmp eq i32 %7110, %7189
  %7191 = or i1 %7188, %7190
  %7192 = load i32, i32* %32, align 4
  %7193 = icmp eq i32 %7110, %7192
  %7194 = or i1 %7191, %7193
  %7195 = load i32, i32* %33, align 4
  %7196 = icmp eq i32 %7110, %7195
  %7197 = or i1 %7194, %7196
  %7198 = load i32, i32* %34, align 4
  %7199 = icmp eq i32 %7110, %7198
  %7200 = or i1 %7197, %7199
  %7201 = load i32, i32* %35, align 4
  %7202 = icmp eq i32 %7110, %7201
  %7203 = or i1 %7200, %7202
  %7204 = load i32, i32* %36, align 4
  %7205 = icmp eq i32 %7110, %7204
  %7206 = or i1 %7203, %7205
  %7207 = load i32, i32* %37, align 4
  %7208 = icmp eq i32 %7110, %7207
  %7209 = or i1 %7206, %7208
  %7210 = load i32, i32* %38, align 4
  %7211 = icmp eq i32 %7110, %7210
  %7212 = or i1 %7209, %7211
  %7213 = load i32, i32* %39, align 4
  %7214 = icmp eq i32 %7110, %7213
  %7215 = or i1 %7212, %7214
  %7216 = load i32, i32* %40, align 4
  %7217 = icmp eq i32 %7110, %7216
  %7218 = or i1 %7215, %7217
  %7219 = load i32, i32* %41, align 4
  %7220 = icmp eq i32 %7110, %7219
  %7221 = or i1 %7218, %7220
  %7222 = load i32, i32* %42, align 4
  %7223 = icmp eq i32 %7110, %7222
  %7224 = or i1 %7221, %7223
  %7225 = load i32, i32* %43, align 4
  %7226 = icmp eq i32 %7110, %7225
  %7227 = or i1 %7224, %7226
  %7228 = load i32, i32* %44, align 4
  %7229 = icmp eq i32 %7110, %7228
  %7230 = or i1 %7227, %7229
  %7231 = load i32, i32* %45, align 4
  %7232 = icmp eq i32 %7110, %7231
  %7233 = or i1 %7230, %7232
  %7234 = load i32, i32* %46, align 4
  %7235 = icmp eq i32 %7110, %7234
  %7236 = or i1 %7233, %7235
  %7237 = load i32, i32* %47, align 4
  %7238 = icmp eq i32 %7110, %7237
  %7239 = or i1 %7236, %7238
  %7240 = load i32, i32* %48, align 4
  %7241 = icmp eq i32 %7110, %7240
  %7242 = or i1 %7239, %7241
  %7243 = load i32, i32* %49, align 4
  %7244 = icmp eq i32 %7110, %7243
  %7245 = or i1 %7242, %7244
  %7246 = load i32, i32* %50, align 4
  %7247 = icmp eq i32 %7110, %7246
  %7248 = or i1 %7245, %7247
  %7249 = load i32, i32* %51, align 4
  %7250 = icmp eq i32 %7110, %7249
  %7251 = or i1 %7248, %7250
  %7252 = load i32, i32* %52, align 4
  %7253 = icmp eq i32 %7110, %7252
  %7254 = or i1 %7251, %7253
  %7255 = load i32, i32* %53, align 4
  %7256 = icmp eq i32 %7110, %7255
  %7257 = or i1 %7254, %7256
  %7258 = load i32, i32* %54, align 4
  %7259 = icmp eq i32 %7110, %7258
  %7260 = or i1 %7257, %7259
  %7261 = load i32, i32* %55, align 4
  %7262 = icmp eq i32 %7110, %7261
  %7263 = or i1 %7260, %7262
  %7264 = load i32, i32* %56, align 4
  %7265 = icmp eq i32 %7110, %7264
  %7266 = or i1 %7263, %7265
  %7267 = load i32, i32* %57, align 4
  %7268 = icmp eq i32 %7110, %7267
  %7269 = or i1 %7266, %7268
  %7270 = load i32, i32* %58, align 4
  %7271 = icmp eq i32 %7110, %7270
  %7272 = or i1 %7269, %7271
  %7273 = load i32, i32* %59, align 4
  %7274 = icmp eq i32 %7110, %7273
  %7275 = or i1 %7272, %7274
  %7276 = load i32, i32* %60, align 4
  %7277 = icmp eq i32 %7110, %7276
  %7278 = or i1 %7275, %7277
  %7279 = load i32, i32* %61, align 4
  %7280 = icmp eq i32 %7110, %7279
  %7281 = or i1 %7278, %7280
  %7282 = load i32, i32* %62, align 4
  %7283 = icmp eq i32 %7110, %7282
  %7284 = or i1 %7281, %7283
  %7285 = getelementptr i8, i8 addrspace(1)* %4, i32 11
  %7286 = zext i1 %7284 to i8
  store i8 %7286, i8 addrspace(1)* %7285, align 1, !nosanitize !3
  %7287 = load i256, i256* %7109, align 4
  %7288 = xor i256 0, -1
  %7289 = and i256 %7288, %6884
  %7290 = xor i256 0, -1
  %7291 = and i256 %7290, %7289
  %7292 = trunc i256 0 to i64
  %7293 = alloca i256, align 8
  store i256 %7291, i256* %7293, align 4
  %7294 = bitcast i256* %7293 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %7292, i8* %7294, i64 32)
  %7295 = add i256 32, 0, !pc !215, !intsan !10
  %7296 = trunc i256 %7295 to i64
  %7297 = alloca i256, align 8
  store i256 11, i256* %7297, align 4
  %7298 = bitcast i256* %7297 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %7296, i8* %7298, i64 32)
  %7299 = add i256 32, %7295, !pc !216, !intsan !10
  %7300 = trunc i256 0 to i32
  %7301 = trunc i256 %7299 to i32
  %7302 = getelementptr inbounds i8, i8* %MEMORY, i32 %7300
  %7303 = alloca i256, align 8
  %7304 = bitcast i256* %7303 to i8*
  call void @__device_sha3(i8* %7302, i32 %7301, i8* %7304)
  %7305 = load i256, i256* %7303, align 4
  %7306 = add i256 2, %7305, !pc !217, !intsan !10
  %7307 = alloca i256, align 8
  store i256 %7306, i256* %7307, align 4
  %7308 = alloca i256, align 8
  call void @__device_sload(i256* %7307, i256* %7308)
  %7309 = call i32 @__hashword(i256* %7307)
  %7310 = load i32, i32* %5, align 4
  %7311 = icmp eq i32 %7309, %7310
  %7312 = or i1 false, %7311
  %7313 = load i32, i32* %6, align 4
  %7314 = icmp eq i32 %7309, %7313
  %7315 = or i1 %7312, %7314
  %7316 = load i32, i32* %7, align 4
  %7317 = icmp eq i32 %7309, %7316
  %7318 = or i1 %7315, %7317
  %7319 = load i32, i32* %8, align 4
  %7320 = icmp eq i32 %7309, %7319
  %7321 = or i1 %7318, %7320
  %7322 = load i32, i32* %9, align 4
  %7323 = icmp eq i32 %7309, %7322
  %7324 = or i1 %7321, %7323
  %7325 = load i32, i32* %10, align 4
  %7326 = icmp eq i32 %7309, %7325
  %7327 = or i1 %7324, %7326
  %7328 = load i32, i32* %11, align 4
  %7329 = icmp eq i32 %7309, %7328
  %7330 = or i1 %7327, %7329
  %7331 = load i32, i32* %12, align 4
  %7332 = icmp eq i32 %7309, %7331
  %7333 = or i1 %7330, %7332
  %7334 = load i32, i32* %13, align 4
  %7335 = icmp eq i32 %7309, %7334
  %7336 = or i1 %7333, %7335
  %7337 = load i32, i32* %14, align 4
  %7338 = icmp eq i32 %7309, %7337
  %7339 = or i1 %7336, %7338
  %7340 = load i32, i32* %15, align 4
  %7341 = icmp eq i32 %7309, %7340
  %7342 = or i1 %7339, %7341
  %7343 = load i32, i32* %16, align 4
  %7344 = icmp eq i32 %7309, %7343
  %7345 = or i1 %7342, %7344
  %7346 = load i32, i32* %17, align 4
  %7347 = icmp eq i32 %7309, %7346
  %7348 = or i1 %7345, %7347
  %7349 = load i32, i32* %18, align 4
  %7350 = icmp eq i32 %7309, %7349
  %7351 = or i1 %7348, %7350
  %7352 = load i32, i32* %19, align 4
  %7353 = icmp eq i32 %7309, %7352
  %7354 = or i1 %7351, %7353
  %7355 = load i32, i32* %20, align 4
  %7356 = icmp eq i32 %7309, %7355
  %7357 = or i1 %7354, %7356
  %7358 = load i32, i32* %21, align 4
  %7359 = icmp eq i32 %7309, %7358
  %7360 = or i1 %7357, %7359
  %7361 = load i32, i32* %22, align 4
  %7362 = icmp eq i32 %7309, %7361
  %7363 = or i1 %7360, %7362
  %7364 = load i32, i32* %23, align 4
  %7365 = icmp eq i32 %7309, %7364
  %7366 = or i1 %7363, %7365
  %7367 = load i32, i32* %24, align 4
  %7368 = icmp eq i32 %7309, %7367
  %7369 = or i1 %7366, %7368
  %7370 = load i32, i32* %25, align 4
  %7371 = icmp eq i32 %7309, %7370
  %7372 = or i1 %7369, %7371
  %7373 = load i32, i32* %26, align 4
  %7374 = icmp eq i32 %7309, %7373
  %7375 = or i1 %7372, %7374
  %7376 = load i32, i32* %27, align 4
  %7377 = icmp eq i32 %7309, %7376
  %7378 = or i1 %7375, %7377
  %7379 = load i32, i32* %28, align 4
  %7380 = icmp eq i32 %7309, %7379
  %7381 = or i1 %7378, %7380
  %7382 = load i32, i32* %29, align 4
  %7383 = icmp eq i32 %7309, %7382
  %7384 = or i1 %7381, %7383
  %7385 = load i32, i32* %30, align 4
  %7386 = icmp eq i32 %7309, %7385
  %7387 = or i1 %7384, %7386
  %7388 = load i32, i32* %31, align 4
  %7389 = icmp eq i32 %7309, %7388
  %7390 = or i1 %7387, %7389
  %7391 = load i32, i32* %32, align 4
  %7392 = icmp eq i32 %7309, %7391
  %7393 = or i1 %7390, %7392
  %7394 = load i32, i32* %33, align 4
  %7395 = icmp eq i32 %7309, %7394
  %7396 = or i1 %7393, %7395
  %7397 = load i32, i32* %34, align 4
  %7398 = icmp eq i32 %7309, %7397
  %7399 = or i1 %7396, %7398
  %7400 = load i32, i32* %35, align 4
  %7401 = icmp eq i32 %7309, %7400
  %7402 = or i1 %7399, %7401
  %7403 = load i32, i32* %36, align 4
  %7404 = icmp eq i32 %7309, %7403
  %7405 = or i1 %7402, %7404
  %7406 = load i32, i32* %37, align 4
  %7407 = icmp eq i32 %7309, %7406
  %7408 = or i1 %7405, %7407
  %7409 = load i32, i32* %38, align 4
  %7410 = icmp eq i32 %7309, %7409
  %7411 = or i1 %7408, %7410
  %7412 = load i32, i32* %39, align 4
  %7413 = icmp eq i32 %7309, %7412
  %7414 = or i1 %7411, %7413
  %7415 = load i32, i32* %40, align 4
  %7416 = icmp eq i32 %7309, %7415
  %7417 = or i1 %7414, %7416
  %7418 = load i32, i32* %41, align 4
  %7419 = icmp eq i32 %7309, %7418
  %7420 = or i1 %7417, %7419
  %7421 = load i32, i32* %42, align 4
  %7422 = icmp eq i32 %7309, %7421
  %7423 = or i1 %7420, %7422
  %7424 = load i32, i32* %43, align 4
  %7425 = icmp eq i32 %7309, %7424
  %7426 = or i1 %7423, %7425
  %7427 = load i32, i32* %44, align 4
  %7428 = icmp eq i32 %7309, %7427
  %7429 = or i1 %7426, %7428
  %7430 = load i32, i32* %45, align 4
  %7431 = icmp eq i32 %7309, %7430
  %7432 = or i1 %7429, %7431
  %7433 = load i32, i32* %46, align 4
  %7434 = icmp eq i32 %7309, %7433
  %7435 = or i1 %7432, %7434
  %7436 = load i32, i32* %47, align 4
  %7437 = icmp eq i32 %7309, %7436
  %7438 = or i1 %7435, %7437
  %7439 = load i32, i32* %48, align 4
  %7440 = icmp eq i32 %7309, %7439
  %7441 = or i1 %7438, %7440
  %7442 = load i32, i32* %49, align 4
  %7443 = icmp eq i32 %7309, %7442
  %7444 = or i1 %7441, %7443
  %7445 = load i32, i32* %50, align 4
  %7446 = icmp eq i32 %7309, %7445
  %7447 = or i1 %7444, %7446
  %7448 = load i32, i32* %51, align 4
  %7449 = icmp eq i32 %7309, %7448
  %7450 = or i1 %7447, %7449
  %7451 = load i32, i32* %52, align 4
  %7452 = icmp eq i32 %7309, %7451
  %7453 = or i1 %7450, %7452
  %7454 = load i32, i32* %53, align 4
  %7455 = icmp eq i32 %7309, %7454
  %7456 = or i1 %7453, %7455
  %7457 = load i32, i32* %54, align 4
  %7458 = icmp eq i32 %7309, %7457
  %7459 = or i1 %7456, %7458
  %7460 = load i32, i32* %55, align 4
  %7461 = icmp eq i32 %7309, %7460
  %7462 = or i1 %7459, %7461
  %7463 = load i32, i32* %56, align 4
  %7464 = icmp eq i32 %7309, %7463
  %7465 = or i1 %7462, %7464
  %7466 = load i32, i32* %57, align 4
  %7467 = icmp eq i32 %7309, %7466
  %7468 = or i1 %7465, %7467
  %7469 = load i32, i32* %58, align 4
  %7470 = icmp eq i32 %7309, %7469
  %7471 = or i1 %7468, %7470
  %7472 = load i32, i32* %59, align 4
  %7473 = icmp eq i32 %7309, %7472
  %7474 = or i1 %7471, %7473
  %7475 = load i32, i32* %60, align 4
  %7476 = icmp eq i32 %7309, %7475
  %7477 = or i1 %7474, %7476
  %7478 = load i32, i32* %61, align 4
  %7479 = icmp eq i32 %7309, %7478
  %7480 = or i1 %7477, %7479
  %7481 = load i32, i32* %62, align 4
  %7482 = icmp eq i32 %7309, %7481
  %7483 = or i1 %7480, %7482
  %7484 = getelementptr i8, i8 addrspace(1)* %4, i32 12
  %7485 = zext i1 %7483 to i8
  store i8 %7485, i8 addrspace(1)* %7484, align 1, !nosanitize !3
  %7486 = load i256, i256* %7308, align 4
  %7487 = trunc i256 4359 to i64
  %7488 = load i64, i64* %STACK_DEP_PTR, align 4
  %7489 = add i64 %7488, 1
  store i64 %7489, i64* %STACK_DEP_PTR, align 4
  %7490 = load i64, i64* %STACK_DEP_PTR, align 4
  %7491 = getelementptr i256, i256* %STACK, i64 %7490
  store i256 %7088, i256* %7491, align 4
  %7492 = load i64, i64* %STACK_DEP_PTR, align 4
  %7493 = add i64 %7492, 1
  store i64 %7493, i64* %STACK_DEP_PTR, align 4
  %7494 = load i64, i64* %STACK_DEP_PTR, align 4
  %7495 = getelementptr i256, i256* %STACK, i64 %7494
  store i256 %7287, i256* %7495, align 4
  %7496 = load i64, i64* %STACK_DEP_PTR, align 4
  %7497 = add i64 %7496, 1
  store i64 %7497, i64* %STACK_DEP_PTR, align 4
  %7498 = load i64, i64* %STACK_DEP_PTR, align 4
  %7499 = getelementptr i256, i256* %STACK, i64 %7498
  store i256 %7486, i256* %7499, align 4
  %7500 = load i64, i64* %STACK_DEP_PTR, align 4
  %7501 = add i64 %7500, 1
  store i64 %7501, i64* %STACK_DEP_PTR, align 4
  %7502 = load i64, i64* %STACK_DEP_PTR, align 4
  %7503 = getelementptr i256, i256* %STACK, i64 %7502
  store i256 %6884, i256* %7503, align 4
  br label %.4359, !EVMBB !4

.4358:                                            ; preds = %6209, %JumpTable
  br label %.4359

.4359:                                            ; preds = %.4358, %6658, %JumpTable
  %7504 = load i64, i64* %remaing_gas, align 4
  %7505 = icmp ugt i64 464, %7504
  br i1 %7505, label %Abort, label %7506

7506:                                             ; preds = %.4359
  %7507 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %7508 = xor i32 %7507, 2308
  %7509 = urem i32 %7508, 4096
  %7510 = getelementptr i8, i8 addrspace(1)* %4, i32 %7509
  %7511 = load i8, i8 addrspace(1)* %7510, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %7510, align 1, !nosanitize !3
  store i32 1154, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %7512 = sub i64 %7504, 464
  store i64 %7512, i64* %remaing_gas, align 4
  %7513 = load i64, i64* %STACK_DEP_PTR, align 4
  %7514 = getelementptr i256, i256* %STACK, i64 %7513
  %7515 = load i256, i256* %7514, align 4
  %7516 = load i64, i64* %STACK_DEP_PTR, align 4
  %7517 = sub i64 %7516, 1
  store i64 %7517, i64* %STACK_DEP_PTR, align 4
  %7518 = load i64, i64* %STACK_DEP_PTR, align 4
  %7519 = getelementptr i256, i256* %STACK, i64 %7518
  %7520 = load i256, i256* %7519, align 4
  %7521 = load i64, i64* %STACK_DEP_PTR, align 4
  %7522 = sub i64 %7521, 1
  store i64 %7522, i64* %STACK_DEP_PTR, align 4
  %7523 = load i64, i64* %STACK_DEP_PTR, align 4
  %7524 = getelementptr i256, i256* %STACK, i64 %7523
  %7525 = load i256, i256* %7524, align 4
  %7526 = load i64, i64* %STACK_DEP_PTR, align 4
  %7527 = sub i64 %7526, 1
  store i64 %7527, i64* %STACK_DEP_PTR, align 4
  %7528 = load i64, i64* %STACK_DEP_PTR, align 4
  %7529 = getelementptr i256, i256* %STACK, i64 %7528
  %7530 = load i256, i256* %7529, align 4
  %7531 = load i64, i64* %STACK_DEP_PTR, align 4
  %7532 = sub i64 %7531, 1
  store i64 %7532, i64* %STACK_DEP_PTR, align 4
  %7533 = load i64, i64* %STACK_DEP_PTR, align 4
  %7534 = getelementptr i256, i256* %STACK, i64 %7533
  %7535 = load i256, i256* %7534, align 4
  %7536 = load i64, i64* %STACK_DEP_PTR, align 4
  %7537 = sub i64 %7536, 1
  store i64 %7537, i64* %STACK_DEP_PTR, align 4
  %7538 = load i64, i64* %STACK_DEP_PTR, align 4
  %7539 = getelementptr i256, i256* %STACK, i64 %7538
  %7540 = load i256, i256* %7539, align 4
  %7541 = load i64, i64* %STACK_DEP_PTR, align 4
  %7542 = sub i64 %7541, 1
  store i64 %7542, i64* %STACK_DEP_PTR, align 4
  %7543 = trunc i256 %7540 to i64
  store i64 %7543, i64* %JMP_TARGET_PTR, align 4
  %7544 = load i64, i64* %STACK_DEP_PTR, align 4
  %7545 = add i64 %7544, 1
  store i64 %7545, i64* %STACK_DEP_PTR, align 4
  %7546 = load i64, i64* %STACK_DEP_PTR, align 4
  %7547 = getelementptr i256, i256* %STACK, i64 %7546
  store i256 %7530, i256* %7547, align 4
  %7548 = load i64, i64* %STACK_DEP_PTR, align 4
  %7549 = add i64 %7548, 1
  store i64 %7549, i64* %STACK_DEP_PTR, align 4
  %7550 = load i64, i64* %STACK_DEP_PTR, align 4
  %7551 = getelementptr i256, i256* %STACK, i64 %7550
  store i256 %7525, i256* %7551, align 4
  %7552 = load i64, i64* %STACK_DEP_PTR, align 4
  %7553 = add i64 %7552, 1
  store i64 %7553, i64* %STACK_DEP_PTR, align 4
  %7554 = load i64, i64* %STACK_DEP_PTR, align 4
  %7555 = getelementptr i256, i256* %STACK, i64 %7554
  store i256 %7520, i256* %7555, align 4
  br label %JumpTable, !EVMBB !4

.4367:                                            ; preds = %24525, %21641, %16025, %4917, %993, %JumpTable
  %7556 = load i64, i64* %remaing_gas, align 4
  %7557 = icmp ugt i64 224, %7556
  br i1 %7557, label %Abort, label %7558

7558:                                             ; preds = %.4367
  %7559 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %7560 = xor i32 %7559, 1884
  %7561 = urem i32 %7560, 4096
  %7562 = getelementptr i8, i8 addrspace(1)* %4, i32 %7561
  %7563 = load i8, i8 addrspace(1)* %7562, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %7562, align 1, !nosanitize !3
  store i32 942, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %7564 = sub i64 %7556, 224
  store i64 %7564, i64* %remaing_gas, align 4
  %7565 = alloca i256, align 8
  store i256 13, i256* %7565, align 4
  %7566 = alloca i256, align 8
  call void @__device_sload(i256* %7565, i256* %7566)
  %7567 = call i32 @__hashword(i256* %7565)
  %7568 = load i32, i32* %5, align 4
  %7569 = icmp eq i32 %7567, %7568
  %7570 = or i1 false, %7569
  %7571 = load i32, i32* %6, align 4
  %7572 = icmp eq i32 %7567, %7571
  %7573 = or i1 %7570, %7572
  %7574 = load i32, i32* %7, align 4
  %7575 = icmp eq i32 %7567, %7574
  %7576 = or i1 %7573, %7575
  %7577 = load i32, i32* %8, align 4
  %7578 = icmp eq i32 %7567, %7577
  %7579 = or i1 %7576, %7578
  %7580 = load i32, i32* %9, align 4
  %7581 = icmp eq i32 %7567, %7580
  %7582 = or i1 %7579, %7581
  %7583 = load i32, i32* %10, align 4
  %7584 = icmp eq i32 %7567, %7583
  %7585 = or i1 %7582, %7584
  %7586 = load i32, i32* %11, align 4
  %7587 = icmp eq i32 %7567, %7586
  %7588 = or i1 %7585, %7587
  %7589 = load i32, i32* %12, align 4
  %7590 = icmp eq i32 %7567, %7589
  %7591 = or i1 %7588, %7590
  %7592 = load i32, i32* %13, align 4
  %7593 = icmp eq i32 %7567, %7592
  %7594 = or i1 %7591, %7593
  %7595 = load i32, i32* %14, align 4
  %7596 = icmp eq i32 %7567, %7595
  %7597 = or i1 %7594, %7596
  %7598 = load i32, i32* %15, align 4
  %7599 = icmp eq i32 %7567, %7598
  %7600 = or i1 %7597, %7599
  %7601 = load i32, i32* %16, align 4
  %7602 = icmp eq i32 %7567, %7601
  %7603 = or i1 %7600, %7602
  %7604 = load i32, i32* %17, align 4
  %7605 = icmp eq i32 %7567, %7604
  %7606 = or i1 %7603, %7605
  %7607 = load i32, i32* %18, align 4
  %7608 = icmp eq i32 %7567, %7607
  %7609 = or i1 %7606, %7608
  %7610 = load i32, i32* %19, align 4
  %7611 = icmp eq i32 %7567, %7610
  %7612 = or i1 %7609, %7611
  %7613 = load i32, i32* %20, align 4
  %7614 = icmp eq i32 %7567, %7613
  %7615 = or i1 %7612, %7614
  %7616 = load i32, i32* %21, align 4
  %7617 = icmp eq i32 %7567, %7616
  %7618 = or i1 %7615, %7617
  %7619 = load i32, i32* %22, align 4
  %7620 = icmp eq i32 %7567, %7619
  %7621 = or i1 %7618, %7620
  %7622 = load i32, i32* %23, align 4
  %7623 = icmp eq i32 %7567, %7622
  %7624 = or i1 %7621, %7623
  %7625 = load i32, i32* %24, align 4
  %7626 = icmp eq i32 %7567, %7625
  %7627 = or i1 %7624, %7626
  %7628 = load i32, i32* %25, align 4
  %7629 = icmp eq i32 %7567, %7628
  %7630 = or i1 %7627, %7629
  %7631 = load i32, i32* %26, align 4
  %7632 = icmp eq i32 %7567, %7631
  %7633 = or i1 %7630, %7632
  %7634 = load i32, i32* %27, align 4
  %7635 = icmp eq i32 %7567, %7634
  %7636 = or i1 %7633, %7635
  %7637 = load i32, i32* %28, align 4
  %7638 = icmp eq i32 %7567, %7637
  %7639 = or i1 %7636, %7638
  %7640 = load i32, i32* %29, align 4
  %7641 = icmp eq i32 %7567, %7640
  %7642 = or i1 %7639, %7641
  %7643 = load i32, i32* %30, align 4
  %7644 = icmp eq i32 %7567, %7643
  %7645 = or i1 %7642, %7644
  %7646 = load i32, i32* %31, align 4
  %7647 = icmp eq i32 %7567, %7646
  %7648 = or i1 %7645, %7647
  %7649 = load i32, i32* %32, align 4
  %7650 = icmp eq i32 %7567, %7649
  %7651 = or i1 %7648, %7650
  %7652 = load i32, i32* %33, align 4
  %7653 = icmp eq i32 %7567, %7652
  %7654 = or i1 %7651, %7653
  %7655 = load i32, i32* %34, align 4
  %7656 = icmp eq i32 %7567, %7655
  %7657 = or i1 %7654, %7656
  %7658 = load i32, i32* %35, align 4
  %7659 = icmp eq i32 %7567, %7658
  %7660 = or i1 %7657, %7659
  %7661 = load i32, i32* %36, align 4
  %7662 = icmp eq i32 %7567, %7661
  %7663 = or i1 %7660, %7662
  %7664 = load i32, i32* %37, align 4
  %7665 = icmp eq i32 %7567, %7664
  %7666 = or i1 %7663, %7665
  %7667 = load i32, i32* %38, align 4
  %7668 = icmp eq i32 %7567, %7667
  %7669 = or i1 %7666, %7668
  %7670 = load i32, i32* %39, align 4
  %7671 = icmp eq i32 %7567, %7670
  %7672 = or i1 %7669, %7671
  %7673 = load i32, i32* %40, align 4
  %7674 = icmp eq i32 %7567, %7673
  %7675 = or i1 %7672, %7674
  %7676 = load i32, i32* %41, align 4
  %7677 = icmp eq i32 %7567, %7676
  %7678 = or i1 %7675, %7677
  %7679 = load i32, i32* %42, align 4
  %7680 = icmp eq i32 %7567, %7679
  %7681 = or i1 %7678, %7680
  %7682 = load i32, i32* %43, align 4
  %7683 = icmp eq i32 %7567, %7682
  %7684 = or i1 %7681, %7683
  %7685 = load i32, i32* %44, align 4
  %7686 = icmp eq i32 %7567, %7685
  %7687 = or i1 %7684, %7686
  %7688 = load i32, i32* %45, align 4
  %7689 = icmp eq i32 %7567, %7688
  %7690 = or i1 %7687, %7689
  %7691 = load i32, i32* %46, align 4
  %7692 = icmp eq i32 %7567, %7691
  %7693 = or i1 %7690, %7692
  %7694 = load i32, i32* %47, align 4
  %7695 = icmp eq i32 %7567, %7694
  %7696 = or i1 %7693, %7695
  %7697 = load i32, i32* %48, align 4
  %7698 = icmp eq i32 %7567, %7697
  %7699 = or i1 %7696, %7698
  %7700 = load i32, i32* %49, align 4
  %7701 = icmp eq i32 %7567, %7700
  %7702 = or i1 %7699, %7701
  %7703 = load i32, i32* %50, align 4
  %7704 = icmp eq i32 %7567, %7703
  %7705 = or i1 %7702, %7704
  %7706 = load i32, i32* %51, align 4
  %7707 = icmp eq i32 %7567, %7706
  %7708 = or i1 %7705, %7707
  %7709 = load i32, i32* %52, align 4
  %7710 = icmp eq i32 %7567, %7709
  %7711 = or i1 %7708, %7710
  %7712 = load i32, i32* %53, align 4
  %7713 = icmp eq i32 %7567, %7712
  %7714 = or i1 %7711, %7713
  %7715 = load i32, i32* %54, align 4
  %7716 = icmp eq i32 %7567, %7715
  %7717 = or i1 %7714, %7716
  %7718 = load i32, i32* %55, align 4
  %7719 = icmp eq i32 %7567, %7718
  %7720 = or i1 %7717, %7719
  %7721 = load i32, i32* %56, align 4
  %7722 = icmp eq i32 %7567, %7721
  %7723 = or i1 %7720, %7722
  %7724 = load i32, i32* %57, align 4
  %7725 = icmp eq i32 %7567, %7724
  %7726 = or i1 %7723, %7725
  %7727 = load i32, i32* %58, align 4
  %7728 = icmp eq i32 %7567, %7727
  %7729 = or i1 %7726, %7728
  %7730 = load i32, i32* %59, align 4
  %7731 = icmp eq i32 %7567, %7730
  %7732 = or i1 %7729, %7731
  %7733 = load i32, i32* %60, align 4
  %7734 = icmp eq i32 %7567, %7733
  %7735 = or i1 %7732, %7734
  %7736 = load i32, i32* %61, align 4
  %7737 = icmp eq i32 %7567, %7736
  %7738 = or i1 %7735, %7737
  %7739 = load i32, i32* %62, align 4
  %7740 = icmp eq i32 %7567, %7739
  %7741 = or i1 %7738, %7740
  %7742 = getelementptr i8, i8 addrspace(1)* %4, i32 13
  %7743 = zext i1 %7741 to i8
  store i8 %7743, i8 addrspace(1)* %7742, align 1, !nosanitize !3
  %7744 = load i256, i256* %7566, align 4
  %7745 = alloca i256, align 8
  store i256 6, i256* %7745, align 4
  %7746 = alloca i256, align 8
  call void @__device_sload(i256* %7745, i256* %7746)
  %7747 = call i32 @__hashword(i256* %7745)
  %7748 = load i32, i32* %5, align 4
  %7749 = icmp eq i32 %7747, %7748
  %7750 = or i1 false, %7749
  %7751 = load i32, i32* %6, align 4
  %7752 = icmp eq i32 %7747, %7751
  %7753 = or i1 %7750, %7752
  %7754 = load i32, i32* %7, align 4
  %7755 = icmp eq i32 %7747, %7754
  %7756 = or i1 %7753, %7755
  %7757 = load i32, i32* %8, align 4
  %7758 = icmp eq i32 %7747, %7757
  %7759 = or i1 %7756, %7758
  %7760 = load i32, i32* %9, align 4
  %7761 = icmp eq i32 %7747, %7760
  %7762 = or i1 %7759, %7761
  %7763 = load i32, i32* %10, align 4
  %7764 = icmp eq i32 %7747, %7763
  %7765 = or i1 %7762, %7764
  %7766 = load i32, i32* %11, align 4
  %7767 = icmp eq i32 %7747, %7766
  %7768 = or i1 %7765, %7767
  %7769 = load i32, i32* %12, align 4
  %7770 = icmp eq i32 %7747, %7769
  %7771 = or i1 %7768, %7770
  %7772 = load i32, i32* %13, align 4
  %7773 = icmp eq i32 %7747, %7772
  %7774 = or i1 %7771, %7773
  %7775 = load i32, i32* %14, align 4
  %7776 = icmp eq i32 %7747, %7775
  %7777 = or i1 %7774, %7776
  %7778 = load i32, i32* %15, align 4
  %7779 = icmp eq i32 %7747, %7778
  %7780 = or i1 %7777, %7779
  %7781 = load i32, i32* %16, align 4
  %7782 = icmp eq i32 %7747, %7781
  %7783 = or i1 %7780, %7782
  %7784 = load i32, i32* %17, align 4
  %7785 = icmp eq i32 %7747, %7784
  %7786 = or i1 %7783, %7785
  %7787 = load i32, i32* %18, align 4
  %7788 = icmp eq i32 %7747, %7787
  %7789 = or i1 %7786, %7788
  %7790 = load i32, i32* %19, align 4
  %7791 = icmp eq i32 %7747, %7790
  %7792 = or i1 %7789, %7791
  %7793 = load i32, i32* %20, align 4
  %7794 = icmp eq i32 %7747, %7793
  %7795 = or i1 %7792, %7794
  %7796 = load i32, i32* %21, align 4
  %7797 = icmp eq i32 %7747, %7796
  %7798 = or i1 %7795, %7797
  %7799 = load i32, i32* %22, align 4
  %7800 = icmp eq i32 %7747, %7799
  %7801 = or i1 %7798, %7800
  %7802 = load i32, i32* %23, align 4
  %7803 = icmp eq i32 %7747, %7802
  %7804 = or i1 %7801, %7803
  %7805 = load i32, i32* %24, align 4
  %7806 = icmp eq i32 %7747, %7805
  %7807 = or i1 %7804, %7806
  %7808 = load i32, i32* %25, align 4
  %7809 = icmp eq i32 %7747, %7808
  %7810 = or i1 %7807, %7809
  %7811 = load i32, i32* %26, align 4
  %7812 = icmp eq i32 %7747, %7811
  %7813 = or i1 %7810, %7812
  %7814 = load i32, i32* %27, align 4
  %7815 = icmp eq i32 %7747, %7814
  %7816 = or i1 %7813, %7815
  %7817 = load i32, i32* %28, align 4
  %7818 = icmp eq i32 %7747, %7817
  %7819 = or i1 %7816, %7818
  %7820 = load i32, i32* %29, align 4
  %7821 = icmp eq i32 %7747, %7820
  %7822 = or i1 %7819, %7821
  %7823 = load i32, i32* %30, align 4
  %7824 = icmp eq i32 %7747, %7823
  %7825 = or i1 %7822, %7824
  %7826 = load i32, i32* %31, align 4
  %7827 = icmp eq i32 %7747, %7826
  %7828 = or i1 %7825, %7827
  %7829 = load i32, i32* %32, align 4
  %7830 = icmp eq i32 %7747, %7829
  %7831 = or i1 %7828, %7830
  %7832 = load i32, i32* %33, align 4
  %7833 = icmp eq i32 %7747, %7832
  %7834 = or i1 %7831, %7833
  %7835 = load i32, i32* %34, align 4
  %7836 = icmp eq i32 %7747, %7835
  %7837 = or i1 %7834, %7836
  %7838 = load i32, i32* %35, align 4
  %7839 = icmp eq i32 %7747, %7838
  %7840 = or i1 %7837, %7839
  %7841 = load i32, i32* %36, align 4
  %7842 = icmp eq i32 %7747, %7841
  %7843 = or i1 %7840, %7842
  %7844 = load i32, i32* %37, align 4
  %7845 = icmp eq i32 %7747, %7844
  %7846 = or i1 %7843, %7845
  %7847 = load i32, i32* %38, align 4
  %7848 = icmp eq i32 %7747, %7847
  %7849 = or i1 %7846, %7848
  %7850 = load i32, i32* %39, align 4
  %7851 = icmp eq i32 %7747, %7850
  %7852 = or i1 %7849, %7851
  %7853 = load i32, i32* %40, align 4
  %7854 = icmp eq i32 %7747, %7853
  %7855 = or i1 %7852, %7854
  %7856 = load i32, i32* %41, align 4
  %7857 = icmp eq i32 %7747, %7856
  %7858 = or i1 %7855, %7857
  %7859 = load i32, i32* %42, align 4
  %7860 = icmp eq i32 %7747, %7859
  %7861 = or i1 %7858, %7860
  %7862 = load i32, i32* %43, align 4
  %7863 = icmp eq i32 %7747, %7862
  %7864 = or i1 %7861, %7863
  %7865 = load i32, i32* %44, align 4
  %7866 = icmp eq i32 %7747, %7865
  %7867 = or i1 %7864, %7866
  %7868 = load i32, i32* %45, align 4
  %7869 = icmp eq i32 %7747, %7868
  %7870 = or i1 %7867, %7869
  %7871 = load i32, i32* %46, align 4
  %7872 = icmp eq i32 %7747, %7871
  %7873 = or i1 %7870, %7872
  %7874 = load i32, i32* %47, align 4
  %7875 = icmp eq i32 %7747, %7874
  %7876 = or i1 %7873, %7875
  %7877 = load i32, i32* %48, align 4
  %7878 = icmp eq i32 %7747, %7877
  %7879 = or i1 %7876, %7878
  %7880 = load i32, i32* %49, align 4
  %7881 = icmp eq i32 %7747, %7880
  %7882 = or i1 %7879, %7881
  %7883 = load i32, i32* %50, align 4
  %7884 = icmp eq i32 %7747, %7883
  %7885 = or i1 %7882, %7884
  %7886 = load i32, i32* %51, align 4
  %7887 = icmp eq i32 %7747, %7886
  %7888 = or i1 %7885, %7887
  %7889 = load i32, i32* %52, align 4
  %7890 = icmp eq i32 %7747, %7889
  %7891 = or i1 %7888, %7890
  %7892 = load i32, i32* %53, align 4
  %7893 = icmp eq i32 %7747, %7892
  %7894 = or i1 %7891, %7893
  %7895 = load i32, i32* %54, align 4
  %7896 = icmp eq i32 %7747, %7895
  %7897 = or i1 %7894, %7896
  %7898 = load i32, i32* %55, align 4
  %7899 = icmp eq i32 %7747, %7898
  %7900 = or i1 %7897, %7899
  %7901 = load i32, i32* %56, align 4
  %7902 = icmp eq i32 %7747, %7901
  %7903 = or i1 %7900, %7902
  %7904 = load i32, i32* %57, align 4
  %7905 = icmp eq i32 %7747, %7904
  %7906 = or i1 %7903, %7905
  %7907 = load i32, i32* %58, align 4
  %7908 = icmp eq i32 %7747, %7907
  %7909 = or i1 %7906, %7908
  %7910 = load i32, i32* %59, align 4
  %7911 = icmp eq i32 %7747, %7910
  %7912 = or i1 %7909, %7911
  %7913 = load i32, i32* %60, align 4
  %7914 = icmp eq i32 %7747, %7913
  %7915 = or i1 %7912, %7914
  %7916 = load i32, i32* %61, align 4
  %7917 = icmp eq i32 %7747, %7916
  %7918 = or i1 %7915, %7917
  %7919 = load i32, i32* %62, align 4
  %7920 = icmp eq i32 %7747, %7919
  %7921 = or i1 %7918, %7920
  %7922 = getelementptr i8, i8 addrspace(1)* %4, i32 14
  %7923 = zext i1 %7921 to i8
  store i8 %7923, i8 addrspace(1)* %7922, align 1, !nosanitize !3
  %7924 = load i256, i256* %7746, align 4
  %7925 = icmp ult i256 %7924, %7744
  %7926 = trunc i256 4394 to i64
  %jump.check17 = icmp ne i1 %7925, false
  %7927 = load i64, i64* %STACK_DEP_PTR, align 4
  %7928 = add i64 %7927, 1
  store i64 %7928, i64* %STACK_DEP_PTR, align 4
  %7929 = load i64, i64* %STACK_DEP_PTR, align 4
  %7930 = getelementptr i256, i256* %STACK, i64 %7929
  store i256 0, i256* %7930, align 4
  %7931 = load i64, i64* %STACK_DEP_PTR, align 4
  %7932 = add i64 %7931, 1
  store i64 %7932, i64* %STACK_DEP_PTR, align 4
  %7933 = zext i1 %7925 to i256
  %7934 = load i64, i64* %STACK_DEP_PTR, align 4
  %7935 = getelementptr i256, i256* %STACK, i64 %7934
  store i256 %7933, i256* %7935, align 4
  br i1 %jump.check17, label %.4394, label %.4382, !EVMBB !4

.4382:                                            ; preds = %7558
  %7936 = load i64, i64* %STACK_DEP_PTR, align 4
  %7937 = sub i64 %7936, 1
  store i64 %7937, i64* %STACK_DEP_PTR, align 4
  %7938 = alloca i256, align 8
  store i256 6, i256* %7938, align 4
  %7939 = alloca i256, align 8
  call void @__device_sload(i256* %7938, i256* %7939)
  %7940 = call i32 @__hashword(i256* %7938)
  %7941 = load i32, i32* %5, align 4
  %7942 = icmp eq i32 %7940, %7941
  %7943 = or i1 false, %7942
  %7944 = load i32, i32* %6, align 4
  %7945 = icmp eq i32 %7940, %7944
  %7946 = or i1 %7943, %7945
  %7947 = load i32, i32* %7, align 4
  %7948 = icmp eq i32 %7940, %7947
  %7949 = or i1 %7946, %7948
  %7950 = load i32, i32* %8, align 4
  %7951 = icmp eq i32 %7940, %7950
  %7952 = or i1 %7949, %7951
  %7953 = load i32, i32* %9, align 4
  %7954 = icmp eq i32 %7940, %7953
  %7955 = or i1 %7952, %7954
  %7956 = load i32, i32* %10, align 4
  %7957 = icmp eq i32 %7940, %7956
  %7958 = or i1 %7955, %7957
  %7959 = load i32, i32* %11, align 4
  %7960 = icmp eq i32 %7940, %7959
  %7961 = or i1 %7958, %7960
  %7962 = load i32, i32* %12, align 4
  %7963 = icmp eq i32 %7940, %7962
  %7964 = or i1 %7961, %7963
  %7965 = load i32, i32* %13, align 4
  %7966 = icmp eq i32 %7940, %7965
  %7967 = or i1 %7964, %7966
  %7968 = load i32, i32* %14, align 4
  %7969 = icmp eq i32 %7940, %7968
  %7970 = or i1 %7967, %7969
  %7971 = load i32, i32* %15, align 4
  %7972 = icmp eq i32 %7940, %7971
  %7973 = or i1 %7970, %7972
  %7974 = load i32, i32* %16, align 4
  %7975 = icmp eq i32 %7940, %7974
  %7976 = or i1 %7973, %7975
  %7977 = load i32, i32* %17, align 4
  %7978 = icmp eq i32 %7940, %7977
  %7979 = or i1 %7976, %7978
  %7980 = load i32, i32* %18, align 4
  %7981 = icmp eq i32 %7940, %7980
  %7982 = or i1 %7979, %7981
  %7983 = load i32, i32* %19, align 4
  %7984 = icmp eq i32 %7940, %7983
  %7985 = or i1 %7982, %7984
  %7986 = load i32, i32* %20, align 4
  %7987 = icmp eq i32 %7940, %7986
  %7988 = or i1 %7985, %7987
  %7989 = load i32, i32* %21, align 4
  %7990 = icmp eq i32 %7940, %7989
  %7991 = or i1 %7988, %7990
  %7992 = load i32, i32* %22, align 4
  %7993 = icmp eq i32 %7940, %7992
  %7994 = or i1 %7991, %7993
  %7995 = load i32, i32* %23, align 4
  %7996 = icmp eq i32 %7940, %7995
  %7997 = or i1 %7994, %7996
  %7998 = load i32, i32* %24, align 4
  %7999 = icmp eq i32 %7940, %7998
  %8000 = or i1 %7997, %7999
  %8001 = load i32, i32* %25, align 4
  %8002 = icmp eq i32 %7940, %8001
  %8003 = or i1 %8000, %8002
  %8004 = load i32, i32* %26, align 4
  %8005 = icmp eq i32 %7940, %8004
  %8006 = or i1 %8003, %8005
  %8007 = load i32, i32* %27, align 4
  %8008 = icmp eq i32 %7940, %8007
  %8009 = or i1 %8006, %8008
  %8010 = load i32, i32* %28, align 4
  %8011 = icmp eq i32 %7940, %8010
  %8012 = or i1 %8009, %8011
  %8013 = load i32, i32* %29, align 4
  %8014 = icmp eq i32 %7940, %8013
  %8015 = or i1 %8012, %8014
  %8016 = load i32, i32* %30, align 4
  %8017 = icmp eq i32 %7940, %8016
  %8018 = or i1 %8015, %8017
  %8019 = load i32, i32* %31, align 4
  %8020 = icmp eq i32 %7940, %8019
  %8021 = or i1 %8018, %8020
  %8022 = load i32, i32* %32, align 4
  %8023 = icmp eq i32 %7940, %8022
  %8024 = or i1 %8021, %8023
  %8025 = load i32, i32* %33, align 4
  %8026 = icmp eq i32 %7940, %8025
  %8027 = or i1 %8024, %8026
  %8028 = load i32, i32* %34, align 4
  %8029 = icmp eq i32 %7940, %8028
  %8030 = or i1 %8027, %8029
  %8031 = load i32, i32* %35, align 4
  %8032 = icmp eq i32 %7940, %8031
  %8033 = or i1 %8030, %8032
  %8034 = load i32, i32* %36, align 4
  %8035 = icmp eq i32 %7940, %8034
  %8036 = or i1 %8033, %8035
  %8037 = load i32, i32* %37, align 4
  %8038 = icmp eq i32 %7940, %8037
  %8039 = or i1 %8036, %8038
  %8040 = load i32, i32* %38, align 4
  %8041 = icmp eq i32 %7940, %8040
  %8042 = or i1 %8039, %8041
  %8043 = load i32, i32* %39, align 4
  %8044 = icmp eq i32 %7940, %8043
  %8045 = or i1 %8042, %8044
  %8046 = load i32, i32* %40, align 4
  %8047 = icmp eq i32 %7940, %8046
  %8048 = or i1 %8045, %8047
  %8049 = load i32, i32* %41, align 4
  %8050 = icmp eq i32 %7940, %8049
  %8051 = or i1 %8048, %8050
  %8052 = load i32, i32* %42, align 4
  %8053 = icmp eq i32 %7940, %8052
  %8054 = or i1 %8051, %8053
  %8055 = load i32, i32* %43, align 4
  %8056 = icmp eq i32 %7940, %8055
  %8057 = or i1 %8054, %8056
  %8058 = load i32, i32* %44, align 4
  %8059 = icmp eq i32 %7940, %8058
  %8060 = or i1 %8057, %8059
  %8061 = load i32, i32* %45, align 4
  %8062 = icmp eq i32 %7940, %8061
  %8063 = or i1 %8060, %8062
  %8064 = load i32, i32* %46, align 4
  %8065 = icmp eq i32 %7940, %8064
  %8066 = or i1 %8063, %8065
  %8067 = load i32, i32* %47, align 4
  %8068 = icmp eq i32 %7940, %8067
  %8069 = or i1 %8066, %8068
  %8070 = load i32, i32* %48, align 4
  %8071 = icmp eq i32 %7940, %8070
  %8072 = or i1 %8069, %8071
  %8073 = load i32, i32* %49, align 4
  %8074 = icmp eq i32 %7940, %8073
  %8075 = or i1 %8072, %8074
  %8076 = load i32, i32* %50, align 4
  %8077 = icmp eq i32 %7940, %8076
  %8078 = or i1 %8075, %8077
  %8079 = load i32, i32* %51, align 4
  %8080 = icmp eq i32 %7940, %8079
  %8081 = or i1 %8078, %8080
  %8082 = load i32, i32* %52, align 4
  %8083 = icmp eq i32 %7940, %8082
  %8084 = or i1 %8081, %8083
  %8085 = load i32, i32* %53, align 4
  %8086 = icmp eq i32 %7940, %8085
  %8087 = or i1 %8084, %8086
  %8088 = load i32, i32* %54, align 4
  %8089 = icmp eq i32 %7940, %8088
  %8090 = or i1 %8087, %8089
  %8091 = load i32, i32* %55, align 4
  %8092 = icmp eq i32 %7940, %8091
  %8093 = or i1 %8090, %8092
  %8094 = load i32, i32* %56, align 4
  %8095 = icmp eq i32 %7940, %8094
  %8096 = or i1 %8093, %8095
  %8097 = load i32, i32* %57, align 4
  %8098 = icmp eq i32 %7940, %8097
  %8099 = or i1 %8096, %8098
  %8100 = load i32, i32* %58, align 4
  %8101 = icmp eq i32 %7940, %8100
  %8102 = or i1 %8099, %8101
  %8103 = load i32, i32* %59, align 4
  %8104 = icmp eq i32 %7940, %8103
  %8105 = or i1 %8102, %8104
  %8106 = load i32, i32* %60, align 4
  %8107 = icmp eq i32 %7940, %8106
  %8108 = or i1 %8105, %8107
  %8109 = load i32, i32* %61, align 4
  %8110 = icmp eq i32 %7940, %8109
  %8111 = or i1 %8108, %8110
  %8112 = load i32, i32* %62, align 4
  %8113 = icmp eq i32 %7940, %8112
  %8114 = or i1 %8111, %8113
  %8115 = getelementptr i8, i8 addrspace(1)* %4, i32 15
  %8116 = zext i1 %8114 to i8
  store i8 %8116, i8 addrspace(1)* %8115, align 1, !nosanitize !3
  %8117 = load i256, i256* %7939, align 4
  %8118 = alloca i256, align 8
  store i256 13, i256* %8118, align 4
  %8119 = alloca i256, align 8
  call void @__device_sload(i256* %8118, i256* %8119)
  %8120 = call i32 @__hashword(i256* %8118)
  %8121 = load i32, i32* %5, align 4
  %8122 = icmp eq i32 %8120, %8121
  %8123 = or i1 false, %8122
  %8124 = load i32, i32* %6, align 4
  %8125 = icmp eq i32 %8120, %8124
  %8126 = or i1 %8123, %8125
  %8127 = load i32, i32* %7, align 4
  %8128 = icmp eq i32 %8120, %8127
  %8129 = or i1 %8126, %8128
  %8130 = load i32, i32* %8, align 4
  %8131 = icmp eq i32 %8120, %8130
  %8132 = or i1 %8129, %8131
  %8133 = load i32, i32* %9, align 4
  %8134 = icmp eq i32 %8120, %8133
  %8135 = or i1 %8132, %8134
  %8136 = load i32, i32* %10, align 4
  %8137 = icmp eq i32 %8120, %8136
  %8138 = or i1 %8135, %8137
  %8139 = load i32, i32* %11, align 4
  %8140 = icmp eq i32 %8120, %8139
  %8141 = or i1 %8138, %8140
  %8142 = load i32, i32* %12, align 4
  %8143 = icmp eq i32 %8120, %8142
  %8144 = or i1 %8141, %8143
  %8145 = load i32, i32* %13, align 4
  %8146 = icmp eq i32 %8120, %8145
  %8147 = or i1 %8144, %8146
  %8148 = load i32, i32* %14, align 4
  %8149 = icmp eq i32 %8120, %8148
  %8150 = or i1 %8147, %8149
  %8151 = load i32, i32* %15, align 4
  %8152 = icmp eq i32 %8120, %8151
  %8153 = or i1 %8150, %8152
  %8154 = load i32, i32* %16, align 4
  %8155 = icmp eq i32 %8120, %8154
  %8156 = or i1 %8153, %8155
  %8157 = load i32, i32* %17, align 4
  %8158 = icmp eq i32 %8120, %8157
  %8159 = or i1 %8156, %8158
  %8160 = load i32, i32* %18, align 4
  %8161 = icmp eq i32 %8120, %8160
  %8162 = or i1 %8159, %8161
  %8163 = load i32, i32* %19, align 4
  %8164 = icmp eq i32 %8120, %8163
  %8165 = or i1 %8162, %8164
  %8166 = load i32, i32* %20, align 4
  %8167 = icmp eq i32 %8120, %8166
  %8168 = or i1 %8165, %8167
  %8169 = load i32, i32* %21, align 4
  %8170 = icmp eq i32 %8120, %8169
  %8171 = or i1 %8168, %8170
  %8172 = load i32, i32* %22, align 4
  %8173 = icmp eq i32 %8120, %8172
  %8174 = or i1 %8171, %8173
  %8175 = load i32, i32* %23, align 4
  %8176 = icmp eq i32 %8120, %8175
  %8177 = or i1 %8174, %8176
  %8178 = load i32, i32* %24, align 4
  %8179 = icmp eq i32 %8120, %8178
  %8180 = or i1 %8177, %8179
  %8181 = load i32, i32* %25, align 4
  %8182 = icmp eq i32 %8120, %8181
  %8183 = or i1 %8180, %8182
  %8184 = load i32, i32* %26, align 4
  %8185 = icmp eq i32 %8120, %8184
  %8186 = or i1 %8183, %8185
  %8187 = load i32, i32* %27, align 4
  %8188 = icmp eq i32 %8120, %8187
  %8189 = or i1 %8186, %8188
  %8190 = load i32, i32* %28, align 4
  %8191 = icmp eq i32 %8120, %8190
  %8192 = or i1 %8189, %8191
  %8193 = load i32, i32* %29, align 4
  %8194 = icmp eq i32 %8120, %8193
  %8195 = or i1 %8192, %8194
  %8196 = load i32, i32* %30, align 4
  %8197 = icmp eq i32 %8120, %8196
  %8198 = or i1 %8195, %8197
  %8199 = load i32, i32* %31, align 4
  %8200 = icmp eq i32 %8120, %8199
  %8201 = or i1 %8198, %8200
  %8202 = load i32, i32* %32, align 4
  %8203 = icmp eq i32 %8120, %8202
  %8204 = or i1 %8201, %8203
  %8205 = load i32, i32* %33, align 4
  %8206 = icmp eq i32 %8120, %8205
  %8207 = or i1 %8204, %8206
  %8208 = load i32, i32* %34, align 4
  %8209 = icmp eq i32 %8120, %8208
  %8210 = or i1 %8207, %8209
  %8211 = load i32, i32* %35, align 4
  %8212 = icmp eq i32 %8120, %8211
  %8213 = or i1 %8210, %8212
  %8214 = load i32, i32* %36, align 4
  %8215 = icmp eq i32 %8120, %8214
  %8216 = or i1 %8213, %8215
  %8217 = load i32, i32* %37, align 4
  %8218 = icmp eq i32 %8120, %8217
  %8219 = or i1 %8216, %8218
  %8220 = load i32, i32* %38, align 4
  %8221 = icmp eq i32 %8120, %8220
  %8222 = or i1 %8219, %8221
  %8223 = load i32, i32* %39, align 4
  %8224 = icmp eq i32 %8120, %8223
  %8225 = or i1 %8222, %8224
  %8226 = load i32, i32* %40, align 4
  %8227 = icmp eq i32 %8120, %8226
  %8228 = or i1 %8225, %8227
  %8229 = load i32, i32* %41, align 4
  %8230 = icmp eq i32 %8120, %8229
  %8231 = or i1 %8228, %8230
  %8232 = load i32, i32* %42, align 4
  %8233 = icmp eq i32 %8120, %8232
  %8234 = or i1 %8231, %8233
  %8235 = load i32, i32* %43, align 4
  %8236 = icmp eq i32 %8120, %8235
  %8237 = or i1 %8234, %8236
  %8238 = load i32, i32* %44, align 4
  %8239 = icmp eq i32 %8120, %8238
  %8240 = or i1 %8237, %8239
  %8241 = load i32, i32* %45, align 4
  %8242 = icmp eq i32 %8120, %8241
  %8243 = or i1 %8240, %8242
  %8244 = load i32, i32* %46, align 4
  %8245 = icmp eq i32 %8120, %8244
  %8246 = or i1 %8243, %8245
  %8247 = load i32, i32* %47, align 4
  %8248 = icmp eq i32 %8120, %8247
  %8249 = or i1 %8246, %8248
  %8250 = load i32, i32* %48, align 4
  %8251 = icmp eq i32 %8120, %8250
  %8252 = or i1 %8249, %8251
  %8253 = load i32, i32* %49, align 4
  %8254 = icmp eq i32 %8120, %8253
  %8255 = or i1 %8252, %8254
  %8256 = load i32, i32* %50, align 4
  %8257 = icmp eq i32 %8120, %8256
  %8258 = or i1 %8255, %8257
  %8259 = load i32, i32* %51, align 4
  %8260 = icmp eq i32 %8120, %8259
  %8261 = or i1 %8258, %8260
  %8262 = load i32, i32* %52, align 4
  %8263 = icmp eq i32 %8120, %8262
  %8264 = or i1 %8261, %8263
  %8265 = load i32, i32* %53, align 4
  %8266 = icmp eq i32 %8120, %8265
  %8267 = or i1 %8264, %8266
  %8268 = load i32, i32* %54, align 4
  %8269 = icmp eq i32 %8120, %8268
  %8270 = or i1 %8267, %8269
  %8271 = load i32, i32* %55, align 4
  %8272 = icmp eq i32 %8120, %8271
  %8273 = or i1 %8270, %8272
  %8274 = load i32, i32* %56, align 4
  %8275 = icmp eq i32 %8120, %8274
  %8276 = or i1 %8273, %8275
  %8277 = load i32, i32* %57, align 4
  %8278 = icmp eq i32 %8120, %8277
  %8279 = or i1 %8276, %8278
  %8280 = load i32, i32* %58, align 4
  %8281 = icmp eq i32 %8120, %8280
  %8282 = or i1 %8279, %8281
  %8283 = load i32, i32* %59, align 4
  %8284 = icmp eq i32 %8120, %8283
  %8285 = or i1 %8282, %8284
  %8286 = load i32, i32* %60, align 4
  %8287 = icmp eq i32 %8120, %8286
  %8288 = or i1 %8285, %8287
  %8289 = load i32, i32* %61, align 4
  %8290 = icmp eq i32 %8120, %8289
  %8291 = or i1 %8288, %8290
  %8292 = load i32, i32* %62, align 4
  %8293 = icmp eq i32 %8120, %8292
  %8294 = or i1 %8291, %8293
  %8295 = getelementptr i8, i8 addrspace(1)* %4, i32 16
  %8296 = zext i1 %8294 to i8
  store i8 %8296, i8 addrspace(1)* %8295, align 1, !nosanitize !3
  %8297 = load i256, i256* %8119, align 4
  %8298 = alloca i256, align 8
  store i256 6, i256* %8298, align 4
  %8299 = alloca i256, align 8
  call void @__device_sload(i256* %8298, i256* %8299)
  %8300 = call i32 @__hashword(i256* %8298)
  %8301 = load i32, i32* %5, align 4
  %8302 = icmp eq i32 %8300, %8301
  %8303 = or i1 false, %8302
  %8304 = load i32, i32* %6, align 4
  %8305 = icmp eq i32 %8300, %8304
  %8306 = or i1 %8303, %8305
  %8307 = load i32, i32* %7, align 4
  %8308 = icmp eq i32 %8300, %8307
  %8309 = or i1 %8306, %8308
  %8310 = load i32, i32* %8, align 4
  %8311 = icmp eq i32 %8300, %8310
  %8312 = or i1 %8309, %8311
  %8313 = load i32, i32* %9, align 4
  %8314 = icmp eq i32 %8300, %8313
  %8315 = or i1 %8312, %8314
  %8316 = load i32, i32* %10, align 4
  %8317 = icmp eq i32 %8300, %8316
  %8318 = or i1 %8315, %8317
  %8319 = load i32, i32* %11, align 4
  %8320 = icmp eq i32 %8300, %8319
  %8321 = or i1 %8318, %8320
  %8322 = load i32, i32* %12, align 4
  %8323 = icmp eq i32 %8300, %8322
  %8324 = or i1 %8321, %8323
  %8325 = load i32, i32* %13, align 4
  %8326 = icmp eq i32 %8300, %8325
  %8327 = or i1 %8324, %8326
  %8328 = load i32, i32* %14, align 4
  %8329 = icmp eq i32 %8300, %8328
  %8330 = or i1 %8327, %8329
  %8331 = load i32, i32* %15, align 4
  %8332 = icmp eq i32 %8300, %8331
  %8333 = or i1 %8330, %8332
  %8334 = load i32, i32* %16, align 4
  %8335 = icmp eq i32 %8300, %8334
  %8336 = or i1 %8333, %8335
  %8337 = load i32, i32* %17, align 4
  %8338 = icmp eq i32 %8300, %8337
  %8339 = or i1 %8336, %8338
  %8340 = load i32, i32* %18, align 4
  %8341 = icmp eq i32 %8300, %8340
  %8342 = or i1 %8339, %8341
  %8343 = load i32, i32* %19, align 4
  %8344 = icmp eq i32 %8300, %8343
  %8345 = or i1 %8342, %8344
  %8346 = load i32, i32* %20, align 4
  %8347 = icmp eq i32 %8300, %8346
  %8348 = or i1 %8345, %8347
  %8349 = load i32, i32* %21, align 4
  %8350 = icmp eq i32 %8300, %8349
  %8351 = or i1 %8348, %8350
  %8352 = load i32, i32* %22, align 4
  %8353 = icmp eq i32 %8300, %8352
  %8354 = or i1 %8351, %8353
  %8355 = load i32, i32* %23, align 4
  %8356 = icmp eq i32 %8300, %8355
  %8357 = or i1 %8354, %8356
  %8358 = load i32, i32* %24, align 4
  %8359 = icmp eq i32 %8300, %8358
  %8360 = or i1 %8357, %8359
  %8361 = load i32, i32* %25, align 4
  %8362 = icmp eq i32 %8300, %8361
  %8363 = or i1 %8360, %8362
  %8364 = load i32, i32* %26, align 4
  %8365 = icmp eq i32 %8300, %8364
  %8366 = or i1 %8363, %8365
  %8367 = load i32, i32* %27, align 4
  %8368 = icmp eq i32 %8300, %8367
  %8369 = or i1 %8366, %8368
  %8370 = load i32, i32* %28, align 4
  %8371 = icmp eq i32 %8300, %8370
  %8372 = or i1 %8369, %8371
  %8373 = load i32, i32* %29, align 4
  %8374 = icmp eq i32 %8300, %8373
  %8375 = or i1 %8372, %8374
  %8376 = load i32, i32* %30, align 4
  %8377 = icmp eq i32 %8300, %8376
  %8378 = or i1 %8375, %8377
  %8379 = load i32, i32* %31, align 4
  %8380 = icmp eq i32 %8300, %8379
  %8381 = or i1 %8378, %8380
  %8382 = load i32, i32* %32, align 4
  %8383 = icmp eq i32 %8300, %8382
  %8384 = or i1 %8381, %8383
  %8385 = load i32, i32* %33, align 4
  %8386 = icmp eq i32 %8300, %8385
  %8387 = or i1 %8384, %8386
  %8388 = load i32, i32* %34, align 4
  %8389 = icmp eq i32 %8300, %8388
  %8390 = or i1 %8387, %8389
  %8391 = load i32, i32* %35, align 4
  %8392 = icmp eq i32 %8300, %8391
  %8393 = or i1 %8390, %8392
  %8394 = load i32, i32* %36, align 4
  %8395 = icmp eq i32 %8300, %8394
  %8396 = or i1 %8393, %8395
  %8397 = load i32, i32* %37, align 4
  %8398 = icmp eq i32 %8300, %8397
  %8399 = or i1 %8396, %8398
  %8400 = load i32, i32* %38, align 4
  %8401 = icmp eq i32 %8300, %8400
  %8402 = or i1 %8399, %8401
  %8403 = load i32, i32* %39, align 4
  %8404 = icmp eq i32 %8300, %8403
  %8405 = or i1 %8402, %8404
  %8406 = load i32, i32* %40, align 4
  %8407 = icmp eq i32 %8300, %8406
  %8408 = or i1 %8405, %8407
  %8409 = load i32, i32* %41, align 4
  %8410 = icmp eq i32 %8300, %8409
  %8411 = or i1 %8408, %8410
  %8412 = load i32, i32* %42, align 4
  %8413 = icmp eq i32 %8300, %8412
  %8414 = or i1 %8411, %8413
  %8415 = load i32, i32* %43, align 4
  %8416 = icmp eq i32 %8300, %8415
  %8417 = or i1 %8414, %8416
  %8418 = load i32, i32* %44, align 4
  %8419 = icmp eq i32 %8300, %8418
  %8420 = or i1 %8417, %8419
  %8421 = load i32, i32* %45, align 4
  %8422 = icmp eq i32 %8300, %8421
  %8423 = or i1 %8420, %8422
  %8424 = load i32, i32* %46, align 4
  %8425 = icmp eq i32 %8300, %8424
  %8426 = or i1 %8423, %8425
  %8427 = load i32, i32* %47, align 4
  %8428 = icmp eq i32 %8300, %8427
  %8429 = or i1 %8426, %8428
  %8430 = load i32, i32* %48, align 4
  %8431 = icmp eq i32 %8300, %8430
  %8432 = or i1 %8429, %8431
  %8433 = load i32, i32* %49, align 4
  %8434 = icmp eq i32 %8300, %8433
  %8435 = or i1 %8432, %8434
  %8436 = load i32, i32* %50, align 4
  %8437 = icmp eq i32 %8300, %8436
  %8438 = or i1 %8435, %8437
  %8439 = load i32, i32* %51, align 4
  %8440 = icmp eq i32 %8300, %8439
  %8441 = or i1 %8438, %8440
  %8442 = load i32, i32* %52, align 4
  %8443 = icmp eq i32 %8300, %8442
  %8444 = or i1 %8441, %8443
  %8445 = load i32, i32* %53, align 4
  %8446 = icmp eq i32 %8300, %8445
  %8447 = or i1 %8444, %8446
  %8448 = load i32, i32* %54, align 4
  %8449 = icmp eq i32 %8300, %8448
  %8450 = or i1 %8447, %8449
  %8451 = load i32, i32* %55, align 4
  %8452 = icmp eq i32 %8300, %8451
  %8453 = or i1 %8450, %8452
  %8454 = load i32, i32* %56, align 4
  %8455 = icmp eq i32 %8300, %8454
  %8456 = or i1 %8453, %8455
  %8457 = load i32, i32* %57, align 4
  %8458 = icmp eq i32 %8300, %8457
  %8459 = or i1 %8456, %8458
  %8460 = load i32, i32* %58, align 4
  %8461 = icmp eq i32 %8300, %8460
  %8462 = or i1 %8459, %8461
  %8463 = load i32, i32* %59, align 4
  %8464 = icmp eq i32 %8300, %8463
  %8465 = or i1 %8462, %8464
  %8466 = load i32, i32* %60, align 4
  %8467 = icmp eq i32 %8300, %8466
  %8468 = or i1 %8465, %8467
  %8469 = load i32, i32* %61, align 4
  %8470 = icmp eq i32 %8300, %8469
  %8471 = or i1 %8468, %8470
  %8472 = load i32, i32* %62, align 4
  %8473 = icmp eq i32 %8300, %8472
  %8474 = or i1 %8471, %8473
  %8475 = getelementptr i8, i8 addrspace(1)* %4, i32 17
  %8476 = zext i1 %8474 to i8
  store i8 %8476, i8 addrspace(1)* %8475, align 1, !nosanitize !3
  %8477 = load i256, i256* %8299, align 4
  %8478 = add i256 %8477, %8297, !pc !218, !intsan !10
  %8479 = icmp ult i256 %8478, %8117
  %8480 = load i64, i64* %STACK_DEP_PTR, align 4
  %8481 = add i64 %8480, 1
  store i64 %8481, i64* %STACK_DEP_PTR, align 4
  %8482 = zext i1 %8479 to i256
  %8483 = load i64, i64* %STACK_DEP_PTR, align 4
  %8484 = getelementptr i256, i256* %STACK, i64 %8483
  store i256 %8482, i256* %8484, align 4
  br label %.4394

.4394:                                            ; preds = %.4382, %7558, %JumpTable
  %8485 = load i64, i64* %remaing_gas, align 4
  %8486 = icmp ugt i64 128, %8485
  br i1 %8486, label %Abort, label %8487

8487:                                             ; preds = %.4394
  %8488 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %8489 = xor i32 %8488, 2515
  %8490 = urem i32 %8489, 4096
  %8491 = getelementptr i8, i8 addrspace(1)* %4, i32 %8490
  %8492 = load i8, i8 addrspace(1)* %8491, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %8491, align 1, !nosanitize !3
  store i32 1257, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %8493 = sub i64 %8485, 128
  store i64 %8493, i64* %remaing_gas, align 4
  %8494 = load i64, i64* %STACK_DEP_PTR, align 4
  %8495 = getelementptr i256, i256* %STACK, i64 %8494
  %8496 = load i256, i256* %8495, align 4
  %8497 = load i64, i64* %STACK_DEP_PTR, align 4
  %8498 = sub i64 %8497, 1
  store i64 %8498, i64* %STACK_DEP_PTR, align 4
  %8499 = trunc i256 4412 to i64
  %jump.check22 = icmp ne i256 %8496, 0
  %8500 = load i64, i64* %STACK_DEP_PTR, align 4
  %8501 = add i64 %8500, 1
  store i64 %8501, i64* %STACK_DEP_PTR, align 4
  %8502 = load i64, i64* %STACK_DEP_PTR, align 4
  %8503 = getelementptr i256, i256* %STACK, i64 %8502
  store i256 %8496, i256* %8503, align 4
  br i1 %jump.check22, label %.4412, label %.4400, !EVMBB !4

.4400:                                            ; preds = %8487
  %8504 = load i64, i64* %STACK_DEP_PTR, align 4
  %8505 = sub i64 %8504, 1
  store i64 %8505, i64* %STACK_DEP_PTR, align 4
  %8506 = alloca i256, align 8
  store i256 14, i256* %8506, align 4
  %8507 = alloca i256, align 8
  call void @__device_sload(i256* %8506, i256* %8507)
  %8508 = call i32 @__hashword(i256* %8506)
  %8509 = load i32, i32* %5, align 4
  %8510 = icmp eq i32 %8508, %8509
  %8511 = or i1 false, %8510
  %8512 = load i32, i32* %6, align 4
  %8513 = icmp eq i32 %8508, %8512
  %8514 = or i1 %8511, %8513
  %8515 = load i32, i32* %7, align 4
  %8516 = icmp eq i32 %8508, %8515
  %8517 = or i1 %8514, %8516
  %8518 = load i32, i32* %8, align 4
  %8519 = icmp eq i32 %8508, %8518
  %8520 = or i1 %8517, %8519
  %8521 = load i32, i32* %9, align 4
  %8522 = icmp eq i32 %8508, %8521
  %8523 = or i1 %8520, %8522
  %8524 = load i32, i32* %10, align 4
  %8525 = icmp eq i32 %8508, %8524
  %8526 = or i1 %8523, %8525
  %8527 = load i32, i32* %11, align 4
  %8528 = icmp eq i32 %8508, %8527
  %8529 = or i1 %8526, %8528
  %8530 = load i32, i32* %12, align 4
  %8531 = icmp eq i32 %8508, %8530
  %8532 = or i1 %8529, %8531
  %8533 = load i32, i32* %13, align 4
  %8534 = icmp eq i32 %8508, %8533
  %8535 = or i1 %8532, %8534
  %8536 = load i32, i32* %14, align 4
  %8537 = icmp eq i32 %8508, %8536
  %8538 = or i1 %8535, %8537
  %8539 = load i32, i32* %15, align 4
  %8540 = icmp eq i32 %8508, %8539
  %8541 = or i1 %8538, %8540
  %8542 = load i32, i32* %16, align 4
  %8543 = icmp eq i32 %8508, %8542
  %8544 = or i1 %8541, %8543
  %8545 = load i32, i32* %17, align 4
  %8546 = icmp eq i32 %8508, %8545
  %8547 = or i1 %8544, %8546
  %8548 = load i32, i32* %18, align 4
  %8549 = icmp eq i32 %8508, %8548
  %8550 = or i1 %8547, %8549
  %8551 = load i32, i32* %19, align 4
  %8552 = icmp eq i32 %8508, %8551
  %8553 = or i1 %8550, %8552
  %8554 = load i32, i32* %20, align 4
  %8555 = icmp eq i32 %8508, %8554
  %8556 = or i1 %8553, %8555
  %8557 = load i32, i32* %21, align 4
  %8558 = icmp eq i32 %8508, %8557
  %8559 = or i1 %8556, %8558
  %8560 = load i32, i32* %22, align 4
  %8561 = icmp eq i32 %8508, %8560
  %8562 = or i1 %8559, %8561
  %8563 = load i32, i32* %23, align 4
  %8564 = icmp eq i32 %8508, %8563
  %8565 = or i1 %8562, %8564
  %8566 = load i32, i32* %24, align 4
  %8567 = icmp eq i32 %8508, %8566
  %8568 = or i1 %8565, %8567
  %8569 = load i32, i32* %25, align 4
  %8570 = icmp eq i32 %8508, %8569
  %8571 = or i1 %8568, %8570
  %8572 = load i32, i32* %26, align 4
  %8573 = icmp eq i32 %8508, %8572
  %8574 = or i1 %8571, %8573
  %8575 = load i32, i32* %27, align 4
  %8576 = icmp eq i32 %8508, %8575
  %8577 = or i1 %8574, %8576
  %8578 = load i32, i32* %28, align 4
  %8579 = icmp eq i32 %8508, %8578
  %8580 = or i1 %8577, %8579
  %8581 = load i32, i32* %29, align 4
  %8582 = icmp eq i32 %8508, %8581
  %8583 = or i1 %8580, %8582
  %8584 = load i32, i32* %30, align 4
  %8585 = icmp eq i32 %8508, %8584
  %8586 = or i1 %8583, %8585
  %8587 = load i32, i32* %31, align 4
  %8588 = icmp eq i32 %8508, %8587
  %8589 = or i1 %8586, %8588
  %8590 = load i32, i32* %32, align 4
  %8591 = icmp eq i32 %8508, %8590
  %8592 = or i1 %8589, %8591
  %8593 = load i32, i32* %33, align 4
  %8594 = icmp eq i32 %8508, %8593
  %8595 = or i1 %8592, %8594
  %8596 = load i32, i32* %34, align 4
  %8597 = icmp eq i32 %8508, %8596
  %8598 = or i1 %8595, %8597
  %8599 = load i32, i32* %35, align 4
  %8600 = icmp eq i32 %8508, %8599
  %8601 = or i1 %8598, %8600
  %8602 = load i32, i32* %36, align 4
  %8603 = icmp eq i32 %8508, %8602
  %8604 = or i1 %8601, %8603
  %8605 = load i32, i32* %37, align 4
  %8606 = icmp eq i32 %8508, %8605
  %8607 = or i1 %8604, %8606
  %8608 = load i32, i32* %38, align 4
  %8609 = icmp eq i32 %8508, %8608
  %8610 = or i1 %8607, %8609
  %8611 = load i32, i32* %39, align 4
  %8612 = icmp eq i32 %8508, %8611
  %8613 = or i1 %8610, %8612
  %8614 = load i32, i32* %40, align 4
  %8615 = icmp eq i32 %8508, %8614
  %8616 = or i1 %8613, %8615
  %8617 = load i32, i32* %41, align 4
  %8618 = icmp eq i32 %8508, %8617
  %8619 = or i1 %8616, %8618
  %8620 = load i32, i32* %42, align 4
  %8621 = icmp eq i32 %8508, %8620
  %8622 = or i1 %8619, %8621
  %8623 = load i32, i32* %43, align 4
  %8624 = icmp eq i32 %8508, %8623
  %8625 = or i1 %8622, %8624
  %8626 = load i32, i32* %44, align 4
  %8627 = icmp eq i32 %8508, %8626
  %8628 = or i1 %8625, %8627
  %8629 = load i32, i32* %45, align 4
  %8630 = icmp eq i32 %8508, %8629
  %8631 = or i1 %8628, %8630
  %8632 = load i32, i32* %46, align 4
  %8633 = icmp eq i32 %8508, %8632
  %8634 = or i1 %8631, %8633
  %8635 = load i32, i32* %47, align 4
  %8636 = icmp eq i32 %8508, %8635
  %8637 = or i1 %8634, %8636
  %8638 = load i32, i32* %48, align 4
  %8639 = icmp eq i32 %8508, %8638
  %8640 = or i1 %8637, %8639
  %8641 = load i32, i32* %49, align 4
  %8642 = icmp eq i32 %8508, %8641
  %8643 = or i1 %8640, %8642
  %8644 = load i32, i32* %50, align 4
  %8645 = icmp eq i32 %8508, %8644
  %8646 = or i1 %8643, %8645
  %8647 = load i32, i32* %51, align 4
  %8648 = icmp eq i32 %8508, %8647
  %8649 = or i1 %8646, %8648
  %8650 = load i32, i32* %52, align 4
  %8651 = icmp eq i32 %8508, %8650
  %8652 = or i1 %8649, %8651
  %8653 = load i32, i32* %53, align 4
  %8654 = icmp eq i32 %8508, %8653
  %8655 = or i1 %8652, %8654
  %8656 = load i32, i32* %54, align 4
  %8657 = icmp eq i32 %8508, %8656
  %8658 = or i1 %8655, %8657
  %8659 = load i32, i32* %55, align 4
  %8660 = icmp eq i32 %8508, %8659
  %8661 = or i1 %8658, %8660
  %8662 = load i32, i32* %56, align 4
  %8663 = icmp eq i32 %8508, %8662
  %8664 = or i1 %8661, %8663
  %8665 = load i32, i32* %57, align 4
  %8666 = icmp eq i32 %8508, %8665
  %8667 = or i1 %8664, %8666
  %8668 = load i32, i32* %58, align 4
  %8669 = icmp eq i32 %8508, %8668
  %8670 = or i1 %8667, %8669
  %8671 = load i32, i32* %59, align 4
  %8672 = icmp eq i32 %8508, %8671
  %8673 = or i1 %8670, %8672
  %8674 = load i32, i32* %60, align 4
  %8675 = icmp eq i32 %8508, %8674
  %8676 = or i1 %8673, %8675
  %8677 = load i32, i32* %61, align 4
  %8678 = icmp eq i32 %8508, %8677
  %8679 = or i1 %8676, %8678
  %8680 = load i32, i32* %62, align 4
  %8681 = icmp eq i32 %8508, %8680
  %8682 = or i1 %8679, %8681
  %8683 = getelementptr i8, i8 addrspace(1)* %4, i32 18
  %8684 = zext i1 %8682 to i8
  store i8 %8684, i8 addrspace(1)* %8683, align 1, !nosanitize !3
  %8685 = load i256, i256* %8507, align 4
  %8686 = alloca i256, align 8
  store i256 13, i256* %8686, align 4
  %8687 = alloca i256, align 8
  call void @__device_sload(i256* %8686, i256* %8687)
  %8688 = call i32 @__hashword(i256* %8686)
  %8689 = load i32, i32* %5, align 4
  %8690 = icmp eq i32 %8688, %8689
  %8691 = or i1 false, %8690
  %8692 = load i32, i32* %6, align 4
  %8693 = icmp eq i32 %8688, %8692
  %8694 = or i1 %8691, %8693
  %8695 = load i32, i32* %7, align 4
  %8696 = icmp eq i32 %8688, %8695
  %8697 = or i1 %8694, %8696
  %8698 = load i32, i32* %8, align 4
  %8699 = icmp eq i32 %8688, %8698
  %8700 = or i1 %8697, %8699
  %8701 = load i32, i32* %9, align 4
  %8702 = icmp eq i32 %8688, %8701
  %8703 = or i1 %8700, %8702
  %8704 = load i32, i32* %10, align 4
  %8705 = icmp eq i32 %8688, %8704
  %8706 = or i1 %8703, %8705
  %8707 = load i32, i32* %11, align 4
  %8708 = icmp eq i32 %8688, %8707
  %8709 = or i1 %8706, %8708
  %8710 = load i32, i32* %12, align 4
  %8711 = icmp eq i32 %8688, %8710
  %8712 = or i1 %8709, %8711
  %8713 = load i32, i32* %13, align 4
  %8714 = icmp eq i32 %8688, %8713
  %8715 = or i1 %8712, %8714
  %8716 = load i32, i32* %14, align 4
  %8717 = icmp eq i32 %8688, %8716
  %8718 = or i1 %8715, %8717
  %8719 = load i32, i32* %15, align 4
  %8720 = icmp eq i32 %8688, %8719
  %8721 = or i1 %8718, %8720
  %8722 = load i32, i32* %16, align 4
  %8723 = icmp eq i32 %8688, %8722
  %8724 = or i1 %8721, %8723
  %8725 = load i32, i32* %17, align 4
  %8726 = icmp eq i32 %8688, %8725
  %8727 = or i1 %8724, %8726
  %8728 = load i32, i32* %18, align 4
  %8729 = icmp eq i32 %8688, %8728
  %8730 = or i1 %8727, %8729
  %8731 = load i32, i32* %19, align 4
  %8732 = icmp eq i32 %8688, %8731
  %8733 = or i1 %8730, %8732
  %8734 = load i32, i32* %20, align 4
  %8735 = icmp eq i32 %8688, %8734
  %8736 = or i1 %8733, %8735
  %8737 = load i32, i32* %21, align 4
  %8738 = icmp eq i32 %8688, %8737
  %8739 = or i1 %8736, %8738
  %8740 = load i32, i32* %22, align 4
  %8741 = icmp eq i32 %8688, %8740
  %8742 = or i1 %8739, %8741
  %8743 = load i32, i32* %23, align 4
  %8744 = icmp eq i32 %8688, %8743
  %8745 = or i1 %8742, %8744
  %8746 = load i32, i32* %24, align 4
  %8747 = icmp eq i32 %8688, %8746
  %8748 = or i1 %8745, %8747
  %8749 = load i32, i32* %25, align 4
  %8750 = icmp eq i32 %8688, %8749
  %8751 = or i1 %8748, %8750
  %8752 = load i32, i32* %26, align 4
  %8753 = icmp eq i32 %8688, %8752
  %8754 = or i1 %8751, %8753
  %8755 = load i32, i32* %27, align 4
  %8756 = icmp eq i32 %8688, %8755
  %8757 = or i1 %8754, %8756
  %8758 = load i32, i32* %28, align 4
  %8759 = icmp eq i32 %8688, %8758
  %8760 = or i1 %8757, %8759
  %8761 = load i32, i32* %29, align 4
  %8762 = icmp eq i32 %8688, %8761
  %8763 = or i1 %8760, %8762
  %8764 = load i32, i32* %30, align 4
  %8765 = icmp eq i32 %8688, %8764
  %8766 = or i1 %8763, %8765
  %8767 = load i32, i32* %31, align 4
  %8768 = icmp eq i32 %8688, %8767
  %8769 = or i1 %8766, %8768
  %8770 = load i32, i32* %32, align 4
  %8771 = icmp eq i32 %8688, %8770
  %8772 = or i1 %8769, %8771
  %8773 = load i32, i32* %33, align 4
  %8774 = icmp eq i32 %8688, %8773
  %8775 = or i1 %8772, %8774
  %8776 = load i32, i32* %34, align 4
  %8777 = icmp eq i32 %8688, %8776
  %8778 = or i1 %8775, %8777
  %8779 = load i32, i32* %35, align 4
  %8780 = icmp eq i32 %8688, %8779
  %8781 = or i1 %8778, %8780
  %8782 = load i32, i32* %36, align 4
  %8783 = icmp eq i32 %8688, %8782
  %8784 = or i1 %8781, %8783
  %8785 = load i32, i32* %37, align 4
  %8786 = icmp eq i32 %8688, %8785
  %8787 = or i1 %8784, %8786
  %8788 = load i32, i32* %38, align 4
  %8789 = icmp eq i32 %8688, %8788
  %8790 = or i1 %8787, %8789
  %8791 = load i32, i32* %39, align 4
  %8792 = icmp eq i32 %8688, %8791
  %8793 = or i1 %8790, %8792
  %8794 = load i32, i32* %40, align 4
  %8795 = icmp eq i32 %8688, %8794
  %8796 = or i1 %8793, %8795
  %8797 = load i32, i32* %41, align 4
  %8798 = icmp eq i32 %8688, %8797
  %8799 = or i1 %8796, %8798
  %8800 = load i32, i32* %42, align 4
  %8801 = icmp eq i32 %8688, %8800
  %8802 = or i1 %8799, %8801
  %8803 = load i32, i32* %43, align 4
  %8804 = icmp eq i32 %8688, %8803
  %8805 = or i1 %8802, %8804
  %8806 = load i32, i32* %44, align 4
  %8807 = icmp eq i32 %8688, %8806
  %8808 = or i1 %8805, %8807
  %8809 = load i32, i32* %45, align 4
  %8810 = icmp eq i32 %8688, %8809
  %8811 = or i1 %8808, %8810
  %8812 = load i32, i32* %46, align 4
  %8813 = icmp eq i32 %8688, %8812
  %8814 = or i1 %8811, %8813
  %8815 = load i32, i32* %47, align 4
  %8816 = icmp eq i32 %8688, %8815
  %8817 = or i1 %8814, %8816
  %8818 = load i32, i32* %48, align 4
  %8819 = icmp eq i32 %8688, %8818
  %8820 = or i1 %8817, %8819
  %8821 = load i32, i32* %49, align 4
  %8822 = icmp eq i32 %8688, %8821
  %8823 = or i1 %8820, %8822
  %8824 = load i32, i32* %50, align 4
  %8825 = icmp eq i32 %8688, %8824
  %8826 = or i1 %8823, %8825
  %8827 = load i32, i32* %51, align 4
  %8828 = icmp eq i32 %8688, %8827
  %8829 = or i1 %8826, %8828
  %8830 = load i32, i32* %52, align 4
  %8831 = icmp eq i32 %8688, %8830
  %8832 = or i1 %8829, %8831
  %8833 = load i32, i32* %53, align 4
  %8834 = icmp eq i32 %8688, %8833
  %8835 = or i1 %8832, %8834
  %8836 = load i32, i32* %54, align 4
  %8837 = icmp eq i32 %8688, %8836
  %8838 = or i1 %8835, %8837
  %8839 = load i32, i32* %55, align 4
  %8840 = icmp eq i32 %8688, %8839
  %8841 = or i1 %8838, %8840
  %8842 = load i32, i32* %56, align 4
  %8843 = icmp eq i32 %8688, %8842
  %8844 = or i1 %8841, %8843
  %8845 = load i32, i32* %57, align 4
  %8846 = icmp eq i32 %8688, %8845
  %8847 = or i1 %8844, %8846
  %8848 = load i32, i32* %58, align 4
  %8849 = icmp eq i32 %8688, %8848
  %8850 = or i1 %8847, %8849
  %8851 = load i32, i32* %59, align 4
  %8852 = icmp eq i32 %8688, %8851
  %8853 = or i1 %8850, %8852
  %8854 = load i32, i32* %60, align 4
  %8855 = icmp eq i32 %8688, %8854
  %8856 = or i1 %8853, %8855
  %8857 = load i32, i32* %61, align 4
  %8858 = icmp eq i32 %8688, %8857
  %8859 = or i1 %8856, %8858
  %8860 = load i32, i32* %62, align 4
  %8861 = icmp eq i32 %8688, %8860
  %8862 = or i1 %8859, %8861
  %8863 = getelementptr i8, i8 addrspace(1)* %4, i32 19
  %8864 = zext i1 %8862 to i8
  store i8 %8864, i8 addrspace(1)* %8863, align 1, !nosanitize !3
  %8865 = load i256, i256* %8687, align 4
  %8866 = alloca i256, align 8
  store i256 6, i256* %8866, align 4
  %8867 = alloca i256, align 8
  call void @__device_sload(i256* %8866, i256* %8867)
  %8868 = call i32 @__hashword(i256* %8866)
  %8869 = load i32, i32* %5, align 4
  %8870 = icmp eq i32 %8868, %8869
  %8871 = or i1 false, %8870
  %8872 = load i32, i32* %6, align 4
  %8873 = icmp eq i32 %8868, %8872
  %8874 = or i1 %8871, %8873
  %8875 = load i32, i32* %7, align 4
  %8876 = icmp eq i32 %8868, %8875
  %8877 = or i1 %8874, %8876
  %8878 = load i32, i32* %8, align 4
  %8879 = icmp eq i32 %8868, %8878
  %8880 = or i1 %8877, %8879
  %8881 = load i32, i32* %9, align 4
  %8882 = icmp eq i32 %8868, %8881
  %8883 = or i1 %8880, %8882
  %8884 = load i32, i32* %10, align 4
  %8885 = icmp eq i32 %8868, %8884
  %8886 = or i1 %8883, %8885
  %8887 = load i32, i32* %11, align 4
  %8888 = icmp eq i32 %8868, %8887
  %8889 = or i1 %8886, %8888
  %8890 = load i32, i32* %12, align 4
  %8891 = icmp eq i32 %8868, %8890
  %8892 = or i1 %8889, %8891
  %8893 = load i32, i32* %13, align 4
  %8894 = icmp eq i32 %8868, %8893
  %8895 = or i1 %8892, %8894
  %8896 = load i32, i32* %14, align 4
  %8897 = icmp eq i32 %8868, %8896
  %8898 = or i1 %8895, %8897
  %8899 = load i32, i32* %15, align 4
  %8900 = icmp eq i32 %8868, %8899
  %8901 = or i1 %8898, %8900
  %8902 = load i32, i32* %16, align 4
  %8903 = icmp eq i32 %8868, %8902
  %8904 = or i1 %8901, %8903
  %8905 = load i32, i32* %17, align 4
  %8906 = icmp eq i32 %8868, %8905
  %8907 = or i1 %8904, %8906
  %8908 = load i32, i32* %18, align 4
  %8909 = icmp eq i32 %8868, %8908
  %8910 = or i1 %8907, %8909
  %8911 = load i32, i32* %19, align 4
  %8912 = icmp eq i32 %8868, %8911
  %8913 = or i1 %8910, %8912
  %8914 = load i32, i32* %20, align 4
  %8915 = icmp eq i32 %8868, %8914
  %8916 = or i1 %8913, %8915
  %8917 = load i32, i32* %21, align 4
  %8918 = icmp eq i32 %8868, %8917
  %8919 = or i1 %8916, %8918
  %8920 = load i32, i32* %22, align 4
  %8921 = icmp eq i32 %8868, %8920
  %8922 = or i1 %8919, %8921
  %8923 = load i32, i32* %23, align 4
  %8924 = icmp eq i32 %8868, %8923
  %8925 = or i1 %8922, %8924
  %8926 = load i32, i32* %24, align 4
  %8927 = icmp eq i32 %8868, %8926
  %8928 = or i1 %8925, %8927
  %8929 = load i32, i32* %25, align 4
  %8930 = icmp eq i32 %8868, %8929
  %8931 = or i1 %8928, %8930
  %8932 = load i32, i32* %26, align 4
  %8933 = icmp eq i32 %8868, %8932
  %8934 = or i1 %8931, %8933
  %8935 = load i32, i32* %27, align 4
  %8936 = icmp eq i32 %8868, %8935
  %8937 = or i1 %8934, %8936
  %8938 = load i32, i32* %28, align 4
  %8939 = icmp eq i32 %8868, %8938
  %8940 = or i1 %8937, %8939
  %8941 = load i32, i32* %29, align 4
  %8942 = icmp eq i32 %8868, %8941
  %8943 = or i1 %8940, %8942
  %8944 = load i32, i32* %30, align 4
  %8945 = icmp eq i32 %8868, %8944
  %8946 = or i1 %8943, %8945
  %8947 = load i32, i32* %31, align 4
  %8948 = icmp eq i32 %8868, %8947
  %8949 = or i1 %8946, %8948
  %8950 = load i32, i32* %32, align 4
  %8951 = icmp eq i32 %8868, %8950
  %8952 = or i1 %8949, %8951
  %8953 = load i32, i32* %33, align 4
  %8954 = icmp eq i32 %8868, %8953
  %8955 = or i1 %8952, %8954
  %8956 = load i32, i32* %34, align 4
  %8957 = icmp eq i32 %8868, %8956
  %8958 = or i1 %8955, %8957
  %8959 = load i32, i32* %35, align 4
  %8960 = icmp eq i32 %8868, %8959
  %8961 = or i1 %8958, %8960
  %8962 = load i32, i32* %36, align 4
  %8963 = icmp eq i32 %8868, %8962
  %8964 = or i1 %8961, %8963
  %8965 = load i32, i32* %37, align 4
  %8966 = icmp eq i32 %8868, %8965
  %8967 = or i1 %8964, %8966
  %8968 = load i32, i32* %38, align 4
  %8969 = icmp eq i32 %8868, %8968
  %8970 = or i1 %8967, %8969
  %8971 = load i32, i32* %39, align 4
  %8972 = icmp eq i32 %8868, %8971
  %8973 = or i1 %8970, %8972
  %8974 = load i32, i32* %40, align 4
  %8975 = icmp eq i32 %8868, %8974
  %8976 = or i1 %8973, %8975
  %8977 = load i32, i32* %41, align 4
  %8978 = icmp eq i32 %8868, %8977
  %8979 = or i1 %8976, %8978
  %8980 = load i32, i32* %42, align 4
  %8981 = icmp eq i32 %8868, %8980
  %8982 = or i1 %8979, %8981
  %8983 = load i32, i32* %43, align 4
  %8984 = icmp eq i32 %8868, %8983
  %8985 = or i1 %8982, %8984
  %8986 = load i32, i32* %44, align 4
  %8987 = icmp eq i32 %8868, %8986
  %8988 = or i1 %8985, %8987
  %8989 = load i32, i32* %45, align 4
  %8990 = icmp eq i32 %8868, %8989
  %8991 = or i1 %8988, %8990
  %8992 = load i32, i32* %46, align 4
  %8993 = icmp eq i32 %8868, %8992
  %8994 = or i1 %8991, %8993
  %8995 = load i32, i32* %47, align 4
  %8996 = icmp eq i32 %8868, %8995
  %8997 = or i1 %8994, %8996
  %8998 = load i32, i32* %48, align 4
  %8999 = icmp eq i32 %8868, %8998
  %9000 = or i1 %8997, %8999
  %9001 = load i32, i32* %49, align 4
  %9002 = icmp eq i32 %8868, %9001
  %9003 = or i1 %9000, %9002
  %9004 = load i32, i32* %50, align 4
  %9005 = icmp eq i32 %8868, %9004
  %9006 = or i1 %9003, %9005
  %9007 = load i32, i32* %51, align 4
  %9008 = icmp eq i32 %8868, %9007
  %9009 = or i1 %9006, %9008
  %9010 = load i32, i32* %52, align 4
  %9011 = icmp eq i32 %8868, %9010
  %9012 = or i1 %9009, %9011
  %9013 = load i32, i32* %53, align 4
  %9014 = icmp eq i32 %8868, %9013
  %9015 = or i1 %9012, %9014
  %9016 = load i32, i32* %54, align 4
  %9017 = icmp eq i32 %8868, %9016
  %9018 = or i1 %9015, %9017
  %9019 = load i32, i32* %55, align 4
  %9020 = icmp eq i32 %8868, %9019
  %9021 = or i1 %9018, %9020
  %9022 = load i32, i32* %56, align 4
  %9023 = icmp eq i32 %8868, %9022
  %9024 = or i1 %9021, %9023
  %9025 = load i32, i32* %57, align 4
  %9026 = icmp eq i32 %8868, %9025
  %9027 = or i1 %9024, %9026
  %9028 = load i32, i32* %58, align 4
  %9029 = icmp eq i32 %8868, %9028
  %9030 = or i1 %9027, %9029
  %9031 = load i32, i32* %59, align 4
  %9032 = icmp eq i32 %8868, %9031
  %9033 = or i1 %9030, %9032
  %9034 = load i32, i32* %60, align 4
  %9035 = icmp eq i32 %8868, %9034
  %9036 = or i1 %9033, %9035
  %9037 = load i32, i32* %61, align 4
  %9038 = icmp eq i32 %8868, %9037
  %9039 = or i1 %9036, %9038
  %9040 = load i32, i32* %62, align 4
  %9041 = icmp eq i32 %8868, %9040
  %9042 = or i1 %9039, %9041
  %9043 = getelementptr i8, i8 addrspace(1)* %4, i32 20
  %9044 = zext i1 %9042 to i8
  store i8 %9044, i8 addrspace(1)* %9043, align 1, !nosanitize !3
  %9045 = load i256, i256* %8867, align 4
  %9046 = add i256 %9045, %8865, !pc !219, !intsan !10
  %9047 = icmp ult i256 %9046, %8685
  %9048 = load i64, i64* %STACK_DEP_PTR, align 4
  %9049 = add i64 %9048, 1
  store i64 %9049, i64* %STACK_DEP_PTR, align 4
  %9050 = zext i1 %9047 to i256
  %9051 = load i64, i64* %STACK_DEP_PTR, align 4
  %9052 = getelementptr i256, i256* %STACK, i64 %9051
  store i256 %9050, i256* %9052, align 4
  br label %.4412

.4412:                                            ; preds = %.4400, %8487, %JumpTable
  %9053 = load i64, i64* %remaing_gas, align 4
  %9054 = icmp ugt i64 88, %9053
  br i1 %9054, label %Abort, label %9055

9055:                                             ; preds = %.4412
  %9056 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9057 = xor i32 %9056, 3894
  %9058 = urem i32 %9057, 4096
  %9059 = getelementptr i8, i8 addrspace(1)* %4, i32 %9058
  %9060 = load i8, i8 addrspace(1)* %9059, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %9059, align 1, !nosanitize !3
  store i32 1947, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9061 = sub i64 %9053, 88
  store i64 %9061, i64* %remaing_gas, align 4
  %9062 = load i64, i64* %STACK_DEP_PTR, align 4
  %9063 = getelementptr i256, i256* %STACK, i64 %9062
  %9064 = load i256, i256* %9063, align 4
  %9065 = load i64, i64* %STACK_DEP_PTR, align 4
  %9066 = sub i64 %9065, 1
  store i64 %9066, i64* %STACK_DEP_PTR, align 4
  %9067 = icmp eq i256 %9064, 0
  %9068 = trunc i256 4426 to i64
  %jump.check28 = icmp ne i1 %9067, false
  br i1 %jump.check28, label %.4426, label %.4418, !EVMBB !4

.4418:                                            ; preds = %9055
  %9069 = load i64, i64* %remaing_gas, align 4
  %9070 = icmp ugt i64 120, %9069
  br i1 %9070, label %Abort, label %9071

9071:                                             ; preds = %.4418
  %9072 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9073 = xor i32 %9072, 148
  %9074 = urem i32 %9073, 4096
  %9075 = getelementptr i8, i8 addrspace(1)* %4, i32 %9074
  %9076 = load i8, i8 addrspace(1)* %9075, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %9075, align 1, !nosanitize !3
  store i32 74, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9077 = sub i64 %9069, 120
  store i64 %9077, i64* %remaing_gas, align 4
  %9078 = load i64, i64* %STACK_DEP_PTR, align 4
  %9079 = getelementptr i256, i256* %STACK, i64 %9078
  %9080 = load i256, i256* %9079, align 4
  %9081 = load i64, i64* %STACK_DEP_PTR, align 4
  %9082 = sub i64 %9081, 1
  store i64 %9082, i64* %STACK_DEP_PTR, align 4
  %9083 = trunc i256 4440 to i64
  %9084 = load i64, i64* %STACK_DEP_PTR, align 4
  %9085 = add i64 %9084, 1
  store i64 %9085, i64* %STACK_DEP_PTR, align 4
  %9086 = load i64, i64* %STACK_DEP_PTR, align 4
  %9087 = getelementptr i256, i256* %STACK, i64 %9086
  store i256 0, i256* %9087, align 4
  br label %.4440, !EVMBB !4

.4426:                                            ; preds = %9055, %JumpTable
  %9088 = load i64, i64* %STACK_DEP_PTR, align 4
  %9089 = getelementptr i256, i256* %STACK, i64 %9088
  %9090 = load i256, i256* %9089, align 4
  %9091 = load i64, i64* %STACK_DEP_PTR, align 4
  %9092 = sub i64 %9091, 1
  store i64 %9092, i64* %STACK_DEP_PTR, align 4
  %9093 = alloca i256, align 8
  store i256 14, i256* %9093, align 4
  %9094 = alloca i256, align 8
  call void @__device_sload(i256* %9093, i256* %9094)
  %9095 = call i32 @__hashword(i256* %9093)
  %9096 = load i32, i32* %5, align 4
  %9097 = icmp eq i32 %9095, %9096
  %9098 = or i1 false, %9097
  %9099 = load i32, i32* %6, align 4
  %9100 = icmp eq i32 %9095, %9099
  %9101 = or i1 %9098, %9100
  %9102 = load i32, i32* %7, align 4
  %9103 = icmp eq i32 %9095, %9102
  %9104 = or i1 %9101, %9103
  %9105 = load i32, i32* %8, align 4
  %9106 = icmp eq i32 %9095, %9105
  %9107 = or i1 %9104, %9106
  %9108 = load i32, i32* %9, align 4
  %9109 = icmp eq i32 %9095, %9108
  %9110 = or i1 %9107, %9109
  %9111 = load i32, i32* %10, align 4
  %9112 = icmp eq i32 %9095, %9111
  %9113 = or i1 %9110, %9112
  %9114 = load i32, i32* %11, align 4
  %9115 = icmp eq i32 %9095, %9114
  %9116 = or i1 %9113, %9115
  %9117 = load i32, i32* %12, align 4
  %9118 = icmp eq i32 %9095, %9117
  %9119 = or i1 %9116, %9118
  %9120 = load i32, i32* %13, align 4
  %9121 = icmp eq i32 %9095, %9120
  %9122 = or i1 %9119, %9121
  %9123 = load i32, i32* %14, align 4
  %9124 = icmp eq i32 %9095, %9123
  %9125 = or i1 %9122, %9124
  %9126 = load i32, i32* %15, align 4
  %9127 = icmp eq i32 %9095, %9126
  %9128 = or i1 %9125, %9127
  %9129 = load i32, i32* %16, align 4
  %9130 = icmp eq i32 %9095, %9129
  %9131 = or i1 %9128, %9130
  %9132 = load i32, i32* %17, align 4
  %9133 = icmp eq i32 %9095, %9132
  %9134 = or i1 %9131, %9133
  %9135 = load i32, i32* %18, align 4
  %9136 = icmp eq i32 %9095, %9135
  %9137 = or i1 %9134, %9136
  %9138 = load i32, i32* %19, align 4
  %9139 = icmp eq i32 %9095, %9138
  %9140 = or i1 %9137, %9139
  %9141 = load i32, i32* %20, align 4
  %9142 = icmp eq i32 %9095, %9141
  %9143 = or i1 %9140, %9142
  %9144 = load i32, i32* %21, align 4
  %9145 = icmp eq i32 %9095, %9144
  %9146 = or i1 %9143, %9145
  %9147 = load i32, i32* %22, align 4
  %9148 = icmp eq i32 %9095, %9147
  %9149 = or i1 %9146, %9148
  %9150 = load i32, i32* %23, align 4
  %9151 = icmp eq i32 %9095, %9150
  %9152 = or i1 %9149, %9151
  %9153 = load i32, i32* %24, align 4
  %9154 = icmp eq i32 %9095, %9153
  %9155 = or i1 %9152, %9154
  %9156 = load i32, i32* %25, align 4
  %9157 = icmp eq i32 %9095, %9156
  %9158 = or i1 %9155, %9157
  %9159 = load i32, i32* %26, align 4
  %9160 = icmp eq i32 %9095, %9159
  %9161 = or i1 %9158, %9160
  %9162 = load i32, i32* %27, align 4
  %9163 = icmp eq i32 %9095, %9162
  %9164 = or i1 %9161, %9163
  %9165 = load i32, i32* %28, align 4
  %9166 = icmp eq i32 %9095, %9165
  %9167 = or i1 %9164, %9166
  %9168 = load i32, i32* %29, align 4
  %9169 = icmp eq i32 %9095, %9168
  %9170 = or i1 %9167, %9169
  %9171 = load i32, i32* %30, align 4
  %9172 = icmp eq i32 %9095, %9171
  %9173 = or i1 %9170, %9172
  %9174 = load i32, i32* %31, align 4
  %9175 = icmp eq i32 %9095, %9174
  %9176 = or i1 %9173, %9175
  %9177 = load i32, i32* %32, align 4
  %9178 = icmp eq i32 %9095, %9177
  %9179 = or i1 %9176, %9178
  %9180 = load i32, i32* %33, align 4
  %9181 = icmp eq i32 %9095, %9180
  %9182 = or i1 %9179, %9181
  %9183 = load i32, i32* %34, align 4
  %9184 = icmp eq i32 %9095, %9183
  %9185 = or i1 %9182, %9184
  %9186 = load i32, i32* %35, align 4
  %9187 = icmp eq i32 %9095, %9186
  %9188 = or i1 %9185, %9187
  %9189 = load i32, i32* %36, align 4
  %9190 = icmp eq i32 %9095, %9189
  %9191 = or i1 %9188, %9190
  %9192 = load i32, i32* %37, align 4
  %9193 = icmp eq i32 %9095, %9192
  %9194 = or i1 %9191, %9193
  %9195 = load i32, i32* %38, align 4
  %9196 = icmp eq i32 %9095, %9195
  %9197 = or i1 %9194, %9196
  %9198 = load i32, i32* %39, align 4
  %9199 = icmp eq i32 %9095, %9198
  %9200 = or i1 %9197, %9199
  %9201 = load i32, i32* %40, align 4
  %9202 = icmp eq i32 %9095, %9201
  %9203 = or i1 %9200, %9202
  %9204 = load i32, i32* %41, align 4
  %9205 = icmp eq i32 %9095, %9204
  %9206 = or i1 %9203, %9205
  %9207 = load i32, i32* %42, align 4
  %9208 = icmp eq i32 %9095, %9207
  %9209 = or i1 %9206, %9208
  %9210 = load i32, i32* %43, align 4
  %9211 = icmp eq i32 %9095, %9210
  %9212 = or i1 %9209, %9211
  %9213 = load i32, i32* %44, align 4
  %9214 = icmp eq i32 %9095, %9213
  %9215 = or i1 %9212, %9214
  %9216 = load i32, i32* %45, align 4
  %9217 = icmp eq i32 %9095, %9216
  %9218 = or i1 %9215, %9217
  %9219 = load i32, i32* %46, align 4
  %9220 = icmp eq i32 %9095, %9219
  %9221 = or i1 %9218, %9220
  %9222 = load i32, i32* %47, align 4
  %9223 = icmp eq i32 %9095, %9222
  %9224 = or i1 %9221, %9223
  %9225 = load i32, i32* %48, align 4
  %9226 = icmp eq i32 %9095, %9225
  %9227 = or i1 %9224, %9226
  %9228 = load i32, i32* %49, align 4
  %9229 = icmp eq i32 %9095, %9228
  %9230 = or i1 %9227, %9229
  %9231 = load i32, i32* %50, align 4
  %9232 = icmp eq i32 %9095, %9231
  %9233 = or i1 %9230, %9232
  %9234 = load i32, i32* %51, align 4
  %9235 = icmp eq i32 %9095, %9234
  %9236 = or i1 %9233, %9235
  %9237 = load i32, i32* %52, align 4
  %9238 = icmp eq i32 %9095, %9237
  %9239 = or i1 %9236, %9238
  %9240 = load i32, i32* %53, align 4
  %9241 = icmp eq i32 %9095, %9240
  %9242 = or i1 %9239, %9241
  %9243 = load i32, i32* %54, align 4
  %9244 = icmp eq i32 %9095, %9243
  %9245 = or i1 %9242, %9244
  %9246 = load i32, i32* %55, align 4
  %9247 = icmp eq i32 %9095, %9246
  %9248 = or i1 %9245, %9247
  %9249 = load i32, i32* %56, align 4
  %9250 = icmp eq i32 %9095, %9249
  %9251 = or i1 %9248, %9250
  %9252 = load i32, i32* %57, align 4
  %9253 = icmp eq i32 %9095, %9252
  %9254 = or i1 %9251, %9253
  %9255 = load i32, i32* %58, align 4
  %9256 = icmp eq i32 %9095, %9255
  %9257 = or i1 %9254, %9256
  %9258 = load i32, i32* %59, align 4
  %9259 = icmp eq i32 %9095, %9258
  %9260 = or i1 %9257, %9259
  %9261 = load i32, i32* %60, align 4
  %9262 = icmp eq i32 %9095, %9261
  %9263 = or i1 %9260, %9262
  %9264 = load i32, i32* %61, align 4
  %9265 = icmp eq i32 %9095, %9264
  %9266 = or i1 %9263, %9265
  %9267 = load i32, i32* %62, align 4
  %9268 = icmp eq i32 %9095, %9267
  %9269 = or i1 %9266, %9268
  %9270 = getelementptr i8, i8 addrspace(1)* %4, i32 21
  %9271 = zext i1 %9269 to i8
  store i8 %9271, i8 addrspace(1)* %9270, align 1, !nosanitize !3
  %9272 = load i256, i256* %9094, align 4
  %9273 = alloca i256, align 8
  store i256 13, i256* %9273, align 4
  %9274 = alloca i256, align 8
  call void @__device_sload(i256* %9273, i256* %9274)
  %9275 = call i32 @__hashword(i256* %9273)
  %9276 = load i32, i32* %5, align 4
  %9277 = icmp eq i32 %9275, %9276
  %9278 = or i1 false, %9277
  %9279 = load i32, i32* %6, align 4
  %9280 = icmp eq i32 %9275, %9279
  %9281 = or i1 %9278, %9280
  %9282 = load i32, i32* %7, align 4
  %9283 = icmp eq i32 %9275, %9282
  %9284 = or i1 %9281, %9283
  %9285 = load i32, i32* %8, align 4
  %9286 = icmp eq i32 %9275, %9285
  %9287 = or i1 %9284, %9286
  %9288 = load i32, i32* %9, align 4
  %9289 = icmp eq i32 %9275, %9288
  %9290 = or i1 %9287, %9289
  %9291 = load i32, i32* %10, align 4
  %9292 = icmp eq i32 %9275, %9291
  %9293 = or i1 %9290, %9292
  %9294 = load i32, i32* %11, align 4
  %9295 = icmp eq i32 %9275, %9294
  %9296 = or i1 %9293, %9295
  %9297 = load i32, i32* %12, align 4
  %9298 = icmp eq i32 %9275, %9297
  %9299 = or i1 %9296, %9298
  %9300 = load i32, i32* %13, align 4
  %9301 = icmp eq i32 %9275, %9300
  %9302 = or i1 %9299, %9301
  %9303 = load i32, i32* %14, align 4
  %9304 = icmp eq i32 %9275, %9303
  %9305 = or i1 %9302, %9304
  %9306 = load i32, i32* %15, align 4
  %9307 = icmp eq i32 %9275, %9306
  %9308 = or i1 %9305, %9307
  %9309 = load i32, i32* %16, align 4
  %9310 = icmp eq i32 %9275, %9309
  %9311 = or i1 %9308, %9310
  %9312 = load i32, i32* %17, align 4
  %9313 = icmp eq i32 %9275, %9312
  %9314 = or i1 %9311, %9313
  %9315 = load i32, i32* %18, align 4
  %9316 = icmp eq i32 %9275, %9315
  %9317 = or i1 %9314, %9316
  %9318 = load i32, i32* %19, align 4
  %9319 = icmp eq i32 %9275, %9318
  %9320 = or i1 %9317, %9319
  %9321 = load i32, i32* %20, align 4
  %9322 = icmp eq i32 %9275, %9321
  %9323 = or i1 %9320, %9322
  %9324 = load i32, i32* %21, align 4
  %9325 = icmp eq i32 %9275, %9324
  %9326 = or i1 %9323, %9325
  %9327 = load i32, i32* %22, align 4
  %9328 = icmp eq i32 %9275, %9327
  %9329 = or i1 %9326, %9328
  %9330 = load i32, i32* %23, align 4
  %9331 = icmp eq i32 %9275, %9330
  %9332 = or i1 %9329, %9331
  %9333 = load i32, i32* %24, align 4
  %9334 = icmp eq i32 %9275, %9333
  %9335 = or i1 %9332, %9334
  %9336 = load i32, i32* %25, align 4
  %9337 = icmp eq i32 %9275, %9336
  %9338 = or i1 %9335, %9337
  %9339 = load i32, i32* %26, align 4
  %9340 = icmp eq i32 %9275, %9339
  %9341 = or i1 %9338, %9340
  %9342 = load i32, i32* %27, align 4
  %9343 = icmp eq i32 %9275, %9342
  %9344 = or i1 %9341, %9343
  %9345 = load i32, i32* %28, align 4
  %9346 = icmp eq i32 %9275, %9345
  %9347 = or i1 %9344, %9346
  %9348 = load i32, i32* %29, align 4
  %9349 = icmp eq i32 %9275, %9348
  %9350 = or i1 %9347, %9349
  %9351 = load i32, i32* %30, align 4
  %9352 = icmp eq i32 %9275, %9351
  %9353 = or i1 %9350, %9352
  %9354 = load i32, i32* %31, align 4
  %9355 = icmp eq i32 %9275, %9354
  %9356 = or i1 %9353, %9355
  %9357 = load i32, i32* %32, align 4
  %9358 = icmp eq i32 %9275, %9357
  %9359 = or i1 %9356, %9358
  %9360 = load i32, i32* %33, align 4
  %9361 = icmp eq i32 %9275, %9360
  %9362 = or i1 %9359, %9361
  %9363 = load i32, i32* %34, align 4
  %9364 = icmp eq i32 %9275, %9363
  %9365 = or i1 %9362, %9364
  %9366 = load i32, i32* %35, align 4
  %9367 = icmp eq i32 %9275, %9366
  %9368 = or i1 %9365, %9367
  %9369 = load i32, i32* %36, align 4
  %9370 = icmp eq i32 %9275, %9369
  %9371 = or i1 %9368, %9370
  %9372 = load i32, i32* %37, align 4
  %9373 = icmp eq i32 %9275, %9372
  %9374 = or i1 %9371, %9373
  %9375 = load i32, i32* %38, align 4
  %9376 = icmp eq i32 %9275, %9375
  %9377 = or i1 %9374, %9376
  %9378 = load i32, i32* %39, align 4
  %9379 = icmp eq i32 %9275, %9378
  %9380 = or i1 %9377, %9379
  %9381 = load i32, i32* %40, align 4
  %9382 = icmp eq i32 %9275, %9381
  %9383 = or i1 %9380, %9382
  %9384 = load i32, i32* %41, align 4
  %9385 = icmp eq i32 %9275, %9384
  %9386 = or i1 %9383, %9385
  %9387 = load i32, i32* %42, align 4
  %9388 = icmp eq i32 %9275, %9387
  %9389 = or i1 %9386, %9388
  %9390 = load i32, i32* %43, align 4
  %9391 = icmp eq i32 %9275, %9390
  %9392 = or i1 %9389, %9391
  %9393 = load i32, i32* %44, align 4
  %9394 = icmp eq i32 %9275, %9393
  %9395 = or i1 %9392, %9394
  %9396 = load i32, i32* %45, align 4
  %9397 = icmp eq i32 %9275, %9396
  %9398 = or i1 %9395, %9397
  %9399 = load i32, i32* %46, align 4
  %9400 = icmp eq i32 %9275, %9399
  %9401 = or i1 %9398, %9400
  %9402 = load i32, i32* %47, align 4
  %9403 = icmp eq i32 %9275, %9402
  %9404 = or i1 %9401, %9403
  %9405 = load i32, i32* %48, align 4
  %9406 = icmp eq i32 %9275, %9405
  %9407 = or i1 %9404, %9406
  %9408 = load i32, i32* %49, align 4
  %9409 = icmp eq i32 %9275, %9408
  %9410 = or i1 %9407, %9409
  %9411 = load i32, i32* %50, align 4
  %9412 = icmp eq i32 %9275, %9411
  %9413 = or i1 %9410, %9412
  %9414 = load i32, i32* %51, align 4
  %9415 = icmp eq i32 %9275, %9414
  %9416 = or i1 %9413, %9415
  %9417 = load i32, i32* %52, align 4
  %9418 = icmp eq i32 %9275, %9417
  %9419 = or i1 %9416, %9418
  %9420 = load i32, i32* %53, align 4
  %9421 = icmp eq i32 %9275, %9420
  %9422 = or i1 %9419, %9421
  %9423 = load i32, i32* %54, align 4
  %9424 = icmp eq i32 %9275, %9423
  %9425 = or i1 %9422, %9424
  %9426 = load i32, i32* %55, align 4
  %9427 = icmp eq i32 %9275, %9426
  %9428 = or i1 %9425, %9427
  %9429 = load i32, i32* %56, align 4
  %9430 = icmp eq i32 %9275, %9429
  %9431 = or i1 %9428, %9430
  %9432 = load i32, i32* %57, align 4
  %9433 = icmp eq i32 %9275, %9432
  %9434 = or i1 %9431, %9433
  %9435 = load i32, i32* %58, align 4
  %9436 = icmp eq i32 %9275, %9435
  %9437 = or i1 %9434, %9436
  %9438 = load i32, i32* %59, align 4
  %9439 = icmp eq i32 %9275, %9438
  %9440 = or i1 %9437, %9439
  %9441 = load i32, i32* %60, align 4
  %9442 = icmp eq i32 %9275, %9441
  %9443 = or i1 %9440, %9442
  %9444 = load i32, i32* %61, align 4
  %9445 = icmp eq i32 %9275, %9444
  %9446 = or i1 %9443, %9445
  %9447 = load i32, i32* %62, align 4
  %9448 = icmp eq i32 %9275, %9447
  %9449 = or i1 %9446, %9448
  %9450 = getelementptr i8, i8 addrspace(1)* %4, i32 22
  %9451 = zext i1 %9449 to i8
  store i8 %9451, i8 addrspace(1)* %9450, align 1, !nosanitize !3
  %9452 = load i256, i256* %9274, align 4
  %9453 = alloca i256, align 8
  store i256 6, i256* %9453, align 4
  %9454 = alloca i256, align 8
  call void @__device_sload(i256* %9453, i256* %9454)
  %9455 = call i32 @__hashword(i256* %9453)
  %9456 = load i32, i32* %5, align 4
  %9457 = icmp eq i32 %9455, %9456
  %9458 = or i1 false, %9457
  %9459 = load i32, i32* %6, align 4
  %9460 = icmp eq i32 %9455, %9459
  %9461 = or i1 %9458, %9460
  %9462 = load i32, i32* %7, align 4
  %9463 = icmp eq i32 %9455, %9462
  %9464 = or i1 %9461, %9463
  %9465 = load i32, i32* %8, align 4
  %9466 = icmp eq i32 %9455, %9465
  %9467 = or i1 %9464, %9466
  %9468 = load i32, i32* %9, align 4
  %9469 = icmp eq i32 %9455, %9468
  %9470 = or i1 %9467, %9469
  %9471 = load i32, i32* %10, align 4
  %9472 = icmp eq i32 %9455, %9471
  %9473 = or i1 %9470, %9472
  %9474 = load i32, i32* %11, align 4
  %9475 = icmp eq i32 %9455, %9474
  %9476 = or i1 %9473, %9475
  %9477 = load i32, i32* %12, align 4
  %9478 = icmp eq i32 %9455, %9477
  %9479 = or i1 %9476, %9478
  %9480 = load i32, i32* %13, align 4
  %9481 = icmp eq i32 %9455, %9480
  %9482 = or i1 %9479, %9481
  %9483 = load i32, i32* %14, align 4
  %9484 = icmp eq i32 %9455, %9483
  %9485 = or i1 %9482, %9484
  %9486 = load i32, i32* %15, align 4
  %9487 = icmp eq i32 %9455, %9486
  %9488 = or i1 %9485, %9487
  %9489 = load i32, i32* %16, align 4
  %9490 = icmp eq i32 %9455, %9489
  %9491 = or i1 %9488, %9490
  %9492 = load i32, i32* %17, align 4
  %9493 = icmp eq i32 %9455, %9492
  %9494 = or i1 %9491, %9493
  %9495 = load i32, i32* %18, align 4
  %9496 = icmp eq i32 %9455, %9495
  %9497 = or i1 %9494, %9496
  %9498 = load i32, i32* %19, align 4
  %9499 = icmp eq i32 %9455, %9498
  %9500 = or i1 %9497, %9499
  %9501 = load i32, i32* %20, align 4
  %9502 = icmp eq i32 %9455, %9501
  %9503 = or i1 %9500, %9502
  %9504 = load i32, i32* %21, align 4
  %9505 = icmp eq i32 %9455, %9504
  %9506 = or i1 %9503, %9505
  %9507 = load i32, i32* %22, align 4
  %9508 = icmp eq i32 %9455, %9507
  %9509 = or i1 %9506, %9508
  %9510 = load i32, i32* %23, align 4
  %9511 = icmp eq i32 %9455, %9510
  %9512 = or i1 %9509, %9511
  %9513 = load i32, i32* %24, align 4
  %9514 = icmp eq i32 %9455, %9513
  %9515 = or i1 %9512, %9514
  %9516 = load i32, i32* %25, align 4
  %9517 = icmp eq i32 %9455, %9516
  %9518 = or i1 %9515, %9517
  %9519 = load i32, i32* %26, align 4
  %9520 = icmp eq i32 %9455, %9519
  %9521 = or i1 %9518, %9520
  %9522 = load i32, i32* %27, align 4
  %9523 = icmp eq i32 %9455, %9522
  %9524 = or i1 %9521, %9523
  %9525 = load i32, i32* %28, align 4
  %9526 = icmp eq i32 %9455, %9525
  %9527 = or i1 %9524, %9526
  %9528 = load i32, i32* %29, align 4
  %9529 = icmp eq i32 %9455, %9528
  %9530 = or i1 %9527, %9529
  %9531 = load i32, i32* %30, align 4
  %9532 = icmp eq i32 %9455, %9531
  %9533 = or i1 %9530, %9532
  %9534 = load i32, i32* %31, align 4
  %9535 = icmp eq i32 %9455, %9534
  %9536 = or i1 %9533, %9535
  %9537 = load i32, i32* %32, align 4
  %9538 = icmp eq i32 %9455, %9537
  %9539 = or i1 %9536, %9538
  %9540 = load i32, i32* %33, align 4
  %9541 = icmp eq i32 %9455, %9540
  %9542 = or i1 %9539, %9541
  %9543 = load i32, i32* %34, align 4
  %9544 = icmp eq i32 %9455, %9543
  %9545 = or i1 %9542, %9544
  %9546 = load i32, i32* %35, align 4
  %9547 = icmp eq i32 %9455, %9546
  %9548 = or i1 %9545, %9547
  %9549 = load i32, i32* %36, align 4
  %9550 = icmp eq i32 %9455, %9549
  %9551 = or i1 %9548, %9550
  %9552 = load i32, i32* %37, align 4
  %9553 = icmp eq i32 %9455, %9552
  %9554 = or i1 %9551, %9553
  %9555 = load i32, i32* %38, align 4
  %9556 = icmp eq i32 %9455, %9555
  %9557 = or i1 %9554, %9556
  %9558 = load i32, i32* %39, align 4
  %9559 = icmp eq i32 %9455, %9558
  %9560 = or i1 %9557, %9559
  %9561 = load i32, i32* %40, align 4
  %9562 = icmp eq i32 %9455, %9561
  %9563 = or i1 %9560, %9562
  %9564 = load i32, i32* %41, align 4
  %9565 = icmp eq i32 %9455, %9564
  %9566 = or i1 %9563, %9565
  %9567 = load i32, i32* %42, align 4
  %9568 = icmp eq i32 %9455, %9567
  %9569 = or i1 %9566, %9568
  %9570 = load i32, i32* %43, align 4
  %9571 = icmp eq i32 %9455, %9570
  %9572 = or i1 %9569, %9571
  %9573 = load i32, i32* %44, align 4
  %9574 = icmp eq i32 %9455, %9573
  %9575 = or i1 %9572, %9574
  %9576 = load i32, i32* %45, align 4
  %9577 = icmp eq i32 %9455, %9576
  %9578 = or i1 %9575, %9577
  %9579 = load i32, i32* %46, align 4
  %9580 = icmp eq i32 %9455, %9579
  %9581 = or i1 %9578, %9580
  %9582 = load i32, i32* %47, align 4
  %9583 = icmp eq i32 %9455, %9582
  %9584 = or i1 %9581, %9583
  %9585 = load i32, i32* %48, align 4
  %9586 = icmp eq i32 %9455, %9585
  %9587 = or i1 %9584, %9586
  %9588 = load i32, i32* %49, align 4
  %9589 = icmp eq i32 %9455, %9588
  %9590 = or i1 %9587, %9589
  %9591 = load i32, i32* %50, align 4
  %9592 = icmp eq i32 %9455, %9591
  %9593 = or i1 %9590, %9592
  %9594 = load i32, i32* %51, align 4
  %9595 = icmp eq i32 %9455, %9594
  %9596 = or i1 %9593, %9595
  %9597 = load i32, i32* %52, align 4
  %9598 = icmp eq i32 %9455, %9597
  %9599 = or i1 %9596, %9598
  %9600 = load i32, i32* %53, align 4
  %9601 = icmp eq i32 %9455, %9600
  %9602 = or i1 %9599, %9601
  %9603 = load i32, i32* %54, align 4
  %9604 = icmp eq i32 %9455, %9603
  %9605 = or i1 %9602, %9604
  %9606 = load i32, i32* %55, align 4
  %9607 = icmp eq i32 %9455, %9606
  %9608 = or i1 %9605, %9607
  %9609 = load i32, i32* %56, align 4
  %9610 = icmp eq i32 %9455, %9609
  %9611 = or i1 %9608, %9610
  %9612 = load i32, i32* %57, align 4
  %9613 = icmp eq i32 %9455, %9612
  %9614 = or i1 %9611, %9613
  %9615 = load i32, i32* %58, align 4
  %9616 = icmp eq i32 %9455, %9615
  %9617 = or i1 %9614, %9616
  %9618 = load i32, i32* %59, align 4
  %9619 = icmp eq i32 %9455, %9618
  %9620 = or i1 %9617, %9619
  %9621 = load i32, i32* %60, align 4
  %9622 = icmp eq i32 %9455, %9621
  %9623 = or i1 %9620, %9622
  %9624 = load i32, i32* %61, align 4
  %9625 = icmp eq i32 %9455, %9624
  %9626 = or i1 %9623, %9625
  %9627 = load i32, i32* %62, align 4
  %9628 = icmp eq i32 %9455, %9627
  %9629 = or i1 %9626, %9628
  %9630 = getelementptr i8, i8 addrspace(1)* %4, i32 23
  %9631 = zext i1 %9629 to i8
  store i8 %9631, i8 addrspace(1)* %9630, align 1, !nosanitize !3
  %9632 = load i256, i256* %9454, align 4
  %9633 = add i256 %9632, %9452, !pc !220, !intsan !10
  %9634 = sub i256 %9633, %9272, !pc !221, !intsan !8
  %9635 = load i64, i64* %STACK_DEP_PTR, align 4
  %9636 = add i64 %9635, 1
  store i64 %9636, i64* %STACK_DEP_PTR, align 4
  %9637 = load i64, i64* %STACK_DEP_PTR, align 4
  %9638 = getelementptr i256, i256* %STACK, i64 %9637
  store i256 %9634, i256* %9638, align 4
  br label %.4440

.4440:                                            ; preds = %.4426, %9071, %JumpTable
  %9639 = load i64, i64* %remaing_gas, align 4
  %9640 = icmp ugt i64 176, %9639
  br i1 %9640, label %Abort, label %9641

9641:                                             ; preds = %.4440
  %9642 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9643 = xor i32 %9642, 691
  %9644 = urem i32 %9643, 4096
  %9645 = getelementptr i8, i8 addrspace(1)* %4, i32 %9644
  %9646 = load i8, i8 addrspace(1)* %9645, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %9645, align 1, !nosanitize !3
  store i32 345, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9647 = sub i64 %9639, 176
  store i64 %9647, i64* %remaing_gas, align 4
  %9648 = load i64, i64* %STACK_DEP_PTR, align 4
  %9649 = getelementptr i256, i256* %STACK, i64 %9648
  %9650 = load i256, i256* %9649, align 4
  %9651 = load i64, i64* %STACK_DEP_PTR, align 4
  %9652 = sub i64 %9651, 1
  store i64 %9652, i64* %STACK_DEP_PTR, align 4
  %9653 = load i64, i64* %STACK_DEP_PTR, align 4
  %9654 = getelementptr i256, i256* %STACK, i64 %9653
  %9655 = load i256, i256* %9654, align 4
  %9656 = load i64, i64* %STACK_DEP_PTR, align 4
  %9657 = sub i64 %9656, 1
  store i64 %9657, i64* %STACK_DEP_PTR, align 4
  %9658 = trunc i256 %9655 to i64
  store i64 %9658, i64* %JMP_TARGET_PTR, align 4
  %9659 = load i64, i64* %STACK_DEP_PTR, align 4
  %9660 = add i64 %9659, 1
  store i64 %9660, i64* %STACK_DEP_PTR, align 4
  %9661 = load i64, i64* %STACK_DEP_PTR, align 4
  %9662 = getelementptr i256, i256* %STACK, i64 %9661
  store i256 %9650, i256* %9662, align 4
  br label %JumpTable, !EVMBB !4

.4443:                                            ; preds = %50866, %33953, %1087, %JumpTable
  %9663 = load i64, i64* %remaing_gas, align 4
  %9664 = icmp ugt i64 784, %9663
  br i1 %9664, label %Abort, label %9665

9665:                                             ; preds = %.4443
  %9666 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9667 = xor i32 %9666, 2479
  %9668 = urem i32 %9667, 4096
  %9669 = getelementptr i8, i8 addrspace(1)* %4, i32 %9668
  %9670 = load i8, i8 addrspace(1)* %9669, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %9669, align 1, !nosanitize !3
  store i32 1239, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %9671 = sub i64 %9663, 784
  store i64 %9671, i64* %remaing_gas, align 4
  %9672 = load i64, i64* %STACK_DEP_PTR, align 4
  %9673 = getelementptr i256, i256* %STACK, i64 %9672
  %9674 = load i256, i256* %9673, align 4
  %9675 = load i64, i64* %STACK_DEP_PTR, align 4
  %9676 = sub i64 %9675, 1
  store i64 %9676, i64* %STACK_DEP_PTR, align 4
  %9677 = alloca i256, align 8
  store i256 6, i256* %9677, align 4
  %9678 = alloca i256, align 8
  call void @__device_sload(i256* %9677, i256* %9678)
  %9679 = call i32 @__hashword(i256* %9677)
  %9680 = load i32, i32* %5, align 4
  %9681 = icmp eq i32 %9679, %9680
  %9682 = or i1 false, %9681
  %9683 = load i32, i32* %6, align 4
  %9684 = icmp eq i32 %9679, %9683
  %9685 = or i1 %9682, %9684
  %9686 = load i32, i32* %7, align 4
  %9687 = icmp eq i32 %9679, %9686
  %9688 = or i1 %9685, %9687
  %9689 = load i32, i32* %8, align 4
  %9690 = icmp eq i32 %9679, %9689
  %9691 = or i1 %9688, %9690
  %9692 = load i32, i32* %9, align 4
  %9693 = icmp eq i32 %9679, %9692
  %9694 = or i1 %9691, %9693
  %9695 = load i32, i32* %10, align 4
  %9696 = icmp eq i32 %9679, %9695
  %9697 = or i1 %9694, %9696
  %9698 = load i32, i32* %11, align 4
  %9699 = icmp eq i32 %9679, %9698
  %9700 = or i1 %9697, %9699
  %9701 = load i32, i32* %12, align 4
  %9702 = icmp eq i32 %9679, %9701
  %9703 = or i1 %9700, %9702
  %9704 = load i32, i32* %13, align 4
  %9705 = icmp eq i32 %9679, %9704
  %9706 = or i1 %9703, %9705
  %9707 = load i32, i32* %14, align 4
  %9708 = icmp eq i32 %9679, %9707
  %9709 = or i1 %9706, %9708
  %9710 = load i32, i32* %15, align 4
  %9711 = icmp eq i32 %9679, %9710
  %9712 = or i1 %9709, %9711
  %9713 = load i32, i32* %16, align 4
  %9714 = icmp eq i32 %9679, %9713
  %9715 = or i1 %9712, %9714
  %9716 = load i32, i32* %17, align 4
  %9717 = icmp eq i32 %9679, %9716
  %9718 = or i1 %9715, %9717
  %9719 = load i32, i32* %18, align 4
  %9720 = icmp eq i32 %9679, %9719
  %9721 = or i1 %9718, %9720
  %9722 = load i32, i32* %19, align 4
  %9723 = icmp eq i32 %9679, %9722
  %9724 = or i1 %9721, %9723
  %9725 = load i32, i32* %20, align 4
  %9726 = icmp eq i32 %9679, %9725
  %9727 = or i1 %9724, %9726
  %9728 = load i32, i32* %21, align 4
  %9729 = icmp eq i32 %9679, %9728
  %9730 = or i1 %9727, %9729
  %9731 = load i32, i32* %22, align 4
  %9732 = icmp eq i32 %9679, %9731
  %9733 = or i1 %9730, %9732
  %9734 = load i32, i32* %23, align 4
  %9735 = icmp eq i32 %9679, %9734
  %9736 = or i1 %9733, %9735
  %9737 = load i32, i32* %24, align 4
  %9738 = icmp eq i32 %9679, %9737
  %9739 = or i1 %9736, %9738
  %9740 = load i32, i32* %25, align 4
  %9741 = icmp eq i32 %9679, %9740
  %9742 = or i1 %9739, %9741
  %9743 = load i32, i32* %26, align 4
  %9744 = icmp eq i32 %9679, %9743
  %9745 = or i1 %9742, %9744
  %9746 = load i32, i32* %27, align 4
  %9747 = icmp eq i32 %9679, %9746
  %9748 = or i1 %9745, %9747
  %9749 = load i32, i32* %28, align 4
  %9750 = icmp eq i32 %9679, %9749
  %9751 = or i1 %9748, %9750
  %9752 = load i32, i32* %29, align 4
  %9753 = icmp eq i32 %9679, %9752
  %9754 = or i1 %9751, %9753
  %9755 = load i32, i32* %30, align 4
  %9756 = icmp eq i32 %9679, %9755
  %9757 = or i1 %9754, %9756
  %9758 = load i32, i32* %31, align 4
  %9759 = icmp eq i32 %9679, %9758
  %9760 = or i1 %9757, %9759
  %9761 = load i32, i32* %32, align 4
  %9762 = icmp eq i32 %9679, %9761
  %9763 = or i1 %9760, %9762
  %9764 = load i32, i32* %33, align 4
  %9765 = icmp eq i32 %9679, %9764
  %9766 = or i1 %9763, %9765
  %9767 = load i32, i32* %34, align 4
  %9768 = icmp eq i32 %9679, %9767
  %9769 = or i1 %9766, %9768
  %9770 = load i32, i32* %35, align 4
  %9771 = icmp eq i32 %9679, %9770
  %9772 = or i1 %9769, %9771
  %9773 = load i32, i32* %36, align 4
  %9774 = icmp eq i32 %9679, %9773
  %9775 = or i1 %9772, %9774
  %9776 = load i32, i32* %37, align 4
  %9777 = icmp eq i32 %9679, %9776
  %9778 = or i1 %9775, %9777
  %9779 = load i32, i32* %38, align 4
  %9780 = icmp eq i32 %9679, %9779
  %9781 = or i1 %9778, %9780
  %9782 = load i32, i32* %39, align 4
  %9783 = icmp eq i32 %9679, %9782
  %9784 = or i1 %9781, %9783
  %9785 = load i32, i32* %40, align 4
  %9786 = icmp eq i32 %9679, %9785
  %9787 = or i1 %9784, %9786
  %9788 = load i32, i32* %41, align 4
  %9789 = icmp eq i32 %9679, %9788
  %9790 = or i1 %9787, %9789
  %9791 = load i32, i32* %42, align 4
  %9792 = icmp eq i32 %9679, %9791
  %9793 = or i1 %9790, %9792
  %9794 = load i32, i32* %43, align 4
  %9795 = icmp eq i32 %9679, %9794
  %9796 = or i1 %9793, %9795
  %9797 = load i32, i32* %44, align 4
  %9798 = icmp eq i32 %9679, %9797
  %9799 = or i1 %9796, %9798
  %9800 = load i32, i32* %45, align 4
  %9801 = icmp eq i32 %9679, %9800
  %9802 = or i1 %9799, %9801
  %9803 = load i32, i32* %46, align 4
  %9804 = icmp eq i32 %9679, %9803
  %9805 = or i1 %9802, %9804
  %9806 = load i32, i32* %47, align 4
  %9807 = icmp eq i32 %9679, %9806
  %9808 = or i1 %9805, %9807
  %9809 = load i32, i32* %48, align 4
  %9810 = icmp eq i32 %9679, %9809
  %9811 = or i1 %9808, %9810
  %9812 = load i32, i32* %49, align 4
  %9813 = icmp eq i32 %9679, %9812
  %9814 = or i1 %9811, %9813
  %9815 = load i32, i32* %50, align 4
  %9816 = icmp eq i32 %9679, %9815
  %9817 = or i1 %9814, %9816
  %9818 = load i32, i32* %51, align 4
  %9819 = icmp eq i32 %9679, %9818
  %9820 = or i1 %9817, %9819
  %9821 = load i32, i32* %52, align 4
  %9822 = icmp eq i32 %9679, %9821
  %9823 = or i1 %9820, %9822
  %9824 = load i32, i32* %53, align 4
  %9825 = icmp eq i32 %9679, %9824
  %9826 = or i1 %9823, %9825
  %9827 = load i32, i32* %54, align 4
  %9828 = icmp eq i32 %9679, %9827
  %9829 = or i1 %9826, %9828
  %9830 = load i32, i32* %55, align 4
  %9831 = icmp eq i32 %9679, %9830
  %9832 = or i1 %9829, %9831
  %9833 = load i32, i32* %56, align 4
  %9834 = icmp eq i32 %9679, %9833
  %9835 = or i1 %9832, %9834
  %9836 = load i32, i32* %57, align 4
  %9837 = icmp eq i32 %9679, %9836
  %9838 = or i1 %9835, %9837
  %9839 = load i32, i32* %58, align 4
  %9840 = icmp eq i32 %9679, %9839
  %9841 = or i1 %9838, %9840
  %9842 = load i32, i32* %59, align 4
  %9843 = icmp eq i32 %9679, %9842
  %9844 = or i1 %9841, %9843
  %9845 = load i32, i32* %60, align 4
  %9846 = icmp eq i32 %9679, %9845
  %9847 = or i1 %9844, %9846
  %9848 = load i32, i32* %61, align 4
  %9849 = icmp eq i32 %9679, %9848
  %9850 = or i1 %9847, %9849
  %9851 = load i32, i32* %62, align 4
  %9852 = icmp eq i32 %9679, %9851
  %9853 = or i1 %9850, %9852
  %9854 = getelementptr i8, i8 addrspace(1)* %4, i32 24
  %9855 = zext i1 %9853 to i8
  store i8 %9855, i8 addrspace(1)* %9854, align 1, !nosanitize !3
  %9856 = load i256, i256* %9678, align 4
  %9857 = alloca i256, align 8
  store i256 13, i256* %9857, align 4
  %9858 = alloca i256, align 8
  call void @__device_sload(i256* %9857, i256* %9858)
  %9859 = call i32 @__hashword(i256* %9857)
  %9860 = load i32, i32* %5, align 4
  %9861 = icmp eq i32 %9859, %9860
  %9862 = or i1 false, %9861
  %9863 = load i32, i32* %6, align 4
  %9864 = icmp eq i32 %9859, %9863
  %9865 = or i1 %9862, %9864
  %9866 = load i32, i32* %7, align 4
  %9867 = icmp eq i32 %9859, %9866
  %9868 = or i1 %9865, %9867
  %9869 = load i32, i32* %8, align 4
  %9870 = icmp eq i32 %9859, %9869
  %9871 = or i1 %9868, %9870
  %9872 = load i32, i32* %9, align 4
  %9873 = icmp eq i32 %9859, %9872
  %9874 = or i1 %9871, %9873
  %9875 = load i32, i32* %10, align 4
  %9876 = icmp eq i32 %9859, %9875
  %9877 = or i1 %9874, %9876
  %9878 = load i32, i32* %11, align 4
  %9879 = icmp eq i32 %9859, %9878
  %9880 = or i1 %9877, %9879
  %9881 = load i32, i32* %12, align 4
  %9882 = icmp eq i32 %9859, %9881
  %9883 = or i1 %9880, %9882
  %9884 = load i32, i32* %13, align 4
  %9885 = icmp eq i32 %9859, %9884
  %9886 = or i1 %9883, %9885
  %9887 = load i32, i32* %14, align 4
  %9888 = icmp eq i32 %9859, %9887
  %9889 = or i1 %9886, %9888
  %9890 = load i32, i32* %15, align 4
  %9891 = icmp eq i32 %9859, %9890
  %9892 = or i1 %9889, %9891
  %9893 = load i32, i32* %16, align 4
  %9894 = icmp eq i32 %9859, %9893
  %9895 = or i1 %9892, %9894
  %9896 = load i32, i32* %17, align 4
  %9897 = icmp eq i32 %9859, %9896
  %9898 = or i1 %9895, %9897
  %9899 = load i32, i32* %18, align 4
  %9900 = icmp eq i32 %9859, %9899
  %9901 = or i1 %9898, %9900
  %9902 = load i32, i32* %19, align 4
  %9903 = icmp eq i32 %9859, %9902
  %9904 = or i1 %9901, %9903
  %9905 = load i32, i32* %20, align 4
  %9906 = icmp eq i32 %9859, %9905
  %9907 = or i1 %9904, %9906
  %9908 = load i32, i32* %21, align 4
  %9909 = icmp eq i32 %9859, %9908
  %9910 = or i1 %9907, %9909
  %9911 = load i32, i32* %22, align 4
  %9912 = icmp eq i32 %9859, %9911
  %9913 = or i1 %9910, %9912
  %9914 = load i32, i32* %23, align 4
  %9915 = icmp eq i32 %9859, %9914
  %9916 = or i1 %9913, %9915
  %9917 = load i32, i32* %24, align 4
  %9918 = icmp eq i32 %9859, %9917
  %9919 = or i1 %9916, %9918
  %9920 = load i32, i32* %25, align 4
  %9921 = icmp eq i32 %9859, %9920
  %9922 = or i1 %9919, %9921
  %9923 = load i32, i32* %26, align 4
  %9924 = icmp eq i32 %9859, %9923
  %9925 = or i1 %9922, %9924
  %9926 = load i32, i32* %27, align 4
  %9927 = icmp eq i32 %9859, %9926
  %9928 = or i1 %9925, %9927
  %9929 = load i32, i32* %28, align 4
  %9930 = icmp eq i32 %9859, %9929
  %9931 = or i1 %9928, %9930
  %9932 = load i32, i32* %29, align 4
  %9933 = icmp eq i32 %9859, %9932
  %9934 = or i1 %9931, %9933
  %9935 = load i32, i32* %30, align 4
  %9936 = icmp eq i32 %9859, %9935
  %9937 = or i1 %9934, %9936
  %9938 = load i32, i32* %31, align 4
  %9939 = icmp eq i32 %9859, %9938
  %9940 = or i1 %9937, %9939
  %9941 = load i32, i32* %32, align 4
  %9942 = icmp eq i32 %9859, %9941
  %9943 = or i1 %9940, %9942
  %9944 = load i32, i32* %33, align 4
  %9945 = icmp eq i32 %9859, %9944
  %9946 = or i1 %9943, %9945
  %9947 = load i32, i32* %34, align 4
  %9948 = icmp eq i32 %9859, %9947
  %9949 = or i1 %9946, %9948
  %9950 = load i32, i32* %35, align 4
  %9951 = icmp eq i32 %9859, %9950
  %9952 = or i1 %9949, %9951
  %9953 = load i32, i32* %36, align 4
  %9954 = icmp eq i32 %9859, %9953
  %9955 = or i1 %9952, %9954
  %9956 = load i32, i32* %37, align 4
  %9957 = icmp eq i32 %9859, %9956
  %9958 = or i1 %9955, %9957
  %9959 = load i32, i32* %38, align 4
  %9960 = icmp eq i32 %9859, %9959
  %9961 = or i1 %9958, %9960
  %9962 = load i32, i32* %39, align 4
  %9963 = icmp eq i32 %9859, %9962
  %9964 = or i1 %9961, %9963
  %9965 = load i32, i32* %40, align 4
  %9966 = icmp eq i32 %9859, %9965
  %9967 = or i1 %9964, %9966
  %9968 = load i32, i32* %41, align 4
  %9969 = icmp eq i32 %9859, %9968
  %9970 = or i1 %9967, %9969
  %9971 = load i32, i32* %42, align 4
  %9972 = icmp eq i32 %9859, %9971
  %9973 = or i1 %9970, %9972
  %9974 = load i32, i32* %43, align 4
  %9975 = icmp eq i32 %9859, %9974
  %9976 = or i1 %9973, %9975
  %9977 = load i32, i32* %44, align 4
  %9978 = icmp eq i32 %9859, %9977
  %9979 = or i1 %9976, %9978
  %9980 = load i32, i32* %45, align 4
  %9981 = icmp eq i32 %9859, %9980
  %9982 = or i1 %9979, %9981
  %9983 = load i32, i32* %46, align 4
  %9984 = icmp eq i32 %9859, %9983
  %9985 = or i1 %9982, %9984
  %9986 = load i32, i32* %47, align 4
  %9987 = icmp eq i32 %9859, %9986
  %9988 = or i1 %9985, %9987
  %9989 = load i32, i32* %48, align 4
  %9990 = icmp eq i32 %9859, %9989
  %9991 = or i1 %9988, %9990
  %9992 = load i32, i32* %49, align 4
  %9993 = icmp eq i32 %9859, %9992
  %9994 = or i1 %9991, %9993
  %9995 = load i32, i32* %50, align 4
  %9996 = icmp eq i32 %9859, %9995
  %9997 = or i1 %9994, %9996
  %9998 = load i32, i32* %51, align 4
  %9999 = icmp eq i32 %9859, %9998
  %10000 = or i1 %9997, %9999
  %10001 = load i32, i32* %52, align 4
  %10002 = icmp eq i32 %9859, %10001
  %10003 = or i1 %10000, %10002
  %10004 = load i32, i32* %53, align 4
  %10005 = icmp eq i32 %9859, %10004
  %10006 = or i1 %10003, %10005
  %10007 = load i32, i32* %54, align 4
  %10008 = icmp eq i32 %9859, %10007
  %10009 = or i1 %10006, %10008
  %10010 = load i32, i32* %55, align 4
  %10011 = icmp eq i32 %9859, %10010
  %10012 = or i1 %10009, %10011
  %10013 = load i32, i32* %56, align 4
  %10014 = icmp eq i32 %9859, %10013
  %10015 = or i1 %10012, %10014
  %10016 = load i32, i32* %57, align 4
  %10017 = icmp eq i32 %9859, %10016
  %10018 = or i1 %10015, %10017
  %10019 = load i32, i32* %58, align 4
  %10020 = icmp eq i32 %9859, %10019
  %10021 = or i1 %10018, %10020
  %10022 = load i32, i32* %59, align 4
  %10023 = icmp eq i32 %9859, %10022
  %10024 = or i1 %10021, %10023
  %10025 = load i32, i32* %60, align 4
  %10026 = icmp eq i32 %9859, %10025
  %10027 = or i1 %10024, %10026
  %10028 = load i32, i32* %61, align 4
  %10029 = icmp eq i32 %9859, %10028
  %10030 = or i1 %10027, %10029
  %10031 = load i32, i32* %62, align 4
  %10032 = icmp eq i32 %9859, %10031
  %10033 = or i1 %10030, %10032
  %10034 = getelementptr i8, i8 addrspace(1)* %4, i32 25
  %10035 = zext i1 %10033 to i8
  store i8 %10035, i8 addrspace(1)* %10034, align 1, !nosanitize !3
  %10036 = load i256, i256* %9858, align 4
  %10037 = and i256 1461501637330902918203684832716283019655932542975, %9674
  %10038 = and i256 1461501637330902918203684832716283019655932542975, %10037
  %10039 = trunc i256 0 to i64
  %10040 = alloca i256, align 8
  store i256 %10038, i256* %10040, align 4
  %10041 = bitcast i256* %10040 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %10039, i8* %10041, i64 32)
  %10042 = add i256 32, 0, !pc !222, !intsan !10
  %10043 = trunc i256 %10042 to i64
  %10044 = alloca i256, align 8
  store i256 3, i256* %10044, align 4
  %10045 = bitcast i256* %10044 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %10043, i8* %10045, i64 32)
  %10046 = add i256 32, %10042, !pc !223, !intsan !10
  %10047 = trunc i256 0 to i32
  %10048 = trunc i256 %10046 to i32
  %10049 = getelementptr inbounds i8, i8* %MEMORY, i32 %10047
  %10050 = alloca i256, align 8
  %10051 = bitcast i256* %10050 to i8*
  call void @__device_sha3(i8* %10049, i32 %10048, i8* %10051)
  %10052 = load i256, i256* %10050, align 4
  %10053 = alloca i256, align 8
  store i256 %10052, i256* %10053, align 4
  %10054 = alloca i256, align 8
  call void @__device_sload(i256* %10053, i256* %10054)
  %10055 = call i32 @__hashword(i256* %10053)
  %10056 = load i32, i32* %5, align 4
  %10057 = icmp eq i32 %10055, %10056
  %10058 = or i1 false, %10057
  %10059 = load i32, i32* %6, align 4
  %10060 = icmp eq i32 %10055, %10059
  %10061 = or i1 %10058, %10060
  %10062 = load i32, i32* %7, align 4
  %10063 = icmp eq i32 %10055, %10062
  %10064 = or i1 %10061, %10063
  %10065 = load i32, i32* %8, align 4
  %10066 = icmp eq i32 %10055, %10065
  %10067 = or i1 %10064, %10066
  %10068 = load i32, i32* %9, align 4
  %10069 = icmp eq i32 %10055, %10068
  %10070 = or i1 %10067, %10069
  %10071 = load i32, i32* %10, align 4
  %10072 = icmp eq i32 %10055, %10071
  %10073 = or i1 %10070, %10072
  %10074 = load i32, i32* %11, align 4
  %10075 = icmp eq i32 %10055, %10074
  %10076 = or i1 %10073, %10075
  %10077 = load i32, i32* %12, align 4
  %10078 = icmp eq i32 %10055, %10077
  %10079 = or i1 %10076, %10078
  %10080 = load i32, i32* %13, align 4
  %10081 = icmp eq i32 %10055, %10080
  %10082 = or i1 %10079, %10081
  %10083 = load i32, i32* %14, align 4
  %10084 = icmp eq i32 %10055, %10083
  %10085 = or i1 %10082, %10084
  %10086 = load i32, i32* %15, align 4
  %10087 = icmp eq i32 %10055, %10086
  %10088 = or i1 %10085, %10087
  %10089 = load i32, i32* %16, align 4
  %10090 = icmp eq i32 %10055, %10089
  %10091 = or i1 %10088, %10090
  %10092 = load i32, i32* %17, align 4
  %10093 = icmp eq i32 %10055, %10092
  %10094 = or i1 %10091, %10093
  %10095 = load i32, i32* %18, align 4
  %10096 = icmp eq i32 %10055, %10095
  %10097 = or i1 %10094, %10096
  %10098 = load i32, i32* %19, align 4
  %10099 = icmp eq i32 %10055, %10098
  %10100 = or i1 %10097, %10099
  %10101 = load i32, i32* %20, align 4
  %10102 = icmp eq i32 %10055, %10101
  %10103 = or i1 %10100, %10102
  %10104 = load i32, i32* %21, align 4
  %10105 = icmp eq i32 %10055, %10104
  %10106 = or i1 %10103, %10105
  %10107 = load i32, i32* %22, align 4
  %10108 = icmp eq i32 %10055, %10107
  %10109 = or i1 %10106, %10108
  %10110 = load i32, i32* %23, align 4
  %10111 = icmp eq i32 %10055, %10110
  %10112 = or i1 %10109, %10111
  %10113 = load i32, i32* %24, align 4
  %10114 = icmp eq i32 %10055, %10113
  %10115 = or i1 %10112, %10114
  %10116 = load i32, i32* %25, align 4
  %10117 = icmp eq i32 %10055, %10116
  %10118 = or i1 %10115, %10117
  %10119 = load i32, i32* %26, align 4
  %10120 = icmp eq i32 %10055, %10119
  %10121 = or i1 %10118, %10120
  %10122 = load i32, i32* %27, align 4
  %10123 = icmp eq i32 %10055, %10122
  %10124 = or i1 %10121, %10123
  %10125 = load i32, i32* %28, align 4
  %10126 = icmp eq i32 %10055, %10125
  %10127 = or i1 %10124, %10126
  %10128 = load i32, i32* %29, align 4
  %10129 = icmp eq i32 %10055, %10128
  %10130 = or i1 %10127, %10129
  %10131 = load i32, i32* %30, align 4
  %10132 = icmp eq i32 %10055, %10131
  %10133 = or i1 %10130, %10132
  %10134 = load i32, i32* %31, align 4
  %10135 = icmp eq i32 %10055, %10134
  %10136 = or i1 %10133, %10135
  %10137 = load i32, i32* %32, align 4
  %10138 = icmp eq i32 %10055, %10137
  %10139 = or i1 %10136, %10138
  %10140 = load i32, i32* %33, align 4
  %10141 = icmp eq i32 %10055, %10140
  %10142 = or i1 %10139, %10141
  %10143 = load i32, i32* %34, align 4
  %10144 = icmp eq i32 %10055, %10143
  %10145 = or i1 %10142, %10144
  %10146 = load i32, i32* %35, align 4
  %10147 = icmp eq i32 %10055, %10146
  %10148 = or i1 %10145, %10147
  %10149 = load i32, i32* %36, align 4
  %10150 = icmp eq i32 %10055, %10149
  %10151 = or i1 %10148, %10150
  %10152 = load i32, i32* %37, align 4
  %10153 = icmp eq i32 %10055, %10152
  %10154 = or i1 %10151, %10153
  %10155 = load i32, i32* %38, align 4
  %10156 = icmp eq i32 %10055, %10155
  %10157 = or i1 %10154, %10156
  %10158 = load i32, i32* %39, align 4
  %10159 = icmp eq i32 %10055, %10158
  %10160 = or i1 %10157, %10159
  %10161 = load i32, i32* %40, align 4
  %10162 = icmp eq i32 %10055, %10161
  %10163 = or i1 %10160, %10162
  %10164 = load i32, i32* %41, align 4
  %10165 = icmp eq i32 %10055, %10164
  %10166 = or i1 %10163, %10165
  %10167 = load i32, i32* %42, align 4
  %10168 = icmp eq i32 %10055, %10167
  %10169 = or i1 %10166, %10168
  %10170 = load i32, i32* %43, align 4
  %10171 = icmp eq i32 %10055, %10170
  %10172 = or i1 %10169, %10171
  %10173 = load i32, i32* %44, align 4
  %10174 = icmp eq i32 %10055, %10173
  %10175 = or i1 %10172, %10174
  %10176 = load i32, i32* %45, align 4
  %10177 = icmp eq i32 %10055, %10176
  %10178 = or i1 %10175, %10177
  %10179 = load i32, i32* %46, align 4
  %10180 = icmp eq i32 %10055, %10179
  %10181 = or i1 %10178, %10180
  %10182 = load i32, i32* %47, align 4
  %10183 = icmp eq i32 %10055, %10182
  %10184 = or i1 %10181, %10183
  %10185 = load i32, i32* %48, align 4
  %10186 = icmp eq i32 %10055, %10185
  %10187 = or i1 %10184, %10186
  %10188 = load i32, i32* %49, align 4
  %10189 = icmp eq i32 %10055, %10188
  %10190 = or i1 %10187, %10189
  %10191 = load i32, i32* %50, align 4
  %10192 = icmp eq i32 %10055, %10191
  %10193 = or i1 %10190, %10192
  %10194 = load i32, i32* %51, align 4
  %10195 = icmp eq i32 %10055, %10194
  %10196 = or i1 %10193, %10195
  %10197 = load i32, i32* %52, align 4
  %10198 = icmp eq i32 %10055, %10197
  %10199 = or i1 %10196, %10198
  %10200 = load i32, i32* %53, align 4
  %10201 = icmp eq i32 %10055, %10200
  %10202 = or i1 %10199, %10201
  %10203 = load i32, i32* %54, align 4
  %10204 = icmp eq i32 %10055, %10203
  %10205 = or i1 %10202, %10204
  %10206 = load i32, i32* %55, align 4
  %10207 = icmp eq i32 %10055, %10206
  %10208 = or i1 %10205, %10207
  %10209 = load i32, i32* %56, align 4
  %10210 = icmp eq i32 %10055, %10209
  %10211 = or i1 %10208, %10210
  %10212 = load i32, i32* %57, align 4
  %10213 = icmp eq i32 %10055, %10212
  %10214 = or i1 %10211, %10213
  %10215 = load i32, i32* %58, align 4
  %10216 = icmp eq i32 %10055, %10215
  %10217 = or i1 %10214, %10216
  %10218 = load i32, i32* %59, align 4
  %10219 = icmp eq i32 %10055, %10218
  %10220 = or i1 %10217, %10219
  %10221 = load i32, i32* %60, align 4
  %10222 = icmp eq i32 %10055, %10221
  %10223 = or i1 %10220, %10222
  %10224 = load i32, i32* %61, align 4
  %10225 = icmp eq i32 %10055, %10224
  %10226 = or i1 %10223, %10225
  %10227 = load i32, i32* %62, align 4
  %10228 = icmp eq i32 %10055, %10227
  %10229 = or i1 %10226, %10228
  %10230 = getelementptr i8, i8 addrspace(1)* %4, i32 26
  %10231 = zext i1 %10229 to i8
  store i8 %10231, i8 addrspace(1)* %10230, align 1, !nosanitize !3
  %10232 = load i256, i256* %10054, align 4
  %10233 = trunc i256 0 to i64
  %10234 = alloca i256, align 8
  store i256 %10232, i256* %10234, align 4
  %10235 = bitcast i256* %10234 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %10233, i8* %10235, i64 32)
  %10236 = add i256 32, 0, !pc !224, !intsan !10
  %10237 = trunc i256 %10236 to i64
  %10238 = alloca i256, align 8
  store i256 4, i256* %10238, align 4
  %10239 = bitcast i256* %10238 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %10237, i8* %10239, i64 32)
  %10240 = add i256 32, %10236, !pc !225, !intsan !10
  %10241 = trunc i256 0 to i32
  %10242 = trunc i256 %10240 to i32
  %10243 = getelementptr inbounds i8, i8* %MEMORY, i32 %10241
  %10244 = alloca i256, align 8
  %10245 = bitcast i256* %10244 to i8*
  call void @__device_sha3(i8* %10243, i32 %10242, i8* %10245)
  %10246 = load i256, i256* %10244, align 4
  %10247 = add i256 1, %10246, !pc !226, !intsan !10
  %10248 = alloca i256, align 8
  store i256 %10247, i256* %10248, align 4
  %10249 = alloca i256, align 8
  call void @__device_sload(i256* %10248, i256* %10249)
  %10250 = call i32 @__hashword(i256* %10248)
  %10251 = load i32, i32* %5, align 4
  %10252 = icmp eq i32 %10250, %10251
  %10253 = or i1 false, %10252
  %10254 = load i32, i32* %6, align 4
  %10255 = icmp eq i32 %10250, %10254
  %10256 = or i1 %10253, %10255
  %10257 = load i32, i32* %7, align 4
  %10258 = icmp eq i32 %10250, %10257
  %10259 = or i1 %10256, %10258
  %10260 = load i32, i32* %8, align 4
  %10261 = icmp eq i32 %10250, %10260
  %10262 = or i1 %10259, %10261
  %10263 = load i32, i32* %9, align 4
  %10264 = icmp eq i32 %10250, %10263
  %10265 = or i1 %10262, %10264
  %10266 = load i32, i32* %10, align 4
  %10267 = icmp eq i32 %10250, %10266
  %10268 = or i1 %10265, %10267
  %10269 = load i32, i32* %11, align 4
  %10270 = icmp eq i32 %10250, %10269
  %10271 = or i1 %10268, %10270
  %10272 = load i32, i32* %12, align 4
  %10273 = icmp eq i32 %10250, %10272
  %10274 = or i1 %10271, %10273
  %10275 = load i32, i32* %13, align 4
  %10276 = icmp eq i32 %10250, %10275
  %10277 = or i1 %10274, %10276
  %10278 = load i32, i32* %14, align 4
  %10279 = icmp eq i32 %10250, %10278
  %10280 = or i1 %10277, %10279
  %10281 = load i32, i32* %15, align 4
  %10282 = icmp eq i32 %10250, %10281
  %10283 = or i1 %10280, %10282
  %10284 = load i32, i32* %16, align 4
  %10285 = icmp eq i32 %10250, %10284
  %10286 = or i1 %10283, %10285
  %10287 = load i32, i32* %17, align 4
  %10288 = icmp eq i32 %10250, %10287
  %10289 = or i1 %10286, %10288
  %10290 = load i32, i32* %18, align 4
  %10291 = icmp eq i32 %10250, %10290
  %10292 = or i1 %10289, %10291
  %10293 = load i32, i32* %19, align 4
  %10294 = icmp eq i32 %10250, %10293
  %10295 = or i1 %10292, %10294
  %10296 = load i32, i32* %20, align 4
  %10297 = icmp eq i32 %10250, %10296
  %10298 = or i1 %10295, %10297
  %10299 = load i32, i32* %21, align 4
  %10300 = icmp eq i32 %10250, %10299
  %10301 = or i1 %10298, %10300
  %10302 = load i32, i32* %22, align 4
  %10303 = icmp eq i32 %10250, %10302
  %10304 = or i1 %10301, %10303
  %10305 = load i32, i32* %23, align 4
  %10306 = icmp eq i32 %10250, %10305
  %10307 = or i1 %10304, %10306
  %10308 = load i32, i32* %24, align 4
  %10309 = icmp eq i32 %10250, %10308
  %10310 = or i1 %10307, %10309
  %10311 = load i32, i32* %25, align 4
  %10312 = icmp eq i32 %10250, %10311
  %10313 = or i1 %10310, %10312
  %10314 = load i32, i32* %26, align 4
  %10315 = icmp eq i32 %10250, %10314
  %10316 = or i1 %10313, %10315
  %10317 = load i32, i32* %27, align 4
  %10318 = icmp eq i32 %10250, %10317
  %10319 = or i1 %10316, %10318
  %10320 = load i32, i32* %28, align 4
  %10321 = icmp eq i32 %10250, %10320
  %10322 = or i1 %10319, %10321
  %10323 = load i32, i32* %29, align 4
  %10324 = icmp eq i32 %10250, %10323
  %10325 = or i1 %10322, %10324
  %10326 = load i32, i32* %30, align 4
  %10327 = icmp eq i32 %10250, %10326
  %10328 = or i1 %10325, %10327
  %10329 = load i32, i32* %31, align 4
  %10330 = icmp eq i32 %10250, %10329
  %10331 = or i1 %10328, %10330
  %10332 = load i32, i32* %32, align 4
  %10333 = icmp eq i32 %10250, %10332
  %10334 = or i1 %10331, %10333
  %10335 = load i32, i32* %33, align 4
  %10336 = icmp eq i32 %10250, %10335
  %10337 = or i1 %10334, %10336
  %10338 = load i32, i32* %34, align 4
  %10339 = icmp eq i32 %10250, %10338
  %10340 = or i1 %10337, %10339
  %10341 = load i32, i32* %35, align 4
  %10342 = icmp eq i32 %10250, %10341
  %10343 = or i1 %10340, %10342
  %10344 = load i32, i32* %36, align 4
  %10345 = icmp eq i32 %10250, %10344
  %10346 = or i1 %10343, %10345
  %10347 = load i32, i32* %37, align 4
  %10348 = icmp eq i32 %10250, %10347
  %10349 = or i1 %10346, %10348
  %10350 = load i32, i32* %38, align 4
  %10351 = icmp eq i32 %10250, %10350
  %10352 = or i1 %10349, %10351
  %10353 = load i32, i32* %39, align 4
  %10354 = icmp eq i32 %10250, %10353
  %10355 = or i1 %10352, %10354
  %10356 = load i32, i32* %40, align 4
  %10357 = icmp eq i32 %10250, %10356
  %10358 = or i1 %10355, %10357
  %10359 = load i32, i32* %41, align 4
  %10360 = icmp eq i32 %10250, %10359
  %10361 = or i1 %10358, %10360
  %10362 = load i32, i32* %42, align 4
  %10363 = icmp eq i32 %10250, %10362
  %10364 = or i1 %10361, %10363
  %10365 = load i32, i32* %43, align 4
  %10366 = icmp eq i32 %10250, %10365
  %10367 = or i1 %10364, %10366
  %10368 = load i32, i32* %44, align 4
  %10369 = icmp eq i32 %10250, %10368
  %10370 = or i1 %10367, %10369
  %10371 = load i32, i32* %45, align 4
  %10372 = icmp eq i32 %10250, %10371
  %10373 = or i1 %10370, %10372
  %10374 = load i32, i32* %46, align 4
  %10375 = icmp eq i32 %10250, %10374
  %10376 = or i1 %10373, %10375
  %10377 = load i32, i32* %47, align 4
  %10378 = icmp eq i32 %10250, %10377
  %10379 = or i1 %10376, %10378
  %10380 = load i32, i32* %48, align 4
  %10381 = icmp eq i32 %10250, %10380
  %10382 = or i1 %10379, %10381
  %10383 = load i32, i32* %49, align 4
  %10384 = icmp eq i32 %10250, %10383
  %10385 = or i1 %10382, %10384
  %10386 = load i32, i32* %50, align 4
  %10387 = icmp eq i32 %10250, %10386
  %10388 = or i1 %10385, %10387
  %10389 = load i32, i32* %51, align 4
  %10390 = icmp eq i32 %10250, %10389
  %10391 = or i1 %10388, %10390
  %10392 = load i32, i32* %52, align 4
  %10393 = icmp eq i32 %10250, %10392
  %10394 = or i1 %10391, %10393
  %10395 = load i32, i32* %53, align 4
  %10396 = icmp eq i32 %10250, %10395
  %10397 = or i1 %10394, %10396
  %10398 = load i32, i32* %54, align 4
  %10399 = icmp eq i32 %10250, %10398
  %10400 = or i1 %10397, %10399
  %10401 = load i32, i32* %55, align 4
  %10402 = icmp eq i32 %10250, %10401
  %10403 = or i1 %10400, %10402
  %10404 = load i32, i32* %56, align 4
  %10405 = icmp eq i32 %10250, %10404
  %10406 = or i1 %10403, %10405
  %10407 = load i32, i32* %57, align 4
  %10408 = icmp eq i32 %10250, %10407
  %10409 = or i1 %10406, %10408
  %10410 = load i32, i32* %58, align 4
  %10411 = icmp eq i32 %10250, %10410
  %10412 = or i1 %10409, %10411
  %10413 = load i32, i32* %59, align 4
  %10414 = icmp eq i32 %10250, %10413
  %10415 = or i1 %10412, %10414
  %10416 = load i32, i32* %60, align 4
  %10417 = icmp eq i32 %10250, %10416
  %10418 = or i1 %10415, %10417
  %10419 = load i32, i32* %61, align 4
  %10420 = icmp eq i32 %10250, %10419
  %10421 = or i1 %10418, %10420
  %10422 = load i32, i32* %62, align 4
  %10423 = icmp eq i32 %10250, %10422
  %10424 = or i1 %10421, %10423
  %10425 = getelementptr i8, i8 addrspace(1)* %4, i32 27
  %10426 = zext i1 %10424 to i8
  store i8 %10426, i8 addrspace(1)* %10425, align 1, !nosanitize !3
  %10427 = load i256, i256* %10249, align 4
  %10428 = mul i256 %10427, %10036, !pc !227, !intsan !45
  %10429 = icmp eq i256 %9856, 0
  %10430 = icmp eq i1 %10429, false
  %10431 = trunc i256 4547 to i64
  %jump.check27 = icmp ne i1 %10430, false
  %10432 = load i64, i64* %STACK_DEP_PTR, align 4
  %10433 = add i64 %10432, 1
  store i64 %10433, i64* %STACK_DEP_PTR, align 4
  %10434 = load i64, i64* %STACK_DEP_PTR, align 4
  %10435 = getelementptr i256, i256* %STACK, i64 %10434
  store i256 %9674, i256* %10435, align 4
  %10436 = load i64, i64* %STACK_DEP_PTR, align 4
  %10437 = add i64 %10436, 1
  store i64 %10437, i64* %STACK_DEP_PTR, align 4
  %10438 = load i64, i64* %STACK_DEP_PTR, align 4
  %10439 = getelementptr i256, i256* %STACK, i64 %10438
  store i256 0, i256* %10439, align 4
  %10440 = load i64, i64* %STACK_DEP_PTR, align 4
  %10441 = add i64 %10440, 1
  store i64 %10441, i64* %STACK_DEP_PTR, align 4
  %10442 = load i64, i64* %STACK_DEP_PTR, align 4
  %10443 = getelementptr i256, i256* %STACK, i64 %10442
  store i256 %9856, i256* %10443, align 4
  %10444 = load i64, i64* %STACK_DEP_PTR, align 4
  %10445 = add i64 %10444, 1
  store i64 %10445, i64* %STACK_DEP_PTR, align 4
  %10446 = load i64, i64* %STACK_DEP_PTR, align 4
  %10447 = getelementptr i256, i256* %STACK, i64 %10446
  store i256 %10428, i256* %10447, align 4
  br i1 %jump.check27, label %.4547, label %.4546, !EVMBB !4

.4546:                                            ; preds = %9665
  %10448 = load i64, i64* %remaing_gas, align 4
  %10449 = icmp ugt i64 16, %10448
  br i1 %10449, label %Abort, label %10450

10450:                                            ; preds = %.4546
  %10451 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10452 = xor i32 %10451, 3298
  %10453 = urem i32 %10452, 4096
  %10454 = getelementptr i8, i8 addrspace(1)* %4, i32 %10453
  %10455 = load i8, i8 addrspace(1)* %10454, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10454, align 1, !nosanitize !3
  store i32 1649, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10456 = sub i64 %10448, 16
  store i64 %10456, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4547:                                            ; preds = %9665, %JumpTable
  %10457 = load i64, i64* %remaing_gas, align 4
  %10458 = icmp ugt i64 376, %10457
  br i1 %10458, label %Abort, label %10459

10459:                                            ; preds = %.4547
  %10460 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10461 = xor i32 %10460, 3312
  %10462 = urem i32 %10461, 4096
  %10463 = getelementptr i8, i8 addrspace(1)* %4, i32 %10462
  %10464 = load i8, i8 addrspace(1)* %10463, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10463, align 1, !nosanitize !3
  store i32 1656, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10465 = sub i64 %10457, 376
  store i64 %10465, i64* %remaing_gas, align 4
  %10466 = load i64, i64* %STACK_DEP_PTR, align 4
  %10467 = getelementptr i256, i256* %STACK, i64 %10466
  %10468 = load i256, i256* %10467, align 4
  %10469 = load i64, i64* %STACK_DEP_PTR, align 4
  %10470 = sub i64 %10469, 1
  store i64 %10470, i64* %STACK_DEP_PTR, align 4
  %10471 = load i64, i64* %STACK_DEP_PTR, align 4
  %10472 = getelementptr i256, i256* %STACK, i64 %10471
  %10473 = load i256, i256* %10472, align 4
  %10474 = load i64, i64* %STACK_DEP_PTR, align 4
  %10475 = sub i64 %10474, 1
  store i64 %10475, i64* %STACK_DEP_PTR, align 4
  %10476 = load i64, i64* %STACK_DEP_PTR, align 4
  %10477 = getelementptr i256, i256* %STACK, i64 %10476
  %10478 = load i256, i256* %10477, align 4
  %10479 = load i64, i64* %STACK_DEP_PTR, align 4
  %10480 = sub i64 %10479, 1
  store i64 %10480, i64* %STACK_DEP_PTR, align 4
  %10481 = load i64, i64* %STACK_DEP_PTR, align 4
  %10482 = getelementptr i256, i256* %STACK, i64 %10481
  %10483 = load i256, i256* %10482, align 4
  %10484 = load i64, i64* %STACK_DEP_PTR, align 4
  %10485 = sub i64 %10484, 1
  store i64 %10485, i64* %STACK_DEP_PTR, align 4
  %10486 = load i64, i64* %STACK_DEP_PTR, align 4
  %10487 = getelementptr i256, i256* %STACK, i64 %10486
  %10488 = load i256, i256* %10487, align 4
  %10489 = load i64, i64* %STACK_DEP_PTR, align 4
  %10490 = sub i64 %10489, 1
  store i64 %10490, i64* %STACK_DEP_PTR, align 4
  %10491 = alloca i256, align 8
  store i256 %10468, i256* %10491, align 4
  %10492 = alloca i256, align 8
  store i256 %10473, i256* %10492, align 4
  %10493 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %10491, i256* %10492, i256* %10493), !pc !228, !intsan !6
  %10494 = load i256, i256* %10493, align 4
  %10495 = trunc i256 %10488 to i64
  store i64 %10495, i64* %JMP_TARGET_PTR, align 4
  %10496 = load i64, i64* %STACK_DEP_PTR, align 4
  %10497 = add i64 %10496, 1
  store i64 %10497, i64* %STACK_DEP_PTR, align 4
  %10498 = load i64, i64* %STACK_DEP_PTR, align 4
  %10499 = getelementptr i256, i256* %STACK, i64 %10498
  store i256 %10494, i256* %10499, align 4
  br label %JumpTable, !EVMBB !4

.4555:                                            ; preds = %1171, %JumpTable
  %10500 = load i64, i64* %remaing_gas, align 4
  %10501 = icmp ugt i64 184, %10500
  br i1 %10501, label %Abort, label %10502

10502:                                            ; preds = %.4555
  %10503 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10504 = xor i32 %10503, 996
  %10505 = urem i32 %10504, 4096
  %10506 = getelementptr i8, i8 addrspace(1)* %4, i32 %10505
  %10507 = load i8, i8 addrspace(1)* %10506, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10506, align 1, !nosanitize !3
  store i32 498, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10508 = sub i64 %10500, 184
  store i64 %10508, i64* %remaing_gas, align 4
  %10509 = load i256, i256* %0, align 4
  %10510 = and i256 1461501637330902918203684832716283019655932542975, %10509
  %10511 = alloca i256, align 8
  store i256 7, i256* %10511, align 4
  %10512 = alloca i256, align 8
  call void @__device_sload(i256* %10511, i256* %10512)
  %10513 = call i32 @__hashword(i256* %10511)
  %10514 = load i32, i32* %5, align 4
  %10515 = icmp eq i32 %10513, %10514
  %10516 = or i1 false, %10515
  %10517 = load i32, i32* %6, align 4
  %10518 = icmp eq i32 %10513, %10517
  %10519 = or i1 %10516, %10518
  %10520 = load i32, i32* %7, align 4
  %10521 = icmp eq i32 %10513, %10520
  %10522 = or i1 %10519, %10521
  %10523 = load i32, i32* %8, align 4
  %10524 = icmp eq i32 %10513, %10523
  %10525 = or i1 %10522, %10524
  %10526 = load i32, i32* %9, align 4
  %10527 = icmp eq i32 %10513, %10526
  %10528 = or i1 %10525, %10527
  %10529 = load i32, i32* %10, align 4
  %10530 = icmp eq i32 %10513, %10529
  %10531 = or i1 %10528, %10530
  %10532 = load i32, i32* %11, align 4
  %10533 = icmp eq i32 %10513, %10532
  %10534 = or i1 %10531, %10533
  %10535 = load i32, i32* %12, align 4
  %10536 = icmp eq i32 %10513, %10535
  %10537 = or i1 %10534, %10536
  %10538 = load i32, i32* %13, align 4
  %10539 = icmp eq i32 %10513, %10538
  %10540 = or i1 %10537, %10539
  %10541 = load i32, i32* %14, align 4
  %10542 = icmp eq i32 %10513, %10541
  %10543 = or i1 %10540, %10542
  %10544 = load i32, i32* %15, align 4
  %10545 = icmp eq i32 %10513, %10544
  %10546 = or i1 %10543, %10545
  %10547 = load i32, i32* %16, align 4
  %10548 = icmp eq i32 %10513, %10547
  %10549 = or i1 %10546, %10548
  %10550 = load i32, i32* %17, align 4
  %10551 = icmp eq i32 %10513, %10550
  %10552 = or i1 %10549, %10551
  %10553 = load i32, i32* %18, align 4
  %10554 = icmp eq i32 %10513, %10553
  %10555 = or i1 %10552, %10554
  %10556 = load i32, i32* %19, align 4
  %10557 = icmp eq i32 %10513, %10556
  %10558 = or i1 %10555, %10557
  %10559 = load i32, i32* %20, align 4
  %10560 = icmp eq i32 %10513, %10559
  %10561 = or i1 %10558, %10560
  %10562 = load i32, i32* %21, align 4
  %10563 = icmp eq i32 %10513, %10562
  %10564 = or i1 %10561, %10563
  %10565 = load i32, i32* %22, align 4
  %10566 = icmp eq i32 %10513, %10565
  %10567 = or i1 %10564, %10566
  %10568 = load i32, i32* %23, align 4
  %10569 = icmp eq i32 %10513, %10568
  %10570 = or i1 %10567, %10569
  %10571 = load i32, i32* %24, align 4
  %10572 = icmp eq i32 %10513, %10571
  %10573 = or i1 %10570, %10572
  %10574 = load i32, i32* %25, align 4
  %10575 = icmp eq i32 %10513, %10574
  %10576 = or i1 %10573, %10575
  %10577 = load i32, i32* %26, align 4
  %10578 = icmp eq i32 %10513, %10577
  %10579 = or i1 %10576, %10578
  %10580 = load i32, i32* %27, align 4
  %10581 = icmp eq i32 %10513, %10580
  %10582 = or i1 %10579, %10581
  %10583 = load i32, i32* %28, align 4
  %10584 = icmp eq i32 %10513, %10583
  %10585 = or i1 %10582, %10584
  %10586 = load i32, i32* %29, align 4
  %10587 = icmp eq i32 %10513, %10586
  %10588 = or i1 %10585, %10587
  %10589 = load i32, i32* %30, align 4
  %10590 = icmp eq i32 %10513, %10589
  %10591 = or i1 %10588, %10590
  %10592 = load i32, i32* %31, align 4
  %10593 = icmp eq i32 %10513, %10592
  %10594 = or i1 %10591, %10593
  %10595 = load i32, i32* %32, align 4
  %10596 = icmp eq i32 %10513, %10595
  %10597 = or i1 %10594, %10596
  %10598 = load i32, i32* %33, align 4
  %10599 = icmp eq i32 %10513, %10598
  %10600 = or i1 %10597, %10599
  %10601 = load i32, i32* %34, align 4
  %10602 = icmp eq i32 %10513, %10601
  %10603 = or i1 %10600, %10602
  %10604 = load i32, i32* %35, align 4
  %10605 = icmp eq i32 %10513, %10604
  %10606 = or i1 %10603, %10605
  %10607 = load i32, i32* %36, align 4
  %10608 = icmp eq i32 %10513, %10607
  %10609 = or i1 %10606, %10608
  %10610 = load i32, i32* %37, align 4
  %10611 = icmp eq i32 %10513, %10610
  %10612 = or i1 %10609, %10611
  %10613 = load i32, i32* %38, align 4
  %10614 = icmp eq i32 %10513, %10613
  %10615 = or i1 %10612, %10614
  %10616 = load i32, i32* %39, align 4
  %10617 = icmp eq i32 %10513, %10616
  %10618 = or i1 %10615, %10617
  %10619 = load i32, i32* %40, align 4
  %10620 = icmp eq i32 %10513, %10619
  %10621 = or i1 %10618, %10620
  %10622 = load i32, i32* %41, align 4
  %10623 = icmp eq i32 %10513, %10622
  %10624 = or i1 %10621, %10623
  %10625 = load i32, i32* %42, align 4
  %10626 = icmp eq i32 %10513, %10625
  %10627 = or i1 %10624, %10626
  %10628 = load i32, i32* %43, align 4
  %10629 = icmp eq i32 %10513, %10628
  %10630 = or i1 %10627, %10629
  %10631 = load i32, i32* %44, align 4
  %10632 = icmp eq i32 %10513, %10631
  %10633 = or i1 %10630, %10632
  %10634 = load i32, i32* %45, align 4
  %10635 = icmp eq i32 %10513, %10634
  %10636 = or i1 %10633, %10635
  %10637 = load i32, i32* %46, align 4
  %10638 = icmp eq i32 %10513, %10637
  %10639 = or i1 %10636, %10638
  %10640 = load i32, i32* %47, align 4
  %10641 = icmp eq i32 %10513, %10640
  %10642 = or i1 %10639, %10641
  %10643 = load i32, i32* %48, align 4
  %10644 = icmp eq i32 %10513, %10643
  %10645 = or i1 %10642, %10644
  %10646 = load i32, i32* %49, align 4
  %10647 = icmp eq i32 %10513, %10646
  %10648 = or i1 %10645, %10647
  %10649 = load i32, i32* %50, align 4
  %10650 = icmp eq i32 %10513, %10649
  %10651 = or i1 %10648, %10650
  %10652 = load i32, i32* %51, align 4
  %10653 = icmp eq i32 %10513, %10652
  %10654 = or i1 %10651, %10653
  %10655 = load i32, i32* %52, align 4
  %10656 = icmp eq i32 %10513, %10655
  %10657 = or i1 %10654, %10656
  %10658 = load i32, i32* %53, align 4
  %10659 = icmp eq i32 %10513, %10658
  %10660 = or i1 %10657, %10659
  %10661 = load i32, i32* %54, align 4
  %10662 = icmp eq i32 %10513, %10661
  %10663 = or i1 %10660, %10662
  %10664 = load i32, i32* %55, align 4
  %10665 = icmp eq i32 %10513, %10664
  %10666 = or i1 %10663, %10665
  %10667 = load i32, i32* %56, align 4
  %10668 = icmp eq i32 %10513, %10667
  %10669 = or i1 %10666, %10668
  %10670 = load i32, i32* %57, align 4
  %10671 = icmp eq i32 %10513, %10670
  %10672 = or i1 %10669, %10671
  %10673 = load i32, i32* %58, align 4
  %10674 = icmp eq i32 %10513, %10673
  %10675 = or i1 %10672, %10674
  %10676 = load i32, i32* %59, align 4
  %10677 = icmp eq i32 %10513, %10676
  %10678 = or i1 %10675, %10677
  %10679 = load i32, i32* %60, align 4
  %10680 = icmp eq i32 %10513, %10679
  %10681 = or i1 %10678, %10680
  %10682 = load i32, i32* %61, align 4
  %10683 = icmp eq i32 %10513, %10682
  %10684 = or i1 %10681, %10683
  %10685 = load i32, i32* %62, align 4
  %10686 = icmp eq i32 %10513, %10685
  %10687 = or i1 %10684, %10686
  %10688 = getelementptr i8, i8 addrspace(1)* %4, i32 28
  %10689 = zext i1 %10687 to i8
  store i8 %10689, i8 addrspace(1)* %10688, align 1, !nosanitize !3
  %10690 = load i256, i256* %10512, align 4
  %10691 = alloca i256, align 8
  store i256 %10690, i256* %10691, align 4
  %10692 = alloca i256, align 8
  store i256 1, i256* %10692, align 4
  %10693 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %10691, i256* %10692, i256* %10693), !pc !229, !intsan !6
  %10694 = load i256, i256* %10693, align 4
  %10695 = and i256 1461501637330902918203684832716283019655932542975, %10694
  %10696 = and i256 1461501637330902918203684832716283019655932542975, %10695
  %10697 = icmp eq i256 %10696, %10510
  %10698 = icmp eq i1 %10697, false
  %10699 = icmp eq i1 %10698, false
  %10700 = trunc i256 4647 to i64
  %jump.check32 = icmp ne i1 %10699, false
  br i1 %jump.check32, label %.4647, label %.4643, !EVMBB !4

.4643:                                            ; preds = %10502
  %10701 = load i64, i64* %remaing_gas, align 4
  %10702 = icmp ugt i64 16, %10701
  br i1 %10702, label %Abort, label %10703

10703:                                            ; preds = %.4643
  %10704 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10705 = xor i32 %10704, 2718
  %10706 = urem i32 %10705, 4096
  %10707 = getelementptr i8, i8 addrspace(1)* %4, i32 %10706
  %10708 = load i8, i8 addrspace(1)* %10707, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10707, align 1, !nosanitize !3
  store i32 1359, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10709 = sub i64 %10701, 16
  store i64 %10709, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4647:                                            ; preds = %10502, %JumpTable
  %10710 = load i64, i64* %remaing_gas, align 4
  %10711 = icmp ugt i64 312, %10710
  br i1 %10711, label %Abort, label %10712

10712:                                            ; preds = %.4647
  %10713 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10714 = xor i32 %10713, 2895
  %10715 = urem i32 %10714, 4096
  %10716 = getelementptr i8, i8 addrspace(1)* %4, i32 %10715
  %10717 = load i8, i8 addrspace(1)* %10716, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10716, align 1, !nosanitize !3
  store i32 1447, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10718 = sub i64 %10710, 312
  store i64 %10718, i64* %remaing_gas, align 4
  %10719 = load i64, i64* %STACK_DEP_PTR, align 4
  %10720 = getelementptr i256, i256* %STACK, i64 %10719
  %10721 = load i256, i256* %10720, align 4
  %10722 = load i64, i64* %STACK_DEP_PTR, align 4
  %10723 = sub i64 %10722, 1
  store i64 %10723, i64* %STACK_DEP_PTR, align 4
  %10724 = alloca i256, align 8
  store i256 8, i256* %10724, align 4
  %10725 = alloca i256, align 8
  call void @__device_sload(i256* %10724, i256* %10725)
  %10726 = call i32 @__hashword(i256* %10724)
  %10727 = load i32, i32* %5, align 4
  %10728 = icmp eq i32 %10726, %10727
  %10729 = or i1 false, %10728
  %10730 = load i32, i32* %6, align 4
  %10731 = icmp eq i32 %10726, %10730
  %10732 = or i1 %10729, %10731
  %10733 = load i32, i32* %7, align 4
  %10734 = icmp eq i32 %10726, %10733
  %10735 = or i1 %10732, %10734
  %10736 = load i32, i32* %8, align 4
  %10737 = icmp eq i32 %10726, %10736
  %10738 = or i1 %10735, %10737
  %10739 = load i32, i32* %9, align 4
  %10740 = icmp eq i32 %10726, %10739
  %10741 = or i1 %10738, %10740
  %10742 = load i32, i32* %10, align 4
  %10743 = icmp eq i32 %10726, %10742
  %10744 = or i1 %10741, %10743
  %10745 = load i32, i32* %11, align 4
  %10746 = icmp eq i32 %10726, %10745
  %10747 = or i1 %10744, %10746
  %10748 = load i32, i32* %12, align 4
  %10749 = icmp eq i32 %10726, %10748
  %10750 = or i1 %10747, %10749
  %10751 = load i32, i32* %13, align 4
  %10752 = icmp eq i32 %10726, %10751
  %10753 = or i1 %10750, %10752
  %10754 = load i32, i32* %14, align 4
  %10755 = icmp eq i32 %10726, %10754
  %10756 = or i1 %10753, %10755
  %10757 = load i32, i32* %15, align 4
  %10758 = icmp eq i32 %10726, %10757
  %10759 = or i1 %10756, %10758
  %10760 = load i32, i32* %16, align 4
  %10761 = icmp eq i32 %10726, %10760
  %10762 = or i1 %10759, %10761
  %10763 = load i32, i32* %17, align 4
  %10764 = icmp eq i32 %10726, %10763
  %10765 = or i1 %10762, %10764
  %10766 = load i32, i32* %18, align 4
  %10767 = icmp eq i32 %10726, %10766
  %10768 = or i1 %10765, %10767
  %10769 = load i32, i32* %19, align 4
  %10770 = icmp eq i32 %10726, %10769
  %10771 = or i1 %10768, %10770
  %10772 = load i32, i32* %20, align 4
  %10773 = icmp eq i32 %10726, %10772
  %10774 = or i1 %10771, %10773
  %10775 = load i32, i32* %21, align 4
  %10776 = icmp eq i32 %10726, %10775
  %10777 = or i1 %10774, %10776
  %10778 = load i32, i32* %22, align 4
  %10779 = icmp eq i32 %10726, %10778
  %10780 = or i1 %10777, %10779
  %10781 = load i32, i32* %23, align 4
  %10782 = icmp eq i32 %10726, %10781
  %10783 = or i1 %10780, %10782
  %10784 = load i32, i32* %24, align 4
  %10785 = icmp eq i32 %10726, %10784
  %10786 = or i1 %10783, %10785
  %10787 = load i32, i32* %25, align 4
  %10788 = icmp eq i32 %10726, %10787
  %10789 = or i1 %10786, %10788
  %10790 = load i32, i32* %26, align 4
  %10791 = icmp eq i32 %10726, %10790
  %10792 = or i1 %10789, %10791
  %10793 = load i32, i32* %27, align 4
  %10794 = icmp eq i32 %10726, %10793
  %10795 = or i1 %10792, %10794
  %10796 = load i32, i32* %28, align 4
  %10797 = icmp eq i32 %10726, %10796
  %10798 = or i1 %10795, %10797
  %10799 = load i32, i32* %29, align 4
  %10800 = icmp eq i32 %10726, %10799
  %10801 = or i1 %10798, %10800
  %10802 = load i32, i32* %30, align 4
  %10803 = icmp eq i32 %10726, %10802
  %10804 = or i1 %10801, %10803
  %10805 = load i32, i32* %31, align 4
  %10806 = icmp eq i32 %10726, %10805
  %10807 = or i1 %10804, %10806
  %10808 = load i32, i32* %32, align 4
  %10809 = icmp eq i32 %10726, %10808
  %10810 = or i1 %10807, %10809
  %10811 = load i32, i32* %33, align 4
  %10812 = icmp eq i32 %10726, %10811
  %10813 = or i1 %10810, %10812
  %10814 = load i32, i32* %34, align 4
  %10815 = icmp eq i32 %10726, %10814
  %10816 = or i1 %10813, %10815
  %10817 = load i32, i32* %35, align 4
  %10818 = icmp eq i32 %10726, %10817
  %10819 = or i1 %10816, %10818
  %10820 = load i32, i32* %36, align 4
  %10821 = icmp eq i32 %10726, %10820
  %10822 = or i1 %10819, %10821
  %10823 = load i32, i32* %37, align 4
  %10824 = icmp eq i32 %10726, %10823
  %10825 = or i1 %10822, %10824
  %10826 = load i32, i32* %38, align 4
  %10827 = icmp eq i32 %10726, %10826
  %10828 = or i1 %10825, %10827
  %10829 = load i32, i32* %39, align 4
  %10830 = icmp eq i32 %10726, %10829
  %10831 = or i1 %10828, %10830
  %10832 = load i32, i32* %40, align 4
  %10833 = icmp eq i32 %10726, %10832
  %10834 = or i1 %10831, %10833
  %10835 = load i32, i32* %41, align 4
  %10836 = icmp eq i32 %10726, %10835
  %10837 = or i1 %10834, %10836
  %10838 = load i32, i32* %42, align 4
  %10839 = icmp eq i32 %10726, %10838
  %10840 = or i1 %10837, %10839
  %10841 = load i32, i32* %43, align 4
  %10842 = icmp eq i32 %10726, %10841
  %10843 = or i1 %10840, %10842
  %10844 = load i32, i32* %44, align 4
  %10845 = icmp eq i32 %10726, %10844
  %10846 = or i1 %10843, %10845
  %10847 = load i32, i32* %45, align 4
  %10848 = icmp eq i32 %10726, %10847
  %10849 = or i1 %10846, %10848
  %10850 = load i32, i32* %46, align 4
  %10851 = icmp eq i32 %10726, %10850
  %10852 = or i1 %10849, %10851
  %10853 = load i32, i32* %47, align 4
  %10854 = icmp eq i32 %10726, %10853
  %10855 = or i1 %10852, %10854
  %10856 = load i32, i32* %48, align 4
  %10857 = icmp eq i32 %10726, %10856
  %10858 = or i1 %10855, %10857
  %10859 = load i32, i32* %49, align 4
  %10860 = icmp eq i32 %10726, %10859
  %10861 = or i1 %10858, %10860
  %10862 = load i32, i32* %50, align 4
  %10863 = icmp eq i32 %10726, %10862
  %10864 = or i1 %10861, %10863
  %10865 = load i32, i32* %51, align 4
  %10866 = icmp eq i32 %10726, %10865
  %10867 = or i1 %10864, %10866
  %10868 = load i32, i32* %52, align 4
  %10869 = icmp eq i32 %10726, %10868
  %10870 = or i1 %10867, %10869
  %10871 = load i32, i32* %53, align 4
  %10872 = icmp eq i32 %10726, %10871
  %10873 = or i1 %10870, %10872
  %10874 = load i32, i32* %54, align 4
  %10875 = icmp eq i32 %10726, %10874
  %10876 = or i1 %10873, %10875
  %10877 = load i32, i32* %55, align 4
  %10878 = icmp eq i32 %10726, %10877
  %10879 = or i1 %10876, %10878
  %10880 = load i32, i32* %56, align 4
  %10881 = icmp eq i32 %10726, %10880
  %10882 = or i1 %10879, %10881
  %10883 = load i32, i32* %57, align 4
  %10884 = icmp eq i32 %10726, %10883
  %10885 = or i1 %10882, %10884
  %10886 = load i32, i32* %58, align 4
  %10887 = icmp eq i32 %10726, %10886
  %10888 = or i1 %10885, %10887
  %10889 = load i32, i32* %59, align 4
  %10890 = icmp eq i32 %10726, %10889
  %10891 = or i1 %10888, %10890
  %10892 = load i32, i32* %60, align 4
  %10893 = icmp eq i32 %10726, %10892
  %10894 = or i1 %10891, %10893
  %10895 = load i32, i32* %61, align 4
  %10896 = icmp eq i32 %10726, %10895
  %10897 = or i1 %10894, %10896
  %10898 = load i32, i32* %62, align 4
  %10899 = icmp eq i32 %10726, %10898
  %10900 = or i1 %10897, %10899
  %10901 = getelementptr i8, i8 addrspace(1)* %4, i32 29
  %10902 = zext i1 %10900 to i8
  store i8 %10902, i8 addrspace(1)* %10901, align 1, !nosanitize !3
  %10903 = load i256, i256* %10725, align 4
  %10904 = mul i256 255, 1461501637330902918203684832716283019655932542976, !pc !230, !intsan !45
  %10905 = xor i256 %10904, -1
  %10906 = and i256 %10905, %10903
  %10907 = icmp eq i256 1, 0
  %10908 = icmp eq i1 %10907, false
  %10909 = zext i1 %10908 to i256
  %10910 = mul i256 %10909, 1461501637330902918203684832716283019655932542976, !pc !231, !intsan !45
  %10911 = or i256 %10910, %10906
  %10912 = alloca i256, align 8
  store i256 8, i256* %10912, align 4
  %10913 = alloca i256, align 8
  store i256 %10911, i256* %10913, align 4
  call void @__device_sstore(i256* %10912, i256* %10913)
  %10914 = call i32 @__hashword(i256* %10912)
  store i32 %10914, i32* %5, align 4, !nosanitize !3
  %10915 = trunc i256 64 to i64
  %10916 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %10915, i256* %10916)
  %10917 = load i256, i256* %10916, align 4
  %10918 = trunc i256 64 to i64
  %10919 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %10918, i256* %10919)
  %10920 = load i256, i256* %10919, align 4
  %10921 = sub i256 %10917, %10920, !pc !232, !intsan !8
  %10922 = trunc i256 27006777090035643930611139202264128510007481982678330612677586948398715251804 to i64
  call void @addBugSet(i64 %10922)
  %10923 = trunc i256 %10721 to i64
  store i64 %10923, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.4720:                                            ; preds = %1226, %JumpTable
  %10924 = load i64, i64* %remaing_gas, align 4
  %10925 = icmp ugt i64 216, %10924
  br i1 %10925, label %Abort, label %10926

10926:                                            ; preds = %.4720
  %10927 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10928 = xor i32 %10927, 3890
  %10929 = urem i32 %10928, 4096
  %10930 = getelementptr i8, i8 addrspace(1)* %4, i32 %10929
  %10931 = load i8, i8 addrspace(1)* %10930, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %10930, align 1, !nosanitize !3
  store i32 1945, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %10932 = sub i64 %10924, 216
  store i64 %10932, i64* %remaing_gas, align 4
  %10933 = load i64, i64* %STACK_DEP_PTR, align 4
  %10934 = getelementptr i256, i256* %STACK, i64 %10933
  %10935 = load i256, i256* %10934, align 4
  %10936 = load i64, i64* %STACK_DEP_PTR, align 4
  %10937 = sub i64 %10936, 1
  store i64 %10937, i64* %STACK_DEP_PTR, align 4
  %10938 = alloca i256, align 8
  store i256 5, i256* %10938, align 4
  %10939 = alloca i256, align 8
  call void @__device_sload(i256* %10938, i256* %10939)
  %10940 = call i32 @__hashword(i256* %10938)
  %10941 = load i32, i32* %5, align 4
  %10942 = icmp eq i32 %10940, %10941
  %10943 = or i1 false, %10942
  %10944 = load i32, i32* %6, align 4
  %10945 = icmp eq i32 %10940, %10944
  %10946 = or i1 %10943, %10945
  %10947 = load i32, i32* %7, align 4
  %10948 = icmp eq i32 %10940, %10947
  %10949 = or i1 %10946, %10948
  %10950 = load i32, i32* %8, align 4
  %10951 = icmp eq i32 %10940, %10950
  %10952 = or i1 %10949, %10951
  %10953 = load i32, i32* %9, align 4
  %10954 = icmp eq i32 %10940, %10953
  %10955 = or i1 %10952, %10954
  %10956 = load i32, i32* %10, align 4
  %10957 = icmp eq i32 %10940, %10956
  %10958 = or i1 %10955, %10957
  %10959 = load i32, i32* %11, align 4
  %10960 = icmp eq i32 %10940, %10959
  %10961 = or i1 %10958, %10960
  %10962 = load i32, i32* %12, align 4
  %10963 = icmp eq i32 %10940, %10962
  %10964 = or i1 %10961, %10963
  %10965 = load i32, i32* %13, align 4
  %10966 = icmp eq i32 %10940, %10965
  %10967 = or i1 %10964, %10966
  %10968 = load i32, i32* %14, align 4
  %10969 = icmp eq i32 %10940, %10968
  %10970 = or i1 %10967, %10969
  %10971 = load i32, i32* %15, align 4
  %10972 = icmp eq i32 %10940, %10971
  %10973 = or i1 %10970, %10972
  %10974 = load i32, i32* %16, align 4
  %10975 = icmp eq i32 %10940, %10974
  %10976 = or i1 %10973, %10975
  %10977 = load i32, i32* %17, align 4
  %10978 = icmp eq i32 %10940, %10977
  %10979 = or i1 %10976, %10978
  %10980 = load i32, i32* %18, align 4
  %10981 = icmp eq i32 %10940, %10980
  %10982 = or i1 %10979, %10981
  %10983 = load i32, i32* %19, align 4
  %10984 = icmp eq i32 %10940, %10983
  %10985 = or i1 %10982, %10984
  %10986 = load i32, i32* %20, align 4
  %10987 = icmp eq i32 %10940, %10986
  %10988 = or i1 %10985, %10987
  %10989 = load i32, i32* %21, align 4
  %10990 = icmp eq i32 %10940, %10989
  %10991 = or i1 %10988, %10990
  %10992 = load i32, i32* %22, align 4
  %10993 = icmp eq i32 %10940, %10992
  %10994 = or i1 %10991, %10993
  %10995 = load i32, i32* %23, align 4
  %10996 = icmp eq i32 %10940, %10995
  %10997 = or i1 %10994, %10996
  %10998 = load i32, i32* %24, align 4
  %10999 = icmp eq i32 %10940, %10998
  %11000 = or i1 %10997, %10999
  %11001 = load i32, i32* %25, align 4
  %11002 = icmp eq i32 %10940, %11001
  %11003 = or i1 %11000, %11002
  %11004 = load i32, i32* %26, align 4
  %11005 = icmp eq i32 %10940, %11004
  %11006 = or i1 %11003, %11005
  %11007 = load i32, i32* %27, align 4
  %11008 = icmp eq i32 %10940, %11007
  %11009 = or i1 %11006, %11008
  %11010 = load i32, i32* %28, align 4
  %11011 = icmp eq i32 %10940, %11010
  %11012 = or i1 %11009, %11011
  %11013 = load i32, i32* %29, align 4
  %11014 = icmp eq i32 %10940, %11013
  %11015 = or i1 %11012, %11014
  %11016 = load i32, i32* %30, align 4
  %11017 = icmp eq i32 %10940, %11016
  %11018 = or i1 %11015, %11017
  %11019 = load i32, i32* %31, align 4
  %11020 = icmp eq i32 %10940, %11019
  %11021 = or i1 %11018, %11020
  %11022 = load i32, i32* %32, align 4
  %11023 = icmp eq i32 %10940, %11022
  %11024 = or i1 %11021, %11023
  %11025 = load i32, i32* %33, align 4
  %11026 = icmp eq i32 %10940, %11025
  %11027 = or i1 %11024, %11026
  %11028 = load i32, i32* %34, align 4
  %11029 = icmp eq i32 %10940, %11028
  %11030 = or i1 %11027, %11029
  %11031 = load i32, i32* %35, align 4
  %11032 = icmp eq i32 %10940, %11031
  %11033 = or i1 %11030, %11032
  %11034 = load i32, i32* %36, align 4
  %11035 = icmp eq i32 %10940, %11034
  %11036 = or i1 %11033, %11035
  %11037 = load i32, i32* %37, align 4
  %11038 = icmp eq i32 %10940, %11037
  %11039 = or i1 %11036, %11038
  %11040 = load i32, i32* %38, align 4
  %11041 = icmp eq i32 %10940, %11040
  %11042 = or i1 %11039, %11041
  %11043 = load i32, i32* %39, align 4
  %11044 = icmp eq i32 %10940, %11043
  %11045 = or i1 %11042, %11044
  %11046 = load i32, i32* %40, align 4
  %11047 = icmp eq i32 %10940, %11046
  %11048 = or i1 %11045, %11047
  %11049 = load i32, i32* %41, align 4
  %11050 = icmp eq i32 %10940, %11049
  %11051 = or i1 %11048, %11050
  %11052 = load i32, i32* %42, align 4
  %11053 = icmp eq i32 %10940, %11052
  %11054 = or i1 %11051, %11053
  %11055 = load i32, i32* %43, align 4
  %11056 = icmp eq i32 %10940, %11055
  %11057 = or i1 %11054, %11056
  %11058 = load i32, i32* %44, align 4
  %11059 = icmp eq i32 %10940, %11058
  %11060 = or i1 %11057, %11059
  %11061 = load i32, i32* %45, align 4
  %11062 = icmp eq i32 %10940, %11061
  %11063 = or i1 %11060, %11062
  %11064 = load i32, i32* %46, align 4
  %11065 = icmp eq i32 %10940, %11064
  %11066 = or i1 %11063, %11065
  %11067 = load i32, i32* %47, align 4
  %11068 = icmp eq i32 %10940, %11067
  %11069 = or i1 %11066, %11068
  %11070 = load i32, i32* %48, align 4
  %11071 = icmp eq i32 %10940, %11070
  %11072 = or i1 %11069, %11071
  %11073 = load i32, i32* %49, align 4
  %11074 = icmp eq i32 %10940, %11073
  %11075 = or i1 %11072, %11074
  %11076 = load i32, i32* %50, align 4
  %11077 = icmp eq i32 %10940, %11076
  %11078 = or i1 %11075, %11077
  %11079 = load i32, i32* %51, align 4
  %11080 = icmp eq i32 %10940, %11079
  %11081 = or i1 %11078, %11080
  %11082 = load i32, i32* %52, align 4
  %11083 = icmp eq i32 %10940, %11082
  %11084 = or i1 %11081, %11083
  %11085 = load i32, i32* %53, align 4
  %11086 = icmp eq i32 %10940, %11085
  %11087 = or i1 %11084, %11086
  %11088 = load i32, i32* %54, align 4
  %11089 = icmp eq i32 %10940, %11088
  %11090 = or i1 %11087, %11089
  %11091 = load i32, i32* %55, align 4
  %11092 = icmp eq i32 %10940, %11091
  %11093 = or i1 %11090, %11092
  %11094 = load i32, i32* %56, align 4
  %11095 = icmp eq i32 %10940, %11094
  %11096 = or i1 %11093, %11095
  %11097 = load i32, i32* %57, align 4
  %11098 = icmp eq i32 %10940, %11097
  %11099 = or i1 %11096, %11098
  %11100 = load i32, i32* %58, align 4
  %11101 = icmp eq i32 %10940, %11100
  %11102 = or i1 %11099, %11101
  %11103 = load i32, i32* %59, align 4
  %11104 = icmp eq i32 %10940, %11103
  %11105 = or i1 %11102, %11104
  %11106 = load i32, i32* %60, align 4
  %11107 = icmp eq i32 %10940, %11106
  %11108 = or i1 %11105, %11107
  %11109 = load i32, i32* %61, align 4
  %11110 = icmp eq i32 %10940, %11109
  %11111 = or i1 %11108, %11110
  %11112 = load i32, i32* %62, align 4
  %11113 = icmp eq i32 %10940, %11112
  %11114 = or i1 %11111, %11113
  %11115 = getelementptr i8, i8 addrspace(1)* %4, i32 30
  %11116 = zext i1 %11114 to i8
  store i8 %11116, i8 addrspace(1)* %11115, align 1, !nosanitize !3
  %11117 = load i256, i256* %10939, align 4
  %11118 = trunc i256 %10935 to i64
  store i64 %11118, i64* %JMP_TARGET_PTR, align 4
  %11119 = load i64, i64* %STACK_DEP_PTR, align 4
  %11120 = add i64 %11119, 1
  store i64 %11120, i64* %STACK_DEP_PTR, align 4
  %11121 = load i64, i64* %STACK_DEP_PTR, align 4
  %11122 = getelementptr i256, i256* %STACK, i64 %11121
  store i256 %10935, i256* %11122, align 4
  %11123 = load i64, i64* %STACK_DEP_PTR, align 4
  %11124 = add i64 %11123, 1
  store i64 %11124, i64* %STACK_DEP_PTR, align 4
  %11125 = load i64, i64* %STACK_DEP_PTR, align 4
  %11126 = getelementptr i256, i256* %STACK, i64 %11125
  store i256 %11117, i256* %11126, align 4
  br label %JumpTable, !EVMBB !4

.4726:                                            ; preds = %51120, %34387, %1297, %JumpTable
  %11127 = load i64, i64* %remaing_gas, align 4
  %11128 = icmp ugt i64 784, %11127
  br i1 %11128, label %Abort, label %11129

11129:                                            ; preds = %.4726
  %11130 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11131 = xor i32 %11130, 3349
  %11132 = urem i32 %11131, 4096
  %11133 = getelementptr i8, i8 addrspace(1)* %4, i32 %11132
  %11134 = load i8, i8 addrspace(1)* %11133, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %11133, align 1, !nosanitize !3
  store i32 1674, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11135 = sub i64 %11127, 784
  store i64 %11135, i64* %remaing_gas, align 4
  %11136 = load i64, i64* %STACK_DEP_PTR, align 4
  %11137 = getelementptr i256, i256* %STACK, i64 %11136
  %11138 = load i256, i256* %11137, align 4
  %11139 = load i64, i64* %STACK_DEP_PTR, align 4
  %11140 = sub i64 %11139, 1
  store i64 %11140, i64* %STACK_DEP_PTR, align 4
  %11141 = alloca i256, align 8
  store i256 6, i256* %11141, align 4
  %11142 = alloca i256, align 8
  call void @__device_sload(i256* %11141, i256* %11142)
  %11143 = call i32 @__hashword(i256* %11141)
  %11144 = load i32, i32* %5, align 4
  %11145 = icmp eq i32 %11143, %11144
  %11146 = or i1 false, %11145
  %11147 = load i32, i32* %6, align 4
  %11148 = icmp eq i32 %11143, %11147
  %11149 = or i1 %11146, %11148
  %11150 = load i32, i32* %7, align 4
  %11151 = icmp eq i32 %11143, %11150
  %11152 = or i1 %11149, %11151
  %11153 = load i32, i32* %8, align 4
  %11154 = icmp eq i32 %11143, %11153
  %11155 = or i1 %11152, %11154
  %11156 = load i32, i32* %9, align 4
  %11157 = icmp eq i32 %11143, %11156
  %11158 = or i1 %11155, %11157
  %11159 = load i32, i32* %10, align 4
  %11160 = icmp eq i32 %11143, %11159
  %11161 = or i1 %11158, %11160
  %11162 = load i32, i32* %11, align 4
  %11163 = icmp eq i32 %11143, %11162
  %11164 = or i1 %11161, %11163
  %11165 = load i32, i32* %12, align 4
  %11166 = icmp eq i32 %11143, %11165
  %11167 = or i1 %11164, %11166
  %11168 = load i32, i32* %13, align 4
  %11169 = icmp eq i32 %11143, %11168
  %11170 = or i1 %11167, %11169
  %11171 = load i32, i32* %14, align 4
  %11172 = icmp eq i32 %11143, %11171
  %11173 = or i1 %11170, %11172
  %11174 = load i32, i32* %15, align 4
  %11175 = icmp eq i32 %11143, %11174
  %11176 = or i1 %11173, %11175
  %11177 = load i32, i32* %16, align 4
  %11178 = icmp eq i32 %11143, %11177
  %11179 = or i1 %11176, %11178
  %11180 = load i32, i32* %17, align 4
  %11181 = icmp eq i32 %11143, %11180
  %11182 = or i1 %11179, %11181
  %11183 = load i32, i32* %18, align 4
  %11184 = icmp eq i32 %11143, %11183
  %11185 = or i1 %11182, %11184
  %11186 = load i32, i32* %19, align 4
  %11187 = icmp eq i32 %11143, %11186
  %11188 = or i1 %11185, %11187
  %11189 = load i32, i32* %20, align 4
  %11190 = icmp eq i32 %11143, %11189
  %11191 = or i1 %11188, %11190
  %11192 = load i32, i32* %21, align 4
  %11193 = icmp eq i32 %11143, %11192
  %11194 = or i1 %11191, %11193
  %11195 = load i32, i32* %22, align 4
  %11196 = icmp eq i32 %11143, %11195
  %11197 = or i1 %11194, %11196
  %11198 = load i32, i32* %23, align 4
  %11199 = icmp eq i32 %11143, %11198
  %11200 = or i1 %11197, %11199
  %11201 = load i32, i32* %24, align 4
  %11202 = icmp eq i32 %11143, %11201
  %11203 = or i1 %11200, %11202
  %11204 = load i32, i32* %25, align 4
  %11205 = icmp eq i32 %11143, %11204
  %11206 = or i1 %11203, %11205
  %11207 = load i32, i32* %26, align 4
  %11208 = icmp eq i32 %11143, %11207
  %11209 = or i1 %11206, %11208
  %11210 = load i32, i32* %27, align 4
  %11211 = icmp eq i32 %11143, %11210
  %11212 = or i1 %11209, %11211
  %11213 = load i32, i32* %28, align 4
  %11214 = icmp eq i32 %11143, %11213
  %11215 = or i1 %11212, %11214
  %11216 = load i32, i32* %29, align 4
  %11217 = icmp eq i32 %11143, %11216
  %11218 = or i1 %11215, %11217
  %11219 = load i32, i32* %30, align 4
  %11220 = icmp eq i32 %11143, %11219
  %11221 = or i1 %11218, %11220
  %11222 = load i32, i32* %31, align 4
  %11223 = icmp eq i32 %11143, %11222
  %11224 = or i1 %11221, %11223
  %11225 = load i32, i32* %32, align 4
  %11226 = icmp eq i32 %11143, %11225
  %11227 = or i1 %11224, %11226
  %11228 = load i32, i32* %33, align 4
  %11229 = icmp eq i32 %11143, %11228
  %11230 = or i1 %11227, %11229
  %11231 = load i32, i32* %34, align 4
  %11232 = icmp eq i32 %11143, %11231
  %11233 = or i1 %11230, %11232
  %11234 = load i32, i32* %35, align 4
  %11235 = icmp eq i32 %11143, %11234
  %11236 = or i1 %11233, %11235
  %11237 = load i32, i32* %36, align 4
  %11238 = icmp eq i32 %11143, %11237
  %11239 = or i1 %11236, %11238
  %11240 = load i32, i32* %37, align 4
  %11241 = icmp eq i32 %11143, %11240
  %11242 = or i1 %11239, %11241
  %11243 = load i32, i32* %38, align 4
  %11244 = icmp eq i32 %11143, %11243
  %11245 = or i1 %11242, %11244
  %11246 = load i32, i32* %39, align 4
  %11247 = icmp eq i32 %11143, %11246
  %11248 = or i1 %11245, %11247
  %11249 = load i32, i32* %40, align 4
  %11250 = icmp eq i32 %11143, %11249
  %11251 = or i1 %11248, %11250
  %11252 = load i32, i32* %41, align 4
  %11253 = icmp eq i32 %11143, %11252
  %11254 = or i1 %11251, %11253
  %11255 = load i32, i32* %42, align 4
  %11256 = icmp eq i32 %11143, %11255
  %11257 = or i1 %11254, %11256
  %11258 = load i32, i32* %43, align 4
  %11259 = icmp eq i32 %11143, %11258
  %11260 = or i1 %11257, %11259
  %11261 = load i32, i32* %44, align 4
  %11262 = icmp eq i32 %11143, %11261
  %11263 = or i1 %11260, %11262
  %11264 = load i32, i32* %45, align 4
  %11265 = icmp eq i32 %11143, %11264
  %11266 = or i1 %11263, %11265
  %11267 = load i32, i32* %46, align 4
  %11268 = icmp eq i32 %11143, %11267
  %11269 = or i1 %11266, %11268
  %11270 = load i32, i32* %47, align 4
  %11271 = icmp eq i32 %11143, %11270
  %11272 = or i1 %11269, %11271
  %11273 = load i32, i32* %48, align 4
  %11274 = icmp eq i32 %11143, %11273
  %11275 = or i1 %11272, %11274
  %11276 = load i32, i32* %49, align 4
  %11277 = icmp eq i32 %11143, %11276
  %11278 = or i1 %11275, %11277
  %11279 = load i32, i32* %50, align 4
  %11280 = icmp eq i32 %11143, %11279
  %11281 = or i1 %11278, %11280
  %11282 = load i32, i32* %51, align 4
  %11283 = icmp eq i32 %11143, %11282
  %11284 = or i1 %11281, %11283
  %11285 = load i32, i32* %52, align 4
  %11286 = icmp eq i32 %11143, %11285
  %11287 = or i1 %11284, %11286
  %11288 = load i32, i32* %53, align 4
  %11289 = icmp eq i32 %11143, %11288
  %11290 = or i1 %11287, %11289
  %11291 = load i32, i32* %54, align 4
  %11292 = icmp eq i32 %11143, %11291
  %11293 = or i1 %11290, %11292
  %11294 = load i32, i32* %55, align 4
  %11295 = icmp eq i32 %11143, %11294
  %11296 = or i1 %11293, %11295
  %11297 = load i32, i32* %56, align 4
  %11298 = icmp eq i32 %11143, %11297
  %11299 = or i1 %11296, %11298
  %11300 = load i32, i32* %57, align 4
  %11301 = icmp eq i32 %11143, %11300
  %11302 = or i1 %11299, %11301
  %11303 = load i32, i32* %58, align 4
  %11304 = icmp eq i32 %11143, %11303
  %11305 = or i1 %11302, %11304
  %11306 = load i32, i32* %59, align 4
  %11307 = icmp eq i32 %11143, %11306
  %11308 = or i1 %11305, %11307
  %11309 = load i32, i32* %60, align 4
  %11310 = icmp eq i32 %11143, %11309
  %11311 = or i1 %11308, %11310
  %11312 = load i32, i32* %61, align 4
  %11313 = icmp eq i32 %11143, %11312
  %11314 = or i1 %11311, %11313
  %11315 = load i32, i32* %62, align 4
  %11316 = icmp eq i32 %11143, %11315
  %11317 = or i1 %11314, %11316
  %11318 = getelementptr i8, i8 addrspace(1)* %4, i32 31
  %11319 = zext i1 %11317 to i8
  store i8 %11319, i8 addrspace(1)* %11318, align 1, !nosanitize !3
  %11320 = load i256, i256* %11142, align 4
  %11321 = alloca i256, align 8
  store i256 14, i256* %11321, align 4
  %11322 = alloca i256, align 8
  call void @__device_sload(i256* %11321, i256* %11322)
  %11323 = call i32 @__hashword(i256* %11321)
  %11324 = load i32, i32* %5, align 4
  %11325 = icmp eq i32 %11323, %11324
  %11326 = or i1 false, %11325
  %11327 = load i32, i32* %6, align 4
  %11328 = icmp eq i32 %11323, %11327
  %11329 = or i1 %11326, %11328
  %11330 = load i32, i32* %7, align 4
  %11331 = icmp eq i32 %11323, %11330
  %11332 = or i1 %11329, %11331
  %11333 = load i32, i32* %8, align 4
  %11334 = icmp eq i32 %11323, %11333
  %11335 = or i1 %11332, %11334
  %11336 = load i32, i32* %9, align 4
  %11337 = icmp eq i32 %11323, %11336
  %11338 = or i1 %11335, %11337
  %11339 = load i32, i32* %10, align 4
  %11340 = icmp eq i32 %11323, %11339
  %11341 = or i1 %11338, %11340
  %11342 = load i32, i32* %11, align 4
  %11343 = icmp eq i32 %11323, %11342
  %11344 = or i1 %11341, %11343
  %11345 = load i32, i32* %12, align 4
  %11346 = icmp eq i32 %11323, %11345
  %11347 = or i1 %11344, %11346
  %11348 = load i32, i32* %13, align 4
  %11349 = icmp eq i32 %11323, %11348
  %11350 = or i1 %11347, %11349
  %11351 = load i32, i32* %14, align 4
  %11352 = icmp eq i32 %11323, %11351
  %11353 = or i1 %11350, %11352
  %11354 = load i32, i32* %15, align 4
  %11355 = icmp eq i32 %11323, %11354
  %11356 = or i1 %11353, %11355
  %11357 = load i32, i32* %16, align 4
  %11358 = icmp eq i32 %11323, %11357
  %11359 = or i1 %11356, %11358
  %11360 = load i32, i32* %17, align 4
  %11361 = icmp eq i32 %11323, %11360
  %11362 = or i1 %11359, %11361
  %11363 = load i32, i32* %18, align 4
  %11364 = icmp eq i32 %11323, %11363
  %11365 = or i1 %11362, %11364
  %11366 = load i32, i32* %19, align 4
  %11367 = icmp eq i32 %11323, %11366
  %11368 = or i1 %11365, %11367
  %11369 = load i32, i32* %20, align 4
  %11370 = icmp eq i32 %11323, %11369
  %11371 = or i1 %11368, %11370
  %11372 = load i32, i32* %21, align 4
  %11373 = icmp eq i32 %11323, %11372
  %11374 = or i1 %11371, %11373
  %11375 = load i32, i32* %22, align 4
  %11376 = icmp eq i32 %11323, %11375
  %11377 = or i1 %11374, %11376
  %11378 = load i32, i32* %23, align 4
  %11379 = icmp eq i32 %11323, %11378
  %11380 = or i1 %11377, %11379
  %11381 = load i32, i32* %24, align 4
  %11382 = icmp eq i32 %11323, %11381
  %11383 = or i1 %11380, %11382
  %11384 = load i32, i32* %25, align 4
  %11385 = icmp eq i32 %11323, %11384
  %11386 = or i1 %11383, %11385
  %11387 = load i32, i32* %26, align 4
  %11388 = icmp eq i32 %11323, %11387
  %11389 = or i1 %11386, %11388
  %11390 = load i32, i32* %27, align 4
  %11391 = icmp eq i32 %11323, %11390
  %11392 = or i1 %11389, %11391
  %11393 = load i32, i32* %28, align 4
  %11394 = icmp eq i32 %11323, %11393
  %11395 = or i1 %11392, %11394
  %11396 = load i32, i32* %29, align 4
  %11397 = icmp eq i32 %11323, %11396
  %11398 = or i1 %11395, %11397
  %11399 = load i32, i32* %30, align 4
  %11400 = icmp eq i32 %11323, %11399
  %11401 = or i1 %11398, %11400
  %11402 = load i32, i32* %31, align 4
  %11403 = icmp eq i32 %11323, %11402
  %11404 = or i1 %11401, %11403
  %11405 = load i32, i32* %32, align 4
  %11406 = icmp eq i32 %11323, %11405
  %11407 = or i1 %11404, %11406
  %11408 = load i32, i32* %33, align 4
  %11409 = icmp eq i32 %11323, %11408
  %11410 = or i1 %11407, %11409
  %11411 = load i32, i32* %34, align 4
  %11412 = icmp eq i32 %11323, %11411
  %11413 = or i1 %11410, %11412
  %11414 = load i32, i32* %35, align 4
  %11415 = icmp eq i32 %11323, %11414
  %11416 = or i1 %11413, %11415
  %11417 = load i32, i32* %36, align 4
  %11418 = icmp eq i32 %11323, %11417
  %11419 = or i1 %11416, %11418
  %11420 = load i32, i32* %37, align 4
  %11421 = icmp eq i32 %11323, %11420
  %11422 = or i1 %11419, %11421
  %11423 = load i32, i32* %38, align 4
  %11424 = icmp eq i32 %11323, %11423
  %11425 = or i1 %11422, %11424
  %11426 = load i32, i32* %39, align 4
  %11427 = icmp eq i32 %11323, %11426
  %11428 = or i1 %11425, %11427
  %11429 = load i32, i32* %40, align 4
  %11430 = icmp eq i32 %11323, %11429
  %11431 = or i1 %11428, %11430
  %11432 = load i32, i32* %41, align 4
  %11433 = icmp eq i32 %11323, %11432
  %11434 = or i1 %11431, %11433
  %11435 = load i32, i32* %42, align 4
  %11436 = icmp eq i32 %11323, %11435
  %11437 = or i1 %11434, %11436
  %11438 = load i32, i32* %43, align 4
  %11439 = icmp eq i32 %11323, %11438
  %11440 = or i1 %11437, %11439
  %11441 = load i32, i32* %44, align 4
  %11442 = icmp eq i32 %11323, %11441
  %11443 = or i1 %11440, %11442
  %11444 = load i32, i32* %45, align 4
  %11445 = icmp eq i32 %11323, %11444
  %11446 = or i1 %11443, %11445
  %11447 = load i32, i32* %46, align 4
  %11448 = icmp eq i32 %11323, %11447
  %11449 = or i1 %11446, %11448
  %11450 = load i32, i32* %47, align 4
  %11451 = icmp eq i32 %11323, %11450
  %11452 = or i1 %11449, %11451
  %11453 = load i32, i32* %48, align 4
  %11454 = icmp eq i32 %11323, %11453
  %11455 = or i1 %11452, %11454
  %11456 = load i32, i32* %49, align 4
  %11457 = icmp eq i32 %11323, %11456
  %11458 = or i1 %11455, %11457
  %11459 = load i32, i32* %50, align 4
  %11460 = icmp eq i32 %11323, %11459
  %11461 = or i1 %11458, %11460
  %11462 = load i32, i32* %51, align 4
  %11463 = icmp eq i32 %11323, %11462
  %11464 = or i1 %11461, %11463
  %11465 = load i32, i32* %52, align 4
  %11466 = icmp eq i32 %11323, %11465
  %11467 = or i1 %11464, %11466
  %11468 = load i32, i32* %53, align 4
  %11469 = icmp eq i32 %11323, %11468
  %11470 = or i1 %11467, %11469
  %11471 = load i32, i32* %54, align 4
  %11472 = icmp eq i32 %11323, %11471
  %11473 = or i1 %11470, %11472
  %11474 = load i32, i32* %55, align 4
  %11475 = icmp eq i32 %11323, %11474
  %11476 = or i1 %11473, %11475
  %11477 = load i32, i32* %56, align 4
  %11478 = icmp eq i32 %11323, %11477
  %11479 = or i1 %11476, %11478
  %11480 = load i32, i32* %57, align 4
  %11481 = icmp eq i32 %11323, %11480
  %11482 = or i1 %11479, %11481
  %11483 = load i32, i32* %58, align 4
  %11484 = icmp eq i32 %11323, %11483
  %11485 = or i1 %11482, %11484
  %11486 = load i32, i32* %59, align 4
  %11487 = icmp eq i32 %11323, %11486
  %11488 = or i1 %11485, %11487
  %11489 = load i32, i32* %60, align 4
  %11490 = icmp eq i32 %11323, %11489
  %11491 = or i1 %11488, %11490
  %11492 = load i32, i32* %61, align 4
  %11493 = icmp eq i32 %11323, %11492
  %11494 = or i1 %11491, %11493
  %11495 = load i32, i32* %62, align 4
  %11496 = icmp eq i32 %11323, %11495
  %11497 = or i1 %11494, %11496
  %11498 = getelementptr i8, i8 addrspace(1)* %4, i32 32
  %11499 = zext i1 %11497 to i8
  store i8 %11499, i8 addrspace(1)* %11498, align 1, !nosanitize !3
  %11500 = load i256, i256* %11322, align 4
  %11501 = and i256 1461501637330902918203684832716283019655932542975, %11138
  %11502 = and i256 1461501637330902918203684832716283019655932542975, %11501
  %11503 = trunc i256 0 to i64
  %11504 = alloca i256, align 8
  store i256 %11502, i256* %11504, align 4
  %11505 = bitcast i256* %11504 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11503, i8* %11505, i64 32)
  %11506 = add i256 32, 0, !pc !233, !intsan !10
  %11507 = trunc i256 %11506 to i64
  %11508 = alloca i256, align 8
  store i256 3, i256* %11508, align 4
  %11509 = bitcast i256* %11508 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11507, i8* %11509, i64 32)
  %11510 = add i256 32, %11506, !pc !234, !intsan !10
  %11511 = trunc i256 0 to i32
  %11512 = trunc i256 %11510 to i32
  %11513 = getelementptr inbounds i8, i8* %MEMORY, i32 %11511
  %11514 = alloca i256, align 8
  %11515 = bitcast i256* %11514 to i8*
  call void @__device_sha3(i8* %11513, i32 %11512, i8* %11515)
  %11516 = load i256, i256* %11514, align 4
  %11517 = alloca i256, align 8
  store i256 %11516, i256* %11517, align 4
  %11518 = alloca i256, align 8
  call void @__device_sload(i256* %11517, i256* %11518)
  %11519 = call i32 @__hashword(i256* %11517)
  %11520 = load i32, i32* %5, align 4
  %11521 = icmp eq i32 %11519, %11520
  %11522 = or i1 false, %11521
  %11523 = load i32, i32* %6, align 4
  %11524 = icmp eq i32 %11519, %11523
  %11525 = or i1 %11522, %11524
  %11526 = load i32, i32* %7, align 4
  %11527 = icmp eq i32 %11519, %11526
  %11528 = or i1 %11525, %11527
  %11529 = load i32, i32* %8, align 4
  %11530 = icmp eq i32 %11519, %11529
  %11531 = or i1 %11528, %11530
  %11532 = load i32, i32* %9, align 4
  %11533 = icmp eq i32 %11519, %11532
  %11534 = or i1 %11531, %11533
  %11535 = load i32, i32* %10, align 4
  %11536 = icmp eq i32 %11519, %11535
  %11537 = or i1 %11534, %11536
  %11538 = load i32, i32* %11, align 4
  %11539 = icmp eq i32 %11519, %11538
  %11540 = or i1 %11537, %11539
  %11541 = load i32, i32* %12, align 4
  %11542 = icmp eq i32 %11519, %11541
  %11543 = or i1 %11540, %11542
  %11544 = load i32, i32* %13, align 4
  %11545 = icmp eq i32 %11519, %11544
  %11546 = or i1 %11543, %11545
  %11547 = load i32, i32* %14, align 4
  %11548 = icmp eq i32 %11519, %11547
  %11549 = or i1 %11546, %11548
  %11550 = load i32, i32* %15, align 4
  %11551 = icmp eq i32 %11519, %11550
  %11552 = or i1 %11549, %11551
  %11553 = load i32, i32* %16, align 4
  %11554 = icmp eq i32 %11519, %11553
  %11555 = or i1 %11552, %11554
  %11556 = load i32, i32* %17, align 4
  %11557 = icmp eq i32 %11519, %11556
  %11558 = or i1 %11555, %11557
  %11559 = load i32, i32* %18, align 4
  %11560 = icmp eq i32 %11519, %11559
  %11561 = or i1 %11558, %11560
  %11562 = load i32, i32* %19, align 4
  %11563 = icmp eq i32 %11519, %11562
  %11564 = or i1 %11561, %11563
  %11565 = load i32, i32* %20, align 4
  %11566 = icmp eq i32 %11519, %11565
  %11567 = or i1 %11564, %11566
  %11568 = load i32, i32* %21, align 4
  %11569 = icmp eq i32 %11519, %11568
  %11570 = or i1 %11567, %11569
  %11571 = load i32, i32* %22, align 4
  %11572 = icmp eq i32 %11519, %11571
  %11573 = or i1 %11570, %11572
  %11574 = load i32, i32* %23, align 4
  %11575 = icmp eq i32 %11519, %11574
  %11576 = or i1 %11573, %11575
  %11577 = load i32, i32* %24, align 4
  %11578 = icmp eq i32 %11519, %11577
  %11579 = or i1 %11576, %11578
  %11580 = load i32, i32* %25, align 4
  %11581 = icmp eq i32 %11519, %11580
  %11582 = or i1 %11579, %11581
  %11583 = load i32, i32* %26, align 4
  %11584 = icmp eq i32 %11519, %11583
  %11585 = or i1 %11582, %11584
  %11586 = load i32, i32* %27, align 4
  %11587 = icmp eq i32 %11519, %11586
  %11588 = or i1 %11585, %11587
  %11589 = load i32, i32* %28, align 4
  %11590 = icmp eq i32 %11519, %11589
  %11591 = or i1 %11588, %11590
  %11592 = load i32, i32* %29, align 4
  %11593 = icmp eq i32 %11519, %11592
  %11594 = or i1 %11591, %11593
  %11595 = load i32, i32* %30, align 4
  %11596 = icmp eq i32 %11519, %11595
  %11597 = or i1 %11594, %11596
  %11598 = load i32, i32* %31, align 4
  %11599 = icmp eq i32 %11519, %11598
  %11600 = or i1 %11597, %11599
  %11601 = load i32, i32* %32, align 4
  %11602 = icmp eq i32 %11519, %11601
  %11603 = or i1 %11600, %11602
  %11604 = load i32, i32* %33, align 4
  %11605 = icmp eq i32 %11519, %11604
  %11606 = or i1 %11603, %11605
  %11607 = load i32, i32* %34, align 4
  %11608 = icmp eq i32 %11519, %11607
  %11609 = or i1 %11606, %11608
  %11610 = load i32, i32* %35, align 4
  %11611 = icmp eq i32 %11519, %11610
  %11612 = or i1 %11609, %11611
  %11613 = load i32, i32* %36, align 4
  %11614 = icmp eq i32 %11519, %11613
  %11615 = or i1 %11612, %11614
  %11616 = load i32, i32* %37, align 4
  %11617 = icmp eq i32 %11519, %11616
  %11618 = or i1 %11615, %11617
  %11619 = load i32, i32* %38, align 4
  %11620 = icmp eq i32 %11519, %11619
  %11621 = or i1 %11618, %11620
  %11622 = load i32, i32* %39, align 4
  %11623 = icmp eq i32 %11519, %11622
  %11624 = or i1 %11621, %11623
  %11625 = load i32, i32* %40, align 4
  %11626 = icmp eq i32 %11519, %11625
  %11627 = or i1 %11624, %11626
  %11628 = load i32, i32* %41, align 4
  %11629 = icmp eq i32 %11519, %11628
  %11630 = or i1 %11627, %11629
  %11631 = load i32, i32* %42, align 4
  %11632 = icmp eq i32 %11519, %11631
  %11633 = or i1 %11630, %11632
  %11634 = load i32, i32* %43, align 4
  %11635 = icmp eq i32 %11519, %11634
  %11636 = or i1 %11633, %11635
  %11637 = load i32, i32* %44, align 4
  %11638 = icmp eq i32 %11519, %11637
  %11639 = or i1 %11636, %11638
  %11640 = load i32, i32* %45, align 4
  %11641 = icmp eq i32 %11519, %11640
  %11642 = or i1 %11639, %11641
  %11643 = load i32, i32* %46, align 4
  %11644 = icmp eq i32 %11519, %11643
  %11645 = or i1 %11642, %11644
  %11646 = load i32, i32* %47, align 4
  %11647 = icmp eq i32 %11519, %11646
  %11648 = or i1 %11645, %11647
  %11649 = load i32, i32* %48, align 4
  %11650 = icmp eq i32 %11519, %11649
  %11651 = or i1 %11648, %11650
  %11652 = load i32, i32* %49, align 4
  %11653 = icmp eq i32 %11519, %11652
  %11654 = or i1 %11651, %11653
  %11655 = load i32, i32* %50, align 4
  %11656 = icmp eq i32 %11519, %11655
  %11657 = or i1 %11654, %11656
  %11658 = load i32, i32* %51, align 4
  %11659 = icmp eq i32 %11519, %11658
  %11660 = or i1 %11657, %11659
  %11661 = load i32, i32* %52, align 4
  %11662 = icmp eq i32 %11519, %11661
  %11663 = or i1 %11660, %11662
  %11664 = load i32, i32* %53, align 4
  %11665 = icmp eq i32 %11519, %11664
  %11666 = or i1 %11663, %11665
  %11667 = load i32, i32* %54, align 4
  %11668 = icmp eq i32 %11519, %11667
  %11669 = or i1 %11666, %11668
  %11670 = load i32, i32* %55, align 4
  %11671 = icmp eq i32 %11519, %11670
  %11672 = or i1 %11669, %11671
  %11673 = load i32, i32* %56, align 4
  %11674 = icmp eq i32 %11519, %11673
  %11675 = or i1 %11672, %11674
  %11676 = load i32, i32* %57, align 4
  %11677 = icmp eq i32 %11519, %11676
  %11678 = or i1 %11675, %11677
  %11679 = load i32, i32* %58, align 4
  %11680 = icmp eq i32 %11519, %11679
  %11681 = or i1 %11678, %11680
  %11682 = load i32, i32* %59, align 4
  %11683 = icmp eq i32 %11519, %11682
  %11684 = or i1 %11681, %11683
  %11685 = load i32, i32* %60, align 4
  %11686 = icmp eq i32 %11519, %11685
  %11687 = or i1 %11684, %11686
  %11688 = load i32, i32* %61, align 4
  %11689 = icmp eq i32 %11519, %11688
  %11690 = or i1 %11687, %11689
  %11691 = load i32, i32* %62, align 4
  %11692 = icmp eq i32 %11519, %11691
  %11693 = or i1 %11690, %11692
  %11694 = getelementptr i8, i8 addrspace(1)* %4, i32 33
  %11695 = zext i1 %11693 to i8
  store i8 %11695, i8 addrspace(1)* %11694, align 1, !nosanitize !3
  %11696 = load i256, i256* %11518, align 4
  %11697 = trunc i256 0 to i64
  %11698 = alloca i256, align 8
  store i256 %11696, i256* %11698, align 4
  %11699 = bitcast i256* %11698 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11697, i8* %11699, i64 32)
  %11700 = add i256 32, 0, !pc !235, !intsan !10
  %11701 = trunc i256 %11700 to i64
  %11702 = alloca i256, align 8
  store i256 4, i256* %11702, align 4
  %11703 = bitcast i256* %11702 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11701, i8* %11703, i64 32)
  %11704 = add i256 32, %11700, !pc !236, !intsan !10
  %11705 = trunc i256 0 to i32
  %11706 = trunc i256 %11704 to i32
  %11707 = getelementptr inbounds i8, i8* %MEMORY, i32 %11705
  %11708 = alloca i256, align 8
  %11709 = bitcast i256* %11708 to i8*
  call void @__device_sha3(i8* %11707, i32 %11706, i8* %11709)
  %11710 = load i256, i256* %11708, align 4
  %11711 = add i256 1, %11710, !pc !237, !intsan !10
  %11712 = alloca i256, align 8
  store i256 %11711, i256* %11712, align 4
  %11713 = alloca i256, align 8
  call void @__device_sload(i256* %11712, i256* %11713)
  %11714 = call i32 @__hashword(i256* %11712)
  %11715 = load i32, i32* %5, align 4
  %11716 = icmp eq i32 %11714, %11715
  %11717 = or i1 false, %11716
  %11718 = load i32, i32* %6, align 4
  %11719 = icmp eq i32 %11714, %11718
  %11720 = or i1 %11717, %11719
  %11721 = load i32, i32* %7, align 4
  %11722 = icmp eq i32 %11714, %11721
  %11723 = or i1 %11720, %11722
  %11724 = load i32, i32* %8, align 4
  %11725 = icmp eq i32 %11714, %11724
  %11726 = or i1 %11723, %11725
  %11727 = load i32, i32* %9, align 4
  %11728 = icmp eq i32 %11714, %11727
  %11729 = or i1 %11726, %11728
  %11730 = load i32, i32* %10, align 4
  %11731 = icmp eq i32 %11714, %11730
  %11732 = or i1 %11729, %11731
  %11733 = load i32, i32* %11, align 4
  %11734 = icmp eq i32 %11714, %11733
  %11735 = or i1 %11732, %11734
  %11736 = load i32, i32* %12, align 4
  %11737 = icmp eq i32 %11714, %11736
  %11738 = or i1 %11735, %11737
  %11739 = load i32, i32* %13, align 4
  %11740 = icmp eq i32 %11714, %11739
  %11741 = or i1 %11738, %11740
  %11742 = load i32, i32* %14, align 4
  %11743 = icmp eq i32 %11714, %11742
  %11744 = or i1 %11741, %11743
  %11745 = load i32, i32* %15, align 4
  %11746 = icmp eq i32 %11714, %11745
  %11747 = or i1 %11744, %11746
  %11748 = load i32, i32* %16, align 4
  %11749 = icmp eq i32 %11714, %11748
  %11750 = or i1 %11747, %11749
  %11751 = load i32, i32* %17, align 4
  %11752 = icmp eq i32 %11714, %11751
  %11753 = or i1 %11750, %11752
  %11754 = load i32, i32* %18, align 4
  %11755 = icmp eq i32 %11714, %11754
  %11756 = or i1 %11753, %11755
  %11757 = load i32, i32* %19, align 4
  %11758 = icmp eq i32 %11714, %11757
  %11759 = or i1 %11756, %11758
  %11760 = load i32, i32* %20, align 4
  %11761 = icmp eq i32 %11714, %11760
  %11762 = or i1 %11759, %11761
  %11763 = load i32, i32* %21, align 4
  %11764 = icmp eq i32 %11714, %11763
  %11765 = or i1 %11762, %11764
  %11766 = load i32, i32* %22, align 4
  %11767 = icmp eq i32 %11714, %11766
  %11768 = or i1 %11765, %11767
  %11769 = load i32, i32* %23, align 4
  %11770 = icmp eq i32 %11714, %11769
  %11771 = or i1 %11768, %11770
  %11772 = load i32, i32* %24, align 4
  %11773 = icmp eq i32 %11714, %11772
  %11774 = or i1 %11771, %11773
  %11775 = load i32, i32* %25, align 4
  %11776 = icmp eq i32 %11714, %11775
  %11777 = or i1 %11774, %11776
  %11778 = load i32, i32* %26, align 4
  %11779 = icmp eq i32 %11714, %11778
  %11780 = or i1 %11777, %11779
  %11781 = load i32, i32* %27, align 4
  %11782 = icmp eq i32 %11714, %11781
  %11783 = or i1 %11780, %11782
  %11784 = load i32, i32* %28, align 4
  %11785 = icmp eq i32 %11714, %11784
  %11786 = or i1 %11783, %11785
  %11787 = load i32, i32* %29, align 4
  %11788 = icmp eq i32 %11714, %11787
  %11789 = or i1 %11786, %11788
  %11790 = load i32, i32* %30, align 4
  %11791 = icmp eq i32 %11714, %11790
  %11792 = or i1 %11789, %11791
  %11793 = load i32, i32* %31, align 4
  %11794 = icmp eq i32 %11714, %11793
  %11795 = or i1 %11792, %11794
  %11796 = load i32, i32* %32, align 4
  %11797 = icmp eq i32 %11714, %11796
  %11798 = or i1 %11795, %11797
  %11799 = load i32, i32* %33, align 4
  %11800 = icmp eq i32 %11714, %11799
  %11801 = or i1 %11798, %11800
  %11802 = load i32, i32* %34, align 4
  %11803 = icmp eq i32 %11714, %11802
  %11804 = or i1 %11801, %11803
  %11805 = load i32, i32* %35, align 4
  %11806 = icmp eq i32 %11714, %11805
  %11807 = or i1 %11804, %11806
  %11808 = load i32, i32* %36, align 4
  %11809 = icmp eq i32 %11714, %11808
  %11810 = or i1 %11807, %11809
  %11811 = load i32, i32* %37, align 4
  %11812 = icmp eq i32 %11714, %11811
  %11813 = or i1 %11810, %11812
  %11814 = load i32, i32* %38, align 4
  %11815 = icmp eq i32 %11714, %11814
  %11816 = or i1 %11813, %11815
  %11817 = load i32, i32* %39, align 4
  %11818 = icmp eq i32 %11714, %11817
  %11819 = or i1 %11816, %11818
  %11820 = load i32, i32* %40, align 4
  %11821 = icmp eq i32 %11714, %11820
  %11822 = or i1 %11819, %11821
  %11823 = load i32, i32* %41, align 4
  %11824 = icmp eq i32 %11714, %11823
  %11825 = or i1 %11822, %11824
  %11826 = load i32, i32* %42, align 4
  %11827 = icmp eq i32 %11714, %11826
  %11828 = or i1 %11825, %11827
  %11829 = load i32, i32* %43, align 4
  %11830 = icmp eq i32 %11714, %11829
  %11831 = or i1 %11828, %11830
  %11832 = load i32, i32* %44, align 4
  %11833 = icmp eq i32 %11714, %11832
  %11834 = or i1 %11831, %11833
  %11835 = load i32, i32* %45, align 4
  %11836 = icmp eq i32 %11714, %11835
  %11837 = or i1 %11834, %11836
  %11838 = load i32, i32* %46, align 4
  %11839 = icmp eq i32 %11714, %11838
  %11840 = or i1 %11837, %11839
  %11841 = load i32, i32* %47, align 4
  %11842 = icmp eq i32 %11714, %11841
  %11843 = or i1 %11840, %11842
  %11844 = load i32, i32* %48, align 4
  %11845 = icmp eq i32 %11714, %11844
  %11846 = or i1 %11843, %11845
  %11847 = load i32, i32* %49, align 4
  %11848 = icmp eq i32 %11714, %11847
  %11849 = or i1 %11846, %11848
  %11850 = load i32, i32* %50, align 4
  %11851 = icmp eq i32 %11714, %11850
  %11852 = or i1 %11849, %11851
  %11853 = load i32, i32* %51, align 4
  %11854 = icmp eq i32 %11714, %11853
  %11855 = or i1 %11852, %11854
  %11856 = load i32, i32* %52, align 4
  %11857 = icmp eq i32 %11714, %11856
  %11858 = or i1 %11855, %11857
  %11859 = load i32, i32* %53, align 4
  %11860 = icmp eq i32 %11714, %11859
  %11861 = or i1 %11858, %11860
  %11862 = load i32, i32* %54, align 4
  %11863 = icmp eq i32 %11714, %11862
  %11864 = or i1 %11861, %11863
  %11865 = load i32, i32* %55, align 4
  %11866 = icmp eq i32 %11714, %11865
  %11867 = or i1 %11864, %11866
  %11868 = load i32, i32* %56, align 4
  %11869 = icmp eq i32 %11714, %11868
  %11870 = or i1 %11867, %11869
  %11871 = load i32, i32* %57, align 4
  %11872 = icmp eq i32 %11714, %11871
  %11873 = or i1 %11870, %11872
  %11874 = load i32, i32* %58, align 4
  %11875 = icmp eq i32 %11714, %11874
  %11876 = or i1 %11873, %11875
  %11877 = load i32, i32* %59, align 4
  %11878 = icmp eq i32 %11714, %11877
  %11879 = or i1 %11876, %11878
  %11880 = load i32, i32* %60, align 4
  %11881 = icmp eq i32 %11714, %11880
  %11882 = or i1 %11879, %11881
  %11883 = load i32, i32* %61, align 4
  %11884 = icmp eq i32 %11714, %11883
  %11885 = or i1 %11882, %11884
  %11886 = load i32, i32* %62, align 4
  %11887 = icmp eq i32 %11714, %11886
  %11888 = or i1 %11885, %11887
  %11889 = getelementptr i8, i8 addrspace(1)* %4, i32 34
  %11890 = zext i1 %11888 to i8
  store i8 %11890, i8 addrspace(1)* %11889, align 1, !nosanitize !3
  %11891 = load i256, i256* %11713, align 4
  %11892 = mul i256 %11891, %11500, !pc !238, !intsan !45
  %11893 = icmp eq i256 %11320, 0
  %11894 = icmp eq i1 %11893, false
  %11895 = trunc i256 4830 to i64
  %jump.check38 = icmp ne i1 %11894, false
  %11896 = load i64, i64* %STACK_DEP_PTR, align 4
  %11897 = add i64 %11896, 1
  store i64 %11897, i64* %STACK_DEP_PTR, align 4
  %11898 = load i64, i64* %STACK_DEP_PTR, align 4
  %11899 = getelementptr i256, i256* %STACK, i64 %11898
  store i256 %11138, i256* %11899, align 4
  %11900 = load i64, i64* %STACK_DEP_PTR, align 4
  %11901 = add i64 %11900, 1
  store i64 %11901, i64* %STACK_DEP_PTR, align 4
  %11902 = load i64, i64* %STACK_DEP_PTR, align 4
  %11903 = getelementptr i256, i256* %STACK, i64 %11902
  store i256 0, i256* %11903, align 4
  %11904 = load i64, i64* %STACK_DEP_PTR, align 4
  %11905 = add i64 %11904, 1
  store i64 %11905, i64* %STACK_DEP_PTR, align 4
  %11906 = load i64, i64* %STACK_DEP_PTR, align 4
  %11907 = getelementptr i256, i256* %STACK, i64 %11906
  store i256 %11320, i256* %11907, align 4
  %11908 = load i64, i64* %STACK_DEP_PTR, align 4
  %11909 = add i64 %11908, 1
  store i64 %11909, i64* %STACK_DEP_PTR, align 4
  %11910 = load i64, i64* %STACK_DEP_PTR, align 4
  %11911 = getelementptr i256, i256* %STACK, i64 %11910
  store i256 %11892, i256* %11911, align 4
  br i1 %jump.check38, label %.4830, label %.4829, !EVMBB !4

.4829:                                            ; preds = %11129
  %11912 = load i64, i64* %remaing_gas, align 4
  %11913 = icmp ugt i64 16, %11912
  br i1 %11913, label %Abort, label %11914

11914:                                            ; preds = %.4829
  %11915 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11916 = xor i32 %11915, 329
  %11917 = urem i32 %11916, 4096
  %11918 = getelementptr i8, i8 addrspace(1)* %4, i32 %11917
  %11919 = load i8, i8 addrspace(1)* %11918, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %11918, align 1, !nosanitize !3
  store i32 164, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11920 = sub i64 %11912, 16
  store i64 %11920, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4830:                                            ; preds = %11129, %JumpTable
  %11921 = load i64, i64* %remaing_gas, align 4
  %11922 = icmp ugt i64 376, %11921
  br i1 %11922, label %Abort, label %11923

11923:                                            ; preds = %.4830
  %11924 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11925 = xor i32 %11924, 2813
  %11926 = urem i32 %11925, 4096
  %11927 = getelementptr i8, i8 addrspace(1)* %4, i32 %11926
  %11928 = load i8, i8 addrspace(1)* %11927, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %11927, align 1, !nosanitize !3
  store i32 1406, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11929 = sub i64 %11921, 376
  store i64 %11929, i64* %remaing_gas, align 4
  %11930 = load i64, i64* %STACK_DEP_PTR, align 4
  %11931 = getelementptr i256, i256* %STACK, i64 %11930
  %11932 = load i256, i256* %11931, align 4
  %11933 = load i64, i64* %STACK_DEP_PTR, align 4
  %11934 = sub i64 %11933, 1
  store i64 %11934, i64* %STACK_DEP_PTR, align 4
  %11935 = load i64, i64* %STACK_DEP_PTR, align 4
  %11936 = getelementptr i256, i256* %STACK, i64 %11935
  %11937 = load i256, i256* %11936, align 4
  %11938 = load i64, i64* %STACK_DEP_PTR, align 4
  %11939 = sub i64 %11938, 1
  store i64 %11939, i64* %STACK_DEP_PTR, align 4
  %11940 = load i64, i64* %STACK_DEP_PTR, align 4
  %11941 = getelementptr i256, i256* %STACK, i64 %11940
  %11942 = load i256, i256* %11941, align 4
  %11943 = load i64, i64* %STACK_DEP_PTR, align 4
  %11944 = sub i64 %11943, 1
  store i64 %11944, i64* %STACK_DEP_PTR, align 4
  %11945 = load i64, i64* %STACK_DEP_PTR, align 4
  %11946 = getelementptr i256, i256* %STACK, i64 %11945
  %11947 = load i256, i256* %11946, align 4
  %11948 = load i64, i64* %STACK_DEP_PTR, align 4
  %11949 = sub i64 %11948, 1
  store i64 %11949, i64* %STACK_DEP_PTR, align 4
  %11950 = load i64, i64* %STACK_DEP_PTR, align 4
  %11951 = getelementptr i256, i256* %STACK, i64 %11950
  %11952 = load i256, i256* %11951, align 4
  %11953 = load i64, i64* %STACK_DEP_PTR, align 4
  %11954 = sub i64 %11953, 1
  store i64 %11954, i64* %STACK_DEP_PTR, align 4
  %11955 = alloca i256, align 8
  store i256 %11932, i256* %11955, align 4
  %11956 = alloca i256, align 8
  store i256 %11937, i256* %11956, align 4
  %11957 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %11955, i256* %11956, i256* %11957), !pc !239, !intsan !6
  %11958 = load i256, i256* %11957, align 4
  %11959 = trunc i256 %11952 to i64
  store i64 %11959, i64* %JMP_TARGET_PTR, align 4
  %11960 = load i64, i64* %STACK_DEP_PTR, align 4
  %11961 = add i64 %11960, 1
  store i64 %11961, i64* %STACK_DEP_PTR, align 4
  %11962 = load i64, i64* %STACK_DEP_PTR, align 4
  %11963 = getelementptr i256, i256* %STACK, i64 %11962
  store i256 %11958, i256* %11963, align 4
  br label %JumpTable, !EVMBB !4

.4838:                                            ; preds = %1381, %JumpTable
  %11964 = load i64, i64* %remaing_gas, align 4
  %11965 = icmp ugt i64 264, %11964
  br i1 %11965, label %Abort, label %11966

11966:                                            ; preds = %.4838
  %11967 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11968 = xor i32 %11967, 1410
  %11969 = urem i32 %11968, 4096
  %11970 = getelementptr i8, i8 addrspace(1)* %4, i32 %11969
  %11971 = load i8, i8 addrspace(1)* %11970, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %11970, align 1, !nosanitize !3
  store i32 705, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %11972 = sub i64 %11964, 264
  store i64 %11972, i64* %remaing_gas, align 4
  %11973 = load i256, i256* %0, align 4
  %11974 = and i256 1461501637330902918203684832716283019655932542975, %11973
  %11975 = and i256 1461501637330902918203684832716283019655932542975, %11974
  %11976 = trunc i256 0 to i64
  %11977 = alloca i256, align 8
  store i256 %11975, i256* %11977, align 4
  %11978 = bitcast i256* %11977 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11976, i8* %11978, i64 32)
  %11979 = add i256 32, 0, !pc !240, !intsan !10
  %11980 = trunc i256 %11979 to i64
  %11981 = alloca i256, align 8
  store i256 3, i256* %11981, align 4
  %11982 = bitcast i256* %11981 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %11980, i8* %11982, i64 32)
  %11983 = add i256 32, %11979, !pc !241, !intsan !10
  %11984 = trunc i256 0 to i32
  %11985 = trunc i256 %11983 to i32
  %11986 = getelementptr inbounds i8, i8* %MEMORY, i32 %11984
  %11987 = alloca i256, align 8
  %11988 = bitcast i256* %11987 to i8*
  call void @__device_sha3(i8* %11986, i32 %11985, i8* %11988)
  %11989 = load i256, i256* %11987, align 4
  %11990 = alloca i256, align 8
  store i256 %11989, i256* %11990, align 4
  %11991 = alloca i256, align 8
  call void @__device_sload(i256* %11990, i256* %11991)
  %11992 = call i32 @__hashword(i256* %11990)
  %11993 = load i32, i32* %5, align 4
  %11994 = icmp eq i32 %11992, %11993
  %11995 = or i1 false, %11994
  %11996 = load i32, i32* %6, align 4
  %11997 = icmp eq i32 %11992, %11996
  %11998 = or i1 %11995, %11997
  %11999 = load i32, i32* %7, align 4
  %12000 = icmp eq i32 %11992, %11999
  %12001 = or i1 %11998, %12000
  %12002 = load i32, i32* %8, align 4
  %12003 = icmp eq i32 %11992, %12002
  %12004 = or i1 %12001, %12003
  %12005 = load i32, i32* %9, align 4
  %12006 = icmp eq i32 %11992, %12005
  %12007 = or i1 %12004, %12006
  %12008 = load i32, i32* %10, align 4
  %12009 = icmp eq i32 %11992, %12008
  %12010 = or i1 %12007, %12009
  %12011 = load i32, i32* %11, align 4
  %12012 = icmp eq i32 %11992, %12011
  %12013 = or i1 %12010, %12012
  %12014 = load i32, i32* %12, align 4
  %12015 = icmp eq i32 %11992, %12014
  %12016 = or i1 %12013, %12015
  %12017 = load i32, i32* %13, align 4
  %12018 = icmp eq i32 %11992, %12017
  %12019 = or i1 %12016, %12018
  %12020 = load i32, i32* %14, align 4
  %12021 = icmp eq i32 %11992, %12020
  %12022 = or i1 %12019, %12021
  %12023 = load i32, i32* %15, align 4
  %12024 = icmp eq i32 %11992, %12023
  %12025 = or i1 %12022, %12024
  %12026 = load i32, i32* %16, align 4
  %12027 = icmp eq i32 %11992, %12026
  %12028 = or i1 %12025, %12027
  %12029 = load i32, i32* %17, align 4
  %12030 = icmp eq i32 %11992, %12029
  %12031 = or i1 %12028, %12030
  %12032 = load i32, i32* %18, align 4
  %12033 = icmp eq i32 %11992, %12032
  %12034 = or i1 %12031, %12033
  %12035 = load i32, i32* %19, align 4
  %12036 = icmp eq i32 %11992, %12035
  %12037 = or i1 %12034, %12036
  %12038 = load i32, i32* %20, align 4
  %12039 = icmp eq i32 %11992, %12038
  %12040 = or i1 %12037, %12039
  %12041 = load i32, i32* %21, align 4
  %12042 = icmp eq i32 %11992, %12041
  %12043 = or i1 %12040, %12042
  %12044 = load i32, i32* %22, align 4
  %12045 = icmp eq i32 %11992, %12044
  %12046 = or i1 %12043, %12045
  %12047 = load i32, i32* %23, align 4
  %12048 = icmp eq i32 %11992, %12047
  %12049 = or i1 %12046, %12048
  %12050 = load i32, i32* %24, align 4
  %12051 = icmp eq i32 %11992, %12050
  %12052 = or i1 %12049, %12051
  %12053 = load i32, i32* %25, align 4
  %12054 = icmp eq i32 %11992, %12053
  %12055 = or i1 %12052, %12054
  %12056 = load i32, i32* %26, align 4
  %12057 = icmp eq i32 %11992, %12056
  %12058 = or i1 %12055, %12057
  %12059 = load i32, i32* %27, align 4
  %12060 = icmp eq i32 %11992, %12059
  %12061 = or i1 %12058, %12060
  %12062 = load i32, i32* %28, align 4
  %12063 = icmp eq i32 %11992, %12062
  %12064 = or i1 %12061, %12063
  %12065 = load i32, i32* %29, align 4
  %12066 = icmp eq i32 %11992, %12065
  %12067 = or i1 %12064, %12066
  %12068 = load i32, i32* %30, align 4
  %12069 = icmp eq i32 %11992, %12068
  %12070 = or i1 %12067, %12069
  %12071 = load i32, i32* %31, align 4
  %12072 = icmp eq i32 %11992, %12071
  %12073 = or i1 %12070, %12072
  %12074 = load i32, i32* %32, align 4
  %12075 = icmp eq i32 %11992, %12074
  %12076 = or i1 %12073, %12075
  %12077 = load i32, i32* %33, align 4
  %12078 = icmp eq i32 %11992, %12077
  %12079 = or i1 %12076, %12078
  %12080 = load i32, i32* %34, align 4
  %12081 = icmp eq i32 %11992, %12080
  %12082 = or i1 %12079, %12081
  %12083 = load i32, i32* %35, align 4
  %12084 = icmp eq i32 %11992, %12083
  %12085 = or i1 %12082, %12084
  %12086 = load i32, i32* %36, align 4
  %12087 = icmp eq i32 %11992, %12086
  %12088 = or i1 %12085, %12087
  %12089 = load i32, i32* %37, align 4
  %12090 = icmp eq i32 %11992, %12089
  %12091 = or i1 %12088, %12090
  %12092 = load i32, i32* %38, align 4
  %12093 = icmp eq i32 %11992, %12092
  %12094 = or i1 %12091, %12093
  %12095 = load i32, i32* %39, align 4
  %12096 = icmp eq i32 %11992, %12095
  %12097 = or i1 %12094, %12096
  %12098 = load i32, i32* %40, align 4
  %12099 = icmp eq i32 %11992, %12098
  %12100 = or i1 %12097, %12099
  %12101 = load i32, i32* %41, align 4
  %12102 = icmp eq i32 %11992, %12101
  %12103 = or i1 %12100, %12102
  %12104 = load i32, i32* %42, align 4
  %12105 = icmp eq i32 %11992, %12104
  %12106 = or i1 %12103, %12105
  %12107 = load i32, i32* %43, align 4
  %12108 = icmp eq i32 %11992, %12107
  %12109 = or i1 %12106, %12108
  %12110 = load i32, i32* %44, align 4
  %12111 = icmp eq i32 %11992, %12110
  %12112 = or i1 %12109, %12111
  %12113 = load i32, i32* %45, align 4
  %12114 = icmp eq i32 %11992, %12113
  %12115 = or i1 %12112, %12114
  %12116 = load i32, i32* %46, align 4
  %12117 = icmp eq i32 %11992, %12116
  %12118 = or i1 %12115, %12117
  %12119 = load i32, i32* %47, align 4
  %12120 = icmp eq i32 %11992, %12119
  %12121 = or i1 %12118, %12120
  %12122 = load i32, i32* %48, align 4
  %12123 = icmp eq i32 %11992, %12122
  %12124 = or i1 %12121, %12123
  %12125 = load i32, i32* %49, align 4
  %12126 = icmp eq i32 %11992, %12125
  %12127 = or i1 %12124, %12126
  %12128 = load i32, i32* %50, align 4
  %12129 = icmp eq i32 %11992, %12128
  %12130 = or i1 %12127, %12129
  %12131 = load i32, i32* %51, align 4
  %12132 = icmp eq i32 %11992, %12131
  %12133 = or i1 %12130, %12132
  %12134 = load i32, i32* %52, align 4
  %12135 = icmp eq i32 %11992, %12134
  %12136 = or i1 %12133, %12135
  %12137 = load i32, i32* %53, align 4
  %12138 = icmp eq i32 %11992, %12137
  %12139 = or i1 %12136, %12138
  %12140 = load i32, i32* %54, align 4
  %12141 = icmp eq i32 %11992, %12140
  %12142 = or i1 %12139, %12141
  %12143 = load i32, i32* %55, align 4
  %12144 = icmp eq i32 %11992, %12143
  %12145 = or i1 %12142, %12144
  %12146 = load i32, i32* %56, align 4
  %12147 = icmp eq i32 %11992, %12146
  %12148 = or i1 %12145, %12147
  %12149 = load i32, i32* %57, align 4
  %12150 = icmp eq i32 %11992, %12149
  %12151 = or i1 %12148, %12150
  %12152 = load i32, i32* %58, align 4
  %12153 = icmp eq i32 %11992, %12152
  %12154 = or i1 %12151, %12153
  %12155 = load i32, i32* %59, align 4
  %12156 = icmp eq i32 %11992, %12155
  %12157 = or i1 %12154, %12156
  %12158 = load i32, i32* %60, align 4
  %12159 = icmp eq i32 %11992, %12158
  %12160 = or i1 %12157, %12159
  %12161 = load i32, i32* %61, align 4
  %12162 = icmp eq i32 %11992, %12161
  %12163 = or i1 %12160, %12162
  %12164 = load i32, i32* %62, align 4
  %12165 = icmp eq i32 %11992, %12164
  %12166 = or i1 %12163, %12165
  %12167 = getelementptr i8, i8 addrspace(1)* %4, i32 35
  %12168 = zext i1 %12166 to i8
  store i8 %12168, i8 addrspace(1)* %12167, align 1, !nosanitize !3
  %12169 = load i256, i256* %11991, align 4
  %12170 = icmp eq i256 %12169, 0
  %12171 = icmp eq i1 %12170, false
  %12172 = trunc i256 4915 to i64
  %jump.check42 = icmp ne i1 %12171, false
  br i1 %jump.check42, label %.4915, label %.4911, !EVMBB !4

.4911:                                            ; preds = %11966
  %12173 = load i64, i64* %remaing_gas, align 4
  %12174 = icmp ugt i64 16, %12173
  br i1 %12174, label %Abort, label %12175

12175:                                            ; preds = %.4911
  %12176 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12177 = xor i32 %12176, 3662
  %12178 = urem i32 %12177, 4096
  %12179 = getelementptr i8, i8 addrspace(1)* %4, i32 %12178
  %12180 = load i8, i8 addrspace(1)* %12179, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12179, align 1, !nosanitize !3
  store i32 1831, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12181 = sub i64 %12173, 16
  store i64 %12181, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4915:                                            ; preds = %11966, %JumpTable
  %12182 = load i64, i64* %remaing_gas, align 4
  %12183 = icmp ugt i64 168, %12182
  br i1 %12183, label %Abort, label %12184

12184:                                            ; preds = %.4915
  %12185 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12186 = xor i32 %12185, 1449
  %12187 = urem i32 %12186, 4096
  %12188 = getelementptr i8, i8 addrspace(1)* %4, i32 %12187
  %12189 = load i8, i8 addrspace(1)* %12188, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12188, align 1, !nosanitize !3
  store i32 724, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12190 = sub i64 %12182, 168
  store i64 %12190, i64* %remaing_gas, align 4
  %12191 = add i256 0, 9, !pc !242, !intsan !10
  %12192 = alloca i256, align 8
  store i256 %12191, i256* %12192, align 4
  %12193 = alloca i256, align 8
  call void @__device_sload(i256* %12192, i256* %12193)
  %12194 = call i32 @__hashword(i256* %12192)
  %12195 = load i32, i32* %5, align 4
  %12196 = icmp eq i32 %12194, %12195
  %12197 = or i1 false, %12196
  %12198 = load i32, i32* %6, align 4
  %12199 = icmp eq i32 %12194, %12198
  %12200 = or i1 %12197, %12199
  %12201 = load i32, i32* %7, align 4
  %12202 = icmp eq i32 %12194, %12201
  %12203 = or i1 %12200, %12202
  %12204 = load i32, i32* %8, align 4
  %12205 = icmp eq i32 %12194, %12204
  %12206 = or i1 %12203, %12205
  %12207 = load i32, i32* %9, align 4
  %12208 = icmp eq i32 %12194, %12207
  %12209 = or i1 %12206, %12208
  %12210 = load i32, i32* %10, align 4
  %12211 = icmp eq i32 %12194, %12210
  %12212 = or i1 %12209, %12211
  %12213 = load i32, i32* %11, align 4
  %12214 = icmp eq i32 %12194, %12213
  %12215 = or i1 %12212, %12214
  %12216 = load i32, i32* %12, align 4
  %12217 = icmp eq i32 %12194, %12216
  %12218 = or i1 %12215, %12217
  %12219 = load i32, i32* %13, align 4
  %12220 = icmp eq i32 %12194, %12219
  %12221 = or i1 %12218, %12220
  %12222 = load i32, i32* %14, align 4
  %12223 = icmp eq i32 %12194, %12222
  %12224 = or i1 %12221, %12223
  %12225 = load i32, i32* %15, align 4
  %12226 = icmp eq i32 %12194, %12225
  %12227 = or i1 %12224, %12226
  %12228 = load i32, i32* %16, align 4
  %12229 = icmp eq i32 %12194, %12228
  %12230 = or i1 %12227, %12229
  %12231 = load i32, i32* %17, align 4
  %12232 = icmp eq i32 %12194, %12231
  %12233 = or i1 %12230, %12232
  %12234 = load i32, i32* %18, align 4
  %12235 = icmp eq i32 %12194, %12234
  %12236 = or i1 %12233, %12235
  %12237 = load i32, i32* %19, align 4
  %12238 = icmp eq i32 %12194, %12237
  %12239 = or i1 %12236, %12238
  %12240 = load i32, i32* %20, align 4
  %12241 = icmp eq i32 %12194, %12240
  %12242 = or i1 %12239, %12241
  %12243 = load i32, i32* %21, align 4
  %12244 = icmp eq i32 %12194, %12243
  %12245 = or i1 %12242, %12244
  %12246 = load i32, i32* %22, align 4
  %12247 = icmp eq i32 %12194, %12246
  %12248 = or i1 %12245, %12247
  %12249 = load i32, i32* %23, align 4
  %12250 = icmp eq i32 %12194, %12249
  %12251 = or i1 %12248, %12250
  %12252 = load i32, i32* %24, align 4
  %12253 = icmp eq i32 %12194, %12252
  %12254 = or i1 %12251, %12253
  %12255 = load i32, i32* %25, align 4
  %12256 = icmp eq i32 %12194, %12255
  %12257 = or i1 %12254, %12256
  %12258 = load i32, i32* %26, align 4
  %12259 = icmp eq i32 %12194, %12258
  %12260 = or i1 %12257, %12259
  %12261 = load i32, i32* %27, align 4
  %12262 = icmp eq i32 %12194, %12261
  %12263 = or i1 %12260, %12262
  %12264 = load i32, i32* %28, align 4
  %12265 = icmp eq i32 %12194, %12264
  %12266 = or i1 %12263, %12265
  %12267 = load i32, i32* %29, align 4
  %12268 = icmp eq i32 %12194, %12267
  %12269 = or i1 %12266, %12268
  %12270 = load i32, i32* %30, align 4
  %12271 = icmp eq i32 %12194, %12270
  %12272 = or i1 %12269, %12271
  %12273 = load i32, i32* %31, align 4
  %12274 = icmp eq i32 %12194, %12273
  %12275 = or i1 %12272, %12274
  %12276 = load i32, i32* %32, align 4
  %12277 = icmp eq i32 %12194, %12276
  %12278 = or i1 %12275, %12277
  %12279 = load i32, i32* %33, align 4
  %12280 = icmp eq i32 %12194, %12279
  %12281 = or i1 %12278, %12280
  %12282 = load i32, i32* %34, align 4
  %12283 = icmp eq i32 %12194, %12282
  %12284 = or i1 %12281, %12283
  %12285 = load i32, i32* %35, align 4
  %12286 = icmp eq i32 %12194, %12285
  %12287 = or i1 %12284, %12286
  %12288 = load i32, i32* %36, align 4
  %12289 = icmp eq i32 %12194, %12288
  %12290 = or i1 %12287, %12289
  %12291 = load i32, i32* %37, align 4
  %12292 = icmp eq i32 %12194, %12291
  %12293 = or i1 %12290, %12292
  %12294 = load i32, i32* %38, align 4
  %12295 = icmp eq i32 %12194, %12294
  %12296 = or i1 %12293, %12295
  %12297 = load i32, i32* %39, align 4
  %12298 = icmp eq i32 %12194, %12297
  %12299 = or i1 %12296, %12298
  %12300 = load i32, i32* %40, align 4
  %12301 = icmp eq i32 %12194, %12300
  %12302 = or i1 %12299, %12301
  %12303 = load i32, i32* %41, align 4
  %12304 = icmp eq i32 %12194, %12303
  %12305 = or i1 %12302, %12304
  %12306 = load i32, i32* %42, align 4
  %12307 = icmp eq i32 %12194, %12306
  %12308 = or i1 %12305, %12307
  %12309 = load i32, i32* %43, align 4
  %12310 = icmp eq i32 %12194, %12309
  %12311 = or i1 %12308, %12310
  %12312 = load i32, i32* %44, align 4
  %12313 = icmp eq i32 %12194, %12312
  %12314 = or i1 %12311, %12313
  %12315 = load i32, i32* %45, align 4
  %12316 = icmp eq i32 %12194, %12315
  %12317 = or i1 %12314, %12316
  %12318 = load i32, i32* %46, align 4
  %12319 = icmp eq i32 %12194, %12318
  %12320 = or i1 %12317, %12319
  %12321 = load i32, i32* %47, align 4
  %12322 = icmp eq i32 %12194, %12321
  %12323 = or i1 %12320, %12322
  %12324 = load i32, i32* %48, align 4
  %12325 = icmp eq i32 %12194, %12324
  %12326 = or i1 %12323, %12325
  %12327 = load i32, i32* %49, align 4
  %12328 = icmp eq i32 %12194, %12327
  %12329 = or i1 %12326, %12328
  %12330 = load i32, i32* %50, align 4
  %12331 = icmp eq i32 %12194, %12330
  %12332 = or i1 %12329, %12331
  %12333 = load i32, i32* %51, align 4
  %12334 = icmp eq i32 %12194, %12333
  %12335 = or i1 %12332, %12334
  %12336 = load i32, i32* %52, align 4
  %12337 = icmp eq i32 %12194, %12336
  %12338 = or i1 %12335, %12337
  %12339 = load i32, i32* %53, align 4
  %12340 = icmp eq i32 %12194, %12339
  %12341 = or i1 %12338, %12340
  %12342 = load i32, i32* %54, align 4
  %12343 = icmp eq i32 %12194, %12342
  %12344 = or i1 %12341, %12343
  %12345 = load i32, i32* %55, align 4
  %12346 = icmp eq i32 %12194, %12345
  %12347 = or i1 %12344, %12346
  %12348 = load i32, i32* %56, align 4
  %12349 = icmp eq i32 %12194, %12348
  %12350 = or i1 %12347, %12349
  %12351 = load i32, i32* %57, align 4
  %12352 = icmp eq i32 %12194, %12351
  %12353 = or i1 %12350, %12352
  %12354 = load i32, i32* %58, align 4
  %12355 = icmp eq i32 %12194, %12354
  %12356 = or i1 %12353, %12355
  %12357 = load i32, i32* %59, align 4
  %12358 = icmp eq i32 %12194, %12357
  %12359 = or i1 %12356, %12358
  %12360 = load i32, i32* %60, align 4
  %12361 = icmp eq i32 %12194, %12360
  %12362 = or i1 %12359, %12361
  %12363 = load i32, i32* %61, align 4
  %12364 = icmp eq i32 %12194, %12363
  %12365 = or i1 %12362, %12364
  %12366 = load i32, i32* %62, align 4
  %12367 = icmp eq i32 %12194, %12366
  %12368 = or i1 %12365, %12367
  %12369 = getelementptr i8, i8 addrspace(1)* %4, i32 36
  %12370 = zext i1 %12368 to i8
  store i8 %12370, i8 addrspace(1)* %12369, align 1, !nosanitize !3
  %12371 = load i256, i256* %12193, align 4
  %12372 = alloca i256, align 8
  store i256 %12371, i256* %12372, align 4
  %12373 = alloca i256, align 8
  store i256 1, i256* %12373, align 4
  %12374 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %12372, i256* %12373, i256* %12374), !pc !243, !intsan !6
  %12375 = load i256, i256* %12374, align 4
  %12376 = and i256 1461501637330902918203684832716283019655932542975, %12375
  %12377 = and i256 1461501637330902918203684832716283019655932542975, %12376
  %12378 = icmp eq i256 %12377, 0
  %12379 = icmp eq i1 %12378, false
  %12380 = trunc i256 4988 to i64
  %jump.check47 = icmp ne i1 %12379, false
  br i1 %jump.check47, label %.4988, label %.4984, !EVMBB !4

.4984:                                            ; preds = %12184
  %12381 = load i64, i64* %remaing_gas, align 4
  %12382 = icmp ugt i64 16, %12381
  br i1 %12382, label %Abort, label %12383

12383:                                            ; preds = %.4984
  %12384 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12385 = xor i32 %12384, 2568
  %12386 = urem i32 %12385, 4096
  %12387 = getelementptr i8, i8 addrspace(1)* %4, i32 %12386
  %12388 = load i8, i8 addrspace(1)* %12387, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12387, align 1, !nosanitize !3
  store i32 1284, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12389 = sub i64 %12381, 16
  store i64 %12389, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.4988:                                            ; preds = %12184, %JumpTable
  %12390 = load i64, i64* %remaing_gas, align 4
  %12391 = icmp ugt i64 152, %12390
  br i1 %12391, label %Abort, label %12392

12392:                                            ; preds = %.4988
  %12393 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12394 = xor i32 %12393, 3184
  %12395 = urem i32 %12394, 4096
  %12396 = getelementptr i8, i8 addrspace(1)* %4, i32 %12395
  %12397 = load i8, i8 addrspace(1)* %12396, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12396, align 1, !nosanitize !3
  store i32 1592, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12398 = sub i64 %12390, 152
  store i64 %12398, i64* %remaing_gas, align 4
  %12399 = alloca i256, align 8
  store i256 8, i256* %12399, align 4
  %12400 = alloca i256, align 8
  call void @__device_sload(i256* %12399, i256* %12400)
  %12401 = call i32 @__hashword(i256* %12399)
  %12402 = load i32, i32* %5, align 4
  %12403 = icmp eq i32 %12401, %12402
  %12404 = or i1 false, %12403
  %12405 = load i32, i32* %6, align 4
  %12406 = icmp eq i32 %12401, %12405
  %12407 = or i1 %12404, %12406
  %12408 = load i32, i32* %7, align 4
  %12409 = icmp eq i32 %12401, %12408
  %12410 = or i1 %12407, %12409
  %12411 = load i32, i32* %8, align 4
  %12412 = icmp eq i32 %12401, %12411
  %12413 = or i1 %12410, %12412
  %12414 = load i32, i32* %9, align 4
  %12415 = icmp eq i32 %12401, %12414
  %12416 = or i1 %12413, %12415
  %12417 = load i32, i32* %10, align 4
  %12418 = icmp eq i32 %12401, %12417
  %12419 = or i1 %12416, %12418
  %12420 = load i32, i32* %11, align 4
  %12421 = icmp eq i32 %12401, %12420
  %12422 = or i1 %12419, %12421
  %12423 = load i32, i32* %12, align 4
  %12424 = icmp eq i32 %12401, %12423
  %12425 = or i1 %12422, %12424
  %12426 = load i32, i32* %13, align 4
  %12427 = icmp eq i32 %12401, %12426
  %12428 = or i1 %12425, %12427
  %12429 = load i32, i32* %14, align 4
  %12430 = icmp eq i32 %12401, %12429
  %12431 = or i1 %12428, %12430
  %12432 = load i32, i32* %15, align 4
  %12433 = icmp eq i32 %12401, %12432
  %12434 = or i1 %12431, %12433
  %12435 = load i32, i32* %16, align 4
  %12436 = icmp eq i32 %12401, %12435
  %12437 = or i1 %12434, %12436
  %12438 = load i32, i32* %17, align 4
  %12439 = icmp eq i32 %12401, %12438
  %12440 = or i1 %12437, %12439
  %12441 = load i32, i32* %18, align 4
  %12442 = icmp eq i32 %12401, %12441
  %12443 = or i1 %12440, %12442
  %12444 = load i32, i32* %19, align 4
  %12445 = icmp eq i32 %12401, %12444
  %12446 = or i1 %12443, %12445
  %12447 = load i32, i32* %20, align 4
  %12448 = icmp eq i32 %12401, %12447
  %12449 = or i1 %12446, %12448
  %12450 = load i32, i32* %21, align 4
  %12451 = icmp eq i32 %12401, %12450
  %12452 = or i1 %12449, %12451
  %12453 = load i32, i32* %22, align 4
  %12454 = icmp eq i32 %12401, %12453
  %12455 = or i1 %12452, %12454
  %12456 = load i32, i32* %23, align 4
  %12457 = icmp eq i32 %12401, %12456
  %12458 = or i1 %12455, %12457
  %12459 = load i32, i32* %24, align 4
  %12460 = icmp eq i32 %12401, %12459
  %12461 = or i1 %12458, %12460
  %12462 = load i32, i32* %25, align 4
  %12463 = icmp eq i32 %12401, %12462
  %12464 = or i1 %12461, %12463
  %12465 = load i32, i32* %26, align 4
  %12466 = icmp eq i32 %12401, %12465
  %12467 = or i1 %12464, %12466
  %12468 = load i32, i32* %27, align 4
  %12469 = icmp eq i32 %12401, %12468
  %12470 = or i1 %12467, %12469
  %12471 = load i32, i32* %28, align 4
  %12472 = icmp eq i32 %12401, %12471
  %12473 = or i1 %12470, %12472
  %12474 = load i32, i32* %29, align 4
  %12475 = icmp eq i32 %12401, %12474
  %12476 = or i1 %12473, %12475
  %12477 = load i32, i32* %30, align 4
  %12478 = icmp eq i32 %12401, %12477
  %12479 = or i1 %12476, %12478
  %12480 = load i32, i32* %31, align 4
  %12481 = icmp eq i32 %12401, %12480
  %12482 = or i1 %12479, %12481
  %12483 = load i32, i32* %32, align 4
  %12484 = icmp eq i32 %12401, %12483
  %12485 = or i1 %12482, %12484
  %12486 = load i32, i32* %33, align 4
  %12487 = icmp eq i32 %12401, %12486
  %12488 = or i1 %12485, %12487
  %12489 = load i32, i32* %34, align 4
  %12490 = icmp eq i32 %12401, %12489
  %12491 = or i1 %12488, %12490
  %12492 = load i32, i32* %35, align 4
  %12493 = icmp eq i32 %12401, %12492
  %12494 = or i1 %12491, %12493
  %12495 = load i32, i32* %36, align 4
  %12496 = icmp eq i32 %12401, %12495
  %12497 = or i1 %12494, %12496
  %12498 = load i32, i32* %37, align 4
  %12499 = icmp eq i32 %12401, %12498
  %12500 = or i1 %12497, %12499
  %12501 = load i32, i32* %38, align 4
  %12502 = icmp eq i32 %12401, %12501
  %12503 = or i1 %12500, %12502
  %12504 = load i32, i32* %39, align 4
  %12505 = icmp eq i32 %12401, %12504
  %12506 = or i1 %12503, %12505
  %12507 = load i32, i32* %40, align 4
  %12508 = icmp eq i32 %12401, %12507
  %12509 = or i1 %12506, %12508
  %12510 = load i32, i32* %41, align 4
  %12511 = icmp eq i32 %12401, %12510
  %12512 = or i1 %12509, %12511
  %12513 = load i32, i32* %42, align 4
  %12514 = icmp eq i32 %12401, %12513
  %12515 = or i1 %12512, %12514
  %12516 = load i32, i32* %43, align 4
  %12517 = icmp eq i32 %12401, %12516
  %12518 = or i1 %12515, %12517
  %12519 = load i32, i32* %44, align 4
  %12520 = icmp eq i32 %12401, %12519
  %12521 = or i1 %12518, %12520
  %12522 = load i32, i32* %45, align 4
  %12523 = icmp eq i32 %12401, %12522
  %12524 = or i1 %12521, %12523
  %12525 = load i32, i32* %46, align 4
  %12526 = icmp eq i32 %12401, %12525
  %12527 = or i1 %12524, %12526
  %12528 = load i32, i32* %47, align 4
  %12529 = icmp eq i32 %12401, %12528
  %12530 = or i1 %12527, %12529
  %12531 = load i32, i32* %48, align 4
  %12532 = icmp eq i32 %12401, %12531
  %12533 = or i1 %12530, %12532
  %12534 = load i32, i32* %49, align 4
  %12535 = icmp eq i32 %12401, %12534
  %12536 = or i1 %12533, %12535
  %12537 = load i32, i32* %50, align 4
  %12538 = icmp eq i32 %12401, %12537
  %12539 = or i1 %12536, %12538
  %12540 = load i32, i32* %51, align 4
  %12541 = icmp eq i32 %12401, %12540
  %12542 = or i1 %12539, %12541
  %12543 = load i32, i32* %52, align 4
  %12544 = icmp eq i32 %12401, %12543
  %12545 = or i1 %12542, %12544
  %12546 = load i32, i32* %53, align 4
  %12547 = icmp eq i32 %12401, %12546
  %12548 = or i1 %12545, %12547
  %12549 = load i32, i32* %54, align 4
  %12550 = icmp eq i32 %12401, %12549
  %12551 = or i1 %12548, %12550
  %12552 = load i32, i32* %55, align 4
  %12553 = icmp eq i32 %12401, %12552
  %12554 = or i1 %12551, %12553
  %12555 = load i32, i32* %56, align 4
  %12556 = icmp eq i32 %12401, %12555
  %12557 = or i1 %12554, %12556
  %12558 = load i32, i32* %57, align 4
  %12559 = icmp eq i32 %12401, %12558
  %12560 = or i1 %12557, %12559
  %12561 = load i32, i32* %58, align 4
  %12562 = icmp eq i32 %12401, %12561
  %12563 = or i1 %12560, %12562
  %12564 = load i32, i32* %59, align 4
  %12565 = icmp eq i32 %12401, %12564
  %12566 = or i1 %12563, %12565
  %12567 = load i32, i32* %60, align 4
  %12568 = icmp eq i32 %12401, %12567
  %12569 = or i1 %12566, %12568
  %12570 = load i32, i32* %61, align 4
  %12571 = icmp eq i32 %12401, %12570
  %12572 = or i1 %12569, %12571
  %12573 = load i32, i32* %62, align 4
  %12574 = icmp eq i32 %12401, %12573
  %12575 = or i1 %12572, %12574
  %12576 = getelementptr i8, i8 addrspace(1)* %4, i32 37
  %12577 = zext i1 %12575 to i8
  store i8 %12577, i8 addrspace(1)* %12576, align 1, !nosanitize !3
  %12578 = load i256, i256* %12400, align 4
  %12579 = alloca i256, align 8
  store i256 %12578, i256* %12579, align 4
  %12580 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %12580, align 4
  %12581 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %12579, i256* %12580, i256* %12581), !pc !244, !intsan !6
  %12582 = load i256, i256* %12581, align 4
  %12583 = and i256 255, %12582
  %12584 = icmp eq i256 %12583, 0
  %12585 = icmp eq i1 %12584, false
  %12586 = trunc i256 5015 to i64
  %jump.check54 = icmp ne i1 %12585, false
  br i1 %jump.check54, label %.5015, label %.5011, !EVMBB !4

.5011:                                            ; preds = %12392
  %12587 = load i64, i64* %remaing_gas, align 4
  %12588 = icmp ugt i64 16, %12587
  br i1 %12588, label %Abort, label %12589

12589:                                            ; preds = %.5011
  %12590 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12591 = xor i32 %12590, 4052
  %12592 = urem i32 %12591, 4096
  %12593 = getelementptr i8, i8 addrspace(1)* %4, i32 %12592
  %12594 = load i8, i8 addrspace(1)* %12593, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12593, align 1, !nosanitize !3
  store i32 2026, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12595 = sub i64 %12587, 16
  store i64 %12595, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.5015:                                            ; preds = %12392, %JumpTable
  %12596 = load i64, i64* %remaing_gas, align 4
  %12597 = icmp ugt i64 896, %12596
  br i1 %12597, label %Abort, label %12598

12598:                                            ; preds = %.5015
  %12599 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12600 = xor i32 %12599, 2994
  %12601 = urem i32 %12600, 4096
  %12602 = getelementptr i8, i8 addrspace(1)* %4, i32 %12601
  %12603 = load i8, i8 addrspace(1)* %12602, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %12602, align 1, !nosanitize !3
  store i32 1497, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %12604 = sub i64 %12596, 896
  store i64 %12604, i64* %remaing_gas, align 4
  %12605 = load i64, i64* %STACK_DEP_PTR, align 4
  %12606 = getelementptr i256, i256* %STACK, i64 %12605
  %12607 = load i256, i256* %12606, align 4
  %12608 = load i64, i64* %STACK_DEP_PTR, align 4
  %12609 = sub i64 %12608, 1
  store i64 %12609, i64* %STACK_DEP_PTR, align 4
  %12610 = load i64, i64* %STACK_DEP_PTR, align 4
  %12611 = getelementptr i256, i256* %STACK, i64 %12610
  %12612 = load i256, i256* %12611, align 4
  %12613 = load i64, i64* %STACK_DEP_PTR, align 4
  %12614 = sub i64 %12613, 1
  store i64 %12614, i64* %STACK_DEP_PTR, align 4
  %12615 = load i256, i256* %0, align 4
  %12616 = and i256 1461501637330902918203684832716283019655932542975, %12615
  %12617 = and i256 1461501637330902918203684832716283019655932542975, %12616
  %12618 = trunc i256 0 to i64
  %12619 = alloca i256, align 8
  store i256 %12617, i256* %12619, align 4
  %12620 = bitcast i256* %12619 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %12618, i8* %12620, i64 32)
  %12621 = add i256 32, 0, !pc !245, !intsan !10
  %12622 = trunc i256 %12621 to i64
  %12623 = alloca i256, align 8
  store i256 3, i256* %12623, align 4
  %12624 = bitcast i256* %12623 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %12622, i8* %12624, i64 32)
  %12625 = add i256 32, %12621, !pc !246, !intsan !10
  %12626 = trunc i256 0 to i32
  %12627 = trunc i256 %12625 to i32
  %12628 = getelementptr inbounds i8, i8* %MEMORY, i32 %12626
  %12629 = alloca i256, align 8
  %12630 = bitcast i256* %12629 to i8*
  call void @__device_sha3(i8* %12628, i32 %12627, i8* %12630)
  %12631 = load i256, i256* %12629, align 4
  %12632 = alloca i256, align 8
  store i256 %12631, i256* %12632, align 4
  %12633 = alloca i256, align 8
  call void @__device_sload(i256* %12632, i256* %12633)
  %12634 = call i32 @__hashword(i256* %12632)
  %12635 = load i32, i32* %5, align 4
  %12636 = icmp eq i32 %12634, %12635
  %12637 = or i1 false, %12636
  %12638 = load i32, i32* %6, align 4
  %12639 = icmp eq i32 %12634, %12638
  %12640 = or i1 %12637, %12639
  %12641 = load i32, i32* %7, align 4
  %12642 = icmp eq i32 %12634, %12641
  %12643 = or i1 %12640, %12642
  %12644 = load i32, i32* %8, align 4
  %12645 = icmp eq i32 %12634, %12644
  %12646 = or i1 %12643, %12645
  %12647 = load i32, i32* %9, align 4
  %12648 = icmp eq i32 %12634, %12647
  %12649 = or i1 %12646, %12648
  %12650 = load i32, i32* %10, align 4
  %12651 = icmp eq i32 %12634, %12650
  %12652 = or i1 %12649, %12651
  %12653 = load i32, i32* %11, align 4
  %12654 = icmp eq i32 %12634, %12653
  %12655 = or i1 %12652, %12654
  %12656 = load i32, i32* %12, align 4
  %12657 = icmp eq i32 %12634, %12656
  %12658 = or i1 %12655, %12657
  %12659 = load i32, i32* %13, align 4
  %12660 = icmp eq i32 %12634, %12659
  %12661 = or i1 %12658, %12660
  %12662 = load i32, i32* %14, align 4
  %12663 = icmp eq i32 %12634, %12662
  %12664 = or i1 %12661, %12663
  %12665 = load i32, i32* %15, align 4
  %12666 = icmp eq i32 %12634, %12665
  %12667 = or i1 %12664, %12666
  %12668 = load i32, i32* %16, align 4
  %12669 = icmp eq i32 %12634, %12668
  %12670 = or i1 %12667, %12669
  %12671 = load i32, i32* %17, align 4
  %12672 = icmp eq i32 %12634, %12671
  %12673 = or i1 %12670, %12672
  %12674 = load i32, i32* %18, align 4
  %12675 = icmp eq i32 %12634, %12674
  %12676 = or i1 %12673, %12675
  %12677 = load i32, i32* %19, align 4
  %12678 = icmp eq i32 %12634, %12677
  %12679 = or i1 %12676, %12678
  %12680 = load i32, i32* %20, align 4
  %12681 = icmp eq i32 %12634, %12680
  %12682 = or i1 %12679, %12681
  %12683 = load i32, i32* %21, align 4
  %12684 = icmp eq i32 %12634, %12683
  %12685 = or i1 %12682, %12684
  %12686 = load i32, i32* %22, align 4
  %12687 = icmp eq i32 %12634, %12686
  %12688 = or i1 %12685, %12687
  %12689 = load i32, i32* %23, align 4
  %12690 = icmp eq i32 %12634, %12689
  %12691 = or i1 %12688, %12690
  %12692 = load i32, i32* %24, align 4
  %12693 = icmp eq i32 %12634, %12692
  %12694 = or i1 %12691, %12693
  %12695 = load i32, i32* %25, align 4
  %12696 = icmp eq i32 %12634, %12695
  %12697 = or i1 %12694, %12696
  %12698 = load i32, i32* %26, align 4
  %12699 = icmp eq i32 %12634, %12698
  %12700 = or i1 %12697, %12699
  %12701 = load i32, i32* %27, align 4
  %12702 = icmp eq i32 %12634, %12701
  %12703 = or i1 %12700, %12702
  %12704 = load i32, i32* %28, align 4
  %12705 = icmp eq i32 %12634, %12704
  %12706 = or i1 %12703, %12705
  %12707 = load i32, i32* %29, align 4
  %12708 = icmp eq i32 %12634, %12707
  %12709 = or i1 %12706, %12708
  %12710 = load i32, i32* %30, align 4
  %12711 = icmp eq i32 %12634, %12710
  %12712 = or i1 %12709, %12711
  %12713 = load i32, i32* %31, align 4
  %12714 = icmp eq i32 %12634, %12713
  %12715 = or i1 %12712, %12714
  %12716 = load i32, i32* %32, align 4
  %12717 = icmp eq i32 %12634, %12716
  %12718 = or i1 %12715, %12717
  %12719 = load i32, i32* %33, align 4
  %12720 = icmp eq i32 %12634, %12719
  %12721 = or i1 %12718, %12720
  %12722 = load i32, i32* %34, align 4
  %12723 = icmp eq i32 %12634, %12722
  %12724 = or i1 %12721, %12723
  %12725 = load i32, i32* %35, align 4
  %12726 = icmp eq i32 %12634, %12725
  %12727 = or i1 %12724, %12726
  %12728 = load i32, i32* %36, align 4
  %12729 = icmp eq i32 %12634, %12728
  %12730 = or i1 %12727, %12729
  %12731 = load i32, i32* %37, align 4
  %12732 = icmp eq i32 %12634, %12731
  %12733 = or i1 %12730, %12732
  %12734 = load i32, i32* %38, align 4
  %12735 = icmp eq i32 %12634, %12734
  %12736 = or i1 %12733, %12735
  %12737 = load i32, i32* %39, align 4
  %12738 = icmp eq i32 %12634, %12737
  %12739 = or i1 %12736, %12738
  %12740 = load i32, i32* %40, align 4
  %12741 = icmp eq i32 %12634, %12740
  %12742 = or i1 %12739, %12741
  %12743 = load i32, i32* %41, align 4
  %12744 = icmp eq i32 %12634, %12743
  %12745 = or i1 %12742, %12744
  %12746 = load i32, i32* %42, align 4
  %12747 = icmp eq i32 %12634, %12746
  %12748 = or i1 %12745, %12747
  %12749 = load i32, i32* %43, align 4
  %12750 = icmp eq i32 %12634, %12749
  %12751 = or i1 %12748, %12750
  %12752 = load i32, i32* %44, align 4
  %12753 = icmp eq i32 %12634, %12752
  %12754 = or i1 %12751, %12753
  %12755 = load i32, i32* %45, align 4
  %12756 = icmp eq i32 %12634, %12755
  %12757 = or i1 %12754, %12756
  %12758 = load i32, i32* %46, align 4
  %12759 = icmp eq i32 %12634, %12758
  %12760 = or i1 %12757, %12759
  %12761 = load i32, i32* %47, align 4
  %12762 = icmp eq i32 %12634, %12761
  %12763 = or i1 %12760, %12762
  %12764 = load i32, i32* %48, align 4
  %12765 = icmp eq i32 %12634, %12764
  %12766 = or i1 %12763, %12765
  %12767 = load i32, i32* %49, align 4
  %12768 = icmp eq i32 %12634, %12767
  %12769 = or i1 %12766, %12768
  %12770 = load i32, i32* %50, align 4
  %12771 = icmp eq i32 %12634, %12770
  %12772 = or i1 %12769, %12771
  %12773 = load i32, i32* %51, align 4
  %12774 = icmp eq i32 %12634, %12773
  %12775 = or i1 %12772, %12774
  %12776 = load i32, i32* %52, align 4
  %12777 = icmp eq i32 %12634, %12776
  %12778 = or i1 %12775, %12777
  %12779 = load i32, i32* %53, align 4
  %12780 = icmp eq i32 %12634, %12779
  %12781 = or i1 %12778, %12780
  %12782 = load i32, i32* %54, align 4
  %12783 = icmp eq i32 %12634, %12782
  %12784 = or i1 %12781, %12783
  %12785 = load i32, i32* %55, align 4
  %12786 = icmp eq i32 %12634, %12785
  %12787 = or i1 %12784, %12786
  %12788 = load i32, i32* %56, align 4
  %12789 = icmp eq i32 %12634, %12788
  %12790 = or i1 %12787, %12789
  %12791 = load i32, i32* %57, align 4
  %12792 = icmp eq i32 %12634, %12791
  %12793 = or i1 %12790, %12792
  %12794 = load i32, i32* %58, align 4
  %12795 = icmp eq i32 %12634, %12794
  %12796 = or i1 %12793, %12795
  %12797 = load i32, i32* %59, align 4
  %12798 = icmp eq i32 %12634, %12797
  %12799 = or i1 %12796, %12798
  %12800 = load i32, i32* %60, align 4
  %12801 = icmp eq i32 %12634, %12800
  %12802 = or i1 %12799, %12801
  %12803 = load i32, i32* %61, align 4
  %12804 = icmp eq i32 %12634, %12803
  %12805 = or i1 %12802, %12804
  %12806 = load i32, i32* %62, align 4
  %12807 = icmp eq i32 %12634, %12806
  %12808 = or i1 %12805, %12807
  %12809 = getelementptr i8, i8 addrspace(1)* %4, i32 38
  %12810 = zext i1 %12808 to i8
  store i8 %12810, i8 addrspace(1)* %12809, align 1, !nosanitize !3
  %12811 = load i256, i256* %12633, align 4
  %12812 = trunc i256 0 to i64
  %12813 = alloca i256, align 8
  store i256 %12811, i256* %12813, align 4
  %12814 = bitcast i256* %12813 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %12812, i8* %12814, i64 32)
  %12815 = add i256 32, 0, !pc !247, !intsan !10
  %12816 = trunc i256 %12815 to i64
  %12817 = alloca i256, align 8
  store i256 4, i256* %12817, align 4
  %12818 = bitcast i256* %12817 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %12816, i8* %12818, i64 32)
  %12819 = add i256 32, %12815, !pc !248, !intsan !10
  %12820 = trunc i256 0 to i32
  %12821 = trunc i256 %12819 to i32
  %12822 = getelementptr inbounds i8, i8* %MEMORY, i32 %12820
  %12823 = alloca i256, align 8
  %12824 = bitcast i256* %12823 to i8*
  call void @__device_sha3(i8* %12822, i32 %12821, i8* %12824)
  %12825 = load i256, i256* %12823, align 4
  %12826 = add i256 2, %12825, !pc !249, !intsan !10
  %12827 = alloca i256, align 8
  store i256 %12826, i256* %12827, align 4
  %12828 = alloca i256, align 8
  call void @__device_sload(i256* %12827, i256* %12828)
  %12829 = call i32 @__hashword(i256* %12827)
  %12830 = load i32, i32* %5, align 4
  %12831 = icmp eq i32 %12829, %12830
  %12832 = or i1 false, %12831
  %12833 = load i32, i32* %6, align 4
  %12834 = icmp eq i32 %12829, %12833
  %12835 = or i1 %12832, %12834
  %12836 = load i32, i32* %7, align 4
  %12837 = icmp eq i32 %12829, %12836
  %12838 = or i1 %12835, %12837
  %12839 = load i32, i32* %8, align 4
  %12840 = icmp eq i32 %12829, %12839
  %12841 = or i1 %12838, %12840
  %12842 = load i32, i32* %9, align 4
  %12843 = icmp eq i32 %12829, %12842
  %12844 = or i1 %12841, %12843
  %12845 = load i32, i32* %10, align 4
  %12846 = icmp eq i32 %12829, %12845
  %12847 = or i1 %12844, %12846
  %12848 = load i32, i32* %11, align 4
  %12849 = icmp eq i32 %12829, %12848
  %12850 = or i1 %12847, %12849
  %12851 = load i32, i32* %12, align 4
  %12852 = icmp eq i32 %12829, %12851
  %12853 = or i1 %12850, %12852
  %12854 = load i32, i32* %13, align 4
  %12855 = icmp eq i32 %12829, %12854
  %12856 = or i1 %12853, %12855
  %12857 = load i32, i32* %14, align 4
  %12858 = icmp eq i32 %12829, %12857
  %12859 = or i1 %12856, %12858
  %12860 = load i32, i32* %15, align 4
  %12861 = icmp eq i32 %12829, %12860
  %12862 = or i1 %12859, %12861
  %12863 = load i32, i32* %16, align 4
  %12864 = icmp eq i32 %12829, %12863
  %12865 = or i1 %12862, %12864
  %12866 = load i32, i32* %17, align 4
  %12867 = icmp eq i32 %12829, %12866
  %12868 = or i1 %12865, %12867
  %12869 = load i32, i32* %18, align 4
  %12870 = icmp eq i32 %12829, %12869
  %12871 = or i1 %12868, %12870
  %12872 = load i32, i32* %19, align 4
  %12873 = icmp eq i32 %12829, %12872
  %12874 = or i1 %12871, %12873
  %12875 = load i32, i32* %20, align 4
  %12876 = icmp eq i32 %12829, %12875
  %12877 = or i1 %12874, %12876
  %12878 = load i32, i32* %21, align 4
  %12879 = icmp eq i32 %12829, %12878
  %12880 = or i1 %12877, %12879
  %12881 = load i32, i32* %22, align 4
  %12882 = icmp eq i32 %12829, %12881
  %12883 = or i1 %12880, %12882
  %12884 = load i32, i32* %23, align 4
  %12885 = icmp eq i32 %12829, %12884
  %12886 = or i1 %12883, %12885
  %12887 = load i32, i32* %24, align 4
  %12888 = icmp eq i32 %12829, %12887
  %12889 = or i1 %12886, %12888
  %12890 = load i32, i32* %25, align 4
  %12891 = icmp eq i32 %12829, %12890
  %12892 = or i1 %12889, %12891
  %12893 = load i32, i32* %26, align 4
  %12894 = icmp eq i32 %12829, %12893
  %12895 = or i1 %12892, %12894
  %12896 = load i32, i32* %27, align 4
  %12897 = icmp eq i32 %12829, %12896
  %12898 = or i1 %12895, %12897
  %12899 = load i32, i32* %28, align 4
  %12900 = icmp eq i32 %12829, %12899
  %12901 = or i1 %12898, %12900
  %12902 = load i32, i32* %29, align 4
  %12903 = icmp eq i32 %12829, %12902
  %12904 = or i1 %12901, %12903
  %12905 = load i32, i32* %30, align 4
  %12906 = icmp eq i32 %12829, %12905
  %12907 = or i1 %12904, %12906
  %12908 = load i32, i32* %31, align 4
  %12909 = icmp eq i32 %12829, %12908
  %12910 = or i1 %12907, %12909
  %12911 = load i32, i32* %32, align 4
  %12912 = icmp eq i32 %12829, %12911
  %12913 = or i1 %12910, %12912
  %12914 = load i32, i32* %33, align 4
  %12915 = icmp eq i32 %12829, %12914
  %12916 = or i1 %12913, %12915
  %12917 = load i32, i32* %34, align 4
  %12918 = icmp eq i32 %12829, %12917
  %12919 = or i1 %12916, %12918
  %12920 = load i32, i32* %35, align 4
  %12921 = icmp eq i32 %12829, %12920
  %12922 = or i1 %12919, %12921
  %12923 = load i32, i32* %36, align 4
  %12924 = icmp eq i32 %12829, %12923
  %12925 = or i1 %12922, %12924
  %12926 = load i32, i32* %37, align 4
  %12927 = icmp eq i32 %12829, %12926
  %12928 = or i1 %12925, %12927
  %12929 = load i32, i32* %38, align 4
  %12930 = icmp eq i32 %12829, %12929
  %12931 = or i1 %12928, %12930
  %12932 = load i32, i32* %39, align 4
  %12933 = icmp eq i32 %12829, %12932
  %12934 = or i1 %12931, %12933
  %12935 = load i32, i32* %40, align 4
  %12936 = icmp eq i32 %12829, %12935
  %12937 = or i1 %12934, %12936
  %12938 = load i32, i32* %41, align 4
  %12939 = icmp eq i32 %12829, %12938
  %12940 = or i1 %12937, %12939
  %12941 = load i32, i32* %42, align 4
  %12942 = icmp eq i32 %12829, %12941
  %12943 = or i1 %12940, %12942
  %12944 = load i32, i32* %43, align 4
  %12945 = icmp eq i32 %12829, %12944
  %12946 = or i1 %12943, %12945
  %12947 = load i32, i32* %44, align 4
  %12948 = icmp eq i32 %12829, %12947
  %12949 = or i1 %12946, %12948
  %12950 = load i32, i32* %45, align 4
  %12951 = icmp eq i32 %12829, %12950
  %12952 = or i1 %12949, %12951
  %12953 = load i32, i32* %46, align 4
  %12954 = icmp eq i32 %12829, %12953
  %12955 = or i1 %12952, %12954
  %12956 = load i32, i32* %47, align 4
  %12957 = icmp eq i32 %12829, %12956
  %12958 = or i1 %12955, %12957
  %12959 = load i32, i32* %48, align 4
  %12960 = icmp eq i32 %12829, %12959
  %12961 = or i1 %12958, %12960
  %12962 = load i32, i32* %49, align 4
  %12963 = icmp eq i32 %12829, %12962
  %12964 = or i1 %12961, %12963
  %12965 = load i32, i32* %50, align 4
  %12966 = icmp eq i32 %12829, %12965
  %12967 = or i1 %12964, %12966
  %12968 = load i32, i32* %51, align 4
  %12969 = icmp eq i32 %12829, %12968
  %12970 = or i1 %12967, %12969
  %12971 = load i32, i32* %52, align 4
  %12972 = icmp eq i32 %12829, %12971
  %12973 = or i1 %12970, %12972
  %12974 = load i32, i32* %53, align 4
  %12975 = icmp eq i32 %12829, %12974
  %12976 = or i1 %12973, %12975
  %12977 = load i32, i32* %54, align 4
  %12978 = icmp eq i32 %12829, %12977
  %12979 = or i1 %12976, %12978
  %12980 = load i32, i32* %55, align 4
  %12981 = icmp eq i32 %12829, %12980
  %12982 = or i1 %12979, %12981
  %12983 = load i32, i32* %56, align 4
  %12984 = icmp eq i32 %12829, %12983
  %12985 = or i1 %12982, %12984
  %12986 = load i32, i32* %57, align 4
  %12987 = icmp eq i32 %12829, %12986
  %12988 = or i1 %12985, %12987
  %12989 = load i32, i32* %58, align 4
  %12990 = icmp eq i32 %12829, %12989
  %12991 = or i1 %12988, %12990
  %12992 = load i32, i32* %59, align 4
  %12993 = icmp eq i32 %12829, %12992
  %12994 = or i1 %12991, %12993
  %12995 = load i32, i32* %60, align 4
  %12996 = icmp eq i32 %12829, %12995
  %12997 = or i1 %12994, %12996
  %12998 = load i32, i32* %61, align 4
  %12999 = icmp eq i32 %12829, %12998
  %13000 = or i1 %12997, %12999
  %13001 = load i32, i32* %62, align 4
  %13002 = icmp eq i32 %12829, %13001
  %13003 = or i1 %13000, %13002
  %13004 = getelementptr i8, i8 addrspace(1)* %4, i32 39
  %13005 = zext i1 %13003 to i8
  store i8 %13005, i8 addrspace(1)* %13004, align 1, !nosanitize !3
  %13006 = load i256, i256* %12828, align 4
  %13007 = mul i256 255, 1, !pc !250, !intsan !45
  %13008 = xor i256 %13007, -1
  %13009 = and i256 %13008, %13006
  %13010 = icmp eq i256 %12607, 0
  %13011 = icmp eq i1 %13010, false
  %13012 = zext i1 %13011 to i256
  %13013 = mul i256 %13012, 1, !pc !251, !intsan !45
  %13014 = or i256 %13013, %13009
  %13015 = alloca i256, align 8
  store i256 %12826, i256* %13015, align 4
  %13016 = alloca i256, align 8
  store i256 %13014, i256* %13016, align 4
  call void @__device_sstore(i256* %13015, i256* %13016)
  %13017 = call i32 @__hashword(i256* %13015)
  store i32 %13017, i32* %16, align 4, !nosanitize !3
  %13018 = load i256, i256* %0, align 4
  %13019 = trunc i256 64 to i64
  %13020 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %13019, i256* %13020)
  %13021 = load i256, i256* %13020, align 4
  %13022 = and i256 1461501637330902918203684832716283019655932542975, %13018
  %13023 = and i256 1461501637330902918203684832716283019655932542975, %13022
  %13024 = trunc i256 %13021 to i64
  %13025 = alloca i256, align 8
  store i256 %13023, i256* %13025, align 4
  %13026 = bitcast i256* %13025 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %13024, i8* %13026, i64 32)
  %13027 = add i256 32, %13021, !pc !252, !intsan !10
  %13028 = icmp eq i256 %12607, 0
  %13029 = icmp eq i1 %13028, false
  %13030 = icmp eq i1 %13029, false
  %13031 = icmp eq i1 %13030, false
  %13032 = trunc i256 %13027 to i64
  %13033 = zext i1 %13031 to i256
  %13034 = alloca i256, align 8
  store i256 %13033, i256* %13034, align 4
  %13035 = bitcast i256* %13034 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %13032, i8* %13035, i64 32)
  %13036 = add i256 32, %13027, !pc !253, !intsan !10
  %13037 = trunc i256 64 to i64
  %13038 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %13037, i256* %13038)
  %13039 = load i256, i256* %13038, align 4
  %13040 = sub i256 %13036, %13039, !pc !254, !intsan !8
  %13041 = trunc i256 -9889166663396385326354383804442810692571233177814139154686909539046149957790 to i64
  call void @addBugSet(i64 %13041)
  %13042 = trunc i256 %12612 to i64
  store i64 %13042, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.5238:                                            ; preds = %1451, %JumpTable
  %13043 = load i64, i64* %remaing_gas, align 4
  %13044 = icmp ugt i64 184, %13043
  br i1 %13044, label %Abort, label %13045

13045:                                            ; preds = %.5238
  %13046 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13047 = xor i32 %13046, 1418
  %13048 = urem i32 %13047, 4096
  %13049 = getelementptr i8, i8 addrspace(1)* %4, i32 %13048
  %13050 = load i8, i8 addrspace(1)* %13049, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13049, align 1, !nosanitize !3
  store i32 709, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13051 = sub i64 %13043, 184
  store i64 %13051, i64* %remaing_gas, align 4
  %13052 = load i256, i256* %0, align 4
  %13053 = and i256 1461501637330902918203684832716283019655932542975, %13052
  %13054 = alloca i256, align 8
  store i256 7, i256* %13054, align 4
  %13055 = alloca i256, align 8
  call void @__device_sload(i256* %13054, i256* %13055)
  %13056 = call i32 @__hashword(i256* %13054)
  %13057 = load i32, i32* %5, align 4
  %13058 = icmp eq i32 %13056, %13057
  %13059 = or i1 false, %13058
  %13060 = load i32, i32* %6, align 4
  %13061 = icmp eq i32 %13056, %13060
  %13062 = or i1 %13059, %13061
  %13063 = load i32, i32* %7, align 4
  %13064 = icmp eq i32 %13056, %13063
  %13065 = or i1 %13062, %13064
  %13066 = load i32, i32* %8, align 4
  %13067 = icmp eq i32 %13056, %13066
  %13068 = or i1 %13065, %13067
  %13069 = load i32, i32* %9, align 4
  %13070 = icmp eq i32 %13056, %13069
  %13071 = or i1 %13068, %13070
  %13072 = load i32, i32* %10, align 4
  %13073 = icmp eq i32 %13056, %13072
  %13074 = or i1 %13071, %13073
  %13075 = load i32, i32* %11, align 4
  %13076 = icmp eq i32 %13056, %13075
  %13077 = or i1 %13074, %13076
  %13078 = load i32, i32* %12, align 4
  %13079 = icmp eq i32 %13056, %13078
  %13080 = or i1 %13077, %13079
  %13081 = load i32, i32* %13, align 4
  %13082 = icmp eq i32 %13056, %13081
  %13083 = or i1 %13080, %13082
  %13084 = load i32, i32* %14, align 4
  %13085 = icmp eq i32 %13056, %13084
  %13086 = or i1 %13083, %13085
  %13087 = load i32, i32* %15, align 4
  %13088 = icmp eq i32 %13056, %13087
  %13089 = or i1 %13086, %13088
  %13090 = load i32, i32* %16, align 4
  %13091 = icmp eq i32 %13056, %13090
  %13092 = or i1 %13089, %13091
  %13093 = load i32, i32* %17, align 4
  %13094 = icmp eq i32 %13056, %13093
  %13095 = or i1 %13092, %13094
  %13096 = load i32, i32* %18, align 4
  %13097 = icmp eq i32 %13056, %13096
  %13098 = or i1 %13095, %13097
  %13099 = load i32, i32* %19, align 4
  %13100 = icmp eq i32 %13056, %13099
  %13101 = or i1 %13098, %13100
  %13102 = load i32, i32* %20, align 4
  %13103 = icmp eq i32 %13056, %13102
  %13104 = or i1 %13101, %13103
  %13105 = load i32, i32* %21, align 4
  %13106 = icmp eq i32 %13056, %13105
  %13107 = or i1 %13104, %13106
  %13108 = load i32, i32* %22, align 4
  %13109 = icmp eq i32 %13056, %13108
  %13110 = or i1 %13107, %13109
  %13111 = load i32, i32* %23, align 4
  %13112 = icmp eq i32 %13056, %13111
  %13113 = or i1 %13110, %13112
  %13114 = load i32, i32* %24, align 4
  %13115 = icmp eq i32 %13056, %13114
  %13116 = or i1 %13113, %13115
  %13117 = load i32, i32* %25, align 4
  %13118 = icmp eq i32 %13056, %13117
  %13119 = or i1 %13116, %13118
  %13120 = load i32, i32* %26, align 4
  %13121 = icmp eq i32 %13056, %13120
  %13122 = or i1 %13119, %13121
  %13123 = load i32, i32* %27, align 4
  %13124 = icmp eq i32 %13056, %13123
  %13125 = or i1 %13122, %13124
  %13126 = load i32, i32* %28, align 4
  %13127 = icmp eq i32 %13056, %13126
  %13128 = or i1 %13125, %13127
  %13129 = load i32, i32* %29, align 4
  %13130 = icmp eq i32 %13056, %13129
  %13131 = or i1 %13128, %13130
  %13132 = load i32, i32* %30, align 4
  %13133 = icmp eq i32 %13056, %13132
  %13134 = or i1 %13131, %13133
  %13135 = load i32, i32* %31, align 4
  %13136 = icmp eq i32 %13056, %13135
  %13137 = or i1 %13134, %13136
  %13138 = load i32, i32* %32, align 4
  %13139 = icmp eq i32 %13056, %13138
  %13140 = or i1 %13137, %13139
  %13141 = load i32, i32* %33, align 4
  %13142 = icmp eq i32 %13056, %13141
  %13143 = or i1 %13140, %13142
  %13144 = load i32, i32* %34, align 4
  %13145 = icmp eq i32 %13056, %13144
  %13146 = or i1 %13143, %13145
  %13147 = load i32, i32* %35, align 4
  %13148 = icmp eq i32 %13056, %13147
  %13149 = or i1 %13146, %13148
  %13150 = load i32, i32* %36, align 4
  %13151 = icmp eq i32 %13056, %13150
  %13152 = or i1 %13149, %13151
  %13153 = load i32, i32* %37, align 4
  %13154 = icmp eq i32 %13056, %13153
  %13155 = or i1 %13152, %13154
  %13156 = load i32, i32* %38, align 4
  %13157 = icmp eq i32 %13056, %13156
  %13158 = or i1 %13155, %13157
  %13159 = load i32, i32* %39, align 4
  %13160 = icmp eq i32 %13056, %13159
  %13161 = or i1 %13158, %13160
  %13162 = load i32, i32* %40, align 4
  %13163 = icmp eq i32 %13056, %13162
  %13164 = or i1 %13161, %13163
  %13165 = load i32, i32* %41, align 4
  %13166 = icmp eq i32 %13056, %13165
  %13167 = or i1 %13164, %13166
  %13168 = load i32, i32* %42, align 4
  %13169 = icmp eq i32 %13056, %13168
  %13170 = or i1 %13167, %13169
  %13171 = load i32, i32* %43, align 4
  %13172 = icmp eq i32 %13056, %13171
  %13173 = or i1 %13170, %13172
  %13174 = load i32, i32* %44, align 4
  %13175 = icmp eq i32 %13056, %13174
  %13176 = or i1 %13173, %13175
  %13177 = load i32, i32* %45, align 4
  %13178 = icmp eq i32 %13056, %13177
  %13179 = or i1 %13176, %13178
  %13180 = load i32, i32* %46, align 4
  %13181 = icmp eq i32 %13056, %13180
  %13182 = or i1 %13179, %13181
  %13183 = load i32, i32* %47, align 4
  %13184 = icmp eq i32 %13056, %13183
  %13185 = or i1 %13182, %13184
  %13186 = load i32, i32* %48, align 4
  %13187 = icmp eq i32 %13056, %13186
  %13188 = or i1 %13185, %13187
  %13189 = load i32, i32* %49, align 4
  %13190 = icmp eq i32 %13056, %13189
  %13191 = or i1 %13188, %13190
  %13192 = load i32, i32* %50, align 4
  %13193 = icmp eq i32 %13056, %13192
  %13194 = or i1 %13191, %13193
  %13195 = load i32, i32* %51, align 4
  %13196 = icmp eq i32 %13056, %13195
  %13197 = or i1 %13194, %13196
  %13198 = load i32, i32* %52, align 4
  %13199 = icmp eq i32 %13056, %13198
  %13200 = or i1 %13197, %13199
  %13201 = load i32, i32* %53, align 4
  %13202 = icmp eq i32 %13056, %13201
  %13203 = or i1 %13200, %13202
  %13204 = load i32, i32* %54, align 4
  %13205 = icmp eq i32 %13056, %13204
  %13206 = or i1 %13203, %13205
  %13207 = load i32, i32* %55, align 4
  %13208 = icmp eq i32 %13056, %13207
  %13209 = or i1 %13206, %13208
  %13210 = load i32, i32* %56, align 4
  %13211 = icmp eq i32 %13056, %13210
  %13212 = or i1 %13209, %13211
  %13213 = load i32, i32* %57, align 4
  %13214 = icmp eq i32 %13056, %13213
  %13215 = or i1 %13212, %13214
  %13216 = load i32, i32* %58, align 4
  %13217 = icmp eq i32 %13056, %13216
  %13218 = or i1 %13215, %13217
  %13219 = load i32, i32* %59, align 4
  %13220 = icmp eq i32 %13056, %13219
  %13221 = or i1 %13218, %13220
  %13222 = load i32, i32* %60, align 4
  %13223 = icmp eq i32 %13056, %13222
  %13224 = or i1 %13221, %13223
  %13225 = load i32, i32* %61, align 4
  %13226 = icmp eq i32 %13056, %13225
  %13227 = or i1 %13224, %13226
  %13228 = load i32, i32* %62, align 4
  %13229 = icmp eq i32 %13056, %13228
  %13230 = or i1 %13227, %13229
  %13231 = getelementptr i8, i8 addrspace(1)* %4, i32 40
  %13232 = zext i1 %13230 to i8
  store i8 %13232, i8 addrspace(1)* %13231, align 1, !nosanitize !3
  %13233 = load i256, i256* %13055, align 4
  %13234 = alloca i256, align 8
  store i256 %13233, i256* %13234, align 4
  %13235 = alloca i256, align 8
  store i256 1, i256* %13235, align 4
  %13236 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %13234, i256* %13235, i256* %13236), !pc !255, !intsan !6
  %13237 = load i256, i256* %13236, align 4
  %13238 = and i256 1461501637330902918203684832716283019655932542975, %13237
  %13239 = and i256 1461501637330902918203684832716283019655932542975, %13238
  %13240 = icmp eq i256 %13239, %13053
  %13241 = icmp eq i1 %13240, false
  %13242 = icmp eq i1 %13241, false
  %13243 = trunc i256 5330 to i64
  %jump.check46 = icmp ne i1 %13242, false
  br i1 %jump.check46, label %.5330, label %.5326, !EVMBB !4

.5326:                                            ; preds = %13045
  %13244 = load i64, i64* %remaing_gas, align 4
  %13245 = icmp ugt i64 16, %13244
  br i1 %13245, label %Abort, label %13246

13246:                                            ; preds = %.5326
  %13247 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13248 = xor i32 %13247, 2601
  %13249 = urem i32 %13248, 4096
  %13250 = getelementptr i8, i8 addrspace(1)* %4, i32 %13249
  %13251 = load i8, i8 addrspace(1)* %13250, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13250, align 1, !nosanitize !3
  store i32 1300, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13252 = sub i64 %13244, 16
  store i64 %13252, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.5330:                                            ; preds = %13045, %JumpTable
  %13253 = load i64, i64* %remaing_gas, align 4
  %13254 = icmp ugt i64 160, %13253
  br i1 %13254, label %Abort, label %13255

13255:                                            ; preds = %.5330
  %13256 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13257 = xor i32 %13256, 1620
  %13258 = urem i32 %13257, 4096
  %13259 = getelementptr i8, i8 addrspace(1)* %4, i32 %13258
  %13260 = load i8, i8 addrspace(1)* %13259, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13259, align 1, !nosanitize !3
  store i32 810, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13261 = sub i64 %13253, 160
  store i64 %13261, i64* %remaing_gas, align 4
  %13262 = load i64, i64* %STACK_DEP_PTR, align 4
  %13263 = getelementptr i256, i256* %STACK, i64 %13262
  %13264 = load i256, i256* %13263, align 4
  %13265 = load i64, i64* %STACK_DEP_PTR, align 4
  %13266 = sub i64 %13265, 1
  store i64 %13266, i64* %STACK_DEP_PTR, align 4
  %13267 = and i256 1461501637330902918203684832716283019655932542975, 0
  %13268 = and i256 1461501637330902918203684832716283019655932542975, %13264
  %13269 = icmp eq i256 %13268, %13267
  %13270 = icmp eq i1 %13269, false
  %13271 = trunc i256 5388 to i64
  %jump.check53 = icmp ne i1 %13270, false
  %13272 = load i64, i64* %STACK_DEP_PTR, align 4
  %13273 = add i64 %13272, 1
  store i64 %13273, i64* %STACK_DEP_PTR, align 4
  %13274 = load i64, i64* %STACK_DEP_PTR, align 4
  %13275 = getelementptr i256, i256* %STACK, i64 %13274
  store i256 %13264, i256* %13275, align 4
  br i1 %jump.check53, label %.5388, label %.5384, !EVMBB !4

.5384:                                            ; preds = %13255
  %13276 = load i64, i64* %remaing_gas, align 4
  %13277 = icmp ugt i64 40, %13276
  br i1 %13277, label %Abort, label %13278

13278:                                            ; preds = %.5384
  %13279 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13280 = xor i32 %13279, 840
  %13281 = urem i32 %13280, 4096
  %13282 = getelementptr i8, i8 addrspace(1)* %4, i32 %13281
  %13283 = load i8, i8 addrspace(1)* %13282, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13282, align 1, !nosanitize !3
  store i32 420, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13284 = sub i64 %13276, 40
  store i64 %13284, i64* %remaing_gas, align 4
  %13285 = load i64, i64* %STACK_DEP_PTR, align 4
  %13286 = sub i64 %13285, 0
  store i64 %13286, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.5388:                                            ; preds = %13255, %JumpTable
  %13287 = load i64, i64* %remaing_gas, align 4
  %13288 = icmp ugt i64 576, %13287
  br i1 %13288, label %Abort, label %13289

13289:                                            ; preds = %.5388
  %13290 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13291 = xor i32 %13290, 1690
  %13292 = urem i32 %13291, 4096
  %13293 = getelementptr i8, i8 addrspace(1)* %4, i32 %13292
  %13294 = load i8, i8 addrspace(1)* %13293, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13293, align 1, !nosanitize !3
  store i32 845, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13295 = sub i64 %13287, 576
  store i64 %13295, i64* %remaing_gas, align 4
  %13296 = load i64, i64* %STACK_DEP_PTR, align 4
  %13297 = getelementptr i256, i256* %STACK, i64 %13296
  %13298 = load i256, i256* %13297, align 4
  %13299 = load i64, i64* %STACK_DEP_PTR, align 4
  %13300 = sub i64 %13299, 1
  store i64 %13300, i64* %STACK_DEP_PTR, align 4
  %13301 = load i64, i64* %STACK_DEP_PTR, align 4
  %13302 = getelementptr i256, i256* %STACK, i64 %13301
  %13303 = load i256, i256* %13302, align 4
  %13304 = load i64, i64* %STACK_DEP_PTR, align 4
  %13305 = sub i64 %13304, 1
  store i64 %13305, i64* %STACK_DEP_PTR, align 4
  %13306 = alloca i256, align 8
  store i256 8, i256* %13306, align 4
  %13307 = alloca i256, align 8
  call void @__device_sload(i256* %13306, i256* %13307)
  %13308 = call i32 @__hashword(i256* %13306)
  %13309 = load i32, i32* %5, align 4
  %13310 = icmp eq i32 %13308, %13309
  %13311 = or i1 false, %13310
  %13312 = load i32, i32* %6, align 4
  %13313 = icmp eq i32 %13308, %13312
  %13314 = or i1 %13311, %13313
  %13315 = load i32, i32* %7, align 4
  %13316 = icmp eq i32 %13308, %13315
  %13317 = or i1 %13314, %13316
  %13318 = load i32, i32* %8, align 4
  %13319 = icmp eq i32 %13308, %13318
  %13320 = or i1 %13317, %13319
  %13321 = load i32, i32* %9, align 4
  %13322 = icmp eq i32 %13308, %13321
  %13323 = or i1 %13320, %13322
  %13324 = load i32, i32* %10, align 4
  %13325 = icmp eq i32 %13308, %13324
  %13326 = or i1 %13323, %13325
  %13327 = load i32, i32* %11, align 4
  %13328 = icmp eq i32 %13308, %13327
  %13329 = or i1 %13326, %13328
  %13330 = load i32, i32* %12, align 4
  %13331 = icmp eq i32 %13308, %13330
  %13332 = or i1 %13329, %13331
  %13333 = load i32, i32* %13, align 4
  %13334 = icmp eq i32 %13308, %13333
  %13335 = or i1 %13332, %13334
  %13336 = load i32, i32* %14, align 4
  %13337 = icmp eq i32 %13308, %13336
  %13338 = or i1 %13335, %13337
  %13339 = load i32, i32* %15, align 4
  %13340 = icmp eq i32 %13308, %13339
  %13341 = or i1 %13338, %13340
  %13342 = load i32, i32* %16, align 4
  %13343 = icmp eq i32 %13308, %13342
  %13344 = or i1 %13341, %13343
  %13345 = load i32, i32* %17, align 4
  %13346 = icmp eq i32 %13308, %13345
  %13347 = or i1 %13344, %13346
  %13348 = load i32, i32* %18, align 4
  %13349 = icmp eq i32 %13308, %13348
  %13350 = or i1 %13347, %13349
  %13351 = load i32, i32* %19, align 4
  %13352 = icmp eq i32 %13308, %13351
  %13353 = or i1 %13350, %13352
  %13354 = load i32, i32* %20, align 4
  %13355 = icmp eq i32 %13308, %13354
  %13356 = or i1 %13353, %13355
  %13357 = load i32, i32* %21, align 4
  %13358 = icmp eq i32 %13308, %13357
  %13359 = or i1 %13356, %13358
  %13360 = load i32, i32* %22, align 4
  %13361 = icmp eq i32 %13308, %13360
  %13362 = or i1 %13359, %13361
  %13363 = load i32, i32* %23, align 4
  %13364 = icmp eq i32 %13308, %13363
  %13365 = or i1 %13362, %13364
  %13366 = load i32, i32* %24, align 4
  %13367 = icmp eq i32 %13308, %13366
  %13368 = or i1 %13365, %13367
  %13369 = load i32, i32* %25, align 4
  %13370 = icmp eq i32 %13308, %13369
  %13371 = or i1 %13368, %13370
  %13372 = load i32, i32* %26, align 4
  %13373 = icmp eq i32 %13308, %13372
  %13374 = or i1 %13371, %13373
  %13375 = load i32, i32* %27, align 4
  %13376 = icmp eq i32 %13308, %13375
  %13377 = or i1 %13374, %13376
  %13378 = load i32, i32* %28, align 4
  %13379 = icmp eq i32 %13308, %13378
  %13380 = or i1 %13377, %13379
  %13381 = load i32, i32* %29, align 4
  %13382 = icmp eq i32 %13308, %13381
  %13383 = or i1 %13380, %13382
  %13384 = load i32, i32* %30, align 4
  %13385 = icmp eq i32 %13308, %13384
  %13386 = or i1 %13383, %13385
  %13387 = load i32, i32* %31, align 4
  %13388 = icmp eq i32 %13308, %13387
  %13389 = or i1 %13386, %13388
  %13390 = load i32, i32* %32, align 4
  %13391 = icmp eq i32 %13308, %13390
  %13392 = or i1 %13389, %13391
  %13393 = load i32, i32* %33, align 4
  %13394 = icmp eq i32 %13308, %13393
  %13395 = or i1 %13392, %13394
  %13396 = load i32, i32* %34, align 4
  %13397 = icmp eq i32 %13308, %13396
  %13398 = or i1 %13395, %13397
  %13399 = load i32, i32* %35, align 4
  %13400 = icmp eq i32 %13308, %13399
  %13401 = or i1 %13398, %13400
  %13402 = load i32, i32* %36, align 4
  %13403 = icmp eq i32 %13308, %13402
  %13404 = or i1 %13401, %13403
  %13405 = load i32, i32* %37, align 4
  %13406 = icmp eq i32 %13308, %13405
  %13407 = or i1 %13404, %13406
  %13408 = load i32, i32* %38, align 4
  %13409 = icmp eq i32 %13308, %13408
  %13410 = or i1 %13407, %13409
  %13411 = load i32, i32* %39, align 4
  %13412 = icmp eq i32 %13308, %13411
  %13413 = or i1 %13410, %13412
  %13414 = load i32, i32* %40, align 4
  %13415 = icmp eq i32 %13308, %13414
  %13416 = or i1 %13413, %13415
  %13417 = load i32, i32* %41, align 4
  %13418 = icmp eq i32 %13308, %13417
  %13419 = or i1 %13416, %13418
  %13420 = load i32, i32* %42, align 4
  %13421 = icmp eq i32 %13308, %13420
  %13422 = or i1 %13419, %13421
  %13423 = load i32, i32* %43, align 4
  %13424 = icmp eq i32 %13308, %13423
  %13425 = or i1 %13422, %13424
  %13426 = load i32, i32* %44, align 4
  %13427 = icmp eq i32 %13308, %13426
  %13428 = or i1 %13425, %13427
  %13429 = load i32, i32* %45, align 4
  %13430 = icmp eq i32 %13308, %13429
  %13431 = or i1 %13428, %13430
  %13432 = load i32, i32* %46, align 4
  %13433 = icmp eq i32 %13308, %13432
  %13434 = or i1 %13431, %13433
  %13435 = load i32, i32* %47, align 4
  %13436 = icmp eq i32 %13308, %13435
  %13437 = or i1 %13434, %13436
  %13438 = load i32, i32* %48, align 4
  %13439 = icmp eq i32 %13308, %13438
  %13440 = or i1 %13437, %13439
  %13441 = load i32, i32* %49, align 4
  %13442 = icmp eq i32 %13308, %13441
  %13443 = or i1 %13440, %13442
  %13444 = load i32, i32* %50, align 4
  %13445 = icmp eq i32 %13308, %13444
  %13446 = or i1 %13443, %13445
  %13447 = load i32, i32* %51, align 4
  %13448 = icmp eq i32 %13308, %13447
  %13449 = or i1 %13446, %13448
  %13450 = load i32, i32* %52, align 4
  %13451 = icmp eq i32 %13308, %13450
  %13452 = or i1 %13449, %13451
  %13453 = load i32, i32* %53, align 4
  %13454 = icmp eq i32 %13308, %13453
  %13455 = or i1 %13452, %13454
  %13456 = load i32, i32* %54, align 4
  %13457 = icmp eq i32 %13308, %13456
  %13458 = or i1 %13455, %13457
  %13459 = load i32, i32* %55, align 4
  %13460 = icmp eq i32 %13308, %13459
  %13461 = or i1 %13458, %13460
  %13462 = load i32, i32* %56, align 4
  %13463 = icmp eq i32 %13308, %13462
  %13464 = or i1 %13461, %13463
  %13465 = load i32, i32* %57, align 4
  %13466 = icmp eq i32 %13308, %13465
  %13467 = or i1 %13464, %13466
  %13468 = load i32, i32* %58, align 4
  %13469 = icmp eq i32 %13308, %13468
  %13470 = or i1 %13467, %13469
  %13471 = load i32, i32* %59, align 4
  %13472 = icmp eq i32 %13308, %13471
  %13473 = or i1 %13470, %13472
  %13474 = load i32, i32* %60, align 4
  %13475 = icmp eq i32 %13308, %13474
  %13476 = or i1 %13473, %13475
  %13477 = load i32, i32* %61, align 4
  %13478 = icmp eq i32 %13308, %13477
  %13479 = or i1 %13476, %13478
  %13480 = load i32, i32* %62, align 4
  %13481 = icmp eq i32 %13308, %13480
  %13482 = or i1 %13479, %13481
  %13483 = getelementptr i8, i8 addrspace(1)* %4, i32 41
  %13484 = zext i1 %13482 to i8
  store i8 %13484, i8 addrspace(1)* %13483, align 1, !nosanitize !3
  %13485 = load i256, i256* %13307, align 4
  %13486 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !256, !intsan !45
  %13487 = xor i256 %13486, -1
  %13488 = and i256 %13487, %13485
  %13489 = and i256 1461501637330902918203684832716283019655932542975, %13298
  %13490 = mul i256 %13489, 1, !pc !257, !intsan !45
  %13491 = or i256 %13490, %13488
  %13492 = alloca i256, align 8
  store i256 8, i256* %13492, align 4
  %13493 = alloca i256, align 8
  store i256 %13491, i256* %13493, align 4
  call void @__device_sstore(i256* %13492, i256* %13493)
  %13494 = call i32 @__hashword(i256* %13492)
  store i32 %13494, i32* %15, align 4, !nosanitize !3
  %13495 = alloca i256, align 8
  store i256 8, i256* %13495, align 4
  %13496 = alloca i256, align 8
  call void @__device_sload(i256* %13495, i256* %13496)
  %13497 = call i32 @__hashword(i256* %13495)
  %13498 = load i32, i32* %5, align 4
  %13499 = icmp eq i32 %13497, %13498
  %13500 = or i1 false, %13499
  %13501 = load i32, i32* %6, align 4
  %13502 = icmp eq i32 %13497, %13501
  %13503 = or i1 %13500, %13502
  %13504 = load i32, i32* %7, align 4
  %13505 = icmp eq i32 %13497, %13504
  %13506 = or i1 %13503, %13505
  %13507 = load i32, i32* %8, align 4
  %13508 = icmp eq i32 %13497, %13507
  %13509 = or i1 %13506, %13508
  %13510 = load i32, i32* %9, align 4
  %13511 = icmp eq i32 %13497, %13510
  %13512 = or i1 %13509, %13511
  %13513 = load i32, i32* %10, align 4
  %13514 = icmp eq i32 %13497, %13513
  %13515 = or i1 %13512, %13514
  %13516 = load i32, i32* %11, align 4
  %13517 = icmp eq i32 %13497, %13516
  %13518 = or i1 %13515, %13517
  %13519 = load i32, i32* %12, align 4
  %13520 = icmp eq i32 %13497, %13519
  %13521 = or i1 %13518, %13520
  %13522 = load i32, i32* %13, align 4
  %13523 = icmp eq i32 %13497, %13522
  %13524 = or i1 %13521, %13523
  %13525 = load i32, i32* %14, align 4
  %13526 = icmp eq i32 %13497, %13525
  %13527 = or i1 %13524, %13526
  %13528 = load i32, i32* %15, align 4
  %13529 = icmp eq i32 %13497, %13528
  %13530 = or i1 %13527, %13529
  %13531 = load i32, i32* %16, align 4
  %13532 = icmp eq i32 %13497, %13531
  %13533 = or i1 %13530, %13532
  %13534 = load i32, i32* %17, align 4
  %13535 = icmp eq i32 %13497, %13534
  %13536 = or i1 %13533, %13535
  %13537 = load i32, i32* %18, align 4
  %13538 = icmp eq i32 %13497, %13537
  %13539 = or i1 %13536, %13538
  %13540 = load i32, i32* %19, align 4
  %13541 = icmp eq i32 %13497, %13540
  %13542 = or i1 %13539, %13541
  %13543 = load i32, i32* %20, align 4
  %13544 = icmp eq i32 %13497, %13543
  %13545 = or i1 %13542, %13544
  %13546 = load i32, i32* %21, align 4
  %13547 = icmp eq i32 %13497, %13546
  %13548 = or i1 %13545, %13547
  %13549 = load i32, i32* %22, align 4
  %13550 = icmp eq i32 %13497, %13549
  %13551 = or i1 %13548, %13550
  %13552 = load i32, i32* %23, align 4
  %13553 = icmp eq i32 %13497, %13552
  %13554 = or i1 %13551, %13553
  %13555 = load i32, i32* %24, align 4
  %13556 = icmp eq i32 %13497, %13555
  %13557 = or i1 %13554, %13556
  %13558 = load i32, i32* %25, align 4
  %13559 = icmp eq i32 %13497, %13558
  %13560 = or i1 %13557, %13559
  %13561 = load i32, i32* %26, align 4
  %13562 = icmp eq i32 %13497, %13561
  %13563 = or i1 %13560, %13562
  %13564 = load i32, i32* %27, align 4
  %13565 = icmp eq i32 %13497, %13564
  %13566 = or i1 %13563, %13565
  %13567 = load i32, i32* %28, align 4
  %13568 = icmp eq i32 %13497, %13567
  %13569 = or i1 %13566, %13568
  %13570 = load i32, i32* %29, align 4
  %13571 = icmp eq i32 %13497, %13570
  %13572 = or i1 %13569, %13571
  %13573 = load i32, i32* %30, align 4
  %13574 = icmp eq i32 %13497, %13573
  %13575 = or i1 %13572, %13574
  %13576 = load i32, i32* %31, align 4
  %13577 = icmp eq i32 %13497, %13576
  %13578 = or i1 %13575, %13577
  %13579 = load i32, i32* %32, align 4
  %13580 = icmp eq i32 %13497, %13579
  %13581 = or i1 %13578, %13580
  %13582 = load i32, i32* %33, align 4
  %13583 = icmp eq i32 %13497, %13582
  %13584 = or i1 %13581, %13583
  %13585 = load i32, i32* %34, align 4
  %13586 = icmp eq i32 %13497, %13585
  %13587 = or i1 %13584, %13586
  %13588 = load i32, i32* %35, align 4
  %13589 = icmp eq i32 %13497, %13588
  %13590 = or i1 %13587, %13589
  %13591 = load i32, i32* %36, align 4
  %13592 = icmp eq i32 %13497, %13591
  %13593 = or i1 %13590, %13592
  %13594 = load i32, i32* %37, align 4
  %13595 = icmp eq i32 %13497, %13594
  %13596 = or i1 %13593, %13595
  %13597 = load i32, i32* %38, align 4
  %13598 = icmp eq i32 %13497, %13597
  %13599 = or i1 %13596, %13598
  %13600 = load i32, i32* %39, align 4
  %13601 = icmp eq i32 %13497, %13600
  %13602 = or i1 %13599, %13601
  %13603 = load i32, i32* %40, align 4
  %13604 = icmp eq i32 %13497, %13603
  %13605 = or i1 %13602, %13604
  %13606 = load i32, i32* %41, align 4
  %13607 = icmp eq i32 %13497, %13606
  %13608 = or i1 %13605, %13607
  %13609 = load i32, i32* %42, align 4
  %13610 = icmp eq i32 %13497, %13609
  %13611 = or i1 %13608, %13610
  %13612 = load i32, i32* %43, align 4
  %13613 = icmp eq i32 %13497, %13612
  %13614 = or i1 %13611, %13613
  %13615 = load i32, i32* %44, align 4
  %13616 = icmp eq i32 %13497, %13615
  %13617 = or i1 %13614, %13616
  %13618 = load i32, i32* %45, align 4
  %13619 = icmp eq i32 %13497, %13618
  %13620 = or i1 %13617, %13619
  %13621 = load i32, i32* %46, align 4
  %13622 = icmp eq i32 %13497, %13621
  %13623 = or i1 %13620, %13622
  %13624 = load i32, i32* %47, align 4
  %13625 = icmp eq i32 %13497, %13624
  %13626 = or i1 %13623, %13625
  %13627 = load i32, i32* %48, align 4
  %13628 = icmp eq i32 %13497, %13627
  %13629 = or i1 %13626, %13628
  %13630 = load i32, i32* %49, align 4
  %13631 = icmp eq i32 %13497, %13630
  %13632 = or i1 %13629, %13631
  %13633 = load i32, i32* %50, align 4
  %13634 = icmp eq i32 %13497, %13633
  %13635 = or i1 %13632, %13634
  %13636 = load i32, i32* %51, align 4
  %13637 = icmp eq i32 %13497, %13636
  %13638 = or i1 %13635, %13637
  %13639 = load i32, i32* %52, align 4
  %13640 = icmp eq i32 %13497, %13639
  %13641 = or i1 %13638, %13640
  %13642 = load i32, i32* %53, align 4
  %13643 = icmp eq i32 %13497, %13642
  %13644 = or i1 %13641, %13643
  %13645 = load i32, i32* %54, align 4
  %13646 = icmp eq i32 %13497, %13645
  %13647 = or i1 %13644, %13646
  %13648 = load i32, i32* %55, align 4
  %13649 = icmp eq i32 %13497, %13648
  %13650 = or i1 %13647, %13649
  %13651 = load i32, i32* %56, align 4
  %13652 = icmp eq i32 %13497, %13651
  %13653 = or i1 %13650, %13652
  %13654 = load i32, i32* %57, align 4
  %13655 = icmp eq i32 %13497, %13654
  %13656 = or i1 %13653, %13655
  %13657 = load i32, i32* %58, align 4
  %13658 = icmp eq i32 %13497, %13657
  %13659 = or i1 %13656, %13658
  %13660 = load i32, i32* %59, align 4
  %13661 = icmp eq i32 %13497, %13660
  %13662 = or i1 %13659, %13661
  %13663 = load i32, i32* %60, align 4
  %13664 = icmp eq i32 %13497, %13663
  %13665 = or i1 %13662, %13664
  %13666 = load i32, i32* %61, align 4
  %13667 = icmp eq i32 %13497, %13666
  %13668 = or i1 %13665, %13667
  %13669 = load i32, i32* %62, align 4
  %13670 = icmp eq i32 %13497, %13669
  %13671 = or i1 %13668, %13670
  %13672 = getelementptr i8, i8 addrspace(1)* %4, i32 42
  %13673 = zext i1 %13671 to i8
  store i8 %13673, i8 addrspace(1)* %13672, align 1, !nosanitize !3
  %13674 = load i256, i256* %13496, align 4
  %13675 = alloca i256, align 8
  store i256 %13674, i256* %13675, align 4
  %13676 = alloca i256, align 8
  store i256 1, i256* %13676, align 4
  %13677 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %13675, i256* %13676, i256* %13677), !pc !258, !intsan !6
  %13678 = load i256, i256* %13677, align 4
  %13679 = and i256 1461501637330902918203684832716283019655932542975, %13678
  %13680 = trunc i256 64 to i64
  %13681 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %13680, i256* %13681)
  %13682 = load i256, i256* %13681, align 4
  %13683 = and i256 1461501637330902918203684832716283019655932542975, %13679
  %13684 = and i256 1461501637330902918203684832716283019655932542975, %13683
  %13685 = trunc i256 %13682 to i64
  %13686 = alloca i256, align 8
  store i256 %13684, i256* %13686, align 4
  %13687 = bitcast i256* %13686 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %13685, i8* %13687, i64 32)
  %13688 = add i256 32, %13682, !pc !259, !intsan !10
  %13689 = and i256 1461501637330902918203684832716283019655932542975, %13298
  %13690 = and i256 1461501637330902918203684832716283019655932542975, %13689
  %13691 = trunc i256 %13688 to i64
  %13692 = alloca i256, align 8
  store i256 %13690, i256* %13692, align 4
  %13693 = bitcast i256* %13692 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %13691, i8* %13693, i64 32)
  %13694 = add i256 32, %13688, !pc !260, !intsan !10
  %13695 = trunc i256 64 to i64
  %13696 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %13695, i256* %13696)
  %13697 = load i256, i256* %13696, align 4
  %13698 = sub i256 %13694, %13697, !pc !261, !intsan !8
  %13699 = trunc i256 -32876299487445766528710980418843933236369620122727084532110973156116817675672 to i64
  call void @addBugSet(i64 %13699)
  %13700 = trunc i256 %13303 to i64
  store i64 %13700, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.5641:                                            ; preds = %1519, %JumpTable
  %13701 = load i64, i64* %remaing_gas, align 4
  %13702 = icmp ugt i64 280, %13701
  br i1 %13702, label %Abort, label %13703

13703:                                            ; preds = %.5641
  %13704 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13705 = xor i32 %13704, 2058
  %13706 = urem i32 %13705, 4096
  %13707 = getelementptr i8, i8 addrspace(1)* %4, i32 %13706
  %13708 = load i8, i8 addrspace(1)* %13707, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13707, align 1, !nosanitize !3
  store i32 1029, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13709 = sub i64 %13701, 280
  store i64 %13709, i64* %remaing_gas, align 4
  %13710 = load i256, i256* %0, align 4
  %13711 = and i256 1461501637330902918203684832716283019655932542975, %13710
  %13712 = alloca i256, align 8
  store i256 7, i256* %13712, align 4
  %13713 = alloca i256, align 8
  call void @__device_sload(i256* %13712, i256* %13713)
  %13714 = call i32 @__hashword(i256* %13712)
  %13715 = load i32, i32* %5, align 4
  %13716 = icmp eq i32 %13714, %13715
  %13717 = or i1 false, %13716
  %13718 = load i32, i32* %6, align 4
  %13719 = icmp eq i32 %13714, %13718
  %13720 = or i1 %13717, %13719
  %13721 = load i32, i32* %7, align 4
  %13722 = icmp eq i32 %13714, %13721
  %13723 = or i1 %13720, %13722
  %13724 = load i32, i32* %8, align 4
  %13725 = icmp eq i32 %13714, %13724
  %13726 = or i1 %13723, %13725
  %13727 = load i32, i32* %9, align 4
  %13728 = icmp eq i32 %13714, %13727
  %13729 = or i1 %13726, %13728
  %13730 = load i32, i32* %10, align 4
  %13731 = icmp eq i32 %13714, %13730
  %13732 = or i1 %13729, %13731
  %13733 = load i32, i32* %11, align 4
  %13734 = icmp eq i32 %13714, %13733
  %13735 = or i1 %13732, %13734
  %13736 = load i32, i32* %12, align 4
  %13737 = icmp eq i32 %13714, %13736
  %13738 = or i1 %13735, %13737
  %13739 = load i32, i32* %13, align 4
  %13740 = icmp eq i32 %13714, %13739
  %13741 = or i1 %13738, %13740
  %13742 = load i32, i32* %14, align 4
  %13743 = icmp eq i32 %13714, %13742
  %13744 = or i1 %13741, %13743
  %13745 = load i32, i32* %15, align 4
  %13746 = icmp eq i32 %13714, %13745
  %13747 = or i1 %13744, %13746
  %13748 = load i32, i32* %16, align 4
  %13749 = icmp eq i32 %13714, %13748
  %13750 = or i1 %13747, %13749
  %13751 = load i32, i32* %17, align 4
  %13752 = icmp eq i32 %13714, %13751
  %13753 = or i1 %13750, %13752
  %13754 = load i32, i32* %18, align 4
  %13755 = icmp eq i32 %13714, %13754
  %13756 = or i1 %13753, %13755
  %13757 = load i32, i32* %19, align 4
  %13758 = icmp eq i32 %13714, %13757
  %13759 = or i1 %13756, %13758
  %13760 = load i32, i32* %20, align 4
  %13761 = icmp eq i32 %13714, %13760
  %13762 = or i1 %13759, %13761
  %13763 = load i32, i32* %21, align 4
  %13764 = icmp eq i32 %13714, %13763
  %13765 = or i1 %13762, %13764
  %13766 = load i32, i32* %22, align 4
  %13767 = icmp eq i32 %13714, %13766
  %13768 = or i1 %13765, %13767
  %13769 = load i32, i32* %23, align 4
  %13770 = icmp eq i32 %13714, %13769
  %13771 = or i1 %13768, %13770
  %13772 = load i32, i32* %24, align 4
  %13773 = icmp eq i32 %13714, %13772
  %13774 = or i1 %13771, %13773
  %13775 = load i32, i32* %25, align 4
  %13776 = icmp eq i32 %13714, %13775
  %13777 = or i1 %13774, %13776
  %13778 = load i32, i32* %26, align 4
  %13779 = icmp eq i32 %13714, %13778
  %13780 = or i1 %13777, %13779
  %13781 = load i32, i32* %27, align 4
  %13782 = icmp eq i32 %13714, %13781
  %13783 = or i1 %13780, %13782
  %13784 = load i32, i32* %28, align 4
  %13785 = icmp eq i32 %13714, %13784
  %13786 = or i1 %13783, %13785
  %13787 = load i32, i32* %29, align 4
  %13788 = icmp eq i32 %13714, %13787
  %13789 = or i1 %13786, %13788
  %13790 = load i32, i32* %30, align 4
  %13791 = icmp eq i32 %13714, %13790
  %13792 = or i1 %13789, %13791
  %13793 = load i32, i32* %31, align 4
  %13794 = icmp eq i32 %13714, %13793
  %13795 = or i1 %13792, %13794
  %13796 = load i32, i32* %32, align 4
  %13797 = icmp eq i32 %13714, %13796
  %13798 = or i1 %13795, %13797
  %13799 = load i32, i32* %33, align 4
  %13800 = icmp eq i32 %13714, %13799
  %13801 = or i1 %13798, %13800
  %13802 = load i32, i32* %34, align 4
  %13803 = icmp eq i32 %13714, %13802
  %13804 = or i1 %13801, %13803
  %13805 = load i32, i32* %35, align 4
  %13806 = icmp eq i32 %13714, %13805
  %13807 = or i1 %13804, %13806
  %13808 = load i32, i32* %36, align 4
  %13809 = icmp eq i32 %13714, %13808
  %13810 = or i1 %13807, %13809
  %13811 = load i32, i32* %37, align 4
  %13812 = icmp eq i32 %13714, %13811
  %13813 = or i1 %13810, %13812
  %13814 = load i32, i32* %38, align 4
  %13815 = icmp eq i32 %13714, %13814
  %13816 = or i1 %13813, %13815
  %13817 = load i32, i32* %39, align 4
  %13818 = icmp eq i32 %13714, %13817
  %13819 = or i1 %13816, %13818
  %13820 = load i32, i32* %40, align 4
  %13821 = icmp eq i32 %13714, %13820
  %13822 = or i1 %13819, %13821
  %13823 = load i32, i32* %41, align 4
  %13824 = icmp eq i32 %13714, %13823
  %13825 = or i1 %13822, %13824
  %13826 = load i32, i32* %42, align 4
  %13827 = icmp eq i32 %13714, %13826
  %13828 = or i1 %13825, %13827
  %13829 = load i32, i32* %43, align 4
  %13830 = icmp eq i32 %13714, %13829
  %13831 = or i1 %13828, %13830
  %13832 = load i32, i32* %44, align 4
  %13833 = icmp eq i32 %13714, %13832
  %13834 = or i1 %13831, %13833
  %13835 = load i32, i32* %45, align 4
  %13836 = icmp eq i32 %13714, %13835
  %13837 = or i1 %13834, %13836
  %13838 = load i32, i32* %46, align 4
  %13839 = icmp eq i32 %13714, %13838
  %13840 = or i1 %13837, %13839
  %13841 = load i32, i32* %47, align 4
  %13842 = icmp eq i32 %13714, %13841
  %13843 = or i1 %13840, %13842
  %13844 = load i32, i32* %48, align 4
  %13845 = icmp eq i32 %13714, %13844
  %13846 = or i1 %13843, %13845
  %13847 = load i32, i32* %49, align 4
  %13848 = icmp eq i32 %13714, %13847
  %13849 = or i1 %13846, %13848
  %13850 = load i32, i32* %50, align 4
  %13851 = icmp eq i32 %13714, %13850
  %13852 = or i1 %13849, %13851
  %13853 = load i32, i32* %51, align 4
  %13854 = icmp eq i32 %13714, %13853
  %13855 = or i1 %13852, %13854
  %13856 = load i32, i32* %52, align 4
  %13857 = icmp eq i32 %13714, %13856
  %13858 = or i1 %13855, %13857
  %13859 = load i32, i32* %53, align 4
  %13860 = icmp eq i32 %13714, %13859
  %13861 = or i1 %13858, %13860
  %13862 = load i32, i32* %54, align 4
  %13863 = icmp eq i32 %13714, %13862
  %13864 = or i1 %13861, %13863
  %13865 = load i32, i32* %55, align 4
  %13866 = icmp eq i32 %13714, %13865
  %13867 = or i1 %13864, %13866
  %13868 = load i32, i32* %56, align 4
  %13869 = icmp eq i32 %13714, %13868
  %13870 = or i1 %13867, %13869
  %13871 = load i32, i32* %57, align 4
  %13872 = icmp eq i32 %13714, %13871
  %13873 = or i1 %13870, %13872
  %13874 = load i32, i32* %58, align 4
  %13875 = icmp eq i32 %13714, %13874
  %13876 = or i1 %13873, %13875
  %13877 = load i32, i32* %59, align 4
  %13878 = icmp eq i32 %13714, %13877
  %13879 = or i1 %13876, %13878
  %13880 = load i32, i32* %60, align 4
  %13881 = icmp eq i32 %13714, %13880
  %13882 = or i1 %13879, %13881
  %13883 = load i32, i32* %61, align 4
  %13884 = icmp eq i32 %13714, %13883
  %13885 = or i1 %13882, %13884
  %13886 = load i32, i32* %62, align 4
  %13887 = icmp eq i32 %13714, %13886
  %13888 = or i1 %13885, %13887
  %13889 = getelementptr i8, i8 addrspace(1)* %4, i32 43
  %13890 = zext i1 %13888 to i8
  store i8 %13890, i8 addrspace(1)* %13889, align 1, !nosanitize !3
  %13891 = load i256, i256* %13713, align 4
  %13892 = alloca i256, align 8
  store i256 %13891, i256* %13892, align 4
  %13893 = alloca i256, align 8
  store i256 1, i256* %13893, align 4
  %13894 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %13892, i256* %13893, i256* %13894), !pc !262, !intsan !6
  %13895 = load i256, i256* %13894, align 4
  %13896 = and i256 1461501637330902918203684832716283019655932542975, %13895
  %13897 = and i256 1461501637330902918203684832716283019655932542975, %13896
  %13898 = icmp eq i256 %13897, %13711
  %13899 = icmp eq i1 %13898, false
  %13900 = icmp eq i1 %13899, false
  %13901 = trunc i256 5736 to i64
  %jump.check52 = icmp ne i1 %13900, false
  %13902 = load i64, i64* %STACK_DEP_PTR, align 4
  %13903 = add i64 %13902, 1
  store i64 %13903, i64* %STACK_DEP_PTR, align 4
  %13904 = load i64, i64* %STACK_DEP_PTR, align 4
  %13905 = getelementptr i256, i256* %STACK, i64 %13904
  store i256 0, i256* %13905, align 4
  %13906 = load i64, i64* %STACK_DEP_PTR, align 4
  %13907 = add i64 %13906, 1
  store i64 %13907, i64* %STACK_DEP_PTR, align 4
  %13908 = load i64, i64* %STACK_DEP_PTR, align 4
  %13909 = getelementptr i256, i256* %STACK, i64 %13908
  store i256 0, i256* %13909, align 4
  br i1 %jump.check52, label %.5736, label %.5732, !EVMBB !4

.5732:                                            ; preds = %13703
  %13910 = load i64, i64* %remaing_gas, align 4
  %13911 = icmp ugt i64 40, %13910
  br i1 %13911, label %Abort, label %13912

13912:                                            ; preds = %.5732
  %13913 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13914 = xor i32 %13913, 1724
  %13915 = urem i32 %13914, 4096
  %13916 = getelementptr i8, i8 addrspace(1)* %4, i32 %13915
  %13917 = load i8, i8 addrspace(1)* %13916, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %13916, align 1, !nosanitize !3
  store i32 862, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %13918 = sub i64 %13910, 40
  store i64 %13918, i64* %remaing_gas, align 4
  %13919 = load i64, i64* %STACK_DEP_PTR, align 4
  %13920 = sub i64 %13919, 0
  store i64 %13920, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.5736:                                            ; preds = %13703, %JumpTable
  %13921 = load i64, i64* %STACK_DEP_PTR, align 4
  %13922 = getelementptr i256, i256* %STACK, i64 %13921
  %13923 = load i256, i256* %13922, align 4
  %13924 = load i64, i64* %STACK_DEP_PTR, align 4
  %13925 = sub i64 %13924, 1
  store i64 %13925, i64* %STACK_DEP_PTR, align 4
  %13926 = load i64, i64* %STACK_DEP_PTR, align 4
  %13927 = getelementptr i256, i256* %STACK, i64 %13926
  %13928 = load i256, i256* %13927, align 4
  %13929 = load i64, i64* %STACK_DEP_PTR, align 4
  %13930 = sub i64 %13929, 1
  store i64 %13930, i64* %STACK_DEP_PTR, align 4
  %13931 = alloca i256, align 8
  store i256 5, i256* %13931, align 4
  %13932 = alloca i256, align 8
  call void @__device_sload(i256* %13931, i256* %13932)
  %13933 = call i32 @__hashword(i256* %13931)
  %13934 = load i32, i32* %5, align 4
  %13935 = icmp eq i32 %13933, %13934
  %13936 = or i1 false, %13935
  %13937 = load i32, i32* %6, align 4
  %13938 = icmp eq i32 %13933, %13937
  %13939 = or i1 %13936, %13938
  %13940 = load i32, i32* %7, align 4
  %13941 = icmp eq i32 %13933, %13940
  %13942 = or i1 %13939, %13941
  %13943 = load i32, i32* %8, align 4
  %13944 = icmp eq i32 %13933, %13943
  %13945 = or i1 %13942, %13944
  %13946 = load i32, i32* %9, align 4
  %13947 = icmp eq i32 %13933, %13946
  %13948 = or i1 %13945, %13947
  %13949 = load i32, i32* %10, align 4
  %13950 = icmp eq i32 %13933, %13949
  %13951 = or i1 %13948, %13950
  %13952 = load i32, i32* %11, align 4
  %13953 = icmp eq i32 %13933, %13952
  %13954 = or i1 %13951, %13953
  %13955 = load i32, i32* %12, align 4
  %13956 = icmp eq i32 %13933, %13955
  %13957 = or i1 %13954, %13956
  %13958 = load i32, i32* %13, align 4
  %13959 = icmp eq i32 %13933, %13958
  %13960 = or i1 %13957, %13959
  %13961 = load i32, i32* %14, align 4
  %13962 = icmp eq i32 %13933, %13961
  %13963 = or i1 %13960, %13962
  %13964 = load i32, i32* %15, align 4
  %13965 = icmp eq i32 %13933, %13964
  %13966 = or i1 %13963, %13965
  %13967 = load i32, i32* %16, align 4
  %13968 = icmp eq i32 %13933, %13967
  %13969 = or i1 %13966, %13968
  %13970 = load i32, i32* %17, align 4
  %13971 = icmp eq i32 %13933, %13970
  %13972 = or i1 %13969, %13971
  %13973 = load i32, i32* %18, align 4
  %13974 = icmp eq i32 %13933, %13973
  %13975 = or i1 %13972, %13974
  %13976 = load i32, i32* %19, align 4
  %13977 = icmp eq i32 %13933, %13976
  %13978 = or i1 %13975, %13977
  %13979 = load i32, i32* %20, align 4
  %13980 = icmp eq i32 %13933, %13979
  %13981 = or i1 %13978, %13980
  %13982 = load i32, i32* %21, align 4
  %13983 = icmp eq i32 %13933, %13982
  %13984 = or i1 %13981, %13983
  %13985 = load i32, i32* %22, align 4
  %13986 = icmp eq i32 %13933, %13985
  %13987 = or i1 %13984, %13986
  %13988 = load i32, i32* %23, align 4
  %13989 = icmp eq i32 %13933, %13988
  %13990 = or i1 %13987, %13989
  %13991 = load i32, i32* %24, align 4
  %13992 = icmp eq i32 %13933, %13991
  %13993 = or i1 %13990, %13992
  %13994 = load i32, i32* %25, align 4
  %13995 = icmp eq i32 %13933, %13994
  %13996 = or i1 %13993, %13995
  %13997 = load i32, i32* %26, align 4
  %13998 = icmp eq i32 %13933, %13997
  %13999 = or i1 %13996, %13998
  %14000 = load i32, i32* %27, align 4
  %14001 = icmp eq i32 %13933, %14000
  %14002 = or i1 %13999, %14001
  %14003 = load i32, i32* %28, align 4
  %14004 = icmp eq i32 %13933, %14003
  %14005 = or i1 %14002, %14004
  %14006 = load i32, i32* %29, align 4
  %14007 = icmp eq i32 %13933, %14006
  %14008 = or i1 %14005, %14007
  %14009 = load i32, i32* %30, align 4
  %14010 = icmp eq i32 %13933, %14009
  %14011 = or i1 %14008, %14010
  %14012 = load i32, i32* %31, align 4
  %14013 = icmp eq i32 %13933, %14012
  %14014 = or i1 %14011, %14013
  %14015 = load i32, i32* %32, align 4
  %14016 = icmp eq i32 %13933, %14015
  %14017 = or i1 %14014, %14016
  %14018 = load i32, i32* %33, align 4
  %14019 = icmp eq i32 %13933, %14018
  %14020 = or i1 %14017, %14019
  %14021 = load i32, i32* %34, align 4
  %14022 = icmp eq i32 %13933, %14021
  %14023 = or i1 %14020, %14022
  %14024 = load i32, i32* %35, align 4
  %14025 = icmp eq i32 %13933, %14024
  %14026 = or i1 %14023, %14025
  %14027 = load i32, i32* %36, align 4
  %14028 = icmp eq i32 %13933, %14027
  %14029 = or i1 %14026, %14028
  %14030 = load i32, i32* %37, align 4
  %14031 = icmp eq i32 %13933, %14030
  %14032 = or i1 %14029, %14031
  %14033 = load i32, i32* %38, align 4
  %14034 = icmp eq i32 %13933, %14033
  %14035 = or i1 %14032, %14034
  %14036 = load i32, i32* %39, align 4
  %14037 = icmp eq i32 %13933, %14036
  %14038 = or i1 %14035, %14037
  %14039 = load i32, i32* %40, align 4
  %14040 = icmp eq i32 %13933, %14039
  %14041 = or i1 %14038, %14040
  %14042 = load i32, i32* %41, align 4
  %14043 = icmp eq i32 %13933, %14042
  %14044 = or i1 %14041, %14043
  %14045 = load i32, i32* %42, align 4
  %14046 = icmp eq i32 %13933, %14045
  %14047 = or i1 %14044, %14046
  %14048 = load i32, i32* %43, align 4
  %14049 = icmp eq i32 %13933, %14048
  %14050 = or i1 %14047, %14049
  %14051 = load i32, i32* %44, align 4
  %14052 = icmp eq i32 %13933, %14051
  %14053 = or i1 %14050, %14052
  %14054 = load i32, i32* %45, align 4
  %14055 = icmp eq i32 %13933, %14054
  %14056 = or i1 %14053, %14055
  %14057 = load i32, i32* %46, align 4
  %14058 = icmp eq i32 %13933, %14057
  %14059 = or i1 %14056, %14058
  %14060 = load i32, i32* %47, align 4
  %14061 = icmp eq i32 %13933, %14060
  %14062 = or i1 %14059, %14061
  %14063 = load i32, i32* %48, align 4
  %14064 = icmp eq i32 %13933, %14063
  %14065 = or i1 %14062, %14064
  %14066 = load i32, i32* %49, align 4
  %14067 = icmp eq i32 %13933, %14066
  %14068 = or i1 %14065, %14067
  %14069 = load i32, i32* %50, align 4
  %14070 = icmp eq i32 %13933, %14069
  %14071 = or i1 %14068, %14070
  %14072 = load i32, i32* %51, align 4
  %14073 = icmp eq i32 %13933, %14072
  %14074 = or i1 %14071, %14073
  %14075 = load i32, i32* %52, align 4
  %14076 = icmp eq i32 %13933, %14075
  %14077 = or i1 %14074, %14076
  %14078 = load i32, i32* %53, align 4
  %14079 = icmp eq i32 %13933, %14078
  %14080 = or i1 %14077, %14079
  %14081 = load i32, i32* %54, align 4
  %14082 = icmp eq i32 %13933, %14081
  %14083 = or i1 %14080, %14082
  %14084 = load i32, i32* %55, align 4
  %14085 = icmp eq i32 %13933, %14084
  %14086 = or i1 %14083, %14085
  %14087 = load i32, i32* %56, align 4
  %14088 = icmp eq i32 %13933, %14087
  %14089 = or i1 %14086, %14088
  %14090 = load i32, i32* %57, align 4
  %14091 = icmp eq i32 %13933, %14090
  %14092 = or i1 %14089, %14091
  %14093 = load i32, i32* %58, align 4
  %14094 = icmp eq i32 %13933, %14093
  %14095 = or i1 %14092, %14094
  %14096 = load i32, i32* %59, align 4
  %14097 = icmp eq i32 %13933, %14096
  %14098 = or i1 %14095, %14097
  %14099 = load i32, i32* %60, align 4
  %14100 = icmp eq i32 %13933, %14099
  %14101 = or i1 %14098, %14100
  %14102 = load i32, i32* %61, align 4
  %14103 = icmp eq i32 %13933, %14102
  %14104 = or i1 %14101, %14103
  %14105 = load i32, i32* %62, align 4
  %14106 = icmp eq i32 %13933, %14105
  %14107 = or i1 %14104, %14106
  %14108 = getelementptr i8, i8 addrspace(1)* %4, i32 44
  %14109 = zext i1 %14107 to i8
  store i8 %14109, i8 addrspace(1)* %14108, align 1, !nosanitize !3
  %14110 = load i256, i256* %13932, align 4
  %14111 = load i64, i64* %STACK_DEP_PTR, align 4
  %14112 = add i64 %14111, 1
  store i64 %14112, i64* %STACK_DEP_PTR, align 4
  %14113 = load i64, i64* %STACK_DEP_PTR, align 4
  %14114 = getelementptr i256, i256* %STACK, i64 %14113
  store i256 %14110, i256* %14114, align 4
  %14115 = load i64, i64* %STACK_DEP_PTR, align 4
  %14116 = add i64 %14115, 1
  store i64 %14116, i64* %STACK_DEP_PTR, align 4
  %14117 = load i64, i64* %STACK_DEP_PTR, align 4
  %14118 = getelementptr i256, i256* %STACK, i64 %14117
  store i256 1, i256* %14118, align 4
  br label %.5746

.5746:                                            ; preds = %14370, %.5736, %JumpTable
  %14119 = load i64, i64* %remaing_gas, align 4
  %14120 = icmp ugt i64 248, %14119
  br i1 %14120, label %Abort, label %14121

14121:                                            ; preds = %.5746
  %14122 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14123 = xor i32 %14122, 3541
  %14124 = urem i32 %14123, 4096
  %14125 = getelementptr i8, i8 addrspace(1)* %4, i32 %14124
  %14126 = load i8, i8 addrspace(1)* %14125, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14125, align 1, !nosanitize !3
  store i32 1770, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14127 = sub i64 %14119, 248
  store i64 %14127, i64* %remaing_gas, align 4
  %14128 = load i64, i64* %STACK_DEP_PTR, align 4
  %14129 = getelementptr i256, i256* %STACK, i64 %14128
  %14130 = load i256, i256* %14129, align 4
  %14131 = load i64, i64* %STACK_DEP_PTR, align 4
  %14132 = sub i64 %14131, 1
  store i64 %14132, i64* %STACK_DEP_PTR, align 4
  %14133 = load i64, i64* %STACK_DEP_PTR, align 4
  %14134 = getelementptr i256, i256* %STACK, i64 %14133
  %14135 = load i256, i256* %14134, align 4
  %14136 = load i64, i64* %STACK_DEP_PTR, align 4
  %14137 = sub i64 %14136, 1
  store i64 %14137, i64* %STACK_DEP_PTR, align 4
  %14138 = icmp ugt i256 %14130, %14135
  %14139 = icmp eq i1 %14138, false
  %14140 = icmp eq i1 %14139, false
  %14141 = trunc i256 5832 to i64
  %jump.check184 = icmp ne i1 %14140, false
  %14142 = load i64, i64* %STACK_DEP_PTR, align 4
  %14143 = add i64 %14142, 1
  store i64 %14143, i64* %STACK_DEP_PTR, align 4
  %14144 = load i64, i64* %STACK_DEP_PTR, align 4
  %14145 = getelementptr i256, i256* %STACK, i64 %14144
  store i256 %14135, i256* %14145, align 4
  %14146 = load i64, i64* %STACK_DEP_PTR, align 4
  %14147 = add i64 %14146, 1
  store i64 %14147, i64* %STACK_DEP_PTR, align 4
  %14148 = load i64, i64* %STACK_DEP_PTR, align 4
  %14149 = getelementptr i256, i256* %STACK, i64 %14148
  store i256 %14130, i256* %14149, align 4
  br i1 %jump.check184, label %.5832, label %.5756, !EVMBB !4

.5756:                                            ; preds = %14121
  %14150 = load i64, i64* %remaing_gas, align 4
  %14151 = icmp ugt i64 384, %14150
  br i1 %14151, label %Abort, label %14152

14152:                                            ; preds = %.5756
  %14153 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14154 = xor i32 %14153, 270
  %14155 = urem i32 %14154, 4096
  %14156 = getelementptr i8, i8 addrspace(1)* %4, i32 %14155
  %14157 = load i8, i8 addrspace(1)* %14156, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14156, align 1, !nosanitize !3
  store i32 135, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14158 = sub i64 %14150, 384
  store i64 %14158, i64* %remaing_gas, align 4
  %14159 = trunc i256 0 to i64
  %14160 = alloca i256, align 8
  store i256 1, i256* %14160, align 4
  %14161 = bitcast i256* %14160 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14159, i8* %14161, i64 32)
  %14162 = add i256 32, 0, !pc !263, !intsan !10
  %14163 = trunc i256 %14162 to i64
  %14164 = alloca i256, align 8
  store i256 4, i256* %14164, align 4
  %14165 = bitcast i256* %14164 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14163, i8* %14165, i64 32)
  %14166 = add i256 32, %14162, !pc !264, !intsan !10
  %14167 = trunc i256 0 to i32
  %14168 = trunc i256 %14166 to i32
  %14169 = getelementptr inbounds i8, i8* %MEMORY, i32 %14167
  %14170 = alloca i256, align 8
  %14171 = bitcast i256* %14170 to i8*
  call void @__device_sha3(i8* %14169, i32 %14168, i8* %14171)
  %14172 = load i256, i256* %14170, align 4
  %14173 = add i256 0, %14172, !pc !265, !intsan !10
  %14174 = alloca i256, align 8
  store i256 %14173, i256* %14174, align 4
  %14175 = alloca i256, align 8
  call void @__device_sload(i256* %14174, i256* %14175)
  %14176 = call i32 @__hashword(i256* %14174)
  %14177 = load i32, i32* %5, align 4
  %14178 = icmp eq i32 %14176, %14177
  %14179 = or i1 false, %14178
  %14180 = load i32, i32* %6, align 4
  %14181 = icmp eq i32 %14176, %14180
  %14182 = or i1 %14179, %14181
  %14183 = load i32, i32* %7, align 4
  %14184 = icmp eq i32 %14176, %14183
  %14185 = or i1 %14182, %14184
  %14186 = load i32, i32* %8, align 4
  %14187 = icmp eq i32 %14176, %14186
  %14188 = or i1 %14185, %14187
  %14189 = load i32, i32* %9, align 4
  %14190 = icmp eq i32 %14176, %14189
  %14191 = or i1 %14188, %14190
  %14192 = load i32, i32* %10, align 4
  %14193 = icmp eq i32 %14176, %14192
  %14194 = or i1 %14191, %14193
  %14195 = load i32, i32* %11, align 4
  %14196 = icmp eq i32 %14176, %14195
  %14197 = or i1 %14194, %14196
  %14198 = load i32, i32* %12, align 4
  %14199 = icmp eq i32 %14176, %14198
  %14200 = or i1 %14197, %14199
  %14201 = load i32, i32* %13, align 4
  %14202 = icmp eq i32 %14176, %14201
  %14203 = or i1 %14200, %14202
  %14204 = load i32, i32* %14, align 4
  %14205 = icmp eq i32 %14176, %14204
  %14206 = or i1 %14203, %14205
  %14207 = load i32, i32* %15, align 4
  %14208 = icmp eq i32 %14176, %14207
  %14209 = or i1 %14206, %14208
  %14210 = load i32, i32* %16, align 4
  %14211 = icmp eq i32 %14176, %14210
  %14212 = or i1 %14209, %14211
  %14213 = load i32, i32* %17, align 4
  %14214 = icmp eq i32 %14176, %14213
  %14215 = or i1 %14212, %14214
  %14216 = load i32, i32* %18, align 4
  %14217 = icmp eq i32 %14176, %14216
  %14218 = or i1 %14215, %14217
  %14219 = load i32, i32* %19, align 4
  %14220 = icmp eq i32 %14176, %14219
  %14221 = or i1 %14218, %14220
  %14222 = load i32, i32* %20, align 4
  %14223 = icmp eq i32 %14176, %14222
  %14224 = or i1 %14221, %14223
  %14225 = load i32, i32* %21, align 4
  %14226 = icmp eq i32 %14176, %14225
  %14227 = or i1 %14224, %14226
  %14228 = load i32, i32* %22, align 4
  %14229 = icmp eq i32 %14176, %14228
  %14230 = or i1 %14227, %14229
  %14231 = load i32, i32* %23, align 4
  %14232 = icmp eq i32 %14176, %14231
  %14233 = or i1 %14230, %14232
  %14234 = load i32, i32* %24, align 4
  %14235 = icmp eq i32 %14176, %14234
  %14236 = or i1 %14233, %14235
  %14237 = load i32, i32* %25, align 4
  %14238 = icmp eq i32 %14176, %14237
  %14239 = or i1 %14236, %14238
  %14240 = load i32, i32* %26, align 4
  %14241 = icmp eq i32 %14176, %14240
  %14242 = or i1 %14239, %14241
  %14243 = load i32, i32* %27, align 4
  %14244 = icmp eq i32 %14176, %14243
  %14245 = or i1 %14242, %14244
  %14246 = load i32, i32* %28, align 4
  %14247 = icmp eq i32 %14176, %14246
  %14248 = or i1 %14245, %14247
  %14249 = load i32, i32* %29, align 4
  %14250 = icmp eq i32 %14176, %14249
  %14251 = or i1 %14248, %14250
  %14252 = load i32, i32* %30, align 4
  %14253 = icmp eq i32 %14176, %14252
  %14254 = or i1 %14251, %14253
  %14255 = load i32, i32* %31, align 4
  %14256 = icmp eq i32 %14176, %14255
  %14257 = or i1 %14254, %14256
  %14258 = load i32, i32* %32, align 4
  %14259 = icmp eq i32 %14176, %14258
  %14260 = or i1 %14257, %14259
  %14261 = load i32, i32* %33, align 4
  %14262 = icmp eq i32 %14176, %14261
  %14263 = or i1 %14260, %14262
  %14264 = load i32, i32* %34, align 4
  %14265 = icmp eq i32 %14176, %14264
  %14266 = or i1 %14263, %14265
  %14267 = load i32, i32* %35, align 4
  %14268 = icmp eq i32 %14176, %14267
  %14269 = or i1 %14266, %14268
  %14270 = load i32, i32* %36, align 4
  %14271 = icmp eq i32 %14176, %14270
  %14272 = or i1 %14269, %14271
  %14273 = load i32, i32* %37, align 4
  %14274 = icmp eq i32 %14176, %14273
  %14275 = or i1 %14272, %14274
  %14276 = load i32, i32* %38, align 4
  %14277 = icmp eq i32 %14176, %14276
  %14278 = or i1 %14275, %14277
  %14279 = load i32, i32* %39, align 4
  %14280 = icmp eq i32 %14176, %14279
  %14281 = or i1 %14278, %14280
  %14282 = load i32, i32* %40, align 4
  %14283 = icmp eq i32 %14176, %14282
  %14284 = or i1 %14281, %14283
  %14285 = load i32, i32* %41, align 4
  %14286 = icmp eq i32 %14176, %14285
  %14287 = or i1 %14284, %14286
  %14288 = load i32, i32* %42, align 4
  %14289 = icmp eq i32 %14176, %14288
  %14290 = or i1 %14287, %14289
  %14291 = load i32, i32* %43, align 4
  %14292 = icmp eq i32 %14176, %14291
  %14293 = or i1 %14290, %14292
  %14294 = load i32, i32* %44, align 4
  %14295 = icmp eq i32 %14176, %14294
  %14296 = or i1 %14293, %14295
  %14297 = load i32, i32* %45, align 4
  %14298 = icmp eq i32 %14176, %14297
  %14299 = or i1 %14296, %14298
  %14300 = load i32, i32* %46, align 4
  %14301 = icmp eq i32 %14176, %14300
  %14302 = or i1 %14299, %14301
  %14303 = load i32, i32* %47, align 4
  %14304 = icmp eq i32 %14176, %14303
  %14305 = or i1 %14302, %14304
  %14306 = load i32, i32* %48, align 4
  %14307 = icmp eq i32 %14176, %14306
  %14308 = or i1 %14305, %14307
  %14309 = load i32, i32* %49, align 4
  %14310 = icmp eq i32 %14176, %14309
  %14311 = or i1 %14308, %14310
  %14312 = load i32, i32* %50, align 4
  %14313 = icmp eq i32 %14176, %14312
  %14314 = or i1 %14311, %14313
  %14315 = load i32, i32* %51, align 4
  %14316 = icmp eq i32 %14176, %14315
  %14317 = or i1 %14314, %14316
  %14318 = load i32, i32* %52, align 4
  %14319 = icmp eq i32 %14176, %14318
  %14320 = or i1 %14317, %14319
  %14321 = load i32, i32* %53, align 4
  %14322 = icmp eq i32 %14176, %14321
  %14323 = or i1 %14320, %14322
  %14324 = load i32, i32* %54, align 4
  %14325 = icmp eq i32 %14176, %14324
  %14326 = or i1 %14323, %14325
  %14327 = load i32, i32* %55, align 4
  %14328 = icmp eq i32 %14176, %14327
  %14329 = or i1 %14326, %14328
  %14330 = load i32, i32* %56, align 4
  %14331 = icmp eq i32 %14176, %14330
  %14332 = or i1 %14329, %14331
  %14333 = load i32, i32* %57, align 4
  %14334 = icmp eq i32 %14176, %14333
  %14335 = or i1 %14332, %14334
  %14336 = load i32, i32* %58, align 4
  %14337 = icmp eq i32 %14176, %14336
  %14338 = or i1 %14335, %14337
  %14339 = load i32, i32* %59, align 4
  %14340 = icmp eq i32 %14176, %14339
  %14341 = or i1 %14338, %14340
  %14342 = load i32, i32* %60, align 4
  %14343 = icmp eq i32 %14176, %14342
  %14344 = or i1 %14341, %14343
  %14345 = load i32, i32* %61, align 4
  %14346 = icmp eq i32 %14176, %14345
  %14347 = or i1 %14344, %14346
  %14348 = load i32, i32* %62, align 4
  %14349 = icmp eq i32 %14176, %14348
  %14350 = or i1 %14347, %14349
  %14351 = getelementptr i8, i8 addrspace(1)* %4, i32 45
  %14352 = zext i1 %14350 to i8
  store i8 %14352, i8 addrspace(1)* %14351, align 1, !nosanitize !3
  %14353 = load i256, i256* %14175, align 4
  %14354 = alloca i256, align 8
  store i256 %14353, i256* %14354, align 4
  %14355 = alloca i256, align 8
  store i256 1, i256* %14355, align 4
  %14356 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %14354, i256* %14355, i256* %14356), !pc !266, !intsan !6
  %14357 = load i256, i256* %14356, align 4
  %14358 = and i256 1461501637330902918203684832716283019655932542975, %14357
  %14359 = trunc i256 13000 to i64
  %14360 = load i64, i64* %STACK_DEP_PTR, align 4
  %14361 = add i64 %14360, 1
  store i64 %14361, i64* %STACK_DEP_PTR, align 4
  %14362 = load i64, i64* %STACK_DEP_PTR, align 4
  %14363 = getelementptr i256, i256* %STACK, i64 %14362
  store i256 5819, i256* %14363, align 4
  %14364 = load i64, i64* %STACK_DEP_PTR, align 4
  %14365 = add i64 %14364, 1
  store i64 %14365, i64* %STACK_DEP_PTR, align 4
  %14366 = load i64, i64* %STACK_DEP_PTR, align 4
  %14367 = getelementptr i256, i256* %STACK, i64 %14366
  store i256 %14358, i256* %14367, align 4
  br label %.13000, !EVMBB !4

.5819:                                            ; preds = %JumpTable
  %14368 = load i64, i64* %remaing_gas, align 4
  %14369 = icmp ugt i64 128, %14368
  br i1 %14369, label %Abort, label %14370

14370:                                            ; preds = %.5819
  %14371 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14372 = xor i32 %14371, 3608
  %14373 = urem i32 %14372, 4096
  %14374 = getelementptr i8, i8 addrspace(1)* %4, i32 %14373
  %14375 = load i8, i8 addrspace(1)* %14374, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14374, align 1, !nosanitize !3
  store i32 1804, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14376 = sub i64 %14368, 128
  store i64 %14376, i64* %remaing_gas, align 4
  %14377 = load i64, i64* %STACK_DEP_PTR, align 4
  %14378 = getelementptr i256, i256* %STACK, i64 %14377
  %14379 = load i256, i256* %14378, align 4
  %14380 = load i64, i64* %STACK_DEP_PTR, align 4
  %14381 = sub i64 %14380, 1
  store i64 %14381, i64* %STACK_DEP_PTR, align 4
  %14382 = add i256 1, %14379, !pc !267, !intsan !10
  %14383 = trunc i256 5746 to i64
  %14384 = load i64, i64* %STACK_DEP_PTR, align 4
  %14385 = add i64 %14384, 1
  store i64 %14385, i64* %STACK_DEP_PTR, align 4
  %14386 = load i64, i64* %STACK_DEP_PTR, align 4
  %14387 = getelementptr i256, i256* %STACK, i64 %14386
  store i256 %14382, i256* %14387, align 4
  br label %.5746, !EVMBB !4

.5832:                                            ; preds = %14121, %JumpTable
  %14388 = load i64, i64* %remaing_gas, align 4
  %14389 = icmp ugt i64 176, %14388
  br i1 %14389, label %Abort, label %14390

14390:                                            ; preds = %.5832
  %14391 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14392 = xor i32 %14391, 1960
  %14393 = urem i32 %14392, 4096
  %14394 = getelementptr i8, i8 addrspace(1)* %4, i32 %14393
  %14395 = load i8, i8 addrspace(1)* %14394, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14394, align 1, !nosanitize !3
  store i32 980, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14396 = sub i64 %14388, 176
  store i64 %14396, i64* %remaing_gas, align 4
  %14397 = load i64, i64* %STACK_DEP_PTR, align 4
  %14398 = getelementptr i256, i256* %STACK, i64 %14397
  %14399 = load i256, i256* %14398, align 4
  %14400 = load i64, i64* %STACK_DEP_PTR, align 4
  %14401 = sub i64 %14400, 1
  store i64 %14401, i64* %STACK_DEP_PTR, align 4
  %14402 = load i64, i64* %STACK_DEP_PTR, align 4
  %14403 = getelementptr i256, i256* %STACK, i64 %14402
  %14404 = load i256, i256* %14403, align 4
  %14405 = load i64, i64* %STACK_DEP_PTR, align 4
  %14406 = sub i64 %14405, 1
  store i64 %14406, i64* %STACK_DEP_PTR, align 4
  %14407 = load i64, i64* %STACK_DEP_PTR, align 4
  %14408 = getelementptr i256, i256* %STACK, i64 %14407
  %14409 = load i256, i256* %14408, align 4
  %14410 = load i64, i64* %STACK_DEP_PTR, align 4
  %14411 = sub i64 %14410, 1
  store i64 %14411, i64* %STACK_DEP_PTR, align 4
  %14412 = trunc i256 %14409 to i64
  store i64 %14412, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.5836:                                            ; preds = %1574, %JumpTable
  %14413 = load i64, i64* %remaing_gas, align 4
  %14414 = icmp ugt i64 624, %14413
  br i1 %14414, label %Abort, label %14415

14415:                                            ; preds = %.5836
  %14416 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14417 = xor i32 %14416, 68
  %14418 = urem i32 %14417, 4096
  %14419 = getelementptr i8, i8 addrspace(1)* %4, i32 %14418
  %14420 = load i8, i8 addrspace(1)* %14419, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14419, align 1, !nosanitize !3
  store i32 34, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14421 = sub i64 %14413, 624
  store i64 %14421, i64* %remaing_gas, align 4
  %14422 = load i64, i64* %STACK_DEP_PTR, align 4
  %14423 = getelementptr i256, i256* %STACK, i64 %14422
  %14424 = load i256, i256* %14423, align 4
  %14425 = load i64, i64* %STACK_DEP_PTR, align 4
  %14426 = sub i64 %14425, 1
  store i64 %14426, i64* %STACK_DEP_PTR, align 4
  %14427 = load i64, i64* %STACK_DEP_PTR, align 4
  %14428 = getelementptr i256, i256* %STACK, i64 %14427
  %14429 = load i256, i256* %14428, align 4
  %14430 = load i64, i64* %STACK_DEP_PTR, align 4
  %14431 = sub i64 %14430, 1
  store i64 %14431, i64* %STACK_DEP_PTR, align 4
  %14432 = trunc i256 64 to i64
  %14433 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %14432, i256* %14433)
  %14434 = load i256, i256* %14433, align 4
  %14435 = trunc i256 %14434 to i64
  %14436 = alloca i256, align 8
  store i256 0, i256* %14436, align 4
  %14437 = bitcast i256* %14436 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14435, i8* %14437, i64 32)
  %14438 = add i256 31, 0, !pc !268, !intsan !10
  %14439 = xor i256 31, -1
  %14440 = and i256 %14439, %14438
  %14441 = add i256 32, %14440, !pc !269, !intsan !10
  %14442 = add i256 %14434, %14441, !pc !270, !intsan !10
  %14443 = trunc i256 64 to i64
  %14444 = alloca i256, align 8
  store i256 %14442, i256* %14444, align 4
  %14445 = bitcast i256* %14444 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14443, i8* %14445, i64 32)
  %14446 = icmp eq i256 0, 0
  %14447 = trunc i256 5893 to i64
  %jump.check59 = icmp ne i1 %14446, false
  %14448 = load i64, i64* %STACK_DEP_PTR, align 4
  %14449 = add i64 %14448, 1
  store i64 %14449, i64* %STACK_DEP_PTR, align 4
  %14450 = load i64, i64* %STACK_DEP_PTR, align 4
  %14451 = getelementptr i256, i256* %STACK, i64 %14450
  store i256 %14429, i256* %14451, align 4
  %14452 = load i64, i64* %STACK_DEP_PTR, align 4
  %14453 = add i64 %14452, 1
  store i64 %14453, i64* %STACK_DEP_PTR, align 4
  %14454 = load i64, i64* %STACK_DEP_PTR, align 4
  %14455 = getelementptr i256, i256* %STACK, i64 %14454
  store i256 %14424, i256* %14455, align 4
  %14456 = load i64, i64* %STACK_DEP_PTR, align 4
  %14457 = add i64 %14456, 1
  store i64 %14457, i64* %STACK_DEP_PTR, align 4
  %14458 = load i64, i64* %STACK_DEP_PTR, align 4
  %14459 = getelementptr i256, i256* %STACK, i64 %14458
  store i256 5899, i256* %14459, align 4
  %14460 = load i64, i64* %STACK_DEP_PTR, align 4
  %14461 = add i64 %14460, 1
  store i64 %14461, i64* %STACK_DEP_PTR, align 4
  %14462 = load i64, i64* %STACK_DEP_PTR, align 4
  %14463 = getelementptr i256, i256* %STACK, i64 %14462
  store i256 %14429, i256* %14463, align 4
  %14464 = load i64, i64* %STACK_DEP_PTR, align 4
  %14465 = add i64 %14464, 1
  store i64 %14465, i64* %STACK_DEP_PTR, align 4
  %14466 = load i64, i64* %STACK_DEP_PTR, align 4
  %14467 = getelementptr i256, i256* %STACK, i64 %14466
  store i256 %14424, i256* %14467, align 4
  %14468 = load i64, i64* %STACK_DEP_PTR, align 4
  %14469 = add i64 %14468, 1
  store i64 %14469, i64* %STACK_DEP_PTR, align 4
  %14470 = load i64, i64* %STACK_DEP_PTR, align 4
  %14471 = getelementptr i256, i256* %STACK, i64 %14470
  store i256 %14434, i256* %14471, align 4
  %14472 = load i64, i64* %STACK_DEP_PTR, align 4
  %14473 = add i64 %14472, 1
  store i64 %14473, i64* %STACK_DEP_PTR, align 4
  %14474 = load i64, i64* %STACK_DEP_PTR, align 4
  %14475 = getelementptr i256, i256* %STACK, i64 %14474
  store i256 0, i256* %14475, align 4
  br i1 %jump.check59, label %.5893, label %.5873, !EVMBB !4

.5873:                                            ; preds = %14415
  %14476 = load i64, i64* %STACK_DEP_PTR, align 4
  %14477 = sub i64 %14476, 2
  store i64 %14477, i64* %STACK_DEP_PTR, align 4
  %14478 = add i256 32, %14434, !pc !271, !intsan !10
  %14479 = mul i256 0, 32, !pc !272, !intsan !45
  %14480 = trunc i256 %14478 to i32
  %14481 = trunc i256 %14479 to i32
  %14482 = urem i32 %14480, 728
  %14483 = getelementptr i8, i8* %MEMORY, i32 %14482
  %14484 = add i32 1358, 19439
  %14485 = load i32, i32 addrspace(4)* @__evmCodeSize, align 4
  %14486 = urem i32 %14484, %14485
  %14487 = urem i32 %14481, %14485
  %14488 = add i32 %14486, %14487
  %14489 = icmp ugt i32 %14488, %14485
  %14490 = select i1 %14489, i32 0, i32 %14487
  %14491 = add i32 %14482, %14490
  %14492 = icmp ugt i32 %14491, 728
  %14493 = select i1 %14492, i32 0, i32 %14490
  %14494 = getelementptr [32769 x i8], [32769 x i8] addrspace(4)* @__evmCode, i32 0, i32 %14486
  call void @llvm.memcpy.p0i8.p4i8.i32(i8* %14483, i8 addrspace(4)* %14494, i32 %14493, i1 false)
  %14495 = add i256 %14478, %14479, !pc !273, !intsan !10
  %14496 = load i64, i64* %STACK_DEP_PTR, align 4
  %14497 = add i64 %14496, 1
  store i64 %14497, i64* %STACK_DEP_PTR, align 4
  %14498 = load i64, i64* %STACK_DEP_PTR, align 4
  %14499 = getelementptr i256, i256* %STACK, i64 %14498
  store i256 %14434, i256* %14499, align 4
  %14500 = load i64, i64* %STACK_DEP_PTR, align 4
  %14501 = add i64 %14500, 1
  store i64 %14501, i64* %STACK_DEP_PTR, align 4
  %14502 = load i64, i64* %STACK_DEP_PTR, align 4
  %14503 = getelementptr i256, i256* %STACK, i64 %14502
  store i256 %14495, i256* %14503, align 4
  br label %.5893

.5893:                                            ; preds = %.5873, %14415, %JumpTable
  %14504 = load i64, i64* %remaing_gas, align 4
  %14505 = icmp ugt i64 72, %14504
  br i1 %14505, label %Abort, label %14506

14506:                                            ; preds = %.5893
  %14507 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14508 = xor i32 %14507, 3756
  %14509 = urem i32 %14508, 4096
  %14510 = getelementptr i8, i8 addrspace(1)* %4, i32 %14509
  %14511 = load i8, i8 addrspace(1)* %14510, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14510, align 1, !nosanitize !3
  store i32 1878, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14512 = sub i64 %14504, 72
  store i64 %14512, i64* %remaing_gas, align 4
  %14513 = load i64, i64* %STACK_DEP_PTR, align 4
  %14514 = getelementptr i256, i256* %STACK, i64 %14513
  %14515 = load i256, i256* %14514, align 4
  %14516 = load i64, i64* %STACK_DEP_PTR, align 4
  %14517 = sub i64 %14516, 1
  store i64 %14517, i64* %STACK_DEP_PTR, align 4
  %14518 = trunc i256 5903 to i64
  br label %.5903, !EVMBB !4

.5899:                                            ; preds = %JumpTable
  %14519 = load i64, i64* %remaing_gas, align 4
  %14520 = icmp ugt i64 176, %14519
  br i1 %14520, label %Abort, label %14521

14521:                                            ; preds = %.5899
  %14522 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14523 = xor i32 %14522, 2651
  %14524 = urem i32 %14523, 4096
  %14525 = getelementptr i8, i8 addrspace(1)* %4, i32 %14524
  %14526 = load i8, i8 addrspace(1)* %14525, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14525, align 1, !nosanitize !3
  store i32 1325, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14527 = sub i64 %14519, 176
  store i64 %14527, i64* %remaing_gas, align 4
  %14528 = load i64, i64* %STACK_DEP_PTR, align 4
  %14529 = getelementptr i256, i256* %STACK, i64 %14528
  %14530 = load i256, i256* %14529, align 4
  %14531 = load i64, i64* %STACK_DEP_PTR, align 4
  %14532 = sub i64 %14531, 1
  store i64 %14532, i64* %STACK_DEP_PTR, align 4
  %14533 = load i64, i64* %STACK_DEP_PTR, align 4
  %14534 = getelementptr i256, i256* %STACK, i64 %14533
  %14535 = load i256, i256* %14534, align 4
  %14536 = load i64, i64* %STACK_DEP_PTR, align 4
  %14537 = sub i64 %14536, 1
  store i64 %14537, i64* %STACK_DEP_PTR, align 4
  %14538 = load i64, i64* %STACK_DEP_PTR, align 4
  %14539 = getelementptr i256, i256* %STACK, i64 %14538
  %14540 = load i256, i256* %14539, align 4
  %14541 = load i64, i64* %STACK_DEP_PTR, align 4
  %14542 = sub i64 %14541, 1
  store i64 %14542, i64* %STACK_DEP_PTR, align 4
  %14543 = trunc i256 %14540 to i64
  store i64 %14543, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.5903:                                            ; preds = %14506, %1680, %JumpTable
  %14544 = load i64, i64* %remaing_gas, align 4
  %14545 = icmp ugt i64 120, %14544
  br i1 %14545, label %Abort, label %14546

14546:                                            ; preds = %.5903
  %14547 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14548 = xor i32 %14547, 2547
  %14549 = urem i32 %14548, 4096
  %14550 = getelementptr i8, i8 addrspace(1)* %4, i32 %14549
  %14551 = load i8, i8 addrspace(1)* %14550, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14550, align 1, !nosanitize !3
  store i32 1273, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14552 = sub i64 %14544, 120
  store i64 %14552, i64* %remaing_gas, align 4
  %14553 = trunc i256 14033 to i64
  %14554 = load i64, i64* %STACK_DEP_PTR, align 4
  %14555 = add i64 %14554, 1
  store i64 %14555, i64* %STACK_DEP_PTR, align 4
  %14556 = load i64, i64* %STACK_DEP_PTR, align 4
  %14557 = getelementptr i256, i256* %STACK, i64 %14556
  store i256 0, i256* %14557, align 4
  %14558 = load i64, i64* %STACK_DEP_PTR, align 4
  %14559 = add i64 %14558, 1
  store i64 %14559, i64* %STACK_DEP_PTR, align 4
  %14560 = load i64, i64* %STACK_DEP_PTR, align 4
  %14561 = getelementptr i256, i256* %STACK, i64 %14560
  store i256 5913, i256* %14561, align 4
  br label %.14033, !EVMBB !4

.5913:                                            ; preds = %JumpTable
  %14562 = load i64, i64* %remaing_gas, align 4
  %14563 = icmp ugt i64 128, %14562
  br i1 %14563, label %Abort, label %14564

14564:                                            ; preds = %.5913
  %14565 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14566 = xor i32 %14565, 2958
  %14567 = urem i32 %14566, 4096
  %14568 = getelementptr i8, i8 addrspace(1)* %4, i32 %14567
  %14569 = load i8, i8 addrspace(1)* %14568, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14568, align 1, !nosanitize !3
  store i32 1479, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14570 = sub i64 %14562, 128
  store i64 %14570, i64* %remaing_gas, align 4
  %14571 = load i64, i64* %STACK_DEP_PTR, align 4
  %14572 = getelementptr i256, i256* %STACK, i64 %14571
  %14573 = load i256, i256* %14572, align 4
  %14574 = load i64, i64* %STACK_DEP_PTR, align 4
  %14575 = sub i64 %14574, 1
  store i64 %14575, i64* %STACK_DEP_PTR, align 4
  %14576 = and i256 1461501637330902918203684832716283019655932542975, %14573
  %14577 = load i256, i256* %0, align 4
  %14578 = and i256 1461501637330902918203684832716283019655932542975, %14577
  %14579 = icmp eq i256 %14578, %14576
  %14580 = icmp eq i1 %14579, false
  %14581 = icmp eq i1 %14580, false
  %14582 = trunc i256 5970 to i64
  %jump.check107 = icmp ne i1 %14581, false
  br i1 %jump.check107, label %.5970, label %.5966, !EVMBB !4

.5966:                                            ; preds = %14564
  %14583 = load i64, i64* %remaing_gas, align 4
  %14584 = icmp ugt i64 16, %14583
  br i1 %14584, label %Abort, label %14585

14585:                                            ; preds = %.5966
  %14586 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14587 = xor i32 %14586, 1868
  %14588 = urem i32 %14587, 4096
  %14589 = getelementptr i8, i8 addrspace(1)* %4, i32 %14588
  %14590 = load i8, i8 addrspace(1)* %14589, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14589, align 1, !nosanitize !3
  store i32 934, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14591 = sub i64 %14583, 16
  store i64 %14591, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.5970:                                            ; preds = %14564, %JumpTable
  %14592 = load i64, i64* %remaing_gas, align 4
  %14593 = icmp ugt i64 792, %14592
  br i1 %14593, label %Abort, label %14594

14594:                                            ; preds = %.5970
  %14595 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14596 = xor i32 %14595, 3543
  %14597 = urem i32 %14596, 4096
  %14598 = getelementptr i8, i8 addrspace(1)* %4, i32 %14597
  %14599 = load i8, i8 addrspace(1)* %14598, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14598, align 1, !nosanitize !3
  store i32 1771, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14600 = sub i64 %14592, 792
  store i64 %14600, i64* %remaing_gas, align 4
  %14601 = load i64, i64* %STACK_DEP_PTR, align 4
  %14602 = getelementptr i256, i256* %STACK, i64 %14601
  %14603 = load i256, i256* %14602, align 4
  %14604 = load i64, i64* %STACK_DEP_PTR, align 4
  %14605 = sub i64 %14604, 1
  store i64 %14605, i64* %STACK_DEP_PTR, align 4
  %14606 = load i64, i64* %STACK_DEP_PTR, align 4
  %14607 = getelementptr i256, i256* %STACK, i64 %14606
  %14608 = load i256, i256* %14607, align 4
  %14609 = load i64, i64* %STACK_DEP_PTR, align 4
  %14610 = sub i64 %14609, 1
  store i64 %14610, i64* %STACK_DEP_PTR, align 4
  %14611 = load i64, i64* %STACK_DEP_PTR, align 4
  %14612 = getelementptr i256, i256* %STACK, i64 %14611
  %14613 = load i256, i256* %14612, align 4
  %14614 = load i64, i64* %STACK_DEP_PTR, align 4
  %14615 = sub i64 %14614, 1
  store i64 %14615, i64* %STACK_DEP_PTR, align 4
  %14616 = load i64, i64* %STACK_DEP_PTR, align 4
  %14617 = getelementptr i256, i256* %STACK, i64 %14616
  %14618 = load i256, i256* %14617, align 4
  %14619 = load i64, i64* %STACK_DEP_PTR, align 4
  %14620 = sub i64 %14619, 1
  store i64 %14620, i64* %STACK_DEP_PTR, align 4
  %14621 = and i256 1461501637330902918203684832716283019655932542975, 0
  %14622 = xor i256 0, -1
  %14623 = and i256 %14622, %14618
  %14624 = xor i256 0, -1
  %14625 = and i256 %14624, %14623
  %14626 = trunc i256 0 to i64
  %14627 = alloca i256, align 8
  store i256 %14625, i256* %14627, align 4
  %14628 = bitcast i256* %14627 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14626, i8* %14628, i64 32)
  %14629 = add i256 32, 0, !pc !274, !intsan !10
  %14630 = trunc i256 %14629 to i64
  %14631 = alloca i256, align 8
  store i256 11, i256* %14631, align 4
  %14632 = bitcast i256* %14631 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14630, i8* %14632, i64 32)
  %14633 = add i256 32, %14629, !pc !275, !intsan !10
  %14634 = trunc i256 0 to i32
  %14635 = trunc i256 %14633 to i32
  %14636 = getelementptr inbounds i8, i8* %MEMORY, i32 %14634
  %14637 = alloca i256, align 8
  %14638 = bitcast i256* %14637 to i8*
  call void @__device_sha3(i8* %14636, i32 %14635, i8* %14638)
  %14639 = load i256, i256* %14637, align 4
  %14640 = add i256 0, %14639, !pc !276, !intsan !10
  %14641 = alloca i256, align 8
  store i256 %14640, i256* %14641, align 4
  %14642 = alloca i256, align 8
  call void @__device_sload(i256* %14641, i256* %14642)
  %14643 = call i32 @__hashword(i256* %14641)
  %14644 = load i32, i32* %5, align 4
  %14645 = icmp eq i32 %14643, %14644
  %14646 = or i1 false, %14645
  %14647 = load i32, i32* %6, align 4
  %14648 = icmp eq i32 %14643, %14647
  %14649 = or i1 %14646, %14648
  %14650 = load i32, i32* %7, align 4
  %14651 = icmp eq i32 %14643, %14650
  %14652 = or i1 %14649, %14651
  %14653 = load i32, i32* %8, align 4
  %14654 = icmp eq i32 %14643, %14653
  %14655 = or i1 %14652, %14654
  %14656 = load i32, i32* %9, align 4
  %14657 = icmp eq i32 %14643, %14656
  %14658 = or i1 %14655, %14657
  %14659 = load i32, i32* %10, align 4
  %14660 = icmp eq i32 %14643, %14659
  %14661 = or i1 %14658, %14660
  %14662 = load i32, i32* %11, align 4
  %14663 = icmp eq i32 %14643, %14662
  %14664 = or i1 %14661, %14663
  %14665 = load i32, i32* %12, align 4
  %14666 = icmp eq i32 %14643, %14665
  %14667 = or i1 %14664, %14666
  %14668 = load i32, i32* %13, align 4
  %14669 = icmp eq i32 %14643, %14668
  %14670 = or i1 %14667, %14669
  %14671 = load i32, i32* %14, align 4
  %14672 = icmp eq i32 %14643, %14671
  %14673 = or i1 %14670, %14672
  %14674 = load i32, i32* %15, align 4
  %14675 = icmp eq i32 %14643, %14674
  %14676 = or i1 %14673, %14675
  %14677 = load i32, i32* %16, align 4
  %14678 = icmp eq i32 %14643, %14677
  %14679 = or i1 %14676, %14678
  %14680 = load i32, i32* %17, align 4
  %14681 = icmp eq i32 %14643, %14680
  %14682 = or i1 %14679, %14681
  %14683 = load i32, i32* %18, align 4
  %14684 = icmp eq i32 %14643, %14683
  %14685 = or i1 %14682, %14684
  %14686 = load i32, i32* %19, align 4
  %14687 = icmp eq i32 %14643, %14686
  %14688 = or i1 %14685, %14687
  %14689 = load i32, i32* %20, align 4
  %14690 = icmp eq i32 %14643, %14689
  %14691 = or i1 %14688, %14690
  %14692 = load i32, i32* %21, align 4
  %14693 = icmp eq i32 %14643, %14692
  %14694 = or i1 %14691, %14693
  %14695 = load i32, i32* %22, align 4
  %14696 = icmp eq i32 %14643, %14695
  %14697 = or i1 %14694, %14696
  %14698 = load i32, i32* %23, align 4
  %14699 = icmp eq i32 %14643, %14698
  %14700 = or i1 %14697, %14699
  %14701 = load i32, i32* %24, align 4
  %14702 = icmp eq i32 %14643, %14701
  %14703 = or i1 %14700, %14702
  %14704 = load i32, i32* %25, align 4
  %14705 = icmp eq i32 %14643, %14704
  %14706 = or i1 %14703, %14705
  %14707 = load i32, i32* %26, align 4
  %14708 = icmp eq i32 %14643, %14707
  %14709 = or i1 %14706, %14708
  %14710 = load i32, i32* %27, align 4
  %14711 = icmp eq i32 %14643, %14710
  %14712 = or i1 %14709, %14711
  %14713 = load i32, i32* %28, align 4
  %14714 = icmp eq i32 %14643, %14713
  %14715 = or i1 %14712, %14714
  %14716 = load i32, i32* %29, align 4
  %14717 = icmp eq i32 %14643, %14716
  %14718 = or i1 %14715, %14717
  %14719 = load i32, i32* %30, align 4
  %14720 = icmp eq i32 %14643, %14719
  %14721 = or i1 %14718, %14720
  %14722 = load i32, i32* %31, align 4
  %14723 = icmp eq i32 %14643, %14722
  %14724 = or i1 %14721, %14723
  %14725 = load i32, i32* %32, align 4
  %14726 = icmp eq i32 %14643, %14725
  %14727 = or i1 %14724, %14726
  %14728 = load i32, i32* %33, align 4
  %14729 = icmp eq i32 %14643, %14728
  %14730 = or i1 %14727, %14729
  %14731 = load i32, i32* %34, align 4
  %14732 = icmp eq i32 %14643, %14731
  %14733 = or i1 %14730, %14732
  %14734 = load i32, i32* %35, align 4
  %14735 = icmp eq i32 %14643, %14734
  %14736 = or i1 %14733, %14735
  %14737 = load i32, i32* %36, align 4
  %14738 = icmp eq i32 %14643, %14737
  %14739 = or i1 %14736, %14738
  %14740 = load i32, i32* %37, align 4
  %14741 = icmp eq i32 %14643, %14740
  %14742 = or i1 %14739, %14741
  %14743 = load i32, i32* %38, align 4
  %14744 = icmp eq i32 %14643, %14743
  %14745 = or i1 %14742, %14744
  %14746 = load i32, i32* %39, align 4
  %14747 = icmp eq i32 %14643, %14746
  %14748 = or i1 %14745, %14747
  %14749 = load i32, i32* %40, align 4
  %14750 = icmp eq i32 %14643, %14749
  %14751 = or i1 %14748, %14750
  %14752 = load i32, i32* %41, align 4
  %14753 = icmp eq i32 %14643, %14752
  %14754 = or i1 %14751, %14753
  %14755 = load i32, i32* %42, align 4
  %14756 = icmp eq i32 %14643, %14755
  %14757 = or i1 %14754, %14756
  %14758 = load i32, i32* %43, align 4
  %14759 = icmp eq i32 %14643, %14758
  %14760 = or i1 %14757, %14759
  %14761 = load i32, i32* %44, align 4
  %14762 = icmp eq i32 %14643, %14761
  %14763 = or i1 %14760, %14762
  %14764 = load i32, i32* %45, align 4
  %14765 = icmp eq i32 %14643, %14764
  %14766 = or i1 %14763, %14765
  %14767 = load i32, i32* %46, align 4
  %14768 = icmp eq i32 %14643, %14767
  %14769 = or i1 %14766, %14768
  %14770 = load i32, i32* %47, align 4
  %14771 = icmp eq i32 %14643, %14770
  %14772 = or i1 %14769, %14771
  %14773 = load i32, i32* %48, align 4
  %14774 = icmp eq i32 %14643, %14773
  %14775 = or i1 %14772, %14774
  %14776 = load i32, i32* %49, align 4
  %14777 = icmp eq i32 %14643, %14776
  %14778 = or i1 %14775, %14777
  %14779 = load i32, i32* %50, align 4
  %14780 = icmp eq i32 %14643, %14779
  %14781 = or i1 %14778, %14780
  %14782 = load i32, i32* %51, align 4
  %14783 = icmp eq i32 %14643, %14782
  %14784 = or i1 %14781, %14783
  %14785 = load i32, i32* %52, align 4
  %14786 = icmp eq i32 %14643, %14785
  %14787 = or i1 %14784, %14786
  %14788 = load i32, i32* %53, align 4
  %14789 = icmp eq i32 %14643, %14788
  %14790 = or i1 %14787, %14789
  %14791 = load i32, i32* %54, align 4
  %14792 = icmp eq i32 %14643, %14791
  %14793 = or i1 %14790, %14792
  %14794 = load i32, i32* %55, align 4
  %14795 = icmp eq i32 %14643, %14794
  %14796 = or i1 %14793, %14795
  %14797 = load i32, i32* %56, align 4
  %14798 = icmp eq i32 %14643, %14797
  %14799 = or i1 %14796, %14798
  %14800 = load i32, i32* %57, align 4
  %14801 = icmp eq i32 %14643, %14800
  %14802 = or i1 %14799, %14801
  %14803 = load i32, i32* %58, align 4
  %14804 = icmp eq i32 %14643, %14803
  %14805 = or i1 %14802, %14804
  %14806 = load i32, i32* %59, align 4
  %14807 = icmp eq i32 %14643, %14806
  %14808 = or i1 %14805, %14807
  %14809 = load i32, i32* %60, align 4
  %14810 = icmp eq i32 %14643, %14809
  %14811 = or i1 %14808, %14810
  %14812 = load i32, i32* %61, align 4
  %14813 = icmp eq i32 %14643, %14812
  %14814 = or i1 %14811, %14813
  %14815 = load i32, i32* %62, align 4
  %14816 = icmp eq i32 %14643, %14815
  %14817 = or i1 %14814, %14816
  %14818 = getelementptr i8, i8 addrspace(1)* %4, i32 46
  %14819 = zext i1 %14817 to i8
  store i8 %14819, i8 addrspace(1)* %14818, align 1, !nosanitize !3
  %14820 = load i256, i256* %14642, align 4
  %14821 = alloca i256, align 8
  store i256 %14820, i256* %14821, align 4
  %14822 = alloca i256, align 8
  store i256 1, i256* %14822, align 4
  %14823 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %14821, i256* %14822, i256* %14823), !pc !277, !intsan !6
  %14824 = load i256, i256* %14823, align 4
  %14825 = and i256 1461501637330902918203684832716283019655932542975, %14824
  %14826 = and i256 1461501637330902918203684832716283019655932542975, %14825
  %14827 = icmp eq i256 %14826, %14621
  %14828 = icmp eq i1 %14827, false
  %14829 = trunc i256 6091 to i64
  %jump.check113 = icmp ne i1 %14828, false
  %14830 = load i64, i64* %STACK_DEP_PTR, align 4
  %14831 = add i64 %14830, 1
  store i64 %14831, i64* %STACK_DEP_PTR, align 4
  %14832 = load i64, i64* %STACK_DEP_PTR, align 4
  %14833 = getelementptr i256, i256* %STACK, i64 %14832
  store i256 %14618, i256* %14833, align 4
  %14834 = load i64, i64* %STACK_DEP_PTR, align 4
  %14835 = add i64 %14834, 1
  store i64 %14835, i64* %STACK_DEP_PTR, align 4
  %14836 = load i64, i64* %STACK_DEP_PTR, align 4
  %14837 = getelementptr i256, i256* %STACK, i64 %14836
  store i256 %14613, i256* %14837, align 4
  %14838 = load i64, i64* %STACK_DEP_PTR, align 4
  %14839 = add i64 %14838, 1
  store i64 %14839, i64* %STACK_DEP_PTR, align 4
  %14840 = load i64, i64* %STACK_DEP_PTR, align 4
  %14841 = getelementptr i256, i256* %STACK, i64 %14840
  store i256 %14608, i256* %14841, align 4
  %14842 = load i64, i64* %STACK_DEP_PTR, align 4
  %14843 = add i64 %14842, 1
  store i64 %14843, i64* %STACK_DEP_PTR, align 4
  %14844 = load i64, i64* %STACK_DEP_PTR, align 4
  %14845 = getelementptr i256, i256* %STACK, i64 %14844
  store i256 %14603, i256* %14845, align 4
  %14846 = load i64, i64* %STACK_DEP_PTR, align 4
  %14847 = add i64 %14846, 1
  store i64 %14847, i64* %STACK_DEP_PTR, align 4
  %14848 = load i64, i64* %STACK_DEP_PTR, align 4
  %14849 = getelementptr i256, i256* %STACK, i64 %14848
  store i256 %14618, i256* %14849, align 4
  br i1 %jump.check113, label %.6091, label %.6087, !EVMBB !4

.6087:                                            ; preds = %14594
  %14850 = load i64, i64* %remaing_gas, align 4
  %14851 = icmp ugt i64 40, %14850
  br i1 %14851, label %Abort, label %14852

14852:                                            ; preds = %.6087
  %14853 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14854 = xor i32 %14853, 1581
  %14855 = urem i32 %14854, 4096
  %14856 = getelementptr i8, i8 addrspace(1)* %4, i32 %14855
  %14857 = load i8, i8 addrspace(1)* %14856, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14856, align 1, !nosanitize !3
  store i32 790, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14858 = sub i64 %14850, 40
  store i64 %14858, i64* %remaing_gas, align 4
  %14859 = load i64, i64* %STACK_DEP_PTR, align 4
  %14860 = sub i64 %14859, 0
  store i64 %14860, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.6091:                                            ; preds = %14594, %JumpTable
  %14861 = load i64, i64* %remaing_gas, align 4
  %14862 = icmp ugt i64 808, %14861
  br i1 %14862, label %Abort, label %14863

14863:                                            ; preds = %.6091
  %14864 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14865 = xor i32 %14864, 667
  %14866 = urem i32 %14865, 4096
  %14867 = getelementptr i8, i8 addrspace(1)* %4, i32 %14866
  %14868 = load i8, i8 addrspace(1)* %14867, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %14867, align 1, !nosanitize !3
  store i32 333, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %14869 = sub i64 %14861, 808
  store i64 %14869, i64* %remaing_gas, align 4
  %14870 = load i64, i64* %STACK_DEP_PTR, align 4
  %14871 = getelementptr i256, i256* %STACK, i64 %14870
  %14872 = load i256, i256* %14871, align 4
  %14873 = load i64, i64* %STACK_DEP_PTR, align 4
  %14874 = sub i64 %14873, 1
  store i64 %14874, i64* %STACK_DEP_PTR, align 4
  %14875 = load i64, i64* %STACK_DEP_PTR, align 4
  %14876 = getelementptr i256, i256* %STACK, i64 %14875
  %14877 = load i256, i256* %14876, align 4
  %14878 = load i64, i64* %STACK_DEP_PTR, align 4
  %14879 = sub i64 %14878, 1
  store i64 %14879, i64* %STACK_DEP_PTR, align 4
  %14880 = load i64, i64* %STACK_DEP_PTR, align 4
  %14881 = getelementptr i256, i256* %STACK, i64 %14880
  %14882 = load i256, i256* %14881, align 4
  %14883 = load i64, i64* %STACK_DEP_PTR, align 4
  %14884 = sub i64 %14883, 1
  store i64 %14884, i64* %STACK_DEP_PTR, align 4
  %14885 = load i64, i64* %STACK_DEP_PTR, align 4
  %14886 = getelementptr i256, i256* %STACK, i64 %14885
  %14887 = load i256, i256* %14886, align 4
  %14888 = load i64, i64* %STACK_DEP_PTR, align 4
  %14889 = sub i64 %14888, 1
  store i64 %14889, i64* %STACK_DEP_PTR, align 4
  %14890 = load i64, i64* %STACK_DEP_PTR, align 4
  %14891 = getelementptr i256, i256* %STACK, i64 %14890
  %14892 = load i256, i256* %14891, align 4
  %14893 = load i64, i64* %STACK_DEP_PTR, align 4
  %14894 = sub i64 %14893, 1
  store i64 %14894, i64* %STACK_DEP_PTR, align 4
  %14895 = xor i256 0, -1
  %14896 = and i256 %14895, %14892
  %14897 = xor i256 0, -1
  %14898 = and i256 %14897, %14896
  %14899 = trunc i256 0 to i64
  %14900 = alloca i256, align 8
  store i256 %14898, i256* %14900, align 4
  %14901 = bitcast i256* %14900 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14899, i8* %14901, i64 32)
  %14902 = add i256 32, 0, !pc !278, !intsan !10
  %14903 = trunc i256 %14902 to i64
  %14904 = alloca i256, align 8
  store i256 11, i256* %14904, align 4
  %14905 = bitcast i256* %14904 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %14903, i8* %14905, i64 32)
  %14906 = add i256 32, %14902, !pc !279, !intsan !10
  %14907 = trunc i256 0 to i32
  %14908 = trunc i256 %14906 to i32
  %14909 = getelementptr inbounds i8, i8* %MEMORY, i32 %14907
  %14910 = alloca i256, align 8
  %14911 = bitcast i256* %14910 to i8*
  call void @__device_sha3(i8* %14909, i32 %14908, i8* %14911)
  %14912 = load i256, i256* %14910, align 4
  %14913 = add i256 2, %14912, !pc !280, !intsan !10
  %14914 = alloca i256, align 8
  store i256 %14913, i256* %14914, align 4
  %14915 = alloca i256, align 8
  call void @__device_sload(i256* %14914, i256* %14915)
  %14916 = call i32 @__hashword(i256* %14914)
  %14917 = load i32, i32* %5, align 4
  %14918 = icmp eq i32 %14916, %14917
  %14919 = or i1 false, %14918
  %14920 = load i32, i32* %6, align 4
  %14921 = icmp eq i32 %14916, %14920
  %14922 = or i1 %14919, %14921
  %14923 = load i32, i32* %7, align 4
  %14924 = icmp eq i32 %14916, %14923
  %14925 = or i1 %14922, %14924
  %14926 = load i32, i32* %8, align 4
  %14927 = icmp eq i32 %14916, %14926
  %14928 = or i1 %14925, %14927
  %14929 = load i32, i32* %9, align 4
  %14930 = icmp eq i32 %14916, %14929
  %14931 = or i1 %14928, %14930
  %14932 = load i32, i32* %10, align 4
  %14933 = icmp eq i32 %14916, %14932
  %14934 = or i1 %14931, %14933
  %14935 = load i32, i32* %11, align 4
  %14936 = icmp eq i32 %14916, %14935
  %14937 = or i1 %14934, %14936
  %14938 = load i32, i32* %12, align 4
  %14939 = icmp eq i32 %14916, %14938
  %14940 = or i1 %14937, %14939
  %14941 = load i32, i32* %13, align 4
  %14942 = icmp eq i32 %14916, %14941
  %14943 = or i1 %14940, %14942
  %14944 = load i32, i32* %14, align 4
  %14945 = icmp eq i32 %14916, %14944
  %14946 = or i1 %14943, %14945
  %14947 = load i32, i32* %15, align 4
  %14948 = icmp eq i32 %14916, %14947
  %14949 = or i1 %14946, %14948
  %14950 = load i32, i32* %16, align 4
  %14951 = icmp eq i32 %14916, %14950
  %14952 = or i1 %14949, %14951
  %14953 = load i32, i32* %17, align 4
  %14954 = icmp eq i32 %14916, %14953
  %14955 = or i1 %14952, %14954
  %14956 = load i32, i32* %18, align 4
  %14957 = icmp eq i32 %14916, %14956
  %14958 = or i1 %14955, %14957
  %14959 = load i32, i32* %19, align 4
  %14960 = icmp eq i32 %14916, %14959
  %14961 = or i1 %14958, %14960
  %14962 = load i32, i32* %20, align 4
  %14963 = icmp eq i32 %14916, %14962
  %14964 = or i1 %14961, %14963
  %14965 = load i32, i32* %21, align 4
  %14966 = icmp eq i32 %14916, %14965
  %14967 = or i1 %14964, %14966
  %14968 = load i32, i32* %22, align 4
  %14969 = icmp eq i32 %14916, %14968
  %14970 = or i1 %14967, %14969
  %14971 = load i32, i32* %23, align 4
  %14972 = icmp eq i32 %14916, %14971
  %14973 = or i1 %14970, %14972
  %14974 = load i32, i32* %24, align 4
  %14975 = icmp eq i32 %14916, %14974
  %14976 = or i1 %14973, %14975
  %14977 = load i32, i32* %25, align 4
  %14978 = icmp eq i32 %14916, %14977
  %14979 = or i1 %14976, %14978
  %14980 = load i32, i32* %26, align 4
  %14981 = icmp eq i32 %14916, %14980
  %14982 = or i1 %14979, %14981
  %14983 = load i32, i32* %27, align 4
  %14984 = icmp eq i32 %14916, %14983
  %14985 = or i1 %14982, %14984
  %14986 = load i32, i32* %28, align 4
  %14987 = icmp eq i32 %14916, %14986
  %14988 = or i1 %14985, %14987
  %14989 = load i32, i32* %29, align 4
  %14990 = icmp eq i32 %14916, %14989
  %14991 = or i1 %14988, %14990
  %14992 = load i32, i32* %30, align 4
  %14993 = icmp eq i32 %14916, %14992
  %14994 = or i1 %14991, %14993
  %14995 = load i32, i32* %31, align 4
  %14996 = icmp eq i32 %14916, %14995
  %14997 = or i1 %14994, %14996
  %14998 = load i32, i32* %32, align 4
  %14999 = icmp eq i32 %14916, %14998
  %15000 = or i1 %14997, %14999
  %15001 = load i32, i32* %33, align 4
  %15002 = icmp eq i32 %14916, %15001
  %15003 = or i1 %15000, %15002
  %15004 = load i32, i32* %34, align 4
  %15005 = icmp eq i32 %14916, %15004
  %15006 = or i1 %15003, %15005
  %15007 = load i32, i32* %35, align 4
  %15008 = icmp eq i32 %14916, %15007
  %15009 = or i1 %15006, %15008
  %15010 = load i32, i32* %36, align 4
  %15011 = icmp eq i32 %14916, %15010
  %15012 = or i1 %15009, %15011
  %15013 = load i32, i32* %37, align 4
  %15014 = icmp eq i32 %14916, %15013
  %15015 = or i1 %15012, %15014
  %15016 = load i32, i32* %38, align 4
  %15017 = icmp eq i32 %14916, %15016
  %15018 = or i1 %15015, %15017
  %15019 = load i32, i32* %39, align 4
  %15020 = icmp eq i32 %14916, %15019
  %15021 = or i1 %15018, %15020
  %15022 = load i32, i32* %40, align 4
  %15023 = icmp eq i32 %14916, %15022
  %15024 = or i1 %15021, %15023
  %15025 = load i32, i32* %41, align 4
  %15026 = icmp eq i32 %14916, %15025
  %15027 = or i1 %15024, %15026
  %15028 = load i32, i32* %42, align 4
  %15029 = icmp eq i32 %14916, %15028
  %15030 = or i1 %15027, %15029
  %15031 = load i32, i32* %43, align 4
  %15032 = icmp eq i32 %14916, %15031
  %15033 = or i1 %15030, %15032
  %15034 = load i32, i32* %44, align 4
  %15035 = icmp eq i32 %14916, %15034
  %15036 = or i1 %15033, %15035
  %15037 = load i32, i32* %45, align 4
  %15038 = icmp eq i32 %14916, %15037
  %15039 = or i1 %15036, %15038
  %15040 = load i32, i32* %46, align 4
  %15041 = icmp eq i32 %14916, %15040
  %15042 = or i1 %15039, %15041
  %15043 = load i32, i32* %47, align 4
  %15044 = icmp eq i32 %14916, %15043
  %15045 = or i1 %15042, %15044
  %15046 = load i32, i32* %48, align 4
  %15047 = icmp eq i32 %14916, %15046
  %15048 = or i1 %15045, %15047
  %15049 = load i32, i32* %49, align 4
  %15050 = icmp eq i32 %14916, %15049
  %15051 = or i1 %15048, %15050
  %15052 = load i32, i32* %50, align 4
  %15053 = icmp eq i32 %14916, %15052
  %15054 = or i1 %15051, %15053
  %15055 = load i32, i32* %51, align 4
  %15056 = icmp eq i32 %14916, %15055
  %15057 = or i1 %15054, %15056
  %15058 = load i32, i32* %52, align 4
  %15059 = icmp eq i32 %14916, %15058
  %15060 = or i1 %15057, %15059
  %15061 = load i32, i32* %53, align 4
  %15062 = icmp eq i32 %14916, %15061
  %15063 = or i1 %15060, %15062
  %15064 = load i32, i32* %54, align 4
  %15065 = icmp eq i32 %14916, %15064
  %15066 = or i1 %15063, %15065
  %15067 = load i32, i32* %55, align 4
  %15068 = icmp eq i32 %14916, %15067
  %15069 = or i1 %15066, %15068
  %15070 = load i32, i32* %56, align 4
  %15071 = icmp eq i32 %14916, %15070
  %15072 = or i1 %15069, %15071
  %15073 = load i32, i32* %57, align 4
  %15074 = icmp eq i32 %14916, %15073
  %15075 = or i1 %15072, %15074
  %15076 = load i32, i32* %58, align 4
  %15077 = icmp eq i32 %14916, %15076
  %15078 = or i1 %15075, %15077
  %15079 = load i32, i32* %59, align 4
  %15080 = icmp eq i32 %14916, %15079
  %15081 = or i1 %15078, %15080
  %15082 = load i32, i32* %60, align 4
  %15083 = icmp eq i32 %14916, %15082
  %15084 = or i1 %15081, %15083
  %15085 = load i32, i32* %61, align 4
  %15086 = icmp eq i32 %14916, %15085
  %15087 = or i1 %15084, %15086
  %15088 = load i32, i32* %62, align 4
  %15089 = icmp eq i32 %14916, %15088
  %15090 = or i1 %15087, %15089
  %15091 = getelementptr i8, i8 addrspace(1)* %4, i32 47
  %15092 = zext i1 %15090 to i8
  store i8 %15092, i8 addrspace(1)* %15091, align 1, !nosanitize !3
  %15093 = load i256, i256* %14915, align 4
  %15094 = icmp ugt i256 %15093, 0
  %15095 = icmp eq i1 %15094, false
  %15096 = trunc i256 6136 to i64
  %jump.check119 = icmp ne i1 %15095, false
  %15097 = load i64, i64* %STACK_DEP_PTR, align 4
  %15098 = add i64 %15097, 1
  store i64 %15098, i64* %STACK_DEP_PTR, align 4
  %15099 = load i64, i64* %STACK_DEP_PTR, align 4
  %15100 = getelementptr i256, i256* %STACK, i64 %15099
  store i256 %14892, i256* %15100, align 4
  %15101 = load i64, i64* %STACK_DEP_PTR, align 4
  %15102 = add i64 %15101, 1
  store i64 %15102, i64* %STACK_DEP_PTR, align 4
  %15103 = load i64, i64* %STACK_DEP_PTR, align 4
  %15104 = getelementptr i256, i256* %STACK, i64 %15103
  store i256 %14887, i256* %15104, align 4
  %15105 = load i64, i64* %STACK_DEP_PTR, align 4
  %15106 = add i64 %15105, 1
  store i64 %15106, i64* %STACK_DEP_PTR, align 4
  %15107 = load i64, i64* %STACK_DEP_PTR, align 4
  %15108 = getelementptr i256, i256* %STACK, i64 %15107
  store i256 %14882, i256* %15108, align 4
  %15109 = load i64, i64* %STACK_DEP_PTR, align 4
  %15110 = add i64 %15109, 1
  store i64 %15110, i64* %STACK_DEP_PTR, align 4
  %15111 = load i64, i64* %STACK_DEP_PTR, align 4
  %15112 = getelementptr i256, i256* %STACK, i64 %15111
  store i256 %14877, i256* %15112, align 4
  %15113 = load i64, i64* %STACK_DEP_PTR, align 4
  %15114 = add i64 %15113, 1
  store i64 %15114, i64* %STACK_DEP_PTR, align 4
  %15115 = load i64, i64* %STACK_DEP_PTR, align 4
  %15116 = getelementptr i256, i256* %STACK, i64 %15115
  store i256 %14872, i256* %15116, align 4
  %15117 = load i64, i64* %STACK_DEP_PTR, align 4
  %15118 = add i64 %15117, 1
  store i64 %15118, i64* %STACK_DEP_PTR, align 4
  %15119 = load i64, i64* %STACK_DEP_PTR, align 4
  %15120 = getelementptr i256, i256* %STACK, i64 %15119
  store i256 %14892, i256* %15120, align 4
  br i1 %jump.check119, label %.6136, label %.6132, !EVMBB !4

.6132:                                            ; preds = %14863
  %15121 = load i64, i64* %remaing_gas, align 4
  %15122 = icmp ugt i64 40, %15121
  br i1 %15122, label %Abort, label %15123

15123:                                            ; preds = %.6132
  %15124 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15125 = xor i32 %15124, 3337
  %15126 = urem i32 %15125, 4096
  %15127 = getelementptr i8, i8 addrspace(1)* %4, i32 %15126
  %15128 = load i8, i8 addrspace(1)* %15127, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15127, align 1, !nosanitize !3
  store i32 1668, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15129 = sub i64 %15121, 40
  store i64 %15129, i64* %remaing_gas, align 4
  %15130 = load i64, i64* %STACK_DEP_PTR, align 4
  %15131 = sub i64 %15130, 0
  store i64 %15131, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.6136:                                            ; preds = %14863, %JumpTable
  %15132 = load i64, i64* %remaing_gas, align 4
  %15133 = icmp ugt i64 840, %15132
  br i1 %15133, label %Abort, label %15134

15134:                                            ; preds = %.6136
  %15135 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15136 = xor i32 %15135, 834
  %15137 = urem i32 %15136, 4096
  %15138 = getelementptr i8, i8 addrspace(1)* %4, i32 %15137
  %15139 = load i8, i8 addrspace(1)* %15138, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15138, align 1, !nosanitize !3
  store i32 417, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15140 = sub i64 %15132, 840
  store i64 %15140, i64* %remaing_gas, align 4
  %15141 = load i64, i64* %STACK_DEP_PTR, align 4
  %15142 = getelementptr i256, i256* %STACK, i64 %15141
  %15143 = load i256, i256* %15142, align 4
  %15144 = load i64, i64* %STACK_DEP_PTR, align 4
  %15145 = sub i64 %15144, 1
  store i64 %15145, i64* %STACK_DEP_PTR, align 4
  %15146 = load i64, i64* %STACK_DEP_PTR, align 4
  %15147 = getelementptr i256, i256* %STACK, i64 %15146
  %15148 = load i256, i256* %15147, align 4
  %15149 = load i64, i64* %STACK_DEP_PTR, align 4
  %15150 = sub i64 %15149, 1
  store i64 %15150, i64* %STACK_DEP_PTR, align 4
  %15151 = load i64, i64* %STACK_DEP_PTR, align 4
  %15152 = getelementptr i256, i256* %STACK, i64 %15151
  %15153 = load i256, i256* %15152, align 4
  %15154 = load i64, i64* %STACK_DEP_PTR, align 4
  %15155 = sub i64 %15154, 1
  store i64 %15155, i64* %STACK_DEP_PTR, align 4
  %15156 = load i64, i64* %STACK_DEP_PTR, align 4
  %15157 = getelementptr i256, i256* %STACK, i64 %15156
  %15158 = load i256, i256* %15157, align 4
  %15159 = load i64, i64* %STACK_DEP_PTR, align 4
  %15160 = sub i64 %15159, 1
  store i64 %15160, i64* %STACK_DEP_PTR, align 4
  %15161 = load i64, i64* %STACK_DEP_PTR, align 4
  %15162 = getelementptr i256, i256* %STACK, i64 %15161
  %15163 = load i256, i256* %15162, align 4
  %15164 = load i64, i64* %STACK_DEP_PTR, align 4
  %15165 = sub i64 %15164, 1
  store i64 %15165, i64* %STACK_DEP_PTR, align 4
  %15166 = load i64, i64* %STACK_DEP_PTR, align 4
  %15167 = getelementptr i256, i256* %STACK, i64 %15166
  %15168 = load i256, i256* %15167, align 4
  %15169 = load i64, i64* %STACK_DEP_PTR, align 4
  %15170 = sub i64 %15169, 1
  store i64 %15170, i64* %STACK_DEP_PTR, align 4
  %15171 = trunc i256 14564 to i64
  %15172 = load i64, i64* %STACK_DEP_PTR, align 4
  %15173 = add i64 %15172, 1
  store i64 %15173, i64* %STACK_DEP_PTR, align 4
  %15174 = load i64, i64* %STACK_DEP_PTR, align 4
  %15175 = getelementptr i256, i256* %STACK, i64 %15174
  store i256 %15168, i256* %15175, align 4
  %15176 = load i64, i64* %STACK_DEP_PTR, align 4
  %15177 = add i64 %15176, 1
  store i64 %15177, i64* %STACK_DEP_PTR, align 4
  %15178 = load i64, i64* %STACK_DEP_PTR, align 4
  %15179 = getelementptr i256, i256* %STACK, i64 %15178
  store i256 %15163, i256* %15179, align 4
  %15180 = load i64, i64* %STACK_DEP_PTR, align 4
  %15181 = add i64 %15180, 1
  store i64 %15181, i64* %STACK_DEP_PTR, align 4
  %15182 = load i64, i64* %STACK_DEP_PTR, align 4
  %15183 = getelementptr i256, i256* %STACK, i64 %15182
  store i256 %15158, i256* %15183, align 4
  %15184 = load i64, i64* %STACK_DEP_PTR, align 4
  %15185 = add i64 %15184, 1
  store i64 %15185, i64* %STACK_DEP_PTR, align 4
  %15186 = load i64, i64* %STACK_DEP_PTR, align 4
  %15187 = getelementptr i256, i256* %STACK, i64 %15186
  store i256 %15153, i256* %15187, align 4
  %15188 = load i64, i64* %STACK_DEP_PTR, align 4
  %15189 = add i64 %15188, 1
  store i64 %15189, i64* %STACK_DEP_PTR, align 4
  %15190 = load i64, i64* %STACK_DEP_PTR, align 4
  %15191 = getelementptr i256, i256* %STACK, i64 %15190
  store i256 %15148, i256* %15191, align 4
  %15192 = load i64, i64* %STACK_DEP_PTR, align 4
  %15193 = add i64 %15192, 1
  store i64 %15193, i64* %STACK_DEP_PTR, align 4
  %15194 = load i64, i64* %STACK_DEP_PTR, align 4
  %15195 = getelementptr i256, i256* %STACK, i64 %15194
  store i256 %15143, i256* %15195, align 4
  %15196 = load i64, i64* %STACK_DEP_PTR, align 4
  %15197 = add i64 %15196, 1
  store i64 %15197, i64* %STACK_DEP_PTR, align 4
  %15198 = load i64, i64* %STACK_DEP_PTR, align 4
  %15199 = getelementptr i256, i256* %STACK, i64 %15198
  store i256 %15168, i256* %15199, align 4
  %15200 = load i64, i64* %STACK_DEP_PTR, align 4
  %15201 = add i64 %15200, 1
  store i64 %15201, i64* %STACK_DEP_PTR, align 4
  %15202 = load i64, i64* %STACK_DEP_PTR, align 4
  %15203 = getelementptr i256, i256* %STACK, i64 %15202
  store i256 %15163, i256* %15203, align 4
  %15204 = load i64, i64* %STACK_DEP_PTR, align 4
  %15205 = add i64 %15204, 1
  store i64 %15205, i64* %STACK_DEP_PTR, align 4
  %15206 = load i64, i64* %STACK_DEP_PTR, align 4
  %15207 = getelementptr i256, i256* %STACK, i64 %15206
  store i256 0, i256* %15207, align 4
  %15208 = load i64, i64* %STACK_DEP_PTR, align 4
  %15209 = add i64 %15208, 1
  store i64 %15209, i64* %STACK_DEP_PTR, align 4
  %15210 = load i64, i64* %STACK_DEP_PTR, align 4
  %15211 = getelementptr i256, i256* %STACK, i64 %15210
  store i256 6149, i256* %15211, align 4
  %15212 = load i64, i64* %STACK_DEP_PTR, align 4
  %15213 = add i64 %15212, 1
  store i64 %15213, i64* %STACK_DEP_PTR, align 4
  %15214 = load i64, i64* %STACK_DEP_PTR, align 4
  %15215 = getelementptr i256, i256* %STACK, i64 %15214
  store i256 %15163, i256* %15215, align 4
  br label %.14564, !EVMBB !4

.6149:                                            ; preds = %JumpTable
  %15216 = load i64, i64* %remaing_gas, align 4
  %15217 = icmp ugt i64 240, %15216
  br i1 %15217, label %Abort, label %15218

15218:                                            ; preds = %.6149
  %15219 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15220 = xor i32 %15219, 997
  %15221 = urem i32 %15220, 4096
  %15222 = getelementptr i8, i8 addrspace(1)* %4, i32 %15221
  %15223 = load i8, i8 addrspace(1)* %15222, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15222, align 1, !nosanitize !3
  store i32 498, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15224 = sub i64 %15216, 240
  store i64 %15224, i64* %remaing_gas, align 4
  %15225 = load i64, i64* %STACK_DEP_PTR, align 4
  %15226 = getelementptr i256, i256* %STACK, i64 %15225
  %15227 = load i256, i256* %15226, align 4
  %15228 = load i64, i64* %STACK_DEP_PTR, align 4
  %15229 = sub i64 %15228, 1
  store i64 %15229, i64* %STACK_DEP_PTR, align 4
  %15230 = load i64, i64* %STACK_DEP_PTR, align 4
  %15231 = getelementptr i256, i256* %STACK, i64 %15230
  %15232 = load i256, i256* %15231, align 4
  %15233 = load i64, i64* %STACK_DEP_PTR, align 4
  %15234 = sub i64 %15233, 1
  store i64 %15234, i64* %STACK_DEP_PTR, align 4
  %15235 = icmp ult i256 %15227, 1
  %15236 = trunc i256 6167 to i64
  %jump.check185 = icmp ne i1 %15235, false
  %15237 = load i64, i64* %STACK_DEP_PTR, align 4
  %15238 = add i64 %15237, 1
  store i64 %15238, i64* %STACK_DEP_PTR, align 4
  %15239 = load i64, i64* %STACK_DEP_PTR, align 4
  %15240 = getelementptr i256, i256* %STACK, i64 %15239
  store i256 %15227, i256* %15240, align 4
  %15241 = load i64, i64* %STACK_DEP_PTR, align 4
  %15242 = add i64 %15241, 1
  store i64 %15242, i64* %STACK_DEP_PTR, align 4
  %15243 = zext i1 %15235 to i256
  %15244 = load i64, i64* %STACK_DEP_PTR, align 4
  %15245 = getelementptr i256, i256* %STACK, i64 %15244
  store i256 %15243, i256* %15245, align 4
  br i1 %jump.check185, label %.6167, label %.6161, !EVMBB !4

.6161:                                            ; preds = %15218
  %15246 = load i64, i64* %STACK_DEP_PTR, align 4
  %15247 = getelementptr i256, i256* %STACK, i64 %15246
  %15248 = load i256, i256* %15247, align 4
  %15249 = load i64, i64* %STACK_DEP_PTR, align 4
  %15250 = sub i64 %15249, 1
  store i64 %15250, i64* %STACK_DEP_PTR, align 4
  %15251 = load i64, i64* %STACK_DEP_PTR, align 4
  %15252 = getelementptr i256, i256* %STACK, i64 %15251
  %15253 = load i256, i256* %15252, align 4
  %15254 = load i64, i64* %STACK_DEP_PTR, align 4
  %15255 = sub i64 %15254, 1
  store i64 %15255, i64* %STACK_DEP_PTR, align 4
  %15256 = icmp ugt i256 %15253, 10000
  %15257 = load i64, i64* %STACK_DEP_PTR, align 4
  %15258 = add i64 %15257, 1
  store i64 %15258, i64* %STACK_DEP_PTR, align 4
  %15259 = load i64, i64* %STACK_DEP_PTR, align 4
  %15260 = getelementptr i256, i256* %STACK, i64 %15259
  store i256 %15253, i256* %15260, align 4
  %15261 = load i64, i64* %STACK_DEP_PTR, align 4
  %15262 = add i64 %15261, 1
  store i64 %15262, i64* %STACK_DEP_PTR, align 4
  %15263 = zext i1 %15256 to i256
  %15264 = load i64, i64* %STACK_DEP_PTR, align 4
  %15265 = getelementptr i256, i256* %STACK, i64 %15264
  store i256 %15263, i256* %15265, align 4
  br label %.6167

.6167:                                            ; preds = %.6161, %15218, %JumpTable
  %15266 = load i64, i64* %remaing_gas, align 4
  %15267 = icmp ugt i64 136, %15266
  br i1 %15267, label %Abort, label %15268

15268:                                            ; preds = %.6167
  %15269 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15270 = xor i32 %15269, 2054
  %15271 = urem i32 %15270, 4096
  %15272 = getelementptr i8, i8 addrspace(1)* %4, i32 %15271
  %15273 = load i8, i8 addrspace(1)* %15272, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15272, align 1, !nosanitize !3
  store i32 1027, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15274 = sub i64 %15266, 136
  store i64 %15274, i64* %remaing_gas, align 4
  %15275 = load i64, i64* %STACK_DEP_PTR, align 4
  %15276 = getelementptr i256, i256* %STACK, i64 %15275
  %15277 = load i256, i256* %15276, align 4
  %15278 = load i64, i64* %STACK_DEP_PTR, align 4
  %15279 = sub i64 %15278, 1
  store i64 %15279, i64* %STACK_DEP_PTR, align 4
  %15280 = icmp eq i256 %15277, 0
  %15281 = trunc i256 6209 to i64
  %jump.check186 = icmp ne i1 %15280, false
  %15282 = load i64, i64* %STACK_DEP_PTR, align 4
  %15283 = add i64 %15282, 1
  store i64 %15283, i64* %STACK_DEP_PTR, align 4
  %15284 = load i64, i64* %STACK_DEP_PTR, align 4
  %15285 = getelementptr i256, i256* %STACK, i64 %15284
  store i256 %15277, i256* %15285, align 4
  br i1 %jump.check186, label %.6209, label %.6174, !EVMBB !4

.6174:                                            ; preds = %15268
  %15286 = load i64, i64* %STACK_DEP_PTR, align 4
  %15287 = getelementptr i256, i256* %STACK, i64 %15286
  %15288 = load i256, i256* %15287, align 4
  %15289 = load i64, i64* %STACK_DEP_PTR, align 4
  %15290 = sub i64 %15289, 1
  store i64 %15290, i64* %STACK_DEP_PTR, align 4
  %15291 = load i64, i64* %STACK_DEP_PTR, align 4
  %15292 = getelementptr i256, i256* %STACK, i64 %15291
  %15293 = load i256, i256* %15292, align 4
  %15294 = load i64, i64* %STACK_DEP_PTR, align 4
  %15295 = sub i64 %15294, 1
  store i64 %15295, i64* %STACK_DEP_PTR, align 4
  %15296 = load i64, i64* %STACK_DEP_PTR, align 4
  %15297 = getelementptr i256, i256* %STACK, i64 %15296
  %15298 = load i256, i256* %15297, align 4
  %15299 = load i64, i64* %STACK_DEP_PTR, align 4
  %15300 = sub i64 %15299, 1
  store i64 %15300, i64* %STACK_DEP_PTR, align 4
  %15301 = load i64, i64* %STACK_DEP_PTR, align 4
  %15302 = getelementptr i256, i256* %STACK, i64 %15301
  %15303 = load i256, i256* %15302, align 4
  %15304 = load i64, i64* %STACK_DEP_PTR, align 4
  %15305 = sub i64 %15304, 1
  store i64 %15305, i64* %STACK_DEP_PTR, align 4
  %15306 = xor i256 0, -1
  %15307 = and i256 %15306, %15303
  %15308 = xor i256 0, -1
  %15309 = and i256 %15308, %15307
  %15310 = trunc i256 0 to i64
  %15311 = alloca i256, align 8
  store i256 %15309, i256* %15311, align 4
  %15312 = bitcast i256* %15311 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15310, i8* %15312, i64 32)
  %15313 = add i256 32, 0, !pc !281, !intsan !10
  %15314 = trunc i256 %15313 to i64
  %15315 = alloca i256, align 8
  store i256 11, i256* %15315, align 4
  %15316 = bitcast i256* %15315 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15314, i8* %15316, i64 32)
  %15317 = add i256 32, %15313, !pc !282, !intsan !10
  %15318 = trunc i256 0 to i32
  %15319 = trunc i256 %15317 to i32
  %15320 = getelementptr inbounds i8, i8* %MEMORY, i32 %15318
  %15321 = alloca i256, align 8
  %15322 = bitcast i256* %15321 to i8*
  call void @__device_sha3(i8* %15320, i32 %15319, i8* %15322)
  %15323 = load i256, i256* %15321, align 4
  %15324 = add i256 2, %15323, !pc !283, !intsan !10
  %15325 = alloca i256, align 8
  store i256 %15324, i256* %15325, align 4
  %15326 = alloca i256, align 8
  call void @__device_sload(i256* %15325, i256* %15326)
  %15327 = call i32 @__hashword(i256* %15325)
  %15328 = load i32, i32* %5, align 4
  %15329 = icmp eq i32 %15327, %15328
  %15330 = or i1 false, %15329
  %15331 = load i32, i32* %6, align 4
  %15332 = icmp eq i32 %15327, %15331
  %15333 = or i1 %15330, %15332
  %15334 = load i32, i32* %7, align 4
  %15335 = icmp eq i32 %15327, %15334
  %15336 = or i1 %15333, %15335
  %15337 = load i32, i32* %8, align 4
  %15338 = icmp eq i32 %15327, %15337
  %15339 = or i1 %15336, %15338
  %15340 = load i32, i32* %9, align 4
  %15341 = icmp eq i32 %15327, %15340
  %15342 = or i1 %15339, %15341
  %15343 = load i32, i32* %10, align 4
  %15344 = icmp eq i32 %15327, %15343
  %15345 = or i1 %15342, %15344
  %15346 = load i32, i32* %11, align 4
  %15347 = icmp eq i32 %15327, %15346
  %15348 = or i1 %15345, %15347
  %15349 = load i32, i32* %12, align 4
  %15350 = icmp eq i32 %15327, %15349
  %15351 = or i1 %15348, %15350
  %15352 = load i32, i32* %13, align 4
  %15353 = icmp eq i32 %15327, %15352
  %15354 = or i1 %15351, %15353
  %15355 = load i32, i32* %14, align 4
  %15356 = icmp eq i32 %15327, %15355
  %15357 = or i1 %15354, %15356
  %15358 = load i32, i32* %15, align 4
  %15359 = icmp eq i32 %15327, %15358
  %15360 = or i1 %15357, %15359
  %15361 = load i32, i32* %16, align 4
  %15362 = icmp eq i32 %15327, %15361
  %15363 = or i1 %15360, %15362
  %15364 = load i32, i32* %17, align 4
  %15365 = icmp eq i32 %15327, %15364
  %15366 = or i1 %15363, %15365
  %15367 = load i32, i32* %18, align 4
  %15368 = icmp eq i32 %15327, %15367
  %15369 = or i1 %15366, %15368
  %15370 = load i32, i32* %19, align 4
  %15371 = icmp eq i32 %15327, %15370
  %15372 = or i1 %15369, %15371
  %15373 = load i32, i32* %20, align 4
  %15374 = icmp eq i32 %15327, %15373
  %15375 = or i1 %15372, %15374
  %15376 = load i32, i32* %21, align 4
  %15377 = icmp eq i32 %15327, %15376
  %15378 = or i1 %15375, %15377
  %15379 = load i32, i32* %22, align 4
  %15380 = icmp eq i32 %15327, %15379
  %15381 = or i1 %15378, %15380
  %15382 = load i32, i32* %23, align 4
  %15383 = icmp eq i32 %15327, %15382
  %15384 = or i1 %15381, %15383
  %15385 = load i32, i32* %24, align 4
  %15386 = icmp eq i32 %15327, %15385
  %15387 = or i1 %15384, %15386
  %15388 = load i32, i32* %25, align 4
  %15389 = icmp eq i32 %15327, %15388
  %15390 = or i1 %15387, %15389
  %15391 = load i32, i32* %26, align 4
  %15392 = icmp eq i32 %15327, %15391
  %15393 = or i1 %15390, %15392
  %15394 = load i32, i32* %27, align 4
  %15395 = icmp eq i32 %15327, %15394
  %15396 = or i1 %15393, %15395
  %15397 = load i32, i32* %28, align 4
  %15398 = icmp eq i32 %15327, %15397
  %15399 = or i1 %15396, %15398
  %15400 = load i32, i32* %29, align 4
  %15401 = icmp eq i32 %15327, %15400
  %15402 = or i1 %15399, %15401
  %15403 = load i32, i32* %30, align 4
  %15404 = icmp eq i32 %15327, %15403
  %15405 = or i1 %15402, %15404
  %15406 = load i32, i32* %31, align 4
  %15407 = icmp eq i32 %15327, %15406
  %15408 = or i1 %15405, %15407
  %15409 = load i32, i32* %32, align 4
  %15410 = icmp eq i32 %15327, %15409
  %15411 = or i1 %15408, %15410
  %15412 = load i32, i32* %33, align 4
  %15413 = icmp eq i32 %15327, %15412
  %15414 = or i1 %15411, %15413
  %15415 = load i32, i32* %34, align 4
  %15416 = icmp eq i32 %15327, %15415
  %15417 = or i1 %15414, %15416
  %15418 = load i32, i32* %35, align 4
  %15419 = icmp eq i32 %15327, %15418
  %15420 = or i1 %15417, %15419
  %15421 = load i32, i32* %36, align 4
  %15422 = icmp eq i32 %15327, %15421
  %15423 = or i1 %15420, %15422
  %15424 = load i32, i32* %37, align 4
  %15425 = icmp eq i32 %15327, %15424
  %15426 = or i1 %15423, %15425
  %15427 = load i32, i32* %38, align 4
  %15428 = icmp eq i32 %15327, %15427
  %15429 = or i1 %15426, %15428
  %15430 = load i32, i32* %39, align 4
  %15431 = icmp eq i32 %15327, %15430
  %15432 = or i1 %15429, %15431
  %15433 = load i32, i32* %40, align 4
  %15434 = icmp eq i32 %15327, %15433
  %15435 = or i1 %15432, %15434
  %15436 = load i32, i32* %41, align 4
  %15437 = icmp eq i32 %15327, %15436
  %15438 = or i1 %15435, %15437
  %15439 = load i32, i32* %42, align 4
  %15440 = icmp eq i32 %15327, %15439
  %15441 = or i1 %15438, %15440
  %15442 = load i32, i32* %43, align 4
  %15443 = icmp eq i32 %15327, %15442
  %15444 = or i1 %15441, %15443
  %15445 = load i32, i32* %44, align 4
  %15446 = icmp eq i32 %15327, %15445
  %15447 = or i1 %15444, %15446
  %15448 = load i32, i32* %45, align 4
  %15449 = icmp eq i32 %15327, %15448
  %15450 = or i1 %15447, %15449
  %15451 = load i32, i32* %46, align 4
  %15452 = icmp eq i32 %15327, %15451
  %15453 = or i1 %15450, %15452
  %15454 = load i32, i32* %47, align 4
  %15455 = icmp eq i32 %15327, %15454
  %15456 = or i1 %15453, %15455
  %15457 = load i32, i32* %48, align 4
  %15458 = icmp eq i32 %15327, %15457
  %15459 = or i1 %15456, %15458
  %15460 = load i32, i32* %49, align 4
  %15461 = icmp eq i32 %15327, %15460
  %15462 = or i1 %15459, %15461
  %15463 = load i32, i32* %50, align 4
  %15464 = icmp eq i32 %15327, %15463
  %15465 = or i1 %15462, %15464
  %15466 = load i32, i32* %51, align 4
  %15467 = icmp eq i32 %15327, %15466
  %15468 = or i1 %15465, %15467
  %15469 = load i32, i32* %52, align 4
  %15470 = icmp eq i32 %15327, %15469
  %15471 = or i1 %15468, %15470
  %15472 = load i32, i32* %53, align 4
  %15473 = icmp eq i32 %15327, %15472
  %15474 = or i1 %15471, %15473
  %15475 = load i32, i32* %54, align 4
  %15476 = icmp eq i32 %15327, %15475
  %15477 = or i1 %15474, %15476
  %15478 = load i32, i32* %55, align 4
  %15479 = icmp eq i32 %15327, %15478
  %15480 = or i1 %15477, %15479
  %15481 = load i32, i32* %56, align 4
  %15482 = icmp eq i32 %15327, %15481
  %15483 = or i1 %15480, %15482
  %15484 = load i32, i32* %57, align 4
  %15485 = icmp eq i32 %15327, %15484
  %15486 = or i1 %15483, %15485
  %15487 = load i32, i32* %58, align 4
  %15488 = icmp eq i32 %15327, %15487
  %15489 = or i1 %15486, %15488
  %15490 = load i32, i32* %59, align 4
  %15491 = icmp eq i32 %15327, %15490
  %15492 = or i1 %15489, %15491
  %15493 = load i32, i32* %60, align 4
  %15494 = icmp eq i32 %15327, %15493
  %15495 = or i1 %15492, %15494
  %15496 = load i32, i32* %61, align 4
  %15497 = icmp eq i32 %15327, %15496
  %15498 = or i1 %15495, %15497
  %15499 = load i32, i32* %62, align 4
  %15500 = icmp eq i32 %15327, %15499
  %15501 = or i1 %15498, %15500
  %15502 = getelementptr i8, i8 addrspace(1)* %4, i32 48
  %15503 = zext i1 %15501 to i8
  store i8 %15503, i8 addrspace(1)* %15502, align 1, !nosanitize !3
  %15504 = load i256, i256* %15326, align 4
  %15505 = icmp eq i256 %15504, 0
  %15506 = load i64, i64* %STACK_DEP_PTR, align 4
  %15507 = add i64 %15506, 1
  store i64 %15507, i64* %STACK_DEP_PTR, align 4
  %15508 = load i64, i64* %STACK_DEP_PTR, align 4
  %15509 = getelementptr i256, i256* %STACK, i64 %15508
  store i256 %15303, i256* %15509, align 4
  %15510 = load i64, i64* %STACK_DEP_PTR, align 4
  %15511 = add i64 %15510, 1
  store i64 %15511, i64* %STACK_DEP_PTR, align 4
  %15512 = load i64, i64* %STACK_DEP_PTR, align 4
  %15513 = getelementptr i256, i256* %STACK, i64 %15512
  store i256 %15298, i256* %15513, align 4
  %15514 = load i64, i64* %STACK_DEP_PTR, align 4
  %15515 = add i64 %15514, 1
  store i64 %15515, i64* %STACK_DEP_PTR, align 4
  %15516 = load i64, i64* %STACK_DEP_PTR, align 4
  %15517 = getelementptr i256, i256* %STACK, i64 %15516
  store i256 %15293, i256* %15517, align 4
  %15518 = load i64, i64* %STACK_DEP_PTR, align 4
  %15519 = add i64 %15518, 1
  store i64 %15519, i64* %STACK_DEP_PTR, align 4
  %15520 = zext i1 %15505 to i256
  %15521 = load i64, i64* %STACK_DEP_PTR, align 4
  %15522 = getelementptr i256, i256* %STACK, i64 %15521
  store i256 %15520, i256* %15522, align 4
  br label %.6209

.6209:                                            ; preds = %.6174, %15268, %JumpTable
  %15523 = load i64, i64* %remaing_gas, align 4
  %15524 = icmp ugt i64 88, %15523
  br i1 %15524, label %Abort, label %15525

15525:                                            ; preds = %.6209
  %15526 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15527 = xor i32 %15526, 2244
  %15528 = urem i32 %15527, 4096
  %15529 = getelementptr i8, i8 addrspace(1)* %4, i32 %15528
  %15530 = load i8, i8 addrspace(1)* %15529, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15529, align 1, !nosanitize !3
  store i32 1122, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15531 = sub i64 %15523, 88
  store i64 %15531, i64* %remaing_gas, align 4
  %15532 = load i64, i64* %STACK_DEP_PTR, align 4
  %15533 = getelementptr i256, i256* %STACK, i64 %15532
  %15534 = load i256, i256* %15533, align 4
  %15535 = load i64, i64* %STACK_DEP_PTR, align 4
  %15536 = sub i64 %15535, 1
  store i64 %15536, i64* %STACK_DEP_PTR, align 4
  %15537 = icmp eq i256 %15534, 0
  %15538 = trunc i256 6359 to i64
  %jump.check187 = icmp ne i1 %15537, false
  br i1 %jump.check187, label %.6359, label %.6215, !EVMBB !4

.6215:                                            ; preds = %15525
  %15539 = load i64, i64* %remaing_gas, align 4
  %15540 = icmp ugt i64 1216, %15539
  br i1 %15540, label %Abort, label %15541

15541:                                            ; preds = %.6215
  %15542 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15543 = xor i32 %15542, 563
  %15544 = urem i32 %15543, 4096
  %15545 = getelementptr i8, i8 addrspace(1)* %4, i32 %15544
  %15546 = load i8, i8 addrspace(1)* %15545, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %15545, align 1, !nosanitize !3
  store i32 281, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %15547 = sub i64 %15539, 1216
  store i64 %15547, i64* %remaing_gas, align 4
  %15548 = load i64, i64* %STACK_DEP_PTR, align 4
  %15549 = getelementptr i256, i256* %STACK, i64 %15548
  %15550 = load i256, i256* %15549, align 4
  %15551 = load i64, i64* %STACK_DEP_PTR, align 4
  %15552 = sub i64 %15551, 1
  store i64 %15552, i64* %STACK_DEP_PTR, align 4
  %15553 = load i64, i64* %STACK_DEP_PTR, align 4
  %15554 = getelementptr i256, i256* %STACK, i64 %15553
  %15555 = load i256, i256* %15554, align 4
  %15556 = load i64, i64* %STACK_DEP_PTR, align 4
  %15557 = sub i64 %15556, 1
  store i64 %15557, i64* %STACK_DEP_PTR, align 4
  %15558 = load i64, i64* %STACK_DEP_PTR, align 4
  %15559 = getelementptr i256, i256* %STACK, i64 %15558
  %15560 = load i256, i256* %15559, align 4
  %15561 = load i64, i64* %STACK_DEP_PTR, align 4
  %15562 = sub i64 %15561, 1
  store i64 %15562, i64* %STACK_DEP_PTR, align 4
  %15563 = xor i256 0, -1
  %15564 = and i256 %15563, %15560
  %15565 = xor i256 0, -1
  %15566 = and i256 %15565, %15564
  %15567 = trunc i256 0 to i64
  %15568 = alloca i256, align 8
  store i256 %15566, i256* %15568, align 4
  %15569 = bitcast i256* %15568 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15567, i8* %15569, i64 32)
  %15570 = add i256 32, 0, !pc !284, !intsan !10
  %15571 = trunc i256 %15570 to i64
  %15572 = alloca i256, align 8
  store i256 11, i256* %15572, align 4
  %15573 = bitcast i256* %15572 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15571, i8* %15573, i64 32)
  %15574 = add i256 32, %15570, !pc !285, !intsan !10
  %15575 = trunc i256 0 to i32
  %15576 = trunc i256 %15574 to i32
  %15577 = getelementptr inbounds i8, i8* %MEMORY, i32 %15575
  %15578 = alloca i256, align 8
  %15579 = bitcast i256* %15578 to i8*
  call void @__device_sha3(i8* %15577, i32 %15576, i8* %15579)
  %15580 = load i256, i256* %15578, align 4
  %15581 = add i256 2, %15580, !pc !286, !intsan !10
  %15582 = alloca i256, align 8
  store i256 %15581, i256* %15582, align 4
  %15583 = alloca i256, align 8
  store i256 99999, i256* %15583, align 4
  call void @__device_sstore(i256* %15582, i256* %15583)
  %15584 = call i32 @__hashword(i256* %15582)
  store i32 %15584, i32* %35, align 4, !nosanitize !3
  %15585 = xor i256 0, -1
  %15586 = and i256 %15585, %15560
  %15587 = xor i256 0, -1
  %15588 = and i256 %15587, %15586
  %15589 = trunc i256 0 to i64
  %15590 = alloca i256, align 8
  store i256 %15588, i256* %15590, align 4
  %15591 = bitcast i256* %15590 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15589, i8* %15591, i64 32)
  %15592 = add i256 32, 0, !pc !287, !intsan !10
  %15593 = trunc i256 %15592 to i64
  %15594 = alloca i256, align 8
  store i256 11, i256* %15594, align 4
  %15595 = bitcast i256* %15594 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15593, i8* %15595, i64 32)
  %15596 = add i256 32, %15592, !pc !288, !intsan !10
  %15597 = trunc i256 0 to i32
  %15598 = trunc i256 %15596 to i32
  %15599 = getelementptr inbounds i8, i8* %MEMORY, i32 %15597
  %15600 = alloca i256, align 8
  %15601 = bitcast i256* %15600 to i8*
  call void @__device_sha3(i8* %15599, i32 %15598, i8* %15601)
  %15602 = load i256, i256* %15600, align 4
  %15603 = add i256 0, %15602, !pc !289, !intsan !10
  %15604 = alloca i256, align 8
  store i256 %15603, i256* %15604, align 4
  %15605 = alloca i256, align 8
  call void @__device_sload(i256* %15604, i256* %15605)
  %15606 = call i32 @__hashword(i256* %15604)
  %15607 = load i32, i32* %5, align 4
  %15608 = icmp eq i32 %15606, %15607
  %15609 = or i1 false, %15608
  %15610 = load i32, i32* %6, align 4
  %15611 = icmp eq i32 %15606, %15610
  %15612 = or i1 %15609, %15611
  %15613 = load i32, i32* %7, align 4
  %15614 = icmp eq i32 %15606, %15613
  %15615 = or i1 %15612, %15614
  %15616 = load i32, i32* %8, align 4
  %15617 = icmp eq i32 %15606, %15616
  %15618 = or i1 %15615, %15617
  %15619 = load i32, i32* %9, align 4
  %15620 = icmp eq i32 %15606, %15619
  %15621 = or i1 %15618, %15620
  %15622 = load i32, i32* %10, align 4
  %15623 = icmp eq i32 %15606, %15622
  %15624 = or i1 %15621, %15623
  %15625 = load i32, i32* %11, align 4
  %15626 = icmp eq i32 %15606, %15625
  %15627 = or i1 %15624, %15626
  %15628 = load i32, i32* %12, align 4
  %15629 = icmp eq i32 %15606, %15628
  %15630 = or i1 %15627, %15629
  %15631 = load i32, i32* %13, align 4
  %15632 = icmp eq i32 %15606, %15631
  %15633 = or i1 %15630, %15632
  %15634 = load i32, i32* %14, align 4
  %15635 = icmp eq i32 %15606, %15634
  %15636 = or i1 %15633, %15635
  %15637 = load i32, i32* %15, align 4
  %15638 = icmp eq i32 %15606, %15637
  %15639 = or i1 %15636, %15638
  %15640 = load i32, i32* %16, align 4
  %15641 = icmp eq i32 %15606, %15640
  %15642 = or i1 %15639, %15641
  %15643 = load i32, i32* %17, align 4
  %15644 = icmp eq i32 %15606, %15643
  %15645 = or i1 %15642, %15644
  %15646 = load i32, i32* %18, align 4
  %15647 = icmp eq i32 %15606, %15646
  %15648 = or i1 %15645, %15647
  %15649 = load i32, i32* %19, align 4
  %15650 = icmp eq i32 %15606, %15649
  %15651 = or i1 %15648, %15650
  %15652 = load i32, i32* %20, align 4
  %15653 = icmp eq i32 %15606, %15652
  %15654 = or i1 %15651, %15653
  %15655 = load i32, i32* %21, align 4
  %15656 = icmp eq i32 %15606, %15655
  %15657 = or i1 %15654, %15656
  %15658 = load i32, i32* %22, align 4
  %15659 = icmp eq i32 %15606, %15658
  %15660 = or i1 %15657, %15659
  %15661 = load i32, i32* %23, align 4
  %15662 = icmp eq i32 %15606, %15661
  %15663 = or i1 %15660, %15662
  %15664 = load i32, i32* %24, align 4
  %15665 = icmp eq i32 %15606, %15664
  %15666 = or i1 %15663, %15665
  %15667 = load i32, i32* %25, align 4
  %15668 = icmp eq i32 %15606, %15667
  %15669 = or i1 %15666, %15668
  %15670 = load i32, i32* %26, align 4
  %15671 = icmp eq i32 %15606, %15670
  %15672 = or i1 %15669, %15671
  %15673 = load i32, i32* %27, align 4
  %15674 = icmp eq i32 %15606, %15673
  %15675 = or i1 %15672, %15674
  %15676 = load i32, i32* %28, align 4
  %15677 = icmp eq i32 %15606, %15676
  %15678 = or i1 %15675, %15677
  %15679 = load i32, i32* %29, align 4
  %15680 = icmp eq i32 %15606, %15679
  %15681 = or i1 %15678, %15680
  %15682 = load i32, i32* %30, align 4
  %15683 = icmp eq i32 %15606, %15682
  %15684 = or i1 %15681, %15683
  %15685 = load i32, i32* %31, align 4
  %15686 = icmp eq i32 %15606, %15685
  %15687 = or i1 %15684, %15686
  %15688 = load i32, i32* %32, align 4
  %15689 = icmp eq i32 %15606, %15688
  %15690 = or i1 %15687, %15689
  %15691 = load i32, i32* %33, align 4
  %15692 = icmp eq i32 %15606, %15691
  %15693 = or i1 %15690, %15692
  %15694 = load i32, i32* %34, align 4
  %15695 = icmp eq i32 %15606, %15694
  %15696 = or i1 %15693, %15695
  %15697 = load i32, i32* %35, align 4
  %15698 = icmp eq i32 %15606, %15697
  %15699 = or i1 %15696, %15698
  %15700 = load i32, i32* %36, align 4
  %15701 = icmp eq i32 %15606, %15700
  %15702 = or i1 %15699, %15701
  %15703 = load i32, i32* %37, align 4
  %15704 = icmp eq i32 %15606, %15703
  %15705 = or i1 %15702, %15704
  %15706 = load i32, i32* %38, align 4
  %15707 = icmp eq i32 %15606, %15706
  %15708 = or i1 %15705, %15707
  %15709 = load i32, i32* %39, align 4
  %15710 = icmp eq i32 %15606, %15709
  %15711 = or i1 %15708, %15710
  %15712 = load i32, i32* %40, align 4
  %15713 = icmp eq i32 %15606, %15712
  %15714 = or i1 %15711, %15713
  %15715 = load i32, i32* %41, align 4
  %15716 = icmp eq i32 %15606, %15715
  %15717 = or i1 %15714, %15716
  %15718 = load i32, i32* %42, align 4
  %15719 = icmp eq i32 %15606, %15718
  %15720 = or i1 %15717, %15719
  %15721 = load i32, i32* %43, align 4
  %15722 = icmp eq i32 %15606, %15721
  %15723 = or i1 %15720, %15722
  %15724 = load i32, i32* %44, align 4
  %15725 = icmp eq i32 %15606, %15724
  %15726 = or i1 %15723, %15725
  %15727 = load i32, i32* %45, align 4
  %15728 = icmp eq i32 %15606, %15727
  %15729 = or i1 %15726, %15728
  %15730 = load i32, i32* %46, align 4
  %15731 = icmp eq i32 %15606, %15730
  %15732 = or i1 %15729, %15731
  %15733 = load i32, i32* %47, align 4
  %15734 = icmp eq i32 %15606, %15733
  %15735 = or i1 %15732, %15734
  %15736 = load i32, i32* %48, align 4
  %15737 = icmp eq i32 %15606, %15736
  %15738 = or i1 %15735, %15737
  %15739 = load i32, i32* %49, align 4
  %15740 = icmp eq i32 %15606, %15739
  %15741 = or i1 %15738, %15740
  %15742 = load i32, i32* %50, align 4
  %15743 = icmp eq i32 %15606, %15742
  %15744 = or i1 %15741, %15743
  %15745 = load i32, i32* %51, align 4
  %15746 = icmp eq i32 %15606, %15745
  %15747 = or i1 %15744, %15746
  %15748 = load i32, i32* %52, align 4
  %15749 = icmp eq i32 %15606, %15748
  %15750 = or i1 %15747, %15749
  %15751 = load i32, i32* %53, align 4
  %15752 = icmp eq i32 %15606, %15751
  %15753 = or i1 %15750, %15752
  %15754 = load i32, i32* %54, align 4
  %15755 = icmp eq i32 %15606, %15754
  %15756 = or i1 %15753, %15755
  %15757 = load i32, i32* %55, align 4
  %15758 = icmp eq i32 %15606, %15757
  %15759 = or i1 %15756, %15758
  %15760 = load i32, i32* %56, align 4
  %15761 = icmp eq i32 %15606, %15760
  %15762 = or i1 %15759, %15761
  %15763 = load i32, i32* %57, align 4
  %15764 = icmp eq i32 %15606, %15763
  %15765 = or i1 %15762, %15764
  %15766 = load i32, i32* %58, align 4
  %15767 = icmp eq i32 %15606, %15766
  %15768 = or i1 %15765, %15767
  %15769 = load i32, i32* %59, align 4
  %15770 = icmp eq i32 %15606, %15769
  %15771 = or i1 %15768, %15770
  %15772 = load i32, i32* %60, align 4
  %15773 = icmp eq i32 %15606, %15772
  %15774 = or i1 %15771, %15773
  %15775 = load i32, i32* %61, align 4
  %15776 = icmp eq i32 %15606, %15775
  %15777 = or i1 %15774, %15776
  %15778 = load i32, i32* %62, align 4
  %15779 = icmp eq i32 %15606, %15778
  %15780 = or i1 %15777, %15779
  %15781 = getelementptr i8, i8 addrspace(1)* %4, i32 49
  %15782 = zext i1 %15780 to i8
  store i8 %15782, i8 addrspace(1)* %15781, align 1, !nosanitize !3
  %15783 = load i256, i256* %15605, align 4
  %15784 = alloca i256, align 8
  store i256 %15783, i256* %15784, align 4
  %15785 = alloca i256, align 8
  store i256 1, i256* %15785, align 4
  %15786 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %15784, i256* %15785, i256* %15786), !pc !290, !intsan !6
  %15787 = load i256, i256* %15786, align 4
  %15788 = and i256 1461501637330902918203684832716283019655932542975, %15787
  %15789 = xor i256 0, -1
  %15790 = and i256 %15789, %15560
  %15791 = xor i256 0, -1
  %15792 = and i256 %15791, %15790
  %15793 = trunc i256 0 to i64
  %15794 = alloca i256, align 8
  store i256 %15792, i256* %15794, align 4
  %15795 = bitcast i256* %15794 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15793, i8* %15795, i64 32)
  %15796 = add i256 32, 0, !pc !291, !intsan !10
  %15797 = trunc i256 %15796 to i64
  %15798 = alloca i256, align 8
  store i256 11, i256* %15798, align 4
  %15799 = bitcast i256* %15798 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %15797, i8* %15799, i64 32)
  %15800 = add i256 32, %15796, !pc !292, !intsan !10
  %15801 = trunc i256 0 to i32
  %15802 = trunc i256 %15800 to i32
  %15803 = getelementptr inbounds i8, i8* %MEMORY, i32 %15801
  %15804 = alloca i256, align 8
  %15805 = bitcast i256* %15804 to i8*
  call void @__device_sha3(i8* %15803, i32 %15802, i8* %15805)
  %15806 = load i256, i256* %15804, align 4
  %15807 = add i256 1, %15806, !pc !293, !intsan !10
  %15808 = alloca i256, align 8
  store i256 %15807, i256* %15808, align 4
  %15809 = alloca i256, align 8
  call void @__device_sload(i256* %15808, i256* %15809)
  %15810 = call i32 @__hashword(i256* %15808)
  %15811 = load i32, i32* %5, align 4
  %15812 = icmp eq i32 %15810, %15811
  %15813 = or i1 false, %15812
  %15814 = load i32, i32* %6, align 4
  %15815 = icmp eq i32 %15810, %15814
  %15816 = or i1 %15813, %15815
  %15817 = load i32, i32* %7, align 4
  %15818 = icmp eq i32 %15810, %15817
  %15819 = or i1 %15816, %15818
  %15820 = load i32, i32* %8, align 4
  %15821 = icmp eq i32 %15810, %15820
  %15822 = or i1 %15819, %15821
  %15823 = load i32, i32* %9, align 4
  %15824 = icmp eq i32 %15810, %15823
  %15825 = or i1 %15822, %15824
  %15826 = load i32, i32* %10, align 4
  %15827 = icmp eq i32 %15810, %15826
  %15828 = or i1 %15825, %15827
  %15829 = load i32, i32* %11, align 4
  %15830 = icmp eq i32 %15810, %15829
  %15831 = or i1 %15828, %15830
  %15832 = load i32, i32* %12, align 4
  %15833 = icmp eq i32 %15810, %15832
  %15834 = or i1 %15831, %15833
  %15835 = load i32, i32* %13, align 4
  %15836 = icmp eq i32 %15810, %15835
  %15837 = or i1 %15834, %15836
  %15838 = load i32, i32* %14, align 4
  %15839 = icmp eq i32 %15810, %15838
  %15840 = or i1 %15837, %15839
  %15841 = load i32, i32* %15, align 4
  %15842 = icmp eq i32 %15810, %15841
  %15843 = or i1 %15840, %15842
  %15844 = load i32, i32* %16, align 4
  %15845 = icmp eq i32 %15810, %15844
  %15846 = or i1 %15843, %15845
  %15847 = load i32, i32* %17, align 4
  %15848 = icmp eq i32 %15810, %15847
  %15849 = or i1 %15846, %15848
  %15850 = load i32, i32* %18, align 4
  %15851 = icmp eq i32 %15810, %15850
  %15852 = or i1 %15849, %15851
  %15853 = load i32, i32* %19, align 4
  %15854 = icmp eq i32 %15810, %15853
  %15855 = or i1 %15852, %15854
  %15856 = load i32, i32* %20, align 4
  %15857 = icmp eq i32 %15810, %15856
  %15858 = or i1 %15855, %15857
  %15859 = load i32, i32* %21, align 4
  %15860 = icmp eq i32 %15810, %15859
  %15861 = or i1 %15858, %15860
  %15862 = load i32, i32* %22, align 4
  %15863 = icmp eq i32 %15810, %15862
  %15864 = or i1 %15861, %15863
  %15865 = load i32, i32* %23, align 4
  %15866 = icmp eq i32 %15810, %15865
  %15867 = or i1 %15864, %15866
  %15868 = load i32, i32* %24, align 4
  %15869 = icmp eq i32 %15810, %15868
  %15870 = or i1 %15867, %15869
  %15871 = load i32, i32* %25, align 4
  %15872 = icmp eq i32 %15810, %15871
  %15873 = or i1 %15870, %15872
  %15874 = load i32, i32* %26, align 4
  %15875 = icmp eq i32 %15810, %15874
  %15876 = or i1 %15873, %15875
  %15877 = load i32, i32* %27, align 4
  %15878 = icmp eq i32 %15810, %15877
  %15879 = or i1 %15876, %15878
  %15880 = load i32, i32* %28, align 4
  %15881 = icmp eq i32 %15810, %15880
  %15882 = or i1 %15879, %15881
  %15883 = load i32, i32* %29, align 4
  %15884 = icmp eq i32 %15810, %15883
  %15885 = or i1 %15882, %15884
  %15886 = load i32, i32* %30, align 4
  %15887 = icmp eq i32 %15810, %15886
  %15888 = or i1 %15885, %15887
  %15889 = load i32, i32* %31, align 4
  %15890 = icmp eq i32 %15810, %15889
  %15891 = or i1 %15888, %15890
  %15892 = load i32, i32* %32, align 4
  %15893 = icmp eq i32 %15810, %15892
  %15894 = or i1 %15891, %15893
  %15895 = load i32, i32* %33, align 4
  %15896 = icmp eq i32 %15810, %15895
  %15897 = or i1 %15894, %15896
  %15898 = load i32, i32* %34, align 4
  %15899 = icmp eq i32 %15810, %15898
  %15900 = or i1 %15897, %15899
  %15901 = load i32, i32* %35, align 4
  %15902 = icmp eq i32 %15810, %15901
  %15903 = or i1 %15900, %15902
  %15904 = load i32, i32* %36, align 4
  %15905 = icmp eq i32 %15810, %15904
  %15906 = or i1 %15903, %15905
  %15907 = load i32, i32* %37, align 4
  %15908 = icmp eq i32 %15810, %15907
  %15909 = or i1 %15906, %15908
  %15910 = load i32, i32* %38, align 4
  %15911 = icmp eq i32 %15810, %15910
  %15912 = or i1 %15909, %15911
  %15913 = load i32, i32* %39, align 4
  %15914 = icmp eq i32 %15810, %15913
  %15915 = or i1 %15912, %15914
  %15916 = load i32, i32* %40, align 4
  %15917 = icmp eq i32 %15810, %15916
  %15918 = or i1 %15915, %15917
  %15919 = load i32, i32* %41, align 4
  %15920 = icmp eq i32 %15810, %15919
  %15921 = or i1 %15918, %15920
  %15922 = load i32, i32* %42, align 4
  %15923 = icmp eq i32 %15810, %15922
  %15924 = or i1 %15921, %15923
  %15925 = load i32, i32* %43, align 4
  %15926 = icmp eq i32 %15810, %15925
  %15927 = or i1 %15924, %15926
  %15928 = load i32, i32* %44, align 4
  %15929 = icmp eq i32 %15810, %15928
  %15930 = or i1 %15927, %15929
  %15931 = load i32, i32* %45, align 4
  %15932 = icmp eq i32 %15810, %15931
  %15933 = or i1 %15930, %15932
  %15934 = load i32, i32* %46, align 4
  %15935 = icmp eq i32 %15810, %15934
  %15936 = or i1 %15933, %15935
  %15937 = load i32, i32* %47, align 4
  %15938 = icmp eq i32 %15810, %15937
  %15939 = or i1 %15936, %15938
  %15940 = load i32, i32* %48, align 4
  %15941 = icmp eq i32 %15810, %15940
  %15942 = or i1 %15939, %15941
  %15943 = load i32, i32* %49, align 4
  %15944 = icmp eq i32 %15810, %15943
  %15945 = or i1 %15942, %15944
  %15946 = load i32, i32* %50, align 4
  %15947 = icmp eq i32 %15810, %15946
  %15948 = or i1 %15945, %15947
  %15949 = load i32, i32* %51, align 4
  %15950 = icmp eq i32 %15810, %15949
  %15951 = or i1 %15948, %15950
  %15952 = load i32, i32* %52, align 4
  %15953 = icmp eq i32 %15810, %15952
  %15954 = or i1 %15951, %15953
  %15955 = load i32, i32* %53, align 4
  %15956 = icmp eq i32 %15810, %15955
  %15957 = or i1 %15954, %15956
  %15958 = load i32, i32* %54, align 4
  %15959 = icmp eq i32 %15810, %15958
  %15960 = or i1 %15957, %15959
  %15961 = load i32, i32* %55, align 4
  %15962 = icmp eq i32 %15810, %15961
  %15963 = or i1 %15960, %15962
  %15964 = load i32, i32* %56, align 4
  %15965 = icmp eq i32 %15810, %15964
  %15966 = or i1 %15963, %15965
  %15967 = load i32, i32* %57, align 4
  %15968 = icmp eq i32 %15810, %15967
  %15969 = or i1 %15966, %15968
  %15970 = load i32, i32* %58, align 4
  %15971 = icmp eq i32 %15810, %15970
  %15972 = or i1 %15969, %15971
  %15973 = load i32, i32* %59, align 4
  %15974 = icmp eq i32 %15810, %15973
  %15975 = or i1 %15972, %15974
  %15976 = load i32, i32* %60, align 4
  %15977 = icmp eq i32 %15810, %15976
  %15978 = or i1 %15975, %15977
  %15979 = load i32, i32* %61, align 4
  %15980 = icmp eq i32 %15810, %15979
  %15981 = or i1 %15978, %15980
  %15982 = load i32, i32* %62, align 4
  %15983 = icmp eq i32 %15810, %15982
  %15984 = or i1 %15981, %15983
  %15985 = getelementptr i8, i8 addrspace(1)* %4, i32 50
  %15986 = zext i1 %15984 to i8
  store i8 %15986, i8 addrspace(1)* %15985, align 1, !nosanitize !3
  %15987 = load i256, i256* %15809, align 4
  %15988 = trunc i256 14584 to i64
  %15989 = load i64, i64* %STACK_DEP_PTR, align 4
  %15990 = add i64 %15989, 1
  store i64 %15990, i64* %STACK_DEP_PTR, align 4
  %15991 = load i64, i64* %STACK_DEP_PTR, align 4
  %15992 = getelementptr i256, i256* %STACK, i64 %15991
  store i256 %15560, i256* %15992, align 4
  %15993 = load i64, i64* %STACK_DEP_PTR, align 4
  %15994 = add i64 %15993, 1
  store i64 %15994, i64* %STACK_DEP_PTR, align 4
  %15995 = load i64, i64* %STACK_DEP_PTR, align 4
  %15996 = getelementptr i256, i256* %STACK, i64 %15995
  store i256 %15555, i256* %15996, align 4
  %15997 = load i64, i64* %STACK_DEP_PTR, align 4
  %15998 = add i64 %15997, 1
  store i64 %15998, i64* %STACK_DEP_PTR, align 4
  %15999 = load i64, i64* %STACK_DEP_PTR, align 4
  %16000 = getelementptr i256, i256* %STACK, i64 %15999
  store i256 %15550, i256* %16000, align 4
  %16001 = load i64, i64* %STACK_DEP_PTR, align 4
  %16002 = add i64 %16001, 1
  store i64 %16002, i64* %STACK_DEP_PTR, align 4
  %16003 = load i64, i64* %STACK_DEP_PTR, align 4
  %16004 = getelementptr i256, i256* %STACK, i64 %16003
  store i256 6354, i256* %16004, align 4
  %16005 = load i64, i64* %STACK_DEP_PTR, align 4
  %16006 = add i64 %16005, 1
  store i64 %16006, i64* %STACK_DEP_PTR, align 4
  %16007 = load i64, i64* %STACK_DEP_PTR, align 4
  %16008 = getelementptr i256, i256* %STACK, i64 %16007
  store i256 %15788, i256* %16008, align 4
  %16009 = load i64, i64* %STACK_DEP_PTR, align 4
  %16010 = add i64 %16009, 1
  store i64 %16010, i64* %STACK_DEP_PTR, align 4
  %16011 = load i64, i64* %STACK_DEP_PTR, align 4
  %16012 = getelementptr i256, i256* %STACK, i64 %16011
  store i256 %15987, i256* %16012, align 4
  br label %.14584, !EVMBB !4

.6354:                                            ; preds = %JumpTable
  %16013 = load i64, i64* %remaing_gas, align 4
  %16014 = icmp ugt i64 24, %16013
  br i1 %16014, label %Abort, label %16015

16015:                                            ; preds = %.6354
  %16016 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16017 = xor i32 %16016, 3503
  %16018 = urem i32 %16017, 4096
  %16019 = getelementptr i8, i8 addrspace(1)* %4, i32 %16018
  %16020 = load i8, i8 addrspace(1)* %16019, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16019, align 1, !nosanitize !3
  store i32 1751, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16021 = sub i64 %16013, 24
  store i64 %16021, i64* %remaing_gas, align 4
  %16022 = trunc i256 7019 to i64
  br label %.7019, !EVMBB !4

.6359:                                            ; preds = %15525, %JumpTable
  %16023 = load i64, i64* %remaing_gas, align 4
  %16024 = icmp ugt i64 1032, %16023
  br i1 %16024, label %Abort, label %16025

16025:                                            ; preds = %.6359
  %16026 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16027 = xor i32 %16026, 717
  %16028 = urem i32 %16027, 4096
  %16029 = getelementptr i8, i8 addrspace(1)* %4, i32 %16028
  %16030 = load i8, i8 addrspace(1)* %16029, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16029, align 1, !nosanitize !3
  store i32 358, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16031 = sub i64 %16023, 1032
  store i64 %16031, i64* %remaing_gas, align 4
  %16032 = load i64, i64* %STACK_DEP_PTR, align 4
  %16033 = getelementptr i256, i256* %STACK, i64 %16032
  %16034 = load i256, i256* %16033, align 4
  %16035 = load i64, i64* %STACK_DEP_PTR, align 4
  %16036 = sub i64 %16035, 1
  store i64 %16036, i64* %STACK_DEP_PTR, align 4
  %16037 = load i64, i64* %STACK_DEP_PTR, align 4
  %16038 = getelementptr i256, i256* %STACK, i64 %16037
  %16039 = load i256, i256* %16038, align 4
  %16040 = load i64, i64* %STACK_DEP_PTR, align 4
  %16041 = sub i64 %16040, 1
  store i64 %16041, i64* %STACK_DEP_PTR, align 4
  %16042 = load i64, i64* %STACK_DEP_PTR, align 4
  %16043 = getelementptr i256, i256* %STACK, i64 %16042
  %16044 = load i256, i256* %16043, align 4
  %16045 = load i64, i64* %STACK_DEP_PTR, align 4
  %16046 = sub i64 %16045, 1
  store i64 %16046, i64* %STACK_DEP_PTR, align 4
  %16047 = load i64, i64* %STACK_DEP_PTR, align 4
  %16048 = getelementptr i256, i256* %STACK, i64 %16047
  %16049 = load i256, i256* %16048, align 4
  %16050 = load i64, i64* %STACK_DEP_PTR, align 4
  %16051 = sub i64 %16050, 1
  store i64 %16051, i64* %STACK_DEP_PTR, align 4
  %16052 = load i64, i64* %STACK_DEP_PTR, align 4
  %16053 = getelementptr i256, i256* %STACK, i64 %16052
  %16054 = load i256, i256* %16053, align 4
  %16055 = load i64, i64* %STACK_DEP_PTR, align 4
  %16056 = sub i64 %16055, 1
  store i64 %16056, i64* %STACK_DEP_PTR, align 4
  %16057 = load i64, i64* %STACK_DEP_PTR, align 4
  %16058 = getelementptr i256, i256* %STACK, i64 %16057
  %16059 = load i256, i256* %16058, align 4
  %16060 = load i64, i64* %STACK_DEP_PTR, align 4
  %16061 = sub i64 %16060, 1
  store i64 %16061, i64* %STACK_DEP_PTR, align 4
  %16062 = load i64, i64* %STACK_DEP_PTR, align 4
  %16063 = getelementptr i256, i256* %STACK, i64 %16062
  %16064 = load i256, i256* %16063, align 4
  %16065 = load i64, i64* %STACK_DEP_PTR, align 4
  %16066 = sub i64 %16065, 1
  store i64 %16066, i64* %STACK_DEP_PTR, align 4
  %16067 = load i64, i64* %STACK_DEP_PTR, align 4
  %16068 = getelementptr i256, i256* %STACK, i64 %16067
  %16069 = load i256, i256* %16068, align 4
  %16070 = load i64, i64* %STACK_DEP_PTR, align 4
  %16071 = sub i64 %16070, 1
  store i64 %16071, i64* %STACK_DEP_PTR, align 4
  %16072 = load i64, i64* %STACK_DEP_PTR, align 4
  %16073 = getelementptr i256, i256* %STACK, i64 %16072
  %16074 = load i256, i256* %16073, align 4
  %16075 = load i64, i64* %STACK_DEP_PTR, align 4
  %16076 = sub i64 %16075, 1
  store i64 %16076, i64* %STACK_DEP_PTR, align 4
  %16077 = trunc i256 4367 to i64
  %16078 = load i64, i64* %STACK_DEP_PTR, align 4
  %16079 = add i64 %16078, 1
  store i64 %16079, i64* %STACK_DEP_PTR, align 4
  %16080 = load i64, i64* %STACK_DEP_PTR, align 4
  %16081 = getelementptr i256, i256* %STACK, i64 %16080
  store i256 %16074, i256* %16081, align 4
  %16082 = load i64, i64* %STACK_DEP_PTR, align 4
  %16083 = add i64 %16082, 1
  store i64 %16083, i64* %STACK_DEP_PTR, align 4
  %16084 = load i64, i64* %STACK_DEP_PTR, align 4
  %16085 = getelementptr i256, i256* %STACK, i64 %16084
  store i256 %16069, i256* %16085, align 4
  %16086 = load i64, i64* %STACK_DEP_PTR, align 4
  %16087 = add i64 %16086, 1
  store i64 %16087, i64* %STACK_DEP_PTR, align 4
  %16088 = load i64, i64* %STACK_DEP_PTR, align 4
  %16089 = getelementptr i256, i256* %STACK, i64 %16088
  store i256 %16064, i256* %16089, align 4
  %16090 = load i64, i64* %STACK_DEP_PTR, align 4
  %16091 = add i64 %16090, 1
  store i64 %16091, i64* %STACK_DEP_PTR, align 4
  %16092 = load i64, i64* %STACK_DEP_PTR, align 4
  %16093 = getelementptr i256, i256* %STACK, i64 %16092
  store i256 %16059, i256* %16093, align 4
  %16094 = load i64, i64* %STACK_DEP_PTR, align 4
  %16095 = add i64 %16094, 1
  store i64 %16095, i64* %STACK_DEP_PTR, align 4
  %16096 = load i64, i64* %STACK_DEP_PTR, align 4
  %16097 = getelementptr i256, i256* %STACK, i64 %16096
  store i256 %16054, i256* %16097, align 4
  %16098 = load i64, i64* %STACK_DEP_PTR, align 4
  %16099 = add i64 %16098, 1
  store i64 %16099, i64* %STACK_DEP_PTR, align 4
  %16100 = load i64, i64* %STACK_DEP_PTR, align 4
  %16101 = getelementptr i256, i256* %STACK, i64 %16100
  store i256 %16049, i256* %16101, align 4
  %16102 = load i64, i64* %STACK_DEP_PTR, align 4
  %16103 = add i64 %16102, 1
  store i64 %16103, i64* %STACK_DEP_PTR, align 4
  %16104 = load i64, i64* %STACK_DEP_PTR, align 4
  %16105 = getelementptr i256, i256* %STACK, i64 %16104
  store i256 %16044, i256* %16105, align 4
  %16106 = load i64, i64* %STACK_DEP_PTR, align 4
  %16107 = add i64 %16106, 1
  store i64 %16107, i64* %STACK_DEP_PTR, align 4
  %16108 = load i64, i64* %STACK_DEP_PTR, align 4
  %16109 = getelementptr i256, i256* %STACK, i64 %16108
  store i256 %16039, i256* %16109, align 4
  %16110 = load i64, i64* %STACK_DEP_PTR, align 4
  %16111 = add i64 %16110, 1
  store i64 %16111, i64* %STACK_DEP_PTR, align 4
  %16112 = load i64, i64* %STACK_DEP_PTR, align 4
  %16113 = getelementptr i256, i256* %STACK, i64 %16112
  store i256 %16034, i256* %16113, align 4
  %16114 = load i64, i64* %STACK_DEP_PTR, align 4
  %16115 = add i64 %16114, 1
  store i64 %16115, i64* %STACK_DEP_PTR, align 4
  %16116 = load i64, i64* %STACK_DEP_PTR, align 4
  %16117 = getelementptr i256, i256* %STACK, i64 %16116
  store i256 %16074, i256* %16117, align 4
  %16118 = load i64, i64* %STACK_DEP_PTR, align 4
  %16119 = add i64 %16118, 1
  store i64 %16119, i64* %STACK_DEP_PTR, align 4
  %16120 = load i64, i64* %STACK_DEP_PTR, align 4
  %16121 = getelementptr i256, i256* %STACK, i64 %16120
  store i256 10000, i256* %16121, align 4
  %16122 = load i64, i64* %STACK_DEP_PTR, align 4
  %16123 = add i64 %16122, 1
  store i64 %16123, i64* %STACK_DEP_PTR, align 4
  %16124 = load i64, i64* %STACK_DEP_PTR, align 4
  %16125 = getelementptr i256, i256* %STACK, i64 %16124
  store i256 6371, i256* %16125, align 4
  br label %.4367, !EVMBB !4

.6371:                                            ; preds = %JumpTable
  %16126 = load i64, i64* %remaing_gas, align 4
  %16127 = icmp ugt i64 248, %16126
  br i1 %16127, label %Abort, label %16128

16128:                                            ; preds = %.6371
  %16129 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16130 = xor i32 %16129, 3747
  %16131 = urem i32 %16130, 4096
  %16132 = getelementptr i8, i8 addrspace(1)* %4, i32 %16131
  %16133 = load i8, i8 addrspace(1)* %16132, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16132, align 1, !nosanitize !3
  store i32 1873, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16134 = sub i64 %16126, 248
  store i64 %16134, i64* %remaing_gas, align 4
  %16135 = load i64, i64* %STACK_DEP_PTR, align 4
  %16136 = getelementptr i256, i256* %STACK, i64 %16135
  %16137 = load i256, i256* %16136, align 4
  %16138 = load i64, i64* %STACK_DEP_PTR, align 4
  %16139 = sub i64 %16138, 1
  store i64 %16139, i64* %STACK_DEP_PTR, align 4
  %16140 = load i64, i64* %STACK_DEP_PTR, align 4
  %16141 = getelementptr i256, i256* %STACK, i64 %16140
  %16142 = load i256, i256* %16141, align 4
  %16143 = load i64, i64* %STACK_DEP_PTR, align 4
  %16144 = sub i64 %16143, 1
  store i64 %16144, i64* %STACK_DEP_PTR, align 4
  %16145 = mul i256 100, %16137, !pc !294, !intsan !45
  %16146 = icmp eq i256 %16142, 0
  %16147 = icmp eq i1 %16146, false
  %16148 = trunc i256 6383 to i64
  %jump.check188 = icmp ne i1 %16147, false
  %16149 = load i64, i64* %STACK_DEP_PTR, align 4
  %16150 = add i64 %16149, 1
  store i64 %16150, i64* %STACK_DEP_PTR, align 4
  %16151 = load i64, i64* %STACK_DEP_PTR, align 4
  %16152 = getelementptr i256, i256* %STACK, i64 %16151
  store i256 %16142, i256* %16152, align 4
  %16153 = load i64, i64* %STACK_DEP_PTR, align 4
  %16154 = add i64 %16153, 1
  store i64 %16154, i64* %STACK_DEP_PTR, align 4
  %16155 = load i64, i64* %STACK_DEP_PTR, align 4
  %16156 = getelementptr i256, i256* %STACK, i64 %16155
  store i256 %16145, i256* %16156, align 4
  br i1 %jump.check188, label %.6383, label %.6382, !EVMBB !4

.6382:                                            ; preds = %16128
  %16157 = load i64, i64* %remaing_gas, align 4
  %16158 = icmp ugt i64 16, %16157
  br i1 %16158, label %Abort, label %16159

16159:                                            ; preds = %.6382
  %16160 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16161 = xor i32 %16160, 3460
  %16162 = urem i32 %16161, 4096
  %16163 = getelementptr i8, i8 addrspace(1)* %4, i32 %16162
  %16164 = load i8, i8 addrspace(1)* %16163, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16163, align 1, !nosanitize !3
  store i32 1730, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16165 = sub i64 %16157, 16
  store i64 %16165, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.6383:                                            ; preds = %16128, %JumpTable
  %16166 = load i64, i64* %remaing_gas, align 4
  %16167 = icmp ugt i64 696, %16166
  br i1 %16167, label %Abort, label %16168

16168:                                            ; preds = %.6383
  %16169 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16170 = xor i32 %16169, 3711
  %16171 = urem i32 %16170, 4096
  %16172 = getelementptr i8, i8 addrspace(1)* %4, i32 %16171
  %16173 = load i8, i8 addrspace(1)* %16172, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16172, align 1, !nosanitize !3
  store i32 1855, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16174 = sub i64 %16166, 696
  store i64 %16174, i64* %remaing_gas, align 4
  %16175 = load i64, i64* %STACK_DEP_PTR, align 4
  %16176 = getelementptr i256, i256* %STACK, i64 %16175
  %16177 = load i256, i256* %16176, align 4
  %16178 = load i64, i64* %STACK_DEP_PTR, align 4
  %16179 = sub i64 %16178, 1
  store i64 %16179, i64* %STACK_DEP_PTR, align 4
  %16180 = load i64, i64* %STACK_DEP_PTR, align 4
  %16181 = getelementptr i256, i256* %STACK, i64 %16180
  %16182 = load i256, i256* %16181, align 4
  %16183 = load i64, i64* %STACK_DEP_PTR, align 4
  %16184 = sub i64 %16183, 1
  store i64 %16184, i64* %STACK_DEP_PTR, align 4
  %16185 = load i64, i64* %STACK_DEP_PTR, align 4
  %16186 = getelementptr i256, i256* %STACK, i64 %16185
  %16187 = load i256, i256* %16186, align 4
  %16188 = load i64, i64* %STACK_DEP_PTR, align 4
  %16189 = sub i64 %16188, 1
  store i64 %16189, i64* %STACK_DEP_PTR, align 4
  %16190 = alloca i256, align 8
  store i256 %16177, i256* %16190, align 4
  %16191 = alloca i256, align 8
  store i256 %16182, i256* %16191, align 4
  %16192 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %16190, i256* %16191, i256* %16192), !pc !295, !intsan !6
  %16193 = load i256, i256* %16192, align 4
  %16194 = sub i256 10000, 190, !pc !296, !intsan !8
  %16195 = sub i256 %16194, 7500, !pc !297, !intsan !8
  %16196 = xor i256 0, -1
  %16197 = and i256 %16196, %16187
  %16198 = xor i256 0, -1
  %16199 = and i256 %16198, %16197
  %16200 = trunc i256 0 to i64
  %16201 = alloca i256, align 8
  store i256 %16199, i256* %16201, align 4
  %16202 = bitcast i256* %16201 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16200, i8* %16202, i64 32)
  %16203 = add i256 32, 0, !pc !298, !intsan !10
  %16204 = trunc i256 %16203 to i64
  %16205 = alloca i256, align 8
  store i256 11, i256* %16205, align 4
  %16206 = bitcast i256* %16205 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16204, i8* %16206, i64 32)
  %16207 = add i256 32, %16203, !pc !299, !intsan !10
  %16208 = trunc i256 0 to i32
  %16209 = trunc i256 %16207 to i32
  %16210 = getelementptr inbounds i8, i8* %MEMORY, i32 %16208
  %16211 = alloca i256, align 8
  %16212 = bitcast i256* %16211 to i8*
  call void @__device_sha3(i8* %16210, i32 %16209, i8* %16212)
  %16213 = load i256, i256* %16211, align 4
  %16214 = add i256 1, %16213, !pc !300, !intsan !10
  %16215 = alloca i256, align 8
  store i256 %16214, i256* %16215, align 4
  %16216 = alloca i256, align 8
  call void @__device_sload(i256* %16215, i256* %16216)
  %16217 = call i32 @__hashword(i256* %16215)
  %16218 = load i32, i32* %5, align 4
  %16219 = icmp eq i32 %16217, %16218
  %16220 = or i1 false, %16219
  %16221 = load i32, i32* %6, align 4
  %16222 = icmp eq i32 %16217, %16221
  %16223 = or i1 %16220, %16222
  %16224 = load i32, i32* %7, align 4
  %16225 = icmp eq i32 %16217, %16224
  %16226 = or i1 %16223, %16225
  %16227 = load i32, i32* %8, align 4
  %16228 = icmp eq i32 %16217, %16227
  %16229 = or i1 %16226, %16228
  %16230 = load i32, i32* %9, align 4
  %16231 = icmp eq i32 %16217, %16230
  %16232 = or i1 %16229, %16231
  %16233 = load i32, i32* %10, align 4
  %16234 = icmp eq i32 %16217, %16233
  %16235 = or i1 %16232, %16234
  %16236 = load i32, i32* %11, align 4
  %16237 = icmp eq i32 %16217, %16236
  %16238 = or i1 %16235, %16237
  %16239 = load i32, i32* %12, align 4
  %16240 = icmp eq i32 %16217, %16239
  %16241 = or i1 %16238, %16240
  %16242 = load i32, i32* %13, align 4
  %16243 = icmp eq i32 %16217, %16242
  %16244 = or i1 %16241, %16243
  %16245 = load i32, i32* %14, align 4
  %16246 = icmp eq i32 %16217, %16245
  %16247 = or i1 %16244, %16246
  %16248 = load i32, i32* %15, align 4
  %16249 = icmp eq i32 %16217, %16248
  %16250 = or i1 %16247, %16249
  %16251 = load i32, i32* %16, align 4
  %16252 = icmp eq i32 %16217, %16251
  %16253 = or i1 %16250, %16252
  %16254 = load i32, i32* %17, align 4
  %16255 = icmp eq i32 %16217, %16254
  %16256 = or i1 %16253, %16255
  %16257 = load i32, i32* %18, align 4
  %16258 = icmp eq i32 %16217, %16257
  %16259 = or i1 %16256, %16258
  %16260 = load i32, i32* %19, align 4
  %16261 = icmp eq i32 %16217, %16260
  %16262 = or i1 %16259, %16261
  %16263 = load i32, i32* %20, align 4
  %16264 = icmp eq i32 %16217, %16263
  %16265 = or i1 %16262, %16264
  %16266 = load i32, i32* %21, align 4
  %16267 = icmp eq i32 %16217, %16266
  %16268 = or i1 %16265, %16267
  %16269 = load i32, i32* %22, align 4
  %16270 = icmp eq i32 %16217, %16269
  %16271 = or i1 %16268, %16270
  %16272 = load i32, i32* %23, align 4
  %16273 = icmp eq i32 %16217, %16272
  %16274 = or i1 %16271, %16273
  %16275 = load i32, i32* %24, align 4
  %16276 = icmp eq i32 %16217, %16275
  %16277 = or i1 %16274, %16276
  %16278 = load i32, i32* %25, align 4
  %16279 = icmp eq i32 %16217, %16278
  %16280 = or i1 %16277, %16279
  %16281 = load i32, i32* %26, align 4
  %16282 = icmp eq i32 %16217, %16281
  %16283 = or i1 %16280, %16282
  %16284 = load i32, i32* %27, align 4
  %16285 = icmp eq i32 %16217, %16284
  %16286 = or i1 %16283, %16285
  %16287 = load i32, i32* %28, align 4
  %16288 = icmp eq i32 %16217, %16287
  %16289 = or i1 %16286, %16288
  %16290 = load i32, i32* %29, align 4
  %16291 = icmp eq i32 %16217, %16290
  %16292 = or i1 %16289, %16291
  %16293 = load i32, i32* %30, align 4
  %16294 = icmp eq i32 %16217, %16293
  %16295 = or i1 %16292, %16294
  %16296 = load i32, i32* %31, align 4
  %16297 = icmp eq i32 %16217, %16296
  %16298 = or i1 %16295, %16297
  %16299 = load i32, i32* %32, align 4
  %16300 = icmp eq i32 %16217, %16299
  %16301 = or i1 %16298, %16300
  %16302 = load i32, i32* %33, align 4
  %16303 = icmp eq i32 %16217, %16302
  %16304 = or i1 %16301, %16303
  %16305 = load i32, i32* %34, align 4
  %16306 = icmp eq i32 %16217, %16305
  %16307 = or i1 %16304, %16306
  %16308 = load i32, i32* %35, align 4
  %16309 = icmp eq i32 %16217, %16308
  %16310 = or i1 %16307, %16309
  %16311 = load i32, i32* %36, align 4
  %16312 = icmp eq i32 %16217, %16311
  %16313 = or i1 %16310, %16312
  %16314 = load i32, i32* %37, align 4
  %16315 = icmp eq i32 %16217, %16314
  %16316 = or i1 %16313, %16315
  %16317 = load i32, i32* %38, align 4
  %16318 = icmp eq i32 %16217, %16317
  %16319 = or i1 %16316, %16318
  %16320 = load i32, i32* %39, align 4
  %16321 = icmp eq i32 %16217, %16320
  %16322 = or i1 %16319, %16321
  %16323 = load i32, i32* %40, align 4
  %16324 = icmp eq i32 %16217, %16323
  %16325 = or i1 %16322, %16324
  %16326 = load i32, i32* %41, align 4
  %16327 = icmp eq i32 %16217, %16326
  %16328 = or i1 %16325, %16327
  %16329 = load i32, i32* %42, align 4
  %16330 = icmp eq i32 %16217, %16329
  %16331 = or i1 %16328, %16330
  %16332 = load i32, i32* %43, align 4
  %16333 = icmp eq i32 %16217, %16332
  %16334 = or i1 %16331, %16333
  %16335 = load i32, i32* %44, align 4
  %16336 = icmp eq i32 %16217, %16335
  %16337 = or i1 %16334, %16336
  %16338 = load i32, i32* %45, align 4
  %16339 = icmp eq i32 %16217, %16338
  %16340 = or i1 %16337, %16339
  %16341 = load i32, i32* %46, align 4
  %16342 = icmp eq i32 %16217, %16341
  %16343 = or i1 %16340, %16342
  %16344 = load i32, i32* %47, align 4
  %16345 = icmp eq i32 %16217, %16344
  %16346 = or i1 %16343, %16345
  %16347 = load i32, i32* %48, align 4
  %16348 = icmp eq i32 %16217, %16347
  %16349 = or i1 %16346, %16348
  %16350 = load i32, i32* %49, align 4
  %16351 = icmp eq i32 %16217, %16350
  %16352 = or i1 %16349, %16351
  %16353 = load i32, i32* %50, align 4
  %16354 = icmp eq i32 %16217, %16353
  %16355 = or i1 %16352, %16354
  %16356 = load i32, i32* %51, align 4
  %16357 = icmp eq i32 %16217, %16356
  %16358 = or i1 %16355, %16357
  %16359 = load i32, i32* %52, align 4
  %16360 = icmp eq i32 %16217, %16359
  %16361 = or i1 %16358, %16360
  %16362 = load i32, i32* %53, align 4
  %16363 = icmp eq i32 %16217, %16362
  %16364 = or i1 %16361, %16363
  %16365 = load i32, i32* %54, align 4
  %16366 = icmp eq i32 %16217, %16365
  %16367 = or i1 %16364, %16366
  %16368 = load i32, i32* %55, align 4
  %16369 = icmp eq i32 %16217, %16368
  %16370 = or i1 %16367, %16369
  %16371 = load i32, i32* %56, align 4
  %16372 = icmp eq i32 %16217, %16371
  %16373 = or i1 %16370, %16372
  %16374 = load i32, i32* %57, align 4
  %16375 = icmp eq i32 %16217, %16374
  %16376 = or i1 %16373, %16375
  %16377 = load i32, i32* %58, align 4
  %16378 = icmp eq i32 %16217, %16377
  %16379 = or i1 %16376, %16378
  %16380 = load i32, i32* %59, align 4
  %16381 = icmp eq i32 %16217, %16380
  %16382 = or i1 %16379, %16381
  %16383 = load i32, i32* %60, align 4
  %16384 = icmp eq i32 %16217, %16383
  %16385 = or i1 %16382, %16384
  %16386 = load i32, i32* %61, align 4
  %16387 = icmp eq i32 %16217, %16386
  %16388 = or i1 %16385, %16387
  %16389 = load i32, i32* %62, align 4
  %16390 = icmp eq i32 %16217, %16389
  %16391 = or i1 %16388, %16390
  %16392 = getelementptr i8, i8 addrspace(1)* %4, i32 51
  %16393 = zext i1 %16391 to i8
  store i8 %16393, i8 addrspace(1)* %16392, align 1, !nosanitize !3
  %16394 = load i256, i256* %16216, align 4
  %16395 = mul i256 %16394, %16195, !pc !301, !intsan !45
  %16396 = icmp eq i256 7500, 0
  %16397 = icmp eq i1 %16396, false
  %16398 = trunc i256 6436 to i64
  %jump.check189 = icmp ne i1 %16397, false
  %16399 = load i64, i64* %STACK_DEP_PTR, align 4
  %16400 = add i64 %16399, 1
  store i64 %16400, i64* %STACK_DEP_PTR, align 4
  %16401 = load i64, i64* %STACK_DEP_PTR, align 4
  %16402 = getelementptr i256, i256* %STACK, i64 %16401
  store i256 %16187, i256* %16402, align 4
  %16403 = load i64, i64* %STACK_DEP_PTR, align 4
  %16404 = add i64 %16403, 1
  store i64 %16404, i64* %STACK_DEP_PTR, align 4
  %16405 = load i64, i64* %STACK_DEP_PTR, align 4
  %16406 = getelementptr i256, i256* %STACK, i64 %16405
  store i256 %16193, i256* %16406, align 4
  %16407 = load i64, i64* %STACK_DEP_PTR, align 4
  %16408 = add i64 %16407, 1
  store i64 %16408, i64* %STACK_DEP_PTR, align 4
  %16409 = load i64, i64* %STACK_DEP_PTR, align 4
  %16410 = getelementptr i256, i256* %STACK, i64 %16409
  store i256 7500, i256* %16410, align 4
  %16411 = load i64, i64* %STACK_DEP_PTR, align 4
  %16412 = add i64 %16411, 1
  store i64 %16412, i64* %STACK_DEP_PTR, align 4
  %16413 = load i64, i64* %STACK_DEP_PTR, align 4
  %16414 = getelementptr i256, i256* %STACK, i64 %16413
  store i256 %16395, i256* %16414, align 4
  br i1 %jump.check189, label %.6436, label %.6435, !EVMBB !4

.6435:                                            ; preds = %16168
  %16415 = load i64, i64* %remaing_gas, align 4
  %16416 = icmp ugt i64 16, %16415
  br i1 %16416, label %Abort, label %16417

16417:                                            ; preds = %.6435
  %16418 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16419 = xor i32 %16418, 1069
  %16420 = urem i32 %16419, 4096
  %16421 = getelementptr i8, i8 addrspace(1)* %4, i32 %16420
  %16422 = load i8, i8 addrspace(1)* %16421, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16421, align 1, !nosanitize !3
  store i32 534, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16423 = sub i64 %16415, 16
  store i64 %16423, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.6436:                                            ; preds = %16168, %JumpTable
  %16424 = load i64, i64* %remaing_gas, align 4
  %16425 = icmp ugt i64 312, %16424
  br i1 %16425, label %Abort, label %16426

16426:                                            ; preds = %.6436
  %16427 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16428 = xor i32 %16427, 1965
  %16429 = urem i32 %16428, 4096
  %16430 = getelementptr i8, i8 addrspace(1)* %4, i32 %16429
  %16431 = load i8, i8 addrspace(1)* %16430, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16430, align 1, !nosanitize !3
  store i32 982, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16432 = sub i64 %16424, 312
  store i64 %16432, i64* %remaing_gas, align 4
  %16433 = load i64, i64* %STACK_DEP_PTR, align 4
  %16434 = getelementptr i256, i256* %STACK, i64 %16433
  %16435 = load i256, i256* %16434, align 4
  %16436 = load i64, i64* %STACK_DEP_PTR, align 4
  %16437 = sub i64 %16436, 1
  store i64 %16437, i64* %STACK_DEP_PTR, align 4
  %16438 = load i64, i64* %STACK_DEP_PTR, align 4
  %16439 = getelementptr i256, i256* %STACK, i64 %16438
  %16440 = load i256, i256* %16439, align 4
  %16441 = load i64, i64* %STACK_DEP_PTR, align 4
  %16442 = sub i64 %16441, 1
  store i64 %16442, i64* %STACK_DEP_PTR, align 4
  %16443 = load i64, i64* %STACK_DEP_PTR, align 4
  %16444 = getelementptr i256, i256* %STACK, i64 %16443
  %16445 = load i256, i256* %16444, align 4
  %16446 = load i64, i64* %STACK_DEP_PTR, align 4
  %16447 = sub i64 %16446, 1
  store i64 %16447, i64* %STACK_DEP_PTR, align 4
  %16448 = alloca i256, align 8
  store i256 %16435, i256* %16448, align 4
  %16449 = alloca i256, align 8
  store i256 %16440, i256* %16449, align 4
  %16450 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %16448, i256* %16449, i256* %16450), !pc !302, !intsan !6
  %16451 = load i256, i256* %16450, align 4
  %16452 = icmp ugt i256 %16451, %16445
  %16453 = icmp eq i1 %16452, false
  %16454 = icmp eq i1 %16453, false
  %16455 = trunc i256 6489 to i64
  %jump.check190 = icmp ne i1 %16454, false
  %16456 = load i64, i64* %STACK_DEP_PTR, align 4
  %16457 = add i64 %16456, 1
  store i64 %16457, i64* %STACK_DEP_PTR, align 4
  %16458 = zext i1 %16453 to i256
  %16459 = load i64, i64* %STACK_DEP_PTR, align 4
  %16460 = getelementptr i256, i256* %STACK, i64 %16459
  store i256 %16458, i256* %16460, align 4
  br i1 %jump.check190, label %.6489, label %.6446, !EVMBB !4

.6446:                                            ; preds = %16426
  %16461 = load i64, i64* %STACK_DEP_PTR, align 4
  %16462 = getelementptr i256, i256* %STACK, i64 %16461
  %16463 = load i256, i256* %16462, align 4
  %16464 = load i64, i64* %STACK_DEP_PTR, align 4
  %16465 = sub i64 %16464, 1
  store i64 %16465, i64* %STACK_DEP_PTR, align 4
  %16466 = load i64, i64* %STACK_DEP_PTR, align 4
  %16467 = getelementptr i256, i256* %STACK, i64 %16466
  %16468 = load i256, i256* %16467, align 4
  %16469 = load i64, i64* %STACK_DEP_PTR, align 4
  %16470 = sub i64 %16469, 1
  store i64 %16470, i64* %STACK_DEP_PTR, align 4
  %16471 = xor i256 0, -1
  %16472 = and i256 %16471, %16468
  %16473 = xor i256 0, -1
  %16474 = and i256 %16473, %16472
  %16475 = trunc i256 0 to i64
  %16476 = alloca i256, align 8
  store i256 %16474, i256* %16476, align 4
  %16477 = bitcast i256* %16476 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16475, i8* %16477, i64 32)
  %16478 = add i256 32, 0, !pc !303, !intsan !10
  %16479 = trunc i256 %16478 to i64
  %16480 = alloca i256, align 8
  store i256 11, i256* %16480, align 4
  %16481 = bitcast i256* %16480 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16479, i8* %16481, i64 32)
  %16482 = add i256 32, %16478, !pc !304, !intsan !10
  %16483 = trunc i256 0 to i32
  %16484 = trunc i256 %16482 to i32
  %16485 = getelementptr inbounds i8, i8* %MEMORY, i32 %16483
  %16486 = alloca i256, align 8
  %16487 = bitcast i256* %16486 to i8*
  call void @__device_sha3(i8* %16485, i32 %16484, i8* %16487)
  %16488 = load i256, i256* %16486, align 4
  %16489 = add i256 1, %16488, !pc !305, !intsan !10
  %16490 = alloca i256, align 8
  store i256 %16489, i256* %16490, align 4
  %16491 = alloca i256, align 8
  call void @__device_sload(i256* %16490, i256* %16491)
  %16492 = call i32 @__hashword(i256* %16490)
  %16493 = load i32, i32* %5, align 4
  %16494 = icmp eq i32 %16492, %16493
  %16495 = or i1 false, %16494
  %16496 = load i32, i32* %6, align 4
  %16497 = icmp eq i32 %16492, %16496
  %16498 = or i1 %16495, %16497
  %16499 = load i32, i32* %7, align 4
  %16500 = icmp eq i32 %16492, %16499
  %16501 = or i1 %16498, %16500
  %16502 = load i32, i32* %8, align 4
  %16503 = icmp eq i32 %16492, %16502
  %16504 = or i1 %16501, %16503
  %16505 = load i32, i32* %9, align 4
  %16506 = icmp eq i32 %16492, %16505
  %16507 = or i1 %16504, %16506
  %16508 = load i32, i32* %10, align 4
  %16509 = icmp eq i32 %16492, %16508
  %16510 = or i1 %16507, %16509
  %16511 = load i32, i32* %11, align 4
  %16512 = icmp eq i32 %16492, %16511
  %16513 = or i1 %16510, %16512
  %16514 = load i32, i32* %12, align 4
  %16515 = icmp eq i32 %16492, %16514
  %16516 = or i1 %16513, %16515
  %16517 = load i32, i32* %13, align 4
  %16518 = icmp eq i32 %16492, %16517
  %16519 = or i1 %16516, %16518
  %16520 = load i32, i32* %14, align 4
  %16521 = icmp eq i32 %16492, %16520
  %16522 = or i1 %16519, %16521
  %16523 = load i32, i32* %15, align 4
  %16524 = icmp eq i32 %16492, %16523
  %16525 = or i1 %16522, %16524
  %16526 = load i32, i32* %16, align 4
  %16527 = icmp eq i32 %16492, %16526
  %16528 = or i1 %16525, %16527
  %16529 = load i32, i32* %17, align 4
  %16530 = icmp eq i32 %16492, %16529
  %16531 = or i1 %16528, %16530
  %16532 = load i32, i32* %18, align 4
  %16533 = icmp eq i32 %16492, %16532
  %16534 = or i1 %16531, %16533
  %16535 = load i32, i32* %19, align 4
  %16536 = icmp eq i32 %16492, %16535
  %16537 = or i1 %16534, %16536
  %16538 = load i32, i32* %20, align 4
  %16539 = icmp eq i32 %16492, %16538
  %16540 = or i1 %16537, %16539
  %16541 = load i32, i32* %21, align 4
  %16542 = icmp eq i32 %16492, %16541
  %16543 = or i1 %16540, %16542
  %16544 = load i32, i32* %22, align 4
  %16545 = icmp eq i32 %16492, %16544
  %16546 = or i1 %16543, %16545
  %16547 = load i32, i32* %23, align 4
  %16548 = icmp eq i32 %16492, %16547
  %16549 = or i1 %16546, %16548
  %16550 = load i32, i32* %24, align 4
  %16551 = icmp eq i32 %16492, %16550
  %16552 = or i1 %16549, %16551
  %16553 = load i32, i32* %25, align 4
  %16554 = icmp eq i32 %16492, %16553
  %16555 = or i1 %16552, %16554
  %16556 = load i32, i32* %26, align 4
  %16557 = icmp eq i32 %16492, %16556
  %16558 = or i1 %16555, %16557
  %16559 = load i32, i32* %27, align 4
  %16560 = icmp eq i32 %16492, %16559
  %16561 = or i1 %16558, %16560
  %16562 = load i32, i32* %28, align 4
  %16563 = icmp eq i32 %16492, %16562
  %16564 = or i1 %16561, %16563
  %16565 = load i32, i32* %29, align 4
  %16566 = icmp eq i32 %16492, %16565
  %16567 = or i1 %16564, %16566
  %16568 = load i32, i32* %30, align 4
  %16569 = icmp eq i32 %16492, %16568
  %16570 = or i1 %16567, %16569
  %16571 = load i32, i32* %31, align 4
  %16572 = icmp eq i32 %16492, %16571
  %16573 = or i1 %16570, %16572
  %16574 = load i32, i32* %32, align 4
  %16575 = icmp eq i32 %16492, %16574
  %16576 = or i1 %16573, %16575
  %16577 = load i32, i32* %33, align 4
  %16578 = icmp eq i32 %16492, %16577
  %16579 = or i1 %16576, %16578
  %16580 = load i32, i32* %34, align 4
  %16581 = icmp eq i32 %16492, %16580
  %16582 = or i1 %16579, %16581
  %16583 = load i32, i32* %35, align 4
  %16584 = icmp eq i32 %16492, %16583
  %16585 = or i1 %16582, %16584
  %16586 = load i32, i32* %36, align 4
  %16587 = icmp eq i32 %16492, %16586
  %16588 = or i1 %16585, %16587
  %16589 = load i32, i32* %37, align 4
  %16590 = icmp eq i32 %16492, %16589
  %16591 = or i1 %16588, %16590
  %16592 = load i32, i32* %38, align 4
  %16593 = icmp eq i32 %16492, %16592
  %16594 = or i1 %16591, %16593
  %16595 = load i32, i32* %39, align 4
  %16596 = icmp eq i32 %16492, %16595
  %16597 = or i1 %16594, %16596
  %16598 = load i32, i32* %40, align 4
  %16599 = icmp eq i32 %16492, %16598
  %16600 = or i1 %16597, %16599
  %16601 = load i32, i32* %41, align 4
  %16602 = icmp eq i32 %16492, %16601
  %16603 = or i1 %16600, %16602
  %16604 = load i32, i32* %42, align 4
  %16605 = icmp eq i32 %16492, %16604
  %16606 = or i1 %16603, %16605
  %16607 = load i32, i32* %43, align 4
  %16608 = icmp eq i32 %16492, %16607
  %16609 = or i1 %16606, %16608
  %16610 = load i32, i32* %44, align 4
  %16611 = icmp eq i32 %16492, %16610
  %16612 = or i1 %16609, %16611
  %16613 = load i32, i32* %45, align 4
  %16614 = icmp eq i32 %16492, %16613
  %16615 = or i1 %16612, %16614
  %16616 = load i32, i32* %46, align 4
  %16617 = icmp eq i32 %16492, %16616
  %16618 = or i1 %16615, %16617
  %16619 = load i32, i32* %47, align 4
  %16620 = icmp eq i32 %16492, %16619
  %16621 = or i1 %16618, %16620
  %16622 = load i32, i32* %48, align 4
  %16623 = icmp eq i32 %16492, %16622
  %16624 = or i1 %16621, %16623
  %16625 = load i32, i32* %49, align 4
  %16626 = icmp eq i32 %16492, %16625
  %16627 = or i1 %16624, %16626
  %16628 = load i32, i32* %50, align 4
  %16629 = icmp eq i32 %16492, %16628
  %16630 = or i1 %16627, %16629
  %16631 = load i32, i32* %51, align 4
  %16632 = icmp eq i32 %16492, %16631
  %16633 = or i1 %16630, %16632
  %16634 = load i32, i32* %52, align 4
  %16635 = icmp eq i32 %16492, %16634
  %16636 = or i1 %16633, %16635
  %16637 = load i32, i32* %53, align 4
  %16638 = icmp eq i32 %16492, %16637
  %16639 = or i1 %16636, %16638
  %16640 = load i32, i32* %54, align 4
  %16641 = icmp eq i32 %16492, %16640
  %16642 = or i1 %16639, %16641
  %16643 = load i32, i32* %55, align 4
  %16644 = icmp eq i32 %16492, %16643
  %16645 = or i1 %16642, %16644
  %16646 = load i32, i32* %56, align 4
  %16647 = icmp eq i32 %16492, %16646
  %16648 = or i1 %16645, %16647
  %16649 = load i32, i32* %57, align 4
  %16650 = icmp eq i32 %16492, %16649
  %16651 = or i1 %16648, %16650
  %16652 = load i32, i32* %58, align 4
  %16653 = icmp eq i32 %16492, %16652
  %16654 = or i1 %16651, %16653
  %16655 = load i32, i32* %59, align 4
  %16656 = icmp eq i32 %16492, %16655
  %16657 = or i1 %16654, %16656
  %16658 = load i32, i32* %60, align 4
  %16659 = icmp eq i32 %16492, %16658
  %16660 = or i1 %16657, %16659
  %16661 = load i32, i32* %61, align 4
  %16662 = icmp eq i32 %16492, %16661
  %16663 = or i1 %16660, %16662
  %16664 = load i32, i32* %62, align 4
  %16665 = icmp eq i32 %16492, %16664
  %16666 = or i1 %16663, %16665
  %16667 = getelementptr i8, i8 addrspace(1)* %4, i32 52
  %16668 = zext i1 %16666 to i8
  store i8 %16668, i8 addrspace(1)* %16667, align 1, !nosanitize !3
  %16669 = load i256, i256* %16491, align 4
  %16670 = icmp ult i256 %16669, 200000000000000000
  %16671 = icmp eq i1 %16670, false
  %16672 = load i64, i64* %STACK_DEP_PTR, align 4
  %16673 = add i64 %16672, 1
  store i64 %16673, i64* %STACK_DEP_PTR, align 4
  %16674 = load i64, i64* %STACK_DEP_PTR, align 4
  %16675 = getelementptr i256, i256* %STACK, i64 %16674
  store i256 %16468, i256* %16675, align 4
  %16676 = load i64, i64* %STACK_DEP_PTR, align 4
  %16677 = add i64 %16676, 1
  store i64 %16677, i64* %STACK_DEP_PTR, align 4
  %16678 = zext i1 %16671 to i256
  %16679 = load i64, i64* %STACK_DEP_PTR, align 4
  %16680 = getelementptr i256, i256* %STACK, i64 %16679
  store i256 %16678, i256* %16680, align 4
  br label %.6489

.6489:                                            ; preds = %.6446, %16426, %JumpTable
  %16681 = load i64, i64* %remaing_gas, align 4
  %16682 = icmp ugt i64 88, %16681
  br i1 %16682, label %Abort, label %16683

16683:                                            ; preds = %.6489
  %16684 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16685 = xor i32 %16684, 1236
  %16686 = urem i32 %16685, 4096
  %16687 = getelementptr i8, i8 addrspace(1)* %4, i32 %16686
  %16688 = load i8, i8 addrspace(1)* %16687, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16687, align 1, !nosanitize !3
  store i32 618, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16689 = sub i64 %16681, 88
  store i64 %16689, i64* %remaing_gas, align 4
  %16690 = load i64, i64* %STACK_DEP_PTR, align 4
  %16691 = getelementptr i256, i256* %STACK, i64 %16690
  %16692 = load i256, i256* %16691, align 4
  %16693 = load i64, i64* %STACK_DEP_PTR, align 4
  %16694 = sub i64 %16693, 1
  store i64 %16694, i64* %STACK_DEP_PTR, align 4
  %16695 = icmp eq i256 %16692, 0
  %16696 = trunc i256 6871 to i64
  %jump.check191 = icmp ne i1 %16695, false
  br i1 %jump.check191, label %.6871, label %.6495, !EVMBB !4

.6495:                                            ; preds = %16683
  %16697 = load i64, i64* %remaing_gas, align 4
  %16698 = icmp ugt i64 984, %16697
  br i1 %16698, label %Abort, label %16699

16699:                                            ; preds = %.6495
  %16700 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16701 = xor i32 %16700, 1910
  %16702 = urem i32 %16701, 4096
  %16703 = getelementptr i8, i8 addrspace(1)* %4, i32 %16702
  %16704 = load i8, i8 addrspace(1)* %16703, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16703, align 1, !nosanitize !3
  store i32 955, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16705 = sub i64 %16697, 984
  store i64 %16705, i64* %remaing_gas, align 4
  %16706 = load i64, i64* %STACK_DEP_PTR, align 4
  %16707 = getelementptr i256, i256* %STACK, i64 %16706
  %16708 = load i256, i256* %16707, align 4
  %16709 = load i64, i64* %STACK_DEP_PTR, align 4
  %16710 = sub i64 %16709, 1
  store i64 %16710, i64* %STACK_DEP_PTR, align 4
  %16711 = load i64, i64* %STACK_DEP_PTR, align 4
  %16712 = getelementptr i256, i256* %STACK, i64 %16711
  %16713 = load i256, i256* %16712, align 4
  %16714 = load i64, i64* %STACK_DEP_PTR, align 4
  %16715 = sub i64 %16714, 1
  store i64 %16715, i64* %STACK_DEP_PTR, align 4
  %16716 = load i64, i64* %STACK_DEP_PTR, align 4
  %16717 = getelementptr i256, i256* %STACK, i64 %16716
  %16718 = load i256, i256* %16717, align 4
  %16719 = load i64, i64* %STACK_DEP_PTR, align 4
  %16720 = sub i64 %16719, 1
  store i64 %16720, i64* %STACK_DEP_PTR, align 4
  %16721 = load i64, i64* %STACK_DEP_PTR, align 4
  %16722 = getelementptr i256, i256* %STACK, i64 %16721
  %16723 = load i256, i256* %16722, align 4
  %16724 = load i64, i64* %STACK_DEP_PTR, align 4
  %16725 = sub i64 %16724, 1
  store i64 %16725, i64* %STACK_DEP_PTR, align 4
  %16726 = load i64, i64* %STACK_DEP_PTR, align 4
  %16727 = getelementptr i256, i256* %STACK, i64 %16726
  %16728 = load i256, i256* %16727, align 4
  %16729 = load i64, i64* %STACK_DEP_PTR, align 4
  %16730 = sub i64 %16729, 1
  store i64 %16730, i64* %STACK_DEP_PTR, align 4
  %16731 = load i64, i64* %STACK_DEP_PTR, align 4
  %16732 = getelementptr i256, i256* %STACK, i64 %16731
  %16733 = load i256, i256* %16732, align 4
  %16734 = load i64, i64* %STACK_DEP_PTR, align 4
  %16735 = sub i64 %16734, 1
  store i64 %16735, i64* %STACK_DEP_PTR, align 4
  %16736 = load i64, i64* %STACK_DEP_PTR, align 4
  %16737 = getelementptr i256, i256* %STACK, i64 %16736
  %16738 = load i256, i256* %16737, align 4
  %16739 = load i64, i64* %STACK_DEP_PTR, align 4
  %16740 = sub i64 %16739, 1
  store i64 %16740, i64* %STACK_DEP_PTR, align 4
  %16741 = load i64, i64* %STACK_DEP_PTR, align 4
  %16742 = getelementptr i256, i256* %STACK, i64 %16741
  %16743 = load i256, i256* %16742, align 4
  %16744 = load i64, i64* %STACK_DEP_PTR, align 4
  %16745 = sub i64 %16744, 1
  store i64 %16745, i64* %STACK_DEP_PTR, align 4
  %16746 = load i64, i64* %STACK_DEP_PTR, align 4
  %16747 = getelementptr i256, i256* %STACK, i64 %16746
  %16748 = load i256, i256* %16747, align 4
  %16749 = load i64, i64* %STACK_DEP_PTR, align 4
  %16750 = sub i64 %16749, 1
  store i64 %16750, i64* %STACK_DEP_PTR, align 4
  %16751 = trunc i256 14564 to i64
  %16752 = load i64, i64* %STACK_DEP_PTR, align 4
  %16753 = add i64 %16752, 1
  store i64 %16753, i64* %STACK_DEP_PTR, align 4
  %16754 = load i64, i64* %STACK_DEP_PTR, align 4
  %16755 = getelementptr i256, i256* %STACK, i64 %16754
  store i256 %16748, i256* %16755, align 4
  %16756 = load i64, i64* %STACK_DEP_PTR, align 4
  %16757 = add i64 %16756, 1
  store i64 %16757, i64* %STACK_DEP_PTR, align 4
  %16758 = load i64, i64* %STACK_DEP_PTR, align 4
  %16759 = getelementptr i256, i256* %STACK, i64 %16758
  store i256 %16743, i256* %16759, align 4
  %16760 = load i64, i64* %STACK_DEP_PTR, align 4
  %16761 = add i64 %16760, 1
  store i64 %16761, i64* %STACK_DEP_PTR, align 4
  %16762 = load i64, i64* %STACK_DEP_PTR, align 4
  %16763 = getelementptr i256, i256* %STACK, i64 %16762
  store i256 %16738, i256* %16763, align 4
  %16764 = load i64, i64* %STACK_DEP_PTR, align 4
  %16765 = add i64 %16764, 1
  store i64 %16765, i64* %STACK_DEP_PTR, align 4
  %16766 = load i64, i64* %STACK_DEP_PTR, align 4
  %16767 = getelementptr i256, i256* %STACK, i64 %16766
  store i256 %16733, i256* %16767, align 4
  %16768 = load i64, i64* %STACK_DEP_PTR, align 4
  %16769 = add i64 %16768, 1
  store i64 %16769, i64* %STACK_DEP_PTR, align 4
  %16770 = load i64, i64* %STACK_DEP_PTR, align 4
  %16771 = getelementptr i256, i256* %STACK, i64 %16770
  store i256 %16728, i256* %16771, align 4
  %16772 = load i64, i64* %STACK_DEP_PTR, align 4
  %16773 = add i64 %16772, 1
  store i64 %16773, i64* %STACK_DEP_PTR, align 4
  %16774 = load i64, i64* %STACK_DEP_PTR, align 4
  %16775 = getelementptr i256, i256* %STACK, i64 %16774
  store i256 %16723, i256* %16775, align 4
  %16776 = load i64, i64* %STACK_DEP_PTR, align 4
  %16777 = add i64 %16776, 1
  store i64 %16777, i64* %STACK_DEP_PTR, align 4
  %16778 = load i64, i64* %STACK_DEP_PTR, align 4
  %16779 = getelementptr i256, i256* %STACK, i64 %16778
  store i256 %16718, i256* %16779, align 4
  %16780 = load i64, i64* %STACK_DEP_PTR, align 4
  %16781 = add i64 %16780, 1
  store i64 %16781, i64* %STACK_DEP_PTR, align 4
  %16782 = load i64, i64* %STACK_DEP_PTR, align 4
  %16783 = getelementptr i256, i256* %STACK, i64 %16782
  store i256 %16713, i256* %16783, align 4
  %16784 = load i64, i64* %STACK_DEP_PTR, align 4
  %16785 = add i64 %16784, 1
  store i64 %16785, i64* %STACK_DEP_PTR, align 4
  %16786 = load i64, i64* %STACK_DEP_PTR, align 4
  %16787 = getelementptr i256, i256* %STACK, i64 %16786
  store i256 %16708, i256* %16787, align 4
  %16788 = load i64, i64* %STACK_DEP_PTR, align 4
  %16789 = add i64 %16788, 1
  store i64 %16789, i64* %STACK_DEP_PTR, align 4
  %16790 = load i64, i64* %STACK_DEP_PTR, align 4
  %16791 = getelementptr i256, i256* %STACK, i64 %16790
  store i256 6503, i256* %16791, align 4
  %16792 = load i64, i64* %STACK_DEP_PTR, align 4
  %16793 = add i64 %16792, 1
  store i64 %16793, i64* %STACK_DEP_PTR, align 4
  %16794 = load i64, i64* %STACK_DEP_PTR, align 4
  %16795 = getelementptr i256, i256* %STACK, i64 %16794
  store i256 %16748, i256* %16795, align 4
  br label %.14564, !EVMBB !4

.6503:                                            ; preds = %JumpTable
  %16796 = load i64, i64* %remaing_gas, align 4
  %16797 = icmp ugt i64 2032, %16796
  br i1 %16797, label %Abort, label %16798

16798:                                            ; preds = %.6503
  %16799 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16800 = xor i32 %16799, 3655
  %16801 = urem i32 %16800, 4096
  %16802 = getelementptr i8, i8 addrspace(1)* %4, i32 %16801
  %16803 = load i8, i8 addrspace(1)* %16802, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %16802, align 1, !nosanitize !3
  store i32 1827, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %16804 = sub i64 %16796, 2032
  store i64 %16804, i64* %remaing_gas, align 4
  %16805 = load i64, i64* %STACK_DEP_PTR, align 4
  %16806 = getelementptr i256, i256* %STACK, i64 %16805
  %16807 = load i256, i256* %16806, align 4
  %16808 = load i64, i64* %STACK_DEP_PTR, align 4
  %16809 = sub i64 %16808, 1
  store i64 %16809, i64* %STACK_DEP_PTR, align 4
  %16810 = load i64, i64* %STACK_DEP_PTR, align 4
  %16811 = getelementptr i256, i256* %STACK, i64 %16810
  %16812 = load i256, i256* %16811, align 4
  %16813 = load i64, i64* %STACK_DEP_PTR, align 4
  %16814 = sub i64 %16813, 1
  store i64 %16814, i64* %STACK_DEP_PTR, align 4
  %16815 = load i64, i64* %STACK_DEP_PTR, align 4
  %16816 = getelementptr i256, i256* %STACK, i64 %16815
  %16817 = load i256, i256* %16816, align 4
  %16818 = load i64, i64* %STACK_DEP_PTR, align 4
  %16819 = sub i64 %16818, 1
  store i64 %16819, i64* %STACK_DEP_PTR, align 4
  %16820 = load i64, i64* %STACK_DEP_PTR, align 4
  %16821 = getelementptr i256, i256* %STACK, i64 %16820
  %16822 = load i256, i256* %16821, align 4
  %16823 = load i64, i64* %STACK_DEP_PTR, align 4
  %16824 = sub i64 %16823, 1
  store i64 %16824, i64* %STACK_DEP_PTR, align 4
  %16825 = load i64, i64* %STACK_DEP_PTR, align 4
  %16826 = getelementptr i256, i256* %STACK, i64 %16825
  %16827 = load i256, i256* %16826, align 4
  %16828 = load i64, i64* %STACK_DEP_PTR, align 4
  %16829 = sub i64 %16828, 1
  store i64 %16829, i64* %STACK_DEP_PTR, align 4
  %16830 = load i64, i64* %STACK_DEP_PTR, align 4
  %16831 = getelementptr i256, i256* %STACK, i64 %16830
  %16832 = load i256, i256* %16831, align 4
  %16833 = load i64, i64* %STACK_DEP_PTR, align 4
  %16834 = sub i64 %16833, 1
  store i64 %16834, i64* %STACK_DEP_PTR, align 4
  %16835 = load i64, i64* %STACK_DEP_PTR, align 4
  %16836 = getelementptr i256, i256* %STACK, i64 %16835
  %16837 = load i256, i256* %16836, align 4
  %16838 = load i64, i64* %STACK_DEP_PTR, align 4
  %16839 = sub i64 %16838, 1
  store i64 %16839, i64* %STACK_DEP_PTR, align 4
  %16840 = load i64, i64* %STACK_DEP_PTR, align 4
  %16841 = getelementptr i256, i256* %STACK, i64 %16840
  %16842 = load i256, i256* %16841, align 4
  %16843 = load i64, i64* %STACK_DEP_PTR, align 4
  %16844 = sub i64 %16843, 1
  store i64 %16844, i64* %STACK_DEP_PTR, align 4
  %16845 = load i64, i64* %STACK_DEP_PTR, align 4
  %16846 = getelementptr i256, i256* %STACK, i64 %16845
  %16847 = load i256, i256* %16846, align 4
  %16848 = load i64, i64* %STACK_DEP_PTR, align 4
  %16849 = sub i64 %16848, 1
  store i64 %16849, i64* %STACK_DEP_PTR, align 4
  %16850 = load i64, i64* %STACK_DEP_PTR, align 4
  %16851 = getelementptr i256, i256* %STACK, i64 %16850
  %16852 = load i256, i256* %16851, align 4
  %16853 = load i64, i64* %STACK_DEP_PTR, align 4
  %16854 = sub i64 %16853, 1
  store i64 %16854, i64* %STACK_DEP_PTR, align 4
  %16855 = load i64, i64* %STACK_DEP_PTR, align 4
  %16856 = getelementptr i256, i256* %STACK, i64 %16855
  %16857 = load i256, i256* %16856, align 4
  %16858 = load i64, i64* %STACK_DEP_PTR, align 4
  %16859 = sub i64 %16858, 1
  store i64 %16859, i64* %STACK_DEP_PTR, align 4
  %16860 = xor i256 0, -1
  %16861 = and i256 %16860, %16857
  %16862 = xor i256 0, -1
  %16863 = and i256 %16862, %16861
  %16864 = trunc i256 0 to i64
  %16865 = alloca i256, align 8
  store i256 %16863, i256* %16865, align 4
  %16866 = bitcast i256* %16865 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16864, i8* %16866, i64 32)
  %16867 = add i256 32, 0, !pc !306, !intsan !10
  %16868 = trunc i256 %16867 to i64
  %16869 = alloca i256, align 8
  store i256 11, i256* %16869, align 4
  %16870 = bitcast i256* %16869 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16868, i8* %16870, i64 32)
  %16871 = add i256 32, %16867, !pc !307, !intsan !10
  %16872 = trunc i256 0 to i32
  %16873 = trunc i256 %16871 to i32
  %16874 = getelementptr inbounds i8, i8* %MEMORY, i32 %16872
  %16875 = alloca i256, align 8
  %16876 = bitcast i256* %16875 to i8*
  call void @__device_sha3(i8* %16874, i32 %16873, i8* %16876)
  %16877 = load i256, i256* %16875, align 4
  %16878 = add i256 2, %16877, !pc !308, !intsan !10
  %16879 = alloca i256, align 8
  store i256 %16878, i256* %16879, align 4
  %16880 = alloca i256, align 8
  store i256 %16807, i256* %16880, align 4
  call void @__device_sstore(i256* %16879, i256* %16880)
  %16881 = call i32 @__hashword(i256* %16879)
  store i32 %16881, i32* %36, align 4, !nosanitize !3
  %16882 = xor i256 0, -1
  %16883 = and i256 %16882, %16857
  %16884 = xor i256 0, -1
  %16885 = and i256 %16884, %16883
  %16886 = trunc i256 0 to i64
  %16887 = alloca i256, align 8
  store i256 %16885, i256* %16887, align 4
  %16888 = bitcast i256* %16887 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16886, i8* %16888, i64 32)
  %16889 = add i256 32, 0, !pc !309, !intsan !10
  %16890 = trunc i256 %16889 to i64
  %16891 = alloca i256, align 8
  store i256 11, i256* %16891, align 4
  %16892 = bitcast i256* %16891 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16890, i8* %16892, i64 32)
  %16893 = add i256 32, %16889, !pc !310, !intsan !10
  %16894 = trunc i256 0 to i32
  %16895 = trunc i256 %16893 to i32
  %16896 = getelementptr inbounds i8, i8* %MEMORY, i32 %16894
  %16897 = alloca i256, align 8
  %16898 = bitcast i256* %16897 to i8*
  call void @__device_sha3(i8* %16896, i32 %16895, i8* %16898)
  %16899 = load i256, i256* %16897, align 4
  %16900 = trunc i256 64 to i64
  %16901 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %16900, i256* %16901)
  %16902 = load i256, i256* %16901, align 4
  %16903 = add i256 %16902, 96, !pc !311, !intsan !10
  %16904 = trunc i256 64 to i64
  %16905 = alloca i256, align 8
  store i256 %16903, i256* %16905, align 4
  %16906 = bitcast i256* %16905 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %16904, i8* %16906, i64 32)
  %16907 = add i256 %16899, 0, !pc !312, !intsan !10
  %16908 = alloca i256, align 8
  store i256 %16907, i256* %16908, align 4
  %16909 = alloca i256, align 8
  call void @__device_sload(i256* %16908, i256* %16909)
  %16910 = call i32 @__hashword(i256* %16908)
  %16911 = load i32, i32* %5, align 4
  %16912 = icmp eq i32 %16910, %16911
  %16913 = or i1 false, %16912
  %16914 = load i32, i32* %6, align 4
  %16915 = icmp eq i32 %16910, %16914
  %16916 = or i1 %16913, %16915
  %16917 = load i32, i32* %7, align 4
  %16918 = icmp eq i32 %16910, %16917
  %16919 = or i1 %16916, %16918
  %16920 = load i32, i32* %8, align 4
  %16921 = icmp eq i32 %16910, %16920
  %16922 = or i1 %16919, %16921
  %16923 = load i32, i32* %9, align 4
  %16924 = icmp eq i32 %16910, %16923
  %16925 = or i1 %16922, %16924
  %16926 = load i32, i32* %10, align 4
  %16927 = icmp eq i32 %16910, %16926
  %16928 = or i1 %16925, %16927
  %16929 = load i32, i32* %11, align 4
  %16930 = icmp eq i32 %16910, %16929
  %16931 = or i1 %16928, %16930
  %16932 = load i32, i32* %12, align 4
  %16933 = icmp eq i32 %16910, %16932
  %16934 = or i1 %16931, %16933
  %16935 = load i32, i32* %13, align 4
  %16936 = icmp eq i32 %16910, %16935
  %16937 = or i1 %16934, %16936
  %16938 = load i32, i32* %14, align 4
  %16939 = icmp eq i32 %16910, %16938
  %16940 = or i1 %16937, %16939
  %16941 = load i32, i32* %15, align 4
  %16942 = icmp eq i32 %16910, %16941
  %16943 = or i1 %16940, %16942
  %16944 = load i32, i32* %16, align 4
  %16945 = icmp eq i32 %16910, %16944
  %16946 = or i1 %16943, %16945
  %16947 = load i32, i32* %17, align 4
  %16948 = icmp eq i32 %16910, %16947
  %16949 = or i1 %16946, %16948
  %16950 = load i32, i32* %18, align 4
  %16951 = icmp eq i32 %16910, %16950
  %16952 = or i1 %16949, %16951
  %16953 = load i32, i32* %19, align 4
  %16954 = icmp eq i32 %16910, %16953
  %16955 = or i1 %16952, %16954
  %16956 = load i32, i32* %20, align 4
  %16957 = icmp eq i32 %16910, %16956
  %16958 = or i1 %16955, %16957
  %16959 = load i32, i32* %21, align 4
  %16960 = icmp eq i32 %16910, %16959
  %16961 = or i1 %16958, %16960
  %16962 = load i32, i32* %22, align 4
  %16963 = icmp eq i32 %16910, %16962
  %16964 = or i1 %16961, %16963
  %16965 = load i32, i32* %23, align 4
  %16966 = icmp eq i32 %16910, %16965
  %16967 = or i1 %16964, %16966
  %16968 = load i32, i32* %24, align 4
  %16969 = icmp eq i32 %16910, %16968
  %16970 = or i1 %16967, %16969
  %16971 = load i32, i32* %25, align 4
  %16972 = icmp eq i32 %16910, %16971
  %16973 = or i1 %16970, %16972
  %16974 = load i32, i32* %26, align 4
  %16975 = icmp eq i32 %16910, %16974
  %16976 = or i1 %16973, %16975
  %16977 = load i32, i32* %27, align 4
  %16978 = icmp eq i32 %16910, %16977
  %16979 = or i1 %16976, %16978
  %16980 = load i32, i32* %28, align 4
  %16981 = icmp eq i32 %16910, %16980
  %16982 = or i1 %16979, %16981
  %16983 = load i32, i32* %29, align 4
  %16984 = icmp eq i32 %16910, %16983
  %16985 = or i1 %16982, %16984
  %16986 = load i32, i32* %30, align 4
  %16987 = icmp eq i32 %16910, %16986
  %16988 = or i1 %16985, %16987
  %16989 = load i32, i32* %31, align 4
  %16990 = icmp eq i32 %16910, %16989
  %16991 = or i1 %16988, %16990
  %16992 = load i32, i32* %32, align 4
  %16993 = icmp eq i32 %16910, %16992
  %16994 = or i1 %16991, %16993
  %16995 = load i32, i32* %33, align 4
  %16996 = icmp eq i32 %16910, %16995
  %16997 = or i1 %16994, %16996
  %16998 = load i32, i32* %34, align 4
  %16999 = icmp eq i32 %16910, %16998
  %17000 = or i1 %16997, %16999
  %17001 = load i32, i32* %35, align 4
  %17002 = icmp eq i32 %16910, %17001
  %17003 = or i1 %17000, %17002
  %17004 = load i32, i32* %36, align 4
  %17005 = icmp eq i32 %16910, %17004
  %17006 = or i1 %17003, %17005
  %17007 = load i32, i32* %37, align 4
  %17008 = icmp eq i32 %16910, %17007
  %17009 = or i1 %17006, %17008
  %17010 = load i32, i32* %38, align 4
  %17011 = icmp eq i32 %16910, %17010
  %17012 = or i1 %17009, %17011
  %17013 = load i32, i32* %39, align 4
  %17014 = icmp eq i32 %16910, %17013
  %17015 = or i1 %17012, %17014
  %17016 = load i32, i32* %40, align 4
  %17017 = icmp eq i32 %16910, %17016
  %17018 = or i1 %17015, %17017
  %17019 = load i32, i32* %41, align 4
  %17020 = icmp eq i32 %16910, %17019
  %17021 = or i1 %17018, %17020
  %17022 = load i32, i32* %42, align 4
  %17023 = icmp eq i32 %16910, %17022
  %17024 = or i1 %17021, %17023
  %17025 = load i32, i32* %43, align 4
  %17026 = icmp eq i32 %16910, %17025
  %17027 = or i1 %17024, %17026
  %17028 = load i32, i32* %44, align 4
  %17029 = icmp eq i32 %16910, %17028
  %17030 = or i1 %17027, %17029
  %17031 = load i32, i32* %45, align 4
  %17032 = icmp eq i32 %16910, %17031
  %17033 = or i1 %17030, %17032
  %17034 = load i32, i32* %46, align 4
  %17035 = icmp eq i32 %16910, %17034
  %17036 = or i1 %17033, %17035
  %17037 = load i32, i32* %47, align 4
  %17038 = icmp eq i32 %16910, %17037
  %17039 = or i1 %17036, %17038
  %17040 = load i32, i32* %48, align 4
  %17041 = icmp eq i32 %16910, %17040
  %17042 = or i1 %17039, %17041
  %17043 = load i32, i32* %49, align 4
  %17044 = icmp eq i32 %16910, %17043
  %17045 = or i1 %17042, %17044
  %17046 = load i32, i32* %50, align 4
  %17047 = icmp eq i32 %16910, %17046
  %17048 = or i1 %17045, %17047
  %17049 = load i32, i32* %51, align 4
  %17050 = icmp eq i32 %16910, %17049
  %17051 = or i1 %17048, %17050
  %17052 = load i32, i32* %52, align 4
  %17053 = icmp eq i32 %16910, %17052
  %17054 = or i1 %17051, %17053
  %17055 = load i32, i32* %53, align 4
  %17056 = icmp eq i32 %16910, %17055
  %17057 = or i1 %17054, %17056
  %17058 = load i32, i32* %54, align 4
  %17059 = icmp eq i32 %16910, %17058
  %17060 = or i1 %17057, %17059
  %17061 = load i32, i32* %55, align 4
  %17062 = icmp eq i32 %16910, %17061
  %17063 = or i1 %17060, %17062
  %17064 = load i32, i32* %56, align 4
  %17065 = icmp eq i32 %16910, %17064
  %17066 = or i1 %17063, %17065
  %17067 = load i32, i32* %57, align 4
  %17068 = icmp eq i32 %16910, %17067
  %17069 = or i1 %17066, %17068
  %17070 = load i32, i32* %58, align 4
  %17071 = icmp eq i32 %16910, %17070
  %17072 = or i1 %17069, %17071
  %17073 = load i32, i32* %59, align 4
  %17074 = icmp eq i32 %16910, %17073
  %17075 = or i1 %17072, %17074
  %17076 = load i32, i32* %60, align 4
  %17077 = icmp eq i32 %16910, %17076
  %17078 = or i1 %17075, %17077
  %17079 = load i32, i32* %61, align 4
  %17080 = icmp eq i32 %16910, %17079
  %17081 = or i1 %17078, %17080
  %17082 = load i32, i32* %62, align 4
  %17083 = icmp eq i32 %16910, %17082
  %17084 = or i1 %17081, %17083
  %17085 = getelementptr i8, i8 addrspace(1)* %4, i32 53
  %17086 = zext i1 %17084 to i8
  store i8 %17086, i8 addrspace(1)* %17085, align 1, !nosanitize !3
  %17087 = load i256, i256* %16909, align 4
  %17088 = alloca i256, align 8
  store i256 %17087, i256* %17088, align 4
  %17089 = alloca i256, align 8
  store i256 1, i256* %17089, align 4
  %17090 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %17088, i256* %17089, i256* %17090), !pc !313, !intsan !6
  %17091 = load i256, i256* %17090, align 4
  %17092 = and i256 1461501637330902918203684832716283019655932542975, %17091
  %17093 = and i256 1461501637330902918203684832716283019655932542975, %17092
  %17094 = and i256 1461501637330902918203684832716283019655932542975, %17093
  %17095 = trunc i256 %16902 to i64
  %17096 = alloca i256, align 8
  store i256 %17094, i256* %17096, align 4
  %17097 = bitcast i256* %17096 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17095, i8* %17097, i64 32)
  %17098 = add i256 32, %16902, !pc !314, !intsan !10
  %17099 = add i256 %16899, 1, !pc !315, !intsan !10
  %17100 = alloca i256, align 8
  store i256 %17099, i256* %17100, align 4
  %17101 = alloca i256, align 8
  call void @__device_sload(i256* %17100, i256* %17101)
  %17102 = call i32 @__hashword(i256* %17100)
  %17103 = load i32, i32* %5, align 4
  %17104 = icmp eq i32 %17102, %17103
  %17105 = or i1 false, %17104
  %17106 = load i32, i32* %6, align 4
  %17107 = icmp eq i32 %17102, %17106
  %17108 = or i1 %17105, %17107
  %17109 = load i32, i32* %7, align 4
  %17110 = icmp eq i32 %17102, %17109
  %17111 = or i1 %17108, %17110
  %17112 = load i32, i32* %8, align 4
  %17113 = icmp eq i32 %17102, %17112
  %17114 = or i1 %17111, %17113
  %17115 = load i32, i32* %9, align 4
  %17116 = icmp eq i32 %17102, %17115
  %17117 = or i1 %17114, %17116
  %17118 = load i32, i32* %10, align 4
  %17119 = icmp eq i32 %17102, %17118
  %17120 = or i1 %17117, %17119
  %17121 = load i32, i32* %11, align 4
  %17122 = icmp eq i32 %17102, %17121
  %17123 = or i1 %17120, %17122
  %17124 = load i32, i32* %12, align 4
  %17125 = icmp eq i32 %17102, %17124
  %17126 = or i1 %17123, %17125
  %17127 = load i32, i32* %13, align 4
  %17128 = icmp eq i32 %17102, %17127
  %17129 = or i1 %17126, %17128
  %17130 = load i32, i32* %14, align 4
  %17131 = icmp eq i32 %17102, %17130
  %17132 = or i1 %17129, %17131
  %17133 = load i32, i32* %15, align 4
  %17134 = icmp eq i32 %17102, %17133
  %17135 = or i1 %17132, %17134
  %17136 = load i32, i32* %16, align 4
  %17137 = icmp eq i32 %17102, %17136
  %17138 = or i1 %17135, %17137
  %17139 = load i32, i32* %17, align 4
  %17140 = icmp eq i32 %17102, %17139
  %17141 = or i1 %17138, %17140
  %17142 = load i32, i32* %18, align 4
  %17143 = icmp eq i32 %17102, %17142
  %17144 = or i1 %17141, %17143
  %17145 = load i32, i32* %19, align 4
  %17146 = icmp eq i32 %17102, %17145
  %17147 = or i1 %17144, %17146
  %17148 = load i32, i32* %20, align 4
  %17149 = icmp eq i32 %17102, %17148
  %17150 = or i1 %17147, %17149
  %17151 = load i32, i32* %21, align 4
  %17152 = icmp eq i32 %17102, %17151
  %17153 = or i1 %17150, %17152
  %17154 = load i32, i32* %22, align 4
  %17155 = icmp eq i32 %17102, %17154
  %17156 = or i1 %17153, %17155
  %17157 = load i32, i32* %23, align 4
  %17158 = icmp eq i32 %17102, %17157
  %17159 = or i1 %17156, %17158
  %17160 = load i32, i32* %24, align 4
  %17161 = icmp eq i32 %17102, %17160
  %17162 = or i1 %17159, %17161
  %17163 = load i32, i32* %25, align 4
  %17164 = icmp eq i32 %17102, %17163
  %17165 = or i1 %17162, %17164
  %17166 = load i32, i32* %26, align 4
  %17167 = icmp eq i32 %17102, %17166
  %17168 = or i1 %17165, %17167
  %17169 = load i32, i32* %27, align 4
  %17170 = icmp eq i32 %17102, %17169
  %17171 = or i1 %17168, %17170
  %17172 = load i32, i32* %28, align 4
  %17173 = icmp eq i32 %17102, %17172
  %17174 = or i1 %17171, %17173
  %17175 = load i32, i32* %29, align 4
  %17176 = icmp eq i32 %17102, %17175
  %17177 = or i1 %17174, %17176
  %17178 = load i32, i32* %30, align 4
  %17179 = icmp eq i32 %17102, %17178
  %17180 = or i1 %17177, %17179
  %17181 = load i32, i32* %31, align 4
  %17182 = icmp eq i32 %17102, %17181
  %17183 = or i1 %17180, %17182
  %17184 = load i32, i32* %32, align 4
  %17185 = icmp eq i32 %17102, %17184
  %17186 = or i1 %17183, %17185
  %17187 = load i32, i32* %33, align 4
  %17188 = icmp eq i32 %17102, %17187
  %17189 = or i1 %17186, %17188
  %17190 = load i32, i32* %34, align 4
  %17191 = icmp eq i32 %17102, %17190
  %17192 = or i1 %17189, %17191
  %17193 = load i32, i32* %35, align 4
  %17194 = icmp eq i32 %17102, %17193
  %17195 = or i1 %17192, %17194
  %17196 = load i32, i32* %36, align 4
  %17197 = icmp eq i32 %17102, %17196
  %17198 = or i1 %17195, %17197
  %17199 = load i32, i32* %37, align 4
  %17200 = icmp eq i32 %17102, %17199
  %17201 = or i1 %17198, %17200
  %17202 = load i32, i32* %38, align 4
  %17203 = icmp eq i32 %17102, %17202
  %17204 = or i1 %17201, %17203
  %17205 = load i32, i32* %39, align 4
  %17206 = icmp eq i32 %17102, %17205
  %17207 = or i1 %17204, %17206
  %17208 = load i32, i32* %40, align 4
  %17209 = icmp eq i32 %17102, %17208
  %17210 = or i1 %17207, %17209
  %17211 = load i32, i32* %41, align 4
  %17212 = icmp eq i32 %17102, %17211
  %17213 = or i1 %17210, %17212
  %17214 = load i32, i32* %42, align 4
  %17215 = icmp eq i32 %17102, %17214
  %17216 = or i1 %17213, %17215
  %17217 = load i32, i32* %43, align 4
  %17218 = icmp eq i32 %17102, %17217
  %17219 = or i1 %17216, %17218
  %17220 = load i32, i32* %44, align 4
  %17221 = icmp eq i32 %17102, %17220
  %17222 = or i1 %17219, %17221
  %17223 = load i32, i32* %45, align 4
  %17224 = icmp eq i32 %17102, %17223
  %17225 = or i1 %17222, %17224
  %17226 = load i32, i32* %46, align 4
  %17227 = icmp eq i32 %17102, %17226
  %17228 = or i1 %17225, %17227
  %17229 = load i32, i32* %47, align 4
  %17230 = icmp eq i32 %17102, %17229
  %17231 = or i1 %17228, %17230
  %17232 = load i32, i32* %48, align 4
  %17233 = icmp eq i32 %17102, %17232
  %17234 = or i1 %17231, %17233
  %17235 = load i32, i32* %49, align 4
  %17236 = icmp eq i32 %17102, %17235
  %17237 = or i1 %17234, %17236
  %17238 = load i32, i32* %50, align 4
  %17239 = icmp eq i32 %17102, %17238
  %17240 = or i1 %17237, %17239
  %17241 = load i32, i32* %51, align 4
  %17242 = icmp eq i32 %17102, %17241
  %17243 = or i1 %17240, %17242
  %17244 = load i32, i32* %52, align 4
  %17245 = icmp eq i32 %17102, %17244
  %17246 = or i1 %17243, %17245
  %17247 = load i32, i32* %53, align 4
  %17248 = icmp eq i32 %17102, %17247
  %17249 = or i1 %17246, %17248
  %17250 = load i32, i32* %54, align 4
  %17251 = icmp eq i32 %17102, %17250
  %17252 = or i1 %17249, %17251
  %17253 = load i32, i32* %55, align 4
  %17254 = icmp eq i32 %17102, %17253
  %17255 = or i1 %17252, %17254
  %17256 = load i32, i32* %56, align 4
  %17257 = icmp eq i32 %17102, %17256
  %17258 = or i1 %17255, %17257
  %17259 = load i32, i32* %57, align 4
  %17260 = icmp eq i32 %17102, %17259
  %17261 = or i1 %17258, %17260
  %17262 = load i32, i32* %58, align 4
  %17263 = icmp eq i32 %17102, %17262
  %17264 = or i1 %17261, %17263
  %17265 = load i32, i32* %59, align 4
  %17266 = icmp eq i32 %17102, %17265
  %17267 = or i1 %17264, %17266
  %17268 = load i32, i32* %60, align 4
  %17269 = icmp eq i32 %17102, %17268
  %17270 = or i1 %17267, %17269
  %17271 = load i32, i32* %61, align 4
  %17272 = icmp eq i32 %17102, %17271
  %17273 = or i1 %17270, %17272
  %17274 = load i32, i32* %62, align 4
  %17275 = icmp eq i32 %17102, %17274
  %17276 = or i1 %17273, %17275
  %17277 = getelementptr i8, i8 addrspace(1)* %4, i32 54
  %17278 = zext i1 %17276 to i8
  store i8 %17278, i8 addrspace(1)* %17277, align 1, !nosanitize !3
  %17279 = load i256, i256* %17101, align 4
  %17280 = trunc i256 %17098 to i64
  %17281 = alloca i256, align 8
  store i256 %17279, i256* %17281, align 4
  %17282 = bitcast i256* %17281 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17280, i8* %17282, i64 32)
  %17283 = add i256 32, %17098, !pc !316, !intsan !10
  %17284 = add i256 %16899, 2, !pc !317, !intsan !10
  %17285 = alloca i256, align 8
  store i256 %17284, i256* %17285, align 4
  %17286 = alloca i256, align 8
  call void @__device_sload(i256* %17285, i256* %17286)
  %17287 = call i32 @__hashword(i256* %17285)
  %17288 = load i32, i32* %5, align 4
  %17289 = icmp eq i32 %17287, %17288
  %17290 = or i1 false, %17289
  %17291 = load i32, i32* %6, align 4
  %17292 = icmp eq i32 %17287, %17291
  %17293 = or i1 %17290, %17292
  %17294 = load i32, i32* %7, align 4
  %17295 = icmp eq i32 %17287, %17294
  %17296 = or i1 %17293, %17295
  %17297 = load i32, i32* %8, align 4
  %17298 = icmp eq i32 %17287, %17297
  %17299 = or i1 %17296, %17298
  %17300 = load i32, i32* %9, align 4
  %17301 = icmp eq i32 %17287, %17300
  %17302 = or i1 %17299, %17301
  %17303 = load i32, i32* %10, align 4
  %17304 = icmp eq i32 %17287, %17303
  %17305 = or i1 %17302, %17304
  %17306 = load i32, i32* %11, align 4
  %17307 = icmp eq i32 %17287, %17306
  %17308 = or i1 %17305, %17307
  %17309 = load i32, i32* %12, align 4
  %17310 = icmp eq i32 %17287, %17309
  %17311 = or i1 %17308, %17310
  %17312 = load i32, i32* %13, align 4
  %17313 = icmp eq i32 %17287, %17312
  %17314 = or i1 %17311, %17313
  %17315 = load i32, i32* %14, align 4
  %17316 = icmp eq i32 %17287, %17315
  %17317 = or i1 %17314, %17316
  %17318 = load i32, i32* %15, align 4
  %17319 = icmp eq i32 %17287, %17318
  %17320 = or i1 %17317, %17319
  %17321 = load i32, i32* %16, align 4
  %17322 = icmp eq i32 %17287, %17321
  %17323 = or i1 %17320, %17322
  %17324 = load i32, i32* %17, align 4
  %17325 = icmp eq i32 %17287, %17324
  %17326 = or i1 %17323, %17325
  %17327 = load i32, i32* %18, align 4
  %17328 = icmp eq i32 %17287, %17327
  %17329 = or i1 %17326, %17328
  %17330 = load i32, i32* %19, align 4
  %17331 = icmp eq i32 %17287, %17330
  %17332 = or i1 %17329, %17331
  %17333 = load i32, i32* %20, align 4
  %17334 = icmp eq i32 %17287, %17333
  %17335 = or i1 %17332, %17334
  %17336 = load i32, i32* %21, align 4
  %17337 = icmp eq i32 %17287, %17336
  %17338 = or i1 %17335, %17337
  %17339 = load i32, i32* %22, align 4
  %17340 = icmp eq i32 %17287, %17339
  %17341 = or i1 %17338, %17340
  %17342 = load i32, i32* %23, align 4
  %17343 = icmp eq i32 %17287, %17342
  %17344 = or i1 %17341, %17343
  %17345 = load i32, i32* %24, align 4
  %17346 = icmp eq i32 %17287, %17345
  %17347 = or i1 %17344, %17346
  %17348 = load i32, i32* %25, align 4
  %17349 = icmp eq i32 %17287, %17348
  %17350 = or i1 %17347, %17349
  %17351 = load i32, i32* %26, align 4
  %17352 = icmp eq i32 %17287, %17351
  %17353 = or i1 %17350, %17352
  %17354 = load i32, i32* %27, align 4
  %17355 = icmp eq i32 %17287, %17354
  %17356 = or i1 %17353, %17355
  %17357 = load i32, i32* %28, align 4
  %17358 = icmp eq i32 %17287, %17357
  %17359 = or i1 %17356, %17358
  %17360 = load i32, i32* %29, align 4
  %17361 = icmp eq i32 %17287, %17360
  %17362 = or i1 %17359, %17361
  %17363 = load i32, i32* %30, align 4
  %17364 = icmp eq i32 %17287, %17363
  %17365 = or i1 %17362, %17364
  %17366 = load i32, i32* %31, align 4
  %17367 = icmp eq i32 %17287, %17366
  %17368 = or i1 %17365, %17367
  %17369 = load i32, i32* %32, align 4
  %17370 = icmp eq i32 %17287, %17369
  %17371 = or i1 %17368, %17370
  %17372 = load i32, i32* %33, align 4
  %17373 = icmp eq i32 %17287, %17372
  %17374 = or i1 %17371, %17373
  %17375 = load i32, i32* %34, align 4
  %17376 = icmp eq i32 %17287, %17375
  %17377 = or i1 %17374, %17376
  %17378 = load i32, i32* %35, align 4
  %17379 = icmp eq i32 %17287, %17378
  %17380 = or i1 %17377, %17379
  %17381 = load i32, i32* %36, align 4
  %17382 = icmp eq i32 %17287, %17381
  %17383 = or i1 %17380, %17382
  %17384 = load i32, i32* %37, align 4
  %17385 = icmp eq i32 %17287, %17384
  %17386 = or i1 %17383, %17385
  %17387 = load i32, i32* %38, align 4
  %17388 = icmp eq i32 %17287, %17387
  %17389 = or i1 %17386, %17388
  %17390 = load i32, i32* %39, align 4
  %17391 = icmp eq i32 %17287, %17390
  %17392 = or i1 %17389, %17391
  %17393 = load i32, i32* %40, align 4
  %17394 = icmp eq i32 %17287, %17393
  %17395 = or i1 %17392, %17394
  %17396 = load i32, i32* %41, align 4
  %17397 = icmp eq i32 %17287, %17396
  %17398 = or i1 %17395, %17397
  %17399 = load i32, i32* %42, align 4
  %17400 = icmp eq i32 %17287, %17399
  %17401 = or i1 %17398, %17400
  %17402 = load i32, i32* %43, align 4
  %17403 = icmp eq i32 %17287, %17402
  %17404 = or i1 %17401, %17403
  %17405 = load i32, i32* %44, align 4
  %17406 = icmp eq i32 %17287, %17405
  %17407 = or i1 %17404, %17406
  %17408 = load i32, i32* %45, align 4
  %17409 = icmp eq i32 %17287, %17408
  %17410 = or i1 %17407, %17409
  %17411 = load i32, i32* %46, align 4
  %17412 = icmp eq i32 %17287, %17411
  %17413 = or i1 %17410, %17412
  %17414 = load i32, i32* %47, align 4
  %17415 = icmp eq i32 %17287, %17414
  %17416 = or i1 %17413, %17415
  %17417 = load i32, i32* %48, align 4
  %17418 = icmp eq i32 %17287, %17417
  %17419 = or i1 %17416, %17418
  %17420 = load i32, i32* %49, align 4
  %17421 = icmp eq i32 %17287, %17420
  %17422 = or i1 %17419, %17421
  %17423 = load i32, i32* %50, align 4
  %17424 = icmp eq i32 %17287, %17423
  %17425 = or i1 %17422, %17424
  %17426 = load i32, i32* %51, align 4
  %17427 = icmp eq i32 %17287, %17426
  %17428 = or i1 %17425, %17427
  %17429 = load i32, i32* %52, align 4
  %17430 = icmp eq i32 %17287, %17429
  %17431 = or i1 %17428, %17430
  %17432 = load i32, i32* %53, align 4
  %17433 = icmp eq i32 %17287, %17432
  %17434 = or i1 %17431, %17433
  %17435 = load i32, i32* %54, align 4
  %17436 = icmp eq i32 %17287, %17435
  %17437 = or i1 %17434, %17436
  %17438 = load i32, i32* %55, align 4
  %17439 = icmp eq i32 %17287, %17438
  %17440 = or i1 %17437, %17439
  %17441 = load i32, i32* %56, align 4
  %17442 = icmp eq i32 %17287, %17441
  %17443 = or i1 %17440, %17442
  %17444 = load i32, i32* %57, align 4
  %17445 = icmp eq i32 %17287, %17444
  %17446 = or i1 %17443, %17445
  %17447 = load i32, i32* %58, align 4
  %17448 = icmp eq i32 %17287, %17447
  %17449 = or i1 %17446, %17448
  %17450 = load i32, i32* %59, align 4
  %17451 = icmp eq i32 %17287, %17450
  %17452 = or i1 %17449, %17451
  %17453 = load i32, i32* %60, align 4
  %17454 = icmp eq i32 %17287, %17453
  %17455 = or i1 %17452, %17454
  %17456 = load i32, i32* %61, align 4
  %17457 = icmp eq i32 %17287, %17456
  %17458 = or i1 %17455, %17457
  %17459 = load i32, i32* %62, align 4
  %17460 = icmp eq i32 %17287, %17459
  %17461 = or i1 %17458, %17460
  %17462 = getelementptr i8, i8 addrspace(1)* %4, i32 55
  %17463 = zext i1 %17461 to i8
  store i8 %17463, i8 addrspace(1)* %17462, align 1, !nosanitize !3
  %17464 = load i256, i256* %17286, align 4
  %17465 = trunc i256 %17283 to i64
  %17466 = alloca i256, align 8
  store i256 %17464, i256* %17466, align 4
  %17467 = bitcast i256* %17466 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17465, i8* %17467, i64 32)
  %17468 = trunc i256 15314 to i64
  %17469 = load i64, i64* %STACK_DEP_PTR, align 4
  %17470 = add i64 %17469, 1
  store i64 %17470, i64* %STACK_DEP_PTR, align 4
  %17471 = load i64, i64* %STACK_DEP_PTR, align 4
  %17472 = getelementptr i256, i256* %STACK, i64 %17471
  store i256 %16857, i256* %17472, align 4
  %17473 = load i64, i64* %STACK_DEP_PTR, align 4
  %17474 = add i64 %17473, 1
  store i64 %17474, i64* %STACK_DEP_PTR, align 4
  %17475 = load i64, i64* %STACK_DEP_PTR, align 4
  %17476 = getelementptr i256, i256* %STACK, i64 %17475
  store i256 %16852, i256* %17476, align 4
  %17477 = load i64, i64* %STACK_DEP_PTR, align 4
  %17478 = add i64 %17477, 1
  store i64 %17478, i64* %STACK_DEP_PTR, align 4
  %17479 = load i64, i64* %STACK_DEP_PTR, align 4
  %17480 = getelementptr i256, i256* %STACK, i64 %17479
  store i256 %16847, i256* %17480, align 4
  %17481 = load i64, i64* %STACK_DEP_PTR, align 4
  %17482 = add i64 %17481, 1
  store i64 %17482, i64* %STACK_DEP_PTR, align 4
  %17483 = load i64, i64* %STACK_DEP_PTR, align 4
  %17484 = getelementptr i256, i256* %STACK, i64 %17483
  store i256 %16807, i256* %17484, align 4
  %17485 = load i64, i64* %STACK_DEP_PTR, align 4
  %17486 = add i64 %17485, 1
  store i64 %17486, i64* %STACK_DEP_PTR, align 4
  %17487 = load i64, i64* %STACK_DEP_PTR, align 4
  %17488 = getelementptr i256, i256* %STACK, i64 %17487
  store i256 %16837, i256* %17488, align 4
  %17489 = load i64, i64* %STACK_DEP_PTR, align 4
  %17490 = add i64 %17489, 1
  store i64 %17490, i64* %STACK_DEP_PTR, align 4
  %17491 = load i64, i64* %STACK_DEP_PTR, align 4
  %17492 = getelementptr i256, i256* %STACK, i64 %17491
  store i256 %16832, i256* %17492, align 4
  %17493 = load i64, i64* %STACK_DEP_PTR, align 4
  %17494 = add i64 %17493, 1
  store i64 %17494, i64* %STACK_DEP_PTR, align 4
  %17495 = load i64, i64* %STACK_DEP_PTR, align 4
  %17496 = getelementptr i256, i256* %STACK, i64 %17495
  store i256 %16827, i256* %17496, align 4
  %17497 = load i64, i64* %STACK_DEP_PTR, align 4
  %17498 = add i64 %17497, 1
  store i64 %17498, i64* %STACK_DEP_PTR, align 4
  %17499 = load i64, i64* %STACK_DEP_PTR, align 4
  %17500 = getelementptr i256, i256* %STACK, i64 %17499
  store i256 %16822, i256* %17500, align 4
  %17501 = load i64, i64* %STACK_DEP_PTR, align 4
  %17502 = add i64 %17501, 1
  store i64 %17502, i64* %STACK_DEP_PTR, align 4
  %17503 = load i64, i64* %STACK_DEP_PTR, align 4
  %17504 = getelementptr i256, i256* %STACK, i64 %17503
  store i256 %16817, i256* %17504, align 4
  %17505 = load i64, i64* %STACK_DEP_PTR, align 4
  %17506 = add i64 %17505, 1
  store i64 %17506, i64* %STACK_DEP_PTR, align 4
  %17507 = load i64, i64* %STACK_DEP_PTR, align 4
  %17508 = getelementptr i256, i256* %STACK, i64 %17507
  store i256 %16812, i256* %17508, align 4
  %17509 = load i64, i64* %STACK_DEP_PTR, align 4
  %17510 = add i64 %17509, 1
  store i64 %17510, i64* %STACK_DEP_PTR, align 4
  %17511 = load i64, i64* %STACK_DEP_PTR, align 4
  %17512 = getelementptr i256, i256* %STACK, i64 %17511
  store i256 6694, i256* %17512, align 4
  %17513 = load i64, i64* %STACK_DEP_PTR, align 4
  %17514 = add i64 %17513, 1
  store i64 %17514, i64* %STACK_DEP_PTR, align 4
  %17515 = load i64, i64* %STACK_DEP_PTR, align 4
  %17516 = getelementptr i256, i256* %STACK, i64 %17515
  store i256 %16902, i256* %17516, align 4
  %17517 = load i64, i64* %STACK_DEP_PTR, align 4
  %17518 = add i64 %17517, 1
  store i64 %17518, i64* %STACK_DEP_PTR, align 4
  %17519 = load i64, i64* %STACK_DEP_PTR, align 4
  %17520 = getelementptr i256, i256* %STACK, i64 %17519
  store i256 %16807, i256* %17520, align 4
  br label %.15314, !EVMBB !4

.6694:                                            ; preds = %JumpTable
  %17521 = load i64, i64* %remaing_gas, align 4
  %17522 = icmp ugt i64 1752, %17521
  br i1 %17522, label %Abort, label %17523

17523:                                            ; preds = %.6694
  %17524 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %17525 = xor i32 %17524, 3294
  %17526 = urem i32 %17525, 4096
  %17527 = getelementptr i8, i8 addrspace(1)* %4, i32 %17526
  %17528 = load i8, i8 addrspace(1)* %17527, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %17527, align 1, !nosanitize !3
  store i32 1647, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %17529 = sub i64 %17521, 1752
  store i64 %17529, i64* %remaing_gas, align 4
  %17530 = load i64, i64* %STACK_DEP_PTR, align 4
  %17531 = getelementptr i256, i256* %STACK, i64 %17530
  %17532 = load i256, i256* %17531, align 4
  %17533 = load i64, i64* %STACK_DEP_PTR, align 4
  %17534 = sub i64 %17533, 1
  store i64 %17534, i64* %STACK_DEP_PTR, align 4
  %17535 = load i64, i64* %STACK_DEP_PTR, align 4
  %17536 = getelementptr i256, i256* %STACK, i64 %17535
  %17537 = load i256, i256* %17536, align 4
  %17538 = load i64, i64* %STACK_DEP_PTR, align 4
  %17539 = sub i64 %17538, 1
  store i64 %17539, i64* %STACK_DEP_PTR, align 4
  %17540 = load i64, i64* %STACK_DEP_PTR, align 4
  %17541 = getelementptr i256, i256* %STACK, i64 %17540
  %17542 = load i256, i256* %17541, align 4
  %17543 = load i64, i64* %STACK_DEP_PTR, align 4
  %17544 = sub i64 %17543, 1
  store i64 %17544, i64* %STACK_DEP_PTR, align 4
  %17545 = load i64, i64* %STACK_DEP_PTR, align 4
  %17546 = getelementptr i256, i256* %STACK, i64 %17545
  %17547 = load i256, i256* %17546, align 4
  %17548 = load i64, i64* %STACK_DEP_PTR, align 4
  %17549 = sub i64 %17548, 1
  store i64 %17549, i64* %STACK_DEP_PTR, align 4
  %17550 = load i64, i64* %STACK_DEP_PTR, align 4
  %17551 = getelementptr i256, i256* %STACK, i64 %17550
  %17552 = load i256, i256* %17551, align 4
  %17553 = load i64, i64* %STACK_DEP_PTR, align 4
  %17554 = sub i64 %17553, 1
  store i64 %17554, i64* %STACK_DEP_PTR, align 4
  %17555 = load i64, i64* %STACK_DEP_PTR, align 4
  %17556 = getelementptr i256, i256* %STACK, i64 %17555
  %17557 = load i256, i256* %17556, align 4
  %17558 = load i64, i64* %STACK_DEP_PTR, align 4
  %17559 = sub i64 %17558, 1
  store i64 %17559, i64* %STACK_DEP_PTR, align 4
  %17560 = load i64, i64* %STACK_DEP_PTR, align 4
  %17561 = getelementptr i256, i256* %STACK, i64 %17560
  %17562 = load i256, i256* %17561, align 4
  %17563 = load i64, i64* %STACK_DEP_PTR, align 4
  %17564 = sub i64 %17563, 1
  store i64 %17564, i64* %STACK_DEP_PTR, align 4
  %17565 = load i64, i64* %STACK_DEP_PTR, align 4
  %17566 = getelementptr i256, i256* %STACK, i64 %17565
  %17567 = load i256, i256* %17566, align 4
  %17568 = load i64, i64* %STACK_DEP_PTR, align 4
  %17569 = sub i64 %17568, 1
  store i64 %17569, i64* %STACK_DEP_PTR, align 4
  %17570 = load i64, i64* %STACK_DEP_PTR, align 4
  %17571 = getelementptr i256, i256* %STACK, i64 %17570
  %17572 = load i256, i256* %17571, align 4
  %17573 = load i64, i64* %STACK_DEP_PTR, align 4
  %17574 = sub i64 %17573, 1
  store i64 %17574, i64* %STACK_DEP_PTR, align 4
  %17575 = load i64, i64* %STACK_DEP_PTR, align 4
  %17576 = getelementptr i256, i256* %STACK, i64 %17575
  %17577 = load i256, i256* %17576, align 4
  %17578 = load i64, i64* %STACK_DEP_PTR, align 4
  %17579 = sub i64 %17578, 1
  store i64 %17579, i64* %STACK_DEP_PTR, align 4
  %17580 = xor i256 0, -1
  %17581 = and i256 %17580, %17577
  %17582 = xor i256 0, -1
  %17583 = and i256 %17582, %17581
  %17584 = trunc i256 0 to i64
  %17585 = alloca i256, align 8
  store i256 %17583, i256* %17585, align 4
  %17586 = bitcast i256* %17585 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17584, i8* %17586, i64 32)
  %17587 = add i256 32, 0, !pc !318, !intsan !10
  %17588 = trunc i256 %17587 to i64
  %17589 = alloca i256, align 8
  store i256 11, i256* %17589, align 4
  %17590 = bitcast i256* %17589 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17588, i8* %17590, i64 32)
  %17591 = add i256 32, %17587, !pc !319, !intsan !10
  %17592 = trunc i256 0 to i32
  %17593 = trunc i256 %17591 to i32
  %17594 = getelementptr inbounds i8, i8* %MEMORY, i32 %17592
  %17595 = alloca i256, align 8
  %17596 = bitcast i256* %17595 to i8*
  call void @__device_sha3(i8* %17594, i32 %17593, i8* %17596)
  %17597 = load i256, i256* %17595, align 4
  %17598 = trunc i256 64 to i64
  %17599 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %17598, i256* %17599)
  %17600 = load i256, i256* %17599, align 4
  %17601 = add i256 %17600, 96, !pc !320, !intsan !10
  %17602 = trunc i256 64 to i64
  %17603 = alloca i256, align 8
  store i256 %17601, i256* %17603, align 4
  %17604 = bitcast i256* %17603 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17602, i8* %17604, i64 32)
  %17605 = add i256 %17597, 0, !pc !321, !intsan !10
  %17606 = alloca i256, align 8
  store i256 %17605, i256* %17606, align 4
  %17607 = alloca i256, align 8
  call void @__device_sload(i256* %17606, i256* %17607)
  %17608 = call i32 @__hashword(i256* %17606)
  %17609 = load i32, i32* %5, align 4
  %17610 = icmp eq i32 %17608, %17609
  %17611 = or i1 false, %17610
  %17612 = load i32, i32* %6, align 4
  %17613 = icmp eq i32 %17608, %17612
  %17614 = or i1 %17611, %17613
  %17615 = load i32, i32* %7, align 4
  %17616 = icmp eq i32 %17608, %17615
  %17617 = or i1 %17614, %17616
  %17618 = load i32, i32* %8, align 4
  %17619 = icmp eq i32 %17608, %17618
  %17620 = or i1 %17617, %17619
  %17621 = load i32, i32* %9, align 4
  %17622 = icmp eq i32 %17608, %17621
  %17623 = or i1 %17620, %17622
  %17624 = load i32, i32* %10, align 4
  %17625 = icmp eq i32 %17608, %17624
  %17626 = or i1 %17623, %17625
  %17627 = load i32, i32* %11, align 4
  %17628 = icmp eq i32 %17608, %17627
  %17629 = or i1 %17626, %17628
  %17630 = load i32, i32* %12, align 4
  %17631 = icmp eq i32 %17608, %17630
  %17632 = or i1 %17629, %17631
  %17633 = load i32, i32* %13, align 4
  %17634 = icmp eq i32 %17608, %17633
  %17635 = or i1 %17632, %17634
  %17636 = load i32, i32* %14, align 4
  %17637 = icmp eq i32 %17608, %17636
  %17638 = or i1 %17635, %17637
  %17639 = load i32, i32* %15, align 4
  %17640 = icmp eq i32 %17608, %17639
  %17641 = or i1 %17638, %17640
  %17642 = load i32, i32* %16, align 4
  %17643 = icmp eq i32 %17608, %17642
  %17644 = or i1 %17641, %17643
  %17645 = load i32, i32* %17, align 4
  %17646 = icmp eq i32 %17608, %17645
  %17647 = or i1 %17644, %17646
  %17648 = load i32, i32* %18, align 4
  %17649 = icmp eq i32 %17608, %17648
  %17650 = or i1 %17647, %17649
  %17651 = load i32, i32* %19, align 4
  %17652 = icmp eq i32 %17608, %17651
  %17653 = or i1 %17650, %17652
  %17654 = load i32, i32* %20, align 4
  %17655 = icmp eq i32 %17608, %17654
  %17656 = or i1 %17653, %17655
  %17657 = load i32, i32* %21, align 4
  %17658 = icmp eq i32 %17608, %17657
  %17659 = or i1 %17656, %17658
  %17660 = load i32, i32* %22, align 4
  %17661 = icmp eq i32 %17608, %17660
  %17662 = or i1 %17659, %17661
  %17663 = load i32, i32* %23, align 4
  %17664 = icmp eq i32 %17608, %17663
  %17665 = or i1 %17662, %17664
  %17666 = load i32, i32* %24, align 4
  %17667 = icmp eq i32 %17608, %17666
  %17668 = or i1 %17665, %17667
  %17669 = load i32, i32* %25, align 4
  %17670 = icmp eq i32 %17608, %17669
  %17671 = or i1 %17668, %17670
  %17672 = load i32, i32* %26, align 4
  %17673 = icmp eq i32 %17608, %17672
  %17674 = or i1 %17671, %17673
  %17675 = load i32, i32* %27, align 4
  %17676 = icmp eq i32 %17608, %17675
  %17677 = or i1 %17674, %17676
  %17678 = load i32, i32* %28, align 4
  %17679 = icmp eq i32 %17608, %17678
  %17680 = or i1 %17677, %17679
  %17681 = load i32, i32* %29, align 4
  %17682 = icmp eq i32 %17608, %17681
  %17683 = or i1 %17680, %17682
  %17684 = load i32, i32* %30, align 4
  %17685 = icmp eq i32 %17608, %17684
  %17686 = or i1 %17683, %17685
  %17687 = load i32, i32* %31, align 4
  %17688 = icmp eq i32 %17608, %17687
  %17689 = or i1 %17686, %17688
  %17690 = load i32, i32* %32, align 4
  %17691 = icmp eq i32 %17608, %17690
  %17692 = or i1 %17689, %17691
  %17693 = load i32, i32* %33, align 4
  %17694 = icmp eq i32 %17608, %17693
  %17695 = or i1 %17692, %17694
  %17696 = load i32, i32* %34, align 4
  %17697 = icmp eq i32 %17608, %17696
  %17698 = or i1 %17695, %17697
  %17699 = load i32, i32* %35, align 4
  %17700 = icmp eq i32 %17608, %17699
  %17701 = or i1 %17698, %17700
  %17702 = load i32, i32* %36, align 4
  %17703 = icmp eq i32 %17608, %17702
  %17704 = or i1 %17701, %17703
  %17705 = load i32, i32* %37, align 4
  %17706 = icmp eq i32 %17608, %17705
  %17707 = or i1 %17704, %17706
  %17708 = load i32, i32* %38, align 4
  %17709 = icmp eq i32 %17608, %17708
  %17710 = or i1 %17707, %17709
  %17711 = load i32, i32* %39, align 4
  %17712 = icmp eq i32 %17608, %17711
  %17713 = or i1 %17710, %17712
  %17714 = load i32, i32* %40, align 4
  %17715 = icmp eq i32 %17608, %17714
  %17716 = or i1 %17713, %17715
  %17717 = load i32, i32* %41, align 4
  %17718 = icmp eq i32 %17608, %17717
  %17719 = or i1 %17716, %17718
  %17720 = load i32, i32* %42, align 4
  %17721 = icmp eq i32 %17608, %17720
  %17722 = or i1 %17719, %17721
  %17723 = load i32, i32* %43, align 4
  %17724 = icmp eq i32 %17608, %17723
  %17725 = or i1 %17722, %17724
  %17726 = load i32, i32* %44, align 4
  %17727 = icmp eq i32 %17608, %17726
  %17728 = or i1 %17725, %17727
  %17729 = load i32, i32* %45, align 4
  %17730 = icmp eq i32 %17608, %17729
  %17731 = or i1 %17728, %17730
  %17732 = load i32, i32* %46, align 4
  %17733 = icmp eq i32 %17608, %17732
  %17734 = or i1 %17731, %17733
  %17735 = load i32, i32* %47, align 4
  %17736 = icmp eq i32 %17608, %17735
  %17737 = or i1 %17734, %17736
  %17738 = load i32, i32* %48, align 4
  %17739 = icmp eq i32 %17608, %17738
  %17740 = or i1 %17737, %17739
  %17741 = load i32, i32* %49, align 4
  %17742 = icmp eq i32 %17608, %17741
  %17743 = or i1 %17740, %17742
  %17744 = load i32, i32* %50, align 4
  %17745 = icmp eq i32 %17608, %17744
  %17746 = or i1 %17743, %17745
  %17747 = load i32, i32* %51, align 4
  %17748 = icmp eq i32 %17608, %17747
  %17749 = or i1 %17746, %17748
  %17750 = load i32, i32* %52, align 4
  %17751 = icmp eq i32 %17608, %17750
  %17752 = or i1 %17749, %17751
  %17753 = load i32, i32* %53, align 4
  %17754 = icmp eq i32 %17608, %17753
  %17755 = or i1 %17752, %17754
  %17756 = load i32, i32* %54, align 4
  %17757 = icmp eq i32 %17608, %17756
  %17758 = or i1 %17755, %17757
  %17759 = load i32, i32* %55, align 4
  %17760 = icmp eq i32 %17608, %17759
  %17761 = or i1 %17758, %17760
  %17762 = load i32, i32* %56, align 4
  %17763 = icmp eq i32 %17608, %17762
  %17764 = or i1 %17761, %17763
  %17765 = load i32, i32* %57, align 4
  %17766 = icmp eq i32 %17608, %17765
  %17767 = or i1 %17764, %17766
  %17768 = load i32, i32* %58, align 4
  %17769 = icmp eq i32 %17608, %17768
  %17770 = or i1 %17767, %17769
  %17771 = load i32, i32* %59, align 4
  %17772 = icmp eq i32 %17608, %17771
  %17773 = or i1 %17770, %17772
  %17774 = load i32, i32* %60, align 4
  %17775 = icmp eq i32 %17608, %17774
  %17776 = or i1 %17773, %17775
  %17777 = load i32, i32* %61, align 4
  %17778 = icmp eq i32 %17608, %17777
  %17779 = or i1 %17776, %17778
  %17780 = load i32, i32* %62, align 4
  %17781 = icmp eq i32 %17608, %17780
  %17782 = or i1 %17779, %17781
  %17783 = getelementptr i8, i8 addrspace(1)* %4, i32 56
  %17784 = zext i1 %17782 to i8
  store i8 %17784, i8 addrspace(1)* %17783, align 1, !nosanitize !3
  %17785 = load i256, i256* %17607, align 4
  %17786 = alloca i256, align 8
  store i256 %17785, i256* %17786, align 4
  %17787 = alloca i256, align 8
  store i256 1, i256* %17787, align 4
  %17788 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %17786, i256* %17787, i256* %17788), !pc !322, !intsan !6
  %17789 = load i256, i256* %17788, align 4
  %17790 = and i256 1461501637330902918203684832716283019655932542975, %17789
  %17791 = and i256 1461501637330902918203684832716283019655932542975, %17790
  %17792 = and i256 1461501637330902918203684832716283019655932542975, %17791
  %17793 = trunc i256 %17600 to i64
  %17794 = alloca i256, align 8
  store i256 %17792, i256* %17794, align 4
  %17795 = bitcast i256* %17794 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17793, i8* %17795, i64 32)
  %17796 = add i256 32, %17600, !pc !323, !intsan !10
  %17797 = add i256 %17597, 1, !pc !324, !intsan !10
  %17798 = alloca i256, align 8
  store i256 %17797, i256* %17798, align 4
  %17799 = alloca i256, align 8
  call void @__device_sload(i256* %17798, i256* %17799)
  %17800 = call i32 @__hashword(i256* %17798)
  %17801 = load i32, i32* %5, align 4
  %17802 = icmp eq i32 %17800, %17801
  %17803 = or i1 false, %17802
  %17804 = load i32, i32* %6, align 4
  %17805 = icmp eq i32 %17800, %17804
  %17806 = or i1 %17803, %17805
  %17807 = load i32, i32* %7, align 4
  %17808 = icmp eq i32 %17800, %17807
  %17809 = or i1 %17806, %17808
  %17810 = load i32, i32* %8, align 4
  %17811 = icmp eq i32 %17800, %17810
  %17812 = or i1 %17809, %17811
  %17813 = load i32, i32* %9, align 4
  %17814 = icmp eq i32 %17800, %17813
  %17815 = or i1 %17812, %17814
  %17816 = load i32, i32* %10, align 4
  %17817 = icmp eq i32 %17800, %17816
  %17818 = or i1 %17815, %17817
  %17819 = load i32, i32* %11, align 4
  %17820 = icmp eq i32 %17800, %17819
  %17821 = or i1 %17818, %17820
  %17822 = load i32, i32* %12, align 4
  %17823 = icmp eq i32 %17800, %17822
  %17824 = or i1 %17821, %17823
  %17825 = load i32, i32* %13, align 4
  %17826 = icmp eq i32 %17800, %17825
  %17827 = or i1 %17824, %17826
  %17828 = load i32, i32* %14, align 4
  %17829 = icmp eq i32 %17800, %17828
  %17830 = or i1 %17827, %17829
  %17831 = load i32, i32* %15, align 4
  %17832 = icmp eq i32 %17800, %17831
  %17833 = or i1 %17830, %17832
  %17834 = load i32, i32* %16, align 4
  %17835 = icmp eq i32 %17800, %17834
  %17836 = or i1 %17833, %17835
  %17837 = load i32, i32* %17, align 4
  %17838 = icmp eq i32 %17800, %17837
  %17839 = or i1 %17836, %17838
  %17840 = load i32, i32* %18, align 4
  %17841 = icmp eq i32 %17800, %17840
  %17842 = or i1 %17839, %17841
  %17843 = load i32, i32* %19, align 4
  %17844 = icmp eq i32 %17800, %17843
  %17845 = or i1 %17842, %17844
  %17846 = load i32, i32* %20, align 4
  %17847 = icmp eq i32 %17800, %17846
  %17848 = or i1 %17845, %17847
  %17849 = load i32, i32* %21, align 4
  %17850 = icmp eq i32 %17800, %17849
  %17851 = or i1 %17848, %17850
  %17852 = load i32, i32* %22, align 4
  %17853 = icmp eq i32 %17800, %17852
  %17854 = or i1 %17851, %17853
  %17855 = load i32, i32* %23, align 4
  %17856 = icmp eq i32 %17800, %17855
  %17857 = or i1 %17854, %17856
  %17858 = load i32, i32* %24, align 4
  %17859 = icmp eq i32 %17800, %17858
  %17860 = or i1 %17857, %17859
  %17861 = load i32, i32* %25, align 4
  %17862 = icmp eq i32 %17800, %17861
  %17863 = or i1 %17860, %17862
  %17864 = load i32, i32* %26, align 4
  %17865 = icmp eq i32 %17800, %17864
  %17866 = or i1 %17863, %17865
  %17867 = load i32, i32* %27, align 4
  %17868 = icmp eq i32 %17800, %17867
  %17869 = or i1 %17866, %17868
  %17870 = load i32, i32* %28, align 4
  %17871 = icmp eq i32 %17800, %17870
  %17872 = or i1 %17869, %17871
  %17873 = load i32, i32* %29, align 4
  %17874 = icmp eq i32 %17800, %17873
  %17875 = or i1 %17872, %17874
  %17876 = load i32, i32* %30, align 4
  %17877 = icmp eq i32 %17800, %17876
  %17878 = or i1 %17875, %17877
  %17879 = load i32, i32* %31, align 4
  %17880 = icmp eq i32 %17800, %17879
  %17881 = or i1 %17878, %17880
  %17882 = load i32, i32* %32, align 4
  %17883 = icmp eq i32 %17800, %17882
  %17884 = or i1 %17881, %17883
  %17885 = load i32, i32* %33, align 4
  %17886 = icmp eq i32 %17800, %17885
  %17887 = or i1 %17884, %17886
  %17888 = load i32, i32* %34, align 4
  %17889 = icmp eq i32 %17800, %17888
  %17890 = or i1 %17887, %17889
  %17891 = load i32, i32* %35, align 4
  %17892 = icmp eq i32 %17800, %17891
  %17893 = or i1 %17890, %17892
  %17894 = load i32, i32* %36, align 4
  %17895 = icmp eq i32 %17800, %17894
  %17896 = or i1 %17893, %17895
  %17897 = load i32, i32* %37, align 4
  %17898 = icmp eq i32 %17800, %17897
  %17899 = or i1 %17896, %17898
  %17900 = load i32, i32* %38, align 4
  %17901 = icmp eq i32 %17800, %17900
  %17902 = or i1 %17899, %17901
  %17903 = load i32, i32* %39, align 4
  %17904 = icmp eq i32 %17800, %17903
  %17905 = or i1 %17902, %17904
  %17906 = load i32, i32* %40, align 4
  %17907 = icmp eq i32 %17800, %17906
  %17908 = or i1 %17905, %17907
  %17909 = load i32, i32* %41, align 4
  %17910 = icmp eq i32 %17800, %17909
  %17911 = or i1 %17908, %17910
  %17912 = load i32, i32* %42, align 4
  %17913 = icmp eq i32 %17800, %17912
  %17914 = or i1 %17911, %17913
  %17915 = load i32, i32* %43, align 4
  %17916 = icmp eq i32 %17800, %17915
  %17917 = or i1 %17914, %17916
  %17918 = load i32, i32* %44, align 4
  %17919 = icmp eq i32 %17800, %17918
  %17920 = or i1 %17917, %17919
  %17921 = load i32, i32* %45, align 4
  %17922 = icmp eq i32 %17800, %17921
  %17923 = or i1 %17920, %17922
  %17924 = load i32, i32* %46, align 4
  %17925 = icmp eq i32 %17800, %17924
  %17926 = or i1 %17923, %17925
  %17927 = load i32, i32* %47, align 4
  %17928 = icmp eq i32 %17800, %17927
  %17929 = or i1 %17926, %17928
  %17930 = load i32, i32* %48, align 4
  %17931 = icmp eq i32 %17800, %17930
  %17932 = or i1 %17929, %17931
  %17933 = load i32, i32* %49, align 4
  %17934 = icmp eq i32 %17800, %17933
  %17935 = or i1 %17932, %17934
  %17936 = load i32, i32* %50, align 4
  %17937 = icmp eq i32 %17800, %17936
  %17938 = or i1 %17935, %17937
  %17939 = load i32, i32* %51, align 4
  %17940 = icmp eq i32 %17800, %17939
  %17941 = or i1 %17938, %17940
  %17942 = load i32, i32* %52, align 4
  %17943 = icmp eq i32 %17800, %17942
  %17944 = or i1 %17941, %17943
  %17945 = load i32, i32* %53, align 4
  %17946 = icmp eq i32 %17800, %17945
  %17947 = or i1 %17944, %17946
  %17948 = load i32, i32* %54, align 4
  %17949 = icmp eq i32 %17800, %17948
  %17950 = or i1 %17947, %17949
  %17951 = load i32, i32* %55, align 4
  %17952 = icmp eq i32 %17800, %17951
  %17953 = or i1 %17950, %17952
  %17954 = load i32, i32* %56, align 4
  %17955 = icmp eq i32 %17800, %17954
  %17956 = or i1 %17953, %17955
  %17957 = load i32, i32* %57, align 4
  %17958 = icmp eq i32 %17800, %17957
  %17959 = or i1 %17956, %17958
  %17960 = load i32, i32* %58, align 4
  %17961 = icmp eq i32 %17800, %17960
  %17962 = or i1 %17959, %17961
  %17963 = load i32, i32* %59, align 4
  %17964 = icmp eq i32 %17800, %17963
  %17965 = or i1 %17962, %17964
  %17966 = load i32, i32* %60, align 4
  %17967 = icmp eq i32 %17800, %17966
  %17968 = or i1 %17965, %17967
  %17969 = load i32, i32* %61, align 4
  %17970 = icmp eq i32 %17800, %17969
  %17971 = or i1 %17968, %17970
  %17972 = load i32, i32* %62, align 4
  %17973 = icmp eq i32 %17800, %17972
  %17974 = or i1 %17971, %17973
  %17975 = getelementptr i8, i8 addrspace(1)* %4, i32 57
  %17976 = zext i1 %17974 to i8
  store i8 %17976, i8 addrspace(1)* %17975, align 1, !nosanitize !3
  %17977 = load i256, i256* %17799, align 4
  %17978 = trunc i256 %17796 to i64
  %17979 = alloca i256, align 8
  store i256 %17977, i256* %17979, align 4
  %17980 = bitcast i256* %17979 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %17978, i8* %17980, i64 32)
  %17981 = add i256 32, %17796, !pc !325, !intsan !10
  %17982 = add i256 %17597, 2, !pc !326, !intsan !10
  %17983 = alloca i256, align 8
  store i256 %17982, i256* %17983, align 4
  %17984 = alloca i256, align 8
  call void @__device_sload(i256* %17983, i256* %17984)
  %17985 = call i32 @__hashword(i256* %17983)
  %17986 = load i32, i32* %5, align 4
  %17987 = icmp eq i32 %17985, %17986
  %17988 = or i1 false, %17987
  %17989 = load i32, i32* %6, align 4
  %17990 = icmp eq i32 %17985, %17989
  %17991 = or i1 %17988, %17990
  %17992 = load i32, i32* %7, align 4
  %17993 = icmp eq i32 %17985, %17992
  %17994 = or i1 %17991, %17993
  %17995 = load i32, i32* %8, align 4
  %17996 = icmp eq i32 %17985, %17995
  %17997 = or i1 %17994, %17996
  %17998 = load i32, i32* %9, align 4
  %17999 = icmp eq i32 %17985, %17998
  %18000 = or i1 %17997, %17999
  %18001 = load i32, i32* %10, align 4
  %18002 = icmp eq i32 %17985, %18001
  %18003 = or i1 %18000, %18002
  %18004 = load i32, i32* %11, align 4
  %18005 = icmp eq i32 %17985, %18004
  %18006 = or i1 %18003, %18005
  %18007 = load i32, i32* %12, align 4
  %18008 = icmp eq i32 %17985, %18007
  %18009 = or i1 %18006, %18008
  %18010 = load i32, i32* %13, align 4
  %18011 = icmp eq i32 %17985, %18010
  %18012 = or i1 %18009, %18011
  %18013 = load i32, i32* %14, align 4
  %18014 = icmp eq i32 %17985, %18013
  %18015 = or i1 %18012, %18014
  %18016 = load i32, i32* %15, align 4
  %18017 = icmp eq i32 %17985, %18016
  %18018 = or i1 %18015, %18017
  %18019 = load i32, i32* %16, align 4
  %18020 = icmp eq i32 %17985, %18019
  %18021 = or i1 %18018, %18020
  %18022 = load i32, i32* %17, align 4
  %18023 = icmp eq i32 %17985, %18022
  %18024 = or i1 %18021, %18023
  %18025 = load i32, i32* %18, align 4
  %18026 = icmp eq i32 %17985, %18025
  %18027 = or i1 %18024, %18026
  %18028 = load i32, i32* %19, align 4
  %18029 = icmp eq i32 %17985, %18028
  %18030 = or i1 %18027, %18029
  %18031 = load i32, i32* %20, align 4
  %18032 = icmp eq i32 %17985, %18031
  %18033 = or i1 %18030, %18032
  %18034 = load i32, i32* %21, align 4
  %18035 = icmp eq i32 %17985, %18034
  %18036 = or i1 %18033, %18035
  %18037 = load i32, i32* %22, align 4
  %18038 = icmp eq i32 %17985, %18037
  %18039 = or i1 %18036, %18038
  %18040 = load i32, i32* %23, align 4
  %18041 = icmp eq i32 %17985, %18040
  %18042 = or i1 %18039, %18041
  %18043 = load i32, i32* %24, align 4
  %18044 = icmp eq i32 %17985, %18043
  %18045 = or i1 %18042, %18044
  %18046 = load i32, i32* %25, align 4
  %18047 = icmp eq i32 %17985, %18046
  %18048 = or i1 %18045, %18047
  %18049 = load i32, i32* %26, align 4
  %18050 = icmp eq i32 %17985, %18049
  %18051 = or i1 %18048, %18050
  %18052 = load i32, i32* %27, align 4
  %18053 = icmp eq i32 %17985, %18052
  %18054 = or i1 %18051, %18053
  %18055 = load i32, i32* %28, align 4
  %18056 = icmp eq i32 %17985, %18055
  %18057 = or i1 %18054, %18056
  %18058 = load i32, i32* %29, align 4
  %18059 = icmp eq i32 %17985, %18058
  %18060 = or i1 %18057, %18059
  %18061 = load i32, i32* %30, align 4
  %18062 = icmp eq i32 %17985, %18061
  %18063 = or i1 %18060, %18062
  %18064 = load i32, i32* %31, align 4
  %18065 = icmp eq i32 %17985, %18064
  %18066 = or i1 %18063, %18065
  %18067 = load i32, i32* %32, align 4
  %18068 = icmp eq i32 %17985, %18067
  %18069 = or i1 %18066, %18068
  %18070 = load i32, i32* %33, align 4
  %18071 = icmp eq i32 %17985, %18070
  %18072 = or i1 %18069, %18071
  %18073 = load i32, i32* %34, align 4
  %18074 = icmp eq i32 %17985, %18073
  %18075 = or i1 %18072, %18074
  %18076 = load i32, i32* %35, align 4
  %18077 = icmp eq i32 %17985, %18076
  %18078 = or i1 %18075, %18077
  %18079 = load i32, i32* %36, align 4
  %18080 = icmp eq i32 %17985, %18079
  %18081 = or i1 %18078, %18080
  %18082 = load i32, i32* %37, align 4
  %18083 = icmp eq i32 %17985, %18082
  %18084 = or i1 %18081, %18083
  %18085 = load i32, i32* %38, align 4
  %18086 = icmp eq i32 %17985, %18085
  %18087 = or i1 %18084, %18086
  %18088 = load i32, i32* %39, align 4
  %18089 = icmp eq i32 %17985, %18088
  %18090 = or i1 %18087, %18089
  %18091 = load i32, i32* %40, align 4
  %18092 = icmp eq i32 %17985, %18091
  %18093 = or i1 %18090, %18092
  %18094 = load i32, i32* %41, align 4
  %18095 = icmp eq i32 %17985, %18094
  %18096 = or i1 %18093, %18095
  %18097 = load i32, i32* %42, align 4
  %18098 = icmp eq i32 %17985, %18097
  %18099 = or i1 %18096, %18098
  %18100 = load i32, i32* %43, align 4
  %18101 = icmp eq i32 %17985, %18100
  %18102 = or i1 %18099, %18101
  %18103 = load i32, i32* %44, align 4
  %18104 = icmp eq i32 %17985, %18103
  %18105 = or i1 %18102, %18104
  %18106 = load i32, i32* %45, align 4
  %18107 = icmp eq i32 %17985, %18106
  %18108 = or i1 %18105, %18107
  %18109 = load i32, i32* %46, align 4
  %18110 = icmp eq i32 %17985, %18109
  %18111 = or i1 %18108, %18110
  %18112 = load i32, i32* %47, align 4
  %18113 = icmp eq i32 %17985, %18112
  %18114 = or i1 %18111, %18113
  %18115 = load i32, i32* %48, align 4
  %18116 = icmp eq i32 %17985, %18115
  %18117 = or i1 %18114, %18116
  %18118 = load i32, i32* %49, align 4
  %18119 = icmp eq i32 %17985, %18118
  %18120 = or i1 %18117, %18119
  %18121 = load i32, i32* %50, align 4
  %18122 = icmp eq i32 %17985, %18121
  %18123 = or i1 %18120, %18122
  %18124 = load i32, i32* %51, align 4
  %18125 = icmp eq i32 %17985, %18124
  %18126 = or i1 %18123, %18125
  %18127 = load i32, i32* %52, align 4
  %18128 = icmp eq i32 %17985, %18127
  %18129 = or i1 %18126, %18128
  %18130 = load i32, i32* %53, align 4
  %18131 = icmp eq i32 %17985, %18130
  %18132 = or i1 %18129, %18131
  %18133 = load i32, i32* %54, align 4
  %18134 = icmp eq i32 %17985, %18133
  %18135 = or i1 %18132, %18134
  %18136 = load i32, i32* %55, align 4
  %18137 = icmp eq i32 %17985, %18136
  %18138 = or i1 %18135, %18137
  %18139 = load i32, i32* %56, align 4
  %18140 = icmp eq i32 %17985, %18139
  %18141 = or i1 %18138, %18140
  %18142 = load i32, i32* %57, align 4
  %18143 = icmp eq i32 %17985, %18142
  %18144 = or i1 %18141, %18143
  %18145 = load i32, i32* %58, align 4
  %18146 = icmp eq i32 %17985, %18145
  %18147 = or i1 %18144, %18146
  %18148 = load i32, i32* %59, align 4
  %18149 = icmp eq i32 %17985, %18148
  %18150 = or i1 %18147, %18149
  %18151 = load i32, i32* %60, align 4
  %18152 = icmp eq i32 %17985, %18151
  %18153 = or i1 %18150, %18152
  %18154 = load i32, i32* %61, align 4
  %18155 = icmp eq i32 %17985, %18154
  %18156 = or i1 %18153, %18155
  %18157 = load i32, i32* %62, align 4
  %18158 = icmp eq i32 %17985, %18157
  %18159 = or i1 %18156, %18158
  %18160 = getelementptr i8, i8 addrspace(1)* %4, i32 58
  %18161 = zext i1 %18159 to i8
  store i8 %18161, i8 addrspace(1)* %18160, align 1, !nosanitize !3
  %18162 = load i256, i256* %17984, align 4
  %18163 = trunc i256 %17981 to i64
  %18164 = alloca i256, align 8
  store i256 %18162, i256* %18164, align 4
  %18165 = bitcast i256* %18164 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18163, i8* %18165, i64 32)
  %18166 = trunc i256 15556 to i64
  %18167 = load i64, i64* %STACK_DEP_PTR, align 4
  %18168 = add i64 %18167, 1
  store i64 %18168, i64* %STACK_DEP_PTR, align 4
  %18169 = load i64, i64* %STACK_DEP_PTR, align 4
  %18170 = getelementptr i256, i256* %STACK, i64 %18169
  store i256 %17577, i256* %18170, align 4
  %18171 = load i64, i64* %STACK_DEP_PTR, align 4
  %18172 = add i64 %18171, 1
  store i64 %18172, i64* %STACK_DEP_PTR, align 4
  %18173 = load i64, i64* %STACK_DEP_PTR, align 4
  %18174 = getelementptr i256, i256* %STACK, i64 %18173
  store i256 %17572, i256* %18174, align 4
  %18175 = load i64, i64* %STACK_DEP_PTR, align 4
  %18176 = add i64 %18175, 1
  store i64 %18176, i64* %STACK_DEP_PTR, align 4
  %18177 = load i64, i64* %STACK_DEP_PTR, align 4
  %18178 = getelementptr i256, i256* %STACK, i64 %18177
  store i256 %17567, i256* %18178, align 4
  %18179 = load i64, i64* %STACK_DEP_PTR, align 4
  %18180 = add i64 %18179, 1
  store i64 %18180, i64* %STACK_DEP_PTR, align 4
  %18181 = load i64, i64* %STACK_DEP_PTR, align 4
  %18182 = getelementptr i256, i256* %STACK, i64 %18181
  store i256 %17562, i256* %18182, align 4
  %18183 = load i64, i64* %STACK_DEP_PTR, align 4
  %18184 = add i64 %18183, 1
  store i64 %18184, i64* %STACK_DEP_PTR, align 4
  %18185 = load i64, i64* %STACK_DEP_PTR, align 4
  %18186 = getelementptr i256, i256* %STACK, i64 %18185
  store i256 %17557, i256* %18186, align 4
  %18187 = load i64, i64* %STACK_DEP_PTR, align 4
  %18188 = add i64 %18187, 1
  store i64 %18188, i64* %STACK_DEP_PTR, align 4
  %18189 = load i64, i64* %STACK_DEP_PTR, align 4
  %18190 = getelementptr i256, i256* %STACK, i64 %18189
  store i256 %17552, i256* %18190, align 4
  %18191 = load i64, i64* %STACK_DEP_PTR, align 4
  %18192 = add i64 %18191, 1
  store i64 %18192, i64* %STACK_DEP_PTR, align 4
  %18193 = load i64, i64* %STACK_DEP_PTR, align 4
  %18194 = getelementptr i256, i256* %STACK, i64 %18193
  store i256 %17547, i256* %18194, align 4
  %18195 = load i64, i64* %STACK_DEP_PTR, align 4
  %18196 = add i64 %18195, 1
  store i64 %18196, i64* %STACK_DEP_PTR, align 4
  %18197 = load i64, i64* %STACK_DEP_PTR, align 4
  %18198 = getelementptr i256, i256* %STACK, i64 %18197
  store i256 %17542, i256* %18198, align 4
  %18199 = load i64, i64* %STACK_DEP_PTR, align 4
  %18200 = add i64 %18199, 1
  store i64 %18200, i64* %STACK_DEP_PTR, align 4
  %18201 = load i64, i64* %STACK_DEP_PTR, align 4
  %18202 = getelementptr i256, i256* %STACK, i64 %18201
  store i256 %17537, i256* %18202, align 4
  %18203 = load i64, i64* %STACK_DEP_PTR, align 4
  %18204 = add i64 %18203, 1
  store i64 %18204, i64* %STACK_DEP_PTR, align 4
  %18205 = load i64, i64* %STACK_DEP_PTR, align 4
  %18206 = getelementptr i256, i256* %STACK, i64 %18205
  store i256 %17532, i256* %18206, align 4
  %18207 = load i64, i64* %STACK_DEP_PTR, align 4
  %18208 = add i64 %18207, 1
  store i64 %18208, i64* %STACK_DEP_PTR, align 4
  %18209 = load i64, i64* %STACK_DEP_PTR, align 4
  %18210 = getelementptr i256, i256* %STACK, i64 %18209
  store i256 6848, i256* %18210, align 4
  %18211 = load i64, i64* %STACK_DEP_PTR, align 4
  %18212 = add i64 %18211, 1
  store i64 %18212, i64* %STACK_DEP_PTR, align 4
  %18213 = load i64, i64* %STACK_DEP_PTR, align 4
  %18214 = getelementptr i256, i256* %STACK, i64 %18213
  store i256 %17600, i256* %18214, align 4
  %18215 = load i64, i64* %STACK_DEP_PTR, align 4
  %18216 = add i64 %18215, 1
  store i64 %18216, i64* %STACK_DEP_PTR, align 4
  %18217 = load i64, i64* %STACK_DEP_PTR, align 4
  %18218 = getelementptr i256, i256* %STACK, i64 %18217
  store i256 %17562, i256* %18218, align 4
  br label %.15556, !EVMBB !4

.6848:                                            ; preds = %JumpTable
  %18219 = load i64, i64* %remaing_gas, align 4
  %18220 = icmp ugt i64 128, %18219
  br i1 %18220, label %Abort, label %18221

18221:                                            ; preds = %.6848
  %18222 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18223 = xor i32 %18222, 3634
  %18224 = urem i32 %18223, 4096
  %18225 = getelementptr i8, i8 addrspace(1)* %4, i32 %18224
  %18226 = load i8, i8 addrspace(1)* %18225, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %18225, align 1, !nosanitize !3
  store i32 1817, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18227 = sub i64 %18219, 128
  store i64 %18227, i64* %remaing_gas, align 4
  %18228 = alloca i256, align 8
  store i256 15, i256* %18228, align 4
  %18229 = alloca i256, align 8
  call void @__device_sload(i256* %18228, i256* %18229)
  %18230 = call i32 @__hashword(i256* %18228)
  %18231 = load i32, i32* %5, align 4
  %18232 = icmp eq i32 %18230, %18231
  %18233 = or i1 false, %18232
  %18234 = load i32, i32* %6, align 4
  %18235 = icmp eq i32 %18230, %18234
  %18236 = or i1 %18233, %18235
  %18237 = load i32, i32* %7, align 4
  %18238 = icmp eq i32 %18230, %18237
  %18239 = or i1 %18236, %18238
  %18240 = load i32, i32* %8, align 4
  %18241 = icmp eq i32 %18230, %18240
  %18242 = or i1 %18239, %18241
  %18243 = load i32, i32* %9, align 4
  %18244 = icmp eq i32 %18230, %18243
  %18245 = or i1 %18242, %18244
  %18246 = load i32, i32* %10, align 4
  %18247 = icmp eq i32 %18230, %18246
  %18248 = or i1 %18245, %18247
  %18249 = load i32, i32* %11, align 4
  %18250 = icmp eq i32 %18230, %18249
  %18251 = or i1 %18248, %18250
  %18252 = load i32, i32* %12, align 4
  %18253 = icmp eq i32 %18230, %18252
  %18254 = or i1 %18251, %18253
  %18255 = load i32, i32* %13, align 4
  %18256 = icmp eq i32 %18230, %18255
  %18257 = or i1 %18254, %18256
  %18258 = load i32, i32* %14, align 4
  %18259 = icmp eq i32 %18230, %18258
  %18260 = or i1 %18257, %18259
  %18261 = load i32, i32* %15, align 4
  %18262 = icmp eq i32 %18230, %18261
  %18263 = or i1 %18260, %18262
  %18264 = load i32, i32* %16, align 4
  %18265 = icmp eq i32 %18230, %18264
  %18266 = or i1 %18263, %18265
  %18267 = load i32, i32* %17, align 4
  %18268 = icmp eq i32 %18230, %18267
  %18269 = or i1 %18266, %18268
  %18270 = load i32, i32* %18, align 4
  %18271 = icmp eq i32 %18230, %18270
  %18272 = or i1 %18269, %18271
  %18273 = load i32, i32* %19, align 4
  %18274 = icmp eq i32 %18230, %18273
  %18275 = or i1 %18272, %18274
  %18276 = load i32, i32* %20, align 4
  %18277 = icmp eq i32 %18230, %18276
  %18278 = or i1 %18275, %18277
  %18279 = load i32, i32* %21, align 4
  %18280 = icmp eq i32 %18230, %18279
  %18281 = or i1 %18278, %18280
  %18282 = load i32, i32* %22, align 4
  %18283 = icmp eq i32 %18230, %18282
  %18284 = or i1 %18281, %18283
  %18285 = load i32, i32* %23, align 4
  %18286 = icmp eq i32 %18230, %18285
  %18287 = or i1 %18284, %18286
  %18288 = load i32, i32* %24, align 4
  %18289 = icmp eq i32 %18230, %18288
  %18290 = or i1 %18287, %18289
  %18291 = load i32, i32* %25, align 4
  %18292 = icmp eq i32 %18230, %18291
  %18293 = or i1 %18290, %18292
  %18294 = load i32, i32* %26, align 4
  %18295 = icmp eq i32 %18230, %18294
  %18296 = or i1 %18293, %18295
  %18297 = load i32, i32* %27, align 4
  %18298 = icmp eq i32 %18230, %18297
  %18299 = or i1 %18296, %18298
  %18300 = load i32, i32* %28, align 4
  %18301 = icmp eq i32 %18230, %18300
  %18302 = or i1 %18299, %18301
  %18303 = load i32, i32* %29, align 4
  %18304 = icmp eq i32 %18230, %18303
  %18305 = or i1 %18302, %18304
  %18306 = load i32, i32* %30, align 4
  %18307 = icmp eq i32 %18230, %18306
  %18308 = or i1 %18305, %18307
  %18309 = load i32, i32* %31, align 4
  %18310 = icmp eq i32 %18230, %18309
  %18311 = or i1 %18308, %18310
  %18312 = load i32, i32* %32, align 4
  %18313 = icmp eq i32 %18230, %18312
  %18314 = or i1 %18311, %18313
  %18315 = load i32, i32* %33, align 4
  %18316 = icmp eq i32 %18230, %18315
  %18317 = or i1 %18314, %18316
  %18318 = load i32, i32* %34, align 4
  %18319 = icmp eq i32 %18230, %18318
  %18320 = or i1 %18317, %18319
  %18321 = load i32, i32* %35, align 4
  %18322 = icmp eq i32 %18230, %18321
  %18323 = or i1 %18320, %18322
  %18324 = load i32, i32* %36, align 4
  %18325 = icmp eq i32 %18230, %18324
  %18326 = or i1 %18323, %18325
  %18327 = load i32, i32* %37, align 4
  %18328 = icmp eq i32 %18230, %18327
  %18329 = or i1 %18326, %18328
  %18330 = load i32, i32* %38, align 4
  %18331 = icmp eq i32 %18230, %18330
  %18332 = or i1 %18329, %18331
  %18333 = load i32, i32* %39, align 4
  %18334 = icmp eq i32 %18230, %18333
  %18335 = or i1 %18332, %18334
  %18336 = load i32, i32* %40, align 4
  %18337 = icmp eq i32 %18230, %18336
  %18338 = or i1 %18335, %18337
  %18339 = load i32, i32* %41, align 4
  %18340 = icmp eq i32 %18230, %18339
  %18341 = or i1 %18338, %18340
  %18342 = load i32, i32* %42, align 4
  %18343 = icmp eq i32 %18230, %18342
  %18344 = or i1 %18341, %18343
  %18345 = load i32, i32* %43, align 4
  %18346 = icmp eq i32 %18230, %18345
  %18347 = or i1 %18344, %18346
  %18348 = load i32, i32* %44, align 4
  %18349 = icmp eq i32 %18230, %18348
  %18350 = or i1 %18347, %18349
  %18351 = load i32, i32* %45, align 4
  %18352 = icmp eq i32 %18230, %18351
  %18353 = or i1 %18350, %18352
  %18354 = load i32, i32* %46, align 4
  %18355 = icmp eq i32 %18230, %18354
  %18356 = or i1 %18353, %18355
  %18357 = load i32, i32* %47, align 4
  %18358 = icmp eq i32 %18230, %18357
  %18359 = or i1 %18356, %18358
  %18360 = load i32, i32* %48, align 4
  %18361 = icmp eq i32 %18230, %18360
  %18362 = or i1 %18359, %18361
  %18363 = load i32, i32* %49, align 4
  %18364 = icmp eq i32 %18230, %18363
  %18365 = or i1 %18362, %18364
  %18366 = load i32, i32* %50, align 4
  %18367 = icmp eq i32 %18230, %18366
  %18368 = or i1 %18365, %18367
  %18369 = load i32, i32* %51, align 4
  %18370 = icmp eq i32 %18230, %18369
  %18371 = or i1 %18368, %18370
  %18372 = load i32, i32* %52, align 4
  %18373 = icmp eq i32 %18230, %18372
  %18374 = or i1 %18371, %18373
  %18375 = load i32, i32* %53, align 4
  %18376 = icmp eq i32 %18230, %18375
  %18377 = or i1 %18374, %18376
  %18378 = load i32, i32* %54, align 4
  %18379 = icmp eq i32 %18230, %18378
  %18380 = or i1 %18377, %18379
  %18381 = load i32, i32* %55, align 4
  %18382 = icmp eq i32 %18230, %18381
  %18383 = or i1 %18380, %18382
  %18384 = load i32, i32* %56, align 4
  %18385 = icmp eq i32 %18230, %18384
  %18386 = or i1 %18383, %18385
  %18387 = load i32, i32* %57, align 4
  %18388 = icmp eq i32 %18230, %18387
  %18389 = or i1 %18386, %18388
  %18390 = load i32, i32* %58, align 4
  %18391 = icmp eq i32 %18230, %18390
  %18392 = or i1 %18389, %18391
  %18393 = load i32, i32* %59, align 4
  %18394 = icmp eq i32 %18230, %18393
  %18395 = or i1 %18392, %18394
  %18396 = load i32, i32* %60, align 4
  %18397 = icmp eq i32 %18230, %18396
  %18398 = or i1 %18395, %18397
  %18399 = load i32, i32* %61, align 4
  %18400 = icmp eq i32 %18230, %18399
  %18401 = or i1 %18398, %18400
  %18402 = load i32, i32* %62, align 4
  %18403 = icmp eq i32 %18230, %18402
  %18404 = or i1 %18401, %18403
  %18405 = getelementptr i8, i8 addrspace(1)* %4, i32 59
  %18406 = zext i1 %18404 to i8
  store i8 %18406, i8 addrspace(1)* %18405, align 1, !nosanitize !3
  %18407 = load i256, i256* %18229, align 4
  %18408 = mul i256 255, 1, !pc !327, !intsan !45
  %18409 = xor i256 %18408, -1
  %18410 = and i256 %18409, %18407
  %18411 = alloca i256, align 8
  store i256 15, i256* %18411, align 4
  %18412 = alloca i256, align 8
  store i256 %18410, i256* %18412, align 4
  call void @__device_sstore(i256* %18411, i256* %18412)
  %18413 = call i32 @__hashword(i256* %18411)
  store i32 %18413, i32* %37, align 4, !nosanitize !3
  %18414 = trunc i256 7016 to i64
  br label %.7016, !EVMBB !4

.6871:                                            ; preds = %16683, %JumpTable
  %18415 = load i64, i64* %remaing_gas, align 4
  %18416 = icmp ugt i64 1024, %18415
  br i1 %18416, label %Abort, label %18417

18417:                                            ; preds = %.6871
  %18418 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18419 = xor i32 %18418, 3100
  %18420 = urem i32 %18419, 4096
  %18421 = getelementptr i8, i8 addrspace(1)* %4, i32 %18420
  %18422 = load i8, i8 addrspace(1)* %18421, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %18421, align 1, !nosanitize !3
  store i32 1550, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18423 = sub i64 %18415, 1024
  store i64 %18423, i64* %remaing_gas, align 4
  %18424 = load i64, i64* %STACK_DEP_PTR, align 4
  %18425 = getelementptr i256, i256* %STACK, i64 %18424
  %18426 = load i256, i256* %18425, align 4
  %18427 = load i64, i64* %STACK_DEP_PTR, align 4
  %18428 = sub i64 %18427, 1
  store i64 %18428, i64* %STACK_DEP_PTR, align 4
  %18429 = xor i256 0, -1
  %18430 = and i256 %18429, %18426
  %18431 = xor i256 0, -1
  %18432 = and i256 %18431, %18430
  %18433 = trunc i256 0 to i64
  %18434 = alloca i256, align 8
  store i256 %18432, i256* %18434, align 4
  %18435 = bitcast i256* %18434 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18433, i8* %18435, i64 32)
  %18436 = add i256 32, 0, !pc !328, !intsan !10
  %18437 = trunc i256 %18436 to i64
  %18438 = alloca i256, align 8
  store i256 11, i256* %18438, align 4
  %18439 = bitcast i256* %18438 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18437, i8* %18439, i64 32)
  %18440 = add i256 32, %18436, !pc !329, !intsan !10
  %18441 = trunc i256 0 to i32
  %18442 = trunc i256 %18440 to i32
  %18443 = getelementptr inbounds i8, i8* %MEMORY, i32 %18441
  %18444 = alloca i256, align 8
  %18445 = bitcast i256* %18444 to i8*
  call void @__device_sha3(i8* %18443, i32 %18442, i8* %18445)
  %18446 = load i256, i256* %18444, align 4
  %18447 = add i256 2, %18446, !pc !330, !intsan !10
  %18448 = alloca i256, align 8
  store i256 %18447, i256* %18448, align 4
  %18449 = alloca i256, align 8
  store i256 99999, i256* %18449, align 4
  call void @__device_sstore(i256* %18448, i256* %18449)
  %18450 = call i32 @__hashword(i256* %18448)
  store i32 %18450, i32* %38, align 4, !nosanitize !3
  %18451 = xor i256 0, -1
  %18452 = and i256 %18451, %18426
  %18453 = xor i256 0, -1
  %18454 = and i256 %18453, %18452
  %18455 = trunc i256 0 to i64
  %18456 = alloca i256, align 8
  store i256 %18454, i256* %18456, align 4
  %18457 = bitcast i256* %18456 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18455, i8* %18457, i64 32)
  %18458 = add i256 32, 0, !pc !331, !intsan !10
  %18459 = trunc i256 %18458 to i64
  %18460 = alloca i256, align 8
  store i256 11, i256* %18460, align 4
  %18461 = bitcast i256* %18460 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18459, i8* %18461, i64 32)
  %18462 = add i256 32, %18458, !pc !332, !intsan !10
  %18463 = trunc i256 0 to i32
  %18464 = trunc i256 %18462 to i32
  %18465 = getelementptr inbounds i8, i8* %MEMORY, i32 %18463
  %18466 = alloca i256, align 8
  %18467 = bitcast i256* %18466 to i8*
  call void @__device_sha3(i8* %18465, i32 %18464, i8* %18467)
  %18468 = load i256, i256* %18466, align 4
  %18469 = add i256 0, %18468, !pc !333, !intsan !10
  %18470 = alloca i256, align 8
  store i256 %18469, i256* %18470, align 4
  %18471 = alloca i256, align 8
  call void @__device_sload(i256* %18470, i256* %18471)
  %18472 = call i32 @__hashword(i256* %18470)
  %18473 = load i32, i32* %5, align 4
  %18474 = icmp eq i32 %18472, %18473
  %18475 = or i1 false, %18474
  %18476 = load i32, i32* %6, align 4
  %18477 = icmp eq i32 %18472, %18476
  %18478 = or i1 %18475, %18477
  %18479 = load i32, i32* %7, align 4
  %18480 = icmp eq i32 %18472, %18479
  %18481 = or i1 %18478, %18480
  %18482 = load i32, i32* %8, align 4
  %18483 = icmp eq i32 %18472, %18482
  %18484 = or i1 %18481, %18483
  %18485 = load i32, i32* %9, align 4
  %18486 = icmp eq i32 %18472, %18485
  %18487 = or i1 %18484, %18486
  %18488 = load i32, i32* %10, align 4
  %18489 = icmp eq i32 %18472, %18488
  %18490 = or i1 %18487, %18489
  %18491 = load i32, i32* %11, align 4
  %18492 = icmp eq i32 %18472, %18491
  %18493 = or i1 %18490, %18492
  %18494 = load i32, i32* %12, align 4
  %18495 = icmp eq i32 %18472, %18494
  %18496 = or i1 %18493, %18495
  %18497 = load i32, i32* %13, align 4
  %18498 = icmp eq i32 %18472, %18497
  %18499 = or i1 %18496, %18498
  %18500 = load i32, i32* %14, align 4
  %18501 = icmp eq i32 %18472, %18500
  %18502 = or i1 %18499, %18501
  %18503 = load i32, i32* %15, align 4
  %18504 = icmp eq i32 %18472, %18503
  %18505 = or i1 %18502, %18504
  %18506 = load i32, i32* %16, align 4
  %18507 = icmp eq i32 %18472, %18506
  %18508 = or i1 %18505, %18507
  %18509 = load i32, i32* %17, align 4
  %18510 = icmp eq i32 %18472, %18509
  %18511 = or i1 %18508, %18510
  %18512 = load i32, i32* %18, align 4
  %18513 = icmp eq i32 %18472, %18512
  %18514 = or i1 %18511, %18513
  %18515 = load i32, i32* %19, align 4
  %18516 = icmp eq i32 %18472, %18515
  %18517 = or i1 %18514, %18516
  %18518 = load i32, i32* %20, align 4
  %18519 = icmp eq i32 %18472, %18518
  %18520 = or i1 %18517, %18519
  %18521 = load i32, i32* %21, align 4
  %18522 = icmp eq i32 %18472, %18521
  %18523 = or i1 %18520, %18522
  %18524 = load i32, i32* %22, align 4
  %18525 = icmp eq i32 %18472, %18524
  %18526 = or i1 %18523, %18525
  %18527 = load i32, i32* %23, align 4
  %18528 = icmp eq i32 %18472, %18527
  %18529 = or i1 %18526, %18528
  %18530 = load i32, i32* %24, align 4
  %18531 = icmp eq i32 %18472, %18530
  %18532 = or i1 %18529, %18531
  %18533 = load i32, i32* %25, align 4
  %18534 = icmp eq i32 %18472, %18533
  %18535 = or i1 %18532, %18534
  %18536 = load i32, i32* %26, align 4
  %18537 = icmp eq i32 %18472, %18536
  %18538 = or i1 %18535, %18537
  %18539 = load i32, i32* %27, align 4
  %18540 = icmp eq i32 %18472, %18539
  %18541 = or i1 %18538, %18540
  %18542 = load i32, i32* %28, align 4
  %18543 = icmp eq i32 %18472, %18542
  %18544 = or i1 %18541, %18543
  %18545 = load i32, i32* %29, align 4
  %18546 = icmp eq i32 %18472, %18545
  %18547 = or i1 %18544, %18546
  %18548 = load i32, i32* %30, align 4
  %18549 = icmp eq i32 %18472, %18548
  %18550 = or i1 %18547, %18549
  %18551 = load i32, i32* %31, align 4
  %18552 = icmp eq i32 %18472, %18551
  %18553 = or i1 %18550, %18552
  %18554 = load i32, i32* %32, align 4
  %18555 = icmp eq i32 %18472, %18554
  %18556 = or i1 %18553, %18555
  %18557 = load i32, i32* %33, align 4
  %18558 = icmp eq i32 %18472, %18557
  %18559 = or i1 %18556, %18558
  %18560 = load i32, i32* %34, align 4
  %18561 = icmp eq i32 %18472, %18560
  %18562 = or i1 %18559, %18561
  %18563 = load i32, i32* %35, align 4
  %18564 = icmp eq i32 %18472, %18563
  %18565 = or i1 %18562, %18564
  %18566 = load i32, i32* %36, align 4
  %18567 = icmp eq i32 %18472, %18566
  %18568 = or i1 %18565, %18567
  %18569 = load i32, i32* %37, align 4
  %18570 = icmp eq i32 %18472, %18569
  %18571 = or i1 %18568, %18570
  %18572 = load i32, i32* %38, align 4
  %18573 = icmp eq i32 %18472, %18572
  %18574 = or i1 %18571, %18573
  %18575 = load i32, i32* %39, align 4
  %18576 = icmp eq i32 %18472, %18575
  %18577 = or i1 %18574, %18576
  %18578 = load i32, i32* %40, align 4
  %18579 = icmp eq i32 %18472, %18578
  %18580 = or i1 %18577, %18579
  %18581 = load i32, i32* %41, align 4
  %18582 = icmp eq i32 %18472, %18581
  %18583 = or i1 %18580, %18582
  %18584 = load i32, i32* %42, align 4
  %18585 = icmp eq i32 %18472, %18584
  %18586 = or i1 %18583, %18585
  %18587 = load i32, i32* %43, align 4
  %18588 = icmp eq i32 %18472, %18587
  %18589 = or i1 %18586, %18588
  %18590 = load i32, i32* %44, align 4
  %18591 = icmp eq i32 %18472, %18590
  %18592 = or i1 %18589, %18591
  %18593 = load i32, i32* %45, align 4
  %18594 = icmp eq i32 %18472, %18593
  %18595 = or i1 %18592, %18594
  %18596 = load i32, i32* %46, align 4
  %18597 = icmp eq i32 %18472, %18596
  %18598 = or i1 %18595, %18597
  %18599 = load i32, i32* %47, align 4
  %18600 = icmp eq i32 %18472, %18599
  %18601 = or i1 %18598, %18600
  %18602 = load i32, i32* %48, align 4
  %18603 = icmp eq i32 %18472, %18602
  %18604 = or i1 %18601, %18603
  %18605 = load i32, i32* %49, align 4
  %18606 = icmp eq i32 %18472, %18605
  %18607 = or i1 %18604, %18606
  %18608 = load i32, i32* %50, align 4
  %18609 = icmp eq i32 %18472, %18608
  %18610 = or i1 %18607, %18609
  %18611 = load i32, i32* %51, align 4
  %18612 = icmp eq i32 %18472, %18611
  %18613 = or i1 %18610, %18612
  %18614 = load i32, i32* %52, align 4
  %18615 = icmp eq i32 %18472, %18614
  %18616 = or i1 %18613, %18615
  %18617 = load i32, i32* %53, align 4
  %18618 = icmp eq i32 %18472, %18617
  %18619 = or i1 %18616, %18618
  %18620 = load i32, i32* %54, align 4
  %18621 = icmp eq i32 %18472, %18620
  %18622 = or i1 %18619, %18621
  %18623 = load i32, i32* %55, align 4
  %18624 = icmp eq i32 %18472, %18623
  %18625 = or i1 %18622, %18624
  %18626 = load i32, i32* %56, align 4
  %18627 = icmp eq i32 %18472, %18626
  %18628 = or i1 %18625, %18627
  %18629 = load i32, i32* %57, align 4
  %18630 = icmp eq i32 %18472, %18629
  %18631 = or i1 %18628, %18630
  %18632 = load i32, i32* %58, align 4
  %18633 = icmp eq i32 %18472, %18632
  %18634 = or i1 %18631, %18633
  %18635 = load i32, i32* %59, align 4
  %18636 = icmp eq i32 %18472, %18635
  %18637 = or i1 %18634, %18636
  %18638 = load i32, i32* %60, align 4
  %18639 = icmp eq i32 %18472, %18638
  %18640 = or i1 %18637, %18639
  %18641 = load i32, i32* %61, align 4
  %18642 = icmp eq i32 %18472, %18641
  %18643 = or i1 %18640, %18642
  %18644 = load i32, i32* %62, align 4
  %18645 = icmp eq i32 %18472, %18644
  %18646 = or i1 %18643, %18645
  %18647 = getelementptr i8, i8 addrspace(1)* %4, i32 60
  %18648 = zext i1 %18646 to i8
  store i8 %18648, i8 addrspace(1)* %18647, align 1, !nosanitize !3
  %18649 = load i256, i256* %18471, align 4
  %18650 = alloca i256, align 8
  store i256 %18649, i256* %18650, align 4
  %18651 = alloca i256, align 8
  store i256 1, i256* %18651, align 4
  %18652 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %18650, i256* %18651, i256* %18652), !pc !334, !intsan !6
  %18653 = load i256, i256* %18652, align 4
  %18654 = and i256 1461501637330902918203684832716283019655932542975, %18653
  %18655 = xor i256 0, -1
  %18656 = and i256 %18655, %18426
  %18657 = xor i256 0, -1
  %18658 = and i256 %18657, %18656
  %18659 = trunc i256 0 to i64
  %18660 = alloca i256, align 8
  store i256 %18658, i256* %18660, align 4
  %18661 = bitcast i256* %18660 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18659, i8* %18661, i64 32)
  %18662 = add i256 32, 0, !pc !335, !intsan !10
  %18663 = trunc i256 %18662 to i64
  %18664 = alloca i256, align 8
  store i256 11, i256* %18664, align 4
  %18665 = bitcast i256* %18664 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %18663, i8* %18665, i64 32)
  %18666 = add i256 32, %18662, !pc !336, !intsan !10
  %18667 = trunc i256 0 to i32
  %18668 = trunc i256 %18666 to i32
  %18669 = getelementptr inbounds i8, i8* %MEMORY, i32 %18667
  %18670 = alloca i256, align 8
  %18671 = bitcast i256* %18670 to i8*
  call void @__device_sha3(i8* %18669, i32 %18668, i8* %18671)
  %18672 = load i256, i256* %18670, align 4
  %18673 = add i256 1, %18672, !pc !337, !intsan !10
  %18674 = alloca i256, align 8
  store i256 %18673, i256* %18674, align 4
  %18675 = alloca i256, align 8
  call void @__device_sload(i256* %18674, i256* %18675)
  %18676 = call i32 @__hashword(i256* %18674)
  %18677 = load i32, i32* %5, align 4
  %18678 = icmp eq i32 %18676, %18677
  %18679 = or i1 false, %18678
  %18680 = load i32, i32* %6, align 4
  %18681 = icmp eq i32 %18676, %18680
  %18682 = or i1 %18679, %18681
  %18683 = load i32, i32* %7, align 4
  %18684 = icmp eq i32 %18676, %18683
  %18685 = or i1 %18682, %18684
  %18686 = load i32, i32* %8, align 4
  %18687 = icmp eq i32 %18676, %18686
  %18688 = or i1 %18685, %18687
  %18689 = load i32, i32* %9, align 4
  %18690 = icmp eq i32 %18676, %18689
  %18691 = or i1 %18688, %18690
  %18692 = load i32, i32* %10, align 4
  %18693 = icmp eq i32 %18676, %18692
  %18694 = or i1 %18691, %18693
  %18695 = load i32, i32* %11, align 4
  %18696 = icmp eq i32 %18676, %18695
  %18697 = or i1 %18694, %18696
  %18698 = load i32, i32* %12, align 4
  %18699 = icmp eq i32 %18676, %18698
  %18700 = or i1 %18697, %18699
  %18701 = load i32, i32* %13, align 4
  %18702 = icmp eq i32 %18676, %18701
  %18703 = or i1 %18700, %18702
  %18704 = load i32, i32* %14, align 4
  %18705 = icmp eq i32 %18676, %18704
  %18706 = or i1 %18703, %18705
  %18707 = load i32, i32* %15, align 4
  %18708 = icmp eq i32 %18676, %18707
  %18709 = or i1 %18706, %18708
  %18710 = load i32, i32* %16, align 4
  %18711 = icmp eq i32 %18676, %18710
  %18712 = or i1 %18709, %18711
  %18713 = load i32, i32* %17, align 4
  %18714 = icmp eq i32 %18676, %18713
  %18715 = or i1 %18712, %18714
  %18716 = load i32, i32* %18, align 4
  %18717 = icmp eq i32 %18676, %18716
  %18718 = or i1 %18715, %18717
  %18719 = load i32, i32* %19, align 4
  %18720 = icmp eq i32 %18676, %18719
  %18721 = or i1 %18718, %18720
  %18722 = load i32, i32* %20, align 4
  %18723 = icmp eq i32 %18676, %18722
  %18724 = or i1 %18721, %18723
  %18725 = load i32, i32* %21, align 4
  %18726 = icmp eq i32 %18676, %18725
  %18727 = or i1 %18724, %18726
  %18728 = load i32, i32* %22, align 4
  %18729 = icmp eq i32 %18676, %18728
  %18730 = or i1 %18727, %18729
  %18731 = load i32, i32* %23, align 4
  %18732 = icmp eq i32 %18676, %18731
  %18733 = or i1 %18730, %18732
  %18734 = load i32, i32* %24, align 4
  %18735 = icmp eq i32 %18676, %18734
  %18736 = or i1 %18733, %18735
  %18737 = load i32, i32* %25, align 4
  %18738 = icmp eq i32 %18676, %18737
  %18739 = or i1 %18736, %18738
  %18740 = load i32, i32* %26, align 4
  %18741 = icmp eq i32 %18676, %18740
  %18742 = or i1 %18739, %18741
  %18743 = load i32, i32* %27, align 4
  %18744 = icmp eq i32 %18676, %18743
  %18745 = or i1 %18742, %18744
  %18746 = load i32, i32* %28, align 4
  %18747 = icmp eq i32 %18676, %18746
  %18748 = or i1 %18745, %18747
  %18749 = load i32, i32* %29, align 4
  %18750 = icmp eq i32 %18676, %18749
  %18751 = or i1 %18748, %18750
  %18752 = load i32, i32* %30, align 4
  %18753 = icmp eq i32 %18676, %18752
  %18754 = or i1 %18751, %18753
  %18755 = load i32, i32* %31, align 4
  %18756 = icmp eq i32 %18676, %18755
  %18757 = or i1 %18754, %18756
  %18758 = load i32, i32* %32, align 4
  %18759 = icmp eq i32 %18676, %18758
  %18760 = or i1 %18757, %18759
  %18761 = load i32, i32* %33, align 4
  %18762 = icmp eq i32 %18676, %18761
  %18763 = or i1 %18760, %18762
  %18764 = load i32, i32* %34, align 4
  %18765 = icmp eq i32 %18676, %18764
  %18766 = or i1 %18763, %18765
  %18767 = load i32, i32* %35, align 4
  %18768 = icmp eq i32 %18676, %18767
  %18769 = or i1 %18766, %18768
  %18770 = load i32, i32* %36, align 4
  %18771 = icmp eq i32 %18676, %18770
  %18772 = or i1 %18769, %18771
  %18773 = load i32, i32* %37, align 4
  %18774 = icmp eq i32 %18676, %18773
  %18775 = or i1 %18772, %18774
  %18776 = load i32, i32* %38, align 4
  %18777 = icmp eq i32 %18676, %18776
  %18778 = or i1 %18775, %18777
  %18779 = load i32, i32* %39, align 4
  %18780 = icmp eq i32 %18676, %18779
  %18781 = or i1 %18778, %18780
  %18782 = load i32, i32* %40, align 4
  %18783 = icmp eq i32 %18676, %18782
  %18784 = or i1 %18781, %18783
  %18785 = load i32, i32* %41, align 4
  %18786 = icmp eq i32 %18676, %18785
  %18787 = or i1 %18784, %18786
  %18788 = load i32, i32* %42, align 4
  %18789 = icmp eq i32 %18676, %18788
  %18790 = or i1 %18787, %18789
  %18791 = load i32, i32* %43, align 4
  %18792 = icmp eq i32 %18676, %18791
  %18793 = or i1 %18790, %18792
  %18794 = load i32, i32* %44, align 4
  %18795 = icmp eq i32 %18676, %18794
  %18796 = or i1 %18793, %18795
  %18797 = load i32, i32* %45, align 4
  %18798 = icmp eq i32 %18676, %18797
  %18799 = or i1 %18796, %18798
  %18800 = load i32, i32* %46, align 4
  %18801 = icmp eq i32 %18676, %18800
  %18802 = or i1 %18799, %18801
  %18803 = load i32, i32* %47, align 4
  %18804 = icmp eq i32 %18676, %18803
  %18805 = or i1 %18802, %18804
  %18806 = load i32, i32* %48, align 4
  %18807 = icmp eq i32 %18676, %18806
  %18808 = or i1 %18805, %18807
  %18809 = load i32, i32* %49, align 4
  %18810 = icmp eq i32 %18676, %18809
  %18811 = or i1 %18808, %18810
  %18812 = load i32, i32* %50, align 4
  %18813 = icmp eq i32 %18676, %18812
  %18814 = or i1 %18811, %18813
  %18815 = load i32, i32* %51, align 4
  %18816 = icmp eq i32 %18676, %18815
  %18817 = or i1 %18814, %18816
  %18818 = load i32, i32* %52, align 4
  %18819 = icmp eq i32 %18676, %18818
  %18820 = or i1 %18817, %18819
  %18821 = load i32, i32* %53, align 4
  %18822 = icmp eq i32 %18676, %18821
  %18823 = or i1 %18820, %18822
  %18824 = load i32, i32* %54, align 4
  %18825 = icmp eq i32 %18676, %18824
  %18826 = or i1 %18823, %18825
  %18827 = load i32, i32* %55, align 4
  %18828 = icmp eq i32 %18676, %18827
  %18829 = or i1 %18826, %18828
  %18830 = load i32, i32* %56, align 4
  %18831 = icmp eq i32 %18676, %18830
  %18832 = or i1 %18829, %18831
  %18833 = load i32, i32* %57, align 4
  %18834 = icmp eq i32 %18676, %18833
  %18835 = or i1 %18832, %18834
  %18836 = load i32, i32* %58, align 4
  %18837 = icmp eq i32 %18676, %18836
  %18838 = or i1 %18835, %18837
  %18839 = load i32, i32* %59, align 4
  %18840 = icmp eq i32 %18676, %18839
  %18841 = or i1 %18838, %18840
  %18842 = load i32, i32* %60, align 4
  %18843 = icmp eq i32 %18676, %18842
  %18844 = or i1 %18841, %18843
  %18845 = load i32, i32* %61, align 4
  %18846 = icmp eq i32 %18676, %18845
  %18847 = or i1 %18844, %18846
  %18848 = load i32, i32* %62, align 4
  %18849 = icmp eq i32 %18676, %18848
  %18850 = or i1 %18847, %18849
  %18851 = getelementptr i8, i8 addrspace(1)* %4, i32 61
  %18852 = zext i1 %18850 to i8
  store i8 %18852, i8 addrspace(1)* %18851, align 1, !nosanitize !3
  %18853 = load i256, i256* %18675, align 4
  %18854 = trunc i256 14584 to i64
  %18855 = load i64, i64* %STACK_DEP_PTR, align 4
  %18856 = add i64 %18855, 1
  store i64 %18856, i64* %STACK_DEP_PTR, align 4
  %18857 = load i64, i64* %STACK_DEP_PTR, align 4
  %18858 = getelementptr i256, i256* %STACK, i64 %18857
  store i256 %18426, i256* %18858, align 4
  %18859 = load i64, i64* %STACK_DEP_PTR, align 4
  %18860 = add i64 %18859, 1
  store i64 %18860, i64* %STACK_DEP_PTR, align 4
  %18861 = load i64, i64* %STACK_DEP_PTR, align 4
  %18862 = getelementptr i256, i256* %STACK, i64 %18861
  store i256 7011, i256* %18862, align 4
  %18863 = load i64, i64* %STACK_DEP_PTR, align 4
  %18864 = add i64 %18863, 1
  store i64 %18864, i64* %STACK_DEP_PTR, align 4
  %18865 = load i64, i64* %STACK_DEP_PTR, align 4
  %18866 = getelementptr i256, i256* %STACK, i64 %18865
  store i256 %18654, i256* %18866, align 4
  %18867 = load i64, i64* %STACK_DEP_PTR, align 4
  %18868 = add i64 %18867, 1
  store i64 %18868, i64* %STACK_DEP_PTR, align 4
  %18869 = load i64, i64* %STACK_DEP_PTR, align 4
  %18870 = getelementptr i256, i256* %STACK, i64 %18869
  store i256 %18853, i256* %18870, align 4
  br label %.14584, !EVMBB !4

.7011:                                            ; preds = %JumpTable
  %18871 = load i64, i64* %remaing_gas, align 4
  %18872 = icmp ugt i64 24, %18871
  br i1 %18872, label %Abort, label %18873

18873:                                            ; preds = %.7011
  %18874 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18875 = xor i32 %18874, 3564
  %18876 = urem i32 %18875, 4096
  %18877 = getelementptr i8, i8 addrspace(1)* %4, i32 %18876
  %18878 = load i8, i8 addrspace(1)* %18877, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %18877, align 1, !nosanitize !3
  store i32 1782, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18879 = sub i64 %18871, 24
  store i64 %18879, i64* %remaing_gas, align 4
  %18880 = trunc i256 7017 to i64
  br label %.7017, !EVMBB !4

.7016:                                            ; preds = %18221, %JumpTable
  br label %.7017

.7017:                                            ; preds = %.7016, %18873, %JumpTable
  %18881 = load i64, i64* %STACK_DEP_PTR, align 4
  %18882 = getelementptr i256, i256* %STACK, i64 %18881
  %18883 = load i256, i256* %18882, align 4
  %18884 = load i64, i64* %STACK_DEP_PTR, align 4
  %18885 = sub i64 %18884, 1
  store i64 %18885, i64* %STACK_DEP_PTR, align 4
  br label %.7019

.7019:                                            ; preds = %.7017, %16015, %JumpTable
  %18886 = load i64, i64* %remaing_gas, align 4
  %18887 = icmp ugt i64 512, %18886
  br i1 %18887, label %Abort, label %18888

18888:                                            ; preds = %.7019
  %18889 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18890 = xor i32 %18889, 3146
  %18891 = urem i32 %18890, 4096
  %18892 = getelementptr i8, i8 addrspace(1)* %4, i32 %18891
  %18893 = load i8, i8 addrspace(1)* %18892, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %18892, align 1, !nosanitize !3
  store i32 1573, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18894 = sub i64 %18886, 512
  store i64 %18894, i64* %remaing_gas, align 4
  %18895 = load i64, i64* %STACK_DEP_PTR, align 4
  %18896 = getelementptr i256, i256* %STACK, i64 %18895
  %18897 = load i256, i256* %18896, align 4
  %18898 = load i64, i64* %STACK_DEP_PTR, align 4
  %18899 = sub i64 %18898, 1
  store i64 %18899, i64* %STACK_DEP_PTR, align 4
  %18900 = load i64, i64* %STACK_DEP_PTR, align 4
  %18901 = getelementptr i256, i256* %STACK, i64 %18900
  %18902 = load i256, i256* %18901, align 4
  %18903 = load i64, i64* %STACK_DEP_PTR, align 4
  %18904 = sub i64 %18903, 1
  store i64 %18904, i64* %STACK_DEP_PTR, align 4
  %18905 = load i64, i64* %STACK_DEP_PTR, align 4
  %18906 = getelementptr i256, i256* %STACK, i64 %18905
  %18907 = load i256, i256* %18906, align 4
  %18908 = load i64, i64* %STACK_DEP_PTR, align 4
  %18909 = sub i64 %18908, 1
  store i64 %18909, i64* %STACK_DEP_PTR, align 4
  %18910 = load i64, i64* %STACK_DEP_PTR, align 4
  %18911 = getelementptr i256, i256* %STACK, i64 %18910
  %18912 = load i256, i256* %18911, align 4
  %18913 = load i64, i64* %STACK_DEP_PTR, align 4
  %18914 = sub i64 %18913, 1
  store i64 %18914, i64* %STACK_DEP_PTR, align 4
  %18915 = load i64, i64* %STACK_DEP_PTR, align 4
  %18916 = getelementptr i256, i256* %STACK, i64 %18915
  %18917 = load i256, i256* %18916, align 4
  %18918 = load i64, i64* %STACK_DEP_PTR, align 4
  %18919 = sub i64 %18918, 1
  store i64 %18919, i64* %STACK_DEP_PTR, align 4
  %18920 = load i64, i64* %STACK_DEP_PTR, align 4
  %18921 = getelementptr i256, i256* %STACK, i64 %18920
  %18922 = load i256, i256* %18921, align 4
  %18923 = load i64, i64* %STACK_DEP_PTR, align 4
  %18924 = sub i64 %18923, 1
  store i64 %18924, i64* %STACK_DEP_PTR, align 4
  %18925 = load i64, i64* %STACK_DEP_PTR, align 4
  %18926 = getelementptr i256, i256* %STACK, i64 %18925
  %18927 = load i256, i256* %18926, align 4
  %18928 = load i64, i64* %STACK_DEP_PTR, align 4
  %18929 = sub i64 %18928, 1
  store i64 %18929, i64* %STACK_DEP_PTR, align 4
  %18930 = load i64, i64* %STACK_DEP_PTR, align 4
  %18931 = getelementptr i256, i256* %STACK, i64 %18930
  %18932 = load i256, i256* %18931, align 4
  %18933 = load i64, i64* %STACK_DEP_PTR, align 4
  %18934 = sub i64 %18933, 1
  store i64 %18934, i64* %STACK_DEP_PTR, align 4
  %18935 = load i64, i64* %STACK_DEP_PTR, align 4
  %18936 = getelementptr i256, i256* %STACK, i64 %18935
  %18937 = load i256, i256* %18936, align 4
  %18938 = load i64, i64* %STACK_DEP_PTR, align 4
  %18939 = sub i64 %18938, 1
  store i64 %18939, i64* %STACK_DEP_PTR, align 4
  %18940 = load i64, i64* %STACK_DEP_PTR, align 4
  %18941 = getelementptr i256, i256* %STACK, i64 %18940
  %18942 = load i256, i256* %18941, align 4
  %18943 = load i64, i64* %STACK_DEP_PTR, align 4
  %18944 = sub i64 %18943, 1
  store i64 %18944, i64* %STACK_DEP_PTR, align 4
  %18945 = trunc i256 %18942 to i64
  store i64 %18945, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.7030:                                            ; preds = %1823, %JumpTable
  %18946 = load i64, i64* %remaing_gas, align 4
  %18947 = icmp ugt i64 280, %18946
  br i1 %18947, label %Abort, label %18948

18948:                                            ; preds = %.7030
  %18949 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18950 = xor i32 %18949, 964
  %18951 = urem i32 %18950, 4096
  %18952 = getelementptr i8, i8 addrspace(1)* %4, i32 %18951
  %18953 = load i8, i8 addrspace(1)* %18952, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %18952, align 1, !nosanitize !3
  store i32 482, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %18954 = sub i64 %18946, 280
  store i64 %18954, i64* %remaing_gas, align 4
  %18955 = load i64, i64* %STACK_DEP_PTR, align 4
  %18956 = getelementptr i256, i256* %STACK, i64 %18955
  %18957 = load i256, i256* %18956, align 4
  %18958 = load i64, i64* %STACK_DEP_PTR, align 4
  %18959 = sub i64 %18958, 1
  store i64 %18959, i64* %STACK_DEP_PTR, align 4
  %18960 = alloca i256, align 8
  store i256 8, i256* %18960, align 4
  %18961 = alloca i256, align 8
  call void @__device_sload(i256* %18960, i256* %18961)
  %18962 = call i32 @__hashword(i256* %18960)
  %18963 = load i32, i32* %5, align 4
  %18964 = icmp eq i32 %18962, %18963
  %18965 = or i1 false, %18964
  %18966 = load i32, i32* %6, align 4
  %18967 = icmp eq i32 %18962, %18966
  %18968 = or i1 %18965, %18967
  %18969 = load i32, i32* %7, align 4
  %18970 = icmp eq i32 %18962, %18969
  %18971 = or i1 %18968, %18970
  %18972 = load i32, i32* %8, align 4
  %18973 = icmp eq i32 %18962, %18972
  %18974 = or i1 %18971, %18973
  %18975 = load i32, i32* %9, align 4
  %18976 = icmp eq i32 %18962, %18975
  %18977 = or i1 %18974, %18976
  %18978 = load i32, i32* %10, align 4
  %18979 = icmp eq i32 %18962, %18978
  %18980 = or i1 %18977, %18979
  %18981 = load i32, i32* %11, align 4
  %18982 = icmp eq i32 %18962, %18981
  %18983 = or i1 %18980, %18982
  %18984 = load i32, i32* %12, align 4
  %18985 = icmp eq i32 %18962, %18984
  %18986 = or i1 %18983, %18985
  %18987 = load i32, i32* %13, align 4
  %18988 = icmp eq i32 %18962, %18987
  %18989 = or i1 %18986, %18988
  %18990 = load i32, i32* %14, align 4
  %18991 = icmp eq i32 %18962, %18990
  %18992 = or i1 %18989, %18991
  %18993 = load i32, i32* %15, align 4
  %18994 = icmp eq i32 %18962, %18993
  %18995 = or i1 %18992, %18994
  %18996 = load i32, i32* %16, align 4
  %18997 = icmp eq i32 %18962, %18996
  %18998 = or i1 %18995, %18997
  %18999 = load i32, i32* %17, align 4
  %19000 = icmp eq i32 %18962, %18999
  %19001 = or i1 %18998, %19000
  %19002 = load i32, i32* %18, align 4
  %19003 = icmp eq i32 %18962, %19002
  %19004 = or i1 %19001, %19003
  %19005 = load i32, i32* %19, align 4
  %19006 = icmp eq i32 %18962, %19005
  %19007 = or i1 %19004, %19006
  %19008 = load i32, i32* %20, align 4
  %19009 = icmp eq i32 %18962, %19008
  %19010 = or i1 %19007, %19009
  %19011 = load i32, i32* %21, align 4
  %19012 = icmp eq i32 %18962, %19011
  %19013 = or i1 %19010, %19012
  %19014 = load i32, i32* %22, align 4
  %19015 = icmp eq i32 %18962, %19014
  %19016 = or i1 %19013, %19015
  %19017 = load i32, i32* %23, align 4
  %19018 = icmp eq i32 %18962, %19017
  %19019 = or i1 %19016, %19018
  %19020 = load i32, i32* %24, align 4
  %19021 = icmp eq i32 %18962, %19020
  %19022 = or i1 %19019, %19021
  %19023 = load i32, i32* %25, align 4
  %19024 = icmp eq i32 %18962, %19023
  %19025 = or i1 %19022, %19024
  %19026 = load i32, i32* %26, align 4
  %19027 = icmp eq i32 %18962, %19026
  %19028 = or i1 %19025, %19027
  %19029 = load i32, i32* %27, align 4
  %19030 = icmp eq i32 %18962, %19029
  %19031 = or i1 %19028, %19030
  %19032 = load i32, i32* %28, align 4
  %19033 = icmp eq i32 %18962, %19032
  %19034 = or i1 %19031, %19033
  %19035 = load i32, i32* %29, align 4
  %19036 = icmp eq i32 %18962, %19035
  %19037 = or i1 %19034, %19036
  %19038 = load i32, i32* %30, align 4
  %19039 = icmp eq i32 %18962, %19038
  %19040 = or i1 %19037, %19039
  %19041 = load i32, i32* %31, align 4
  %19042 = icmp eq i32 %18962, %19041
  %19043 = or i1 %19040, %19042
  %19044 = load i32, i32* %32, align 4
  %19045 = icmp eq i32 %18962, %19044
  %19046 = or i1 %19043, %19045
  %19047 = load i32, i32* %33, align 4
  %19048 = icmp eq i32 %18962, %19047
  %19049 = or i1 %19046, %19048
  %19050 = load i32, i32* %34, align 4
  %19051 = icmp eq i32 %18962, %19050
  %19052 = or i1 %19049, %19051
  %19053 = load i32, i32* %35, align 4
  %19054 = icmp eq i32 %18962, %19053
  %19055 = or i1 %19052, %19054
  %19056 = load i32, i32* %36, align 4
  %19057 = icmp eq i32 %18962, %19056
  %19058 = or i1 %19055, %19057
  %19059 = load i32, i32* %37, align 4
  %19060 = icmp eq i32 %18962, %19059
  %19061 = or i1 %19058, %19060
  %19062 = load i32, i32* %38, align 4
  %19063 = icmp eq i32 %18962, %19062
  %19064 = or i1 %19061, %19063
  %19065 = load i32, i32* %39, align 4
  %19066 = icmp eq i32 %18962, %19065
  %19067 = or i1 %19064, %19066
  %19068 = load i32, i32* %40, align 4
  %19069 = icmp eq i32 %18962, %19068
  %19070 = or i1 %19067, %19069
  %19071 = load i32, i32* %41, align 4
  %19072 = icmp eq i32 %18962, %19071
  %19073 = or i1 %19070, %19072
  %19074 = load i32, i32* %42, align 4
  %19075 = icmp eq i32 %18962, %19074
  %19076 = or i1 %19073, %19075
  %19077 = load i32, i32* %43, align 4
  %19078 = icmp eq i32 %18962, %19077
  %19079 = or i1 %19076, %19078
  %19080 = load i32, i32* %44, align 4
  %19081 = icmp eq i32 %18962, %19080
  %19082 = or i1 %19079, %19081
  %19083 = load i32, i32* %45, align 4
  %19084 = icmp eq i32 %18962, %19083
  %19085 = or i1 %19082, %19084
  %19086 = load i32, i32* %46, align 4
  %19087 = icmp eq i32 %18962, %19086
  %19088 = or i1 %19085, %19087
  %19089 = load i32, i32* %47, align 4
  %19090 = icmp eq i32 %18962, %19089
  %19091 = or i1 %19088, %19090
  %19092 = load i32, i32* %48, align 4
  %19093 = icmp eq i32 %18962, %19092
  %19094 = or i1 %19091, %19093
  %19095 = load i32, i32* %49, align 4
  %19096 = icmp eq i32 %18962, %19095
  %19097 = or i1 %19094, %19096
  %19098 = load i32, i32* %50, align 4
  %19099 = icmp eq i32 %18962, %19098
  %19100 = or i1 %19097, %19099
  %19101 = load i32, i32* %51, align 4
  %19102 = icmp eq i32 %18962, %19101
  %19103 = or i1 %19100, %19102
  %19104 = load i32, i32* %52, align 4
  %19105 = icmp eq i32 %18962, %19104
  %19106 = or i1 %19103, %19105
  %19107 = load i32, i32* %53, align 4
  %19108 = icmp eq i32 %18962, %19107
  %19109 = or i1 %19106, %19108
  %19110 = load i32, i32* %54, align 4
  %19111 = icmp eq i32 %18962, %19110
  %19112 = or i1 %19109, %19111
  %19113 = load i32, i32* %55, align 4
  %19114 = icmp eq i32 %18962, %19113
  %19115 = or i1 %19112, %19114
  %19116 = load i32, i32* %56, align 4
  %19117 = icmp eq i32 %18962, %19116
  %19118 = or i1 %19115, %19117
  %19119 = load i32, i32* %57, align 4
  %19120 = icmp eq i32 %18962, %19119
  %19121 = or i1 %19118, %19120
  %19122 = load i32, i32* %58, align 4
  %19123 = icmp eq i32 %18962, %19122
  %19124 = or i1 %19121, %19123
  %19125 = load i32, i32* %59, align 4
  %19126 = icmp eq i32 %18962, %19125
  %19127 = or i1 %19124, %19126
  %19128 = load i32, i32* %60, align 4
  %19129 = icmp eq i32 %18962, %19128
  %19130 = or i1 %19127, %19129
  %19131 = load i32, i32* %61, align 4
  %19132 = icmp eq i32 %18962, %19131
  %19133 = or i1 %19130, %19132
  %19134 = load i32, i32* %62, align 4
  %19135 = icmp eq i32 %18962, %19134
  %19136 = or i1 %19133, %19135
  %19137 = getelementptr i8, i8 addrspace(1)* %4, i32 62
  %19138 = zext i1 %19136 to i8
  store i8 %19138, i8 addrspace(1)* %19137, align 1, !nosanitize !3
  %19139 = load i256, i256* %18961, align 4
  %19140 = alloca i256, align 8
  store i256 %19139, i256* %19140, align 4
  %19141 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %19141, align 4
  %19142 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %19140, i256* %19141, i256* %19142), !pc !338, !intsan !6
  %19143 = load i256, i256* %19142, align 4
  %19144 = and i256 255, %19143
  %19145 = trunc i256 %18957 to i64
  store i64 %19145, i64* %JMP_TARGET_PTR, align 4
  %19146 = load i64, i64* %STACK_DEP_PTR, align 4
  %19147 = add i64 %19146, 1
  store i64 %19147, i64* %STACK_DEP_PTR, align 4
  %19148 = load i64, i64* %STACK_DEP_PTR, align 4
  %19149 = getelementptr i256, i256* %STACK, i64 %19148
  store i256 %18957, i256* %19149, align 4
  %19150 = load i64, i64* %STACK_DEP_PTR, align 4
  %19151 = add i64 %19150, 1
  store i64 %19151, i64* %STACK_DEP_PTR, align 4
  %19152 = load i64, i64* %STACK_DEP_PTR, align 4
  %19153 = getelementptr i256, i256* %STACK, i64 %19152
  store i256 %19144, i256* %19153, align 4
  br label %JumpTable, !EVMBB !4

.7049:                                            ; preds = %1899, %JumpTable
  %19154 = load i64, i64* %remaing_gas, align 4
  %19155 = icmp ugt i64 728, %19154
  br i1 %19155, label %Abort, label %19156

19156:                                            ; preds = %.7049
  %19157 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19158 = xor i32 %19157, 3632
  %19159 = urem i32 %19158, 4096
  %19160 = getelementptr i8, i8 addrspace(1)* %4, i32 %19159
  %19161 = load i8, i8 addrspace(1)* %19160, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %19160, align 1, !nosanitize !3
  store i32 1816, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19162 = sub i64 %19154, 728
  store i64 %19162, i64* %remaing_gas, align 4
  %19163 = load i64, i64* %STACK_DEP_PTR, align 4
  %19164 = getelementptr i256, i256* %STACK, i64 %19163
  %19165 = load i256, i256* %19164, align 4
  %19166 = load i64, i64* %STACK_DEP_PTR, align 4
  %19167 = sub i64 %19166, 1
  store i64 %19167, i64* %STACK_DEP_PTR, align 4
  %19168 = load i64, i64* %STACK_DEP_PTR, align 4
  %19169 = getelementptr i256, i256* %STACK, i64 %19168
  %19170 = load i256, i256* %19169, align 4
  %19171 = load i64, i64* %STACK_DEP_PTR, align 4
  %19172 = sub i64 %19171, 1
  store i64 %19172, i64* %STACK_DEP_PTR, align 4
  %19173 = trunc i256 32 to i64
  %19174 = alloca i256, align 8
  store i256 4, i256* %19174, align 4
  %19175 = bitcast i256* %19174 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %19173, i8* %19175, i64 32)
  %19176 = trunc i256 0 to i64
  %19177 = alloca i256, align 8
  store i256 %19165, i256* %19177, align 4
  %19178 = bitcast i256* %19177 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %19176, i8* %19178, i64 32)
  %19179 = trunc i256 0 to i32
  %19180 = trunc i256 64 to i32
  %19181 = getelementptr inbounds i8, i8* %MEMORY, i32 %19179
  %19182 = alloca i256, align 8
  %19183 = bitcast i256* %19182 to i8*
  call void @__device_sha3(i8* %19181, i32 %19180, i8* %19183)
  %19184 = load i256, i256* %19182, align 4
  %19185 = add i256 0, %19184, !pc !339, !intsan !10
  %19186 = alloca i256, align 8
  store i256 %19185, i256* %19186, align 4
  %19187 = alloca i256, align 8
  call void @__device_sload(i256* %19186, i256* %19187)
  %19188 = call i32 @__hashword(i256* %19186)
  %19189 = load i32, i32* %5, align 4
  %19190 = icmp eq i32 %19188, %19189
  %19191 = or i1 false, %19190
  %19192 = load i32, i32* %6, align 4
  %19193 = icmp eq i32 %19188, %19192
  %19194 = or i1 %19191, %19193
  %19195 = load i32, i32* %7, align 4
  %19196 = icmp eq i32 %19188, %19195
  %19197 = or i1 %19194, %19196
  %19198 = load i32, i32* %8, align 4
  %19199 = icmp eq i32 %19188, %19198
  %19200 = or i1 %19197, %19199
  %19201 = load i32, i32* %9, align 4
  %19202 = icmp eq i32 %19188, %19201
  %19203 = or i1 %19200, %19202
  %19204 = load i32, i32* %10, align 4
  %19205 = icmp eq i32 %19188, %19204
  %19206 = or i1 %19203, %19205
  %19207 = load i32, i32* %11, align 4
  %19208 = icmp eq i32 %19188, %19207
  %19209 = or i1 %19206, %19208
  %19210 = load i32, i32* %12, align 4
  %19211 = icmp eq i32 %19188, %19210
  %19212 = or i1 %19209, %19211
  %19213 = load i32, i32* %13, align 4
  %19214 = icmp eq i32 %19188, %19213
  %19215 = or i1 %19212, %19214
  %19216 = load i32, i32* %14, align 4
  %19217 = icmp eq i32 %19188, %19216
  %19218 = or i1 %19215, %19217
  %19219 = load i32, i32* %15, align 4
  %19220 = icmp eq i32 %19188, %19219
  %19221 = or i1 %19218, %19220
  %19222 = load i32, i32* %16, align 4
  %19223 = icmp eq i32 %19188, %19222
  %19224 = or i1 %19221, %19223
  %19225 = load i32, i32* %17, align 4
  %19226 = icmp eq i32 %19188, %19225
  %19227 = or i1 %19224, %19226
  %19228 = load i32, i32* %18, align 4
  %19229 = icmp eq i32 %19188, %19228
  %19230 = or i1 %19227, %19229
  %19231 = load i32, i32* %19, align 4
  %19232 = icmp eq i32 %19188, %19231
  %19233 = or i1 %19230, %19232
  %19234 = load i32, i32* %20, align 4
  %19235 = icmp eq i32 %19188, %19234
  %19236 = or i1 %19233, %19235
  %19237 = load i32, i32* %21, align 4
  %19238 = icmp eq i32 %19188, %19237
  %19239 = or i1 %19236, %19238
  %19240 = load i32, i32* %22, align 4
  %19241 = icmp eq i32 %19188, %19240
  %19242 = or i1 %19239, %19241
  %19243 = load i32, i32* %23, align 4
  %19244 = icmp eq i32 %19188, %19243
  %19245 = or i1 %19242, %19244
  %19246 = load i32, i32* %24, align 4
  %19247 = icmp eq i32 %19188, %19246
  %19248 = or i1 %19245, %19247
  %19249 = load i32, i32* %25, align 4
  %19250 = icmp eq i32 %19188, %19249
  %19251 = or i1 %19248, %19250
  %19252 = load i32, i32* %26, align 4
  %19253 = icmp eq i32 %19188, %19252
  %19254 = or i1 %19251, %19253
  %19255 = load i32, i32* %27, align 4
  %19256 = icmp eq i32 %19188, %19255
  %19257 = or i1 %19254, %19256
  %19258 = load i32, i32* %28, align 4
  %19259 = icmp eq i32 %19188, %19258
  %19260 = or i1 %19257, %19259
  %19261 = load i32, i32* %29, align 4
  %19262 = icmp eq i32 %19188, %19261
  %19263 = or i1 %19260, %19262
  %19264 = load i32, i32* %30, align 4
  %19265 = icmp eq i32 %19188, %19264
  %19266 = or i1 %19263, %19265
  %19267 = load i32, i32* %31, align 4
  %19268 = icmp eq i32 %19188, %19267
  %19269 = or i1 %19266, %19268
  %19270 = load i32, i32* %32, align 4
  %19271 = icmp eq i32 %19188, %19270
  %19272 = or i1 %19269, %19271
  %19273 = load i32, i32* %33, align 4
  %19274 = icmp eq i32 %19188, %19273
  %19275 = or i1 %19272, %19274
  %19276 = load i32, i32* %34, align 4
  %19277 = icmp eq i32 %19188, %19276
  %19278 = or i1 %19275, %19277
  %19279 = load i32, i32* %35, align 4
  %19280 = icmp eq i32 %19188, %19279
  %19281 = or i1 %19278, %19280
  %19282 = load i32, i32* %36, align 4
  %19283 = icmp eq i32 %19188, %19282
  %19284 = or i1 %19281, %19283
  %19285 = load i32, i32* %37, align 4
  %19286 = icmp eq i32 %19188, %19285
  %19287 = or i1 %19284, %19286
  %19288 = load i32, i32* %38, align 4
  %19289 = icmp eq i32 %19188, %19288
  %19290 = or i1 %19287, %19289
  %19291 = load i32, i32* %39, align 4
  %19292 = icmp eq i32 %19188, %19291
  %19293 = or i1 %19290, %19292
  %19294 = load i32, i32* %40, align 4
  %19295 = icmp eq i32 %19188, %19294
  %19296 = or i1 %19293, %19295
  %19297 = load i32, i32* %41, align 4
  %19298 = icmp eq i32 %19188, %19297
  %19299 = or i1 %19296, %19298
  %19300 = load i32, i32* %42, align 4
  %19301 = icmp eq i32 %19188, %19300
  %19302 = or i1 %19299, %19301
  %19303 = load i32, i32* %43, align 4
  %19304 = icmp eq i32 %19188, %19303
  %19305 = or i1 %19302, %19304
  %19306 = load i32, i32* %44, align 4
  %19307 = icmp eq i32 %19188, %19306
  %19308 = or i1 %19305, %19307
  %19309 = load i32, i32* %45, align 4
  %19310 = icmp eq i32 %19188, %19309
  %19311 = or i1 %19308, %19310
  %19312 = load i32, i32* %46, align 4
  %19313 = icmp eq i32 %19188, %19312
  %19314 = or i1 %19311, %19313
  %19315 = load i32, i32* %47, align 4
  %19316 = icmp eq i32 %19188, %19315
  %19317 = or i1 %19314, %19316
  %19318 = load i32, i32* %48, align 4
  %19319 = icmp eq i32 %19188, %19318
  %19320 = or i1 %19317, %19319
  %19321 = load i32, i32* %49, align 4
  %19322 = icmp eq i32 %19188, %19321
  %19323 = or i1 %19320, %19322
  %19324 = load i32, i32* %50, align 4
  %19325 = icmp eq i32 %19188, %19324
  %19326 = or i1 %19323, %19325
  %19327 = load i32, i32* %51, align 4
  %19328 = icmp eq i32 %19188, %19327
  %19329 = or i1 %19326, %19328
  %19330 = load i32, i32* %52, align 4
  %19331 = icmp eq i32 %19188, %19330
  %19332 = or i1 %19329, %19331
  %19333 = load i32, i32* %53, align 4
  %19334 = icmp eq i32 %19188, %19333
  %19335 = or i1 %19332, %19334
  %19336 = load i32, i32* %54, align 4
  %19337 = icmp eq i32 %19188, %19336
  %19338 = or i1 %19335, %19337
  %19339 = load i32, i32* %55, align 4
  %19340 = icmp eq i32 %19188, %19339
  %19341 = or i1 %19338, %19340
  %19342 = load i32, i32* %56, align 4
  %19343 = icmp eq i32 %19188, %19342
  %19344 = or i1 %19341, %19343
  %19345 = load i32, i32* %57, align 4
  %19346 = icmp eq i32 %19188, %19345
  %19347 = or i1 %19344, %19346
  %19348 = load i32, i32* %58, align 4
  %19349 = icmp eq i32 %19188, %19348
  %19350 = or i1 %19347, %19349
  %19351 = load i32, i32* %59, align 4
  %19352 = icmp eq i32 %19188, %19351
  %19353 = or i1 %19350, %19352
  %19354 = load i32, i32* %60, align 4
  %19355 = icmp eq i32 %19188, %19354
  %19356 = or i1 %19353, %19355
  %19357 = load i32, i32* %61, align 4
  %19358 = icmp eq i32 %19188, %19357
  %19359 = or i1 %19356, %19358
  %19360 = load i32, i32* %62, align 4
  %19361 = icmp eq i32 %19188, %19360
  %19362 = or i1 %19359, %19361
  %19363 = getelementptr i8, i8 addrspace(1)* %4, i32 63
  %19364 = zext i1 %19362 to i8
  store i8 %19364, i8 addrspace(1)* %19363, align 1, !nosanitize !3
  %19365 = load i256, i256* %19187, align 4
  %19366 = alloca i256, align 8
  store i256 %19365, i256* %19366, align 4
  %19367 = alloca i256, align 8
  store i256 1, i256* %19367, align 4
  %19368 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %19366, i256* %19367, i256* %19368), !pc !340, !intsan !6
  %19369 = load i256, i256* %19368, align 4
  %19370 = and i256 1461501637330902918203684832716283019655932542975, %19369
  %19371 = add i256 1, %19184, !pc !341, !intsan !10
  %19372 = alloca i256, align 8
  store i256 %19371, i256* %19372, align 4
  %19373 = alloca i256, align 8
  call void @__device_sload(i256* %19372, i256* %19373)
  %19374 = call i32 @__hashword(i256* %19372)
  %19375 = load i32, i32* %5, align 4
  %19376 = icmp eq i32 %19374, %19375
  %19377 = or i1 false, %19376
  %19378 = load i32, i32* %6, align 4
  %19379 = icmp eq i32 %19374, %19378
  %19380 = or i1 %19377, %19379
  %19381 = load i32, i32* %7, align 4
  %19382 = icmp eq i32 %19374, %19381
  %19383 = or i1 %19380, %19382
  %19384 = load i32, i32* %8, align 4
  %19385 = icmp eq i32 %19374, %19384
  %19386 = or i1 %19383, %19385
  %19387 = load i32, i32* %9, align 4
  %19388 = icmp eq i32 %19374, %19387
  %19389 = or i1 %19386, %19388
  %19390 = load i32, i32* %10, align 4
  %19391 = icmp eq i32 %19374, %19390
  %19392 = or i1 %19389, %19391
  %19393 = load i32, i32* %11, align 4
  %19394 = icmp eq i32 %19374, %19393
  %19395 = or i1 %19392, %19394
  %19396 = load i32, i32* %12, align 4
  %19397 = icmp eq i32 %19374, %19396
  %19398 = or i1 %19395, %19397
  %19399 = load i32, i32* %13, align 4
  %19400 = icmp eq i32 %19374, %19399
  %19401 = or i1 %19398, %19400
  %19402 = load i32, i32* %14, align 4
  %19403 = icmp eq i32 %19374, %19402
  %19404 = or i1 %19401, %19403
  %19405 = load i32, i32* %15, align 4
  %19406 = icmp eq i32 %19374, %19405
  %19407 = or i1 %19404, %19406
  %19408 = load i32, i32* %16, align 4
  %19409 = icmp eq i32 %19374, %19408
  %19410 = or i1 %19407, %19409
  %19411 = load i32, i32* %17, align 4
  %19412 = icmp eq i32 %19374, %19411
  %19413 = or i1 %19410, %19412
  %19414 = load i32, i32* %18, align 4
  %19415 = icmp eq i32 %19374, %19414
  %19416 = or i1 %19413, %19415
  %19417 = load i32, i32* %19, align 4
  %19418 = icmp eq i32 %19374, %19417
  %19419 = or i1 %19416, %19418
  %19420 = load i32, i32* %20, align 4
  %19421 = icmp eq i32 %19374, %19420
  %19422 = or i1 %19419, %19421
  %19423 = load i32, i32* %21, align 4
  %19424 = icmp eq i32 %19374, %19423
  %19425 = or i1 %19422, %19424
  %19426 = load i32, i32* %22, align 4
  %19427 = icmp eq i32 %19374, %19426
  %19428 = or i1 %19425, %19427
  %19429 = load i32, i32* %23, align 4
  %19430 = icmp eq i32 %19374, %19429
  %19431 = or i1 %19428, %19430
  %19432 = load i32, i32* %24, align 4
  %19433 = icmp eq i32 %19374, %19432
  %19434 = or i1 %19431, %19433
  %19435 = load i32, i32* %25, align 4
  %19436 = icmp eq i32 %19374, %19435
  %19437 = or i1 %19434, %19436
  %19438 = load i32, i32* %26, align 4
  %19439 = icmp eq i32 %19374, %19438
  %19440 = or i1 %19437, %19439
  %19441 = load i32, i32* %27, align 4
  %19442 = icmp eq i32 %19374, %19441
  %19443 = or i1 %19440, %19442
  %19444 = load i32, i32* %28, align 4
  %19445 = icmp eq i32 %19374, %19444
  %19446 = or i1 %19443, %19445
  %19447 = load i32, i32* %29, align 4
  %19448 = icmp eq i32 %19374, %19447
  %19449 = or i1 %19446, %19448
  %19450 = load i32, i32* %30, align 4
  %19451 = icmp eq i32 %19374, %19450
  %19452 = or i1 %19449, %19451
  %19453 = load i32, i32* %31, align 4
  %19454 = icmp eq i32 %19374, %19453
  %19455 = or i1 %19452, %19454
  %19456 = load i32, i32* %32, align 4
  %19457 = icmp eq i32 %19374, %19456
  %19458 = or i1 %19455, %19457
  %19459 = load i32, i32* %33, align 4
  %19460 = icmp eq i32 %19374, %19459
  %19461 = or i1 %19458, %19460
  %19462 = load i32, i32* %34, align 4
  %19463 = icmp eq i32 %19374, %19462
  %19464 = or i1 %19461, %19463
  %19465 = load i32, i32* %35, align 4
  %19466 = icmp eq i32 %19374, %19465
  %19467 = or i1 %19464, %19466
  %19468 = load i32, i32* %36, align 4
  %19469 = icmp eq i32 %19374, %19468
  %19470 = or i1 %19467, %19469
  %19471 = load i32, i32* %37, align 4
  %19472 = icmp eq i32 %19374, %19471
  %19473 = or i1 %19470, %19472
  %19474 = load i32, i32* %38, align 4
  %19475 = icmp eq i32 %19374, %19474
  %19476 = or i1 %19473, %19475
  %19477 = load i32, i32* %39, align 4
  %19478 = icmp eq i32 %19374, %19477
  %19479 = or i1 %19476, %19478
  %19480 = load i32, i32* %40, align 4
  %19481 = icmp eq i32 %19374, %19480
  %19482 = or i1 %19479, %19481
  %19483 = load i32, i32* %41, align 4
  %19484 = icmp eq i32 %19374, %19483
  %19485 = or i1 %19482, %19484
  %19486 = load i32, i32* %42, align 4
  %19487 = icmp eq i32 %19374, %19486
  %19488 = or i1 %19485, %19487
  %19489 = load i32, i32* %43, align 4
  %19490 = icmp eq i32 %19374, %19489
  %19491 = or i1 %19488, %19490
  %19492 = load i32, i32* %44, align 4
  %19493 = icmp eq i32 %19374, %19492
  %19494 = or i1 %19491, %19493
  %19495 = load i32, i32* %45, align 4
  %19496 = icmp eq i32 %19374, %19495
  %19497 = or i1 %19494, %19496
  %19498 = load i32, i32* %46, align 4
  %19499 = icmp eq i32 %19374, %19498
  %19500 = or i1 %19497, %19499
  %19501 = load i32, i32* %47, align 4
  %19502 = icmp eq i32 %19374, %19501
  %19503 = or i1 %19500, %19502
  %19504 = load i32, i32* %48, align 4
  %19505 = icmp eq i32 %19374, %19504
  %19506 = or i1 %19503, %19505
  %19507 = load i32, i32* %49, align 4
  %19508 = icmp eq i32 %19374, %19507
  %19509 = or i1 %19506, %19508
  %19510 = load i32, i32* %50, align 4
  %19511 = icmp eq i32 %19374, %19510
  %19512 = or i1 %19509, %19511
  %19513 = load i32, i32* %51, align 4
  %19514 = icmp eq i32 %19374, %19513
  %19515 = or i1 %19512, %19514
  %19516 = load i32, i32* %52, align 4
  %19517 = icmp eq i32 %19374, %19516
  %19518 = or i1 %19515, %19517
  %19519 = load i32, i32* %53, align 4
  %19520 = icmp eq i32 %19374, %19519
  %19521 = or i1 %19518, %19520
  %19522 = load i32, i32* %54, align 4
  %19523 = icmp eq i32 %19374, %19522
  %19524 = or i1 %19521, %19523
  %19525 = load i32, i32* %55, align 4
  %19526 = icmp eq i32 %19374, %19525
  %19527 = or i1 %19524, %19526
  %19528 = load i32, i32* %56, align 4
  %19529 = icmp eq i32 %19374, %19528
  %19530 = or i1 %19527, %19529
  %19531 = load i32, i32* %57, align 4
  %19532 = icmp eq i32 %19374, %19531
  %19533 = or i1 %19530, %19532
  %19534 = load i32, i32* %58, align 4
  %19535 = icmp eq i32 %19374, %19534
  %19536 = or i1 %19533, %19535
  %19537 = load i32, i32* %59, align 4
  %19538 = icmp eq i32 %19374, %19537
  %19539 = or i1 %19536, %19538
  %19540 = load i32, i32* %60, align 4
  %19541 = icmp eq i32 %19374, %19540
  %19542 = or i1 %19539, %19541
  %19543 = load i32, i32* %61, align 4
  %19544 = icmp eq i32 %19374, %19543
  %19545 = or i1 %19542, %19544
  %19546 = load i32, i32* %62, align 4
  %19547 = icmp eq i32 %19374, %19546
  %19548 = or i1 %19545, %19547
  %19549 = getelementptr i8, i8 addrspace(1)* %4, i32 64
  %19550 = zext i1 %19548 to i8
  store i8 %19550, i8 addrspace(1)* %19549, align 1, !nosanitize !3
  %19551 = load i256, i256* %19373, align 4
  %19552 = add i256 2, %19184, !pc !342, !intsan !10
  %19553 = alloca i256, align 8
  store i256 %19552, i256* %19553, align 4
  %19554 = alloca i256, align 8
  call void @__device_sload(i256* %19553, i256* %19554)
  %19555 = call i32 @__hashword(i256* %19553)
  %19556 = load i32, i32* %5, align 4
  %19557 = icmp eq i32 %19555, %19556
  %19558 = or i1 false, %19557
  %19559 = load i32, i32* %6, align 4
  %19560 = icmp eq i32 %19555, %19559
  %19561 = or i1 %19558, %19560
  %19562 = load i32, i32* %7, align 4
  %19563 = icmp eq i32 %19555, %19562
  %19564 = or i1 %19561, %19563
  %19565 = load i32, i32* %8, align 4
  %19566 = icmp eq i32 %19555, %19565
  %19567 = or i1 %19564, %19566
  %19568 = load i32, i32* %9, align 4
  %19569 = icmp eq i32 %19555, %19568
  %19570 = or i1 %19567, %19569
  %19571 = load i32, i32* %10, align 4
  %19572 = icmp eq i32 %19555, %19571
  %19573 = or i1 %19570, %19572
  %19574 = load i32, i32* %11, align 4
  %19575 = icmp eq i32 %19555, %19574
  %19576 = or i1 %19573, %19575
  %19577 = load i32, i32* %12, align 4
  %19578 = icmp eq i32 %19555, %19577
  %19579 = or i1 %19576, %19578
  %19580 = load i32, i32* %13, align 4
  %19581 = icmp eq i32 %19555, %19580
  %19582 = or i1 %19579, %19581
  %19583 = load i32, i32* %14, align 4
  %19584 = icmp eq i32 %19555, %19583
  %19585 = or i1 %19582, %19584
  %19586 = load i32, i32* %15, align 4
  %19587 = icmp eq i32 %19555, %19586
  %19588 = or i1 %19585, %19587
  %19589 = load i32, i32* %16, align 4
  %19590 = icmp eq i32 %19555, %19589
  %19591 = or i1 %19588, %19590
  %19592 = load i32, i32* %17, align 4
  %19593 = icmp eq i32 %19555, %19592
  %19594 = or i1 %19591, %19593
  %19595 = load i32, i32* %18, align 4
  %19596 = icmp eq i32 %19555, %19595
  %19597 = or i1 %19594, %19596
  %19598 = load i32, i32* %19, align 4
  %19599 = icmp eq i32 %19555, %19598
  %19600 = or i1 %19597, %19599
  %19601 = load i32, i32* %20, align 4
  %19602 = icmp eq i32 %19555, %19601
  %19603 = or i1 %19600, %19602
  %19604 = load i32, i32* %21, align 4
  %19605 = icmp eq i32 %19555, %19604
  %19606 = or i1 %19603, %19605
  %19607 = load i32, i32* %22, align 4
  %19608 = icmp eq i32 %19555, %19607
  %19609 = or i1 %19606, %19608
  %19610 = load i32, i32* %23, align 4
  %19611 = icmp eq i32 %19555, %19610
  %19612 = or i1 %19609, %19611
  %19613 = load i32, i32* %24, align 4
  %19614 = icmp eq i32 %19555, %19613
  %19615 = or i1 %19612, %19614
  %19616 = load i32, i32* %25, align 4
  %19617 = icmp eq i32 %19555, %19616
  %19618 = or i1 %19615, %19617
  %19619 = load i32, i32* %26, align 4
  %19620 = icmp eq i32 %19555, %19619
  %19621 = or i1 %19618, %19620
  %19622 = load i32, i32* %27, align 4
  %19623 = icmp eq i32 %19555, %19622
  %19624 = or i1 %19621, %19623
  %19625 = load i32, i32* %28, align 4
  %19626 = icmp eq i32 %19555, %19625
  %19627 = or i1 %19624, %19626
  %19628 = load i32, i32* %29, align 4
  %19629 = icmp eq i32 %19555, %19628
  %19630 = or i1 %19627, %19629
  %19631 = load i32, i32* %30, align 4
  %19632 = icmp eq i32 %19555, %19631
  %19633 = or i1 %19630, %19632
  %19634 = load i32, i32* %31, align 4
  %19635 = icmp eq i32 %19555, %19634
  %19636 = or i1 %19633, %19635
  %19637 = load i32, i32* %32, align 4
  %19638 = icmp eq i32 %19555, %19637
  %19639 = or i1 %19636, %19638
  %19640 = load i32, i32* %33, align 4
  %19641 = icmp eq i32 %19555, %19640
  %19642 = or i1 %19639, %19641
  %19643 = load i32, i32* %34, align 4
  %19644 = icmp eq i32 %19555, %19643
  %19645 = or i1 %19642, %19644
  %19646 = load i32, i32* %35, align 4
  %19647 = icmp eq i32 %19555, %19646
  %19648 = or i1 %19645, %19647
  %19649 = load i32, i32* %36, align 4
  %19650 = icmp eq i32 %19555, %19649
  %19651 = or i1 %19648, %19650
  %19652 = load i32, i32* %37, align 4
  %19653 = icmp eq i32 %19555, %19652
  %19654 = or i1 %19651, %19653
  %19655 = load i32, i32* %38, align 4
  %19656 = icmp eq i32 %19555, %19655
  %19657 = or i1 %19654, %19656
  %19658 = load i32, i32* %39, align 4
  %19659 = icmp eq i32 %19555, %19658
  %19660 = or i1 %19657, %19659
  %19661 = load i32, i32* %40, align 4
  %19662 = icmp eq i32 %19555, %19661
  %19663 = or i1 %19660, %19662
  %19664 = load i32, i32* %41, align 4
  %19665 = icmp eq i32 %19555, %19664
  %19666 = or i1 %19663, %19665
  %19667 = load i32, i32* %42, align 4
  %19668 = icmp eq i32 %19555, %19667
  %19669 = or i1 %19666, %19668
  %19670 = load i32, i32* %43, align 4
  %19671 = icmp eq i32 %19555, %19670
  %19672 = or i1 %19669, %19671
  %19673 = load i32, i32* %44, align 4
  %19674 = icmp eq i32 %19555, %19673
  %19675 = or i1 %19672, %19674
  %19676 = load i32, i32* %45, align 4
  %19677 = icmp eq i32 %19555, %19676
  %19678 = or i1 %19675, %19677
  %19679 = load i32, i32* %46, align 4
  %19680 = icmp eq i32 %19555, %19679
  %19681 = or i1 %19678, %19680
  %19682 = load i32, i32* %47, align 4
  %19683 = icmp eq i32 %19555, %19682
  %19684 = or i1 %19681, %19683
  %19685 = load i32, i32* %48, align 4
  %19686 = icmp eq i32 %19555, %19685
  %19687 = or i1 %19684, %19686
  %19688 = load i32, i32* %49, align 4
  %19689 = icmp eq i32 %19555, %19688
  %19690 = or i1 %19687, %19689
  %19691 = load i32, i32* %50, align 4
  %19692 = icmp eq i32 %19555, %19691
  %19693 = or i1 %19690, %19692
  %19694 = load i32, i32* %51, align 4
  %19695 = icmp eq i32 %19555, %19694
  %19696 = or i1 %19693, %19695
  %19697 = load i32, i32* %52, align 4
  %19698 = icmp eq i32 %19555, %19697
  %19699 = or i1 %19696, %19698
  %19700 = load i32, i32* %53, align 4
  %19701 = icmp eq i32 %19555, %19700
  %19702 = or i1 %19699, %19701
  %19703 = load i32, i32* %54, align 4
  %19704 = icmp eq i32 %19555, %19703
  %19705 = or i1 %19702, %19704
  %19706 = load i32, i32* %55, align 4
  %19707 = icmp eq i32 %19555, %19706
  %19708 = or i1 %19705, %19707
  %19709 = load i32, i32* %56, align 4
  %19710 = icmp eq i32 %19555, %19709
  %19711 = or i1 %19708, %19710
  %19712 = load i32, i32* %57, align 4
  %19713 = icmp eq i32 %19555, %19712
  %19714 = or i1 %19711, %19713
  %19715 = load i32, i32* %58, align 4
  %19716 = icmp eq i32 %19555, %19715
  %19717 = or i1 %19714, %19716
  %19718 = load i32, i32* %59, align 4
  %19719 = icmp eq i32 %19555, %19718
  %19720 = or i1 %19717, %19719
  %19721 = load i32, i32* %60, align 4
  %19722 = icmp eq i32 %19555, %19721
  %19723 = or i1 %19720, %19722
  %19724 = load i32, i32* %61, align 4
  %19725 = icmp eq i32 %19555, %19724
  %19726 = or i1 %19723, %19725
  %19727 = load i32, i32* %62, align 4
  %19728 = icmp eq i32 %19555, %19727
  %19729 = or i1 %19726, %19728
  %19730 = getelementptr i8, i8 addrspace(1)* %4, i32 65
  %19731 = zext i1 %19729 to i8
  store i8 %19731, i8 addrspace(1)* %19730, align 1, !nosanitize !3
  %19732 = load i256, i256* %19554, align 4
  %19733 = alloca i256, align 8
  store i256 %19732, i256* %19733, align 4
  %19734 = alloca i256, align 8
  store i256 1, i256* %19734, align 4
  %19735 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %19733, i256* %19734, i256* %19735), !pc !343, !intsan !6
  %19736 = load i256, i256* %19735, align 4
  %19737 = and i256 255, %19736
  %19738 = trunc i256 %19170 to i64
  store i64 %19738, i64* %JMP_TARGET_PTR, align 4
  %19739 = load i64, i64* %STACK_DEP_PTR, align 4
  %19740 = add i64 %19739, 1
  store i64 %19740, i64* %STACK_DEP_PTR, align 4
  %19741 = load i64, i64* %STACK_DEP_PTR, align 4
  %19742 = getelementptr i256, i256* %STACK, i64 %19741
  store i256 %19170, i256* %19742, align 4
  %19743 = load i64, i64* %STACK_DEP_PTR, align 4
  %19744 = add i64 %19743, 1
  store i64 %19744, i64* %STACK_DEP_PTR, align 4
  %19745 = load i64, i64* %STACK_DEP_PTR, align 4
  %19746 = getelementptr i256, i256* %STACK, i64 %19745
  store i256 %19370, i256* %19746, align 4
  %19747 = load i64, i64* %STACK_DEP_PTR, align 4
  %19748 = add i64 %19747, 1
  store i64 %19748, i64* %STACK_DEP_PTR, align 4
  %19749 = load i64, i64* %STACK_DEP_PTR, align 4
  %19750 = getelementptr i256, i256* %STACK, i64 %19749
  store i256 %19551, i256* %19750, align 4
  %19751 = load i64, i64* %STACK_DEP_PTR, align 4
  %19752 = add i64 %19751, 1
  store i64 %19752, i64* %STACK_DEP_PTR, align 4
  %19753 = load i64, i64* %STACK_DEP_PTR, align 4
  %19754 = getelementptr i256, i256* %STACK, i64 %19753
  store i256 %19737, i256* %19754, align 4
  br label %JumpTable, !EVMBB !4

.7136:                                            ; preds = %35424, %25951, %2007, %JumpTable
  %19755 = load i64, i64* %STACK_DEP_PTR, align 4
  %19756 = add i64 %19755, 1
  store i64 %19756, i64* %STACK_DEP_PTR, align 4
  %19757 = load i64, i64* %STACK_DEP_PTR, align 4
  %19758 = getelementptr i256, i256* %STACK, i64 %19757
  store i256 0, i256* %19758, align 4
  %19759 = load i64, i64* %STACK_DEP_PTR, align 4
  %19760 = add i64 %19759, 1
  store i64 %19760, i64* %STACK_DEP_PTR, align 4
  %19761 = load i64, i64* %STACK_DEP_PTR, align 4
  %19762 = getelementptr i256, i256* %STACK, i64 %19761
  store i256 1, i256* %19762, align 4
  %19763 = load i64, i64* %STACK_DEP_PTR, align 4
  %19764 = add i64 %19763, 1
  store i64 %19764, i64* %STACK_DEP_PTR, align 4
  %19765 = load i64, i64* %STACK_DEP_PTR, align 4
  %19766 = getelementptr i256, i256* %STACK, i64 %19765
  store i256 1, i256* %19766, align 4
  br label %.7150

.7150:                                            ; preds = %20483, %.7136, %JumpTable
  %19767 = load i64, i64* %remaing_gas, align 4
  %19768 = icmp ugt i64 192, %19767
  br i1 %19768, label %Abort, label %19769

19769:                                            ; preds = %.7150
  %19770 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19771 = xor i32 %19770, 2806
  %19772 = urem i32 %19771, 4096
  %19773 = getelementptr i8, i8 addrspace(1)* %4, i32 %19772
  %19774 = load i8, i8 addrspace(1)* %19773, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %19773, align 1, !nosanitize !3
  store i32 1403, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19775 = sub i64 %19767, 192
  store i64 %19775, i64* %remaing_gas, align 4
  %19776 = load i64, i64* %STACK_DEP_PTR, align 4
  %19777 = getelementptr i256, i256* %STACK, i64 %19776
  %19778 = load i256, i256* %19777, align 4
  %19779 = load i64, i64* %STACK_DEP_PTR, align 4
  %19780 = sub i64 %19779, 1
  store i64 %19780, i64* %STACK_DEP_PTR, align 4
  %19781 = alloca i256, align 8
  store i256 5, i256* %19781, align 4
  %19782 = alloca i256, align 8
  call void @__device_sload(i256* %19781, i256* %19782)
  %19783 = call i32 @__hashword(i256* %19781)
  %19784 = load i32, i32* %5, align 4
  %19785 = icmp eq i32 %19783, %19784
  %19786 = or i1 false, %19785
  %19787 = load i32, i32* %6, align 4
  %19788 = icmp eq i32 %19783, %19787
  %19789 = or i1 %19786, %19788
  %19790 = load i32, i32* %7, align 4
  %19791 = icmp eq i32 %19783, %19790
  %19792 = or i1 %19789, %19791
  %19793 = load i32, i32* %8, align 4
  %19794 = icmp eq i32 %19783, %19793
  %19795 = or i1 %19792, %19794
  %19796 = load i32, i32* %9, align 4
  %19797 = icmp eq i32 %19783, %19796
  %19798 = or i1 %19795, %19797
  %19799 = load i32, i32* %10, align 4
  %19800 = icmp eq i32 %19783, %19799
  %19801 = or i1 %19798, %19800
  %19802 = load i32, i32* %11, align 4
  %19803 = icmp eq i32 %19783, %19802
  %19804 = or i1 %19801, %19803
  %19805 = load i32, i32* %12, align 4
  %19806 = icmp eq i32 %19783, %19805
  %19807 = or i1 %19804, %19806
  %19808 = load i32, i32* %13, align 4
  %19809 = icmp eq i32 %19783, %19808
  %19810 = or i1 %19807, %19809
  %19811 = load i32, i32* %14, align 4
  %19812 = icmp eq i32 %19783, %19811
  %19813 = or i1 %19810, %19812
  %19814 = load i32, i32* %15, align 4
  %19815 = icmp eq i32 %19783, %19814
  %19816 = or i1 %19813, %19815
  %19817 = load i32, i32* %16, align 4
  %19818 = icmp eq i32 %19783, %19817
  %19819 = or i1 %19816, %19818
  %19820 = load i32, i32* %17, align 4
  %19821 = icmp eq i32 %19783, %19820
  %19822 = or i1 %19819, %19821
  %19823 = load i32, i32* %18, align 4
  %19824 = icmp eq i32 %19783, %19823
  %19825 = or i1 %19822, %19824
  %19826 = load i32, i32* %19, align 4
  %19827 = icmp eq i32 %19783, %19826
  %19828 = or i1 %19825, %19827
  %19829 = load i32, i32* %20, align 4
  %19830 = icmp eq i32 %19783, %19829
  %19831 = or i1 %19828, %19830
  %19832 = load i32, i32* %21, align 4
  %19833 = icmp eq i32 %19783, %19832
  %19834 = or i1 %19831, %19833
  %19835 = load i32, i32* %22, align 4
  %19836 = icmp eq i32 %19783, %19835
  %19837 = or i1 %19834, %19836
  %19838 = load i32, i32* %23, align 4
  %19839 = icmp eq i32 %19783, %19838
  %19840 = or i1 %19837, %19839
  %19841 = load i32, i32* %24, align 4
  %19842 = icmp eq i32 %19783, %19841
  %19843 = or i1 %19840, %19842
  %19844 = load i32, i32* %25, align 4
  %19845 = icmp eq i32 %19783, %19844
  %19846 = or i1 %19843, %19845
  %19847 = load i32, i32* %26, align 4
  %19848 = icmp eq i32 %19783, %19847
  %19849 = or i1 %19846, %19848
  %19850 = load i32, i32* %27, align 4
  %19851 = icmp eq i32 %19783, %19850
  %19852 = or i1 %19849, %19851
  %19853 = load i32, i32* %28, align 4
  %19854 = icmp eq i32 %19783, %19853
  %19855 = or i1 %19852, %19854
  %19856 = load i32, i32* %29, align 4
  %19857 = icmp eq i32 %19783, %19856
  %19858 = or i1 %19855, %19857
  %19859 = load i32, i32* %30, align 4
  %19860 = icmp eq i32 %19783, %19859
  %19861 = or i1 %19858, %19860
  %19862 = load i32, i32* %31, align 4
  %19863 = icmp eq i32 %19783, %19862
  %19864 = or i1 %19861, %19863
  %19865 = load i32, i32* %32, align 4
  %19866 = icmp eq i32 %19783, %19865
  %19867 = or i1 %19864, %19866
  %19868 = load i32, i32* %33, align 4
  %19869 = icmp eq i32 %19783, %19868
  %19870 = or i1 %19867, %19869
  %19871 = load i32, i32* %34, align 4
  %19872 = icmp eq i32 %19783, %19871
  %19873 = or i1 %19870, %19872
  %19874 = load i32, i32* %35, align 4
  %19875 = icmp eq i32 %19783, %19874
  %19876 = or i1 %19873, %19875
  %19877 = load i32, i32* %36, align 4
  %19878 = icmp eq i32 %19783, %19877
  %19879 = or i1 %19876, %19878
  %19880 = load i32, i32* %37, align 4
  %19881 = icmp eq i32 %19783, %19880
  %19882 = or i1 %19879, %19881
  %19883 = load i32, i32* %38, align 4
  %19884 = icmp eq i32 %19783, %19883
  %19885 = or i1 %19882, %19884
  %19886 = load i32, i32* %39, align 4
  %19887 = icmp eq i32 %19783, %19886
  %19888 = or i1 %19885, %19887
  %19889 = load i32, i32* %40, align 4
  %19890 = icmp eq i32 %19783, %19889
  %19891 = or i1 %19888, %19890
  %19892 = load i32, i32* %41, align 4
  %19893 = icmp eq i32 %19783, %19892
  %19894 = or i1 %19891, %19893
  %19895 = load i32, i32* %42, align 4
  %19896 = icmp eq i32 %19783, %19895
  %19897 = or i1 %19894, %19896
  %19898 = load i32, i32* %43, align 4
  %19899 = icmp eq i32 %19783, %19898
  %19900 = or i1 %19897, %19899
  %19901 = load i32, i32* %44, align 4
  %19902 = icmp eq i32 %19783, %19901
  %19903 = or i1 %19900, %19902
  %19904 = load i32, i32* %45, align 4
  %19905 = icmp eq i32 %19783, %19904
  %19906 = or i1 %19903, %19905
  %19907 = load i32, i32* %46, align 4
  %19908 = icmp eq i32 %19783, %19907
  %19909 = or i1 %19906, %19908
  %19910 = load i32, i32* %47, align 4
  %19911 = icmp eq i32 %19783, %19910
  %19912 = or i1 %19909, %19911
  %19913 = load i32, i32* %48, align 4
  %19914 = icmp eq i32 %19783, %19913
  %19915 = or i1 %19912, %19914
  %19916 = load i32, i32* %49, align 4
  %19917 = icmp eq i32 %19783, %19916
  %19918 = or i1 %19915, %19917
  %19919 = load i32, i32* %50, align 4
  %19920 = icmp eq i32 %19783, %19919
  %19921 = or i1 %19918, %19920
  %19922 = load i32, i32* %51, align 4
  %19923 = icmp eq i32 %19783, %19922
  %19924 = or i1 %19921, %19923
  %19925 = load i32, i32* %52, align 4
  %19926 = icmp eq i32 %19783, %19925
  %19927 = or i1 %19924, %19926
  %19928 = load i32, i32* %53, align 4
  %19929 = icmp eq i32 %19783, %19928
  %19930 = or i1 %19927, %19929
  %19931 = load i32, i32* %54, align 4
  %19932 = icmp eq i32 %19783, %19931
  %19933 = or i1 %19930, %19932
  %19934 = load i32, i32* %55, align 4
  %19935 = icmp eq i32 %19783, %19934
  %19936 = or i1 %19933, %19935
  %19937 = load i32, i32* %56, align 4
  %19938 = icmp eq i32 %19783, %19937
  %19939 = or i1 %19936, %19938
  %19940 = load i32, i32* %57, align 4
  %19941 = icmp eq i32 %19783, %19940
  %19942 = or i1 %19939, %19941
  %19943 = load i32, i32* %58, align 4
  %19944 = icmp eq i32 %19783, %19943
  %19945 = or i1 %19942, %19944
  %19946 = load i32, i32* %59, align 4
  %19947 = icmp eq i32 %19783, %19946
  %19948 = or i1 %19945, %19947
  %19949 = load i32, i32* %60, align 4
  %19950 = icmp eq i32 %19783, %19949
  %19951 = or i1 %19948, %19950
  %19952 = load i32, i32* %61, align 4
  %19953 = icmp eq i32 %19783, %19952
  %19954 = or i1 %19951, %19953
  %19955 = load i32, i32* %62, align 4
  %19956 = icmp eq i32 %19783, %19955
  %19957 = or i1 %19954, %19956
  %19958 = getelementptr i8, i8 addrspace(1)* %4, i32 66
  %19959 = zext i1 %19957 to i8
  store i8 %19959, i8 addrspace(1)* %19958, align 1, !nosanitize !3
  %19960 = load i256, i256* %19782, align 4
  %19961 = icmp ugt i256 %19778, %19960
  %19962 = icmp eq i1 %19961, false
  %19963 = icmp eq i1 %19962, false
  %19964 = trunc i256 7310 to i64
  %jump.check192 = icmp ne i1 %19963, false
  %19965 = load i64, i64* %STACK_DEP_PTR, align 4
  %19966 = add i64 %19965, 1
  store i64 %19966, i64* %STACK_DEP_PTR, align 4
  %19967 = load i64, i64* %STACK_DEP_PTR, align 4
  %19968 = getelementptr i256, i256* %STACK, i64 %19967
  store i256 %19778, i256* %19968, align 4
  br i1 %jump.check192, label %.7310, label %.7162, !EVMBB !4

.7162:                                            ; preds = %19769
  %19969 = load i64, i64* %remaing_gas, align 4
  %19970 = icmp ugt i64 576, %19969
  br i1 %19970, label %Abort, label %19971

19971:                                            ; preds = %.7162
  %19972 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19973 = xor i32 %19972, 3616
  %19974 = urem i32 %19973, 4096
  %19975 = getelementptr i8, i8 addrspace(1)* %4, i32 %19974
  %19976 = load i8, i8 addrspace(1)* %19975, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %19975, align 1, !nosanitize !3
  store i32 1808, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %19977 = sub i64 %19969, 576
  store i64 %19977, i64* %remaing_gas, align 4
  %19978 = load i64, i64* %STACK_DEP_PTR, align 4
  %19979 = getelementptr i256, i256* %STACK, i64 %19978
  %19980 = load i256, i256* %19979, align 4
  %19981 = load i64, i64* %STACK_DEP_PTR, align 4
  %19982 = sub i64 %19981, 1
  store i64 %19982, i64* %STACK_DEP_PTR, align 4
  %19983 = load i64, i64* %STACK_DEP_PTR, align 4
  %19984 = getelementptr i256, i256* %STACK, i64 %19983
  %19985 = load i256, i256* %19984, align 4
  %19986 = load i64, i64* %STACK_DEP_PTR, align 4
  %19987 = sub i64 %19986, 1
  store i64 %19987, i64* %STACK_DEP_PTR, align 4
  %19988 = trunc i256 0 to i64
  %19989 = alloca i256, align 8
  store i256 %19985, i256* %19989, align 4
  %19990 = bitcast i256* %19989 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %19988, i8* %19990, i64 32)
  %19991 = add i256 32, 0, !pc !344, !intsan !10
  %19992 = trunc i256 %19991 to i64
  %19993 = alloca i256, align 8
  store i256 4, i256* %19993, align 4
  %19994 = bitcast i256* %19993 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %19992, i8* %19994, i64 32)
  %19995 = add i256 32, %19991, !pc !345, !intsan !10
  %19996 = trunc i256 0 to i32
  %19997 = trunc i256 %19995 to i32
  %19998 = getelementptr inbounds i8, i8* %MEMORY, i32 %19996
  %19999 = alloca i256, align 8
  %20000 = bitcast i256* %19999 to i8*
  call void @__device_sha3(i8* %19998, i32 %19997, i8* %20000)
  %20001 = load i256, i256* %19999, align 4
  %20002 = add i256 0, %20001, !pc !346, !intsan !10
  %20003 = alloca i256, align 8
  store i256 %20002, i256* %20003, align 4
  %20004 = alloca i256, align 8
  call void @__device_sload(i256* %20003, i256* %20004)
  %20005 = call i32 @__hashword(i256* %20003)
  %20006 = load i32, i32* %5, align 4
  %20007 = icmp eq i32 %20005, %20006
  %20008 = or i1 false, %20007
  %20009 = load i32, i32* %6, align 4
  %20010 = icmp eq i32 %20005, %20009
  %20011 = or i1 %20008, %20010
  %20012 = load i32, i32* %7, align 4
  %20013 = icmp eq i32 %20005, %20012
  %20014 = or i1 %20011, %20013
  %20015 = load i32, i32* %8, align 4
  %20016 = icmp eq i32 %20005, %20015
  %20017 = or i1 %20014, %20016
  %20018 = load i32, i32* %9, align 4
  %20019 = icmp eq i32 %20005, %20018
  %20020 = or i1 %20017, %20019
  %20021 = load i32, i32* %10, align 4
  %20022 = icmp eq i32 %20005, %20021
  %20023 = or i1 %20020, %20022
  %20024 = load i32, i32* %11, align 4
  %20025 = icmp eq i32 %20005, %20024
  %20026 = or i1 %20023, %20025
  %20027 = load i32, i32* %12, align 4
  %20028 = icmp eq i32 %20005, %20027
  %20029 = or i1 %20026, %20028
  %20030 = load i32, i32* %13, align 4
  %20031 = icmp eq i32 %20005, %20030
  %20032 = or i1 %20029, %20031
  %20033 = load i32, i32* %14, align 4
  %20034 = icmp eq i32 %20005, %20033
  %20035 = or i1 %20032, %20034
  %20036 = load i32, i32* %15, align 4
  %20037 = icmp eq i32 %20005, %20036
  %20038 = or i1 %20035, %20037
  %20039 = load i32, i32* %16, align 4
  %20040 = icmp eq i32 %20005, %20039
  %20041 = or i1 %20038, %20040
  %20042 = load i32, i32* %17, align 4
  %20043 = icmp eq i32 %20005, %20042
  %20044 = or i1 %20041, %20043
  %20045 = load i32, i32* %18, align 4
  %20046 = icmp eq i32 %20005, %20045
  %20047 = or i1 %20044, %20046
  %20048 = load i32, i32* %19, align 4
  %20049 = icmp eq i32 %20005, %20048
  %20050 = or i1 %20047, %20049
  %20051 = load i32, i32* %20, align 4
  %20052 = icmp eq i32 %20005, %20051
  %20053 = or i1 %20050, %20052
  %20054 = load i32, i32* %21, align 4
  %20055 = icmp eq i32 %20005, %20054
  %20056 = or i1 %20053, %20055
  %20057 = load i32, i32* %22, align 4
  %20058 = icmp eq i32 %20005, %20057
  %20059 = or i1 %20056, %20058
  %20060 = load i32, i32* %23, align 4
  %20061 = icmp eq i32 %20005, %20060
  %20062 = or i1 %20059, %20061
  %20063 = load i32, i32* %24, align 4
  %20064 = icmp eq i32 %20005, %20063
  %20065 = or i1 %20062, %20064
  %20066 = load i32, i32* %25, align 4
  %20067 = icmp eq i32 %20005, %20066
  %20068 = or i1 %20065, %20067
  %20069 = load i32, i32* %26, align 4
  %20070 = icmp eq i32 %20005, %20069
  %20071 = or i1 %20068, %20070
  %20072 = load i32, i32* %27, align 4
  %20073 = icmp eq i32 %20005, %20072
  %20074 = or i1 %20071, %20073
  %20075 = load i32, i32* %28, align 4
  %20076 = icmp eq i32 %20005, %20075
  %20077 = or i1 %20074, %20076
  %20078 = load i32, i32* %29, align 4
  %20079 = icmp eq i32 %20005, %20078
  %20080 = or i1 %20077, %20079
  %20081 = load i32, i32* %30, align 4
  %20082 = icmp eq i32 %20005, %20081
  %20083 = or i1 %20080, %20082
  %20084 = load i32, i32* %31, align 4
  %20085 = icmp eq i32 %20005, %20084
  %20086 = or i1 %20083, %20085
  %20087 = load i32, i32* %32, align 4
  %20088 = icmp eq i32 %20005, %20087
  %20089 = or i1 %20086, %20088
  %20090 = load i32, i32* %33, align 4
  %20091 = icmp eq i32 %20005, %20090
  %20092 = or i1 %20089, %20091
  %20093 = load i32, i32* %34, align 4
  %20094 = icmp eq i32 %20005, %20093
  %20095 = or i1 %20092, %20094
  %20096 = load i32, i32* %35, align 4
  %20097 = icmp eq i32 %20005, %20096
  %20098 = or i1 %20095, %20097
  %20099 = load i32, i32* %36, align 4
  %20100 = icmp eq i32 %20005, %20099
  %20101 = or i1 %20098, %20100
  %20102 = load i32, i32* %37, align 4
  %20103 = icmp eq i32 %20005, %20102
  %20104 = or i1 %20101, %20103
  %20105 = load i32, i32* %38, align 4
  %20106 = icmp eq i32 %20005, %20105
  %20107 = or i1 %20104, %20106
  %20108 = load i32, i32* %39, align 4
  %20109 = icmp eq i32 %20005, %20108
  %20110 = or i1 %20107, %20109
  %20111 = load i32, i32* %40, align 4
  %20112 = icmp eq i32 %20005, %20111
  %20113 = or i1 %20110, %20112
  %20114 = load i32, i32* %41, align 4
  %20115 = icmp eq i32 %20005, %20114
  %20116 = or i1 %20113, %20115
  %20117 = load i32, i32* %42, align 4
  %20118 = icmp eq i32 %20005, %20117
  %20119 = or i1 %20116, %20118
  %20120 = load i32, i32* %43, align 4
  %20121 = icmp eq i32 %20005, %20120
  %20122 = or i1 %20119, %20121
  %20123 = load i32, i32* %44, align 4
  %20124 = icmp eq i32 %20005, %20123
  %20125 = or i1 %20122, %20124
  %20126 = load i32, i32* %45, align 4
  %20127 = icmp eq i32 %20005, %20126
  %20128 = or i1 %20125, %20127
  %20129 = load i32, i32* %46, align 4
  %20130 = icmp eq i32 %20005, %20129
  %20131 = or i1 %20128, %20130
  %20132 = load i32, i32* %47, align 4
  %20133 = icmp eq i32 %20005, %20132
  %20134 = or i1 %20131, %20133
  %20135 = load i32, i32* %48, align 4
  %20136 = icmp eq i32 %20005, %20135
  %20137 = or i1 %20134, %20136
  %20138 = load i32, i32* %49, align 4
  %20139 = icmp eq i32 %20005, %20138
  %20140 = or i1 %20137, %20139
  %20141 = load i32, i32* %50, align 4
  %20142 = icmp eq i32 %20005, %20141
  %20143 = or i1 %20140, %20142
  %20144 = load i32, i32* %51, align 4
  %20145 = icmp eq i32 %20005, %20144
  %20146 = or i1 %20143, %20145
  %20147 = load i32, i32* %52, align 4
  %20148 = icmp eq i32 %20005, %20147
  %20149 = or i1 %20146, %20148
  %20150 = load i32, i32* %53, align 4
  %20151 = icmp eq i32 %20005, %20150
  %20152 = or i1 %20149, %20151
  %20153 = load i32, i32* %54, align 4
  %20154 = icmp eq i32 %20005, %20153
  %20155 = or i1 %20152, %20154
  %20156 = load i32, i32* %55, align 4
  %20157 = icmp eq i32 %20005, %20156
  %20158 = or i1 %20155, %20157
  %20159 = load i32, i32* %56, align 4
  %20160 = icmp eq i32 %20005, %20159
  %20161 = or i1 %20158, %20160
  %20162 = load i32, i32* %57, align 4
  %20163 = icmp eq i32 %20005, %20162
  %20164 = or i1 %20161, %20163
  %20165 = load i32, i32* %58, align 4
  %20166 = icmp eq i32 %20005, %20165
  %20167 = or i1 %20164, %20166
  %20168 = load i32, i32* %59, align 4
  %20169 = icmp eq i32 %20005, %20168
  %20170 = or i1 %20167, %20169
  %20171 = load i32, i32* %60, align 4
  %20172 = icmp eq i32 %20005, %20171
  %20173 = or i1 %20170, %20172
  %20174 = load i32, i32* %61, align 4
  %20175 = icmp eq i32 %20005, %20174
  %20176 = or i1 %20173, %20175
  %20177 = load i32, i32* %62, align 4
  %20178 = icmp eq i32 %20005, %20177
  %20179 = or i1 %20176, %20178
  %20180 = getelementptr i8, i8 addrspace(1)* %4, i32 67
  %20181 = zext i1 %20179 to i8
  store i8 %20181, i8 addrspace(1)* %20180, align 1, !nosanitize !3
  %20182 = load i256, i256* %20004, align 4
  %20183 = alloca i256, align 8
  store i256 %20182, i256* %20183, align 4
  %20184 = alloca i256, align 8
  store i256 1, i256* %20184, align 4
  %20185 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %20183, i256* %20184, i256* %20185), !pc !347, !intsan !6
  %20186 = load i256, i256* %20185, align 4
  %20187 = and i256 1461501637330902918203684832716283019655932542975, %20186
  %20188 = trunc i256 11418 to i64
  %20189 = load i64, i64* %STACK_DEP_PTR, align 4
  %20190 = add i64 %20189, 1
  store i64 %20190, i64* %STACK_DEP_PTR, align 4
  %20191 = load i64, i64* %STACK_DEP_PTR, align 4
  %20192 = getelementptr i256, i256* %STACK, i64 %20191
  store i256 %19985, i256* %20192, align 4
  %20193 = load i64, i64* %STACK_DEP_PTR, align 4
  %20194 = add i64 %20193, 1
  store i64 %20194, i64* %STACK_DEP_PTR, align 4
  %20195 = load i64, i64* %STACK_DEP_PTR, align 4
  %20196 = getelementptr i256, i256* %STACK, i64 %20195
  store i256 %19980, i256* %20196, align 4
  %20197 = load i64, i64* %STACK_DEP_PTR, align 4
  %20198 = add i64 %20197, 1
  store i64 %20198, i64* %STACK_DEP_PTR, align 4
  %20199 = load i64, i64* %STACK_DEP_PTR, align 4
  %20200 = getelementptr i256, i256* %STACK, i64 %20199
  store i256 7224, i256* %20200, align 4
  %20201 = load i64, i64* %STACK_DEP_PTR, align 4
  %20202 = add i64 %20201, 1
  store i64 %20202, i64* %STACK_DEP_PTR, align 4
  %20203 = load i64, i64* %STACK_DEP_PTR, align 4
  %20204 = getelementptr i256, i256* %STACK, i64 %20203
  store i256 %20187, i256* %20204, align 4
  br label %.11418, !EVMBB !4

.7224:                                            ; preds = %JumpTable
  %20205 = load i64, i64* %remaing_gas, align 4
  %20206 = icmp ugt i64 576, %20205
  br i1 %20206, label %Abort, label %20207

20207:                                            ; preds = %.7224
  %20208 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20209 = xor i32 %20208, 2083
  %20210 = urem i32 %20209, 4096
  %20211 = getelementptr i8, i8 addrspace(1)* %4, i32 %20210
  %20212 = load i8, i8 addrspace(1)* %20211, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20211, align 1, !nosanitize !3
  store i32 1041, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20213 = sub i64 %20205, 576
  store i64 %20213, i64* %remaing_gas, align 4
  %20214 = load i64, i64* %STACK_DEP_PTR, align 4
  %20215 = getelementptr i256, i256* %STACK, i64 %20214
  %20216 = load i256, i256* %20215, align 4
  %20217 = load i64, i64* %STACK_DEP_PTR, align 4
  %20218 = sub i64 %20217, 1
  store i64 %20218, i64* %STACK_DEP_PTR, align 4
  %20219 = load i64, i64* %STACK_DEP_PTR, align 4
  %20220 = getelementptr i256, i256* %STACK, i64 %20219
  %20221 = load i256, i256* %20220, align 4
  %20222 = load i64, i64* %STACK_DEP_PTR, align 4
  %20223 = sub i64 %20222, 1
  store i64 %20223, i64* %STACK_DEP_PTR, align 4
  %20224 = trunc i256 0 to i64
  %20225 = alloca i256, align 8
  store i256 %20221, i256* %20225, align 4
  %20226 = bitcast i256* %20225 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %20224, i8* %20226, i64 32)
  %20227 = add i256 32, 0, !pc !348, !intsan !10
  %20228 = trunc i256 %20227 to i64
  %20229 = alloca i256, align 8
  store i256 4, i256* %20229, align 4
  %20230 = bitcast i256* %20229 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %20228, i8* %20230, i64 32)
  %20231 = add i256 32, %20227, !pc !349, !intsan !10
  %20232 = trunc i256 0 to i32
  %20233 = trunc i256 %20231 to i32
  %20234 = getelementptr inbounds i8, i8* %MEMORY, i32 %20232
  %20235 = alloca i256, align 8
  %20236 = bitcast i256* %20235 to i8*
  call void @__device_sha3(i8* %20234, i32 %20233, i8* %20236)
  %20237 = load i256, i256* %20235, align 4
  %20238 = add i256 0, %20237, !pc !350, !intsan !10
  %20239 = alloca i256, align 8
  store i256 %20238, i256* %20239, align 4
  %20240 = alloca i256, align 8
  call void @__device_sload(i256* %20239, i256* %20240)
  %20241 = call i32 @__hashword(i256* %20239)
  %20242 = load i32, i32* %5, align 4
  %20243 = icmp eq i32 %20241, %20242
  %20244 = or i1 false, %20243
  %20245 = load i32, i32* %6, align 4
  %20246 = icmp eq i32 %20241, %20245
  %20247 = or i1 %20244, %20246
  %20248 = load i32, i32* %7, align 4
  %20249 = icmp eq i32 %20241, %20248
  %20250 = or i1 %20247, %20249
  %20251 = load i32, i32* %8, align 4
  %20252 = icmp eq i32 %20241, %20251
  %20253 = or i1 %20250, %20252
  %20254 = load i32, i32* %9, align 4
  %20255 = icmp eq i32 %20241, %20254
  %20256 = or i1 %20253, %20255
  %20257 = load i32, i32* %10, align 4
  %20258 = icmp eq i32 %20241, %20257
  %20259 = or i1 %20256, %20258
  %20260 = load i32, i32* %11, align 4
  %20261 = icmp eq i32 %20241, %20260
  %20262 = or i1 %20259, %20261
  %20263 = load i32, i32* %12, align 4
  %20264 = icmp eq i32 %20241, %20263
  %20265 = or i1 %20262, %20264
  %20266 = load i32, i32* %13, align 4
  %20267 = icmp eq i32 %20241, %20266
  %20268 = or i1 %20265, %20267
  %20269 = load i32, i32* %14, align 4
  %20270 = icmp eq i32 %20241, %20269
  %20271 = or i1 %20268, %20270
  %20272 = load i32, i32* %15, align 4
  %20273 = icmp eq i32 %20241, %20272
  %20274 = or i1 %20271, %20273
  %20275 = load i32, i32* %16, align 4
  %20276 = icmp eq i32 %20241, %20275
  %20277 = or i1 %20274, %20276
  %20278 = load i32, i32* %17, align 4
  %20279 = icmp eq i32 %20241, %20278
  %20280 = or i1 %20277, %20279
  %20281 = load i32, i32* %18, align 4
  %20282 = icmp eq i32 %20241, %20281
  %20283 = or i1 %20280, %20282
  %20284 = load i32, i32* %19, align 4
  %20285 = icmp eq i32 %20241, %20284
  %20286 = or i1 %20283, %20285
  %20287 = load i32, i32* %20, align 4
  %20288 = icmp eq i32 %20241, %20287
  %20289 = or i1 %20286, %20288
  %20290 = load i32, i32* %21, align 4
  %20291 = icmp eq i32 %20241, %20290
  %20292 = or i1 %20289, %20291
  %20293 = load i32, i32* %22, align 4
  %20294 = icmp eq i32 %20241, %20293
  %20295 = or i1 %20292, %20294
  %20296 = load i32, i32* %23, align 4
  %20297 = icmp eq i32 %20241, %20296
  %20298 = or i1 %20295, %20297
  %20299 = load i32, i32* %24, align 4
  %20300 = icmp eq i32 %20241, %20299
  %20301 = or i1 %20298, %20300
  %20302 = load i32, i32* %25, align 4
  %20303 = icmp eq i32 %20241, %20302
  %20304 = or i1 %20301, %20303
  %20305 = load i32, i32* %26, align 4
  %20306 = icmp eq i32 %20241, %20305
  %20307 = or i1 %20304, %20306
  %20308 = load i32, i32* %27, align 4
  %20309 = icmp eq i32 %20241, %20308
  %20310 = or i1 %20307, %20309
  %20311 = load i32, i32* %28, align 4
  %20312 = icmp eq i32 %20241, %20311
  %20313 = or i1 %20310, %20312
  %20314 = load i32, i32* %29, align 4
  %20315 = icmp eq i32 %20241, %20314
  %20316 = or i1 %20313, %20315
  %20317 = load i32, i32* %30, align 4
  %20318 = icmp eq i32 %20241, %20317
  %20319 = or i1 %20316, %20318
  %20320 = load i32, i32* %31, align 4
  %20321 = icmp eq i32 %20241, %20320
  %20322 = or i1 %20319, %20321
  %20323 = load i32, i32* %32, align 4
  %20324 = icmp eq i32 %20241, %20323
  %20325 = or i1 %20322, %20324
  %20326 = load i32, i32* %33, align 4
  %20327 = icmp eq i32 %20241, %20326
  %20328 = or i1 %20325, %20327
  %20329 = load i32, i32* %34, align 4
  %20330 = icmp eq i32 %20241, %20329
  %20331 = or i1 %20328, %20330
  %20332 = load i32, i32* %35, align 4
  %20333 = icmp eq i32 %20241, %20332
  %20334 = or i1 %20331, %20333
  %20335 = load i32, i32* %36, align 4
  %20336 = icmp eq i32 %20241, %20335
  %20337 = or i1 %20334, %20336
  %20338 = load i32, i32* %37, align 4
  %20339 = icmp eq i32 %20241, %20338
  %20340 = or i1 %20337, %20339
  %20341 = load i32, i32* %38, align 4
  %20342 = icmp eq i32 %20241, %20341
  %20343 = or i1 %20340, %20342
  %20344 = load i32, i32* %39, align 4
  %20345 = icmp eq i32 %20241, %20344
  %20346 = or i1 %20343, %20345
  %20347 = load i32, i32* %40, align 4
  %20348 = icmp eq i32 %20241, %20347
  %20349 = or i1 %20346, %20348
  %20350 = load i32, i32* %41, align 4
  %20351 = icmp eq i32 %20241, %20350
  %20352 = or i1 %20349, %20351
  %20353 = load i32, i32* %42, align 4
  %20354 = icmp eq i32 %20241, %20353
  %20355 = or i1 %20352, %20354
  %20356 = load i32, i32* %43, align 4
  %20357 = icmp eq i32 %20241, %20356
  %20358 = or i1 %20355, %20357
  %20359 = load i32, i32* %44, align 4
  %20360 = icmp eq i32 %20241, %20359
  %20361 = or i1 %20358, %20360
  %20362 = load i32, i32* %45, align 4
  %20363 = icmp eq i32 %20241, %20362
  %20364 = or i1 %20361, %20363
  %20365 = load i32, i32* %46, align 4
  %20366 = icmp eq i32 %20241, %20365
  %20367 = or i1 %20364, %20366
  %20368 = load i32, i32* %47, align 4
  %20369 = icmp eq i32 %20241, %20368
  %20370 = or i1 %20367, %20369
  %20371 = load i32, i32* %48, align 4
  %20372 = icmp eq i32 %20241, %20371
  %20373 = or i1 %20370, %20372
  %20374 = load i32, i32* %49, align 4
  %20375 = icmp eq i32 %20241, %20374
  %20376 = or i1 %20373, %20375
  %20377 = load i32, i32* %50, align 4
  %20378 = icmp eq i32 %20241, %20377
  %20379 = or i1 %20376, %20378
  %20380 = load i32, i32* %51, align 4
  %20381 = icmp eq i32 %20241, %20380
  %20382 = or i1 %20379, %20381
  %20383 = load i32, i32* %52, align 4
  %20384 = icmp eq i32 %20241, %20383
  %20385 = or i1 %20382, %20384
  %20386 = load i32, i32* %53, align 4
  %20387 = icmp eq i32 %20241, %20386
  %20388 = or i1 %20385, %20387
  %20389 = load i32, i32* %54, align 4
  %20390 = icmp eq i32 %20241, %20389
  %20391 = or i1 %20388, %20390
  %20392 = load i32, i32* %55, align 4
  %20393 = icmp eq i32 %20241, %20392
  %20394 = or i1 %20391, %20393
  %20395 = load i32, i32* %56, align 4
  %20396 = icmp eq i32 %20241, %20395
  %20397 = or i1 %20394, %20396
  %20398 = load i32, i32* %57, align 4
  %20399 = icmp eq i32 %20241, %20398
  %20400 = or i1 %20397, %20399
  %20401 = load i32, i32* %58, align 4
  %20402 = icmp eq i32 %20241, %20401
  %20403 = or i1 %20400, %20402
  %20404 = load i32, i32* %59, align 4
  %20405 = icmp eq i32 %20241, %20404
  %20406 = or i1 %20403, %20405
  %20407 = load i32, i32* %60, align 4
  %20408 = icmp eq i32 %20241, %20407
  %20409 = or i1 %20406, %20408
  %20410 = load i32, i32* %61, align 4
  %20411 = icmp eq i32 %20241, %20410
  %20412 = or i1 %20409, %20411
  %20413 = load i32, i32* %62, align 4
  %20414 = icmp eq i32 %20241, %20413
  %20415 = or i1 %20412, %20414
  %20416 = getelementptr i8, i8 addrspace(1)* %4, i32 68
  %20417 = zext i1 %20415 to i8
  store i8 %20417, i8 addrspace(1)* %20416, align 1, !nosanitize !3
  %20418 = load i256, i256* %20240, align 4
  %20419 = alloca i256, align 8
  store i256 %20418, i256* %20419, align 4
  %20420 = alloca i256, align 8
  store i256 1, i256* %20420, align 4
  %20421 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %20419, i256* %20420, i256* %20421), !pc !351, !intsan !6
  %20422 = load i256, i256* %20421, align 4
  %20423 = and i256 1461501637330902918203684832716283019655932542975, %20422
  %20424 = trunc i256 11418 to i64
  %20425 = load i64, i64* %STACK_DEP_PTR, align 4
  %20426 = add i64 %20425, 1
  store i64 %20426, i64* %STACK_DEP_PTR, align 4
  %20427 = load i64, i64* %STACK_DEP_PTR, align 4
  %20428 = getelementptr i256, i256* %STACK, i64 %20427
  store i256 %20221, i256* %20428, align 4
  %20429 = load i64, i64* %STACK_DEP_PTR, align 4
  %20430 = add i64 %20429, 1
  store i64 %20430, i64* %STACK_DEP_PTR, align 4
  %20431 = load i64, i64* %STACK_DEP_PTR, align 4
  %20432 = getelementptr i256, i256* %STACK, i64 %20431
  store i256 %20216, i256* %20432, align 4
  %20433 = load i64, i64* %STACK_DEP_PTR, align 4
  %20434 = add i64 %20433, 1
  store i64 %20434, i64* %STACK_DEP_PTR, align 4
  %20435 = load i64, i64* %STACK_DEP_PTR, align 4
  %20436 = getelementptr i256, i256* %STACK, i64 %20435
  store i256 7287, i256* %20436, align 4
  %20437 = load i64, i64* %STACK_DEP_PTR, align 4
  %20438 = add i64 %20437, 1
  store i64 %20438, i64* %STACK_DEP_PTR, align 4
  %20439 = load i64, i64* %STACK_DEP_PTR, align 4
  %20440 = getelementptr i256, i256* %STACK, i64 %20439
  store i256 %20423, i256* %20440, align 4
  br label %.11418, !EVMBB !4

.7287:                                            ; preds = %JumpTable
  %20441 = load i64, i64* %remaing_gas, align 4
  %20442 = icmp ugt i64 144, %20441
  br i1 %20442, label %Abort, label %20443

20443:                                            ; preds = %.7287
  %20444 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20445 = xor i32 %20444, 1669
  %20446 = urem i32 %20445, 4096
  %20447 = getelementptr i8, i8 addrspace(1)* %4, i32 %20446
  %20448 = load i8, i8 addrspace(1)* %20447, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20447, align 1, !nosanitize !3
  store i32 834, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20449 = sub i64 %20441, 144
  store i64 %20449, i64* %remaing_gas, align 4
  %20450 = load i64, i64* %STACK_DEP_PTR, align 4
  %20451 = getelementptr i256, i256* %STACK, i64 %20450
  %20452 = load i256, i256* %20451, align 4
  %20453 = load i64, i64* %STACK_DEP_PTR, align 4
  %20454 = sub i64 %20453, 1
  store i64 %20454, i64* %STACK_DEP_PTR, align 4
  %20455 = load i64, i64* %STACK_DEP_PTR, align 4
  %20456 = getelementptr i256, i256* %STACK, i64 %20455
  %20457 = load i256, i256* %20456, align 4
  %20458 = load i64, i64* %STACK_DEP_PTR, align 4
  %20459 = sub i64 %20458, 1
  store i64 %20459, i64* %STACK_DEP_PTR, align 4
  %20460 = icmp ult i256 %20452, %20457
  %20461 = icmp eq i1 %20460, false
  %20462 = trunc i256 7297 to i64
  %jump.check193 = icmp ne i1 %20461, false
  br i1 %jump.check193, label %.7297, label %.7294, !EVMBB !4

.7294:                                            ; preds = %20443
  %20463 = load i64, i64* %STACK_DEP_PTR, align 4
  %20464 = getelementptr i256, i256* %STACK, i64 %20463
  %20465 = load i256, i256* %20464, align 4
  %20466 = load i64, i64* %STACK_DEP_PTR, align 4
  %20467 = sub i64 %20466, 1
  store i64 %20467, i64* %STACK_DEP_PTR, align 4
  %20468 = load i64, i64* %STACK_DEP_PTR, align 4
  %20469 = getelementptr i256, i256* %STACK, i64 %20468
  %20470 = load i256, i256* %20469, align 4
  %20471 = load i64, i64* %STACK_DEP_PTR, align 4
  %20472 = sub i64 %20471, 1
  store i64 %20472, i64* %STACK_DEP_PTR, align 4
  %20473 = load i64, i64* %STACK_DEP_PTR, align 4
  %20474 = add i64 %20473, 1
  store i64 %20474, i64* %STACK_DEP_PTR, align 4
  %20475 = load i64, i64* %STACK_DEP_PTR, align 4
  %20476 = getelementptr i256, i256* %STACK, i64 %20475
  store i256 %20465, i256* %20476, align 4
  %20477 = load i64, i64* %STACK_DEP_PTR, align 4
  %20478 = add i64 %20477, 1
  store i64 %20478, i64* %STACK_DEP_PTR, align 4
  %20479 = load i64, i64* %STACK_DEP_PTR, align 4
  %20480 = getelementptr i256, i256* %STACK, i64 %20479
  store i256 %20465, i256* %20480, align 4
  br label %.7297

.7297:                                            ; preds = %.7294, %20443, %JumpTable
  %20481 = load i64, i64* %remaing_gas, align 4
  %20482 = icmp ugt i64 128, %20481
  br i1 %20482, label %Abort, label %20483

20483:                                            ; preds = %.7297
  %20484 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20485 = xor i32 %20484, 1388
  %20486 = urem i32 %20485, 4096
  %20487 = getelementptr i8, i8 addrspace(1)* %4, i32 %20486
  %20488 = load i8, i8 addrspace(1)* %20487, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20487, align 1, !nosanitize !3
  store i32 694, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20489 = sub i64 %20481, 128
  store i64 %20489, i64* %remaing_gas, align 4
  %20490 = load i64, i64* %STACK_DEP_PTR, align 4
  %20491 = getelementptr i256, i256* %STACK, i64 %20490
  %20492 = load i256, i256* %20491, align 4
  %20493 = load i64, i64* %STACK_DEP_PTR, align 4
  %20494 = sub i64 %20493, 1
  store i64 %20494, i64* %STACK_DEP_PTR, align 4
  %20495 = add i256 1, %20492, !pc !352, !intsan !10
  %20496 = trunc i256 7150 to i64
  %20497 = load i64, i64* %STACK_DEP_PTR, align 4
  %20498 = add i64 %20497, 1
  store i64 %20498, i64* %STACK_DEP_PTR, align 4
  %20499 = load i64, i64* %STACK_DEP_PTR, align 4
  %20500 = getelementptr i256, i256* %STACK, i64 %20499
  store i256 %20495, i256* %20500, align 4
  br label %.7150, !EVMBB !4

.7310:                                            ; preds = %19769, %JumpTable
  %20501 = load i64, i64* %remaing_gas, align 4
  %20502 = icmp ugt i64 272, %20501
  br i1 %20502, label %Abort, label %20503

20503:                                            ; preds = %.7310
  %20504 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20505 = xor i32 %20504, 1531
  %20506 = urem i32 %20505, 4096
  %20507 = getelementptr i8, i8 addrspace(1)* %4, i32 %20506
  %20508 = load i8, i8 addrspace(1)* %20507, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20507, align 1, !nosanitize !3
  store i32 765, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20509 = sub i64 %20501, 272
  store i64 %20509, i64* %remaing_gas, align 4
  %20510 = load i64, i64* %STACK_DEP_PTR, align 4
  %20511 = getelementptr i256, i256* %STACK, i64 %20510
  %20512 = load i256, i256* %20511, align 4
  %20513 = load i64, i64* %STACK_DEP_PTR, align 4
  %20514 = sub i64 %20513, 1
  store i64 %20514, i64* %STACK_DEP_PTR, align 4
  %20515 = load i64, i64* %STACK_DEP_PTR, align 4
  %20516 = getelementptr i256, i256* %STACK, i64 %20515
  %20517 = load i256, i256* %20516, align 4
  %20518 = load i64, i64* %STACK_DEP_PTR, align 4
  %20519 = sub i64 %20518, 1
  store i64 %20519, i64* %STACK_DEP_PTR, align 4
  %20520 = load i64, i64* %STACK_DEP_PTR, align 4
  %20521 = getelementptr i256, i256* %STACK, i64 %20520
  %20522 = load i256, i256* %20521, align 4
  %20523 = load i64, i64* %STACK_DEP_PTR, align 4
  %20524 = sub i64 %20523, 1
  store i64 %20524, i64* %STACK_DEP_PTR, align 4
  %20525 = load i64, i64* %STACK_DEP_PTR, align 4
  %20526 = getelementptr i256, i256* %STACK, i64 %20525
  %20527 = load i256, i256* %20526, align 4
  %20528 = load i64, i64* %STACK_DEP_PTR, align 4
  %20529 = sub i64 %20528, 1
  store i64 %20529, i64* %STACK_DEP_PTR, align 4
  %20530 = trunc i256 %20527 to i64
  store i64 %20530, i64* %JMP_TARGET_PTR, align 4
  %20531 = load i64, i64* %STACK_DEP_PTR, align 4
  %20532 = add i64 %20531, 1
  store i64 %20532, i64* %STACK_DEP_PTR, align 4
  %20533 = load i64, i64* %STACK_DEP_PTR, align 4
  %20534 = getelementptr i256, i256* %STACK, i64 %20533
  store i256 %20517, i256* %20534, align 4
  br label %JumpTable, !EVMBB !4

.7318:                                            ; preds = %2078, %JumpTable
  %20535 = load i64, i64* %remaing_gas, align 4
  %20536 = icmp ugt i64 200, %20535
  br i1 %20536, label %Abort, label %20537

20537:                                            ; preds = %.7318
  %20538 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20539 = xor i32 %20538, 3250
  %20540 = urem i32 %20539, 4096
  %20541 = getelementptr i8, i8 addrspace(1)* %4, i32 %20540
  %20542 = load i8, i8 addrspace(1)* %20541, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20541, align 1, !nosanitize !3
  store i32 1625, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20543 = sub i64 %20535, 200
  store i64 %20543, i64* %remaing_gas, align 4
  %20544 = alloca i256, align 8
  store i256 8, i256* %20544, align 4
  %20545 = alloca i256, align 8
  call void @__device_sload(i256* %20544, i256* %20545)
  %20546 = call i32 @__hashword(i256* %20544)
  %20547 = load i32, i32* %5, align 4
  %20548 = icmp eq i32 %20546, %20547
  %20549 = or i1 false, %20548
  %20550 = load i32, i32* %6, align 4
  %20551 = icmp eq i32 %20546, %20550
  %20552 = or i1 %20549, %20551
  %20553 = load i32, i32* %7, align 4
  %20554 = icmp eq i32 %20546, %20553
  %20555 = or i1 %20552, %20554
  %20556 = load i32, i32* %8, align 4
  %20557 = icmp eq i32 %20546, %20556
  %20558 = or i1 %20555, %20557
  %20559 = load i32, i32* %9, align 4
  %20560 = icmp eq i32 %20546, %20559
  %20561 = or i1 %20558, %20560
  %20562 = load i32, i32* %10, align 4
  %20563 = icmp eq i32 %20546, %20562
  %20564 = or i1 %20561, %20563
  %20565 = load i32, i32* %11, align 4
  %20566 = icmp eq i32 %20546, %20565
  %20567 = or i1 %20564, %20566
  %20568 = load i32, i32* %12, align 4
  %20569 = icmp eq i32 %20546, %20568
  %20570 = or i1 %20567, %20569
  %20571 = load i32, i32* %13, align 4
  %20572 = icmp eq i32 %20546, %20571
  %20573 = or i1 %20570, %20572
  %20574 = load i32, i32* %14, align 4
  %20575 = icmp eq i32 %20546, %20574
  %20576 = or i1 %20573, %20575
  %20577 = load i32, i32* %15, align 4
  %20578 = icmp eq i32 %20546, %20577
  %20579 = or i1 %20576, %20578
  %20580 = load i32, i32* %16, align 4
  %20581 = icmp eq i32 %20546, %20580
  %20582 = or i1 %20579, %20581
  %20583 = load i32, i32* %17, align 4
  %20584 = icmp eq i32 %20546, %20583
  %20585 = or i1 %20582, %20584
  %20586 = load i32, i32* %18, align 4
  %20587 = icmp eq i32 %20546, %20586
  %20588 = or i1 %20585, %20587
  %20589 = load i32, i32* %19, align 4
  %20590 = icmp eq i32 %20546, %20589
  %20591 = or i1 %20588, %20590
  %20592 = load i32, i32* %20, align 4
  %20593 = icmp eq i32 %20546, %20592
  %20594 = or i1 %20591, %20593
  %20595 = load i32, i32* %21, align 4
  %20596 = icmp eq i32 %20546, %20595
  %20597 = or i1 %20594, %20596
  %20598 = load i32, i32* %22, align 4
  %20599 = icmp eq i32 %20546, %20598
  %20600 = or i1 %20597, %20599
  %20601 = load i32, i32* %23, align 4
  %20602 = icmp eq i32 %20546, %20601
  %20603 = or i1 %20600, %20602
  %20604 = load i32, i32* %24, align 4
  %20605 = icmp eq i32 %20546, %20604
  %20606 = or i1 %20603, %20605
  %20607 = load i32, i32* %25, align 4
  %20608 = icmp eq i32 %20546, %20607
  %20609 = or i1 %20606, %20608
  %20610 = load i32, i32* %26, align 4
  %20611 = icmp eq i32 %20546, %20610
  %20612 = or i1 %20609, %20611
  %20613 = load i32, i32* %27, align 4
  %20614 = icmp eq i32 %20546, %20613
  %20615 = or i1 %20612, %20614
  %20616 = load i32, i32* %28, align 4
  %20617 = icmp eq i32 %20546, %20616
  %20618 = or i1 %20615, %20617
  %20619 = load i32, i32* %29, align 4
  %20620 = icmp eq i32 %20546, %20619
  %20621 = or i1 %20618, %20620
  %20622 = load i32, i32* %30, align 4
  %20623 = icmp eq i32 %20546, %20622
  %20624 = or i1 %20621, %20623
  %20625 = load i32, i32* %31, align 4
  %20626 = icmp eq i32 %20546, %20625
  %20627 = or i1 %20624, %20626
  %20628 = load i32, i32* %32, align 4
  %20629 = icmp eq i32 %20546, %20628
  %20630 = or i1 %20627, %20629
  %20631 = load i32, i32* %33, align 4
  %20632 = icmp eq i32 %20546, %20631
  %20633 = or i1 %20630, %20632
  %20634 = load i32, i32* %34, align 4
  %20635 = icmp eq i32 %20546, %20634
  %20636 = or i1 %20633, %20635
  %20637 = load i32, i32* %35, align 4
  %20638 = icmp eq i32 %20546, %20637
  %20639 = or i1 %20636, %20638
  %20640 = load i32, i32* %36, align 4
  %20641 = icmp eq i32 %20546, %20640
  %20642 = or i1 %20639, %20641
  %20643 = load i32, i32* %37, align 4
  %20644 = icmp eq i32 %20546, %20643
  %20645 = or i1 %20642, %20644
  %20646 = load i32, i32* %38, align 4
  %20647 = icmp eq i32 %20546, %20646
  %20648 = or i1 %20645, %20647
  %20649 = load i32, i32* %39, align 4
  %20650 = icmp eq i32 %20546, %20649
  %20651 = or i1 %20648, %20650
  %20652 = load i32, i32* %40, align 4
  %20653 = icmp eq i32 %20546, %20652
  %20654 = or i1 %20651, %20653
  %20655 = load i32, i32* %41, align 4
  %20656 = icmp eq i32 %20546, %20655
  %20657 = or i1 %20654, %20656
  %20658 = load i32, i32* %42, align 4
  %20659 = icmp eq i32 %20546, %20658
  %20660 = or i1 %20657, %20659
  %20661 = load i32, i32* %43, align 4
  %20662 = icmp eq i32 %20546, %20661
  %20663 = or i1 %20660, %20662
  %20664 = load i32, i32* %44, align 4
  %20665 = icmp eq i32 %20546, %20664
  %20666 = or i1 %20663, %20665
  %20667 = load i32, i32* %45, align 4
  %20668 = icmp eq i32 %20546, %20667
  %20669 = or i1 %20666, %20668
  %20670 = load i32, i32* %46, align 4
  %20671 = icmp eq i32 %20546, %20670
  %20672 = or i1 %20669, %20671
  %20673 = load i32, i32* %47, align 4
  %20674 = icmp eq i32 %20546, %20673
  %20675 = or i1 %20672, %20674
  %20676 = load i32, i32* %48, align 4
  %20677 = icmp eq i32 %20546, %20676
  %20678 = or i1 %20675, %20677
  %20679 = load i32, i32* %49, align 4
  %20680 = icmp eq i32 %20546, %20679
  %20681 = or i1 %20678, %20680
  %20682 = load i32, i32* %50, align 4
  %20683 = icmp eq i32 %20546, %20682
  %20684 = or i1 %20681, %20683
  %20685 = load i32, i32* %51, align 4
  %20686 = icmp eq i32 %20546, %20685
  %20687 = or i1 %20684, %20686
  %20688 = load i32, i32* %52, align 4
  %20689 = icmp eq i32 %20546, %20688
  %20690 = or i1 %20687, %20689
  %20691 = load i32, i32* %53, align 4
  %20692 = icmp eq i32 %20546, %20691
  %20693 = or i1 %20690, %20692
  %20694 = load i32, i32* %54, align 4
  %20695 = icmp eq i32 %20546, %20694
  %20696 = or i1 %20693, %20695
  %20697 = load i32, i32* %55, align 4
  %20698 = icmp eq i32 %20546, %20697
  %20699 = or i1 %20696, %20698
  %20700 = load i32, i32* %56, align 4
  %20701 = icmp eq i32 %20546, %20700
  %20702 = or i1 %20699, %20701
  %20703 = load i32, i32* %57, align 4
  %20704 = icmp eq i32 %20546, %20703
  %20705 = or i1 %20702, %20704
  %20706 = load i32, i32* %58, align 4
  %20707 = icmp eq i32 %20546, %20706
  %20708 = or i1 %20705, %20707
  %20709 = load i32, i32* %59, align 4
  %20710 = icmp eq i32 %20546, %20709
  %20711 = or i1 %20708, %20710
  %20712 = load i32, i32* %60, align 4
  %20713 = icmp eq i32 %20546, %20712
  %20714 = or i1 %20711, %20713
  %20715 = load i32, i32* %61, align 4
  %20716 = icmp eq i32 %20546, %20715
  %20717 = or i1 %20714, %20716
  %20718 = load i32, i32* %62, align 4
  %20719 = icmp eq i32 %20546, %20718
  %20720 = or i1 %20717, %20719
  %20721 = getelementptr i8, i8 addrspace(1)* %4, i32 69
  %20722 = zext i1 %20720 to i8
  store i8 %20722, i8 addrspace(1)* %20721, align 1, !nosanitize !3
  %20723 = load i256, i256* %20545, align 4
  %20724 = alloca i256, align 8
  store i256 %20723, i256* %20724, align 4
  %20725 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %20725, align 4
  %20726 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %20724, i256* %20725, i256* %20726), !pc !353, !intsan !6
  %20727 = load i256, i256* %20726, align 4
  %20728 = and i256 255, %20727
  %20729 = icmp eq i256 %20728, 0
  %20730 = icmp eq i1 %20729, false
  %20731 = trunc i256 7347 to i64
  %jump.check80 = icmp ne i1 %20730, false
  %20732 = load i64, i64* %STACK_DEP_PTR, align 4
  %20733 = add i64 %20732, 1
  store i64 %20733, i64* %STACK_DEP_PTR, align 4
  %20734 = load i64, i64* %STACK_DEP_PTR, align 4
  %20735 = getelementptr i256, i256* %STACK, i64 %20734
  store i256 0, i256* %20735, align 4
  br i1 %jump.check80, label %.7347, label %.7343, !EVMBB !4

.7343:                                            ; preds = %20537
  %20736 = load i64, i64* %remaing_gas, align 4
  %20737 = icmp ugt i64 40, %20736
  br i1 %20737, label %Abort, label %20738

20738:                                            ; preds = %.7343
  %20739 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20740 = xor i32 %20739, 2055
  %20741 = urem i32 %20740, 4096
  %20742 = getelementptr i8, i8 addrspace(1)* %4, i32 %20741
  %20743 = load i8, i8 addrspace(1)* %20742, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20742, align 1, !nosanitize !3
  store i32 1027, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20744 = sub i64 %20736, 40
  store i64 %20744, i64* %remaing_gas, align 4
  %20745 = load i64, i64* %STACK_DEP_PTR, align 4
  %20746 = sub i64 %20745, 0
  store i64 %20746, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.7347:                                            ; preds = %20537, %JumpTable
  %20747 = load i64, i64* %remaing_gas, align 4
  %20748 = icmp ugt i64 184, %20747
  br i1 %20748, label %Abort, label %20749

20749:                                            ; preds = %.7347
  %20750 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20751 = xor i32 %20750, 772
  %20752 = urem i32 %20751, 4096
  %20753 = getelementptr i8, i8 addrspace(1)* %4, i32 %20752
  %20754 = load i8, i8 addrspace(1)* %20753, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20753, align 1, !nosanitize !3
  store i32 386, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20755 = sub i64 %20747, 184
  store i64 %20755, i64* %remaing_gas, align 4
  %20756 = load i256, i256* %0, align 4
  %20757 = and i256 1461501637330902918203684832716283019655932542975, %20756
  %20758 = alloca i256, align 8
  store i256 7, i256* %20758, align 4
  %20759 = alloca i256, align 8
  call void @__device_sload(i256* %20758, i256* %20759)
  %20760 = call i32 @__hashword(i256* %20758)
  %20761 = load i32, i32* %5, align 4
  %20762 = icmp eq i32 %20760, %20761
  %20763 = or i1 false, %20762
  %20764 = load i32, i32* %6, align 4
  %20765 = icmp eq i32 %20760, %20764
  %20766 = or i1 %20763, %20765
  %20767 = load i32, i32* %7, align 4
  %20768 = icmp eq i32 %20760, %20767
  %20769 = or i1 %20766, %20768
  %20770 = load i32, i32* %8, align 4
  %20771 = icmp eq i32 %20760, %20770
  %20772 = or i1 %20769, %20771
  %20773 = load i32, i32* %9, align 4
  %20774 = icmp eq i32 %20760, %20773
  %20775 = or i1 %20772, %20774
  %20776 = load i32, i32* %10, align 4
  %20777 = icmp eq i32 %20760, %20776
  %20778 = or i1 %20775, %20777
  %20779 = load i32, i32* %11, align 4
  %20780 = icmp eq i32 %20760, %20779
  %20781 = or i1 %20778, %20780
  %20782 = load i32, i32* %12, align 4
  %20783 = icmp eq i32 %20760, %20782
  %20784 = or i1 %20781, %20783
  %20785 = load i32, i32* %13, align 4
  %20786 = icmp eq i32 %20760, %20785
  %20787 = or i1 %20784, %20786
  %20788 = load i32, i32* %14, align 4
  %20789 = icmp eq i32 %20760, %20788
  %20790 = or i1 %20787, %20789
  %20791 = load i32, i32* %15, align 4
  %20792 = icmp eq i32 %20760, %20791
  %20793 = or i1 %20790, %20792
  %20794 = load i32, i32* %16, align 4
  %20795 = icmp eq i32 %20760, %20794
  %20796 = or i1 %20793, %20795
  %20797 = load i32, i32* %17, align 4
  %20798 = icmp eq i32 %20760, %20797
  %20799 = or i1 %20796, %20798
  %20800 = load i32, i32* %18, align 4
  %20801 = icmp eq i32 %20760, %20800
  %20802 = or i1 %20799, %20801
  %20803 = load i32, i32* %19, align 4
  %20804 = icmp eq i32 %20760, %20803
  %20805 = or i1 %20802, %20804
  %20806 = load i32, i32* %20, align 4
  %20807 = icmp eq i32 %20760, %20806
  %20808 = or i1 %20805, %20807
  %20809 = load i32, i32* %21, align 4
  %20810 = icmp eq i32 %20760, %20809
  %20811 = or i1 %20808, %20810
  %20812 = load i32, i32* %22, align 4
  %20813 = icmp eq i32 %20760, %20812
  %20814 = or i1 %20811, %20813
  %20815 = load i32, i32* %23, align 4
  %20816 = icmp eq i32 %20760, %20815
  %20817 = or i1 %20814, %20816
  %20818 = load i32, i32* %24, align 4
  %20819 = icmp eq i32 %20760, %20818
  %20820 = or i1 %20817, %20819
  %20821 = load i32, i32* %25, align 4
  %20822 = icmp eq i32 %20760, %20821
  %20823 = or i1 %20820, %20822
  %20824 = load i32, i32* %26, align 4
  %20825 = icmp eq i32 %20760, %20824
  %20826 = or i1 %20823, %20825
  %20827 = load i32, i32* %27, align 4
  %20828 = icmp eq i32 %20760, %20827
  %20829 = or i1 %20826, %20828
  %20830 = load i32, i32* %28, align 4
  %20831 = icmp eq i32 %20760, %20830
  %20832 = or i1 %20829, %20831
  %20833 = load i32, i32* %29, align 4
  %20834 = icmp eq i32 %20760, %20833
  %20835 = or i1 %20832, %20834
  %20836 = load i32, i32* %30, align 4
  %20837 = icmp eq i32 %20760, %20836
  %20838 = or i1 %20835, %20837
  %20839 = load i32, i32* %31, align 4
  %20840 = icmp eq i32 %20760, %20839
  %20841 = or i1 %20838, %20840
  %20842 = load i32, i32* %32, align 4
  %20843 = icmp eq i32 %20760, %20842
  %20844 = or i1 %20841, %20843
  %20845 = load i32, i32* %33, align 4
  %20846 = icmp eq i32 %20760, %20845
  %20847 = or i1 %20844, %20846
  %20848 = load i32, i32* %34, align 4
  %20849 = icmp eq i32 %20760, %20848
  %20850 = or i1 %20847, %20849
  %20851 = load i32, i32* %35, align 4
  %20852 = icmp eq i32 %20760, %20851
  %20853 = or i1 %20850, %20852
  %20854 = load i32, i32* %36, align 4
  %20855 = icmp eq i32 %20760, %20854
  %20856 = or i1 %20853, %20855
  %20857 = load i32, i32* %37, align 4
  %20858 = icmp eq i32 %20760, %20857
  %20859 = or i1 %20856, %20858
  %20860 = load i32, i32* %38, align 4
  %20861 = icmp eq i32 %20760, %20860
  %20862 = or i1 %20859, %20861
  %20863 = load i32, i32* %39, align 4
  %20864 = icmp eq i32 %20760, %20863
  %20865 = or i1 %20862, %20864
  %20866 = load i32, i32* %40, align 4
  %20867 = icmp eq i32 %20760, %20866
  %20868 = or i1 %20865, %20867
  %20869 = load i32, i32* %41, align 4
  %20870 = icmp eq i32 %20760, %20869
  %20871 = or i1 %20868, %20870
  %20872 = load i32, i32* %42, align 4
  %20873 = icmp eq i32 %20760, %20872
  %20874 = or i1 %20871, %20873
  %20875 = load i32, i32* %43, align 4
  %20876 = icmp eq i32 %20760, %20875
  %20877 = or i1 %20874, %20876
  %20878 = load i32, i32* %44, align 4
  %20879 = icmp eq i32 %20760, %20878
  %20880 = or i1 %20877, %20879
  %20881 = load i32, i32* %45, align 4
  %20882 = icmp eq i32 %20760, %20881
  %20883 = or i1 %20880, %20882
  %20884 = load i32, i32* %46, align 4
  %20885 = icmp eq i32 %20760, %20884
  %20886 = or i1 %20883, %20885
  %20887 = load i32, i32* %47, align 4
  %20888 = icmp eq i32 %20760, %20887
  %20889 = or i1 %20886, %20888
  %20890 = load i32, i32* %48, align 4
  %20891 = icmp eq i32 %20760, %20890
  %20892 = or i1 %20889, %20891
  %20893 = load i32, i32* %49, align 4
  %20894 = icmp eq i32 %20760, %20893
  %20895 = or i1 %20892, %20894
  %20896 = load i32, i32* %50, align 4
  %20897 = icmp eq i32 %20760, %20896
  %20898 = or i1 %20895, %20897
  %20899 = load i32, i32* %51, align 4
  %20900 = icmp eq i32 %20760, %20899
  %20901 = or i1 %20898, %20900
  %20902 = load i32, i32* %52, align 4
  %20903 = icmp eq i32 %20760, %20902
  %20904 = or i1 %20901, %20903
  %20905 = load i32, i32* %53, align 4
  %20906 = icmp eq i32 %20760, %20905
  %20907 = or i1 %20904, %20906
  %20908 = load i32, i32* %54, align 4
  %20909 = icmp eq i32 %20760, %20908
  %20910 = or i1 %20907, %20909
  %20911 = load i32, i32* %55, align 4
  %20912 = icmp eq i32 %20760, %20911
  %20913 = or i1 %20910, %20912
  %20914 = load i32, i32* %56, align 4
  %20915 = icmp eq i32 %20760, %20914
  %20916 = or i1 %20913, %20915
  %20917 = load i32, i32* %57, align 4
  %20918 = icmp eq i32 %20760, %20917
  %20919 = or i1 %20916, %20918
  %20920 = load i32, i32* %58, align 4
  %20921 = icmp eq i32 %20760, %20920
  %20922 = or i1 %20919, %20921
  %20923 = load i32, i32* %59, align 4
  %20924 = icmp eq i32 %20760, %20923
  %20925 = or i1 %20922, %20924
  %20926 = load i32, i32* %60, align 4
  %20927 = icmp eq i32 %20760, %20926
  %20928 = or i1 %20925, %20927
  %20929 = load i32, i32* %61, align 4
  %20930 = icmp eq i32 %20760, %20929
  %20931 = or i1 %20928, %20930
  %20932 = load i32, i32* %62, align 4
  %20933 = icmp eq i32 %20760, %20932
  %20934 = or i1 %20931, %20933
  %20935 = getelementptr i8, i8 addrspace(1)* %4, i32 70
  %20936 = zext i1 %20934 to i8
  store i8 %20936, i8 addrspace(1)* %20935, align 1, !nosanitize !3
  %20937 = load i256, i256* %20759, align 4
  %20938 = alloca i256, align 8
  store i256 %20937, i256* %20938, align 4
  %20939 = alloca i256, align 8
  store i256 1, i256* %20939, align 4
  %20940 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %20938, i256* %20939, i256* %20940), !pc !354, !intsan !6
  %20941 = load i256, i256* %20940, align 4
  %20942 = and i256 1461501637330902918203684832716283019655932542975, %20941
  %20943 = and i256 1461501637330902918203684832716283019655932542975, %20942
  %20944 = icmp eq i256 %20943, %20757
  %20945 = icmp eq i1 %20944, false
  %20946 = icmp eq i1 %20945, false
  %20947 = trunc i256 7439 to i64
  %jump.check86 = icmp ne i1 %20946, false
  br i1 %jump.check86, label %.7439, label %.7435, !EVMBB !4

.7435:                                            ; preds = %20749
  %20948 = load i64, i64* %remaing_gas, align 4
  %20949 = icmp ugt i64 16, %20948
  br i1 %20949, label %Abort, label %20950

20950:                                            ; preds = %.7435
  %20951 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20952 = xor i32 %20951, 4084
  %20953 = urem i32 %20952, 4096
  %20954 = getelementptr i8, i8 addrspace(1)* %4, i32 %20953
  %20955 = load i8, i8 addrspace(1)* %20954, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20954, align 1, !nosanitize !3
  store i32 2042, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20956 = sub i64 %20948, 16
  store i64 %20956, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.7439:                                            ; preds = %20749, %JumpTable
  %20957 = load i64, i64* %STACK_DEP_PTR, align 4
  %20958 = getelementptr i256, i256* %STACK, i64 %20957
  %20959 = load i256, i256* %20958, align 4
  %20960 = load i64, i64* %STACK_DEP_PTR, align 4
  %20961 = sub i64 %20960, 1
  store i64 %20961, i64* %STACK_DEP_PTR, align 4
  %20962 = load i64, i64* %STACK_DEP_PTR, align 4
  %20963 = add i64 %20962, 1
  store i64 %20963, i64* %STACK_DEP_PTR, align 4
  %20964 = load i64, i64* %STACK_DEP_PTR, align 4
  %20965 = getelementptr i256, i256* %STACK, i64 %20964
  store i256 1, i256* %20965, align 4
  br label %.7444

.7444:                                            ; preds = %21170, %.7439, %JumpTable
  %20966 = load i64, i64* %remaing_gas, align 4
  %20967 = icmp ugt i64 192, %20966
  br i1 %20967, label %Abort, label %20968

20968:                                            ; preds = %.7444
  %20969 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20970 = xor i32 %20969, 3052
  %20971 = urem i32 %20970, 4096
  %20972 = getelementptr i8, i8 addrspace(1)* %4, i32 %20971
  %20973 = load i8, i8 addrspace(1)* %20972, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %20972, align 1, !nosanitize !3
  store i32 1526, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %20974 = sub i64 %20966, 192
  store i64 %20974, i64* %remaing_gas, align 4
  %20975 = load i64, i64* %STACK_DEP_PTR, align 4
  %20976 = getelementptr i256, i256* %STACK, i64 %20975
  %20977 = load i256, i256* %20976, align 4
  %20978 = load i64, i64* %STACK_DEP_PTR, align 4
  %20979 = sub i64 %20978, 1
  store i64 %20979, i64* %STACK_DEP_PTR, align 4
  %20980 = alloca i256, align 8
  store i256 5, i256* %20980, align 4
  %20981 = alloca i256, align 8
  call void @__device_sload(i256* %20980, i256* %20981)
  %20982 = call i32 @__hashword(i256* %20980)
  %20983 = load i32, i32* %5, align 4
  %20984 = icmp eq i32 %20982, %20983
  %20985 = or i1 false, %20984
  %20986 = load i32, i32* %6, align 4
  %20987 = icmp eq i32 %20982, %20986
  %20988 = or i1 %20985, %20987
  %20989 = load i32, i32* %7, align 4
  %20990 = icmp eq i32 %20982, %20989
  %20991 = or i1 %20988, %20990
  %20992 = load i32, i32* %8, align 4
  %20993 = icmp eq i32 %20982, %20992
  %20994 = or i1 %20991, %20993
  %20995 = load i32, i32* %9, align 4
  %20996 = icmp eq i32 %20982, %20995
  %20997 = or i1 %20994, %20996
  %20998 = load i32, i32* %10, align 4
  %20999 = icmp eq i32 %20982, %20998
  %21000 = or i1 %20997, %20999
  %21001 = load i32, i32* %11, align 4
  %21002 = icmp eq i32 %20982, %21001
  %21003 = or i1 %21000, %21002
  %21004 = load i32, i32* %12, align 4
  %21005 = icmp eq i32 %20982, %21004
  %21006 = or i1 %21003, %21005
  %21007 = load i32, i32* %13, align 4
  %21008 = icmp eq i32 %20982, %21007
  %21009 = or i1 %21006, %21008
  %21010 = load i32, i32* %14, align 4
  %21011 = icmp eq i32 %20982, %21010
  %21012 = or i1 %21009, %21011
  %21013 = load i32, i32* %15, align 4
  %21014 = icmp eq i32 %20982, %21013
  %21015 = or i1 %21012, %21014
  %21016 = load i32, i32* %16, align 4
  %21017 = icmp eq i32 %20982, %21016
  %21018 = or i1 %21015, %21017
  %21019 = load i32, i32* %17, align 4
  %21020 = icmp eq i32 %20982, %21019
  %21021 = or i1 %21018, %21020
  %21022 = load i32, i32* %18, align 4
  %21023 = icmp eq i32 %20982, %21022
  %21024 = or i1 %21021, %21023
  %21025 = load i32, i32* %19, align 4
  %21026 = icmp eq i32 %20982, %21025
  %21027 = or i1 %21024, %21026
  %21028 = load i32, i32* %20, align 4
  %21029 = icmp eq i32 %20982, %21028
  %21030 = or i1 %21027, %21029
  %21031 = load i32, i32* %21, align 4
  %21032 = icmp eq i32 %20982, %21031
  %21033 = or i1 %21030, %21032
  %21034 = load i32, i32* %22, align 4
  %21035 = icmp eq i32 %20982, %21034
  %21036 = or i1 %21033, %21035
  %21037 = load i32, i32* %23, align 4
  %21038 = icmp eq i32 %20982, %21037
  %21039 = or i1 %21036, %21038
  %21040 = load i32, i32* %24, align 4
  %21041 = icmp eq i32 %20982, %21040
  %21042 = or i1 %21039, %21041
  %21043 = load i32, i32* %25, align 4
  %21044 = icmp eq i32 %20982, %21043
  %21045 = or i1 %21042, %21044
  %21046 = load i32, i32* %26, align 4
  %21047 = icmp eq i32 %20982, %21046
  %21048 = or i1 %21045, %21047
  %21049 = load i32, i32* %27, align 4
  %21050 = icmp eq i32 %20982, %21049
  %21051 = or i1 %21048, %21050
  %21052 = load i32, i32* %28, align 4
  %21053 = icmp eq i32 %20982, %21052
  %21054 = or i1 %21051, %21053
  %21055 = load i32, i32* %29, align 4
  %21056 = icmp eq i32 %20982, %21055
  %21057 = or i1 %21054, %21056
  %21058 = load i32, i32* %30, align 4
  %21059 = icmp eq i32 %20982, %21058
  %21060 = or i1 %21057, %21059
  %21061 = load i32, i32* %31, align 4
  %21062 = icmp eq i32 %20982, %21061
  %21063 = or i1 %21060, %21062
  %21064 = load i32, i32* %32, align 4
  %21065 = icmp eq i32 %20982, %21064
  %21066 = or i1 %21063, %21065
  %21067 = load i32, i32* %33, align 4
  %21068 = icmp eq i32 %20982, %21067
  %21069 = or i1 %21066, %21068
  %21070 = load i32, i32* %34, align 4
  %21071 = icmp eq i32 %20982, %21070
  %21072 = or i1 %21069, %21071
  %21073 = load i32, i32* %35, align 4
  %21074 = icmp eq i32 %20982, %21073
  %21075 = or i1 %21072, %21074
  %21076 = load i32, i32* %36, align 4
  %21077 = icmp eq i32 %20982, %21076
  %21078 = or i1 %21075, %21077
  %21079 = load i32, i32* %37, align 4
  %21080 = icmp eq i32 %20982, %21079
  %21081 = or i1 %21078, %21080
  %21082 = load i32, i32* %38, align 4
  %21083 = icmp eq i32 %20982, %21082
  %21084 = or i1 %21081, %21083
  %21085 = load i32, i32* %39, align 4
  %21086 = icmp eq i32 %20982, %21085
  %21087 = or i1 %21084, %21086
  %21088 = load i32, i32* %40, align 4
  %21089 = icmp eq i32 %20982, %21088
  %21090 = or i1 %21087, %21089
  %21091 = load i32, i32* %41, align 4
  %21092 = icmp eq i32 %20982, %21091
  %21093 = or i1 %21090, %21092
  %21094 = load i32, i32* %42, align 4
  %21095 = icmp eq i32 %20982, %21094
  %21096 = or i1 %21093, %21095
  %21097 = load i32, i32* %43, align 4
  %21098 = icmp eq i32 %20982, %21097
  %21099 = or i1 %21096, %21098
  %21100 = load i32, i32* %44, align 4
  %21101 = icmp eq i32 %20982, %21100
  %21102 = or i1 %21099, %21101
  %21103 = load i32, i32* %45, align 4
  %21104 = icmp eq i32 %20982, %21103
  %21105 = or i1 %21102, %21104
  %21106 = load i32, i32* %46, align 4
  %21107 = icmp eq i32 %20982, %21106
  %21108 = or i1 %21105, %21107
  %21109 = load i32, i32* %47, align 4
  %21110 = icmp eq i32 %20982, %21109
  %21111 = or i1 %21108, %21110
  %21112 = load i32, i32* %48, align 4
  %21113 = icmp eq i32 %20982, %21112
  %21114 = or i1 %21111, %21113
  %21115 = load i32, i32* %49, align 4
  %21116 = icmp eq i32 %20982, %21115
  %21117 = or i1 %21114, %21116
  %21118 = load i32, i32* %50, align 4
  %21119 = icmp eq i32 %20982, %21118
  %21120 = or i1 %21117, %21119
  %21121 = load i32, i32* %51, align 4
  %21122 = icmp eq i32 %20982, %21121
  %21123 = or i1 %21120, %21122
  %21124 = load i32, i32* %52, align 4
  %21125 = icmp eq i32 %20982, %21124
  %21126 = or i1 %21123, %21125
  %21127 = load i32, i32* %53, align 4
  %21128 = icmp eq i32 %20982, %21127
  %21129 = or i1 %21126, %21128
  %21130 = load i32, i32* %54, align 4
  %21131 = icmp eq i32 %20982, %21130
  %21132 = or i1 %21129, %21131
  %21133 = load i32, i32* %55, align 4
  %21134 = icmp eq i32 %20982, %21133
  %21135 = or i1 %21132, %21134
  %21136 = load i32, i32* %56, align 4
  %21137 = icmp eq i32 %20982, %21136
  %21138 = or i1 %21135, %21137
  %21139 = load i32, i32* %57, align 4
  %21140 = icmp eq i32 %20982, %21139
  %21141 = or i1 %21138, %21140
  %21142 = load i32, i32* %58, align 4
  %21143 = icmp eq i32 %20982, %21142
  %21144 = or i1 %21141, %21143
  %21145 = load i32, i32* %59, align 4
  %21146 = icmp eq i32 %20982, %21145
  %21147 = or i1 %21144, %21146
  %21148 = load i32, i32* %60, align 4
  %21149 = icmp eq i32 %20982, %21148
  %21150 = or i1 %21147, %21149
  %21151 = load i32, i32* %61, align 4
  %21152 = icmp eq i32 %20982, %21151
  %21153 = or i1 %21150, %21152
  %21154 = load i32, i32* %62, align 4
  %21155 = icmp eq i32 %20982, %21154
  %21156 = or i1 %21153, %21155
  %21157 = getelementptr i8, i8 addrspace(1)* %4, i32 71
  %21158 = zext i1 %21156 to i8
  store i8 %21158, i8 addrspace(1)* %21157, align 1, !nosanitize !3
  %21159 = load i256, i256* %20981, align 4
  %21160 = icmp ugt i256 %20977, %21159
  %21161 = icmp eq i1 %21160, false
  %21162 = icmp eq i1 %21161, false
  %21163 = trunc i256 7506 to i64
  %jump.check194 = icmp ne i1 %21162, false
  %21164 = load i64, i64* %STACK_DEP_PTR, align 4
  %21165 = add i64 %21164, 1
  store i64 %21165, i64* %STACK_DEP_PTR, align 4
  %21166 = load i64, i64* %STACK_DEP_PTR, align 4
  %21167 = getelementptr i256, i256* %STACK, i64 %21166
  store i256 %20977, i256* %21167, align 4
  br i1 %jump.check194, label %.7506, label %.7456, !EVMBB !4

.7456:                                            ; preds = %20968
  %21168 = load i64, i64* %remaing_gas, align 4
  %21169 = icmp ugt i64 392, %21168
  br i1 %21169, label %Abort, label %21170

21170:                                            ; preds = %.7456
  %21171 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21172 = xor i32 %21171, 2827
  %21173 = urem i32 %21172, 4096
  %21174 = getelementptr i8, i8 addrspace(1)* %4, i32 %21173
  %21175 = load i8, i8 addrspace(1)* %21174, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %21174, align 1, !nosanitize !3
  store i32 1413, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21176 = sub i64 %21168, 392
  store i64 %21176, i64* %remaing_gas, align 4
  %21177 = load i64, i64* %STACK_DEP_PTR, align 4
  %21178 = getelementptr i256, i256* %STACK, i64 %21177
  %21179 = load i256, i256* %21178, align 4
  %21180 = load i64, i64* %STACK_DEP_PTR, align 4
  %21181 = sub i64 %21180, 1
  store i64 %21181, i64* %STACK_DEP_PTR, align 4
  %21182 = trunc i256 0 to i64
  %21183 = alloca i256, align 8
  store i256 %21179, i256* %21183, align 4
  %21184 = bitcast i256* %21183 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %21182, i8* %21184, i64 32)
  %21185 = add i256 32, 0, !pc !355, !intsan !10
  %21186 = trunc i256 %21185 to i64
  %21187 = alloca i256, align 8
  store i256 4, i256* %21187, align 4
  %21188 = bitcast i256* %21187 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %21186, i8* %21188, i64 32)
  %21189 = add i256 32, %21185, !pc !356, !intsan !10
  %21190 = trunc i256 0 to i32
  %21191 = trunc i256 %21189 to i32
  %21192 = getelementptr inbounds i8, i8* %MEMORY, i32 %21190
  %21193 = alloca i256, align 8
  %21194 = bitcast i256* %21193 to i8*
  call void @__device_sha3(i8* %21192, i32 %21191, i8* %21194)
  %21195 = load i256, i256* %21193, align 4
  %21196 = add i256 2, %21195, !pc !357, !intsan !10
  %21197 = alloca i256, align 8
  store i256 %21196, i256* %21197, align 4
  %21198 = alloca i256, align 8
  call void @__device_sload(i256* %21197, i256* %21198)
  %21199 = call i32 @__hashword(i256* %21197)
  %21200 = load i32, i32* %5, align 4
  %21201 = icmp eq i32 %21199, %21200
  %21202 = or i1 false, %21201
  %21203 = load i32, i32* %6, align 4
  %21204 = icmp eq i32 %21199, %21203
  %21205 = or i1 %21202, %21204
  %21206 = load i32, i32* %7, align 4
  %21207 = icmp eq i32 %21199, %21206
  %21208 = or i1 %21205, %21207
  %21209 = load i32, i32* %8, align 4
  %21210 = icmp eq i32 %21199, %21209
  %21211 = or i1 %21208, %21210
  %21212 = load i32, i32* %9, align 4
  %21213 = icmp eq i32 %21199, %21212
  %21214 = or i1 %21211, %21213
  %21215 = load i32, i32* %10, align 4
  %21216 = icmp eq i32 %21199, %21215
  %21217 = or i1 %21214, %21216
  %21218 = load i32, i32* %11, align 4
  %21219 = icmp eq i32 %21199, %21218
  %21220 = or i1 %21217, %21219
  %21221 = load i32, i32* %12, align 4
  %21222 = icmp eq i32 %21199, %21221
  %21223 = or i1 %21220, %21222
  %21224 = load i32, i32* %13, align 4
  %21225 = icmp eq i32 %21199, %21224
  %21226 = or i1 %21223, %21225
  %21227 = load i32, i32* %14, align 4
  %21228 = icmp eq i32 %21199, %21227
  %21229 = or i1 %21226, %21228
  %21230 = load i32, i32* %15, align 4
  %21231 = icmp eq i32 %21199, %21230
  %21232 = or i1 %21229, %21231
  %21233 = load i32, i32* %16, align 4
  %21234 = icmp eq i32 %21199, %21233
  %21235 = or i1 %21232, %21234
  %21236 = load i32, i32* %17, align 4
  %21237 = icmp eq i32 %21199, %21236
  %21238 = or i1 %21235, %21237
  %21239 = load i32, i32* %18, align 4
  %21240 = icmp eq i32 %21199, %21239
  %21241 = or i1 %21238, %21240
  %21242 = load i32, i32* %19, align 4
  %21243 = icmp eq i32 %21199, %21242
  %21244 = or i1 %21241, %21243
  %21245 = load i32, i32* %20, align 4
  %21246 = icmp eq i32 %21199, %21245
  %21247 = or i1 %21244, %21246
  %21248 = load i32, i32* %21, align 4
  %21249 = icmp eq i32 %21199, %21248
  %21250 = or i1 %21247, %21249
  %21251 = load i32, i32* %22, align 4
  %21252 = icmp eq i32 %21199, %21251
  %21253 = or i1 %21250, %21252
  %21254 = load i32, i32* %23, align 4
  %21255 = icmp eq i32 %21199, %21254
  %21256 = or i1 %21253, %21255
  %21257 = load i32, i32* %24, align 4
  %21258 = icmp eq i32 %21199, %21257
  %21259 = or i1 %21256, %21258
  %21260 = load i32, i32* %25, align 4
  %21261 = icmp eq i32 %21199, %21260
  %21262 = or i1 %21259, %21261
  %21263 = load i32, i32* %26, align 4
  %21264 = icmp eq i32 %21199, %21263
  %21265 = or i1 %21262, %21264
  %21266 = load i32, i32* %27, align 4
  %21267 = icmp eq i32 %21199, %21266
  %21268 = or i1 %21265, %21267
  %21269 = load i32, i32* %28, align 4
  %21270 = icmp eq i32 %21199, %21269
  %21271 = or i1 %21268, %21270
  %21272 = load i32, i32* %29, align 4
  %21273 = icmp eq i32 %21199, %21272
  %21274 = or i1 %21271, %21273
  %21275 = load i32, i32* %30, align 4
  %21276 = icmp eq i32 %21199, %21275
  %21277 = or i1 %21274, %21276
  %21278 = load i32, i32* %31, align 4
  %21279 = icmp eq i32 %21199, %21278
  %21280 = or i1 %21277, %21279
  %21281 = load i32, i32* %32, align 4
  %21282 = icmp eq i32 %21199, %21281
  %21283 = or i1 %21280, %21282
  %21284 = load i32, i32* %33, align 4
  %21285 = icmp eq i32 %21199, %21284
  %21286 = or i1 %21283, %21285
  %21287 = load i32, i32* %34, align 4
  %21288 = icmp eq i32 %21199, %21287
  %21289 = or i1 %21286, %21288
  %21290 = load i32, i32* %35, align 4
  %21291 = icmp eq i32 %21199, %21290
  %21292 = or i1 %21289, %21291
  %21293 = load i32, i32* %36, align 4
  %21294 = icmp eq i32 %21199, %21293
  %21295 = or i1 %21292, %21294
  %21296 = load i32, i32* %37, align 4
  %21297 = icmp eq i32 %21199, %21296
  %21298 = or i1 %21295, %21297
  %21299 = load i32, i32* %38, align 4
  %21300 = icmp eq i32 %21199, %21299
  %21301 = or i1 %21298, %21300
  %21302 = load i32, i32* %39, align 4
  %21303 = icmp eq i32 %21199, %21302
  %21304 = or i1 %21301, %21303
  %21305 = load i32, i32* %40, align 4
  %21306 = icmp eq i32 %21199, %21305
  %21307 = or i1 %21304, %21306
  %21308 = load i32, i32* %41, align 4
  %21309 = icmp eq i32 %21199, %21308
  %21310 = or i1 %21307, %21309
  %21311 = load i32, i32* %42, align 4
  %21312 = icmp eq i32 %21199, %21311
  %21313 = or i1 %21310, %21312
  %21314 = load i32, i32* %43, align 4
  %21315 = icmp eq i32 %21199, %21314
  %21316 = or i1 %21313, %21315
  %21317 = load i32, i32* %44, align 4
  %21318 = icmp eq i32 %21199, %21317
  %21319 = or i1 %21316, %21318
  %21320 = load i32, i32* %45, align 4
  %21321 = icmp eq i32 %21199, %21320
  %21322 = or i1 %21319, %21321
  %21323 = load i32, i32* %46, align 4
  %21324 = icmp eq i32 %21199, %21323
  %21325 = or i1 %21322, %21324
  %21326 = load i32, i32* %47, align 4
  %21327 = icmp eq i32 %21199, %21326
  %21328 = or i1 %21325, %21327
  %21329 = load i32, i32* %48, align 4
  %21330 = icmp eq i32 %21199, %21329
  %21331 = or i1 %21328, %21330
  %21332 = load i32, i32* %49, align 4
  %21333 = icmp eq i32 %21199, %21332
  %21334 = or i1 %21331, %21333
  %21335 = load i32, i32* %50, align 4
  %21336 = icmp eq i32 %21199, %21335
  %21337 = or i1 %21334, %21336
  %21338 = load i32, i32* %51, align 4
  %21339 = icmp eq i32 %21199, %21338
  %21340 = or i1 %21337, %21339
  %21341 = load i32, i32* %52, align 4
  %21342 = icmp eq i32 %21199, %21341
  %21343 = or i1 %21340, %21342
  %21344 = load i32, i32* %53, align 4
  %21345 = icmp eq i32 %21199, %21344
  %21346 = or i1 %21343, %21345
  %21347 = load i32, i32* %54, align 4
  %21348 = icmp eq i32 %21199, %21347
  %21349 = or i1 %21346, %21348
  %21350 = load i32, i32* %55, align 4
  %21351 = icmp eq i32 %21199, %21350
  %21352 = or i1 %21349, %21351
  %21353 = load i32, i32* %56, align 4
  %21354 = icmp eq i32 %21199, %21353
  %21355 = or i1 %21352, %21354
  %21356 = load i32, i32* %57, align 4
  %21357 = icmp eq i32 %21199, %21356
  %21358 = or i1 %21355, %21357
  %21359 = load i32, i32* %58, align 4
  %21360 = icmp eq i32 %21199, %21359
  %21361 = or i1 %21358, %21360
  %21362 = load i32, i32* %59, align 4
  %21363 = icmp eq i32 %21199, %21362
  %21364 = or i1 %21361, %21363
  %21365 = load i32, i32* %60, align 4
  %21366 = icmp eq i32 %21199, %21365
  %21367 = or i1 %21364, %21366
  %21368 = load i32, i32* %61, align 4
  %21369 = icmp eq i32 %21199, %21368
  %21370 = or i1 %21367, %21369
  %21371 = load i32, i32* %62, align 4
  %21372 = icmp eq i32 %21199, %21371
  %21373 = or i1 %21370, %21372
  %21374 = getelementptr i8, i8 addrspace(1)* %4, i32 72
  %21375 = zext i1 %21373 to i8
  store i8 %21375, i8 addrspace(1)* %21374, align 1, !nosanitize !3
  %21376 = load i256, i256* %21198, align 4
  %21377 = mul i256 255, 1, !pc !358, !intsan !45
  %21378 = xor i256 %21377, -1
  %21379 = and i256 %21378, %21376
  %21380 = alloca i256, align 8
  store i256 %21196, i256* %21380, align 4
  %21381 = alloca i256, align 8
  store i256 %21379, i256* %21381, align 4
  call void @__device_sstore(i256* %21380, i256* %21381)
  %21382 = call i32 @__hashword(i256* %21380)
  store i32 %21382, i32* %39, align 4, !nosanitize !3
  %21383 = add i256 1, %21179, !pc !359, !intsan !10
  %21384 = trunc i256 7444 to i64
  %21385 = load i64, i64* %STACK_DEP_PTR, align 4
  %21386 = add i64 %21385, 1
  store i64 %21386, i64* %STACK_DEP_PTR, align 4
  %21387 = load i64, i64* %STACK_DEP_PTR, align 4
  %21388 = getelementptr i256, i256* %STACK, i64 %21387
  store i256 %21383, i256* %21388, align 4
  br label %.7444, !EVMBB !4

.7506:                                            ; preds = %20968, %JumpTable
  %21389 = load i64, i64* %remaing_gas, align 4
  %21390 = icmp ugt i64 712, %21389
  br i1 %21390, label %Abort, label %21391

21391:                                            ; preds = %.7506
  %21392 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21393 = xor i32 %21392, 2233
  %21394 = urem i32 %21393, 4096
  %21395 = getelementptr i8, i8 addrspace(1)* %4, i32 %21394
  %21396 = load i8, i8 addrspace(1)* %21395, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %21395, align 1, !nosanitize !3
  store i32 1116, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21397 = sub i64 %21389, 712
  store i64 %21397, i64* %remaing_gas, align 4
  %21398 = load i64, i64* %STACK_DEP_PTR, align 4
  %21399 = getelementptr i256, i256* %STACK, i64 %21398
  %21400 = load i256, i256* %21399, align 4
  %21401 = load i64, i64* %STACK_DEP_PTR, align 4
  %21402 = sub i64 %21401, 1
  store i64 %21402, i64* %STACK_DEP_PTR, align 4
  %21403 = load i64, i64* %STACK_DEP_PTR, align 4
  %21404 = getelementptr i256, i256* %STACK, i64 %21403
  %21405 = load i256, i256* %21404, align 4
  %21406 = load i64, i64* %STACK_DEP_PTR, align 4
  %21407 = sub i64 %21406, 1
  store i64 %21407, i64* %STACK_DEP_PTR, align 4
  %21408 = load i64, i64* %STACK_DEP_PTR, align 4
  %21409 = getelementptr i256, i256* %STACK, i64 %21408
  %21410 = load i256, i256* %21409, align 4
  %21411 = load i64, i64* %STACK_DEP_PTR, align 4
  %21412 = sub i64 %21411, 1
  store i64 %21412, i64* %STACK_DEP_PTR, align 4
  %21413 = trunc i256 64 to i64
  %21414 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %21413, i256* %21414)
  %21415 = load i256, i256* %21414, align 4
  %21416 = add i256 %21415, 64, !pc !360, !intsan !10
  %21417 = trunc i256 64 to i64
  %21418 = alloca i256, align 8
  store i256 %21416, i256* %21418, align 4
  %21419 = bitcast i256* %21418 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %21417, i8* %21419, i64 32)
  %21420 = and i256 1461501637330902918203684832716283019655932542975, %21405
  %21421 = trunc i256 %21415 to i64
  %21422 = alloca i256, align 8
  store i256 %21420, i256* %21422, align 4
  %21423 = bitcast i256* %21422 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %21421, i8* %21423, i64 32)
  %21424 = add i256 32, %21415, !pc !361, !intsan !10
  %timestamp195 = load i256, i256 addrspace(4)* @TIMESTAMP, align 4, !pc !362, !bsdsan !3
  %21425 = trunc i256 %21424 to i64
  %21426 = alloca i256, align 8
  store i256 %timestamp195, i256* %21426, align 4
  %21427 = bitcast i256* %21426 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %21425, i8* %21427, i64 32)
  %21428 = add i256 %21415, 0, !pc !363, !intsan !10
  %21429 = trunc i256 %21428 to i64
  %21430 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %21429, i256* %21430)
  %21431 = load i256, i256* %21430, align 4
  %21432 = add i256 0, 9, !pc !364, !intsan !10
  %21433 = alloca i256, align 8
  store i256 %21432, i256* %21433, align 4
  %21434 = alloca i256, align 8
  call void @__device_sload(i256* %21433, i256* %21434)
  %21435 = call i32 @__hashword(i256* %21433)
  %21436 = load i32, i32* %5, align 4
  %21437 = icmp eq i32 %21435, %21436
  %21438 = or i1 false, %21437
  %21439 = load i32, i32* %6, align 4
  %21440 = icmp eq i32 %21435, %21439
  %21441 = or i1 %21438, %21440
  %21442 = load i32, i32* %7, align 4
  %21443 = icmp eq i32 %21435, %21442
  %21444 = or i1 %21441, %21443
  %21445 = load i32, i32* %8, align 4
  %21446 = icmp eq i32 %21435, %21445
  %21447 = or i1 %21444, %21446
  %21448 = load i32, i32* %9, align 4
  %21449 = icmp eq i32 %21435, %21448
  %21450 = or i1 %21447, %21449
  %21451 = load i32, i32* %10, align 4
  %21452 = icmp eq i32 %21435, %21451
  %21453 = or i1 %21450, %21452
  %21454 = load i32, i32* %11, align 4
  %21455 = icmp eq i32 %21435, %21454
  %21456 = or i1 %21453, %21455
  %21457 = load i32, i32* %12, align 4
  %21458 = icmp eq i32 %21435, %21457
  %21459 = or i1 %21456, %21458
  %21460 = load i32, i32* %13, align 4
  %21461 = icmp eq i32 %21435, %21460
  %21462 = or i1 %21459, %21461
  %21463 = load i32, i32* %14, align 4
  %21464 = icmp eq i32 %21435, %21463
  %21465 = or i1 %21462, %21464
  %21466 = load i32, i32* %15, align 4
  %21467 = icmp eq i32 %21435, %21466
  %21468 = or i1 %21465, %21467
  %21469 = load i32, i32* %16, align 4
  %21470 = icmp eq i32 %21435, %21469
  %21471 = or i1 %21468, %21470
  %21472 = load i32, i32* %17, align 4
  %21473 = icmp eq i32 %21435, %21472
  %21474 = or i1 %21471, %21473
  %21475 = load i32, i32* %18, align 4
  %21476 = icmp eq i32 %21435, %21475
  %21477 = or i1 %21474, %21476
  %21478 = load i32, i32* %19, align 4
  %21479 = icmp eq i32 %21435, %21478
  %21480 = or i1 %21477, %21479
  %21481 = load i32, i32* %20, align 4
  %21482 = icmp eq i32 %21435, %21481
  %21483 = or i1 %21480, %21482
  %21484 = load i32, i32* %21, align 4
  %21485 = icmp eq i32 %21435, %21484
  %21486 = or i1 %21483, %21485
  %21487 = load i32, i32* %22, align 4
  %21488 = icmp eq i32 %21435, %21487
  %21489 = or i1 %21486, %21488
  %21490 = load i32, i32* %23, align 4
  %21491 = icmp eq i32 %21435, %21490
  %21492 = or i1 %21489, %21491
  %21493 = load i32, i32* %24, align 4
  %21494 = icmp eq i32 %21435, %21493
  %21495 = or i1 %21492, %21494
  %21496 = load i32, i32* %25, align 4
  %21497 = icmp eq i32 %21435, %21496
  %21498 = or i1 %21495, %21497
  %21499 = load i32, i32* %26, align 4
  %21500 = icmp eq i32 %21435, %21499
  %21501 = or i1 %21498, %21500
  %21502 = load i32, i32* %27, align 4
  %21503 = icmp eq i32 %21435, %21502
  %21504 = or i1 %21501, %21503
  %21505 = load i32, i32* %28, align 4
  %21506 = icmp eq i32 %21435, %21505
  %21507 = or i1 %21504, %21506
  %21508 = load i32, i32* %29, align 4
  %21509 = icmp eq i32 %21435, %21508
  %21510 = or i1 %21507, %21509
  %21511 = load i32, i32* %30, align 4
  %21512 = icmp eq i32 %21435, %21511
  %21513 = or i1 %21510, %21512
  %21514 = load i32, i32* %31, align 4
  %21515 = icmp eq i32 %21435, %21514
  %21516 = or i1 %21513, %21515
  %21517 = load i32, i32* %32, align 4
  %21518 = icmp eq i32 %21435, %21517
  %21519 = or i1 %21516, %21518
  %21520 = load i32, i32* %33, align 4
  %21521 = icmp eq i32 %21435, %21520
  %21522 = or i1 %21519, %21521
  %21523 = load i32, i32* %34, align 4
  %21524 = icmp eq i32 %21435, %21523
  %21525 = or i1 %21522, %21524
  %21526 = load i32, i32* %35, align 4
  %21527 = icmp eq i32 %21435, %21526
  %21528 = or i1 %21525, %21527
  %21529 = load i32, i32* %36, align 4
  %21530 = icmp eq i32 %21435, %21529
  %21531 = or i1 %21528, %21530
  %21532 = load i32, i32* %37, align 4
  %21533 = icmp eq i32 %21435, %21532
  %21534 = or i1 %21531, %21533
  %21535 = load i32, i32* %38, align 4
  %21536 = icmp eq i32 %21435, %21535
  %21537 = or i1 %21534, %21536
  %21538 = load i32, i32* %39, align 4
  %21539 = icmp eq i32 %21435, %21538
  %21540 = or i1 %21537, %21539
  %21541 = load i32, i32* %40, align 4
  %21542 = icmp eq i32 %21435, %21541
  %21543 = or i1 %21540, %21542
  %21544 = load i32, i32* %41, align 4
  %21545 = icmp eq i32 %21435, %21544
  %21546 = or i1 %21543, %21545
  %21547 = load i32, i32* %42, align 4
  %21548 = icmp eq i32 %21435, %21547
  %21549 = or i1 %21546, %21548
  %21550 = load i32, i32* %43, align 4
  %21551 = icmp eq i32 %21435, %21550
  %21552 = or i1 %21549, %21551
  %21553 = load i32, i32* %44, align 4
  %21554 = icmp eq i32 %21435, %21553
  %21555 = or i1 %21552, %21554
  %21556 = load i32, i32* %45, align 4
  %21557 = icmp eq i32 %21435, %21556
  %21558 = or i1 %21555, %21557
  %21559 = load i32, i32* %46, align 4
  %21560 = icmp eq i32 %21435, %21559
  %21561 = or i1 %21558, %21560
  %21562 = load i32, i32* %47, align 4
  %21563 = icmp eq i32 %21435, %21562
  %21564 = or i1 %21561, %21563
  %21565 = load i32, i32* %48, align 4
  %21566 = icmp eq i32 %21435, %21565
  %21567 = or i1 %21564, %21566
  %21568 = load i32, i32* %49, align 4
  %21569 = icmp eq i32 %21435, %21568
  %21570 = or i1 %21567, %21569
  %21571 = load i32, i32* %50, align 4
  %21572 = icmp eq i32 %21435, %21571
  %21573 = or i1 %21570, %21572
  %21574 = load i32, i32* %51, align 4
  %21575 = icmp eq i32 %21435, %21574
  %21576 = or i1 %21573, %21575
  %21577 = load i32, i32* %52, align 4
  %21578 = icmp eq i32 %21435, %21577
  %21579 = or i1 %21576, %21578
  %21580 = load i32, i32* %53, align 4
  %21581 = icmp eq i32 %21435, %21580
  %21582 = or i1 %21579, %21581
  %21583 = load i32, i32* %54, align 4
  %21584 = icmp eq i32 %21435, %21583
  %21585 = or i1 %21582, %21584
  %21586 = load i32, i32* %55, align 4
  %21587 = icmp eq i32 %21435, %21586
  %21588 = or i1 %21585, %21587
  %21589 = load i32, i32* %56, align 4
  %21590 = icmp eq i32 %21435, %21589
  %21591 = or i1 %21588, %21590
  %21592 = load i32, i32* %57, align 4
  %21593 = icmp eq i32 %21435, %21592
  %21594 = or i1 %21591, %21593
  %21595 = load i32, i32* %58, align 4
  %21596 = icmp eq i32 %21435, %21595
  %21597 = or i1 %21594, %21596
  %21598 = load i32, i32* %59, align 4
  %21599 = icmp eq i32 %21435, %21598
  %21600 = or i1 %21597, %21599
  %21601 = load i32, i32* %60, align 4
  %21602 = icmp eq i32 %21435, %21601
  %21603 = or i1 %21600, %21602
  %21604 = load i32, i32* %61, align 4
  %21605 = icmp eq i32 %21435, %21604
  %21606 = or i1 %21603, %21605
  %21607 = load i32, i32* %62, align 4
  %21608 = icmp eq i32 %21435, %21607
  %21609 = or i1 %21606, %21608
  %21610 = getelementptr i8, i8 addrspace(1)* %4, i32 73
  %21611 = zext i1 %21609 to i8
  store i8 %21611, i8 addrspace(1)* %21610, align 1, !nosanitize !3
  %21612 = load i256, i256* %21434, align 4
  %21613 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !365, !intsan !45
  %21614 = xor i256 %21613, -1
  %21615 = and i256 %21614, %21612
  %21616 = and i256 1461501637330902918203684832716283019655932542975, %21431
  %21617 = mul i256 %21616, 1, !pc !366, !intsan !45
  %21618 = or i256 %21617, %21615
  %21619 = alloca i256, align 8
  store i256 %21432, i256* %21619, align 4
  %21620 = alloca i256, align 8
  store i256 %21618, i256* %21620, align 4
  call void @__device_sstore(i256* %21619, i256* %21620)
  %21621 = call i32 @__hashword(i256* %21619)
  store i32 %21621, i32* %40, align 4, !nosanitize !3
  %21622 = add i256 %21415, 32, !pc !367, !intsan !10
  %21623 = trunc i256 %21622 to i64
  %21624 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %21623, i256* %21624)
  %21625 = load i256, i256* %21624, align 4
  %21626 = add i256 1, 9, !pc !368, !intsan !10
  %21627 = alloca i256, align 8
  store i256 %21626, i256* %21627, align 4
  %21628 = alloca i256, align 8
  store i256 %21625, i256* %21628, align 4
  call void @__device_sstore(i256* %21627, i256* %21628)
  %21629 = call i32 @__hashword(i256* %21627)
  store i32 %21629, i32* %41, align 4, !nosanitize !3
  %21630 = trunc i256 64 to i64
  %21631 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %21630, i256* %21631)
  %21632 = load i256, i256* %21631, align 4
  %21633 = trunc i256 64 to i64
  %21634 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %21633, i256* %21634)
  %21635 = load i256, i256* %21634, align 4
  %21636 = sub i256 %21632, %21635, !pc !369, !intsan !8
  %21637 = trunc i256 48875775716446405325528862532607795666212601207483300998172835284530334870923 to i64
  call void @addBugSet(i64 %21637)
  %21638 = trunc i256 %21410 to i64
  store i64 %21638, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.7683:                                            ; preds = %2146, %JumpTable
  %21639 = load i64, i64* %remaing_gas, align 4
  %21640 = icmp ugt i64 552, %21639
  br i1 %21640, label %Abort, label %21641

21641:                                            ; preds = %.7683
  %21642 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21643 = xor i32 %21642, 3616
  %21644 = urem i32 %21643, 4096
  %21645 = getelementptr i8, i8 addrspace(1)* %4, i32 %21644
  %21646 = load i8, i8 addrspace(1)* %21645, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %21645, align 1, !nosanitize !3
  store i32 1808, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21647 = sub i64 %21639, 552
  store i64 %21647, i64* %remaing_gas, align 4
  %21648 = trunc i256 4367 to i64
  %21649 = load i64, i64* %STACK_DEP_PTR, align 4
  %21650 = add i64 %21649, 1
  store i64 %21650, i64* %STACK_DEP_PTR, align 4
  %21651 = load i64, i64* %STACK_DEP_PTR, align 4
  %21652 = getelementptr i256, i256* %STACK, i64 %21651
  store i256 0, i256* %21652, align 4
  %21653 = load i64, i64* %STACK_DEP_PTR, align 4
  %21654 = add i64 %21653, 1
  store i64 %21654, i64* %STACK_DEP_PTR, align 4
  %21655 = load i64, i64* %STACK_DEP_PTR, align 4
  %21656 = getelementptr i256, i256* %STACK, i64 %21655
  store i256 0, i256* %21656, align 4
  %21657 = load i64, i64* %STACK_DEP_PTR, align 4
  %21658 = add i64 %21657, 1
  store i64 %21658, i64* %STACK_DEP_PTR, align 4
  %21659 = load i64, i64* %STACK_DEP_PTR, align 4
  %21660 = getelementptr i256, i256* %STACK, i64 %21659
  store i256 0, i256* %21660, align 4
  %21661 = load i64, i64* %STACK_DEP_PTR, align 4
  %21662 = add i64 %21661, 1
  store i64 %21662, i64* %STACK_DEP_PTR, align 4
  %21663 = load i64, i64* %STACK_DEP_PTR, align 4
  %21664 = getelementptr i256, i256* %STACK, i64 %21663
  store i256 0, i256* %21664, align 4
  %21665 = load i64, i64* %STACK_DEP_PTR, align 4
  %21666 = add i64 %21665, 1
  store i64 %21666, i64* %STACK_DEP_PTR, align 4
  %21667 = load i64, i64* %STACK_DEP_PTR, align 4
  %21668 = getelementptr i256, i256* %STACK, i64 %21667
  store i256 0, i256* %21668, align 4
  %21669 = load i64, i64* %STACK_DEP_PTR, align 4
  %21670 = add i64 %21669, 1
  store i64 %21670, i64* %STACK_DEP_PTR, align 4
  %21671 = load i64, i64* %STACK_DEP_PTR, align 4
  %21672 = getelementptr i256, i256* %STACK, i64 %21671
  store i256 0, i256* %21672, align 4
  %21673 = load i64, i64* %STACK_DEP_PTR, align 4
  %21674 = add i64 %21673, 1
  store i64 %21674, i64* %STACK_DEP_PTR, align 4
  %21675 = load i64, i64* %STACK_DEP_PTR, align 4
  %21676 = getelementptr i256, i256* %STACK, i64 %21675
  store i256 0, i256* %21676, align 4
  %21677 = load i64, i64* %STACK_DEP_PTR, align 4
  %21678 = add i64 %21677, 1
  store i64 %21678, i64* %STACK_DEP_PTR, align 4
  %21679 = load i64, i64* %STACK_DEP_PTR, align 4
  %21680 = getelementptr i256, i256* %STACK, i64 %21679
  store i256 0, i256* %21680, align 4
  %21681 = load i64, i64* %STACK_DEP_PTR, align 4
  %21682 = add i64 %21681, 1
  store i64 %21682, i64* %STACK_DEP_PTR, align 4
  %21683 = load i64, i64* %STACK_DEP_PTR, align 4
  %21684 = getelementptr i256, i256* %STACK, i64 %21683
  store i256 0, i256* %21684, align 4
  %21685 = load i64, i64* %STACK_DEP_PTR, align 4
  %21686 = add i64 %21685, 1
  store i64 %21686, i64* %STACK_DEP_PTR, align 4
  %21687 = load i64, i64* %STACK_DEP_PTR, align 4
  %21688 = getelementptr i256, i256* %STACK, i64 %21687
  store i256 0, i256* %21688, align 4
  %21689 = load i64, i64* %STACK_DEP_PTR, align 4
  %21690 = add i64 %21689, 1
  store i64 %21690, i64* %STACK_DEP_PTR, align 4
  %21691 = load i64, i64* %STACK_DEP_PTR, align 4
  %21692 = getelementptr i256, i256* %STACK, i64 %21691
  store i256 7706, i256* %21692, align 4
  br label %.4367, !EVMBB !4

.7706:                                            ; preds = %JumpTable
  %21693 = load i64, i64* %remaing_gas, align 4
  %21694 = icmp ugt i64 312, %21693
  br i1 %21694, label %Abort, label %21695

21695:                                            ; preds = %.7706
  %21696 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21697 = xor i32 %21696, 2234
  %21698 = urem i32 %21697, 4096
  %21699 = getelementptr i8, i8 addrspace(1)* %4, i32 %21698
  %21700 = load i8, i8 addrspace(1)* %21699, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %21699, align 1, !nosanitize !3
  store i32 1117, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21701 = sub i64 %21693, 312
  store i64 %21701, i64* %remaing_gas, align 4
  %21702 = load i64, i64* %STACK_DEP_PTR, align 4
  %21703 = getelementptr i256, i256* %STACK, i64 %21702
  %21704 = load i256, i256* %21703, align 4
  %21705 = load i64, i64* %STACK_DEP_PTR, align 4
  %21706 = sub i64 %21705, 1
  store i64 %21706, i64* %STACK_DEP_PTR, align 4
  %21707 = load i64, i64* %STACK_DEP_PTR, align 4
  %21708 = getelementptr i256, i256* %STACK, i64 %21707
  %21709 = load i256, i256* %21708, align 4
  %21710 = load i64, i64* %STACK_DEP_PTR, align 4
  %21711 = sub i64 %21710, 1
  store i64 %21711, i64* %STACK_DEP_PTR, align 4
  %21712 = load i64, i64* %STACK_DEP_PTR, align 4
  %21713 = getelementptr i256, i256* %STACK, i64 %21712
  %21714 = load i256, i256* %21713, align 4
  %21715 = load i64, i64* %STACK_DEP_PTR, align 4
  %21716 = sub i64 %21715, 1
  store i64 %21716, i64* %STACK_DEP_PTR, align 4
  %21717 = trunc i256 8787 to i64
  %21718 = load i64, i64* %STACK_DEP_PTR, align 4
  %21719 = add i64 %21718, 1
  store i64 %21719, i64* %STACK_DEP_PTR, align 4
  %21720 = load i64, i64* %STACK_DEP_PTR, align 4
  %21721 = getelementptr i256, i256* %STACK, i64 %21720
  store i256 %21704, i256* %21721, align 4
  %21722 = load i64, i64* %STACK_DEP_PTR, align 4
  %21723 = add i64 %21722, 1
  store i64 %21723, i64* %STACK_DEP_PTR, align 4
  %21724 = load i64, i64* %STACK_DEP_PTR, align 4
  %21725 = getelementptr i256, i256* %STACK, i64 %21724
  store i256 %21709, i256* %21725, align 4
  %21726 = load i64, i64* %STACK_DEP_PTR, align 4
  %21727 = add i64 %21726, 1
  store i64 %21727, i64* %STACK_DEP_PTR, align 4
  %21728 = load i64, i64* %STACK_DEP_PTR, align 4
  %21729 = getelementptr i256, i256* %STACK, i64 %21728
  store i256 7716, i256* %21729, align 4
  br label %.8787, !EVMBB !4

.7716:                                            ; preds = %JumpTable
  %21730 = load i64, i64* %remaing_gas, align 4
  %21731 = icmp ugt i64 1120, %21730
  br i1 %21731, label %Abort, label %21732

21732:                                            ; preds = %.7716
  %21733 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21734 = xor i32 %21733, 2950
  %21735 = urem i32 %21734, 4096
  %21736 = getelementptr i8, i8 addrspace(1)* %4, i32 %21735
  %21737 = load i8, i8 addrspace(1)* %21736, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %21736, align 1, !nosanitize !3
  store i32 1475, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %21738 = sub i64 %21730, 1120
  store i64 %21738, i64* %remaing_gas, align 4
  %21739 = load i64, i64* %STACK_DEP_PTR, align 4
  %21740 = getelementptr i256, i256* %STACK, i64 %21739
  %21741 = load i256, i256* %21740, align 4
  %21742 = load i64, i64* %STACK_DEP_PTR, align 4
  %21743 = sub i64 %21742, 1
  store i64 %21743, i64* %STACK_DEP_PTR, align 4
  %21744 = load i64, i64* %STACK_DEP_PTR, align 4
  %21745 = getelementptr i256, i256* %STACK, i64 %21744
  %21746 = load i256, i256* %21745, align 4
  %21747 = load i64, i64* %STACK_DEP_PTR, align 4
  %21748 = sub i64 %21747, 1
  store i64 %21748, i64* %STACK_DEP_PTR, align 4
  %21749 = load i64, i64* %STACK_DEP_PTR, align 4
  %21750 = getelementptr i256, i256* %STACK, i64 %21749
  %21751 = load i256, i256* %21750, align 4
  %21752 = load i64, i64* %STACK_DEP_PTR, align 4
  %21753 = sub i64 %21752, 1
  store i64 %21753, i64* %STACK_DEP_PTR, align 4
  %21754 = load i64, i64* %STACK_DEP_PTR, align 4
  %21755 = getelementptr i256, i256* %STACK, i64 %21754
  %21756 = load i256, i256* %21755, align 4
  %21757 = load i64, i64* %STACK_DEP_PTR, align 4
  %21758 = sub i64 %21757, 1
  store i64 %21758, i64* %STACK_DEP_PTR, align 4
  %21759 = load i64, i64* %STACK_DEP_PTR, align 4
  %21760 = getelementptr i256, i256* %STACK, i64 %21759
  %21761 = load i256, i256* %21760, align 4
  %21762 = load i64, i64* %STACK_DEP_PTR, align 4
  %21763 = sub i64 %21762, 1
  store i64 %21763, i64* %STACK_DEP_PTR, align 4
  %21764 = load i64, i64* %STACK_DEP_PTR, align 4
  %21765 = getelementptr i256, i256* %STACK, i64 %21764
  %21766 = load i256, i256* %21765, align 4
  %21767 = load i64, i64* %STACK_DEP_PTR, align 4
  %21768 = sub i64 %21767, 1
  store i64 %21768, i64* %STACK_DEP_PTR, align 4
  %21769 = load i64, i64* %STACK_DEP_PTR, align 4
  %21770 = getelementptr i256, i256* %STACK, i64 %21769
  %21771 = load i256, i256* %21770, align 4
  %21772 = load i64, i64* %STACK_DEP_PTR, align 4
  %21773 = sub i64 %21772, 1
  store i64 %21773, i64* %STACK_DEP_PTR, align 4
  %21774 = load i64, i64* %STACK_DEP_PTR, align 4
  %21775 = getelementptr i256, i256* %STACK, i64 %21774
  %21776 = load i256, i256* %21775, align 4
  %21777 = load i64, i64* %STACK_DEP_PTR, align 4
  %21778 = sub i64 %21777, 1
  store i64 %21778, i64* %STACK_DEP_PTR, align 4
  %21779 = load i64, i64* %STACK_DEP_PTR, align 4
  %21780 = getelementptr i256, i256* %STACK, i64 %21779
  %21781 = load i256, i256* %21780, align 4
  %21782 = load i64, i64* %STACK_DEP_PTR, align 4
  %21783 = sub i64 %21782, 1
  store i64 %21783, i64* %STACK_DEP_PTR, align 4
  %21784 = load i64, i64* %STACK_DEP_PTR, align 4
  %21785 = getelementptr i256, i256* %STACK, i64 %21784
  %21786 = load i256, i256* %21785, align 4
  %21787 = load i64, i64* %STACK_DEP_PTR, align 4
  %21788 = sub i64 %21787, 1
  store i64 %21788, i64* %STACK_DEP_PTR, align 4
  %21789 = load i64, i64* %STACK_DEP_PTR, align 4
  %21790 = getelementptr i256, i256* %STACK, i64 %21789
  %21791 = load i256, i256* %21790, align 4
  %21792 = load i64, i64* %STACK_DEP_PTR, align 4
  %21793 = sub i64 %21792, 1
  store i64 %21793, i64* %STACK_DEP_PTR, align 4
  %21794 = load i64, i64* %STACK_DEP_PTR, align 4
  %21795 = getelementptr i256, i256* %STACK, i64 %21794
  %21796 = load i256, i256* %21795, align 4
  %21797 = load i64, i64* %STACK_DEP_PTR, align 4
  %21798 = sub i64 %21797, 1
  store i64 %21798, i64* %STACK_DEP_PTR, align 4
  %21799 = alloca i256, align 8
  store i256 14, i256* %21799, align 4
  %21800 = alloca i256, align 8
  call void @__device_sload(i256* %21799, i256* %21800)
  %21801 = call i32 @__hashword(i256* %21799)
  %21802 = load i32, i32* %5, align 4
  %21803 = icmp eq i32 %21801, %21802
  %21804 = or i1 false, %21803
  %21805 = load i32, i32* %6, align 4
  %21806 = icmp eq i32 %21801, %21805
  %21807 = or i1 %21804, %21806
  %21808 = load i32, i32* %7, align 4
  %21809 = icmp eq i32 %21801, %21808
  %21810 = or i1 %21807, %21809
  %21811 = load i32, i32* %8, align 4
  %21812 = icmp eq i32 %21801, %21811
  %21813 = or i1 %21810, %21812
  %21814 = load i32, i32* %9, align 4
  %21815 = icmp eq i32 %21801, %21814
  %21816 = or i1 %21813, %21815
  %21817 = load i32, i32* %10, align 4
  %21818 = icmp eq i32 %21801, %21817
  %21819 = or i1 %21816, %21818
  %21820 = load i32, i32* %11, align 4
  %21821 = icmp eq i32 %21801, %21820
  %21822 = or i1 %21819, %21821
  %21823 = load i32, i32* %12, align 4
  %21824 = icmp eq i32 %21801, %21823
  %21825 = or i1 %21822, %21824
  %21826 = load i32, i32* %13, align 4
  %21827 = icmp eq i32 %21801, %21826
  %21828 = or i1 %21825, %21827
  %21829 = load i32, i32* %14, align 4
  %21830 = icmp eq i32 %21801, %21829
  %21831 = or i1 %21828, %21830
  %21832 = load i32, i32* %15, align 4
  %21833 = icmp eq i32 %21801, %21832
  %21834 = or i1 %21831, %21833
  %21835 = load i32, i32* %16, align 4
  %21836 = icmp eq i32 %21801, %21835
  %21837 = or i1 %21834, %21836
  %21838 = load i32, i32* %17, align 4
  %21839 = icmp eq i32 %21801, %21838
  %21840 = or i1 %21837, %21839
  %21841 = load i32, i32* %18, align 4
  %21842 = icmp eq i32 %21801, %21841
  %21843 = or i1 %21840, %21842
  %21844 = load i32, i32* %19, align 4
  %21845 = icmp eq i32 %21801, %21844
  %21846 = or i1 %21843, %21845
  %21847 = load i32, i32* %20, align 4
  %21848 = icmp eq i32 %21801, %21847
  %21849 = or i1 %21846, %21848
  %21850 = load i32, i32* %21, align 4
  %21851 = icmp eq i32 %21801, %21850
  %21852 = or i1 %21849, %21851
  %21853 = load i32, i32* %22, align 4
  %21854 = icmp eq i32 %21801, %21853
  %21855 = or i1 %21852, %21854
  %21856 = load i32, i32* %23, align 4
  %21857 = icmp eq i32 %21801, %21856
  %21858 = or i1 %21855, %21857
  %21859 = load i32, i32* %24, align 4
  %21860 = icmp eq i32 %21801, %21859
  %21861 = or i1 %21858, %21860
  %21862 = load i32, i32* %25, align 4
  %21863 = icmp eq i32 %21801, %21862
  %21864 = or i1 %21861, %21863
  %21865 = load i32, i32* %26, align 4
  %21866 = icmp eq i32 %21801, %21865
  %21867 = or i1 %21864, %21866
  %21868 = load i32, i32* %27, align 4
  %21869 = icmp eq i32 %21801, %21868
  %21870 = or i1 %21867, %21869
  %21871 = load i32, i32* %28, align 4
  %21872 = icmp eq i32 %21801, %21871
  %21873 = or i1 %21870, %21872
  %21874 = load i32, i32* %29, align 4
  %21875 = icmp eq i32 %21801, %21874
  %21876 = or i1 %21873, %21875
  %21877 = load i32, i32* %30, align 4
  %21878 = icmp eq i32 %21801, %21877
  %21879 = or i1 %21876, %21878
  %21880 = load i32, i32* %31, align 4
  %21881 = icmp eq i32 %21801, %21880
  %21882 = or i1 %21879, %21881
  %21883 = load i32, i32* %32, align 4
  %21884 = icmp eq i32 %21801, %21883
  %21885 = or i1 %21882, %21884
  %21886 = load i32, i32* %33, align 4
  %21887 = icmp eq i32 %21801, %21886
  %21888 = or i1 %21885, %21887
  %21889 = load i32, i32* %34, align 4
  %21890 = icmp eq i32 %21801, %21889
  %21891 = or i1 %21888, %21890
  %21892 = load i32, i32* %35, align 4
  %21893 = icmp eq i32 %21801, %21892
  %21894 = or i1 %21891, %21893
  %21895 = load i32, i32* %36, align 4
  %21896 = icmp eq i32 %21801, %21895
  %21897 = or i1 %21894, %21896
  %21898 = load i32, i32* %37, align 4
  %21899 = icmp eq i32 %21801, %21898
  %21900 = or i1 %21897, %21899
  %21901 = load i32, i32* %38, align 4
  %21902 = icmp eq i32 %21801, %21901
  %21903 = or i1 %21900, %21902
  %21904 = load i32, i32* %39, align 4
  %21905 = icmp eq i32 %21801, %21904
  %21906 = or i1 %21903, %21905
  %21907 = load i32, i32* %40, align 4
  %21908 = icmp eq i32 %21801, %21907
  %21909 = or i1 %21906, %21908
  %21910 = load i32, i32* %41, align 4
  %21911 = icmp eq i32 %21801, %21910
  %21912 = or i1 %21909, %21911
  %21913 = load i32, i32* %42, align 4
  %21914 = icmp eq i32 %21801, %21913
  %21915 = or i1 %21912, %21914
  %21916 = load i32, i32* %43, align 4
  %21917 = icmp eq i32 %21801, %21916
  %21918 = or i1 %21915, %21917
  %21919 = load i32, i32* %44, align 4
  %21920 = icmp eq i32 %21801, %21919
  %21921 = or i1 %21918, %21920
  %21922 = load i32, i32* %45, align 4
  %21923 = icmp eq i32 %21801, %21922
  %21924 = or i1 %21921, %21923
  %21925 = load i32, i32* %46, align 4
  %21926 = icmp eq i32 %21801, %21925
  %21927 = or i1 %21924, %21926
  %21928 = load i32, i32* %47, align 4
  %21929 = icmp eq i32 %21801, %21928
  %21930 = or i1 %21927, %21929
  %21931 = load i32, i32* %48, align 4
  %21932 = icmp eq i32 %21801, %21931
  %21933 = or i1 %21930, %21932
  %21934 = load i32, i32* %49, align 4
  %21935 = icmp eq i32 %21801, %21934
  %21936 = or i1 %21933, %21935
  %21937 = load i32, i32* %50, align 4
  %21938 = icmp eq i32 %21801, %21937
  %21939 = or i1 %21936, %21938
  %21940 = load i32, i32* %51, align 4
  %21941 = icmp eq i32 %21801, %21940
  %21942 = or i1 %21939, %21941
  %21943 = load i32, i32* %52, align 4
  %21944 = icmp eq i32 %21801, %21943
  %21945 = or i1 %21942, %21944
  %21946 = load i32, i32* %53, align 4
  %21947 = icmp eq i32 %21801, %21946
  %21948 = or i1 %21945, %21947
  %21949 = load i32, i32* %54, align 4
  %21950 = icmp eq i32 %21801, %21949
  %21951 = or i1 %21948, %21950
  %21952 = load i32, i32* %55, align 4
  %21953 = icmp eq i32 %21801, %21952
  %21954 = or i1 %21951, %21953
  %21955 = load i32, i32* %56, align 4
  %21956 = icmp eq i32 %21801, %21955
  %21957 = or i1 %21954, %21956
  %21958 = load i32, i32* %57, align 4
  %21959 = icmp eq i32 %21801, %21958
  %21960 = or i1 %21957, %21959
  %21961 = load i32, i32* %58, align 4
  %21962 = icmp eq i32 %21801, %21961
  %21963 = or i1 %21960, %21962
  %21964 = load i32, i32* %59, align 4
  %21965 = icmp eq i32 %21801, %21964
  %21966 = or i1 %21963, %21965
  %21967 = load i32, i32* %60, align 4
  %21968 = icmp eq i32 %21801, %21967
  %21969 = or i1 %21966, %21968
  %21970 = load i32, i32* %61, align 4
  %21971 = icmp eq i32 %21801, %21970
  %21972 = or i1 %21969, %21971
  %21973 = load i32, i32* %62, align 4
  %21974 = icmp eq i32 %21801, %21973
  %21975 = or i1 %21972, %21974
  %21976 = getelementptr i8, i8 addrspace(1)* %4, i32 74
  %21977 = zext i1 %21975 to i8
  store i8 %21977, i8 addrspace(1)* %21976, align 1, !nosanitize !3
  %21978 = load i256, i256* %21800, align 4
  %21979 = alloca i256, align 8
  store i256 13, i256* %21979, align 4
  %21980 = alloca i256, align 8
  call void @__device_sload(i256* %21979, i256* %21980)
  %21981 = call i32 @__hashword(i256* %21979)
  %21982 = load i32, i32* %5, align 4
  %21983 = icmp eq i32 %21981, %21982
  %21984 = or i1 false, %21983
  %21985 = load i32, i32* %6, align 4
  %21986 = icmp eq i32 %21981, %21985
  %21987 = or i1 %21984, %21986
  %21988 = load i32, i32* %7, align 4
  %21989 = icmp eq i32 %21981, %21988
  %21990 = or i1 %21987, %21989
  %21991 = load i32, i32* %8, align 4
  %21992 = icmp eq i32 %21981, %21991
  %21993 = or i1 %21990, %21992
  %21994 = load i32, i32* %9, align 4
  %21995 = icmp eq i32 %21981, %21994
  %21996 = or i1 %21993, %21995
  %21997 = load i32, i32* %10, align 4
  %21998 = icmp eq i32 %21981, %21997
  %21999 = or i1 %21996, %21998
  %22000 = load i32, i32* %11, align 4
  %22001 = icmp eq i32 %21981, %22000
  %22002 = or i1 %21999, %22001
  %22003 = load i32, i32* %12, align 4
  %22004 = icmp eq i32 %21981, %22003
  %22005 = or i1 %22002, %22004
  %22006 = load i32, i32* %13, align 4
  %22007 = icmp eq i32 %21981, %22006
  %22008 = or i1 %22005, %22007
  %22009 = load i32, i32* %14, align 4
  %22010 = icmp eq i32 %21981, %22009
  %22011 = or i1 %22008, %22010
  %22012 = load i32, i32* %15, align 4
  %22013 = icmp eq i32 %21981, %22012
  %22014 = or i1 %22011, %22013
  %22015 = load i32, i32* %16, align 4
  %22016 = icmp eq i32 %21981, %22015
  %22017 = or i1 %22014, %22016
  %22018 = load i32, i32* %17, align 4
  %22019 = icmp eq i32 %21981, %22018
  %22020 = or i1 %22017, %22019
  %22021 = load i32, i32* %18, align 4
  %22022 = icmp eq i32 %21981, %22021
  %22023 = or i1 %22020, %22022
  %22024 = load i32, i32* %19, align 4
  %22025 = icmp eq i32 %21981, %22024
  %22026 = or i1 %22023, %22025
  %22027 = load i32, i32* %20, align 4
  %22028 = icmp eq i32 %21981, %22027
  %22029 = or i1 %22026, %22028
  %22030 = load i32, i32* %21, align 4
  %22031 = icmp eq i32 %21981, %22030
  %22032 = or i1 %22029, %22031
  %22033 = load i32, i32* %22, align 4
  %22034 = icmp eq i32 %21981, %22033
  %22035 = or i1 %22032, %22034
  %22036 = load i32, i32* %23, align 4
  %22037 = icmp eq i32 %21981, %22036
  %22038 = or i1 %22035, %22037
  %22039 = load i32, i32* %24, align 4
  %22040 = icmp eq i32 %21981, %22039
  %22041 = or i1 %22038, %22040
  %22042 = load i32, i32* %25, align 4
  %22043 = icmp eq i32 %21981, %22042
  %22044 = or i1 %22041, %22043
  %22045 = load i32, i32* %26, align 4
  %22046 = icmp eq i32 %21981, %22045
  %22047 = or i1 %22044, %22046
  %22048 = load i32, i32* %27, align 4
  %22049 = icmp eq i32 %21981, %22048
  %22050 = or i1 %22047, %22049
  %22051 = load i32, i32* %28, align 4
  %22052 = icmp eq i32 %21981, %22051
  %22053 = or i1 %22050, %22052
  %22054 = load i32, i32* %29, align 4
  %22055 = icmp eq i32 %21981, %22054
  %22056 = or i1 %22053, %22055
  %22057 = load i32, i32* %30, align 4
  %22058 = icmp eq i32 %21981, %22057
  %22059 = or i1 %22056, %22058
  %22060 = load i32, i32* %31, align 4
  %22061 = icmp eq i32 %21981, %22060
  %22062 = or i1 %22059, %22061
  %22063 = load i32, i32* %32, align 4
  %22064 = icmp eq i32 %21981, %22063
  %22065 = or i1 %22062, %22064
  %22066 = load i32, i32* %33, align 4
  %22067 = icmp eq i32 %21981, %22066
  %22068 = or i1 %22065, %22067
  %22069 = load i32, i32* %34, align 4
  %22070 = icmp eq i32 %21981, %22069
  %22071 = or i1 %22068, %22070
  %22072 = load i32, i32* %35, align 4
  %22073 = icmp eq i32 %21981, %22072
  %22074 = or i1 %22071, %22073
  %22075 = load i32, i32* %36, align 4
  %22076 = icmp eq i32 %21981, %22075
  %22077 = or i1 %22074, %22076
  %22078 = load i32, i32* %37, align 4
  %22079 = icmp eq i32 %21981, %22078
  %22080 = or i1 %22077, %22079
  %22081 = load i32, i32* %38, align 4
  %22082 = icmp eq i32 %21981, %22081
  %22083 = or i1 %22080, %22082
  %22084 = load i32, i32* %39, align 4
  %22085 = icmp eq i32 %21981, %22084
  %22086 = or i1 %22083, %22085
  %22087 = load i32, i32* %40, align 4
  %22088 = icmp eq i32 %21981, %22087
  %22089 = or i1 %22086, %22088
  %22090 = load i32, i32* %41, align 4
  %22091 = icmp eq i32 %21981, %22090
  %22092 = or i1 %22089, %22091
  %22093 = load i32, i32* %42, align 4
  %22094 = icmp eq i32 %21981, %22093
  %22095 = or i1 %22092, %22094
  %22096 = load i32, i32* %43, align 4
  %22097 = icmp eq i32 %21981, %22096
  %22098 = or i1 %22095, %22097
  %22099 = load i32, i32* %44, align 4
  %22100 = icmp eq i32 %21981, %22099
  %22101 = or i1 %22098, %22100
  %22102 = load i32, i32* %45, align 4
  %22103 = icmp eq i32 %21981, %22102
  %22104 = or i1 %22101, %22103
  %22105 = load i32, i32* %46, align 4
  %22106 = icmp eq i32 %21981, %22105
  %22107 = or i1 %22104, %22106
  %22108 = load i32, i32* %47, align 4
  %22109 = icmp eq i32 %21981, %22108
  %22110 = or i1 %22107, %22109
  %22111 = load i32, i32* %48, align 4
  %22112 = icmp eq i32 %21981, %22111
  %22113 = or i1 %22110, %22112
  %22114 = load i32, i32* %49, align 4
  %22115 = icmp eq i32 %21981, %22114
  %22116 = or i1 %22113, %22115
  %22117 = load i32, i32* %50, align 4
  %22118 = icmp eq i32 %21981, %22117
  %22119 = or i1 %22116, %22118
  %22120 = load i32, i32* %51, align 4
  %22121 = icmp eq i32 %21981, %22120
  %22122 = or i1 %22119, %22121
  %22123 = load i32, i32* %52, align 4
  %22124 = icmp eq i32 %21981, %22123
  %22125 = or i1 %22122, %22124
  %22126 = load i32, i32* %53, align 4
  %22127 = icmp eq i32 %21981, %22126
  %22128 = or i1 %22125, %22127
  %22129 = load i32, i32* %54, align 4
  %22130 = icmp eq i32 %21981, %22129
  %22131 = or i1 %22128, %22130
  %22132 = load i32, i32* %55, align 4
  %22133 = icmp eq i32 %21981, %22132
  %22134 = or i1 %22131, %22133
  %22135 = load i32, i32* %56, align 4
  %22136 = icmp eq i32 %21981, %22135
  %22137 = or i1 %22134, %22136
  %22138 = load i32, i32* %57, align 4
  %22139 = icmp eq i32 %21981, %22138
  %22140 = or i1 %22137, %22139
  %22141 = load i32, i32* %58, align 4
  %22142 = icmp eq i32 %21981, %22141
  %22143 = or i1 %22140, %22142
  %22144 = load i32, i32* %59, align 4
  %22145 = icmp eq i32 %21981, %22144
  %22146 = or i1 %22143, %22145
  %22147 = load i32, i32* %60, align 4
  %22148 = icmp eq i32 %21981, %22147
  %22149 = or i1 %22146, %22148
  %22150 = load i32, i32* %61, align 4
  %22151 = icmp eq i32 %21981, %22150
  %22152 = or i1 %22149, %22151
  %22153 = load i32, i32* %62, align 4
  %22154 = icmp eq i32 %21981, %22153
  %22155 = or i1 %22152, %22154
  %22156 = getelementptr i8, i8 addrspace(1)* %4, i32 75
  %22157 = zext i1 %22155 to i8
  store i8 %22157, i8 addrspace(1)* %22156, align 1, !nosanitize !3
  %22158 = load i256, i256* %21980, align 4
  %22159 = sub i256 %22158, %21978, !pc !370, !intsan !8
  %22160 = alloca i256, align 8
  store i256 12, i256* %22160, align 4
  %22161 = alloca i256, align 8
  call void @__device_sload(i256* %22160, i256* %22161)
  %22162 = call i32 @__hashword(i256* %22160)
  %22163 = load i32, i32* %5, align 4
  %22164 = icmp eq i32 %22162, %22163
  %22165 = or i1 false, %22164
  %22166 = load i32, i32* %6, align 4
  %22167 = icmp eq i32 %22162, %22166
  %22168 = or i1 %22165, %22167
  %22169 = load i32, i32* %7, align 4
  %22170 = icmp eq i32 %22162, %22169
  %22171 = or i1 %22168, %22170
  %22172 = load i32, i32* %8, align 4
  %22173 = icmp eq i32 %22162, %22172
  %22174 = or i1 %22171, %22173
  %22175 = load i32, i32* %9, align 4
  %22176 = icmp eq i32 %22162, %22175
  %22177 = or i1 %22174, %22176
  %22178 = load i32, i32* %10, align 4
  %22179 = icmp eq i32 %22162, %22178
  %22180 = or i1 %22177, %22179
  %22181 = load i32, i32* %11, align 4
  %22182 = icmp eq i32 %22162, %22181
  %22183 = or i1 %22180, %22182
  %22184 = load i32, i32* %12, align 4
  %22185 = icmp eq i32 %22162, %22184
  %22186 = or i1 %22183, %22185
  %22187 = load i32, i32* %13, align 4
  %22188 = icmp eq i32 %22162, %22187
  %22189 = or i1 %22186, %22188
  %22190 = load i32, i32* %14, align 4
  %22191 = icmp eq i32 %22162, %22190
  %22192 = or i1 %22189, %22191
  %22193 = load i32, i32* %15, align 4
  %22194 = icmp eq i32 %22162, %22193
  %22195 = or i1 %22192, %22194
  %22196 = load i32, i32* %16, align 4
  %22197 = icmp eq i32 %22162, %22196
  %22198 = or i1 %22195, %22197
  %22199 = load i32, i32* %17, align 4
  %22200 = icmp eq i32 %22162, %22199
  %22201 = or i1 %22198, %22200
  %22202 = load i32, i32* %18, align 4
  %22203 = icmp eq i32 %22162, %22202
  %22204 = or i1 %22201, %22203
  %22205 = load i32, i32* %19, align 4
  %22206 = icmp eq i32 %22162, %22205
  %22207 = or i1 %22204, %22206
  %22208 = load i32, i32* %20, align 4
  %22209 = icmp eq i32 %22162, %22208
  %22210 = or i1 %22207, %22209
  %22211 = load i32, i32* %21, align 4
  %22212 = icmp eq i32 %22162, %22211
  %22213 = or i1 %22210, %22212
  %22214 = load i32, i32* %22, align 4
  %22215 = icmp eq i32 %22162, %22214
  %22216 = or i1 %22213, %22215
  %22217 = load i32, i32* %23, align 4
  %22218 = icmp eq i32 %22162, %22217
  %22219 = or i1 %22216, %22218
  %22220 = load i32, i32* %24, align 4
  %22221 = icmp eq i32 %22162, %22220
  %22222 = or i1 %22219, %22221
  %22223 = load i32, i32* %25, align 4
  %22224 = icmp eq i32 %22162, %22223
  %22225 = or i1 %22222, %22224
  %22226 = load i32, i32* %26, align 4
  %22227 = icmp eq i32 %22162, %22226
  %22228 = or i1 %22225, %22227
  %22229 = load i32, i32* %27, align 4
  %22230 = icmp eq i32 %22162, %22229
  %22231 = or i1 %22228, %22230
  %22232 = load i32, i32* %28, align 4
  %22233 = icmp eq i32 %22162, %22232
  %22234 = or i1 %22231, %22233
  %22235 = load i32, i32* %29, align 4
  %22236 = icmp eq i32 %22162, %22235
  %22237 = or i1 %22234, %22236
  %22238 = load i32, i32* %30, align 4
  %22239 = icmp eq i32 %22162, %22238
  %22240 = or i1 %22237, %22239
  %22241 = load i32, i32* %31, align 4
  %22242 = icmp eq i32 %22162, %22241
  %22243 = or i1 %22240, %22242
  %22244 = load i32, i32* %32, align 4
  %22245 = icmp eq i32 %22162, %22244
  %22246 = or i1 %22243, %22245
  %22247 = load i32, i32* %33, align 4
  %22248 = icmp eq i32 %22162, %22247
  %22249 = or i1 %22246, %22248
  %22250 = load i32, i32* %34, align 4
  %22251 = icmp eq i32 %22162, %22250
  %22252 = or i1 %22249, %22251
  %22253 = load i32, i32* %35, align 4
  %22254 = icmp eq i32 %22162, %22253
  %22255 = or i1 %22252, %22254
  %22256 = load i32, i32* %36, align 4
  %22257 = icmp eq i32 %22162, %22256
  %22258 = or i1 %22255, %22257
  %22259 = load i32, i32* %37, align 4
  %22260 = icmp eq i32 %22162, %22259
  %22261 = or i1 %22258, %22260
  %22262 = load i32, i32* %38, align 4
  %22263 = icmp eq i32 %22162, %22262
  %22264 = or i1 %22261, %22263
  %22265 = load i32, i32* %39, align 4
  %22266 = icmp eq i32 %22162, %22265
  %22267 = or i1 %22264, %22266
  %22268 = load i32, i32* %40, align 4
  %22269 = icmp eq i32 %22162, %22268
  %22270 = or i1 %22267, %22269
  %22271 = load i32, i32* %41, align 4
  %22272 = icmp eq i32 %22162, %22271
  %22273 = or i1 %22270, %22272
  %22274 = load i32, i32* %42, align 4
  %22275 = icmp eq i32 %22162, %22274
  %22276 = or i1 %22273, %22275
  %22277 = load i32, i32* %43, align 4
  %22278 = icmp eq i32 %22162, %22277
  %22279 = or i1 %22276, %22278
  %22280 = load i32, i32* %44, align 4
  %22281 = icmp eq i32 %22162, %22280
  %22282 = or i1 %22279, %22281
  %22283 = load i32, i32* %45, align 4
  %22284 = icmp eq i32 %22162, %22283
  %22285 = or i1 %22282, %22284
  %22286 = load i32, i32* %46, align 4
  %22287 = icmp eq i32 %22162, %22286
  %22288 = or i1 %22285, %22287
  %22289 = load i32, i32* %47, align 4
  %22290 = icmp eq i32 %22162, %22289
  %22291 = or i1 %22288, %22290
  %22292 = load i32, i32* %48, align 4
  %22293 = icmp eq i32 %22162, %22292
  %22294 = or i1 %22291, %22293
  %22295 = load i32, i32* %49, align 4
  %22296 = icmp eq i32 %22162, %22295
  %22297 = or i1 %22294, %22296
  %22298 = load i32, i32* %50, align 4
  %22299 = icmp eq i32 %22162, %22298
  %22300 = or i1 %22297, %22299
  %22301 = load i32, i32* %51, align 4
  %22302 = icmp eq i32 %22162, %22301
  %22303 = or i1 %22300, %22302
  %22304 = load i32, i32* %52, align 4
  %22305 = icmp eq i32 %22162, %22304
  %22306 = or i1 %22303, %22305
  %22307 = load i32, i32* %53, align 4
  %22308 = icmp eq i32 %22162, %22307
  %22309 = or i1 %22306, %22308
  %22310 = load i32, i32* %54, align 4
  %22311 = icmp eq i32 %22162, %22310
  %22312 = or i1 %22309, %22311
  %22313 = load i32, i32* %55, align 4
  %22314 = icmp eq i32 %22162, %22313
  %22315 = or i1 %22312, %22314
  %22316 = load i32, i32* %56, align 4
  %22317 = icmp eq i32 %22162, %22316
  %22318 = or i1 %22315, %22317
  %22319 = load i32, i32* %57, align 4
  %22320 = icmp eq i32 %22162, %22319
  %22321 = or i1 %22318, %22320
  %22322 = load i32, i32* %58, align 4
  %22323 = icmp eq i32 %22162, %22322
  %22324 = or i1 %22321, %22323
  %22325 = load i32, i32* %59, align 4
  %22326 = icmp eq i32 %22162, %22325
  %22327 = or i1 %22324, %22326
  %22328 = load i32, i32* %60, align 4
  %22329 = icmp eq i32 %22162, %22328
  %22330 = or i1 %22327, %22329
  %22331 = load i32, i32* %61, align 4
  %22332 = icmp eq i32 %22162, %22331
  %22333 = or i1 %22330, %22332
  %22334 = load i32, i32* %62, align 4
  %22335 = icmp eq i32 %22162, %22334
  %22336 = or i1 %22333, %22335
  %22337 = getelementptr i8, i8 addrspace(1)* %4, i32 76
  %22338 = zext i1 %22336 to i8
  store i8 %22338, i8 addrspace(1)* %22337, align 1, !nosanitize !3
  %22339 = load i256, i256* %22161, align 4
  %22340 = trunc i256 %21796 to i64
  store i64 %22340, i64* %JMP_TARGET_PTR, align 4
  %22341 = load i64, i64* %STACK_DEP_PTR, align 4
  %22342 = add i64 %22341, 1
  store i64 %22342, i64* %STACK_DEP_PTR, align 4
  %22343 = load i64, i64* %STACK_DEP_PTR, align 4
  %22344 = getelementptr i256, i256* %STACK, i64 %22343
  store i256 %21751, i256* %22344, align 4
  %22345 = load i64, i64* %STACK_DEP_PTR, align 4
  %22346 = add i64 %22345, 1
  store i64 %22346, i64* %STACK_DEP_PTR, align 4
  %22347 = load i64, i64* %STACK_DEP_PTR, align 4
  %22348 = getelementptr i256, i256* %STACK, i64 %22347
  store i256 7500, i256* %22348, align 4
  %22349 = load i64, i64* %STACK_DEP_PTR, align 4
  %22350 = add i64 %22349, 1
  store i64 %22350, i64* %STACK_DEP_PTR, align 4
  %22351 = load i64, i64* %STACK_DEP_PTR, align 4
  %22352 = getelementptr i256, i256* %STACK, i64 %22351
  store i256 190, i256* %22352, align 4
  %22353 = load i64, i64* %STACK_DEP_PTR, align 4
  %22354 = add i64 %22353, 1
  store i64 %22354, i64* %STACK_DEP_PTR, align 4
  %22355 = load i64, i64* %STACK_DEP_PTR, align 4
  %22356 = getelementptr i256, i256* %STACK, i64 %22355
  store i256 100, i256* %22356, align 4
  %22357 = load i64, i64* %STACK_DEP_PTR, align 4
  %22358 = add i64 %22357, 1
  store i64 %22358, i64* %STACK_DEP_PTR, align 4
  %22359 = load i64, i64* %STACK_DEP_PTR, align 4
  %22360 = getelementptr i256, i256* %STACK, i64 %22359
  store i256 200000000000000000, i256* %22360, align 4
  %22361 = load i64, i64* %STACK_DEP_PTR, align 4
  %22362 = add i64 %22361, 1
  store i64 %22362, i64* %STACK_DEP_PTR, align 4
  %22363 = load i64, i64* %STACK_DEP_PTR, align 4
  %22364 = getelementptr i256, i256* %STACK, i64 %22363
  store i256 %22159, i256* %22364, align 4
  %22365 = load i64, i64* %STACK_DEP_PTR, align 4
  %22366 = add i64 %22365, 1
  store i64 %22366, i64* %STACK_DEP_PTR, align 4
  %22367 = load i64, i64* %STACK_DEP_PTR, align 4
  %22368 = getelementptr i256, i256* %STACK, i64 %22367
  store i256 %21741, i256* %22368, align 4
  %22369 = load i64, i64* %STACK_DEP_PTR, align 4
  %22370 = add i64 %22369, 1
  store i64 %22370, i64* %STACK_DEP_PTR, align 4
  %22371 = load i64, i64* %STACK_DEP_PTR, align 4
  %22372 = getelementptr i256, i256* %STACK, i64 %22371
  store i256 %22339, i256* %22372, align 4
  br label %JumpTable, !EVMBB !4

.7777:                                            ; preds = %2280, %JumpTable
  %22373 = load i64, i64* %remaing_gas, align 4
  %22374 = icmp ugt i64 184, %22373
  br i1 %22374, label %Abort, label %22375

22375:                                            ; preds = %.7777
  %22376 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22377 = xor i32 %22376, 3267
  %22378 = urem i32 %22377, 4096
  %22379 = getelementptr i8, i8 addrspace(1)* %4, i32 %22378
  %22380 = load i8, i8 addrspace(1)* %22379, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22379, align 1, !nosanitize !3
  store i32 1633, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22381 = sub i64 %22373, 184
  store i64 %22381, i64* %remaing_gas, align 4
  %22382 = load i256, i256* %0, align 4
  %22383 = and i256 1461501637330902918203684832716283019655932542975, %22382
  %22384 = alloca i256, align 8
  store i256 7, i256* %22384, align 4
  %22385 = alloca i256, align 8
  call void @__device_sload(i256* %22384, i256* %22385)
  %22386 = call i32 @__hashword(i256* %22384)
  %22387 = load i32, i32* %5, align 4
  %22388 = icmp eq i32 %22386, %22387
  %22389 = or i1 false, %22388
  %22390 = load i32, i32* %6, align 4
  %22391 = icmp eq i32 %22386, %22390
  %22392 = or i1 %22389, %22391
  %22393 = load i32, i32* %7, align 4
  %22394 = icmp eq i32 %22386, %22393
  %22395 = or i1 %22392, %22394
  %22396 = load i32, i32* %8, align 4
  %22397 = icmp eq i32 %22386, %22396
  %22398 = or i1 %22395, %22397
  %22399 = load i32, i32* %9, align 4
  %22400 = icmp eq i32 %22386, %22399
  %22401 = or i1 %22398, %22400
  %22402 = load i32, i32* %10, align 4
  %22403 = icmp eq i32 %22386, %22402
  %22404 = or i1 %22401, %22403
  %22405 = load i32, i32* %11, align 4
  %22406 = icmp eq i32 %22386, %22405
  %22407 = or i1 %22404, %22406
  %22408 = load i32, i32* %12, align 4
  %22409 = icmp eq i32 %22386, %22408
  %22410 = or i1 %22407, %22409
  %22411 = load i32, i32* %13, align 4
  %22412 = icmp eq i32 %22386, %22411
  %22413 = or i1 %22410, %22412
  %22414 = load i32, i32* %14, align 4
  %22415 = icmp eq i32 %22386, %22414
  %22416 = or i1 %22413, %22415
  %22417 = load i32, i32* %15, align 4
  %22418 = icmp eq i32 %22386, %22417
  %22419 = or i1 %22416, %22418
  %22420 = load i32, i32* %16, align 4
  %22421 = icmp eq i32 %22386, %22420
  %22422 = or i1 %22419, %22421
  %22423 = load i32, i32* %17, align 4
  %22424 = icmp eq i32 %22386, %22423
  %22425 = or i1 %22422, %22424
  %22426 = load i32, i32* %18, align 4
  %22427 = icmp eq i32 %22386, %22426
  %22428 = or i1 %22425, %22427
  %22429 = load i32, i32* %19, align 4
  %22430 = icmp eq i32 %22386, %22429
  %22431 = or i1 %22428, %22430
  %22432 = load i32, i32* %20, align 4
  %22433 = icmp eq i32 %22386, %22432
  %22434 = or i1 %22431, %22433
  %22435 = load i32, i32* %21, align 4
  %22436 = icmp eq i32 %22386, %22435
  %22437 = or i1 %22434, %22436
  %22438 = load i32, i32* %22, align 4
  %22439 = icmp eq i32 %22386, %22438
  %22440 = or i1 %22437, %22439
  %22441 = load i32, i32* %23, align 4
  %22442 = icmp eq i32 %22386, %22441
  %22443 = or i1 %22440, %22442
  %22444 = load i32, i32* %24, align 4
  %22445 = icmp eq i32 %22386, %22444
  %22446 = or i1 %22443, %22445
  %22447 = load i32, i32* %25, align 4
  %22448 = icmp eq i32 %22386, %22447
  %22449 = or i1 %22446, %22448
  %22450 = load i32, i32* %26, align 4
  %22451 = icmp eq i32 %22386, %22450
  %22452 = or i1 %22449, %22451
  %22453 = load i32, i32* %27, align 4
  %22454 = icmp eq i32 %22386, %22453
  %22455 = or i1 %22452, %22454
  %22456 = load i32, i32* %28, align 4
  %22457 = icmp eq i32 %22386, %22456
  %22458 = or i1 %22455, %22457
  %22459 = load i32, i32* %29, align 4
  %22460 = icmp eq i32 %22386, %22459
  %22461 = or i1 %22458, %22460
  %22462 = load i32, i32* %30, align 4
  %22463 = icmp eq i32 %22386, %22462
  %22464 = or i1 %22461, %22463
  %22465 = load i32, i32* %31, align 4
  %22466 = icmp eq i32 %22386, %22465
  %22467 = or i1 %22464, %22466
  %22468 = load i32, i32* %32, align 4
  %22469 = icmp eq i32 %22386, %22468
  %22470 = or i1 %22467, %22469
  %22471 = load i32, i32* %33, align 4
  %22472 = icmp eq i32 %22386, %22471
  %22473 = or i1 %22470, %22472
  %22474 = load i32, i32* %34, align 4
  %22475 = icmp eq i32 %22386, %22474
  %22476 = or i1 %22473, %22475
  %22477 = load i32, i32* %35, align 4
  %22478 = icmp eq i32 %22386, %22477
  %22479 = or i1 %22476, %22478
  %22480 = load i32, i32* %36, align 4
  %22481 = icmp eq i32 %22386, %22480
  %22482 = or i1 %22479, %22481
  %22483 = load i32, i32* %37, align 4
  %22484 = icmp eq i32 %22386, %22483
  %22485 = or i1 %22482, %22484
  %22486 = load i32, i32* %38, align 4
  %22487 = icmp eq i32 %22386, %22486
  %22488 = or i1 %22485, %22487
  %22489 = load i32, i32* %39, align 4
  %22490 = icmp eq i32 %22386, %22489
  %22491 = or i1 %22488, %22490
  %22492 = load i32, i32* %40, align 4
  %22493 = icmp eq i32 %22386, %22492
  %22494 = or i1 %22491, %22493
  %22495 = load i32, i32* %41, align 4
  %22496 = icmp eq i32 %22386, %22495
  %22497 = or i1 %22494, %22496
  %22498 = load i32, i32* %42, align 4
  %22499 = icmp eq i32 %22386, %22498
  %22500 = or i1 %22497, %22499
  %22501 = load i32, i32* %43, align 4
  %22502 = icmp eq i32 %22386, %22501
  %22503 = or i1 %22500, %22502
  %22504 = load i32, i32* %44, align 4
  %22505 = icmp eq i32 %22386, %22504
  %22506 = or i1 %22503, %22505
  %22507 = load i32, i32* %45, align 4
  %22508 = icmp eq i32 %22386, %22507
  %22509 = or i1 %22506, %22508
  %22510 = load i32, i32* %46, align 4
  %22511 = icmp eq i32 %22386, %22510
  %22512 = or i1 %22509, %22511
  %22513 = load i32, i32* %47, align 4
  %22514 = icmp eq i32 %22386, %22513
  %22515 = or i1 %22512, %22514
  %22516 = load i32, i32* %48, align 4
  %22517 = icmp eq i32 %22386, %22516
  %22518 = or i1 %22515, %22517
  %22519 = load i32, i32* %49, align 4
  %22520 = icmp eq i32 %22386, %22519
  %22521 = or i1 %22518, %22520
  %22522 = load i32, i32* %50, align 4
  %22523 = icmp eq i32 %22386, %22522
  %22524 = or i1 %22521, %22523
  %22525 = load i32, i32* %51, align 4
  %22526 = icmp eq i32 %22386, %22525
  %22527 = or i1 %22524, %22526
  %22528 = load i32, i32* %52, align 4
  %22529 = icmp eq i32 %22386, %22528
  %22530 = or i1 %22527, %22529
  %22531 = load i32, i32* %53, align 4
  %22532 = icmp eq i32 %22386, %22531
  %22533 = or i1 %22530, %22532
  %22534 = load i32, i32* %54, align 4
  %22535 = icmp eq i32 %22386, %22534
  %22536 = or i1 %22533, %22535
  %22537 = load i32, i32* %55, align 4
  %22538 = icmp eq i32 %22386, %22537
  %22539 = or i1 %22536, %22538
  %22540 = load i32, i32* %56, align 4
  %22541 = icmp eq i32 %22386, %22540
  %22542 = or i1 %22539, %22541
  %22543 = load i32, i32* %57, align 4
  %22544 = icmp eq i32 %22386, %22543
  %22545 = or i1 %22542, %22544
  %22546 = load i32, i32* %58, align 4
  %22547 = icmp eq i32 %22386, %22546
  %22548 = or i1 %22545, %22547
  %22549 = load i32, i32* %59, align 4
  %22550 = icmp eq i32 %22386, %22549
  %22551 = or i1 %22548, %22550
  %22552 = load i32, i32* %60, align 4
  %22553 = icmp eq i32 %22386, %22552
  %22554 = or i1 %22551, %22553
  %22555 = load i32, i32* %61, align 4
  %22556 = icmp eq i32 %22386, %22555
  %22557 = or i1 %22554, %22556
  %22558 = load i32, i32* %62, align 4
  %22559 = icmp eq i32 %22386, %22558
  %22560 = or i1 %22557, %22559
  %22561 = getelementptr i8, i8 addrspace(1)* %4, i32 77
  %22562 = zext i1 %22560 to i8
  store i8 %22562, i8 addrspace(1)* %22561, align 1, !nosanitize !3
  %22563 = load i256, i256* %22385, align 4
  %22564 = alloca i256, align 8
  store i256 %22563, i256* %22564, align 4
  %22565 = alloca i256, align 8
  store i256 1, i256* %22565, align 4
  %22566 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %22564, i256* %22565, i256* %22566), !pc !371, !intsan !6
  %22567 = load i256, i256* %22566, align 4
  %22568 = and i256 1461501637330902918203684832716283019655932542975, %22567
  %22569 = and i256 1461501637330902918203684832716283019655932542975, %22568
  %22570 = icmp eq i256 %22569, %22383
  %22571 = icmp eq i1 %22570, false
  %22572 = icmp eq i1 %22571, false
  %22573 = trunc i256 7869 to i64
  %jump.check90 = icmp ne i1 %22572, false
  br i1 %jump.check90, label %.7869, label %.7865, !EVMBB !4

.7865:                                            ; preds = %22375
  %22574 = load i64, i64* %remaing_gas, align 4
  %22575 = icmp ugt i64 16, %22574
  br i1 %22575, label %Abort, label %22576

22576:                                            ; preds = %.7865
  %22577 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22578 = xor i32 %22577, 1598
  %22579 = urem i32 %22578, 4096
  %22580 = getelementptr i8, i8 addrspace(1)* %4, i32 %22579
  %22581 = load i8, i8 addrspace(1)* %22580, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22580, align 1, !nosanitize !3
  store i32 799, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22582 = sub i64 %22574, 16
  store i64 %22582, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.7869:                                            ; preds = %22375, %JumpTable
  %22583 = load i64, i64* %remaing_gas, align 4
  %22584 = icmp ugt i64 168, %22583
  br i1 %22584, label %Abort, label %22585

22585:                                            ; preds = %.7869
  %22586 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22587 = xor i32 %22586, 2565
  %22588 = urem i32 %22587, 4096
  %22589 = getelementptr i8, i8 addrspace(1)* %4, i32 %22588
  %22590 = load i8, i8 addrspace(1)* %22589, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22589, align 1, !nosanitize !3
  store i32 1282, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22591 = sub i64 %22583, 168
  store i64 %22591, i64* %remaing_gas, align 4
  %22592 = load i64, i64* %STACK_DEP_PTR, align 4
  %22593 = getelementptr i256, i256* %STACK, i64 %22592
  %22594 = load i256, i256* %22593, align 4
  %22595 = load i64, i64* %STACK_DEP_PTR, align 4
  %22596 = sub i64 %22595, 1
  store i64 %22596, i64* %STACK_DEP_PTR, align 4
  %22597 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, 0, !pc !372, !intsan !45
  %22598 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %22599 = and i256 %22598, %22594
  %22600 = icmp eq i256 %22599, %22597
  %22601 = icmp eq i1 %22600, false
  %22602 = trunc i256 7951 to i64
  %jump.check96 = icmp ne i1 %22601, false
  %22603 = load i64, i64* %STACK_DEP_PTR, align 4
  %22604 = add i64 %22603, 1
  store i64 %22604, i64* %STACK_DEP_PTR, align 4
  %22605 = load i64, i64* %STACK_DEP_PTR, align 4
  %22606 = getelementptr i256, i256* %STACK, i64 %22605
  store i256 %22594, i256* %22606, align 4
  br i1 %jump.check96, label %.7951, label %.7947, !EVMBB !4

.7947:                                            ; preds = %22585
  %22607 = load i64, i64* %remaing_gas, align 4
  %22608 = icmp ugt i64 40, %22607
  br i1 %22608, label %Abort, label %22609

22609:                                            ; preds = %.7947
  %22610 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22611 = xor i32 %22610, 241
  %22612 = urem i32 %22611, 4096
  %22613 = getelementptr i8, i8 addrspace(1)* %4, i32 %22612
  %22614 = load i8, i8 addrspace(1)* %22613, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22613, align 1, !nosanitize !3
  store i32 120, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22615 = sub i64 %22607, 40
  store i64 %22615, i64* %remaing_gas, align 4
  %22616 = load i64, i64* %STACK_DEP_PTR, align 4
  %22617 = sub i64 %22616, 0
  store i64 %22617, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.7951:                                            ; preds = %22585, %JumpTable
  %22618 = load i64, i64* %remaing_gas, align 4
  %22619 = icmp ugt i64 232, %22618
  br i1 %22619, label %Abort, label %22620

22620:                                            ; preds = %.7951
  %22621 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22622 = xor i32 %22621, 3564
  %22623 = urem i32 %22622, 4096
  %22624 = getelementptr i8, i8 addrspace(1)* %4, i32 %22623
  %22625 = load i8, i8 addrspace(1)* %22624, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22624, align 1, !nosanitize !3
  store i32 1782, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22626 = sub i64 %22618, 232
  store i64 %22626, i64* %remaing_gas, align 4
  %22627 = load i64, i64* %STACK_DEP_PTR, align 4
  %22628 = getelementptr i256, i256* %STACK, i64 %22627
  %22629 = load i256, i256* %22628, align 4
  %22630 = load i64, i64* %STACK_DEP_PTR, align 4
  %22631 = sub i64 %22630, 1
  store i64 %22631, i64* %STACK_DEP_PTR, align 4
  %22632 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, 1, !pc !373, !intsan !45
  %22633 = or i256 %22629, %22632
  %22634 = trunc i256 15876 to i64
  %22635 = load i64, i64* %STACK_DEP_PTR, align 4
  %22636 = add i64 %22635, 1
  store i64 %22636, i64* %STACK_DEP_PTR, align 4
  %22637 = load i64, i64* %STACK_DEP_PTR, align 4
  %22638 = getelementptr i256, i256* %STACK, i64 %22637
  store i256 %22629, i256* %22638, align 4
  %22639 = load i64, i64* %STACK_DEP_PTR, align 4
  %22640 = add i64 %22639, 1
  store i64 %22640, i64* %STACK_DEP_PTR, align 4
  %22641 = load i64, i64* %STACK_DEP_PTR, align 4
  %22642 = getelementptr i256, i256* %STACK, i64 %22641
  store i256 7997, i256* %22642, align 4
  %22643 = load i64, i64* %STACK_DEP_PTR, align 4
  %22644 = add i64 %22643, 1
  store i64 %22644, i64* %STACK_DEP_PTR, align 4
  %22645 = load i64, i64* %STACK_DEP_PTR, align 4
  %22646 = getelementptr i256, i256* %STACK, i64 %22645
  store i256 %22633, i256* %22646, align 4
  br label %.15876, !EVMBB !4

.7997:                                            ; preds = %JumpTable
  %22647 = load i64, i64* %remaing_gas, align 4
  %22648 = icmp ugt i64 128, %22647
  br i1 %22648, label %Abort, label %22649

22649:                                            ; preds = %.7997
  %22650 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22651 = xor i32 %22650, 3801
  %22652 = urem i32 %22651, 4096
  %22653 = getelementptr i8, i8 addrspace(1)* %4, i32 %22652
  %22654 = load i8, i8 addrspace(1)* %22653, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22653, align 1, !nosanitize !3
  store i32 1900, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22655 = sub i64 %22647, 128
  store i64 %22655, i64* %remaing_gas, align 4
  %22656 = load i64, i64* %STACK_DEP_PTR, align 4
  %22657 = getelementptr i256, i256* %STACK, i64 %22656
  %22658 = load i256, i256* %22657, align 4
  %22659 = load i64, i64* %STACK_DEP_PTR, align 4
  %22660 = sub i64 %22659, 1
  store i64 %22660, i64* %STACK_DEP_PTR, align 4
  %22661 = load i64, i64* %STACK_DEP_PTR, align 4
  %22662 = getelementptr i256, i256* %STACK, i64 %22661
  %22663 = load i256, i256* %22662, align 4
  %22664 = load i64, i64* %STACK_DEP_PTR, align 4
  %22665 = sub i64 %22664, 1
  store i64 %22665, i64* %STACK_DEP_PTR, align 4
  %22666 = trunc i256 %22663 to i64
  store i64 %22666, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.8000:                                            ; preds = %2349, %JumpTable
  %22667 = load i64, i64* %remaing_gas, align 4
  %22668 = icmp ugt i64 184, %22667
  br i1 %22668, label %Abort, label %22669

22669:                                            ; preds = %.8000
  %22670 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22671 = xor i32 %22670, 2151
  %22672 = urem i32 %22671, 4096
  %22673 = getelementptr i8, i8 addrspace(1)* %4, i32 %22672
  %22674 = load i8, i8 addrspace(1)* %22673, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22673, align 1, !nosanitize !3
  store i32 1075, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22675 = sub i64 %22667, 184
  store i64 %22675, i64* %remaing_gas, align 4
  %22676 = load i256, i256* %0, align 4
  %22677 = and i256 1461501637330902918203684832716283019655932542975, %22676
  %22678 = alloca i256, align 8
  store i256 7, i256* %22678, align 4
  %22679 = alloca i256, align 8
  call void @__device_sload(i256* %22678, i256* %22679)
  %22680 = call i32 @__hashword(i256* %22678)
  %22681 = load i32, i32* %5, align 4
  %22682 = icmp eq i32 %22680, %22681
  %22683 = or i1 false, %22682
  %22684 = load i32, i32* %6, align 4
  %22685 = icmp eq i32 %22680, %22684
  %22686 = or i1 %22683, %22685
  %22687 = load i32, i32* %7, align 4
  %22688 = icmp eq i32 %22680, %22687
  %22689 = or i1 %22686, %22688
  %22690 = load i32, i32* %8, align 4
  %22691 = icmp eq i32 %22680, %22690
  %22692 = or i1 %22689, %22691
  %22693 = load i32, i32* %9, align 4
  %22694 = icmp eq i32 %22680, %22693
  %22695 = or i1 %22692, %22694
  %22696 = load i32, i32* %10, align 4
  %22697 = icmp eq i32 %22680, %22696
  %22698 = or i1 %22695, %22697
  %22699 = load i32, i32* %11, align 4
  %22700 = icmp eq i32 %22680, %22699
  %22701 = or i1 %22698, %22700
  %22702 = load i32, i32* %12, align 4
  %22703 = icmp eq i32 %22680, %22702
  %22704 = or i1 %22701, %22703
  %22705 = load i32, i32* %13, align 4
  %22706 = icmp eq i32 %22680, %22705
  %22707 = or i1 %22704, %22706
  %22708 = load i32, i32* %14, align 4
  %22709 = icmp eq i32 %22680, %22708
  %22710 = or i1 %22707, %22709
  %22711 = load i32, i32* %15, align 4
  %22712 = icmp eq i32 %22680, %22711
  %22713 = or i1 %22710, %22712
  %22714 = load i32, i32* %16, align 4
  %22715 = icmp eq i32 %22680, %22714
  %22716 = or i1 %22713, %22715
  %22717 = load i32, i32* %17, align 4
  %22718 = icmp eq i32 %22680, %22717
  %22719 = or i1 %22716, %22718
  %22720 = load i32, i32* %18, align 4
  %22721 = icmp eq i32 %22680, %22720
  %22722 = or i1 %22719, %22721
  %22723 = load i32, i32* %19, align 4
  %22724 = icmp eq i32 %22680, %22723
  %22725 = or i1 %22722, %22724
  %22726 = load i32, i32* %20, align 4
  %22727 = icmp eq i32 %22680, %22726
  %22728 = or i1 %22725, %22727
  %22729 = load i32, i32* %21, align 4
  %22730 = icmp eq i32 %22680, %22729
  %22731 = or i1 %22728, %22730
  %22732 = load i32, i32* %22, align 4
  %22733 = icmp eq i32 %22680, %22732
  %22734 = or i1 %22731, %22733
  %22735 = load i32, i32* %23, align 4
  %22736 = icmp eq i32 %22680, %22735
  %22737 = or i1 %22734, %22736
  %22738 = load i32, i32* %24, align 4
  %22739 = icmp eq i32 %22680, %22738
  %22740 = or i1 %22737, %22739
  %22741 = load i32, i32* %25, align 4
  %22742 = icmp eq i32 %22680, %22741
  %22743 = or i1 %22740, %22742
  %22744 = load i32, i32* %26, align 4
  %22745 = icmp eq i32 %22680, %22744
  %22746 = or i1 %22743, %22745
  %22747 = load i32, i32* %27, align 4
  %22748 = icmp eq i32 %22680, %22747
  %22749 = or i1 %22746, %22748
  %22750 = load i32, i32* %28, align 4
  %22751 = icmp eq i32 %22680, %22750
  %22752 = or i1 %22749, %22751
  %22753 = load i32, i32* %29, align 4
  %22754 = icmp eq i32 %22680, %22753
  %22755 = or i1 %22752, %22754
  %22756 = load i32, i32* %30, align 4
  %22757 = icmp eq i32 %22680, %22756
  %22758 = or i1 %22755, %22757
  %22759 = load i32, i32* %31, align 4
  %22760 = icmp eq i32 %22680, %22759
  %22761 = or i1 %22758, %22760
  %22762 = load i32, i32* %32, align 4
  %22763 = icmp eq i32 %22680, %22762
  %22764 = or i1 %22761, %22763
  %22765 = load i32, i32* %33, align 4
  %22766 = icmp eq i32 %22680, %22765
  %22767 = or i1 %22764, %22766
  %22768 = load i32, i32* %34, align 4
  %22769 = icmp eq i32 %22680, %22768
  %22770 = or i1 %22767, %22769
  %22771 = load i32, i32* %35, align 4
  %22772 = icmp eq i32 %22680, %22771
  %22773 = or i1 %22770, %22772
  %22774 = load i32, i32* %36, align 4
  %22775 = icmp eq i32 %22680, %22774
  %22776 = or i1 %22773, %22775
  %22777 = load i32, i32* %37, align 4
  %22778 = icmp eq i32 %22680, %22777
  %22779 = or i1 %22776, %22778
  %22780 = load i32, i32* %38, align 4
  %22781 = icmp eq i32 %22680, %22780
  %22782 = or i1 %22779, %22781
  %22783 = load i32, i32* %39, align 4
  %22784 = icmp eq i32 %22680, %22783
  %22785 = or i1 %22782, %22784
  %22786 = load i32, i32* %40, align 4
  %22787 = icmp eq i32 %22680, %22786
  %22788 = or i1 %22785, %22787
  %22789 = load i32, i32* %41, align 4
  %22790 = icmp eq i32 %22680, %22789
  %22791 = or i1 %22788, %22790
  %22792 = load i32, i32* %42, align 4
  %22793 = icmp eq i32 %22680, %22792
  %22794 = or i1 %22791, %22793
  %22795 = load i32, i32* %43, align 4
  %22796 = icmp eq i32 %22680, %22795
  %22797 = or i1 %22794, %22796
  %22798 = load i32, i32* %44, align 4
  %22799 = icmp eq i32 %22680, %22798
  %22800 = or i1 %22797, %22799
  %22801 = load i32, i32* %45, align 4
  %22802 = icmp eq i32 %22680, %22801
  %22803 = or i1 %22800, %22802
  %22804 = load i32, i32* %46, align 4
  %22805 = icmp eq i32 %22680, %22804
  %22806 = or i1 %22803, %22805
  %22807 = load i32, i32* %47, align 4
  %22808 = icmp eq i32 %22680, %22807
  %22809 = or i1 %22806, %22808
  %22810 = load i32, i32* %48, align 4
  %22811 = icmp eq i32 %22680, %22810
  %22812 = or i1 %22809, %22811
  %22813 = load i32, i32* %49, align 4
  %22814 = icmp eq i32 %22680, %22813
  %22815 = or i1 %22812, %22814
  %22816 = load i32, i32* %50, align 4
  %22817 = icmp eq i32 %22680, %22816
  %22818 = or i1 %22815, %22817
  %22819 = load i32, i32* %51, align 4
  %22820 = icmp eq i32 %22680, %22819
  %22821 = or i1 %22818, %22820
  %22822 = load i32, i32* %52, align 4
  %22823 = icmp eq i32 %22680, %22822
  %22824 = or i1 %22821, %22823
  %22825 = load i32, i32* %53, align 4
  %22826 = icmp eq i32 %22680, %22825
  %22827 = or i1 %22824, %22826
  %22828 = load i32, i32* %54, align 4
  %22829 = icmp eq i32 %22680, %22828
  %22830 = or i1 %22827, %22829
  %22831 = load i32, i32* %55, align 4
  %22832 = icmp eq i32 %22680, %22831
  %22833 = or i1 %22830, %22832
  %22834 = load i32, i32* %56, align 4
  %22835 = icmp eq i32 %22680, %22834
  %22836 = or i1 %22833, %22835
  %22837 = load i32, i32* %57, align 4
  %22838 = icmp eq i32 %22680, %22837
  %22839 = or i1 %22836, %22838
  %22840 = load i32, i32* %58, align 4
  %22841 = icmp eq i32 %22680, %22840
  %22842 = or i1 %22839, %22841
  %22843 = load i32, i32* %59, align 4
  %22844 = icmp eq i32 %22680, %22843
  %22845 = or i1 %22842, %22844
  %22846 = load i32, i32* %60, align 4
  %22847 = icmp eq i32 %22680, %22846
  %22848 = or i1 %22845, %22847
  %22849 = load i32, i32* %61, align 4
  %22850 = icmp eq i32 %22680, %22849
  %22851 = or i1 %22848, %22850
  %22852 = load i32, i32* %62, align 4
  %22853 = icmp eq i32 %22680, %22852
  %22854 = or i1 %22851, %22853
  %22855 = getelementptr i8, i8 addrspace(1)* %4, i32 78
  %22856 = zext i1 %22854 to i8
  store i8 %22856, i8 addrspace(1)* %22855, align 1, !nosanitize !3
  %22857 = load i256, i256* %22679, align 4
  %22858 = alloca i256, align 8
  store i256 %22857, i256* %22858, align 4
  %22859 = alloca i256, align 8
  store i256 1, i256* %22859, align 4
  %22860 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %22858, i256* %22859, i256* %22860), !pc !374, !intsan !6
  %22861 = load i256, i256* %22860, align 4
  %22862 = and i256 1461501637330902918203684832716283019655932542975, %22861
  %22863 = and i256 1461501637330902918203684832716283019655932542975, %22862
  %22864 = icmp eq i256 %22863, %22677
  %22865 = icmp eq i1 %22864, false
  %22866 = icmp eq i1 %22865, false
  %22867 = trunc i256 8092 to i64
  %jump.check95 = icmp ne i1 %22866, false
  br i1 %jump.check95, label %.8092, label %.8088, !EVMBB !4

.8088:                                            ; preds = %22669
  %22868 = load i64, i64* %remaing_gas, align 4
  %22869 = icmp ugt i64 16, %22868
  br i1 %22869, label %Abort, label %22870

22870:                                            ; preds = %.8088
  %22871 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22872 = xor i32 %22871, 3123
  %22873 = urem i32 %22872, 4096
  %22874 = getelementptr i8, i8 addrspace(1)* %4, i32 %22873
  %22875 = load i8, i8 addrspace(1)* %22874, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22874, align 1, !nosanitize !3
  store i32 1561, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22876 = sub i64 %22868, 16
  store i64 %22876, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.8092:                                            ; preds = %22669, %JumpTable
  %22877 = load i64, i64* %remaing_gas, align 4
  %22878 = icmp ugt i64 152, %22877
  br i1 %22878, label %Abort, label %22879

22879:                                            ; preds = %.8092
  %22880 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22881 = xor i32 %22880, 2999
  %22882 = urem i32 %22881, 4096
  %22883 = getelementptr i8, i8 addrspace(1)* %4, i32 %22882
  %22884 = load i8, i8 addrspace(1)* %22883, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %22883, align 1, !nosanitize !3
  store i32 1499, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %22885 = sub i64 %22877, 152
  store i64 %22885, i64* %remaing_gas, align 4
  %22886 = alloca i256, align 8
  store i256 8, i256* %22886, align 4
  %22887 = alloca i256, align 8
  call void @__device_sload(i256* %22886, i256* %22887)
  %22888 = call i32 @__hashword(i256* %22886)
  %22889 = load i32, i32* %5, align 4
  %22890 = icmp eq i32 %22888, %22889
  %22891 = or i1 false, %22890
  %22892 = load i32, i32* %6, align 4
  %22893 = icmp eq i32 %22888, %22892
  %22894 = or i1 %22891, %22893
  %22895 = load i32, i32* %7, align 4
  %22896 = icmp eq i32 %22888, %22895
  %22897 = or i1 %22894, %22896
  %22898 = load i32, i32* %8, align 4
  %22899 = icmp eq i32 %22888, %22898
  %22900 = or i1 %22897, %22899
  %22901 = load i32, i32* %9, align 4
  %22902 = icmp eq i32 %22888, %22901
  %22903 = or i1 %22900, %22902
  %22904 = load i32, i32* %10, align 4
  %22905 = icmp eq i32 %22888, %22904
  %22906 = or i1 %22903, %22905
  %22907 = load i32, i32* %11, align 4
  %22908 = icmp eq i32 %22888, %22907
  %22909 = or i1 %22906, %22908
  %22910 = load i32, i32* %12, align 4
  %22911 = icmp eq i32 %22888, %22910
  %22912 = or i1 %22909, %22911
  %22913 = load i32, i32* %13, align 4
  %22914 = icmp eq i32 %22888, %22913
  %22915 = or i1 %22912, %22914
  %22916 = load i32, i32* %14, align 4
  %22917 = icmp eq i32 %22888, %22916
  %22918 = or i1 %22915, %22917
  %22919 = load i32, i32* %15, align 4
  %22920 = icmp eq i32 %22888, %22919
  %22921 = or i1 %22918, %22920
  %22922 = load i32, i32* %16, align 4
  %22923 = icmp eq i32 %22888, %22922
  %22924 = or i1 %22921, %22923
  %22925 = load i32, i32* %17, align 4
  %22926 = icmp eq i32 %22888, %22925
  %22927 = or i1 %22924, %22926
  %22928 = load i32, i32* %18, align 4
  %22929 = icmp eq i32 %22888, %22928
  %22930 = or i1 %22927, %22929
  %22931 = load i32, i32* %19, align 4
  %22932 = icmp eq i32 %22888, %22931
  %22933 = or i1 %22930, %22932
  %22934 = load i32, i32* %20, align 4
  %22935 = icmp eq i32 %22888, %22934
  %22936 = or i1 %22933, %22935
  %22937 = load i32, i32* %21, align 4
  %22938 = icmp eq i32 %22888, %22937
  %22939 = or i1 %22936, %22938
  %22940 = load i32, i32* %22, align 4
  %22941 = icmp eq i32 %22888, %22940
  %22942 = or i1 %22939, %22941
  %22943 = load i32, i32* %23, align 4
  %22944 = icmp eq i32 %22888, %22943
  %22945 = or i1 %22942, %22944
  %22946 = load i32, i32* %24, align 4
  %22947 = icmp eq i32 %22888, %22946
  %22948 = or i1 %22945, %22947
  %22949 = load i32, i32* %25, align 4
  %22950 = icmp eq i32 %22888, %22949
  %22951 = or i1 %22948, %22950
  %22952 = load i32, i32* %26, align 4
  %22953 = icmp eq i32 %22888, %22952
  %22954 = or i1 %22951, %22953
  %22955 = load i32, i32* %27, align 4
  %22956 = icmp eq i32 %22888, %22955
  %22957 = or i1 %22954, %22956
  %22958 = load i32, i32* %28, align 4
  %22959 = icmp eq i32 %22888, %22958
  %22960 = or i1 %22957, %22959
  %22961 = load i32, i32* %29, align 4
  %22962 = icmp eq i32 %22888, %22961
  %22963 = or i1 %22960, %22962
  %22964 = load i32, i32* %30, align 4
  %22965 = icmp eq i32 %22888, %22964
  %22966 = or i1 %22963, %22965
  %22967 = load i32, i32* %31, align 4
  %22968 = icmp eq i32 %22888, %22967
  %22969 = or i1 %22966, %22968
  %22970 = load i32, i32* %32, align 4
  %22971 = icmp eq i32 %22888, %22970
  %22972 = or i1 %22969, %22971
  %22973 = load i32, i32* %33, align 4
  %22974 = icmp eq i32 %22888, %22973
  %22975 = or i1 %22972, %22974
  %22976 = load i32, i32* %34, align 4
  %22977 = icmp eq i32 %22888, %22976
  %22978 = or i1 %22975, %22977
  %22979 = load i32, i32* %35, align 4
  %22980 = icmp eq i32 %22888, %22979
  %22981 = or i1 %22978, %22980
  %22982 = load i32, i32* %36, align 4
  %22983 = icmp eq i32 %22888, %22982
  %22984 = or i1 %22981, %22983
  %22985 = load i32, i32* %37, align 4
  %22986 = icmp eq i32 %22888, %22985
  %22987 = or i1 %22984, %22986
  %22988 = load i32, i32* %38, align 4
  %22989 = icmp eq i32 %22888, %22988
  %22990 = or i1 %22987, %22989
  %22991 = load i32, i32* %39, align 4
  %22992 = icmp eq i32 %22888, %22991
  %22993 = or i1 %22990, %22992
  %22994 = load i32, i32* %40, align 4
  %22995 = icmp eq i32 %22888, %22994
  %22996 = or i1 %22993, %22995
  %22997 = load i32, i32* %41, align 4
  %22998 = icmp eq i32 %22888, %22997
  %22999 = or i1 %22996, %22998
  %23000 = load i32, i32* %42, align 4
  %23001 = icmp eq i32 %22888, %23000
  %23002 = or i1 %22999, %23001
  %23003 = load i32, i32* %43, align 4
  %23004 = icmp eq i32 %22888, %23003
  %23005 = or i1 %23002, %23004
  %23006 = load i32, i32* %44, align 4
  %23007 = icmp eq i32 %22888, %23006
  %23008 = or i1 %23005, %23007
  %23009 = load i32, i32* %45, align 4
  %23010 = icmp eq i32 %22888, %23009
  %23011 = or i1 %23008, %23010
  %23012 = load i32, i32* %46, align 4
  %23013 = icmp eq i32 %22888, %23012
  %23014 = or i1 %23011, %23013
  %23015 = load i32, i32* %47, align 4
  %23016 = icmp eq i32 %22888, %23015
  %23017 = or i1 %23014, %23016
  %23018 = load i32, i32* %48, align 4
  %23019 = icmp eq i32 %22888, %23018
  %23020 = or i1 %23017, %23019
  %23021 = load i32, i32* %49, align 4
  %23022 = icmp eq i32 %22888, %23021
  %23023 = or i1 %23020, %23022
  %23024 = load i32, i32* %50, align 4
  %23025 = icmp eq i32 %22888, %23024
  %23026 = or i1 %23023, %23025
  %23027 = load i32, i32* %51, align 4
  %23028 = icmp eq i32 %22888, %23027
  %23029 = or i1 %23026, %23028
  %23030 = load i32, i32* %52, align 4
  %23031 = icmp eq i32 %22888, %23030
  %23032 = or i1 %23029, %23031
  %23033 = load i32, i32* %53, align 4
  %23034 = icmp eq i32 %22888, %23033
  %23035 = or i1 %23032, %23034
  %23036 = load i32, i32* %54, align 4
  %23037 = icmp eq i32 %22888, %23036
  %23038 = or i1 %23035, %23037
  %23039 = load i32, i32* %55, align 4
  %23040 = icmp eq i32 %22888, %23039
  %23041 = or i1 %23038, %23040
  %23042 = load i32, i32* %56, align 4
  %23043 = icmp eq i32 %22888, %23042
  %23044 = or i1 %23041, %23043
  %23045 = load i32, i32* %57, align 4
  %23046 = icmp eq i32 %22888, %23045
  %23047 = or i1 %23044, %23046
  %23048 = load i32, i32* %58, align 4
  %23049 = icmp eq i32 %22888, %23048
  %23050 = or i1 %23047, %23049
  %23051 = load i32, i32* %59, align 4
  %23052 = icmp eq i32 %22888, %23051
  %23053 = or i1 %23050, %23052
  %23054 = load i32, i32* %60, align 4
  %23055 = icmp eq i32 %22888, %23054
  %23056 = or i1 %23053, %23055
  %23057 = load i32, i32* %61, align 4
  %23058 = icmp eq i32 %22888, %23057
  %23059 = or i1 %23056, %23058
  %23060 = load i32, i32* %62, align 4
  %23061 = icmp eq i32 %22888, %23060
  %23062 = or i1 %23059, %23061
  %23063 = getelementptr i8, i8 addrspace(1)* %4, i32 79
  %23064 = zext i1 %23062 to i8
  store i8 %23064, i8 addrspace(1)* %23063, align 1, !nosanitize !3
  %23065 = load i256, i256* %22887, align 4
  %23066 = alloca i256, align 8
  store i256 %23065, i256* %23066, align 4
  %23067 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %23067, align 4
  %23068 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %23066, i256* %23067, i256* %23068), !pc !375, !intsan !6
  %23069 = load i256, i256* %23068, align 4
  %23070 = and i256 255, %23069
  %23071 = icmp eq i256 %23070, 0
  %23072 = icmp eq i1 %23071, false
  %23073 = trunc i256 8119 to i64
  %jump.check101 = icmp ne i1 %23072, false
  br i1 %jump.check101, label %.8119, label %.8115, !EVMBB !4

.8115:                                            ; preds = %22879
  %23074 = load i64, i64* %remaing_gas, align 4
  %23075 = icmp ugt i64 16, %23074
  br i1 %23075, label %Abort, label %23076

23076:                                            ; preds = %.8115
  %23077 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23078 = xor i32 %23077, 1689
  %23079 = urem i32 %23078, 4096
  %23080 = getelementptr i8, i8 addrspace(1)* %4, i32 %23079
  %23081 = load i8, i8 addrspace(1)* %23080, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23080, align 1, !nosanitize !3
  store i32 844, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23082 = sub i64 %23074, 16
  store i64 %23082, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.8119:                                            ; preds = %22879, %JumpTable
  %23083 = load i64, i64* %remaing_gas, align 4
  %23084 = icmp ugt i64 216, %23083
  br i1 %23084, label %Abort, label %23085

23085:                                            ; preds = %.8119
  %23086 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23087 = xor i32 %23086, 2128
  %23088 = urem i32 %23087, 4096
  %23089 = getelementptr i8, i8 addrspace(1)* %4, i32 %23088
  %23090 = load i8, i8 addrspace(1)* %23089, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23089, align 1, !nosanitize !3
  store i32 1064, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23091 = sub i64 %23083, 216
  store i64 %23091, i64* %remaing_gas, align 4
  %23092 = load i64, i64* %STACK_DEP_PTR, align 4
  %23093 = getelementptr i256, i256* %STACK, i64 %23092
  %23094 = load i256, i256* %23093, align 4
  %23095 = load i64, i64* %STACK_DEP_PTR, align 4
  %23096 = sub i64 %23095, 1
  store i64 %23096, i64* %STACK_DEP_PTR, align 4
  %23097 = trunc i256 13000 to i64
  %23098 = load i64, i64* %STACK_DEP_PTR, align 4
  %23099 = add i64 %23098, 1
  store i64 %23099, i64* %STACK_DEP_PTR, align 4
  %23100 = load i64, i64* %STACK_DEP_PTR, align 4
  %23101 = getelementptr i256, i256* %STACK, i64 %23100
  store i256 %23094, i256* %23101, align 4
  %23102 = load i64, i64* %STACK_DEP_PTR, align 4
  %23103 = add i64 %23102, 1
  store i64 %23103, i64* %STACK_DEP_PTR, align 4
  %23104 = load i64, i64* %STACK_DEP_PTR, align 4
  %23105 = getelementptr i256, i256* %STACK, i64 %23104
  store i256 8128, i256* %23105, align 4
  %23106 = load i64, i64* %STACK_DEP_PTR, align 4
  %23107 = add i64 %23106, 1
  store i64 %23107, i64* %STACK_DEP_PTR, align 4
  %23108 = load i64, i64* %STACK_DEP_PTR, align 4
  %23109 = getelementptr i256, i256* %STACK, i64 %23108
  store i256 %23094, i256* %23109, align 4
  br label %.13000, !EVMBB !4

.8128:                                            ; preds = %JumpTable
  %23110 = load i64, i64* %remaing_gas, align 4
  %23111 = icmp ugt i64 288, %23110
  br i1 %23111, label %Abort, label %23112

23112:                                            ; preds = %.8128
  %23113 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23114 = xor i32 %23113, 2467
  %23115 = urem i32 %23114, 4096
  %23116 = getelementptr i8, i8 addrspace(1)* %4, i32 %23115
  %23117 = load i8, i8 addrspace(1)* %23116, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23116, align 1, !nosanitize !3
  store i32 1233, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23118 = sub i64 %23110, 288
  store i64 %23118, i64* %remaing_gas, align 4
  %23119 = load i64, i64* %STACK_DEP_PTR, align 4
  %23120 = getelementptr i256, i256* %STACK, i64 %23119
  %23121 = load i256, i256* %23120, align 4
  %23122 = load i64, i64* %STACK_DEP_PTR, align 4
  %23123 = sub i64 %23122, 1
  store i64 %23123, i64* %STACK_DEP_PTR, align 4
  %23124 = load i64, i64* %STACK_DEP_PTR, align 4
  %23125 = getelementptr i256, i256* %STACK, i64 %23124
  %23126 = load i256, i256* %23125, align 4
  %23127 = load i64, i64* %STACK_DEP_PTR, align 4
  %23128 = sub i64 %23127, 1
  store i64 %23128, i64* %STACK_DEP_PTR, align 4
  %23129 = add i256 9, 0, !pc !376, !intsan !10
  %23130 = alloca i256, align 8
  store i256 %23129, i256* %23130, align 4
  %23131 = alloca i256, align 8
  call void @__device_sload(i256* %23130, i256* %23131)
  %23132 = call i32 @__hashword(i256* %23130)
  %23133 = load i32, i32* %5, align 4
  %23134 = icmp eq i32 %23132, %23133
  %23135 = or i1 false, %23134
  %23136 = load i32, i32* %6, align 4
  %23137 = icmp eq i32 %23132, %23136
  %23138 = or i1 %23135, %23137
  %23139 = load i32, i32* %7, align 4
  %23140 = icmp eq i32 %23132, %23139
  %23141 = or i1 %23138, %23140
  %23142 = load i32, i32* %8, align 4
  %23143 = icmp eq i32 %23132, %23142
  %23144 = or i1 %23141, %23143
  %23145 = load i32, i32* %9, align 4
  %23146 = icmp eq i32 %23132, %23145
  %23147 = or i1 %23144, %23146
  %23148 = load i32, i32* %10, align 4
  %23149 = icmp eq i32 %23132, %23148
  %23150 = or i1 %23147, %23149
  %23151 = load i32, i32* %11, align 4
  %23152 = icmp eq i32 %23132, %23151
  %23153 = or i1 %23150, %23152
  %23154 = load i32, i32* %12, align 4
  %23155 = icmp eq i32 %23132, %23154
  %23156 = or i1 %23153, %23155
  %23157 = load i32, i32* %13, align 4
  %23158 = icmp eq i32 %23132, %23157
  %23159 = or i1 %23156, %23158
  %23160 = load i32, i32* %14, align 4
  %23161 = icmp eq i32 %23132, %23160
  %23162 = or i1 %23159, %23161
  %23163 = load i32, i32* %15, align 4
  %23164 = icmp eq i32 %23132, %23163
  %23165 = or i1 %23162, %23164
  %23166 = load i32, i32* %16, align 4
  %23167 = icmp eq i32 %23132, %23166
  %23168 = or i1 %23165, %23167
  %23169 = load i32, i32* %17, align 4
  %23170 = icmp eq i32 %23132, %23169
  %23171 = or i1 %23168, %23170
  %23172 = load i32, i32* %18, align 4
  %23173 = icmp eq i32 %23132, %23172
  %23174 = or i1 %23171, %23173
  %23175 = load i32, i32* %19, align 4
  %23176 = icmp eq i32 %23132, %23175
  %23177 = or i1 %23174, %23176
  %23178 = load i32, i32* %20, align 4
  %23179 = icmp eq i32 %23132, %23178
  %23180 = or i1 %23177, %23179
  %23181 = load i32, i32* %21, align 4
  %23182 = icmp eq i32 %23132, %23181
  %23183 = or i1 %23180, %23182
  %23184 = load i32, i32* %22, align 4
  %23185 = icmp eq i32 %23132, %23184
  %23186 = or i1 %23183, %23185
  %23187 = load i32, i32* %23, align 4
  %23188 = icmp eq i32 %23132, %23187
  %23189 = or i1 %23186, %23188
  %23190 = load i32, i32* %24, align 4
  %23191 = icmp eq i32 %23132, %23190
  %23192 = or i1 %23189, %23191
  %23193 = load i32, i32* %25, align 4
  %23194 = icmp eq i32 %23132, %23193
  %23195 = or i1 %23192, %23194
  %23196 = load i32, i32* %26, align 4
  %23197 = icmp eq i32 %23132, %23196
  %23198 = or i1 %23195, %23197
  %23199 = load i32, i32* %27, align 4
  %23200 = icmp eq i32 %23132, %23199
  %23201 = or i1 %23198, %23200
  %23202 = load i32, i32* %28, align 4
  %23203 = icmp eq i32 %23132, %23202
  %23204 = or i1 %23201, %23203
  %23205 = load i32, i32* %29, align 4
  %23206 = icmp eq i32 %23132, %23205
  %23207 = or i1 %23204, %23206
  %23208 = load i32, i32* %30, align 4
  %23209 = icmp eq i32 %23132, %23208
  %23210 = or i1 %23207, %23209
  %23211 = load i32, i32* %31, align 4
  %23212 = icmp eq i32 %23132, %23211
  %23213 = or i1 %23210, %23212
  %23214 = load i32, i32* %32, align 4
  %23215 = icmp eq i32 %23132, %23214
  %23216 = or i1 %23213, %23215
  %23217 = load i32, i32* %33, align 4
  %23218 = icmp eq i32 %23132, %23217
  %23219 = or i1 %23216, %23218
  %23220 = load i32, i32* %34, align 4
  %23221 = icmp eq i32 %23132, %23220
  %23222 = or i1 %23219, %23221
  %23223 = load i32, i32* %35, align 4
  %23224 = icmp eq i32 %23132, %23223
  %23225 = or i1 %23222, %23224
  %23226 = load i32, i32* %36, align 4
  %23227 = icmp eq i32 %23132, %23226
  %23228 = or i1 %23225, %23227
  %23229 = load i32, i32* %37, align 4
  %23230 = icmp eq i32 %23132, %23229
  %23231 = or i1 %23228, %23230
  %23232 = load i32, i32* %38, align 4
  %23233 = icmp eq i32 %23132, %23232
  %23234 = or i1 %23231, %23233
  %23235 = load i32, i32* %39, align 4
  %23236 = icmp eq i32 %23132, %23235
  %23237 = or i1 %23234, %23236
  %23238 = load i32, i32* %40, align 4
  %23239 = icmp eq i32 %23132, %23238
  %23240 = or i1 %23237, %23239
  %23241 = load i32, i32* %41, align 4
  %23242 = icmp eq i32 %23132, %23241
  %23243 = or i1 %23240, %23242
  %23244 = load i32, i32* %42, align 4
  %23245 = icmp eq i32 %23132, %23244
  %23246 = or i1 %23243, %23245
  %23247 = load i32, i32* %43, align 4
  %23248 = icmp eq i32 %23132, %23247
  %23249 = or i1 %23246, %23248
  %23250 = load i32, i32* %44, align 4
  %23251 = icmp eq i32 %23132, %23250
  %23252 = or i1 %23249, %23251
  %23253 = load i32, i32* %45, align 4
  %23254 = icmp eq i32 %23132, %23253
  %23255 = or i1 %23252, %23254
  %23256 = load i32, i32* %46, align 4
  %23257 = icmp eq i32 %23132, %23256
  %23258 = or i1 %23255, %23257
  %23259 = load i32, i32* %47, align 4
  %23260 = icmp eq i32 %23132, %23259
  %23261 = or i1 %23258, %23260
  %23262 = load i32, i32* %48, align 4
  %23263 = icmp eq i32 %23132, %23262
  %23264 = or i1 %23261, %23263
  %23265 = load i32, i32* %49, align 4
  %23266 = icmp eq i32 %23132, %23265
  %23267 = or i1 %23264, %23266
  %23268 = load i32, i32* %50, align 4
  %23269 = icmp eq i32 %23132, %23268
  %23270 = or i1 %23267, %23269
  %23271 = load i32, i32* %51, align 4
  %23272 = icmp eq i32 %23132, %23271
  %23273 = or i1 %23270, %23272
  %23274 = load i32, i32* %52, align 4
  %23275 = icmp eq i32 %23132, %23274
  %23276 = or i1 %23273, %23275
  %23277 = load i32, i32* %53, align 4
  %23278 = icmp eq i32 %23132, %23277
  %23279 = or i1 %23276, %23278
  %23280 = load i32, i32* %54, align 4
  %23281 = icmp eq i32 %23132, %23280
  %23282 = or i1 %23279, %23281
  %23283 = load i32, i32* %55, align 4
  %23284 = icmp eq i32 %23132, %23283
  %23285 = or i1 %23282, %23284
  %23286 = load i32, i32* %56, align 4
  %23287 = icmp eq i32 %23132, %23286
  %23288 = or i1 %23285, %23287
  %23289 = load i32, i32* %57, align 4
  %23290 = icmp eq i32 %23132, %23289
  %23291 = or i1 %23288, %23290
  %23292 = load i32, i32* %58, align 4
  %23293 = icmp eq i32 %23132, %23292
  %23294 = or i1 %23291, %23293
  %23295 = load i32, i32* %59, align 4
  %23296 = icmp eq i32 %23132, %23295
  %23297 = or i1 %23294, %23296
  %23298 = load i32, i32* %60, align 4
  %23299 = icmp eq i32 %23132, %23298
  %23300 = or i1 %23297, %23299
  %23301 = load i32, i32* %61, align 4
  %23302 = icmp eq i32 %23132, %23301
  %23303 = or i1 %23300, %23302
  %23304 = load i32, i32* %62, align 4
  %23305 = icmp eq i32 %23132, %23304
  %23306 = or i1 %23303, %23305
  %23307 = getelementptr i8, i8 addrspace(1)* %4, i32 80
  %23308 = zext i1 %23306 to i8
  store i8 %23308, i8 addrspace(1)* %23307, align 1, !nosanitize !3
  %23309 = load i256, i256* %23131, align 4
  %23310 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !377, !intsan !45
  %23311 = xor i256 %23310, -1
  %23312 = and i256 %23311, %23309
  %23313 = alloca i256, align 8
  store i256 %23129, i256* %23313, align 4
  %23314 = alloca i256, align 8
  store i256 %23312, i256* %23314, align 4
  call void @__device_sstore(i256* %23313, i256* %23314)
  %23315 = call i32 @__hashword(i256* %23313)
  store i32 %23315, i32* %42, align 4, !nosanitize !3
  %23316 = add i256 9, 1, !pc !378, !intsan !10
  %23317 = alloca i256, align 8
  store i256 %23316, i256* %23317, align 4
  %23318 = alloca i256, align 8
  store i256 0, i256* %23318, align 4
  call void @__device_sstore(i256* %23317, i256* %23318)
  %23319 = call i32 @__hashword(i256* %23317)
  store i32 %23319, i32* %43, align 4, !nosanitize !3
  %23320 = trunc i256 %23126 to i64
  store i64 %23320, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.8183:                                            ; preds = %2417, %JumpTable
  %23321 = load i64, i64* %remaing_gas, align 4
  %23322 = icmp ugt i64 384, %23321
  br i1 %23322, label %Abort, label %23323

23323:                                            ; preds = %.8183
  %23324 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23325 = xor i32 %23324, 739
  %23326 = urem i32 %23325, 4096
  %23327 = getelementptr i8, i8 addrspace(1)* %4, i32 %23326
  %23328 = load i8, i8 addrspace(1)* %23327, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23327, align 1, !nosanitize !3
  store i32 369, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23329 = sub i64 %23321, 384
  store i64 %23329, i64* %remaing_gas, align 4
  %23330 = load i64, i64* %STACK_DEP_PTR, align 4
  %23331 = getelementptr i256, i256* %STACK, i64 %23330
  %23332 = load i256, i256* %23331, align 4
  %23333 = load i64, i64* %STACK_DEP_PTR, align 4
  %23334 = sub i64 %23333, 1
  store i64 %23334, i64* %STACK_DEP_PTR, align 4
  %23335 = add i256 0, 9, !pc !379, !intsan !10
  %23336 = alloca i256, align 8
  store i256 %23335, i256* %23336, align 4
  %23337 = alloca i256, align 8
  call void @__device_sload(i256* %23336, i256* %23337)
  %23338 = call i32 @__hashword(i256* %23336)
  %23339 = load i32, i32* %5, align 4
  %23340 = icmp eq i32 %23338, %23339
  %23341 = or i1 false, %23340
  %23342 = load i32, i32* %6, align 4
  %23343 = icmp eq i32 %23338, %23342
  %23344 = or i1 %23341, %23343
  %23345 = load i32, i32* %7, align 4
  %23346 = icmp eq i32 %23338, %23345
  %23347 = or i1 %23344, %23346
  %23348 = load i32, i32* %8, align 4
  %23349 = icmp eq i32 %23338, %23348
  %23350 = or i1 %23347, %23349
  %23351 = load i32, i32* %9, align 4
  %23352 = icmp eq i32 %23338, %23351
  %23353 = or i1 %23350, %23352
  %23354 = load i32, i32* %10, align 4
  %23355 = icmp eq i32 %23338, %23354
  %23356 = or i1 %23353, %23355
  %23357 = load i32, i32* %11, align 4
  %23358 = icmp eq i32 %23338, %23357
  %23359 = or i1 %23356, %23358
  %23360 = load i32, i32* %12, align 4
  %23361 = icmp eq i32 %23338, %23360
  %23362 = or i1 %23359, %23361
  %23363 = load i32, i32* %13, align 4
  %23364 = icmp eq i32 %23338, %23363
  %23365 = or i1 %23362, %23364
  %23366 = load i32, i32* %14, align 4
  %23367 = icmp eq i32 %23338, %23366
  %23368 = or i1 %23365, %23367
  %23369 = load i32, i32* %15, align 4
  %23370 = icmp eq i32 %23338, %23369
  %23371 = or i1 %23368, %23370
  %23372 = load i32, i32* %16, align 4
  %23373 = icmp eq i32 %23338, %23372
  %23374 = or i1 %23371, %23373
  %23375 = load i32, i32* %17, align 4
  %23376 = icmp eq i32 %23338, %23375
  %23377 = or i1 %23374, %23376
  %23378 = load i32, i32* %18, align 4
  %23379 = icmp eq i32 %23338, %23378
  %23380 = or i1 %23377, %23379
  %23381 = load i32, i32* %19, align 4
  %23382 = icmp eq i32 %23338, %23381
  %23383 = or i1 %23380, %23382
  %23384 = load i32, i32* %20, align 4
  %23385 = icmp eq i32 %23338, %23384
  %23386 = or i1 %23383, %23385
  %23387 = load i32, i32* %21, align 4
  %23388 = icmp eq i32 %23338, %23387
  %23389 = or i1 %23386, %23388
  %23390 = load i32, i32* %22, align 4
  %23391 = icmp eq i32 %23338, %23390
  %23392 = or i1 %23389, %23391
  %23393 = load i32, i32* %23, align 4
  %23394 = icmp eq i32 %23338, %23393
  %23395 = or i1 %23392, %23394
  %23396 = load i32, i32* %24, align 4
  %23397 = icmp eq i32 %23338, %23396
  %23398 = or i1 %23395, %23397
  %23399 = load i32, i32* %25, align 4
  %23400 = icmp eq i32 %23338, %23399
  %23401 = or i1 %23398, %23400
  %23402 = load i32, i32* %26, align 4
  %23403 = icmp eq i32 %23338, %23402
  %23404 = or i1 %23401, %23403
  %23405 = load i32, i32* %27, align 4
  %23406 = icmp eq i32 %23338, %23405
  %23407 = or i1 %23404, %23406
  %23408 = load i32, i32* %28, align 4
  %23409 = icmp eq i32 %23338, %23408
  %23410 = or i1 %23407, %23409
  %23411 = load i32, i32* %29, align 4
  %23412 = icmp eq i32 %23338, %23411
  %23413 = or i1 %23410, %23412
  %23414 = load i32, i32* %30, align 4
  %23415 = icmp eq i32 %23338, %23414
  %23416 = or i1 %23413, %23415
  %23417 = load i32, i32* %31, align 4
  %23418 = icmp eq i32 %23338, %23417
  %23419 = or i1 %23416, %23418
  %23420 = load i32, i32* %32, align 4
  %23421 = icmp eq i32 %23338, %23420
  %23422 = or i1 %23419, %23421
  %23423 = load i32, i32* %33, align 4
  %23424 = icmp eq i32 %23338, %23423
  %23425 = or i1 %23422, %23424
  %23426 = load i32, i32* %34, align 4
  %23427 = icmp eq i32 %23338, %23426
  %23428 = or i1 %23425, %23427
  %23429 = load i32, i32* %35, align 4
  %23430 = icmp eq i32 %23338, %23429
  %23431 = or i1 %23428, %23430
  %23432 = load i32, i32* %36, align 4
  %23433 = icmp eq i32 %23338, %23432
  %23434 = or i1 %23431, %23433
  %23435 = load i32, i32* %37, align 4
  %23436 = icmp eq i32 %23338, %23435
  %23437 = or i1 %23434, %23436
  %23438 = load i32, i32* %38, align 4
  %23439 = icmp eq i32 %23338, %23438
  %23440 = or i1 %23437, %23439
  %23441 = load i32, i32* %39, align 4
  %23442 = icmp eq i32 %23338, %23441
  %23443 = or i1 %23440, %23442
  %23444 = load i32, i32* %40, align 4
  %23445 = icmp eq i32 %23338, %23444
  %23446 = or i1 %23443, %23445
  %23447 = load i32, i32* %41, align 4
  %23448 = icmp eq i32 %23338, %23447
  %23449 = or i1 %23446, %23448
  %23450 = load i32, i32* %42, align 4
  %23451 = icmp eq i32 %23338, %23450
  %23452 = or i1 %23449, %23451
  %23453 = load i32, i32* %43, align 4
  %23454 = icmp eq i32 %23338, %23453
  %23455 = or i1 %23452, %23454
  %23456 = load i32, i32* %44, align 4
  %23457 = icmp eq i32 %23338, %23456
  %23458 = or i1 %23455, %23457
  %23459 = load i32, i32* %45, align 4
  %23460 = icmp eq i32 %23338, %23459
  %23461 = or i1 %23458, %23460
  %23462 = load i32, i32* %46, align 4
  %23463 = icmp eq i32 %23338, %23462
  %23464 = or i1 %23461, %23463
  %23465 = load i32, i32* %47, align 4
  %23466 = icmp eq i32 %23338, %23465
  %23467 = or i1 %23464, %23466
  %23468 = load i32, i32* %48, align 4
  %23469 = icmp eq i32 %23338, %23468
  %23470 = or i1 %23467, %23469
  %23471 = load i32, i32* %49, align 4
  %23472 = icmp eq i32 %23338, %23471
  %23473 = or i1 %23470, %23472
  %23474 = load i32, i32* %50, align 4
  %23475 = icmp eq i32 %23338, %23474
  %23476 = or i1 %23473, %23475
  %23477 = load i32, i32* %51, align 4
  %23478 = icmp eq i32 %23338, %23477
  %23479 = or i1 %23476, %23478
  %23480 = load i32, i32* %52, align 4
  %23481 = icmp eq i32 %23338, %23480
  %23482 = or i1 %23479, %23481
  %23483 = load i32, i32* %53, align 4
  %23484 = icmp eq i32 %23338, %23483
  %23485 = or i1 %23482, %23484
  %23486 = load i32, i32* %54, align 4
  %23487 = icmp eq i32 %23338, %23486
  %23488 = or i1 %23485, %23487
  %23489 = load i32, i32* %55, align 4
  %23490 = icmp eq i32 %23338, %23489
  %23491 = or i1 %23488, %23490
  %23492 = load i32, i32* %56, align 4
  %23493 = icmp eq i32 %23338, %23492
  %23494 = or i1 %23491, %23493
  %23495 = load i32, i32* %57, align 4
  %23496 = icmp eq i32 %23338, %23495
  %23497 = or i1 %23494, %23496
  %23498 = load i32, i32* %58, align 4
  %23499 = icmp eq i32 %23338, %23498
  %23500 = or i1 %23497, %23499
  %23501 = load i32, i32* %59, align 4
  %23502 = icmp eq i32 %23338, %23501
  %23503 = or i1 %23500, %23502
  %23504 = load i32, i32* %60, align 4
  %23505 = icmp eq i32 %23338, %23504
  %23506 = or i1 %23503, %23505
  %23507 = load i32, i32* %61, align 4
  %23508 = icmp eq i32 %23338, %23507
  %23509 = or i1 %23506, %23508
  %23510 = load i32, i32* %62, align 4
  %23511 = icmp eq i32 %23338, %23510
  %23512 = or i1 %23509, %23511
  %23513 = getelementptr i8, i8 addrspace(1)* %4, i32 81
  %23514 = zext i1 %23512 to i8
  store i8 %23514, i8 addrspace(1)* %23513, align 1, !nosanitize !3
  %23515 = load i256, i256* %23337, align 4
  %23516 = alloca i256, align 8
  store i256 %23515, i256* %23516, align 4
  %23517 = alloca i256, align 8
  store i256 1, i256* %23517, align 4
  %23518 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %23516, i256* %23517, i256* %23518), !pc !380, !intsan !6
  %23519 = load i256, i256* %23518, align 4
  %23520 = and i256 1461501637330902918203684832716283019655932542975, %23519
  %23521 = add i256 1, 9, !pc !381, !intsan !10
  %23522 = alloca i256, align 8
  store i256 %23521, i256* %23522, align 4
  %23523 = alloca i256, align 8
  call void @__device_sload(i256* %23522, i256* %23523)
  %23524 = call i32 @__hashword(i256* %23522)
  %23525 = load i32, i32* %5, align 4
  %23526 = icmp eq i32 %23524, %23525
  %23527 = or i1 false, %23526
  %23528 = load i32, i32* %6, align 4
  %23529 = icmp eq i32 %23524, %23528
  %23530 = or i1 %23527, %23529
  %23531 = load i32, i32* %7, align 4
  %23532 = icmp eq i32 %23524, %23531
  %23533 = or i1 %23530, %23532
  %23534 = load i32, i32* %8, align 4
  %23535 = icmp eq i32 %23524, %23534
  %23536 = or i1 %23533, %23535
  %23537 = load i32, i32* %9, align 4
  %23538 = icmp eq i32 %23524, %23537
  %23539 = or i1 %23536, %23538
  %23540 = load i32, i32* %10, align 4
  %23541 = icmp eq i32 %23524, %23540
  %23542 = or i1 %23539, %23541
  %23543 = load i32, i32* %11, align 4
  %23544 = icmp eq i32 %23524, %23543
  %23545 = or i1 %23542, %23544
  %23546 = load i32, i32* %12, align 4
  %23547 = icmp eq i32 %23524, %23546
  %23548 = or i1 %23545, %23547
  %23549 = load i32, i32* %13, align 4
  %23550 = icmp eq i32 %23524, %23549
  %23551 = or i1 %23548, %23550
  %23552 = load i32, i32* %14, align 4
  %23553 = icmp eq i32 %23524, %23552
  %23554 = or i1 %23551, %23553
  %23555 = load i32, i32* %15, align 4
  %23556 = icmp eq i32 %23524, %23555
  %23557 = or i1 %23554, %23556
  %23558 = load i32, i32* %16, align 4
  %23559 = icmp eq i32 %23524, %23558
  %23560 = or i1 %23557, %23559
  %23561 = load i32, i32* %17, align 4
  %23562 = icmp eq i32 %23524, %23561
  %23563 = or i1 %23560, %23562
  %23564 = load i32, i32* %18, align 4
  %23565 = icmp eq i32 %23524, %23564
  %23566 = or i1 %23563, %23565
  %23567 = load i32, i32* %19, align 4
  %23568 = icmp eq i32 %23524, %23567
  %23569 = or i1 %23566, %23568
  %23570 = load i32, i32* %20, align 4
  %23571 = icmp eq i32 %23524, %23570
  %23572 = or i1 %23569, %23571
  %23573 = load i32, i32* %21, align 4
  %23574 = icmp eq i32 %23524, %23573
  %23575 = or i1 %23572, %23574
  %23576 = load i32, i32* %22, align 4
  %23577 = icmp eq i32 %23524, %23576
  %23578 = or i1 %23575, %23577
  %23579 = load i32, i32* %23, align 4
  %23580 = icmp eq i32 %23524, %23579
  %23581 = or i1 %23578, %23580
  %23582 = load i32, i32* %24, align 4
  %23583 = icmp eq i32 %23524, %23582
  %23584 = or i1 %23581, %23583
  %23585 = load i32, i32* %25, align 4
  %23586 = icmp eq i32 %23524, %23585
  %23587 = or i1 %23584, %23586
  %23588 = load i32, i32* %26, align 4
  %23589 = icmp eq i32 %23524, %23588
  %23590 = or i1 %23587, %23589
  %23591 = load i32, i32* %27, align 4
  %23592 = icmp eq i32 %23524, %23591
  %23593 = or i1 %23590, %23592
  %23594 = load i32, i32* %28, align 4
  %23595 = icmp eq i32 %23524, %23594
  %23596 = or i1 %23593, %23595
  %23597 = load i32, i32* %29, align 4
  %23598 = icmp eq i32 %23524, %23597
  %23599 = or i1 %23596, %23598
  %23600 = load i32, i32* %30, align 4
  %23601 = icmp eq i32 %23524, %23600
  %23602 = or i1 %23599, %23601
  %23603 = load i32, i32* %31, align 4
  %23604 = icmp eq i32 %23524, %23603
  %23605 = or i1 %23602, %23604
  %23606 = load i32, i32* %32, align 4
  %23607 = icmp eq i32 %23524, %23606
  %23608 = or i1 %23605, %23607
  %23609 = load i32, i32* %33, align 4
  %23610 = icmp eq i32 %23524, %23609
  %23611 = or i1 %23608, %23610
  %23612 = load i32, i32* %34, align 4
  %23613 = icmp eq i32 %23524, %23612
  %23614 = or i1 %23611, %23613
  %23615 = load i32, i32* %35, align 4
  %23616 = icmp eq i32 %23524, %23615
  %23617 = or i1 %23614, %23616
  %23618 = load i32, i32* %36, align 4
  %23619 = icmp eq i32 %23524, %23618
  %23620 = or i1 %23617, %23619
  %23621 = load i32, i32* %37, align 4
  %23622 = icmp eq i32 %23524, %23621
  %23623 = or i1 %23620, %23622
  %23624 = load i32, i32* %38, align 4
  %23625 = icmp eq i32 %23524, %23624
  %23626 = or i1 %23623, %23625
  %23627 = load i32, i32* %39, align 4
  %23628 = icmp eq i32 %23524, %23627
  %23629 = or i1 %23626, %23628
  %23630 = load i32, i32* %40, align 4
  %23631 = icmp eq i32 %23524, %23630
  %23632 = or i1 %23629, %23631
  %23633 = load i32, i32* %41, align 4
  %23634 = icmp eq i32 %23524, %23633
  %23635 = or i1 %23632, %23634
  %23636 = load i32, i32* %42, align 4
  %23637 = icmp eq i32 %23524, %23636
  %23638 = or i1 %23635, %23637
  %23639 = load i32, i32* %43, align 4
  %23640 = icmp eq i32 %23524, %23639
  %23641 = or i1 %23638, %23640
  %23642 = load i32, i32* %44, align 4
  %23643 = icmp eq i32 %23524, %23642
  %23644 = or i1 %23641, %23643
  %23645 = load i32, i32* %45, align 4
  %23646 = icmp eq i32 %23524, %23645
  %23647 = or i1 %23644, %23646
  %23648 = load i32, i32* %46, align 4
  %23649 = icmp eq i32 %23524, %23648
  %23650 = or i1 %23647, %23649
  %23651 = load i32, i32* %47, align 4
  %23652 = icmp eq i32 %23524, %23651
  %23653 = or i1 %23650, %23652
  %23654 = load i32, i32* %48, align 4
  %23655 = icmp eq i32 %23524, %23654
  %23656 = or i1 %23653, %23655
  %23657 = load i32, i32* %49, align 4
  %23658 = icmp eq i32 %23524, %23657
  %23659 = or i1 %23656, %23658
  %23660 = load i32, i32* %50, align 4
  %23661 = icmp eq i32 %23524, %23660
  %23662 = or i1 %23659, %23661
  %23663 = load i32, i32* %51, align 4
  %23664 = icmp eq i32 %23524, %23663
  %23665 = or i1 %23662, %23664
  %23666 = load i32, i32* %52, align 4
  %23667 = icmp eq i32 %23524, %23666
  %23668 = or i1 %23665, %23667
  %23669 = load i32, i32* %53, align 4
  %23670 = icmp eq i32 %23524, %23669
  %23671 = or i1 %23668, %23670
  %23672 = load i32, i32* %54, align 4
  %23673 = icmp eq i32 %23524, %23672
  %23674 = or i1 %23671, %23673
  %23675 = load i32, i32* %55, align 4
  %23676 = icmp eq i32 %23524, %23675
  %23677 = or i1 %23674, %23676
  %23678 = load i32, i32* %56, align 4
  %23679 = icmp eq i32 %23524, %23678
  %23680 = or i1 %23677, %23679
  %23681 = load i32, i32* %57, align 4
  %23682 = icmp eq i32 %23524, %23681
  %23683 = or i1 %23680, %23682
  %23684 = load i32, i32* %58, align 4
  %23685 = icmp eq i32 %23524, %23684
  %23686 = or i1 %23683, %23685
  %23687 = load i32, i32* %59, align 4
  %23688 = icmp eq i32 %23524, %23687
  %23689 = or i1 %23686, %23688
  %23690 = load i32, i32* %60, align 4
  %23691 = icmp eq i32 %23524, %23690
  %23692 = or i1 %23689, %23691
  %23693 = load i32, i32* %61, align 4
  %23694 = icmp eq i32 %23524, %23693
  %23695 = or i1 %23692, %23694
  %23696 = load i32, i32* %62, align 4
  %23697 = icmp eq i32 %23524, %23696
  %23698 = or i1 %23695, %23697
  %23699 = getelementptr i8, i8 addrspace(1)* %4, i32 82
  %23700 = zext i1 %23698 to i8
  store i8 %23700, i8 addrspace(1)* %23699, align 1, !nosanitize !3
  %23701 = load i256, i256* %23523, align 4
  %23702 = trunc i256 %23332 to i64
  store i64 %23702, i64* %JMP_TARGET_PTR, align 4
  %23703 = load i64, i64* %STACK_DEP_PTR, align 4
  %23704 = add i64 %23703, 1
  store i64 %23704, i64* %STACK_DEP_PTR, align 4
  %23705 = load i64, i64* %STACK_DEP_PTR, align 4
  %23706 = getelementptr i256, i256* %STACK, i64 %23705
  store i256 %23332, i256* %23706, align 4
  %23707 = load i64, i64* %STACK_DEP_PTR, align 4
  %23708 = add i64 %23707, 1
  store i64 %23708, i64* %STACK_DEP_PTR, align 4
  %23709 = load i64, i64* %STACK_DEP_PTR, align 4
  %23710 = getelementptr i256, i256* %STACK, i64 %23709
  store i256 %23520, i256* %23710, align 4
  %23711 = load i64, i64* %STACK_DEP_PTR, align 4
  %23712 = add i64 %23711, 1
  store i64 %23712, i64* %STACK_DEP_PTR, align 4
  %23713 = load i64, i64* %STACK_DEP_PTR, align 4
  %23714 = getelementptr i256, i256* %STACK, i64 %23713
  store i256 %23701, i256* %23714, align 4
  br label %JumpTable, !EVMBB !4

.8233:                                            ; preds = %2499, %JumpTable
  %23715 = load i64, i64* %remaing_gas, align 4
  %23716 = icmp ugt i64 928, %23715
  br i1 %23716, label %Abort, label %23717

23717:                                            ; preds = %.8233
  %23718 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23719 = xor i32 %23718, 3092
  %23720 = urem i32 %23719, 4096
  %23721 = getelementptr i8, i8 addrspace(1)* %4, i32 %23720
  %23722 = load i8, i8 addrspace(1)* %23721, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23721, align 1, !nosanitize !3
  store i32 1546, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23723 = sub i64 %23715, 928
  store i64 %23723, i64* %remaing_gas, align 4
  %23724 = alloca i256, align 8
  store i256 0, i256* %23724, align 4
  %23725 = alloca i256, align 8
  call void @__device_sload(i256* %23724, i256* %23725)
  %23726 = call i32 @__hashword(i256* %23724)
  %23727 = load i32, i32* %5, align 4
  %23728 = icmp eq i32 %23726, %23727
  %23729 = or i1 false, %23728
  %23730 = load i32, i32* %6, align 4
  %23731 = icmp eq i32 %23726, %23730
  %23732 = or i1 %23729, %23731
  %23733 = load i32, i32* %7, align 4
  %23734 = icmp eq i32 %23726, %23733
  %23735 = or i1 %23732, %23734
  %23736 = load i32, i32* %8, align 4
  %23737 = icmp eq i32 %23726, %23736
  %23738 = or i1 %23735, %23737
  %23739 = load i32, i32* %9, align 4
  %23740 = icmp eq i32 %23726, %23739
  %23741 = or i1 %23738, %23740
  %23742 = load i32, i32* %10, align 4
  %23743 = icmp eq i32 %23726, %23742
  %23744 = or i1 %23741, %23743
  %23745 = load i32, i32* %11, align 4
  %23746 = icmp eq i32 %23726, %23745
  %23747 = or i1 %23744, %23746
  %23748 = load i32, i32* %12, align 4
  %23749 = icmp eq i32 %23726, %23748
  %23750 = or i1 %23747, %23749
  %23751 = load i32, i32* %13, align 4
  %23752 = icmp eq i32 %23726, %23751
  %23753 = or i1 %23750, %23752
  %23754 = load i32, i32* %14, align 4
  %23755 = icmp eq i32 %23726, %23754
  %23756 = or i1 %23753, %23755
  %23757 = load i32, i32* %15, align 4
  %23758 = icmp eq i32 %23726, %23757
  %23759 = or i1 %23756, %23758
  %23760 = load i32, i32* %16, align 4
  %23761 = icmp eq i32 %23726, %23760
  %23762 = or i1 %23759, %23761
  %23763 = load i32, i32* %17, align 4
  %23764 = icmp eq i32 %23726, %23763
  %23765 = or i1 %23762, %23764
  %23766 = load i32, i32* %18, align 4
  %23767 = icmp eq i32 %23726, %23766
  %23768 = or i1 %23765, %23767
  %23769 = load i32, i32* %19, align 4
  %23770 = icmp eq i32 %23726, %23769
  %23771 = or i1 %23768, %23770
  %23772 = load i32, i32* %20, align 4
  %23773 = icmp eq i32 %23726, %23772
  %23774 = or i1 %23771, %23773
  %23775 = load i32, i32* %21, align 4
  %23776 = icmp eq i32 %23726, %23775
  %23777 = or i1 %23774, %23776
  %23778 = load i32, i32* %22, align 4
  %23779 = icmp eq i32 %23726, %23778
  %23780 = or i1 %23777, %23779
  %23781 = load i32, i32* %23, align 4
  %23782 = icmp eq i32 %23726, %23781
  %23783 = or i1 %23780, %23782
  %23784 = load i32, i32* %24, align 4
  %23785 = icmp eq i32 %23726, %23784
  %23786 = or i1 %23783, %23785
  %23787 = load i32, i32* %25, align 4
  %23788 = icmp eq i32 %23726, %23787
  %23789 = or i1 %23786, %23788
  %23790 = load i32, i32* %26, align 4
  %23791 = icmp eq i32 %23726, %23790
  %23792 = or i1 %23789, %23791
  %23793 = load i32, i32* %27, align 4
  %23794 = icmp eq i32 %23726, %23793
  %23795 = or i1 %23792, %23794
  %23796 = load i32, i32* %28, align 4
  %23797 = icmp eq i32 %23726, %23796
  %23798 = or i1 %23795, %23797
  %23799 = load i32, i32* %29, align 4
  %23800 = icmp eq i32 %23726, %23799
  %23801 = or i1 %23798, %23800
  %23802 = load i32, i32* %30, align 4
  %23803 = icmp eq i32 %23726, %23802
  %23804 = or i1 %23801, %23803
  %23805 = load i32, i32* %31, align 4
  %23806 = icmp eq i32 %23726, %23805
  %23807 = or i1 %23804, %23806
  %23808 = load i32, i32* %32, align 4
  %23809 = icmp eq i32 %23726, %23808
  %23810 = or i1 %23807, %23809
  %23811 = load i32, i32* %33, align 4
  %23812 = icmp eq i32 %23726, %23811
  %23813 = or i1 %23810, %23812
  %23814 = load i32, i32* %34, align 4
  %23815 = icmp eq i32 %23726, %23814
  %23816 = or i1 %23813, %23815
  %23817 = load i32, i32* %35, align 4
  %23818 = icmp eq i32 %23726, %23817
  %23819 = or i1 %23816, %23818
  %23820 = load i32, i32* %36, align 4
  %23821 = icmp eq i32 %23726, %23820
  %23822 = or i1 %23819, %23821
  %23823 = load i32, i32* %37, align 4
  %23824 = icmp eq i32 %23726, %23823
  %23825 = or i1 %23822, %23824
  %23826 = load i32, i32* %38, align 4
  %23827 = icmp eq i32 %23726, %23826
  %23828 = or i1 %23825, %23827
  %23829 = load i32, i32* %39, align 4
  %23830 = icmp eq i32 %23726, %23829
  %23831 = or i1 %23828, %23830
  %23832 = load i32, i32* %40, align 4
  %23833 = icmp eq i32 %23726, %23832
  %23834 = or i1 %23831, %23833
  %23835 = load i32, i32* %41, align 4
  %23836 = icmp eq i32 %23726, %23835
  %23837 = or i1 %23834, %23836
  %23838 = load i32, i32* %42, align 4
  %23839 = icmp eq i32 %23726, %23838
  %23840 = or i1 %23837, %23839
  %23841 = load i32, i32* %43, align 4
  %23842 = icmp eq i32 %23726, %23841
  %23843 = or i1 %23840, %23842
  %23844 = load i32, i32* %44, align 4
  %23845 = icmp eq i32 %23726, %23844
  %23846 = or i1 %23843, %23845
  %23847 = load i32, i32* %45, align 4
  %23848 = icmp eq i32 %23726, %23847
  %23849 = or i1 %23846, %23848
  %23850 = load i32, i32* %46, align 4
  %23851 = icmp eq i32 %23726, %23850
  %23852 = or i1 %23849, %23851
  %23853 = load i32, i32* %47, align 4
  %23854 = icmp eq i32 %23726, %23853
  %23855 = or i1 %23852, %23854
  %23856 = load i32, i32* %48, align 4
  %23857 = icmp eq i32 %23726, %23856
  %23858 = or i1 %23855, %23857
  %23859 = load i32, i32* %49, align 4
  %23860 = icmp eq i32 %23726, %23859
  %23861 = or i1 %23858, %23860
  %23862 = load i32, i32* %50, align 4
  %23863 = icmp eq i32 %23726, %23862
  %23864 = or i1 %23861, %23863
  %23865 = load i32, i32* %51, align 4
  %23866 = icmp eq i32 %23726, %23865
  %23867 = or i1 %23864, %23866
  %23868 = load i32, i32* %52, align 4
  %23869 = icmp eq i32 %23726, %23868
  %23870 = or i1 %23867, %23869
  %23871 = load i32, i32* %53, align 4
  %23872 = icmp eq i32 %23726, %23871
  %23873 = or i1 %23870, %23872
  %23874 = load i32, i32* %54, align 4
  %23875 = icmp eq i32 %23726, %23874
  %23876 = or i1 %23873, %23875
  %23877 = load i32, i32* %55, align 4
  %23878 = icmp eq i32 %23726, %23877
  %23879 = or i1 %23876, %23878
  %23880 = load i32, i32* %56, align 4
  %23881 = icmp eq i32 %23726, %23880
  %23882 = or i1 %23879, %23881
  %23883 = load i32, i32* %57, align 4
  %23884 = icmp eq i32 %23726, %23883
  %23885 = or i1 %23882, %23884
  %23886 = load i32, i32* %58, align 4
  %23887 = icmp eq i32 %23726, %23886
  %23888 = or i1 %23885, %23887
  %23889 = load i32, i32* %59, align 4
  %23890 = icmp eq i32 %23726, %23889
  %23891 = or i1 %23888, %23890
  %23892 = load i32, i32* %60, align 4
  %23893 = icmp eq i32 %23726, %23892
  %23894 = or i1 %23891, %23893
  %23895 = load i32, i32* %61, align 4
  %23896 = icmp eq i32 %23726, %23895
  %23897 = or i1 %23894, %23896
  %23898 = load i32, i32* %62, align 4
  %23899 = icmp eq i32 %23726, %23898
  %23900 = or i1 %23897, %23899
  %23901 = getelementptr i8, i8 addrspace(1)* %4, i32 83
  %23902 = zext i1 %23900 to i8
  store i8 %23902, i8 addrspace(1)* %23901, align 1, !nosanitize !3
  %23903 = load i256, i256* %23725, align 4
  %23904 = alloca i256, align 8
  store i256 %23903, i256* %23904, align 4
  %23905 = alloca i256, align 8
  store i256 1, i256* %23905, align 4
  %23906 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %23904, i256* %23905, i256* %23906), !pc !382, !intsan !6
  %23907 = load i256, i256* %23906, align 4
  %23908 = and i256 1461501637330902918203684832716283019655932542975, %23907
  %23909 = and i256 1461501637330902918203684832716283019655932542975, %23908
  %23910 = trunc i256 64 to i64
  %23911 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %23910, i256* %23911)
  %23912 = load i256, i256* %23911, align 4
  %23913 = and i256 4294967295, 952911921
  %23914 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %23913, !pc !383, !intsan !45
  %23915 = trunc i256 %23912 to i64
  %23916 = alloca i256, align 8
  store i256 %23914, i256* %23916, align 4
  %23917 = bitcast i256* %23916 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %23915, i8* %23917, i64 32)
  %23918 = add i256 4, %23912, !pc !384, !intsan !10
  %23919 = trunc i256 64 to i64
  %23920 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %23919, i256* %23920)
  %23921 = load i256, i256* %23920, align 4
  %23922 = sub i256 %23918, %23921, !pc !385, !intsan !8
  %23923 = icmp eq i256 1, 0
  %23924 = icmp eq i1 %23923, false
  %23925 = trunc i256 8371 to i64
  %jump.check105 = icmp ne i1 %23924, false
  %23926 = load i64, i64* %STACK_DEP_PTR, align 4
  %23927 = add i64 %23926, 1
  store i64 %23927, i64* %STACK_DEP_PTR, align 4
  %23928 = load i64, i64* %STACK_DEP_PTR, align 4
  %23929 = getelementptr i256, i256* %STACK, i64 %23928
  store i256 0, i256* %23929, align 4
  %23930 = load i64, i64* %STACK_DEP_PTR, align 4
  %23931 = add i64 %23930, 1
  store i64 %23931, i64* %STACK_DEP_PTR, align 4
  %23932 = load i64, i64* %STACK_DEP_PTR, align 4
  %23933 = getelementptr i256, i256* %STACK, i64 %23932
  store i256 0, i256* %23933, align 4
  %23934 = load i64, i64* %STACK_DEP_PTR, align 4
  %23935 = add i64 %23934, 1
  store i64 %23935, i64* %STACK_DEP_PTR, align 4
  %23936 = load i64, i64* %STACK_DEP_PTR, align 4
  %23937 = getelementptr i256, i256* %STACK, i64 %23936
  store i256 0, i256* %23937, align 4
  %23938 = load i64, i64* %STACK_DEP_PTR, align 4
  %23939 = add i64 %23938, 1
  store i64 %23939, i64* %STACK_DEP_PTR, align 4
  %23940 = load i64, i64* %STACK_DEP_PTR, align 4
  %23941 = getelementptr i256, i256* %STACK, i64 %23940
  store i256 %23909, i256* %23941, align 4
  %23942 = load i64, i64* %STACK_DEP_PTR, align 4
  %23943 = add i64 %23942, 1
  store i64 %23943, i64* %STACK_DEP_PTR, align 4
  %23944 = load i64, i64* %STACK_DEP_PTR, align 4
  %23945 = getelementptr i256, i256* %STACK, i64 %23944
  store i256 952911921, i256* %23945, align 4
  %23946 = load i64, i64* %STACK_DEP_PTR, align 4
  %23947 = add i64 %23946, 1
  store i64 %23947, i64* %STACK_DEP_PTR, align 4
  %23948 = load i64, i64* %STACK_DEP_PTR, align 4
  %23949 = getelementptr i256, i256* %STACK, i64 %23948
  store i256 %23918, i256* %23949, align 4
  %23950 = load i64, i64* %STACK_DEP_PTR, align 4
  %23951 = add i64 %23950, 1
  store i64 %23951, i64* %STACK_DEP_PTR, align 4
  %23952 = load i64, i64* %STACK_DEP_PTR, align 4
  %23953 = getelementptr i256, i256* %STACK, i64 %23952
  store i256 32, i256* %23953, align 4
  %23954 = load i64, i64* %STACK_DEP_PTR, align 4
  %23955 = add i64 %23954, 1
  store i64 %23955, i64* %STACK_DEP_PTR, align 4
  %23956 = load i64, i64* %STACK_DEP_PTR, align 4
  %23957 = getelementptr i256, i256* %STACK, i64 %23956
  store i256 %23921, i256* %23957, align 4
  %23958 = load i64, i64* %STACK_DEP_PTR, align 4
  %23959 = add i64 %23958, 1
  store i64 %23959, i64* %STACK_DEP_PTR, align 4
  %23960 = load i64, i64* %STACK_DEP_PTR, align 4
  %23961 = getelementptr i256, i256* %STACK, i64 %23960
  store i256 %23922, i256* %23961, align 4
  %23962 = load i64, i64* %STACK_DEP_PTR, align 4
  %23963 = add i64 %23962, 1
  store i64 %23963, i64* %STACK_DEP_PTR, align 4
  %23964 = load i64, i64* %STACK_DEP_PTR, align 4
  %23965 = getelementptr i256, i256* %STACK, i64 %23964
  store i256 %23921, i256* %23965, align 4
  %23966 = load i64, i64* %STACK_DEP_PTR, align 4
  %23967 = add i64 %23966, 1
  store i64 %23967, i64* %STACK_DEP_PTR, align 4
  %23968 = load i64, i64* %STACK_DEP_PTR, align 4
  %23969 = getelementptr i256, i256* %STACK, i64 %23968
  store i256 0, i256* %23969, align 4
  %23970 = load i64, i64* %STACK_DEP_PTR, align 4
  %23971 = add i64 %23970, 1
  store i64 %23971, i64* %STACK_DEP_PTR, align 4
  %23972 = load i64, i64* %STACK_DEP_PTR, align 4
  %23973 = getelementptr i256, i256* %STACK, i64 %23972
  store i256 %23909, i256* %23973, align 4
  %23974 = load i64, i64* %STACK_DEP_PTR, align 4
  %23975 = add i64 %23974, 1
  store i64 %23975, i64* %STACK_DEP_PTR, align 4
  %23976 = zext i1 %23923 to i256
  %23977 = load i64, i64* %STACK_DEP_PTR, align 4
  %23978 = getelementptr i256, i256* %STACK, i64 %23977
  store i256 %23976, i256* %23978, align 4
  br i1 %jump.check105, label %.8371, label %.8367, !EVMBB !4

.8367:                                            ; preds = %23717
  %23979 = load i64, i64* %remaing_gas, align 4
  %23980 = icmp ugt i64 40, %23979
  br i1 %23980, label %Abort, label %23981

23981:                                            ; preds = %.8367
  %23982 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23983 = xor i32 %23982, 2003
  %23984 = urem i32 %23983, 4096
  %23985 = getelementptr i8, i8 addrspace(1)* %4, i32 %23984
  %23986 = load i8, i8 addrspace(1)* %23985, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23985, align 1, !nosanitize !3
  store i32 1001, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23987 = sub i64 %23979, 40
  store i64 %23987, i64* %remaing_gas, align 4
  %23988 = load i64, i64* %STACK_DEP_PTR, align 4
  %23989 = sub i64 %23988, 0
  store i64 %23989, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8371:                                            ; preds = %23717, %JumpTable
  %23990 = load i64, i64* %remaing_gas, align 4
  %23991 = icmp ugt i64 456, %23990
  br i1 %23991, label %Abort, label %23992

23992:                                            ; preds = %.8371
  %23993 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23994 = xor i32 %23993, 3545
  %23995 = urem i32 %23994, 4096
  %23996 = getelementptr i8, i8 addrspace(1)* %4, i32 %23995
  %23997 = load i8, i8 addrspace(1)* %23996, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %23996, align 1, !nosanitize !3
  store i32 1772, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %23998 = sub i64 %23990, 456
  store i64 %23998, i64* %remaing_gas, align 4
  %23999 = load i64, i64* %STACK_DEP_PTR, align 4
  %24000 = getelementptr i256, i256* %STACK, i64 %23999
  %24001 = load i256, i256* %24000, align 4
  %24002 = load i64, i64* %STACK_DEP_PTR, align 4
  %24003 = sub i64 %24002, 1
  store i64 %24003, i64* %STACK_DEP_PTR, align 4
  %24004 = load i64, i64* %STACK_DEP_PTR, align 4
  %24005 = getelementptr i256, i256* %STACK, i64 %24004
  %24006 = load i256, i256* %24005, align 4
  %24007 = load i64, i64* %STACK_DEP_PTR, align 4
  %24008 = sub i64 %24007, 1
  store i64 %24008, i64* %STACK_DEP_PTR, align 4
  %24009 = load i64, i64* %STACK_DEP_PTR, align 4
  %24010 = getelementptr i256, i256* %STACK, i64 %24009
  %24011 = load i256, i256* %24010, align 4
  %24012 = load i64, i64* %STACK_DEP_PTR, align 4
  %24013 = sub i64 %24012, 1
  store i64 %24013, i64* %STACK_DEP_PTR, align 4
  %24014 = load i64, i64* %STACK_DEP_PTR, align 4
  %24015 = getelementptr i256, i256* %STACK, i64 %24014
  %24016 = load i256, i256* %24015, align 4
  %24017 = load i64, i64* %STACK_DEP_PTR, align 4
  %24018 = sub i64 %24017, 1
  store i64 %24018, i64* %STACK_DEP_PTR, align 4
  %24019 = load i64, i64* %STACK_DEP_PTR, align 4
  %24020 = getelementptr i256, i256* %STACK, i64 %24019
  %24021 = load i256, i256* %24020, align 4
  %24022 = load i64, i64* %STACK_DEP_PTR, align 4
  %24023 = sub i64 %24022, 1
  store i64 %24023, i64* %STACK_DEP_PTR, align 4
  %24024 = load i64, i64* %STACK_DEP_PTR, align 4
  %24025 = getelementptr i256, i256* %STACK, i64 %24024
  %24026 = load i256, i256* %24025, align 4
  %24027 = load i64, i64* %STACK_DEP_PTR, align 4
  %24028 = sub i64 %24027, 1
  store i64 %24028, i64* %STACK_DEP_PTR, align 4
  %24029 = load i64, i64* %STACK_DEP_PTR, align 4
  %24030 = getelementptr i256, i256* %STACK, i64 %24029
  %24031 = load i256, i256* %24030, align 4
  %24032 = load i64, i64* %STACK_DEP_PTR, align 4
  %24033 = sub i64 %24032, 1
  store i64 %24033, i64* %STACK_DEP_PTR, align 4
  %24034 = trunc i256 %24006 to i160
  %24035 = call i1 @solidity_call(), !pc !386
  %24036 = icmp eq i1 %24035, false
  %24037 = icmp eq i1 %24036, false
  %24038 = trunc i256 8391 to i64
  %jump.check111 = icmp ne i1 %24037, false
  %24039 = load i64, i64* %STACK_DEP_PTR, align 4
  %24040 = add i64 %24039, 1
  store i64 %24040, i64* %STACK_DEP_PTR, align 4
  %24041 = zext i1 %24036 to i256
  %24042 = load i64, i64* %STACK_DEP_PTR, align 4
  %24043 = getelementptr i256, i256* %STACK, i64 %24042
  store i256 %24041, i256* %24043, align 4
  br i1 %jump.check111, label %.8391, label %.8382, !EVMBB !4

.8382:                                            ; preds = %23992
  %24044 = load i64, i64* %remaing_gas, align 4
  %24045 = icmp ugt i64 40, %24044
  br i1 %24045, label %Abort, label %24046

24046:                                            ; preds = %.8382
  %24047 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24048 = xor i32 %24047, 2612
  %24049 = urem i32 %24048, 4096
  %24050 = getelementptr i8, i8 addrspace(1)* %4, i32 %24049
  %24051 = load i8, i8 addrspace(1)* %24050, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24050, align 1, !nosanitize !3
  store i32 1306, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24052 = sub i64 %24044, 40
  store i64 %24052, i64* %remaing_gas, align 4
  %24053 = load i64, i64* %STACK_DEP_PTR, align 4
  %24054 = sub i64 %24053, 0
  store i64 %24054, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8391:                                            ; preds = %23992, %JumpTable
  %24055 = load i64, i64* %remaing_gas, align 4
  %24056 = icmp ugt i64 384, %24055
  br i1 %24056, label %Abort, label %24057

24057:                                            ; preds = %.8391
  %24058 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24059 = xor i32 %24058, 4087
  %24060 = urem i32 %24059, 4096
  %24061 = getelementptr i8, i8 addrspace(1)* %4, i32 %24060
  %24062 = load i8, i8 addrspace(1)* %24061, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24061, align 1, !nosanitize !3
  store i32 2043, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24063 = sub i64 %24055, 384
  store i64 %24063, i64* %remaing_gas, align 4
  %24064 = load i64, i64* %STACK_DEP_PTR, align 4
  %24065 = getelementptr i256, i256* %STACK, i64 %24064
  %24066 = load i256, i256* %24065, align 4
  %24067 = load i64, i64* %STACK_DEP_PTR, align 4
  %24068 = sub i64 %24067, 1
  store i64 %24068, i64* %STACK_DEP_PTR, align 4
  %24069 = load i64, i64* %STACK_DEP_PTR, align 4
  %24070 = getelementptr i256, i256* %STACK, i64 %24069
  %24071 = load i256, i256* %24070, align 4
  %24072 = load i64, i64* %STACK_DEP_PTR, align 4
  %24073 = sub i64 %24072, 1
  store i64 %24073, i64* %STACK_DEP_PTR, align 4
  %24074 = load i64, i64* %STACK_DEP_PTR, align 4
  %24075 = getelementptr i256, i256* %STACK, i64 %24074
  %24076 = load i256, i256* %24075, align 4
  %24077 = load i64, i64* %STACK_DEP_PTR, align 4
  %24078 = sub i64 %24077, 1
  store i64 %24078, i64* %STACK_DEP_PTR, align 4
  %24079 = load i64, i64* %STACK_DEP_PTR, align 4
  %24080 = getelementptr i256, i256* %STACK, i64 %24079
  %24081 = load i256, i256* %24080, align 4
  %24082 = load i64, i64* %STACK_DEP_PTR, align 4
  %24083 = sub i64 %24082, 1
  store i64 %24083, i64* %STACK_DEP_PTR, align 4
  %24084 = trunc i256 64 to i64
  %24085 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24084, i256* %24085)
  %24086 = load i256, i256* %24085, align 4
  %24087 = zext i64 0 to i256
  %24088 = icmp ult i256 %24087, 32
  %24089 = icmp eq i1 %24088, false
  %24090 = trunc i256 8413 to i64
  %jump.check117 = icmp ne i1 %24089, false
  %24091 = load i64, i64* %STACK_DEP_PTR, align 4
  %24092 = add i64 %24091, 1
  store i64 %24092, i64* %STACK_DEP_PTR, align 4
  %24093 = load i64, i64* %STACK_DEP_PTR, align 4
  %24094 = getelementptr i256, i256* %STACK, i64 %24093
  store i256 %24086, i256* %24094, align 4
  %24095 = load i64, i64* %STACK_DEP_PTR, align 4
  %24096 = add i64 %24095, 1
  store i64 %24096, i64* %STACK_DEP_PTR, align 4
  %24097 = zext i64 0 to i256
  %24098 = load i64, i64* %STACK_DEP_PTR, align 4
  %24099 = getelementptr i256, i256* %STACK, i64 %24098
  store i256 %24097, i256* %24099, align 4
  br i1 %jump.check117, label %.8413, label %.8409, !EVMBB !4

.8409:                                            ; preds = %24057
  %24100 = load i64, i64* %remaing_gas, align 4
  %24101 = icmp ugt i64 40, %24100
  br i1 %24101, label %Abort, label %24102

24102:                                            ; preds = %.8409
  %24103 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24104 = xor i32 %24103, 1118
  %24105 = urem i32 %24104, 4096
  %24106 = getelementptr i8, i8 addrspace(1)* %4, i32 %24105
  %24107 = load i8, i8 addrspace(1)* %24106, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24106, align 1, !nosanitize !3
  store i32 559, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24108 = sub i64 %24100, 40
  store i64 %24108, i64* %remaing_gas, align 4
  %24109 = load i64, i64* %STACK_DEP_PTR, align 4
  %24110 = sub i64 %24109, 0
  store i64 %24110, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8413:                                            ; preds = %24057, %JumpTable
  %24111 = load i64, i64* %remaing_gas, align 4
  %24112 = icmp ugt i64 1072, %24111
  br i1 %24112, label %Abort, label %24113

24113:                                            ; preds = %.8413
  %24114 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24115 = xor i32 %24114, 4000
  %24116 = urem i32 %24115, 4096
  %24117 = getelementptr i8, i8 addrspace(1)* %4, i32 %24116
  %24118 = load i8, i8 addrspace(1)* %24117, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24117, align 1, !nosanitize !3
  store i32 2000, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24119 = sub i64 %24111, 1072
  store i64 %24119, i64* %remaing_gas, align 4
  %24120 = load i64, i64* %STACK_DEP_PTR, align 4
  %24121 = getelementptr i256, i256* %STACK, i64 %24120
  %24122 = load i256, i256* %24121, align 4
  %24123 = load i64, i64* %STACK_DEP_PTR, align 4
  %24124 = sub i64 %24123, 1
  store i64 %24124, i64* %STACK_DEP_PTR, align 4
  %24125 = load i64, i64* %STACK_DEP_PTR, align 4
  %24126 = getelementptr i256, i256* %STACK, i64 %24125
  %24127 = load i256, i256* %24126, align 4
  %24128 = load i64, i64* %STACK_DEP_PTR, align 4
  %24129 = sub i64 %24128, 1
  store i64 %24129, i64* %STACK_DEP_PTR, align 4
  %24130 = add i256 %24127, %24122, !pc !387, !intsan !10
  %24131 = trunc i256 %24127 to i64
  %24132 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24131, i256* %24132)
  %24133 = load i256, i256* %24132, align 4
  %24134 = add i256 32, %24127, !pc !388, !intsan !10
  %24135 = and i256 1461501637330902918203684832716283019655932542975, %24133
  %24136 = alloca i256, align 8
  store i256 2, i256* %24136, align 4
  %24137 = alloca i256, align 8
  call void @__device_sload(i256* %24136, i256* %24137)
  %24138 = call i32 @__hashword(i256* %24136)
  %24139 = load i32, i32* %5, align 4
  %24140 = icmp eq i32 %24138, %24139
  %24141 = or i1 false, %24140
  %24142 = load i32, i32* %6, align 4
  %24143 = icmp eq i32 %24138, %24142
  %24144 = or i1 %24141, %24143
  %24145 = load i32, i32* %7, align 4
  %24146 = icmp eq i32 %24138, %24145
  %24147 = or i1 %24144, %24146
  %24148 = load i32, i32* %8, align 4
  %24149 = icmp eq i32 %24138, %24148
  %24150 = or i1 %24147, %24149
  %24151 = load i32, i32* %9, align 4
  %24152 = icmp eq i32 %24138, %24151
  %24153 = or i1 %24150, %24152
  %24154 = load i32, i32* %10, align 4
  %24155 = icmp eq i32 %24138, %24154
  %24156 = or i1 %24153, %24155
  %24157 = load i32, i32* %11, align 4
  %24158 = icmp eq i32 %24138, %24157
  %24159 = or i1 %24156, %24158
  %24160 = load i32, i32* %12, align 4
  %24161 = icmp eq i32 %24138, %24160
  %24162 = or i1 %24159, %24161
  %24163 = load i32, i32* %13, align 4
  %24164 = icmp eq i32 %24138, %24163
  %24165 = or i1 %24162, %24164
  %24166 = load i32, i32* %14, align 4
  %24167 = icmp eq i32 %24138, %24166
  %24168 = or i1 %24165, %24167
  %24169 = load i32, i32* %15, align 4
  %24170 = icmp eq i32 %24138, %24169
  %24171 = or i1 %24168, %24170
  %24172 = load i32, i32* %16, align 4
  %24173 = icmp eq i32 %24138, %24172
  %24174 = or i1 %24171, %24173
  %24175 = load i32, i32* %17, align 4
  %24176 = icmp eq i32 %24138, %24175
  %24177 = or i1 %24174, %24176
  %24178 = load i32, i32* %18, align 4
  %24179 = icmp eq i32 %24138, %24178
  %24180 = or i1 %24177, %24179
  %24181 = load i32, i32* %19, align 4
  %24182 = icmp eq i32 %24138, %24181
  %24183 = or i1 %24180, %24182
  %24184 = load i32, i32* %20, align 4
  %24185 = icmp eq i32 %24138, %24184
  %24186 = or i1 %24183, %24185
  %24187 = load i32, i32* %21, align 4
  %24188 = icmp eq i32 %24138, %24187
  %24189 = or i1 %24186, %24188
  %24190 = load i32, i32* %22, align 4
  %24191 = icmp eq i32 %24138, %24190
  %24192 = or i1 %24189, %24191
  %24193 = load i32, i32* %23, align 4
  %24194 = icmp eq i32 %24138, %24193
  %24195 = or i1 %24192, %24194
  %24196 = load i32, i32* %24, align 4
  %24197 = icmp eq i32 %24138, %24196
  %24198 = or i1 %24195, %24197
  %24199 = load i32, i32* %25, align 4
  %24200 = icmp eq i32 %24138, %24199
  %24201 = or i1 %24198, %24200
  %24202 = load i32, i32* %26, align 4
  %24203 = icmp eq i32 %24138, %24202
  %24204 = or i1 %24201, %24203
  %24205 = load i32, i32* %27, align 4
  %24206 = icmp eq i32 %24138, %24205
  %24207 = or i1 %24204, %24206
  %24208 = load i32, i32* %28, align 4
  %24209 = icmp eq i32 %24138, %24208
  %24210 = or i1 %24207, %24209
  %24211 = load i32, i32* %29, align 4
  %24212 = icmp eq i32 %24138, %24211
  %24213 = or i1 %24210, %24212
  %24214 = load i32, i32* %30, align 4
  %24215 = icmp eq i32 %24138, %24214
  %24216 = or i1 %24213, %24215
  %24217 = load i32, i32* %31, align 4
  %24218 = icmp eq i32 %24138, %24217
  %24219 = or i1 %24216, %24218
  %24220 = load i32, i32* %32, align 4
  %24221 = icmp eq i32 %24138, %24220
  %24222 = or i1 %24219, %24221
  %24223 = load i32, i32* %33, align 4
  %24224 = icmp eq i32 %24138, %24223
  %24225 = or i1 %24222, %24224
  %24226 = load i32, i32* %34, align 4
  %24227 = icmp eq i32 %24138, %24226
  %24228 = or i1 %24225, %24227
  %24229 = load i32, i32* %35, align 4
  %24230 = icmp eq i32 %24138, %24229
  %24231 = or i1 %24228, %24230
  %24232 = load i32, i32* %36, align 4
  %24233 = icmp eq i32 %24138, %24232
  %24234 = or i1 %24231, %24233
  %24235 = load i32, i32* %37, align 4
  %24236 = icmp eq i32 %24138, %24235
  %24237 = or i1 %24234, %24236
  %24238 = load i32, i32* %38, align 4
  %24239 = icmp eq i32 %24138, %24238
  %24240 = or i1 %24237, %24239
  %24241 = load i32, i32* %39, align 4
  %24242 = icmp eq i32 %24138, %24241
  %24243 = or i1 %24240, %24242
  %24244 = load i32, i32* %40, align 4
  %24245 = icmp eq i32 %24138, %24244
  %24246 = or i1 %24243, %24245
  %24247 = load i32, i32* %41, align 4
  %24248 = icmp eq i32 %24138, %24247
  %24249 = or i1 %24246, %24248
  %24250 = load i32, i32* %42, align 4
  %24251 = icmp eq i32 %24138, %24250
  %24252 = or i1 %24249, %24251
  %24253 = load i32, i32* %43, align 4
  %24254 = icmp eq i32 %24138, %24253
  %24255 = or i1 %24252, %24254
  %24256 = load i32, i32* %44, align 4
  %24257 = icmp eq i32 %24138, %24256
  %24258 = or i1 %24255, %24257
  %24259 = load i32, i32* %45, align 4
  %24260 = icmp eq i32 %24138, %24259
  %24261 = or i1 %24258, %24260
  %24262 = load i32, i32* %46, align 4
  %24263 = icmp eq i32 %24138, %24262
  %24264 = or i1 %24261, %24263
  %24265 = load i32, i32* %47, align 4
  %24266 = icmp eq i32 %24138, %24265
  %24267 = or i1 %24264, %24266
  %24268 = load i32, i32* %48, align 4
  %24269 = icmp eq i32 %24138, %24268
  %24270 = or i1 %24267, %24269
  %24271 = load i32, i32* %49, align 4
  %24272 = icmp eq i32 %24138, %24271
  %24273 = or i1 %24270, %24272
  %24274 = load i32, i32* %50, align 4
  %24275 = icmp eq i32 %24138, %24274
  %24276 = or i1 %24273, %24275
  %24277 = load i32, i32* %51, align 4
  %24278 = icmp eq i32 %24138, %24277
  %24279 = or i1 %24276, %24278
  %24280 = load i32, i32* %52, align 4
  %24281 = icmp eq i32 %24138, %24280
  %24282 = or i1 %24279, %24281
  %24283 = load i32, i32* %53, align 4
  %24284 = icmp eq i32 %24138, %24283
  %24285 = or i1 %24282, %24284
  %24286 = load i32, i32* %54, align 4
  %24287 = icmp eq i32 %24138, %24286
  %24288 = or i1 %24285, %24287
  %24289 = load i32, i32* %55, align 4
  %24290 = icmp eq i32 %24138, %24289
  %24291 = or i1 %24288, %24290
  %24292 = load i32, i32* %56, align 4
  %24293 = icmp eq i32 %24138, %24292
  %24294 = or i1 %24291, %24293
  %24295 = load i32, i32* %57, align 4
  %24296 = icmp eq i32 %24138, %24295
  %24297 = or i1 %24294, %24296
  %24298 = load i32, i32* %58, align 4
  %24299 = icmp eq i32 %24138, %24298
  %24300 = or i1 %24297, %24299
  %24301 = load i32, i32* %59, align 4
  %24302 = icmp eq i32 %24138, %24301
  %24303 = or i1 %24300, %24302
  %24304 = load i32, i32* %60, align 4
  %24305 = icmp eq i32 %24138, %24304
  %24306 = or i1 %24303, %24305
  %24307 = load i32, i32* %61, align 4
  %24308 = icmp eq i32 %24138, %24307
  %24309 = or i1 %24306, %24308
  %24310 = load i32, i32* %62, align 4
  %24311 = icmp eq i32 %24138, %24310
  %24312 = or i1 %24309, %24311
  %24313 = getelementptr i8, i8 addrspace(1)* %4, i32 84
  %24314 = zext i1 %24312 to i8
  store i8 %24314, i8 addrspace(1)* %24313, align 1, !nosanitize !3
  %24315 = load i256, i256* %24137, align 4
  %24316 = add i256 175000, %24315, !pc !389, !intsan !10
  %24317 = trunc i256 64 to i64
  %24318 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24317, i256* %24318)
  %24319 = load i256, i256* %24318, align 4
  %24320 = and i256 4294967295, 787721420
  %24321 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %24320, !pc !390, !intsan !45
  %24322 = trunc i256 %24319 to i64
  %24323 = alloca i256, align 8
  store i256 %24321, i256* %24323, align 4
  %24324 = bitcast i256* %24323 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %24322, i8* %24324, i64 32)
  %24325 = add i256 4, %24319, !pc !391, !intsan !10
  %24326 = add i256 32, %24325, !pc !392, !intsan !10
  %24327 = trunc i256 %24326 to i64
  %24328 = alloca i256, align 8
  store i256 %24316, i256* %24328, align 4
  %24329 = bitcast i256* %24328 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %24327, i8* %24329, i64 32)
  %24330 = add i256 32, %24326, !pc !393, !intsan !10
  %24331 = sub i256 %24330, %24325, !pc !394, !intsan !8
  %24332 = trunc i256 %24325 to i64
  %24333 = alloca i256, align 8
  store i256 %24331, i256* %24333, align 4
  %24334 = bitcast i256* %24333 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %24332, i8* %24334, i64 32)
  %24335 = trunc i256 %24330 to i64
  %24336 = alloca i256, align 8
  store i256 3, i256* %24336, align 4
  %24337 = bitcast i256* %24336 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %24335, i8* %24337, i64 32)
  %24338 = add i256 32, %24330, !pc !395, !intsan !10
  %24339 = trunc i256 %24338 to i64
  %24340 = alloca i256, align 8
  store i256 38591998121611826609606229052672359276638289559839154232670315000474409893888, i256* %24340, align 4
  %24341 = bitcast i256* %24340 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %24339, i8* %24341, i64 32)
  %24342 = add i256 32, %24338, !pc !396, !intsan !10
  %24343 = trunc i256 64 to i64
  %24344 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24343, i256* %24344)
  %24345 = load i256, i256* %24344, align 4
  %24346 = sub i256 %24342, %24345, !pc !397, !intsan !8
  %24347 = icmp eq i256 1, 0
  %24348 = icmp eq i1 %24347, false
  %24349 = trunc i256 8604 to i64
  %jump.check122 = icmp ne i1 %24348, false
  %24350 = load i64, i64* %STACK_DEP_PTR, align 4
  %24351 = add i64 %24350, 1
  store i64 %24351, i64* %STACK_DEP_PTR, align 4
  %24352 = load i64, i64* %STACK_DEP_PTR, align 4
  %24353 = getelementptr i256, i256* %STACK, i64 %24352
  store i256 %24135, i256* %24353, align 4
  %24354 = load i64, i64* %STACK_DEP_PTR, align 4
  %24355 = add i64 %24354, 1
  store i64 %24355, i64* %STACK_DEP_PTR, align 4
  %24356 = load i64, i64* %STACK_DEP_PTR, align 4
  %24357 = getelementptr i256, i256* %STACK, i64 %24356
  store i256 787721420, i256* %24357, align 4
  %24358 = load i64, i64* %STACK_DEP_PTR, align 4
  %24359 = add i64 %24358, 1
  store i64 %24359, i64* %STACK_DEP_PTR, align 4
  %24360 = load i64, i64* %STACK_DEP_PTR, align 4
  %24361 = getelementptr i256, i256* %STACK, i64 %24360
  store i256 %24342, i256* %24361, align 4
  %24362 = load i64, i64* %STACK_DEP_PTR, align 4
  %24363 = add i64 %24362, 1
  store i64 %24363, i64* %STACK_DEP_PTR, align 4
  %24364 = load i64, i64* %STACK_DEP_PTR, align 4
  %24365 = getelementptr i256, i256* %STACK, i64 %24364
  store i256 32, i256* %24365, align 4
  %24366 = load i64, i64* %STACK_DEP_PTR, align 4
  %24367 = add i64 %24366, 1
  store i64 %24367, i64* %STACK_DEP_PTR, align 4
  %24368 = load i64, i64* %STACK_DEP_PTR, align 4
  %24369 = getelementptr i256, i256* %STACK, i64 %24368
  store i256 %24345, i256* %24369, align 4
  %24370 = load i64, i64* %STACK_DEP_PTR, align 4
  %24371 = add i64 %24370, 1
  store i64 %24371, i64* %STACK_DEP_PTR, align 4
  %24372 = load i64, i64* %STACK_DEP_PTR, align 4
  %24373 = getelementptr i256, i256* %STACK, i64 %24372
  store i256 %24346, i256* %24373, align 4
  %24374 = load i64, i64* %STACK_DEP_PTR, align 4
  %24375 = add i64 %24374, 1
  store i64 %24375, i64* %STACK_DEP_PTR, align 4
  %24376 = load i64, i64* %STACK_DEP_PTR, align 4
  %24377 = getelementptr i256, i256* %STACK, i64 %24376
  store i256 %24345, i256* %24377, align 4
  %24378 = load i64, i64* %STACK_DEP_PTR, align 4
  %24379 = add i64 %24378, 1
  store i64 %24379, i64* %STACK_DEP_PTR, align 4
  %24380 = load i64, i64* %STACK_DEP_PTR, align 4
  %24381 = getelementptr i256, i256* %STACK, i64 %24380
  store i256 0, i256* %24381, align 4
  %24382 = load i64, i64* %STACK_DEP_PTR, align 4
  %24383 = add i64 %24382, 1
  store i64 %24383, i64* %STACK_DEP_PTR, align 4
  %24384 = load i64, i64* %STACK_DEP_PTR, align 4
  %24385 = getelementptr i256, i256* %STACK, i64 %24384
  store i256 %24135, i256* %24385, align 4
  %24386 = load i64, i64* %STACK_DEP_PTR, align 4
  %24387 = add i64 %24386, 1
  store i64 %24387, i64* %STACK_DEP_PTR, align 4
  %24388 = zext i1 %24347 to i256
  %24389 = load i64, i64* %STACK_DEP_PTR, align 4
  %24390 = getelementptr i256, i256* %STACK, i64 %24389
  store i256 %24388, i256* %24390, align 4
  br i1 %jump.check122, label %.8604, label %.8600, !EVMBB !4

.8600:                                            ; preds = %24113
  %24391 = load i64, i64* %remaing_gas, align 4
  %24392 = icmp ugt i64 40, %24391
  br i1 %24392, label %Abort, label %24393

24393:                                            ; preds = %.8600
  %24394 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24395 = xor i32 %24394, 1522
  %24396 = urem i32 %24395, 4096
  %24397 = getelementptr i8, i8 addrspace(1)* %4, i32 %24396
  %24398 = load i8, i8 addrspace(1)* %24397, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24397, align 1, !nosanitize !3
  store i32 761, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24399 = sub i64 %24391, 40
  store i64 %24399, i64* %remaing_gas, align 4
  %24400 = load i64, i64* %STACK_DEP_PTR, align 4
  %24401 = sub i64 %24400, 0
  store i64 %24401, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8604:                                            ; preds = %24113, %JumpTable
  %24402 = load i64, i64* %remaing_gas, align 4
  %24403 = icmp ugt i64 456, %24402
  br i1 %24403, label %Abort, label %24404

24404:                                            ; preds = %.8604
  %24405 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24406 = xor i32 %24405, 272
  %24407 = urem i32 %24406, 4096
  %24408 = getelementptr i8, i8 addrspace(1)* %4, i32 %24407
  %24409 = load i8, i8 addrspace(1)* %24408, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24408, align 1, !nosanitize !3
  store i32 136, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24410 = sub i64 %24402, 456
  store i64 %24410, i64* %remaing_gas, align 4
  %24411 = load i64, i64* %STACK_DEP_PTR, align 4
  %24412 = getelementptr i256, i256* %STACK, i64 %24411
  %24413 = load i256, i256* %24412, align 4
  %24414 = load i64, i64* %STACK_DEP_PTR, align 4
  %24415 = sub i64 %24414, 1
  store i64 %24415, i64* %STACK_DEP_PTR, align 4
  %24416 = load i64, i64* %STACK_DEP_PTR, align 4
  %24417 = getelementptr i256, i256* %STACK, i64 %24416
  %24418 = load i256, i256* %24417, align 4
  %24419 = load i64, i64* %STACK_DEP_PTR, align 4
  %24420 = sub i64 %24419, 1
  store i64 %24420, i64* %STACK_DEP_PTR, align 4
  %24421 = load i64, i64* %STACK_DEP_PTR, align 4
  %24422 = getelementptr i256, i256* %STACK, i64 %24421
  %24423 = load i256, i256* %24422, align 4
  %24424 = load i64, i64* %STACK_DEP_PTR, align 4
  %24425 = sub i64 %24424, 1
  store i64 %24425, i64* %STACK_DEP_PTR, align 4
  %24426 = load i64, i64* %STACK_DEP_PTR, align 4
  %24427 = getelementptr i256, i256* %STACK, i64 %24426
  %24428 = load i256, i256* %24427, align 4
  %24429 = load i64, i64* %STACK_DEP_PTR, align 4
  %24430 = sub i64 %24429, 1
  store i64 %24430, i64* %STACK_DEP_PTR, align 4
  %24431 = load i64, i64* %STACK_DEP_PTR, align 4
  %24432 = getelementptr i256, i256* %STACK, i64 %24431
  %24433 = load i256, i256* %24432, align 4
  %24434 = load i64, i64* %STACK_DEP_PTR, align 4
  %24435 = sub i64 %24434, 1
  store i64 %24435, i64* %STACK_DEP_PTR, align 4
  %24436 = load i64, i64* %STACK_DEP_PTR, align 4
  %24437 = getelementptr i256, i256* %STACK, i64 %24436
  %24438 = load i256, i256* %24437, align 4
  %24439 = load i64, i64* %STACK_DEP_PTR, align 4
  %24440 = sub i64 %24439, 1
  store i64 %24440, i64* %STACK_DEP_PTR, align 4
  %24441 = load i64, i64* %STACK_DEP_PTR, align 4
  %24442 = getelementptr i256, i256* %STACK, i64 %24441
  %24443 = load i256, i256* %24442, align 4
  %24444 = load i64, i64* %STACK_DEP_PTR, align 4
  %24445 = sub i64 %24444, 1
  store i64 %24445, i64* %STACK_DEP_PTR, align 4
  %24446 = trunc i256 %24418 to i160
  %24447 = call i1 @solidity_call(), !pc !398
  %24448 = icmp eq i1 %24447, false
  %24449 = icmp eq i1 %24448, false
  %24450 = trunc i256 8624 to i64
  %jump.check127 = icmp ne i1 %24449, false
  %24451 = load i64, i64* %STACK_DEP_PTR, align 4
  %24452 = add i64 %24451, 1
  store i64 %24452, i64* %STACK_DEP_PTR, align 4
  %24453 = zext i1 %24448 to i256
  %24454 = load i64, i64* %STACK_DEP_PTR, align 4
  %24455 = getelementptr i256, i256* %STACK, i64 %24454
  store i256 %24453, i256* %24455, align 4
  br i1 %jump.check127, label %.8624, label %.8615, !EVMBB !4

.8615:                                            ; preds = %24404
  %24456 = load i64, i64* %remaing_gas, align 4
  %24457 = icmp ugt i64 40, %24456
  br i1 %24457, label %Abort, label %24458

24458:                                            ; preds = %.8615
  %24459 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24460 = xor i32 %24459, 1960
  %24461 = urem i32 %24460, 4096
  %24462 = getelementptr i8, i8 addrspace(1)* %4, i32 %24461
  %24463 = load i8, i8 addrspace(1)* %24462, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24462, align 1, !nosanitize !3
  store i32 980, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24464 = sub i64 %24456, 40
  store i64 %24464, i64* %remaing_gas, align 4
  %24465 = load i64, i64* %STACK_DEP_PTR, align 4
  %24466 = sub i64 %24465, 0
  store i64 %24466, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8624:                                            ; preds = %24404, %JumpTable
  %24467 = load i64, i64* %remaing_gas, align 4
  %24468 = icmp ugt i64 384, %24467
  br i1 %24468, label %Abort, label %24469

24469:                                            ; preds = %.8624
  %24470 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24471 = xor i32 %24470, 2294
  %24472 = urem i32 %24471, 4096
  %24473 = getelementptr i8, i8 addrspace(1)* %4, i32 %24472
  %24474 = load i8, i8 addrspace(1)* %24473, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24473, align 1, !nosanitize !3
  store i32 1147, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24475 = sub i64 %24467, 384
  store i64 %24475, i64* %remaing_gas, align 4
  %24476 = load i64, i64* %STACK_DEP_PTR, align 4
  %24477 = getelementptr i256, i256* %STACK, i64 %24476
  %24478 = load i256, i256* %24477, align 4
  %24479 = load i64, i64* %STACK_DEP_PTR, align 4
  %24480 = sub i64 %24479, 1
  store i64 %24480, i64* %STACK_DEP_PTR, align 4
  %24481 = load i64, i64* %STACK_DEP_PTR, align 4
  %24482 = getelementptr i256, i256* %STACK, i64 %24481
  %24483 = load i256, i256* %24482, align 4
  %24484 = load i64, i64* %STACK_DEP_PTR, align 4
  %24485 = sub i64 %24484, 1
  store i64 %24485, i64* %STACK_DEP_PTR, align 4
  %24486 = load i64, i64* %STACK_DEP_PTR, align 4
  %24487 = getelementptr i256, i256* %STACK, i64 %24486
  %24488 = load i256, i256* %24487, align 4
  %24489 = load i64, i64* %STACK_DEP_PTR, align 4
  %24490 = sub i64 %24489, 1
  store i64 %24490, i64* %STACK_DEP_PTR, align 4
  %24491 = load i64, i64* %STACK_DEP_PTR, align 4
  %24492 = getelementptr i256, i256* %STACK, i64 %24491
  %24493 = load i256, i256* %24492, align 4
  %24494 = load i64, i64* %STACK_DEP_PTR, align 4
  %24495 = sub i64 %24494, 1
  store i64 %24495, i64* %STACK_DEP_PTR, align 4
  %24496 = trunc i256 64 to i64
  %24497 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24496, i256* %24497)
  %24498 = load i256, i256* %24497, align 4
  %24499 = zext i64 0 to i256
  %24500 = icmp ult i256 %24499, 32
  %24501 = icmp eq i1 %24500, false
  %24502 = trunc i256 8646 to i64
  %jump.check132 = icmp ne i1 %24501, false
  %24503 = load i64, i64* %STACK_DEP_PTR, align 4
  %24504 = add i64 %24503, 1
  store i64 %24504, i64* %STACK_DEP_PTR, align 4
  %24505 = load i64, i64* %STACK_DEP_PTR, align 4
  %24506 = getelementptr i256, i256* %STACK, i64 %24505
  store i256 %24498, i256* %24506, align 4
  %24507 = load i64, i64* %STACK_DEP_PTR, align 4
  %24508 = add i64 %24507, 1
  store i64 %24508, i64* %STACK_DEP_PTR, align 4
  %24509 = zext i64 0 to i256
  %24510 = load i64, i64* %STACK_DEP_PTR, align 4
  %24511 = getelementptr i256, i256* %STACK, i64 %24510
  store i256 %24509, i256* %24511, align 4
  br i1 %jump.check132, label %.8646, label %.8642, !EVMBB !4

.8642:                                            ; preds = %24469
  %24512 = load i64, i64* %remaing_gas, align 4
  %24513 = icmp ugt i64 40, %24512
  br i1 %24513, label %Abort, label %24514

24514:                                            ; preds = %.8642
  %24515 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24516 = xor i32 %24515, 261
  %24517 = urem i32 %24516, 4096
  %24518 = getelementptr i8, i8 addrspace(1)* %4, i32 %24517
  %24519 = load i8, i8 addrspace(1)* %24518, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24518, align 1, !nosanitize !3
  store i32 130, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24520 = sub i64 %24512, 40
  store i64 %24520, i64* %remaing_gas, align 4
  %24521 = load i64, i64* %STACK_DEP_PTR, align 4
  %24522 = sub i64 %24521, 0
  store i64 %24522, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.8646:                                            ; preds = %24469, %JumpTable
  %24523 = load i64, i64* %remaing_gas, align 4
  %24524 = icmp ugt i64 528, %24523
  br i1 %24524, label %Abort, label %24525

24525:                                            ; preds = %.8646
  %24526 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24527 = xor i32 %24526, 916
  %24528 = urem i32 %24527, 4096
  %24529 = getelementptr i8, i8 addrspace(1)* %4, i32 %24528
  %24530 = load i8, i8 addrspace(1)* %24529, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24529, align 1, !nosanitize !3
  store i32 458, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24531 = sub i64 %24523, 528
  store i64 %24531, i64* %remaing_gas, align 4
  %24532 = load i64, i64* %STACK_DEP_PTR, align 4
  %24533 = getelementptr i256, i256* %STACK, i64 %24532
  %24534 = load i256, i256* %24533, align 4
  %24535 = load i64, i64* %STACK_DEP_PTR, align 4
  %24536 = sub i64 %24535, 1
  store i64 %24536, i64* %STACK_DEP_PTR, align 4
  %24537 = load i64, i64* %STACK_DEP_PTR, align 4
  %24538 = getelementptr i256, i256* %STACK, i64 %24537
  %24539 = load i256, i256* %24538, align 4
  %24540 = load i64, i64* %STACK_DEP_PTR, align 4
  %24541 = sub i64 %24540, 1
  store i64 %24541, i64* %STACK_DEP_PTR, align 4
  %24542 = load i64, i64* %STACK_DEP_PTR, align 4
  %24543 = getelementptr i256, i256* %STACK, i64 %24542
  %24544 = load i256, i256* %24543, align 4
  %24545 = load i64, i64* %STACK_DEP_PTR, align 4
  %24546 = sub i64 %24545, 1
  store i64 %24546, i64* %STACK_DEP_PTR, align 4
  %24547 = load i64, i64* %STACK_DEP_PTR, align 4
  %24548 = getelementptr i256, i256* %STACK, i64 %24547
  %24549 = load i256, i256* %24548, align 4
  %24550 = load i64, i64* %STACK_DEP_PTR, align 4
  %24551 = sub i64 %24550, 1
  store i64 %24551, i64* %STACK_DEP_PTR, align 4
  %24552 = add i256 %24539, %24534, !pc !399, !intsan !10
  %24553 = trunc i256 %24539 to i64
  %24554 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %24553, i256* %24554)
  %24555 = load i256, i256* %24554, align 4
  %24556 = add i256 32, %24539, !pc !400, !intsan !10
  %24557 = sub i256 10000, 190, !pc !401, !intsan !8
  %24558 = sub i256 %24557, 7500, !pc !402, !intsan !8
  %24559 = mul i256 10000, %24558, !pc !403, !intsan !45
  %24560 = trunc i256 4367 to i64
  %24561 = load i64, i64* %STACK_DEP_PTR, align 4
  %24562 = add i64 %24561, 1
  store i64 %24562, i64* %STACK_DEP_PTR, align 4
  %24563 = load i64, i64* %STACK_DEP_PTR, align 4
  %24564 = getelementptr i256, i256* %STACK, i64 %24563
  store i256 %24555, i256* %24564, align 4
  %24565 = load i64, i64* %STACK_DEP_PTR, align 4
  %24566 = add i64 %24565, 1
  store i64 %24566, i64* %STACK_DEP_PTR, align 4
  %24567 = load i64, i64* %STACK_DEP_PTR, align 4
  %24568 = getelementptr i256, i256* %STACK, i64 %24567
  store i256 %24544, i256* %24568, align 4
  %24569 = load i64, i64* %STACK_DEP_PTR, align 4
  %24570 = add i64 %24569, 1
  store i64 %24570, i64* %STACK_DEP_PTR, align 4
  %24571 = load i64, i64* %STACK_DEP_PTR, align 4
  %24572 = getelementptr i256, i256* %STACK, i64 %24571
  store i256 %24559, i256* %24572, align 4
  %24573 = load i64, i64* %STACK_DEP_PTR, align 4
  %24574 = add i64 %24573, 1
  store i64 %24574, i64* %STACK_DEP_PTR, align 4
  %24575 = load i64, i64* %STACK_DEP_PTR, align 4
  %24576 = getelementptr i256, i256* %STACK, i64 %24575
  store i256 7500, i256* %24576, align 4
  %24577 = load i64, i64* %STACK_DEP_PTR, align 4
  %24578 = add i64 %24577, 1
  store i64 %24578, i64* %STACK_DEP_PTR, align 4
  %24579 = load i64, i64* %STACK_DEP_PTR, align 4
  %24580 = getelementptr i256, i256* %STACK, i64 %24579
  store i256 8690, i256* %24580, align 4
  br label %.4367, !EVMBB !4

.8690:                                            ; preds = %JumpTable
  %24581 = load i64, i64* %remaing_gas, align 4
  %24582 = icmp ugt i64 304, %24581
  br i1 %24582, label %Abort, label %24583

24583:                                            ; preds = %.8690
  %24584 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24585 = xor i32 %24584, 1025
  %24586 = urem i32 %24585, 4096
  %24587 = getelementptr i8, i8 addrspace(1)* %4, i32 %24586
  %24588 = load i8, i8 addrspace(1)* %24587, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24587, align 1, !nosanitize !3
  store i32 512, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24589 = sub i64 %24581, 304
  store i64 %24589, i64* %remaing_gas, align 4
  %24590 = load i64, i64* %STACK_DEP_PTR, align 4
  %24591 = getelementptr i256, i256* %STACK, i64 %24590
  %24592 = load i256, i256* %24591, align 4
  %24593 = load i64, i64* %STACK_DEP_PTR, align 4
  %24594 = sub i64 %24593, 1
  store i64 %24594, i64* %STACK_DEP_PTR, align 4
  %24595 = load i64, i64* %STACK_DEP_PTR, align 4
  %24596 = getelementptr i256, i256* %STACK, i64 %24595
  %24597 = load i256, i256* %24596, align 4
  %24598 = load i64, i64* %STACK_DEP_PTR, align 4
  %24599 = sub i64 %24598, 1
  store i64 %24599, i64* %STACK_DEP_PTR, align 4
  %24600 = load i64, i64* %STACK_DEP_PTR, align 4
  %24601 = getelementptr i256, i256* %STACK, i64 %24600
  %24602 = load i256, i256* %24601, align 4
  %24603 = load i64, i64* %STACK_DEP_PTR, align 4
  %24604 = sub i64 %24603, 1
  store i64 %24604, i64* %STACK_DEP_PTR, align 4
  %24605 = mul i256 100, %24592, !pc !404, !intsan !45
  %24606 = mul i256 %24605, %24597, !pc !405, !intsan !45
  %24607 = icmp eq i256 %24602, 0
  %24608 = icmp eq i1 %24607, false
  %24609 = trunc i256 8703 to i64
  %jump.check196 = icmp ne i1 %24608, false
  %24610 = load i64, i64* %STACK_DEP_PTR, align 4
  %24611 = add i64 %24610, 1
  store i64 %24611, i64* %STACK_DEP_PTR, align 4
  %24612 = load i64, i64* %STACK_DEP_PTR, align 4
  %24613 = getelementptr i256, i256* %STACK, i64 %24612
  store i256 %24602, i256* %24613, align 4
  %24614 = load i64, i64* %STACK_DEP_PTR, align 4
  %24615 = add i64 %24614, 1
  store i64 %24615, i64* %STACK_DEP_PTR, align 4
  %24616 = load i64, i64* %STACK_DEP_PTR, align 4
  %24617 = getelementptr i256, i256* %STACK, i64 %24616
  store i256 %24606, i256* %24617, align 4
  br i1 %jump.check196, label %.8703, label %.8702, !EVMBB !4

.8702:                                            ; preds = %24583
  %24618 = load i64, i64* %remaing_gas, align 4
  %24619 = icmp ugt i64 16, %24618
  br i1 %24619, label %Abort, label %24620

24620:                                            ; preds = %.8702
  %24621 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24622 = xor i32 %24621, 2494
  %24623 = urem i32 %24622, 4096
  %24624 = getelementptr i8, i8 addrspace(1)* %4, i32 %24623
  %24625 = load i8, i8 addrspace(1)* %24624, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24624, align 1, !nosanitize !3
  store i32 1247, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24626 = sub i64 %24618, 16
  store i64 %24626, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.8703:                                            ; preds = %24583, %JumpTable
  %24627 = load i64, i64* %remaing_gas, align 4
  %24628 = icmp ugt i64 432, %24627
  br i1 %24628, label %Abort, label %24629

24629:                                            ; preds = %.8703
  %24630 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24631 = xor i32 %24630, 436
  %24632 = urem i32 %24631, 4096
  %24633 = getelementptr i8, i8 addrspace(1)* %4, i32 %24632
  %24634 = load i8, i8 addrspace(1)* %24633, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24633, align 1, !nosanitize !3
  store i32 218, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24635 = sub i64 %24627, 432
  store i64 %24635, i64* %remaing_gas, align 4
  %24636 = load i64, i64* %STACK_DEP_PTR, align 4
  %24637 = getelementptr i256, i256* %STACK, i64 %24636
  %24638 = load i256, i256* %24637, align 4
  %24639 = load i64, i64* %STACK_DEP_PTR, align 4
  %24640 = sub i64 %24639, 1
  store i64 %24640, i64* %STACK_DEP_PTR, align 4
  %24641 = load i64, i64* %STACK_DEP_PTR, align 4
  %24642 = getelementptr i256, i256* %STACK, i64 %24641
  %24643 = load i256, i256* %24642, align 4
  %24644 = load i64, i64* %STACK_DEP_PTR, align 4
  %24645 = sub i64 %24644, 1
  store i64 %24645, i64* %STACK_DEP_PTR, align 4
  %24646 = load i64, i64* %STACK_DEP_PTR, align 4
  %24647 = getelementptr i256, i256* %STACK, i64 %24646
  %24648 = load i256, i256* %24647, align 4
  %24649 = load i64, i64* %STACK_DEP_PTR, align 4
  %24650 = sub i64 %24649, 1
  store i64 %24650, i64* %STACK_DEP_PTR, align 4
  %24651 = load i64, i64* %STACK_DEP_PTR, align 4
  %24652 = getelementptr i256, i256* %STACK, i64 %24651
  %24653 = load i256, i256* %24652, align 4
  %24654 = load i64, i64* %STACK_DEP_PTR, align 4
  %24655 = sub i64 %24654, 1
  store i64 %24655, i64* %STACK_DEP_PTR, align 4
  %24656 = load i64, i64* %STACK_DEP_PTR, align 4
  %24657 = getelementptr i256, i256* %STACK, i64 %24656
  %24658 = load i256, i256* %24657, align 4
  %24659 = load i64, i64* %STACK_DEP_PTR, align 4
  %24660 = sub i64 %24659, 1
  store i64 %24660, i64* %STACK_DEP_PTR, align 4
  %24661 = load i64, i64* %STACK_DEP_PTR, align 4
  %24662 = getelementptr i256, i256* %STACK, i64 %24661
  %24663 = load i256, i256* %24662, align 4
  %24664 = load i64, i64* %STACK_DEP_PTR, align 4
  %24665 = sub i64 %24664, 1
  store i64 %24665, i64* %STACK_DEP_PTR, align 4
  %24666 = alloca i256, align 8
  store i256 %24638, i256* %24666, align 4
  %24667 = alloca i256, align 8
  store i256 %24643, i256* %24667, align 4
  %24668 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %24666, i256* %24667, i256* %24668), !pc !406, !intsan !6
  %24669 = load i256, i256* %24668, align 4
  %24670 = add i256 %24669, %24653, !pc !407, !intsan !10
  %24671 = trunc i256 %24663 to i64
  store i64 %24671, i64* %JMP_TARGET_PTR, align 4
  %24672 = load i64, i64* %STACK_DEP_PTR, align 4
  %24673 = add i64 %24672, 1
  store i64 %24673, i64* %STACK_DEP_PTR, align 4
  %24674 = load i64, i64* %STACK_DEP_PTR, align 4
  %24675 = getelementptr i256, i256* %STACK, i64 %24674
  store i256 %24670, i256* %24675, align 4
  br label %JumpTable, !EVMBB !4

.8716:                                            ; preds = %2570, %JumpTable
  %24676 = load i64, i64* %remaing_gas, align 4
  %24677 = icmp ugt i64 216, %24676
  br i1 %24677, label %Abort, label %24678

24678:                                            ; preds = %.8716
  %24679 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24680 = xor i32 %24679, 3260
  %24681 = urem i32 %24680, 4096
  %24682 = getelementptr i8, i8 addrspace(1)* %4, i32 %24681
  %24683 = load i8, i8 addrspace(1)* %24682, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24682, align 1, !nosanitize !3
  store i32 1630, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24684 = sub i64 %24676, 216
  store i64 %24684, i64* %remaing_gas, align 4
  %24685 = load i64, i64* %STACK_DEP_PTR, align 4
  %24686 = getelementptr i256, i256* %STACK, i64 %24685
  %24687 = load i256, i256* %24686, align 4
  %24688 = load i64, i64* %STACK_DEP_PTR, align 4
  %24689 = sub i64 %24688, 1
  store i64 %24689, i64* %STACK_DEP_PTR, align 4
  %24690 = alloca i256, align 8
  store i256 14, i256* %24690, align 4
  %24691 = alloca i256, align 8
  call void @__device_sload(i256* %24690, i256* %24691)
  %24692 = call i32 @__hashword(i256* %24690)
  %24693 = load i32, i32* %5, align 4
  %24694 = icmp eq i32 %24692, %24693
  %24695 = or i1 false, %24694
  %24696 = load i32, i32* %6, align 4
  %24697 = icmp eq i32 %24692, %24696
  %24698 = or i1 %24695, %24697
  %24699 = load i32, i32* %7, align 4
  %24700 = icmp eq i32 %24692, %24699
  %24701 = or i1 %24698, %24700
  %24702 = load i32, i32* %8, align 4
  %24703 = icmp eq i32 %24692, %24702
  %24704 = or i1 %24701, %24703
  %24705 = load i32, i32* %9, align 4
  %24706 = icmp eq i32 %24692, %24705
  %24707 = or i1 %24704, %24706
  %24708 = load i32, i32* %10, align 4
  %24709 = icmp eq i32 %24692, %24708
  %24710 = or i1 %24707, %24709
  %24711 = load i32, i32* %11, align 4
  %24712 = icmp eq i32 %24692, %24711
  %24713 = or i1 %24710, %24712
  %24714 = load i32, i32* %12, align 4
  %24715 = icmp eq i32 %24692, %24714
  %24716 = or i1 %24713, %24715
  %24717 = load i32, i32* %13, align 4
  %24718 = icmp eq i32 %24692, %24717
  %24719 = or i1 %24716, %24718
  %24720 = load i32, i32* %14, align 4
  %24721 = icmp eq i32 %24692, %24720
  %24722 = or i1 %24719, %24721
  %24723 = load i32, i32* %15, align 4
  %24724 = icmp eq i32 %24692, %24723
  %24725 = or i1 %24722, %24724
  %24726 = load i32, i32* %16, align 4
  %24727 = icmp eq i32 %24692, %24726
  %24728 = or i1 %24725, %24727
  %24729 = load i32, i32* %17, align 4
  %24730 = icmp eq i32 %24692, %24729
  %24731 = or i1 %24728, %24730
  %24732 = load i32, i32* %18, align 4
  %24733 = icmp eq i32 %24692, %24732
  %24734 = or i1 %24731, %24733
  %24735 = load i32, i32* %19, align 4
  %24736 = icmp eq i32 %24692, %24735
  %24737 = or i1 %24734, %24736
  %24738 = load i32, i32* %20, align 4
  %24739 = icmp eq i32 %24692, %24738
  %24740 = or i1 %24737, %24739
  %24741 = load i32, i32* %21, align 4
  %24742 = icmp eq i32 %24692, %24741
  %24743 = or i1 %24740, %24742
  %24744 = load i32, i32* %22, align 4
  %24745 = icmp eq i32 %24692, %24744
  %24746 = or i1 %24743, %24745
  %24747 = load i32, i32* %23, align 4
  %24748 = icmp eq i32 %24692, %24747
  %24749 = or i1 %24746, %24748
  %24750 = load i32, i32* %24, align 4
  %24751 = icmp eq i32 %24692, %24750
  %24752 = or i1 %24749, %24751
  %24753 = load i32, i32* %25, align 4
  %24754 = icmp eq i32 %24692, %24753
  %24755 = or i1 %24752, %24754
  %24756 = load i32, i32* %26, align 4
  %24757 = icmp eq i32 %24692, %24756
  %24758 = or i1 %24755, %24757
  %24759 = load i32, i32* %27, align 4
  %24760 = icmp eq i32 %24692, %24759
  %24761 = or i1 %24758, %24760
  %24762 = load i32, i32* %28, align 4
  %24763 = icmp eq i32 %24692, %24762
  %24764 = or i1 %24761, %24763
  %24765 = load i32, i32* %29, align 4
  %24766 = icmp eq i32 %24692, %24765
  %24767 = or i1 %24764, %24766
  %24768 = load i32, i32* %30, align 4
  %24769 = icmp eq i32 %24692, %24768
  %24770 = or i1 %24767, %24769
  %24771 = load i32, i32* %31, align 4
  %24772 = icmp eq i32 %24692, %24771
  %24773 = or i1 %24770, %24772
  %24774 = load i32, i32* %32, align 4
  %24775 = icmp eq i32 %24692, %24774
  %24776 = or i1 %24773, %24775
  %24777 = load i32, i32* %33, align 4
  %24778 = icmp eq i32 %24692, %24777
  %24779 = or i1 %24776, %24778
  %24780 = load i32, i32* %34, align 4
  %24781 = icmp eq i32 %24692, %24780
  %24782 = or i1 %24779, %24781
  %24783 = load i32, i32* %35, align 4
  %24784 = icmp eq i32 %24692, %24783
  %24785 = or i1 %24782, %24784
  %24786 = load i32, i32* %36, align 4
  %24787 = icmp eq i32 %24692, %24786
  %24788 = or i1 %24785, %24787
  %24789 = load i32, i32* %37, align 4
  %24790 = icmp eq i32 %24692, %24789
  %24791 = or i1 %24788, %24790
  %24792 = load i32, i32* %38, align 4
  %24793 = icmp eq i32 %24692, %24792
  %24794 = or i1 %24791, %24793
  %24795 = load i32, i32* %39, align 4
  %24796 = icmp eq i32 %24692, %24795
  %24797 = or i1 %24794, %24796
  %24798 = load i32, i32* %40, align 4
  %24799 = icmp eq i32 %24692, %24798
  %24800 = or i1 %24797, %24799
  %24801 = load i32, i32* %41, align 4
  %24802 = icmp eq i32 %24692, %24801
  %24803 = or i1 %24800, %24802
  %24804 = load i32, i32* %42, align 4
  %24805 = icmp eq i32 %24692, %24804
  %24806 = or i1 %24803, %24805
  %24807 = load i32, i32* %43, align 4
  %24808 = icmp eq i32 %24692, %24807
  %24809 = or i1 %24806, %24808
  %24810 = load i32, i32* %44, align 4
  %24811 = icmp eq i32 %24692, %24810
  %24812 = or i1 %24809, %24811
  %24813 = load i32, i32* %45, align 4
  %24814 = icmp eq i32 %24692, %24813
  %24815 = or i1 %24812, %24814
  %24816 = load i32, i32* %46, align 4
  %24817 = icmp eq i32 %24692, %24816
  %24818 = or i1 %24815, %24817
  %24819 = load i32, i32* %47, align 4
  %24820 = icmp eq i32 %24692, %24819
  %24821 = or i1 %24818, %24820
  %24822 = load i32, i32* %48, align 4
  %24823 = icmp eq i32 %24692, %24822
  %24824 = or i1 %24821, %24823
  %24825 = load i32, i32* %49, align 4
  %24826 = icmp eq i32 %24692, %24825
  %24827 = or i1 %24824, %24826
  %24828 = load i32, i32* %50, align 4
  %24829 = icmp eq i32 %24692, %24828
  %24830 = or i1 %24827, %24829
  %24831 = load i32, i32* %51, align 4
  %24832 = icmp eq i32 %24692, %24831
  %24833 = or i1 %24830, %24832
  %24834 = load i32, i32* %52, align 4
  %24835 = icmp eq i32 %24692, %24834
  %24836 = or i1 %24833, %24835
  %24837 = load i32, i32* %53, align 4
  %24838 = icmp eq i32 %24692, %24837
  %24839 = or i1 %24836, %24838
  %24840 = load i32, i32* %54, align 4
  %24841 = icmp eq i32 %24692, %24840
  %24842 = or i1 %24839, %24841
  %24843 = load i32, i32* %55, align 4
  %24844 = icmp eq i32 %24692, %24843
  %24845 = or i1 %24842, %24844
  %24846 = load i32, i32* %56, align 4
  %24847 = icmp eq i32 %24692, %24846
  %24848 = or i1 %24845, %24847
  %24849 = load i32, i32* %57, align 4
  %24850 = icmp eq i32 %24692, %24849
  %24851 = or i1 %24848, %24850
  %24852 = load i32, i32* %58, align 4
  %24853 = icmp eq i32 %24692, %24852
  %24854 = or i1 %24851, %24853
  %24855 = load i32, i32* %59, align 4
  %24856 = icmp eq i32 %24692, %24855
  %24857 = or i1 %24854, %24856
  %24858 = load i32, i32* %60, align 4
  %24859 = icmp eq i32 %24692, %24858
  %24860 = or i1 %24857, %24859
  %24861 = load i32, i32* %61, align 4
  %24862 = icmp eq i32 %24692, %24861
  %24863 = or i1 %24860, %24862
  %24864 = load i32, i32* %62, align 4
  %24865 = icmp eq i32 %24692, %24864
  %24866 = or i1 %24863, %24865
  %24867 = getelementptr i8, i8 addrspace(1)* %4, i32 85
  %24868 = zext i1 %24866 to i8
  store i8 %24868, i8 addrspace(1)* %24867, align 1, !nosanitize !3
  %24869 = load i256, i256* %24691, align 4
  %24870 = trunc i256 %24687 to i64
  store i64 %24870, i64* %JMP_TARGET_PTR, align 4
  %24871 = load i64, i64* %STACK_DEP_PTR, align 4
  %24872 = add i64 %24871, 1
  store i64 %24872, i64* %STACK_DEP_PTR, align 4
  %24873 = load i64, i64* %STACK_DEP_PTR, align 4
  %24874 = getelementptr i256, i256* %STACK, i64 %24873
  store i256 %24687, i256* %24874, align 4
  %24875 = load i64, i64* %STACK_DEP_PTR, align 4
  %24876 = add i64 %24875, 1
  store i64 %24876, i64* %STACK_DEP_PTR, align 4
  %24877 = load i64, i64* %STACK_DEP_PTR, align 4
  %24878 = getelementptr i256, i256* %STACK, i64 %24877
  store i256 %24869, i256* %24878, align 4
  br label %JumpTable, !EVMBB !4

.8722:                                            ; preds = %2641, %JumpTable
  %24879 = load i64, i64* %remaing_gas, align 4
  %24880 = icmp ugt i64 216, %24879
  br i1 %24880, label %Abort, label %24881

24881:                                            ; preds = %.8722
  %24882 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24883 = xor i32 %24882, 1348
  %24884 = urem i32 %24883, 4096
  %24885 = getelementptr i8, i8 addrspace(1)* %4, i32 %24884
  %24886 = load i8, i8 addrspace(1)* %24885, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %24885, align 1, !nosanitize !3
  store i32 674, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %24887 = sub i64 %24879, 216
  store i64 %24887, i64* %remaing_gas, align 4
  %24888 = load i64, i64* %STACK_DEP_PTR, align 4
  %24889 = getelementptr i256, i256* %STACK, i64 %24888
  %24890 = load i256, i256* %24889, align 4
  %24891 = load i64, i64* %STACK_DEP_PTR, align 4
  %24892 = sub i64 %24891, 1
  store i64 %24892, i64* %STACK_DEP_PTR, align 4
  %24893 = alloca i256, align 8
  store i256 13, i256* %24893, align 4
  %24894 = alloca i256, align 8
  call void @__device_sload(i256* %24893, i256* %24894)
  %24895 = call i32 @__hashword(i256* %24893)
  %24896 = load i32, i32* %5, align 4
  %24897 = icmp eq i32 %24895, %24896
  %24898 = or i1 false, %24897
  %24899 = load i32, i32* %6, align 4
  %24900 = icmp eq i32 %24895, %24899
  %24901 = or i1 %24898, %24900
  %24902 = load i32, i32* %7, align 4
  %24903 = icmp eq i32 %24895, %24902
  %24904 = or i1 %24901, %24903
  %24905 = load i32, i32* %8, align 4
  %24906 = icmp eq i32 %24895, %24905
  %24907 = or i1 %24904, %24906
  %24908 = load i32, i32* %9, align 4
  %24909 = icmp eq i32 %24895, %24908
  %24910 = or i1 %24907, %24909
  %24911 = load i32, i32* %10, align 4
  %24912 = icmp eq i32 %24895, %24911
  %24913 = or i1 %24910, %24912
  %24914 = load i32, i32* %11, align 4
  %24915 = icmp eq i32 %24895, %24914
  %24916 = or i1 %24913, %24915
  %24917 = load i32, i32* %12, align 4
  %24918 = icmp eq i32 %24895, %24917
  %24919 = or i1 %24916, %24918
  %24920 = load i32, i32* %13, align 4
  %24921 = icmp eq i32 %24895, %24920
  %24922 = or i1 %24919, %24921
  %24923 = load i32, i32* %14, align 4
  %24924 = icmp eq i32 %24895, %24923
  %24925 = or i1 %24922, %24924
  %24926 = load i32, i32* %15, align 4
  %24927 = icmp eq i32 %24895, %24926
  %24928 = or i1 %24925, %24927
  %24929 = load i32, i32* %16, align 4
  %24930 = icmp eq i32 %24895, %24929
  %24931 = or i1 %24928, %24930
  %24932 = load i32, i32* %17, align 4
  %24933 = icmp eq i32 %24895, %24932
  %24934 = or i1 %24931, %24933
  %24935 = load i32, i32* %18, align 4
  %24936 = icmp eq i32 %24895, %24935
  %24937 = or i1 %24934, %24936
  %24938 = load i32, i32* %19, align 4
  %24939 = icmp eq i32 %24895, %24938
  %24940 = or i1 %24937, %24939
  %24941 = load i32, i32* %20, align 4
  %24942 = icmp eq i32 %24895, %24941
  %24943 = or i1 %24940, %24942
  %24944 = load i32, i32* %21, align 4
  %24945 = icmp eq i32 %24895, %24944
  %24946 = or i1 %24943, %24945
  %24947 = load i32, i32* %22, align 4
  %24948 = icmp eq i32 %24895, %24947
  %24949 = or i1 %24946, %24948
  %24950 = load i32, i32* %23, align 4
  %24951 = icmp eq i32 %24895, %24950
  %24952 = or i1 %24949, %24951
  %24953 = load i32, i32* %24, align 4
  %24954 = icmp eq i32 %24895, %24953
  %24955 = or i1 %24952, %24954
  %24956 = load i32, i32* %25, align 4
  %24957 = icmp eq i32 %24895, %24956
  %24958 = or i1 %24955, %24957
  %24959 = load i32, i32* %26, align 4
  %24960 = icmp eq i32 %24895, %24959
  %24961 = or i1 %24958, %24960
  %24962 = load i32, i32* %27, align 4
  %24963 = icmp eq i32 %24895, %24962
  %24964 = or i1 %24961, %24963
  %24965 = load i32, i32* %28, align 4
  %24966 = icmp eq i32 %24895, %24965
  %24967 = or i1 %24964, %24966
  %24968 = load i32, i32* %29, align 4
  %24969 = icmp eq i32 %24895, %24968
  %24970 = or i1 %24967, %24969
  %24971 = load i32, i32* %30, align 4
  %24972 = icmp eq i32 %24895, %24971
  %24973 = or i1 %24970, %24972
  %24974 = load i32, i32* %31, align 4
  %24975 = icmp eq i32 %24895, %24974
  %24976 = or i1 %24973, %24975
  %24977 = load i32, i32* %32, align 4
  %24978 = icmp eq i32 %24895, %24977
  %24979 = or i1 %24976, %24978
  %24980 = load i32, i32* %33, align 4
  %24981 = icmp eq i32 %24895, %24980
  %24982 = or i1 %24979, %24981
  %24983 = load i32, i32* %34, align 4
  %24984 = icmp eq i32 %24895, %24983
  %24985 = or i1 %24982, %24984
  %24986 = load i32, i32* %35, align 4
  %24987 = icmp eq i32 %24895, %24986
  %24988 = or i1 %24985, %24987
  %24989 = load i32, i32* %36, align 4
  %24990 = icmp eq i32 %24895, %24989
  %24991 = or i1 %24988, %24990
  %24992 = load i32, i32* %37, align 4
  %24993 = icmp eq i32 %24895, %24992
  %24994 = or i1 %24991, %24993
  %24995 = load i32, i32* %38, align 4
  %24996 = icmp eq i32 %24895, %24995
  %24997 = or i1 %24994, %24996
  %24998 = load i32, i32* %39, align 4
  %24999 = icmp eq i32 %24895, %24998
  %25000 = or i1 %24997, %24999
  %25001 = load i32, i32* %40, align 4
  %25002 = icmp eq i32 %24895, %25001
  %25003 = or i1 %25000, %25002
  %25004 = load i32, i32* %41, align 4
  %25005 = icmp eq i32 %24895, %25004
  %25006 = or i1 %25003, %25005
  %25007 = load i32, i32* %42, align 4
  %25008 = icmp eq i32 %24895, %25007
  %25009 = or i1 %25006, %25008
  %25010 = load i32, i32* %43, align 4
  %25011 = icmp eq i32 %24895, %25010
  %25012 = or i1 %25009, %25011
  %25013 = load i32, i32* %44, align 4
  %25014 = icmp eq i32 %24895, %25013
  %25015 = or i1 %25012, %25014
  %25016 = load i32, i32* %45, align 4
  %25017 = icmp eq i32 %24895, %25016
  %25018 = or i1 %25015, %25017
  %25019 = load i32, i32* %46, align 4
  %25020 = icmp eq i32 %24895, %25019
  %25021 = or i1 %25018, %25020
  %25022 = load i32, i32* %47, align 4
  %25023 = icmp eq i32 %24895, %25022
  %25024 = or i1 %25021, %25023
  %25025 = load i32, i32* %48, align 4
  %25026 = icmp eq i32 %24895, %25025
  %25027 = or i1 %25024, %25026
  %25028 = load i32, i32* %49, align 4
  %25029 = icmp eq i32 %24895, %25028
  %25030 = or i1 %25027, %25029
  %25031 = load i32, i32* %50, align 4
  %25032 = icmp eq i32 %24895, %25031
  %25033 = or i1 %25030, %25032
  %25034 = load i32, i32* %51, align 4
  %25035 = icmp eq i32 %24895, %25034
  %25036 = or i1 %25033, %25035
  %25037 = load i32, i32* %52, align 4
  %25038 = icmp eq i32 %24895, %25037
  %25039 = or i1 %25036, %25038
  %25040 = load i32, i32* %53, align 4
  %25041 = icmp eq i32 %24895, %25040
  %25042 = or i1 %25039, %25041
  %25043 = load i32, i32* %54, align 4
  %25044 = icmp eq i32 %24895, %25043
  %25045 = or i1 %25042, %25044
  %25046 = load i32, i32* %55, align 4
  %25047 = icmp eq i32 %24895, %25046
  %25048 = or i1 %25045, %25047
  %25049 = load i32, i32* %56, align 4
  %25050 = icmp eq i32 %24895, %25049
  %25051 = or i1 %25048, %25050
  %25052 = load i32, i32* %57, align 4
  %25053 = icmp eq i32 %24895, %25052
  %25054 = or i1 %25051, %25053
  %25055 = load i32, i32* %58, align 4
  %25056 = icmp eq i32 %24895, %25055
  %25057 = or i1 %25054, %25056
  %25058 = load i32, i32* %59, align 4
  %25059 = icmp eq i32 %24895, %25058
  %25060 = or i1 %25057, %25059
  %25061 = load i32, i32* %60, align 4
  %25062 = icmp eq i32 %24895, %25061
  %25063 = or i1 %25060, %25062
  %25064 = load i32, i32* %61, align 4
  %25065 = icmp eq i32 %24895, %25064
  %25066 = or i1 %25063, %25065
  %25067 = load i32, i32* %62, align 4
  %25068 = icmp eq i32 %24895, %25067
  %25069 = or i1 %25066, %25068
  %25070 = getelementptr i8, i8 addrspace(1)* %4, i32 86
  %25071 = zext i1 %25069 to i8
  store i8 %25071, i8 addrspace(1)* %25070, align 1, !nosanitize !3
  %25072 = load i256, i256* %24894, align 4
  %25073 = trunc i256 %24890 to i64
  store i64 %25073, i64* %JMP_TARGET_PTR, align 4
  %25074 = load i64, i64* %STACK_DEP_PTR, align 4
  %25075 = add i64 %25074, 1
  store i64 %25075, i64* %STACK_DEP_PTR, align 4
  %25076 = load i64, i64* %STACK_DEP_PTR, align 4
  %25077 = getelementptr i256, i256* %STACK, i64 %25076
  store i256 %24890, i256* %25077, align 4
  %25078 = load i64, i64* %STACK_DEP_PTR, align 4
  %25079 = add i64 %25078, 1
  store i64 %25079, i64* %STACK_DEP_PTR, align 4
  %25080 = load i64, i64* %STACK_DEP_PTR, align 4
  %25081 = getelementptr i256, i256* %STACK, i64 %25080
  store i256 %25072, i256* %25081, align 4
  br label %JumpTable, !EVMBB !4

.8728:                                            ; preds = %2712, %JumpTable
  %25082 = load i64, i64* %remaing_gas, align 4
  %25083 = icmp ugt i64 400, %25082
  br i1 %25083, label %Abort, label %25084

25084:                                            ; preds = %.8728
  %25085 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25086 = xor i32 %25085, 3704
  %25087 = urem i32 %25086, 4096
  %25088 = getelementptr i8, i8 addrspace(1)* %4, i32 %25087
  %25089 = load i8, i8 addrspace(1)* %25088, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25088, align 1, !nosanitize !3
  store i32 1852, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25090 = sub i64 %25082, 400
  store i64 %25090, i64* %remaing_gas, align 4
  %25091 = load i64, i64* %STACK_DEP_PTR, align 4
  %25092 = getelementptr i256, i256* %STACK, i64 %25091
  %25093 = load i256, i256* %25092, align 4
  %25094 = load i64, i64* %STACK_DEP_PTR, align 4
  %25095 = sub i64 %25094, 1
  store i64 %25095, i64* %STACK_DEP_PTR, align 4
  %25096 = load i64, i64* %STACK_DEP_PTR, align 4
  %25097 = getelementptr i256, i256* %STACK, i64 %25096
  %25098 = load i256, i256* %25097, align 4
  %25099 = load i64, i64* %STACK_DEP_PTR, align 4
  %25100 = sub i64 %25099, 1
  store i64 %25100, i64* %STACK_DEP_PTR, align 4
  %25101 = trunc i256 32 to i64
  %25102 = alloca i256, align 8
  store i256 3, i256* %25102, align 4
  %25103 = bitcast i256* %25102 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %25101, i8* %25103, i64 32)
  %25104 = trunc i256 0 to i64
  %25105 = alloca i256, align 8
  store i256 %25093, i256* %25105, align 4
  %25106 = bitcast i256* %25105 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %25104, i8* %25106, i64 32)
  %25107 = trunc i256 0 to i32
  %25108 = trunc i256 64 to i32
  %25109 = getelementptr inbounds i8, i8* %MEMORY, i32 %25107
  %25110 = alloca i256, align 8
  %25111 = bitcast i256* %25110 to i8*
  call void @__device_sha3(i8* %25109, i32 %25108, i8* %25111)
  %25112 = load i256, i256* %25110, align 4
  %25113 = alloca i256, align 8
  store i256 %25112, i256* %25113, align 4
  %25114 = alloca i256, align 8
  call void @__device_sload(i256* %25113, i256* %25114)
  %25115 = call i32 @__hashword(i256* %25113)
  %25116 = load i32, i32* %5, align 4
  %25117 = icmp eq i32 %25115, %25116
  %25118 = or i1 false, %25117
  %25119 = load i32, i32* %6, align 4
  %25120 = icmp eq i32 %25115, %25119
  %25121 = or i1 %25118, %25120
  %25122 = load i32, i32* %7, align 4
  %25123 = icmp eq i32 %25115, %25122
  %25124 = or i1 %25121, %25123
  %25125 = load i32, i32* %8, align 4
  %25126 = icmp eq i32 %25115, %25125
  %25127 = or i1 %25124, %25126
  %25128 = load i32, i32* %9, align 4
  %25129 = icmp eq i32 %25115, %25128
  %25130 = or i1 %25127, %25129
  %25131 = load i32, i32* %10, align 4
  %25132 = icmp eq i32 %25115, %25131
  %25133 = or i1 %25130, %25132
  %25134 = load i32, i32* %11, align 4
  %25135 = icmp eq i32 %25115, %25134
  %25136 = or i1 %25133, %25135
  %25137 = load i32, i32* %12, align 4
  %25138 = icmp eq i32 %25115, %25137
  %25139 = or i1 %25136, %25138
  %25140 = load i32, i32* %13, align 4
  %25141 = icmp eq i32 %25115, %25140
  %25142 = or i1 %25139, %25141
  %25143 = load i32, i32* %14, align 4
  %25144 = icmp eq i32 %25115, %25143
  %25145 = or i1 %25142, %25144
  %25146 = load i32, i32* %15, align 4
  %25147 = icmp eq i32 %25115, %25146
  %25148 = or i1 %25145, %25147
  %25149 = load i32, i32* %16, align 4
  %25150 = icmp eq i32 %25115, %25149
  %25151 = or i1 %25148, %25150
  %25152 = load i32, i32* %17, align 4
  %25153 = icmp eq i32 %25115, %25152
  %25154 = or i1 %25151, %25153
  %25155 = load i32, i32* %18, align 4
  %25156 = icmp eq i32 %25115, %25155
  %25157 = or i1 %25154, %25156
  %25158 = load i32, i32* %19, align 4
  %25159 = icmp eq i32 %25115, %25158
  %25160 = or i1 %25157, %25159
  %25161 = load i32, i32* %20, align 4
  %25162 = icmp eq i32 %25115, %25161
  %25163 = or i1 %25160, %25162
  %25164 = load i32, i32* %21, align 4
  %25165 = icmp eq i32 %25115, %25164
  %25166 = or i1 %25163, %25165
  %25167 = load i32, i32* %22, align 4
  %25168 = icmp eq i32 %25115, %25167
  %25169 = or i1 %25166, %25168
  %25170 = load i32, i32* %23, align 4
  %25171 = icmp eq i32 %25115, %25170
  %25172 = or i1 %25169, %25171
  %25173 = load i32, i32* %24, align 4
  %25174 = icmp eq i32 %25115, %25173
  %25175 = or i1 %25172, %25174
  %25176 = load i32, i32* %25, align 4
  %25177 = icmp eq i32 %25115, %25176
  %25178 = or i1 %25175, %25177
  %25179 = load i32, i32* %26, align 4
  %25180 = icmp eq i32 %25115, %25179
  %25181 = or i1 %25178, %25180
  %25182 = load i32, i32* %27, align 4
  %25183 = icmp eq i32 %25115, %25182
  %25184 = or i1 %25181, %25183
  %25185 = load i32, i32* %28, align 4
  %25186 = icmp eq i32 %25115, %25185
  %25187 = or i1 %25184, %25186
  %25188 = load i32, i32* %29, align 4
  %25189 = icmp eq i32 %25115, %25188
  %25190 = or i1 %25187, %25189
  %25191 = load i32, i32* %30, align 4
  %25192 = icmp eq i32 %25115, %25191
  %25193 = or i1 %25190, %25192
  %25194 = load i32, i32* %31, align 4
  %25195 = icmp eq i32 %25115, %25194
  %25196 = or i1 %25193, %25195
  %25197 = load i32, i32* %32, align 4
  %25198 = icmp eq i32 %25115, %25197
  %25199 = or i1 %25196, %25198
  %25200 = load i32, i32* %33, align 4
  %25201 = icmp eq i32 %25115, %25200
  %25202 = or i1 %25199, %25201
  %25203 = load i32, i32* %34, align 4
  %25204 = icmp eq i32 %25115, %25203
  %25205 = or i1 %25202, %25204
  %25206 = load i32, i32* %35, align 4
  %25207 = icmp eq i32 %25115, %25206
  %25208 = or i1 %25205, %25207
  %25209 = load i32, i32* %36, align 4
  %25210 = icmp eq i32 %25115, %25209
  %25211 = or i1 %25208, %25210
  %25212 = load i32, i32* %37, align 4
  %25213 = icmp eq i32 %25115, %25212
  %25214 = or i1 %25211, %25213
  %25215 = load i32, i32* %38, align 4
  %25216 = icmp eq i32 %25115, %25215
  %25217 = or i1 %25214, %25216
  %25218 = load i32, i32* %39, align 4
  %25219 = icmp eq i32 %25115, %25218
  %25220 = or i1 %25217, %25219
  %25221 = load i32, i32* %40, align 4
  %25222 = icmp eq i32 %25115, %25221
  %25223 = or i1 %25220, %25222
  %25224 = load i32, i32* %41, align 4
  %25225 = icmp eq i32 %25115, %25224
  %25226 = or i1 %25223, %25225
  %25227 = load i32, i32* %42, align 4
  %25228 = icmp eq i32 %25115, %25227
  %25229 = or i1 %25226, %25228
  %25230 = load i32, i32* %43, align 4
  %25231 = icmp eq i32 %25115, %25230
  %25232 = or i1 %25229, %25231
  %25233 = load i32, i32* %44, align 4
  %25234 = icmp eq i32 %25115, %25233
  %25235 = or i1 %25232, %25234
  %25236 = load i32, i32* %45, align 4
  %25237 = icmp eq i32 %25115, %25236
  %25238 = or i1 %25235, %25237
  %25239 = load i32, i32* %46, align 4
  %25240 = icmp eq i32 %25115, %25239
  %25241 = or i1 %25238, %25240
  %25242 = load i32, i32* %47, align 4
  %25243 = icmp eq i32 %25115, %25242
  %25244 = or i1 %25241, %25243
  %25245 = load i32, i32* %48, align 4
  %25246 = icmp eq i32 %25115, %25245
  %25247 = or i1 %25244, %25246
  %25248 = load i32, i32* %49, align 4
  %25249 = icmp eq i32 %25115, %25248
  %25250 = or i1 %25247, %25249
  %25251 = load i32, i32* %50, align 4
  %25252 = icmp eq i32 %25115, %25251
  %25253 = or i1 %25250, %25252
  %25254 = load i32, i32* %51, align 4
  %25255 = icmp eq i32 %25115, %25254
  %25256 = or i1 %25253, %25255
  %25257 = load i32, i32* %52, align 4
  %25258 = icmp eq i32 %25115, %25257
  %25259 = or i1 %25256, %25258
  %25260 = load i32, i32* %53, align 4
  %25261 = icmp eq i32 %25115, %25260
  %25262 = or i1 %25259, %25261
  %25263 = load i32, i32* %54, align 4
  %25264 = icmp eq i32 %25115, %25263
  %25265 = or i1 %25262, %25264
  %25266 = load i32, i32* %55, align 4
  %25267 = icmp eq i32 %25115, %25266
  %25268 = or i1 %25265, %25267
  %25269 = load i32, i32* %56, align 4
  %25270 = icmp eq i32 %25115, %25269
  %25271 = or i1 %25268, %25270
  %25272 = load i32, i32* %57, align 4
  %25273 = icmp eq i32 %25115, %25272
  %25274 = or i1 %25271, %25273
  %25275 = load i32, i32* %58, align 4
  %25276 = icmp eq i32 %25115, %25275
  %25277 = or i1 %25274, %25276
  %25278 = load i32, i32* %59, align 4
  %25279 = icmp eq i32 %25115, %25278
  %25280 = or i1 %25277, %25279
  %25281 = load i32, i32* %60, align 4
  %25282 = icmp eq i32 %25115, %25281
  %25283 = or i1 %25280, %25282
  %25284 = load i32, i32* %61, align 4
  %25285 = icmp eq i32 %25115, %25284
  %25286 = or i1 %25283, %25285
  %25287 = load i32, i32* %62, align 4
  %25288 = icmp eq i32 %25115, %25287
  %25289 = or i1 %25286, %25288
  %25290 = getelementptr i8, i8 addrspace(1)* %4, i32 87
  %25291 = zext i1 %25289 to i8
  store i8 %25291, i8 addrspace(1)* %25290, align 1, !nosanitize !3
  %25292 = load i256, i256* %25114, align 4
  %25293 = trunc i256 %25098 to i64
  store i64 %25293, i64* %JMP_TARGET_PTR, align 4
  %25294 = load i64, i64* %STACK_DEP_PTR, align 4
  %25295 = add i64 %25294, 1
  store i64 %25295, i64* %STACK_DEP_PTR, align 4
  %25296 = load i64, i64* %STACK_DEP_PTR, align 4
  %25297 = getelementptr i256, i256* %STACK, i64 %25296
  store i256 %25098, i256* %25297, align 4
  %25298 = load i64, i64* %STACK_DEP_PTR, align 4
  %25299 = add i64 %25298, 1
  store i64 %25299, i64* %STACK_DEP_PTR, align 4
  %25300 = load i64, i64* %STACK_DEP_PTR, align 4
  %25301 = getelementptr i256, i256* %STACK, i64 %25300
  store i256 %25292, i256* %25301, align 4
  br label %JumpTable, !EVMBB !4

.8752:                                            ; preds = %2796, %JumpTable
  %25302 = load i64, i64* %remaing_gas, align 4
  %25303 = icmp ugt i64 288, %25302
  br i1 %25303, label %Abort, label %25304

25304:                                            ; preds = %.8752
  %25305 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25306 = xor i32 %25305, 762
  %25307 = urem i32 %25306, 4096
  %25308 = getelementptr i8, i8 addrspace(1)* %4, i32 %25307
  %25309 = load i8, i8 addrspace(1)* %25308, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25308, align 1, !nosanitize !3
  store i32 381, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25310 = sub i64 %25302, 288
  store i64 %25310, i64* %remaing_gas, align 4
  %25311 = load i64, i64* %STACK_DEP_PTR, align 4
  %25312 = getelementptr i256, i256* %STACK, i64 %25311
  %25313 = load i256, i256* %25312, align 4
  %25314 = load i64, i64* %STACK_DEP_PTR, align 4
  %25315 = sub i64 %25314, 1
  store i64 %25315, i64* %STACK_DEP_PTR, align 4
  %25316 = alloca i256, align 8
  store i256 12, i256* %25316, align 4
  %25317 = alloca i256, align 8
  call void @__device_sload(i256* %25316, i256* %25317)
  %25318 = call i32 @__hashword(i256* %25316)
  %25319 = load i32, i32* %5, align 4
  %25320 = icmp eq i32 %25318, %25319
  %25321 = or i1 false, %25320
  %25322 = load i32, i32* %6, align 4
  %25323 = icmp eq i32 %25318, %25322
  %25324 = or i1 %25321, %25323
  %25325 = load i32, i32* %7, align 4
  %25326 = icmp eq i32 %25318, %25325
  %25327 = or i1 %25324, %25326
  %25328 = load i32, i32* %8, align 4
  %25329 = icmp eq i32 %25318, %25328
  %25330 = or i1 %25327, %25329
  %25331 = load i32, i32* %9, align 4
  %25332 = icmp eq i32 %25318, %25331
  %25333 = or i1 %25330, %25332
  %25334 = load i32, i32* %10, align 4
  %25335 = icmp eq i32 %25318, %25334
  %25336 = or i1 %25333, %25335
  %25337 = load i32, i32* %11, align 4
  %25338 = icmp eq i32 %25318, %25337
  %25339 = or i1 %25336, %25338
  %25340 = load i32, i32* %12, align 4
  %25341 = icmp eq i32 %25318, %25340
  %25342 = or i1 %25339, %25341
  %25343 = load i32, i32* %13, align 4
  %25344 = icmp eq i32 %25318, %25343
  %25345 = or i1 %25342, %25344
  %25346 = load i32, i32* %14, align 4
  %25347 = icmp eq i32 %25318, %25346
  %25348 = or i1 %25345, %25347
  %25349 = load i32, i32* %15, align 4
  %25350 = icmp eq i32 %25318, %25349
  %25351 = or i1 %25348, %25350
  %25352 = load i32, i32* %16, align 4
  %25353 = icmp eq i32 %25318, %25352
  %25354 = or i1 %25351, %25353
  %25355 = load i32, i32* %17, align 4
  %25356 = icmp eq i32 %25318, %25355
  %25357 = or i1 %25354, %25356
  %25358 = load i32, i32* %18, align 4
  %25359 = icmp eq i32 %25318, %25358
  %25360 = or i1 %25357, %25359
  %25361 = load i32, i32* %19, align 4
  %25362 = icmp eq i32 %25318, %25361
  %25363 = or i1 %25360, %25362
  %25364 = load i32, i32* %20, align 4
  %25365 = icmp eq i32 %25318, %25364
  %25366 = or i1 %25363, %25365
  %25367 = load i32, i32* %21, align 4
  %25368 = icmp eq i32 %25318, %25367
  %25369 = or i1 %25366, %25368
  %25370 = load i32, i32* %22, align 4
  %25371 = icmp eq i32 %25318, %25370
  %25372 = or i1 %25369, %25371
  %25373 = load i32, i32* %23, align 4
  %25374 = icmp eq i32 %25318, %25373
  %25375 = or i1 %25372, %25374
  %25376 = load i32, i32* %24, align 4
  %25377 = icmp eq i32 %25318, %25376
  %25378 = or i1 %25375, %25377
  %25379 = load i32, i32* %25, align 4
  %25380 = icmp eq i32 %25318, %25379
  %25381 = or i1 %25378, %25380
  %25382 = load i32, i32* %26, align 4
  %25383 = icmp eq i32 %25318, %25382
  %25384 = or i1 %25381, %25383
  %25385 = load i32, i32* %27, align 4
  %25386 = icmp eq i32 %25318, %25385
  %25387 = or i1 %25384, %25386
  %25388 = load i32, i32* %28, align 4
  %25389 = icmp eq i32 %25318, %25388
  %25390 = or i1 %25387, %25389
  %25391 = load i32, i32* %29, align 4
  %25392 = icmp eq i32 %25318, %25391
  %25393 = or i1 %25390, %25392
  %25394 = load i32, i32* %30, align 4
  %25395 = icmp eq i32 %25318, %25394
  %25396 = or i1 %25393, %25395
  %25397 = load i32, i32* %31, align 4
  %25398 = icmp eq i32 %25318, %25397
  %25399 = or i1 %25396, %25398
  %25400 = load i32, i32* %32, align 4
  %25401 = icmp eq i32 %25318, %25400
  %25402 = or i1 %25399, %25401
  %25403 = load i32, i32* %33, align 4
  %25404 = icmp eq i32 %25318, %25403
  %25405 = or i1 %25402, %25404
  %25406 = load i32, i32* %34, align 4
  %25407 = icmp eq i32 %25318, %25406
  %25408 = or i1 %25405, %25407
  %25409 = load i32, i32* %35, align 4
  %25410 = icmp eq i32 %25318, %25409
  %25411 = or i1 %25408, %25410
  %25412 = load i32, i32* %36, align 4
  %25413 = icmp eq i32 %25318, %25412
  %25414 = or i1 %25411, %25413
  %25415 = load i32, i32* %37, align 4
  %25416 = icmp eq i32 %25318, %25415
  %25417 = or i1 %25414, %25416
  %25418 = load i32, i32* %38, align 4
  %25419 = icmp eq i32 %25318, %25418
  %25420 = or i1 %25417, %25419
  %25421 = load i32, i32* %39, align 4
  %25422 = icmp eq i32 %25318, %25421
  %25423 = or i1 %25420, %25422
  %25424 = load i32, i32* %40, align 4
  %25425 = icmp eq i32 %25318, %25424
  %25426 = or i1 %25423, %25425
  %25427 = load i32, i32* %41, align 4
  %25428 = icmp eq i32 %25318, %25427
  %25429 = or i1 %25426, %25428
  %25430 = load i32, i32* %42, align 4
  %25431 = icmp eq i32 %25318, %25430
  %25432 = or i1 %25429, %25431
  %25433 = load i32, i32* %43, align 4
  %25434 = icmp eq i32 %25318, %25433
  %25435 = or i1 %25432, %25434
  %25436 = load i32, i32* %44, align 4
  %25437 = icmp eq i32 %25318, %25436
  %25438 = or i1 %25435, %25437
  %25439 = load i32, i32* %45, align 4
  %25440 = icmp eq i32 %25318, %25439
  %25441 = or i1 %25438, %25440
  %25442 = load i32, i32* %46, align 4
  %25443 = icmp eq i32 %25318, %25442
  %25444 = or i1 %25441, %25443
  %25445 = load i32, i32* %47, align 4
  %25446 = icmp eq i32 %25318, %25445
  %25447 = or i1 %25444, %25446
  %25448 = load i32, i32* %48, align 4
  %25449 = icmp eq i32 %25318, %25448
  %25450 = or i1 %25447, %25449
  %25451 = load i32, i32* %49, align 4
  %25452 = icmp eq i32 %25318, %25451
  %25453 = or i1 %25450, %25452
  %25454 = load i32, i32* %50, align 4
  %25455 = icmp eq i32 %25318, %25454
  %25456 = or i1 %25453, %25455
  %25457 = load i32, i32* %51, align 4
  %25458 = icmp eq i32 %25318, %25457
  %25459 = or i1 %25456, %25458
  %25460 = load i32, i32* %52, align 4
  %25461 = icmp eq i32 %25318, %25460
  %25462 = or i1 %25459, %25461
  %25463 = load i32, i32* %53, align 4
  %25464 = icmp eq i32 %25318, %25463
  %25465 = or i1 %25462, %25464
  %25466 = load i32, i32* %54, align 4
  %25467 = icmp eq i32 %25318, %25466
  %25468 = or i1 %25465, %25467
  %25469 = load i32, i32* %55, align 4
  %25470 = icmp eq i32 %25318, %25469
  %25471 = or i1 %25468, %25470
  %25472 = load i32, i32* %56, align 4
  %25473 = icmp eq i32 %25318, %25472
  %25474 = or i1 %25471, %25473
  %25475 = load i32, i32* %57, align 4
  %25476 = icmp eq i32 %25318, %25475
  %25477 = or i1 %25474, %25476
  %25478 = load i32, i32* %58, align 4
  %25479 = icmp eq i32 %25318, %25478
  %25480 = or i1 %25477, %25479
  %25481 = load i32, i32* %59, align 4
  %25482 = icmp eq i32 %25318, %25481
  %25483 = or i1 %25480, %25482
  %25484 = load i32, i32* %60, align 4
  %25485 = icmp eq i32 %25318, %25484
  %25486 = or i1 %25483, %25485
  %25487 = load i32, i32* %61, align 4
  %25488 = icmp eq i32 %25318, %25487
  %25489 = or i1 %25486, %25488
  %25490 = load i32, i32* %62, align 4
  %25491 = icmp eq i32 %25318, %25490
  %25492 = or i1 %25489, %25491
  %25493 = getelementptr i8, i8 addrspace(1)* %4, i32 88
  %25494 = zext i1 %25492 to i8
  store i8 %25494, i8 addrspace(1)* %25493, align 1, !nosanitize !3
  %25495 = load i256, i256* %25317, align 4
  %25496 = icmp ult i256 %25313, %25495
  %25497 = icmp eq i1 %25496, false
  %25498 = icmp eq i1 %25497, false
  %25499 = trunc i256 8767 to i64
  %jump.check126 = icmp ne i1 %25498, false
  %25500 = load i64, i64* %STACK_DEP_PTR, align 4
  %25501 = add i64 %25500, 1
  store i64 %25501, i64* %STACK_DEP_PTR, align 4
  %25502 = load i64, i64* %STACK_DEP_PTR, align 4
  %25503 = getelementptr i256, i256* %STACK, i64 %25502
  store i256 %25313, i256* %25503, align 4
  %25504 = load i64, i64* %STACK_DEP_PTR, align 4
  %25505 = add i64 %25504, 1
  store i64 %25505, i64* %STACK_DEP_PTR, align 4
  %25506 = load i64, i64* %STACK_DEP_PTR, align 4
  %25507 = getelementptr i256, i256* %STACK, i64 %25506
  store i256 12, i256* %25507, align 4
  %25508 = load i64, i64* %STACK_DEP_PTR, align 4
  %25509 = add i64 %25508, 1
  store i64 %25509, i64* %STACK_DEP_PTR, align 4
  %25510 = load i64, i64* %STACK_DEP_PTR, align 4
  %25511 = getelementptr i256, i256* %STACK, i64 %25510
  store i256 %25313, i256* %25511, align 4
  br i1 %jump.check126, label %.8767, label %.8766, !EVMBB !4

.8766:                                            ; preds = %25304
  %25512 = load i64, i64* %remaing_gas, align 4
  %25513 = icmp ugt i64 16, %25512
  br i1 %25513, label %Abort, label %25514

25514:                                            ; preds = %.8766
  %25515 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25516 = xor i32 %25515, 3913
  %25517 = urem i32 %25516, 4096
  %25518 = getelementptr i8, i8 addrspace(1)* %4, i32 %25517
  %25519 = load i8, i8 addrspace(1)* %25518, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25518, align 1, !nosanitize !3
  store i32 1956, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25520 = sub i64 %25512, 16
  store i64 %25520, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.8767:                                            ; preds = %25304, %JumpTable
  %25521 = load i64, i64* %remaing_gas, align 4
  %25522 = icmp ugt i64 464, %25521
  br i1 %25522, label %Abort, label %25523

25523:                                            ; preds = %.8767
  %25524 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25525 = xor i32 %25524, 3945
  %25526 = urem i32 %25525, 4096
  %25527 = getelementptr i8, i8 addrspace(1)* %4, i32 %25526
  %25528 = load i8, i8 addrspace(1)* %25527, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25527, align 1, !nosanitize !3
  store i32 1972, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25529 = sub i64 %25521, 464
  store i64 %25529, i64* %remaing_gas, align 4
  %25530 = load i64, i64* %STACK_DEP_PTR, align 4
  %25531 = getelementptr i256, i256* %STACK, i64 %25530
  %25532 = load i256, i256* %25531, align 4
  %25533 = load i64, i64* %STACK_DEP_PTR, align 4
  %25534 = sub i64 %25533, 1
  store i64 %25534, i64* %STACK_DEP_PTR, align 4
  %25535 = load i64, i64* %STACK_DEP_PTR, align 4
  %25536 = getelementptr i256, i256* %STACK, i64 %25535
  %25537 = load i256, i256* %25536, align 4
  %25538 = load i64, i64* %STACK_DEP_PTR, align 4
  %25539 = sub i64 %25538, 1
  store i64 %25539, i64* %STACK_DEP_PTR, align 4
  %25540 = load i64, i64* %STACK_DEP_PTR, align 4
  %25541 = getelementptr i256, i256* %STACK, i64 %25540
  %25542 = load i256, i256* %25541, align 4
  %25543 = load i64, i64* %STACK_DEP_PTR, align 4
  %25544 = sub i64 %25543, 1
  store i64 %25544, i64* %STACK_DEP_PTR, align 4
  %25545 = load i64, i64* %STACK_DEP_PTR, align 4
  %25546 = getelementptr i256, i256* %STACK, i64 %25545
  %25547 = load i256, i256* %25546, align 4
  %25548 = load i64, i64* %STACK_DEP_PTR, align 4
  %25549 = sub i64 %25548, 1
  store i64 %25549, i64* %STACK_DEP_PTR, align 4
  %25550 = trunc i256 0 to i64
  %25551 = alloca i256, align 8
  store i256 %25537, i256* %25551, align 4
  %25552 = bitcast i256* %25551 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %25550, i8* %25552, i64 32)
  %25553 = trunc i256 0 to i32
  %25554 = trunc i256 32 to i32
  %25555 = getelementptr inbounds i8, i8* %MEMORY, i32 %25553
  %25556 = alloca i256, align 8
  %25557 = bitcast i256* %25556 to i8*
  call void @__device_sha3(i8* %25555, i32 %25554, i8* %25557)
  %25558 = load i256, i256* %25556, align 4
  %25559 = add i256 %25558, %25532, !pc !408, !intsan !10
  %25560 = alloca i256, align 8
  store i256 %25559, i256* %25560, align 4
  %25561 = alloca i256, align 8
  call void @__device_sload(i256* %25560, i256* %25561)
  %25562 = call i32 @__hashword(i256* %25560)
  %25563 = load i32, i32* %5, align 4
  %25564 = icmp eq i32 %25562, %25563
  %25565 = or i1 false, %25564
  %25566 = load i32, i32* %6, align 4
  %25567 = icmp eq i32 %25562, %25566
  %25568 = or i1 %25565, %25567
  %25569 = load i32, i32* %7, align 4
  %25570 = icmp eq i32 %25562, %25569
  %25571 = or i1 %25568, %25570
  %25572 = load i32, i32* %8, align 4
  %25573 = icmp eq i32 %25562, %25572
  %25574 = or i1 %25571, %25573
  %25575 = load i32, i32* %9, align 4
  %25576 = icmp eq i32 %25562, %25575
  %25577 = or i1 %25574, %25576
  %25578 = load i32, i32* %10, align 4
  %25579 = icmp eq i32 %25562, %25578
  %25580 = or i1 %25577, %25579
  %25581 = load i32, i32* %11, align 4
  %25582 = icmp eq i32 %25562, %25581
  %25583 = or i1 %25580, %25582
  %25584 = load i32, i32* %12, align 4
  %25585 = icmp eq i32 %25562, %25584
  %25586 = or i1 %25583, %25585
  %25587 = load i32, i32* %13, align 4
  %25588 = icmp eq i32 %25562, %25587
  %25589 = or i1 %25586, %25588
  %25590 = load i32, i32* %14, align 4
  %25591 = icmp eq i32 %25562, %25590
  %25592 = or i1 %25589, %25591
  %25593 = load i32, i32* %15, align 4
  %25594 = icmp eq i32 %25562, %25593
  %25595 = or i1 %25592, %25594
  %25596 = load i32, i32* %16, align 4
  %25597 = icmp eq i32 %25562, %25596
  %25598 = or i1 %25595, %25597
  %25599 = load i32, i32* %17, align 4
  %25600 = icmp eq i32 %25562, %25599
  %25601 = or i1 %25598, %25600
  %25602 = load i32, i32* %18, align 4
  %25603 = icmp eq i32 %25562, %25602
  %25604 = or i1 %25601, %25603
  %25605 = load i32, i32* %19, align 4
  %25606 = icmp eq i32 %25562, %25605
  %25607 = or i1 %25604, %25606
  %25608 = load i32, i32* %20, align 4
  %25609 = icmp eq i32 %25562, %25608
  %25610 = or i1 %25607, %25609
  %25611 = load i32, i32* %21, align 4
  %25612 = icmp eq i32 %25562, %25611
  %25613 = or i1 %25610, %25612
  %25614 = load i32, i32* %22, align 4
  %25615 = icmp eq i32 %25562, %25614
  %25616 = or i1 %25613, %25615
  %25617 = load i32, i32* %23, align 4
  %25618 = icmp eq i32 %25562, %25617
  %25619 = or i1 %25616, %25618
  %25620 = load i32, i32* %24, align 4
  %25621 = icmp eq i32 %25562, %25620
  %25622 = or i1 %25619, %25621
  %25623 = load i32, i32* %25, align 4
  %25624 = icmp eq i32 %25562, %25623
  %25625 = or i1 %25622, %25624
  %25626 = load i32, i32* %26, align 4
  %25627 = icmp eq i32 %25562, %25626
  %25628 = or i1 %25625, %25627
  %25629 = load i32, i32* %27, align 4
  %25630 = icmp eq i32 %25562, %25629
  %25631 = or i1 %25628, %25630
  %25632 = load i32, i32* %28, align 4
  %25633 = icmp eq i32 %25562, %25632
  %25634 = or i1 %25631, %25633
  %25635 = load i32, i32* %29, align 4
  %25636 = icmp eq i32 %25562, %25635
  %25637 = or i1 %25634, %25636
  %25638 = load i32, i32* %30, align 4
  %25639 = icmp eq i32 %25562, %25638
  %25640 = or i1 %25637, %25639
  %25641 = load i32, i32* %31, align 4
  %25642 = icmp eq i32 %25562, %25641
  %25643 = or i1 %25640, %25642
  %25644 = load i32, i32* %32, align 4
  %25645 = icmp eq i32 %25562, %25644
  %25646 = or i1 %25643, %25645
  %25647 = load i32, i32* %33, align 4
  %25648 = icmp eq i32 %25562, %25647
  %25649 = or i1 %25646, %25648
  %25650 = load i32, i32* %34, align 4
  %25651 = icmp eq i32 %25562, %25650
  %25652 = or i1 %25649, %25651
  %25653 = load i32, i32* %35, align 4
  %25654 = icmp eq i32 %25562, %25653
  %25655 = or i1 %25652, %25654
  %25656 = load i32, i32* %36, align 4
  %25657 = icmp eq i32 %25562, %25656
  %25658 = or i1 %25655, %25657
  %25659 = load i32, i32* %37, align 4
  %25660 = icmp eq i32 %25562, %25659
  %25661 = or i1 %25658, %25660
  %25662 = load i32, i32* %38, align 4
  %25663 = icmp eq i32 %25562, %25662
  %25664 = or i1 %25661, %25663
  %25665 = load i32, i32* %39, align 4
  %25666 = icmp eq i32 %25562, %25665
  %25667 = or i1 %25664, %25666
  %25668 = load i32, i32* %40, align 4
  %25669 = icmp eq i32 %25562, %25668
  %25670 = or i1 %25667, %25669
  %25671 = load i32, i32* %41, align 4
  %25672 = icmp eq i32 %25562, %25671
  %25673 = or i1 %25670, %25672
  %25674 = load i32, i32* %42, align 4
  %25675 = icmp eq i32 %25562, %25674
  %25676 = or i1 %25673, %25675
  %25677 = load i32, i32* %43, align 4
  %25678 = icmp eq i32 %25562, %25677
  %25679 = or i1 %25676, %25678
  %25680 = load i32, i32* %44, align 4
  %25681 = icmp eq i32 %25562, %25680
  %25682 = or i1 %25679, %25681
  %25683 = load i32, i32* %45, align 4
  %25684 = icmp eq i32 %25562, %25683
  %25685 = or i1 %25682, %25684
  %25686 = load i32, i32* %46, align 4
  %25687 = icmp eq i32 %25562, %25686
  %25688 = or i1 %25685, %25687
  %25689 = load i32, i32* %47, align 4
  %25690 = icmp eq i32 %25562, %25689
  %25691 = or i1 %25688, %25690
  %25692 = load i32, i32* %48, align 4
  %25693 = icmp eq i32 %25562, %25692
  %25694 = or i1 %25691, %25693
  %25695 = load i32, i32* %49, align 4
  %25696 = icmp eq i32 %25562, %25695
  %25697 = or i1 %25694, %25696
  %25698 = load i32, i32* %50, align 4
  %25699 = icmp eq i32 %25562, %25698
  %25700 = or i1 %25697, %25699
  %25701 = load i32, i32* %51, align 4
  %25702 = icmp eq i32 %25562, %25701
  %25703 = or i1 %25700, %25702
  %25704 = load i32, i32* %52, align 4
  %25705 = icmp eq i32 %25562, %25704
  %25706 = or i1 %25703, %25705
  %25707 = load i32, i32* %53, align 4
  %25708 = icmp eq i32 %25562, %25707
  %25709 = or i1 %25706, %25708
  %25710 = load i32, i32* %54, align 4
  %25711 = icmp eq i32 %25562, %25710
  %25712 = or i1 %25709, %25711
  %25713 = load i32, i32* %55, align 4
  %25714 = icmp eq i32 %25562, %25713
  %25715 = or i1 %25712, %25714
  %25716 = load i32, i32* %56, align 4
  %25717 = icmp eq i32 %25562, %25716
  %25718 = or i1 %25715, %25717
  %25719 = load i32, i32* %57, align 4
  %25720 = icmp eq i32 %25562, %25719
  %25721 = or i1 %25718, %25720
  %25722 = load i32, i32* %58, align 4
  %25723 = icmp eq i32 %25562, %25722
  %25724 = or i1 %25721, %25723
  %25725 = load i32, i32* %59, align 4
  %25726 = icmp eq i32 %25562, %25725
  %25727 = or i1 %25724, %25726
  %25728 = load i32, i32* %60, align 4
  %25729 = icmp eq i32 %25562, %25728
  %25730 = or i1 %25727, %25729
  %25731 = load i32, i32* %61, align 4
  %25732 = icmp eq i32 %25562, %25731
  %25733 = or i1 %25730, %25732
  %25734 = load i32, i32* %62, align 4
  %25735 = icmp eq i32 %25562, %25734
  %25736 = or i1 %25733, %25735
  %25737 = getelementptr i8, i8 addrspace(1)* %4, i32 89
  %25738 = zext i1 %25736 to i8
  store i8 %25738, i8 addrspace(1)* %25737, align 1, !nosanitize !3
  %25739 = load i256, i256* %25561, align 4
  %25740 = trunc i256 %25547 to i64
  store i64 %25740, i64* %JMP_TARGET_PTR, align 4
  %25741 = load i64, i64* %STACK_DEP_PTR, align 4
  %25742 = add i64 %25741, 1
  store i64 %25742, i64* %STACK_DEP_PTR, align 4
  %25743 = load i64, i64* %STACK_DEP_PTR, align 4
  %25744 = getelementptr i256, i256* %STACK, i64 %25743
  store i256 %25547, i256* %25744, align 4
  %25745 = load i64, i64* %STACK_DEP_PTR, align 4
  %25746 = add i64 %25745, 1
  store i64 %25746, i64* %STACK_DEP_PTR, align 4
  %25747 = load i64, i64* %STACK_DEP_PTR, align 4
  %25748 = getelementptr i256, i256* %STACK, i64 %25747
  store i256 %25739, i256* %25748, align 4
  br label %JumpTable, !EVMBB !4

.8787:                                            ; preds = %35176, %21695, %2883, %JumpTable
  %25749 = load i64, i64* %remaing_gas, align 4
  %25750 = icmp ugt i64 184, %25749
  br i1 %25750, label %Abort, label %25751

25751:                                            ; preds = %.8787
  %25752 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25753 = xor i32 %25752, 230
  %25754 = urem i32 %25753, 4096
  %25755 = getelementptr i8, i8 addrspace(1)* %4, i32 %25754
  %25756 = load i8, i8 addrspace(1)* %25755, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25755, align 1, !nosanitize !3
  store i32 115, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25757 = sub i64 %25749, 184
  store i64 %25757, i64* %remaing_gas, align 4
  %25758 = alloca i256, align 8
  store i256 5, i256* %25758, align 4
  %25759 = alloca i256, align 8
  call void @__device_sload(i256* %25758, i256* %25759)
  %25760 = call i32 @__hashword(i256* %25758)
  %25761 = load i32, i32* %5, align 4
  %25762 = icmp eq i32 %25760, %25761
  %25763 = or i1 false, %25762
  %25764 = load i32, i32* %6, align 4
  %25765 = icmp eq i32 %25760, %25764
  %25766 = or i1 %25763, %25765
  %25767 = load i32, i32* %7, align 4
  %25768 = icmp eq i32 %25760, %25767
  %25769 = or i1 %25766, %25768
  %25770 = load i32, i32* %8, align 4
  %25771 = icmp eq i32 %25760, %25770
  %25772 = or i1 %25769, %25771
  %25773 = load i32, i32* %9, align 4
  %25774 = icmp eq i32 %25760, %25773
  %25775 = or i1 %25772, %25774
  %25776 = load i32, i32* %10, align 4
  %25777 = icmp eq i32 %25760, %25776
  %25778 = or i1 %25775, %25777
  %25779 = load i32, i32* %11, align 4
  %25780 = icmp eq i32 %25760, %25779
  %25781 = or i1 %25778, %25780
  %25782 = load i32, i32* %12, align 4
  %25783 = icmp eq i32 %25760, %25782
  %25784 = or i1 %25781, %25783
  %25785 = load i32, i32* %13, align 4
  %25786 = icmp eq i32 %25760, %25785
  %25787 = or i1 %25784, %25786
  %25788 = load i32, i32* %14, align 4
  %25789 = icmp eq i32 %25760, %25788
  %25790 = or i1 %25787, %25789
  %25791 = load i32, i32* %15, align 4
  %25792 = icmp eq i32 %25760, %25791
  %25793 = or i1 %25790, %25792
  %25794 = load i32, i32* %16, align 4
  %25795 = icmp eq i32 %25760, %25794
  %25796 = or i1 %25793, %25795
  %25797 = load i32, i32* %17, align 4
  %25798 = icmp eq i32 %25760, %25797
  %25799 = or i1 %25796, %25798
  %25800 = load i32, i32* %18, align 4
  %25801 = icmp eq i32 %25760, %25800
  %25802 = or i1 %25799, %25801
  %25803 = load i32, i32* %19, align 4
  %25804 = icmp eq i32 %25760, %25803
  %25805 = or i1 %25802, %25804
  %25806 = load i32, i32* %20, align 4
  %25807 = icmp eq i32 %25760, %25806
  %25808 = or i1 %25805, %25807
  %25809 = load i32, i32* %21, align 4
  %25810 = icmp eq i32 %25760, %25809
  %25811 = or i1 %25808, %25810
  %25812 = load i32, i32* %22, align 4
  %25813 = icmp eq i32 %25760, %25812
  %25814 = or i1 %25811, %25813
  %25815 = load i32, i32* %23, align 4
  %25816 = icmp eq i32 %25760, %25815
  %25817 = or i1 %25814, %25816
  %25818 = load i32, i32* %24, align 4
  %25819 = icmp eq i32 %25760, %25818
  %25820 = or i1 %25817, %25819
  %25821 = load i32, i32* %25, align 4
  %25822 = icmp eq i32 %25760, %25821
  %25823 = or i1 %25820, %25822
  %25824 = load i32, i32* %26, align 4
  %25825 = icmp eq i32 %25760, %25824
  %25826 = or i1 %25823, %25825
  %25827 = load i32, i32* %27, align 4
  %25828 = icmp eq i32 %25760, %25827
  %25829 = or i1 %25826, %25828
  %25830 = load i32, i32* %28, align 4
  %25831 = icmp eq i32 %25760, %25830
  %25832 = or i1 %25829, %25831
  %25833 = load i32, i32* %29, align 4
  %25834 = icmp eq i32 %25760, %25833
  %25835 = or i1 %25832, %25834
  %25836 = load i32, i32* %30, align 4
  %25837 = icmp eq i32 %25760, %25836
  %25838 = or i1 %25835, %25837
  %25839 = load i32, i32* %31, align 4
  %25840 = icmp eq i32 %25760, %25839
  %25841 = or i1 %25838, %25840
  %25842 = load i32, i32* %32, align 4
  %25843 = icmp eq i32 %25760, %25842
  %25844 = or i1 %25841, %25843
  %25845 = load i32, i32* %33, align 4
  %25846 = icmp eq i32 %25760, %25845
  %25847 = or i1 %25844, %25846
  %25848 = load i32, i32* %34, align 4
  %25849 = icmp eq i32 %25760, %25848
  %25850 = or i1 %25847, %25849
  %25851 = load i32, i32* %35, align 4
  %25852 = icmp eq i32 %25760, %25851
  %25853 = or i1 %25850, %25852
  %25854 = load i32, i32* %36, align 4
  %25855 = icmp eq i32 %25760, %25854
  %25856 = or i1 %25853, %25855
  %25857 = load i32, i32* %37, align 4
  %25858 = icmp eq i32 %25760, %25857
  %25859 = or i1 %25856, %25858
  %25860 = load i32, i32* %38, align 4
  %25861 = icmp eq i32 %25760, %25860
  %25862 = or i1 %25859, %25861
  %25863 = load i32, i32* %39, align 4
  %25864 = icmp eq i32 %25760, %25863
  %25865 = or i1 %25862, %25864
  %25866 = load i32, i32* %40, align 4
  %25867 = icmp eq i32 %25760, %25866
  %25868 = or i1 %25865, %25867
  %25869 = load i32, i32* %41, align 4
  %25870 = icmp eq i32 %25760, %25869
  %25871 = or i1 %25868, %25870
  %25872 = load i32, i32* %42, align 4
  %25873 = icmp eq i32 %25760, %25872
  %25874 = or i1 %25871, %25873
  %25875 = load i32, i32* %43, align 4
  %25876 = icmp eq i32 %25760, %25875
  %25877 = or i1 %25874, %25876
  %25878 = load i32, i32* %44, align 4
  %25879 = icmp eq i32 %25760, %25878
  %25880 = or i1 %25877, %25879
  %25881 = load i32, i32* %45, align 4
  %25882 = icmp eq i32 %25760, %25881
  %25883 = or i1 %25880, %25882
  %25884 = load i32, i32* %46, align 4
  %25885 = icmp eq i32 %25760, %25884
  %25886 = or i1 %25883, %25885
  %25887 = load i32, i32* %47, align 4
  %25888 = icmp eq i32 %25760, %25887
  %25889 = or i1 %25886, %25888
  %25890 = load i32, i32* %48, align 4
  %25891 = icmp eq i32 %25760, %25890
  %25892 = or i1 %25889, %25891
  %25893 = load i32, i32* %49, align 4
  %25894 = icmp eq i32 %25760, %25893
  %25895 = or i1 %25892, %25894
  %25896 = load i32, i32* %50, align 4
  %25897 = icmp eq i32 %25760, %25896
  %25898 = or i1 %25895, %25897
  %25899 = load i32, i32* %51, align 4
  %25900 = icmp eq i32 %25760, %25899
  %25901 = or i1 %25898, %25900
  %25902 = load i32, i32* %52, align 4
  %25903 = icmp eq i32 %25760, %25902
  %25904 = or i1 %25901, %25903
  %25905 = load i32, i32* %53, align 4
  %25906 = icmp eq i32 %25760, %25905
  %25907 = or i1 %25904, %25906
  %25908 = load i32, i32* %54, align 4
  %25909 = icmp eq i32 %25760, %25908
  %25910 = or i1 %25907, %25909
  %25911 = load i32, i32* %55, align 4
  %25912 = icmp eq i32 %25760, %25911
  %25913 = or i1 %25910, %25912
  %25914 = load i32, i32* %56, align 4
  %25915 = icmp eq i32 %25760, %25914
  %25916 = or i1 %25913, %25915
  %25917 = load i32, i32* %57, align 4
  %25918 = icmp eq i32 %25760, %25917
  %25919 = or i1 %25916, %25918
  %25920 = load i32, i32* %58, align 4
  %25921 = icmp eq i32 %25760, %25920
  %25922 = or i1 %25919, %25921
  %25923 = load i32, i32* %59, align 4
  %25924 = icmp eq i32 %25760, %25923
  %25925 = or i1 %25922, %25924
  %25926 = load i32, i32* %60, align 4
  %25927 = icmp eq i32 %25760, %25926
  %25928 = or i1 %25925, %25927
  %25929 = load i32, i32* %61, align 4
  %25930 = icmp eq i32 %25760, %25929
  %25931 = or i1 %25928, %25930
  %25932 = load i32, i32* %62, align 4
  %25933 = icmp eq i32 %25760, %25932
  %25934 = or i1 %25931, %25933
  %25935 = getelementptr i8, i8 addrspace(1)* %4, i32 90
  %25936 = zext i1 %25934 to i8
  store i8 %25936, i8 addrspace(1)* %25935, align 1, !nosanitize !3
  %25937 = load i256, i256* %25759, align 4
  %25938 = icmp eq i256 %25937, 10
  %25939 = icmp eq i1 %25938, false
  %25940 = trunc i256 8881 to i64
  %jump.check131 = icmp ne i1 %25939, false
  %25941 = load i64, i64* %STACK_DEP_PTR, align 4
  %25942 = add i64 %25941, 1
  store i64 %25942, i64* %STACK_DEP_PTR, align 4
  %25943 = load i64, i64* %STACK_DEP_PTR, align 4
  %25944 = getelementptr i256, i256* %STACK, i64 %25943
  store i256 0, i256* %25944, align 4
  %25945 = load i64, i64* %STACK_DEP_PTR, align 4
  %25946 = add i64 %25945, 1
  store i64 %25946, i64* %STACK_DEP_PTR, align 4
  %25947 = load i64, i64* %STACK_DEP_PTR, align 4
  %25948 = getelementptr i256, i256* %STACK, i64 %25947
  store i256 0, i256* %25948, align 4
  br i1 %jump.check131, label %.8881, label %.8802, !EVMBB !4

.8802:                                            ; preds = %25751
  %25949 = load i64, i64* %remaing_gas, align 4
  %25950 = icmp ugt i64 96, %25949
  br i1 %25950, label %Abort, label %25951

25951:                                            ; preds = %.8802
  %25952 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25953 = xor i32 %25952, 3619
  %25954 = urem i32 %25953, 4096
  %25955 = getelementptr i8, i8 addrspace(1)* %4, i32 %25954
  %25956 = load i8, i8 addrspace(1)* %25955, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25955, align 1, !nosanitize !3
  store i32 1809, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25957 = sub i64 %25949, 96
  store i64 %25957, i64* %remaing_gas, align 4
  %25958 = load i64, i64* %STACK_DEP_PTR, align 4
  %25959 = sub i64 %25958, 0
  store i64 %25959, i64* %STACK_DEP_PTR, align 4
  %25960 = trunc i256 7136 to i64
  %25961 = load i64, i64* %STACK_DEP_PTR, align 4
  %25962 = add i64 %25961, 1
  store i64 %25962, i64* %STACK_DEP_PTR, align 4
  %25963 = load i64, i64* %STACK_DEP_PTR, align 4
  %25964 = getelementptr i256, i256* %STACK, i64 %25963
  store i256 8809, i256* %25964, align 4
  br label %.7136, !EVMBB !4

.8809:                                            ; preds = %JumpTable
  %25965 = load i64, i64* %remaing_gas, align 4
  %25966 = icmp ugt i64 528, %25965
  br i1 %25966, label %Abort, label %25967

25967:                                            ; preds = %.8809
  %25968 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25969 = xor i32 %25968, 2000
  %25970 = urem i32 %25969, 4096
  %25971 = getelementptr i8, i8 addrspace(1)* %4, i32 %25970
  %25972 = load i8, i8 addrspace(1)* %25971, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %25971, align 1, !nosanitize !3
  store i32 1000, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %25973 = sub i64 %25965, 528
  store i64 %25973, i64* %remaing_gas, align 4
  %25974 = load i64, i64* %STACK_DEP_PTR, align 4
  %25975 = getelementptr i256, i256* %STACK, i64 %25974
  %25976 = load i256, i256* %25975, align 4
  %25977 = load i64, i64* %STACK_DEP_PTR, align 4
  %25978 = sub i64 %25977, 1
  store i64 %25978, i64* %STACK_DEP_PTR, align 4
  %25979 = load i64, i64* %STACK_DEP_PTR, align 4
  %25980 = getelementptr i256, i256* %STACK, i64 %25979
  %25981 = load i256, i256* %25980, align 4
  %25982 = load i64, i64* %STACK_DEP_PTR, align 4
  %25983 = sub i64 %25982, 1
  store i64 %25983, i64* %STACK_DEP_PTR, align 4
  %25984 = trunc i256 0 to i64
  %25985 = alloca i256, align 8
  store i256 %25976, i256* %25985, align 4
  %25986 = bitcast i256* %25985 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %25984, i8* %25986, i64 32)
  %25987 = add i256 32, 0, !pc !409, !intsan !10
  %25988 = trunc i256 %25987 to i64
  %25989 = alloca i256, align 8
  store i256 4, i256* %25989, align 4
  %25990 = bitcast i256* %25989 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %25988, i8* %25990, i64 32)
  %25991 = add i256 32, %25987, !pc !410, !intsan !10
  %25992 = trunc i256 0 to i32
  %25993 = trunc i256 %25991 to i32
  %25994 = getelementptr inbounds i8, i8* %MEMORY, i32 %25992
  %25995 = alloca i256, align 8
  %25996 = bitcast i256* %25995 to i8*
  call void @__device_sha3(i8* %25994, i32 %25993, i8* %25996)
  %25997 = load i256, i256* %25995, align 4
  %25998 = add i256 0, %25997, !pc !411, !intsan !10
  %25999 = alloca i256, align 8
  store i256 %25998, i256* %25999, align 4
  %26000 = alloca i256, align 8
  call void @__device_sload(i256* %25999, i256* %26000)
  %26001 = call i32 @__hashword(i256* %25999)
  %26002 = load i32, i32* %5, align 4
  %26003 = icmp eq i32 %26001, %26002
  %26004 = or i1 false, %26003
  %26005 = load i32, i32* %6, align 4
  %26006 = icmp eq i32 %26001, %26005
  %26007 = or i1 %26004, %26006
  %26008 = load i32, i32* %7, align 4
  %26009 = icmp eq i32 %26001, %26008
  %26010 = or i1 %26007, %26009
  %26011 = load i32, i32* %8, align 4
  %26012 = icmp eq i32 %26001, %26011
  %26013 = or i1 %26010, %26012
  %26014 = load i32, i32* %9, align 4
  %26015 = icmp eq i32 %26001, %26014
  %26016 = or i1 %26013, %26015
  %26017 = load i32, i32* %10, align 4
  %26018 = icmp eq i32 %26001, %26017
  %26019 = or i1 %26016, %26018
  %26020 = load i32, i32* %11, align 4
  %26021 = icmp eq i32 %26001, %26020
  %26022 = or i1 %26019, %26021
  %26023 = load i32, i32* %12, align 4
  %26024 = icmp eq i32 %26001, %26023
  %26025 = or i1 %26022, %26024
  %26026 = load i32, i32* %13, align 4
  %26027 = icmp eq i32 %26001, %26026
  %26028 = or i1 %26025, %26027
  %26029 = load i32, i32* %14, align 4
  %26030 = icmp eq i32 %26001, %26029
  %26031 = or i1 %26028, %26030
  %26032 = load i32, i32* %15, align 4
  %26033 = icmp eq i32 %26001, %26032
  %26034 = or i1 %26031, %26033
  %26035 = load i32, i32* %16, align 4
  %26036 = icmp eq i32 %26001, %26035
  %26037 = or i1 %26034, %26036
  %26038 = load i32, i32* %17, align 4
  %26039 = icmp eq i32 %26001, %26038
  %26040 = or i1 %26037, %26039
  %26041 = load i32, i32* %18, align 4
  %26042 = icmp eq i32 %26001, %26041
  %26043 = or i1 %26040, %26042
  %26044 = load i32, i32* %19, align 4
  %26045 = icmp eq i32 %26001, %26044
  %26046 = or i1 %26043, %26045
  %26047 = load i32, i32* %20, align 4
  %26048 = icmp eq i32 %26001, %26047
  %26049 = or i1 %26046, %26048
  %26050 = load i32, i32* %21, align 4
  %26051 = icmp eq i32 %26001, %26050
  %26052 = or i1 %26049, %26051
  %26053 = load i32, i32* %22, align 4
  %26054 = icmp eq i32 %26001, %26053
  %26055 = or i1 %26052, %26054
  %26056 = load i32, i32* %23, align 4
  %26057 = icmp eq i32 %26001, %26056
  %26058 = or i1 %26055, %26057
  %26059 = load i32, i32* %24, align 4
  %26060 = icmp eq i32 %26001, %26059
  %26061 = or i1 %26058, %26060
  %26062 = load i32, i32* %25, align 4
  %26063 = icmp eq i32 %26001, %26062
  %26064 = or i1 %26061, %26063
  %26065 = load i32, i32* %26, align 4
  %26066 = icmp eq i32 %26001, %26065
  %26067 = or i1 %26064, %26066
  %26068 = load i32, i32* %27, align 4
  %26069 = icmp eq i32 %26001, %26068
  %26070 = or i1 %26067, %26069
  %26071 = load i32, i32* %28, align 4
  %26072 = icmp eq i32 %26001, %26071
  %26073 = or i1 %26070, %26072
  %26074 = load i32, i32* %29, align 4
  %26075 = icmp eq i32 %26001, %26074
  %26076 = or i1 %26073, %26075
  %26077 = load i32, i32* %30, align 4
  %26078 = icmp eq i32 %26001, %26077
  %26079 = or i1 %26076, %26078
  %26080 = load i32, i32* %31, align 4
  %26081 = icmp eq i32 %26001, %26080
  %26082 = or i1 %26079, %26081
  %26083 = load i32, i32* %32, align 4
  %26084 = icmp eq i32 %26001, %26083
  %26085 = or i1 %26082, %26084
  %26086 = load i32, i32* %33, align 4
  %26087 = icmp eq i32 %26001, %26086
  %26088 = or i1 %26085, %26087
  %26089 = load i32, i32* %34, align 4
  %26090 = icmp eq i32 %26001, %26089
  %26091 = or i1 %26088, %26090
  %26092 = load i32, i32* %35, align 4
  %26093 = icmp eq i32 %26001, %26092
  %26094 = or i1 %26091, %26093
  %26095 = load i32, i32* %36, align 4
  %26096 = icmp eq i32 %26001, %26095
  %26097 = or i1 %26094, %26096
  %26098 = load i32, i32* %37, align 4
  %26099 = icmp eq i32 %26001, %26098
  %26100 = or i1 %26097, %26099
  %26101 = load i32, i32* %38, align 4
  %26102 = icmp eq i32 %26001, %26101
  %26103 = or i1 %26100, %26102
  %26104 = load i32, i32* %39, align 4
  %26105 = icmp eq i32 %26001, %26104
  %26106 = or i1 %26103, %26105
  %26107 = load i32, i32* %40, align 4
  %26108 = icmp eq i32 %26001, %26107
  %26109 = or i1 %26106, %26108
  %26110 = load i32, i32* %41, align 4
  %26111 = icmp eq i32 %26001, %26110
  %26112 = or i1 %26109, %26111
  %26113 = load i32, i32* %42, align 4
  %26114 = icmp eq i32 %26001, %26113
  %26115 = or i1 %26112, %26114
  %26116 = load i32, i32* %43, align 4
  %26117 = icmp eq i32 %26001, %26116
  %26118 = or i1 %26115, %26117
  %26119 = load i32, i32* %44, align 4
  %26120 = icmp eq i32 %26001, %26119
  %26121 = or i1 %26118, %26120
  %26122 = load i32, i32* %45, align 4
  %26123 = icmp eq i32 %26001, %26122
  %26124 = or i1 %26121, %26123
  %26125 = load i32, i32* %46, align 4
  %26126 = icmp eq i32 %26001, %26125
  %26127 = or i1 %26124, %26126
  %26128 = load i32, i32* %47, align 4
  %26129 = icmp eq i32 %26001, %26128
  %26130 = or i1 %26127, %26129
  %26131 = load i32, i32* %48, align 4
  %26132 = icmp eq i32 %26001, %26131
  %26133 = or i1 %26130, %26132
  %26134 = load i32, i32* %49, align 4
  %26135 = icmp eq i32 %26001, %26134
  %26136 = or i1 %26133, %26135
  %26137 = load i32, i32* %50, align 4
  %26138 = icmp eq i32 %26001, %26137
  %26139 = or i1 %26136, %26138
  %26140 = load i32, i32* %51, align 4
  %26141 = icmp eq i32 %26001, %26140
  %26142 = or i1 %26139, %26141
  %26143 = load i32, i32* %52, align 4
  %26144 = icmp eq i32 %26001, %26143
  %26145 = or i1 %26142, %26144
  %26146 = load i32, i32* %53, align 4
  %26147 = icmp eq i32 %26001, %26146
  %26148 = or i1 %26145, %26147
  %26149 = load i32, i32* %54, align 4
  %26150 = icmp eq i32 %26001, %26149
  %26151 = or i1 %26148, %26150
  %26152 = load i32, i32* %55, align 4
  %26153 = icmp eq i32 %26001, %26152
  %26154 = or i1 %26151, %26153
  %26155 = load i32, i32* %56, align 4
  %26156 = icmp eq i32 %26001, %26155
  %26157 = or i1 %26154, %26156
  %26158 = load i32, i32* %57, align 4
  %26159 = icmp eq i32 %26001, %26158
  %26160 = or i1 %26157, %26159
  %26161 = load i32, i32* %58, align 4
  %26162 = icmp eq i32 %26001, %26161
  %26163 = or i1 %26160, %26162
  %26164 = load i32, i32* %59, align 4
  %26165 = icmp eq i32 %26001, %26164
  %26166 = or i1 %26163, %26165
  %26167 = load i32, i32* %60, align 4
  %26168 = icmp eq i32 %26001, %26167
  %26169 = or i1 %26166, %26168
  %26170 = load i32, i32* %61, align 4
  %26171 = icmp eq i32 %26001, %26170
  %26172 = or i1 %26169, %26171
  %26173 = load i32, i32* %62, align 4
  %26174 = icmp eq i32 %26001, %26173
  %26175 = or i1 %26172, %26174
  %26176 = getelementptr i8, i8 addrspace(1)* %4, i32 91
  %26177 = zext i1 %26175 to i8
  store i8 %26177, i8 addrspace(1)* %26176, align 1, !nosanitize !3
  %26178 = load i256, i256* %26000, align 4
  %26179 = alloca i256, align 8
  store i256 %26178, i256* %26179, align 4
  %26180 = alloca i256, align 8
  store i256 1, i256* %26180, align 4
  %26181 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %26179, i256* %26180, i256* %26181), !pc !412, !intsan !6
  %26182 = load i256, i256* %26181, align 4
  %26183 = and i256 1461501637330902918203684832716283019655932542975, %26182
  %26184 = trunc i256 11418 to i64
  %26185 = load i64, i64* %STACK_DEP_PTR, align 4
  %26186 = add i64 %26185, 1
  store i64 %26186, i64* %STACK_DEP_PTR, align 4
  %26187 = load i64, i64* %STACK_DEP_PTR, align 4
  %26188 = getelementptr i256, i256* %STACK, i64 %26187
  store i256 %25976, i256* %26188, align 4
  %26189 = load i64, i64* %STACK_DEP_PTR, align 4
  %26190 = add i64 %26189, 1
  store i64 %26190, i64* %STACK_DEP_PTR, align 4
  %26191 = load i64, i64* %STACK_DEP_PTR, align 4
  %26192 = getelementptr i256, i256* %STACK, i64 %26191
  store i256 8874, i256* %26192, align 4
  %26193 = load i64, i64* %STACK_DEP_PTR, align 4
  %26194 = add i64 %26193, 1
  store i64 %26194, i64* %STACK_DEP_PTR, align 4
  %26195 = load i64, i64* %STACK_DEP_PTR, align 4
  %26196 = getelementptr i256, i256* %STACK, i64 %26195
  store i256 %26183, i256* %26196, align 4
  br label %.11418, !EVMBB !4

.8874:                                            ; preds = %JumpTable
  %26197 = load i64, i64* %remaing_gas, align 4
  %26198 = icmp ugt i64 264, %26197
  br i1 %26198, label %Abort, label %26199

26199:                                            ; preds = %.8874
  %26200 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26201 = xor i32 %26200, 3354
  %26202 = urem i32 %26201, 4096
  %26203 = getelementptr i8, i8 addrspace(1)* %4, i32 %26202
  %26204 = load i8, i8 addrspace(1)* %26203, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26203, align 1, !nosanitize !3
  store i32 1677, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26205 = sub i64 %26197, 264
  store i64 %26205, i64* %remaing_gas, align 4
  %26206 = load i64, i64* %STACK_DEP_PTR, align 4
  %26207 = getelementptr i256, i256* %STACK, i64 %26206
  %26208 = load i256, i256* %26207, align 4
  %26209 = load i64, i64* %STACK_DEP_PTR, align 4
  %26210 = sub i64 %26209, 1
  store i64 %26210, i64* %STACK_DEP_PTR, align 4
  %26211 = load i64, i64* %STACK_DEP_PTR, align 4
  %26212 = getelementptr i256, i256* %STACK, i64 %26211
  %26213 = load i256, i256* %26212, align 4
  %26214 = load i64, i64* %STACK_DEP_PTR, align 4
  %26215 = sub i64 %26214, 1
  store i64 %26215, i64* %STACK_DEP_PTR, align 4
  %26216 = load i64, i64* %STACK_DEP_PTR, align 4
  %26217 = getelementptr i256, i256* %STACK, i64 %26216
  %26218 = load i256, i256* %26217, align 4
  %26219 = load i64, i64* %STACK_DEP_PTR, align 4
  %26220 = sub i64 %26219, 1
  store i64 %26220, i64* %STACK_DEP_PTR, align 4
  %26221 = trunc i256 8886 to i64
  %26222 = load i64, i64* %STACK_DEP_PTR, align 4
  %26223 = add i64 %26222, 1
  store i64 %26223, i64* %STACK_DEP_PTR, align 4
  %26224 = load i64, i64* %STACK_DEP_PTR, align 4
  %26225 = getelementptr i256, i256* %STACK, i64 %26224
  store i256 %26208, i256* %26225, align 4
  %26226 = load i64, i64* %STACK_DEP_PTR, align 4
  %26227 = add i64 %26226, 1
  store i64 %26227, i64* %STACK_DEP_PTR, align 4
  %26228 = load i64, i64* %STACK_DEP_PTR, align 4
  %26229 = getelementptr i256, i256* %STACK, i64 %26228
  store i256 %26213, i256* %26229, align 4
  br label %.8886, !EVMBB !4

.8881:                                            ; preds = %25751, %JumpTable
  %26230 = load i64, i64* %STACK_DEP_PTR, align 4
  %26231 = getelementptr i256, i256* %STACK, i64 %26230
  %26232 = load i256, i256* %26231, align 4
  %26233 = load i64, i64* %STACK_DEP_PTR, align 4
  %26234 = sub i64 %26233, 1
  store i64 %26234, i64* %STACK_DEP_PTR, align 4
  %26235 = load i64, i64* %STACK_DEP_PTR, align 4
  %26236 = getelementptr i256, i256* %STACK, i64 %26235
  %26237 = load i256, i256* %26236, align 4
  %26238 = load i64, i64* %STACK_DEP_PTR, align 4
  %26239 = sub i64 %26238, 1
  store i64 %26239, i64* %STACK_DEP_PTR, align 4
  %26240 = load i64, i64* %STACK_DEP_PTR, align 4
  %26241 = add i64 %26240, 1
  store i64 %26241, i64* %STACK_DEP_PTR, align 4
  %26242 = load i64, i64* %STACK_DEP_PTR, align 4
  %26243 = getelementptr i256, i256* %STACK, i64 %26242
  store i256 0, i256* %26243, align 4
  %26244 = load i64, i64* %STACK_DEP_PTR, align 4
  %26245 = add i64 %26244, 1
  store i64 %26245, i64* %STACK_DEP_PTR, align 4
  %26246 = load i64, i64* %STACK_DEP_PTR, align 4
  %26247 = getelementptr i256, i256* %STACK, i64 %26246
  store i256 %26232, i256* %26247, align 4
  br label %.8886

.8886:                                            ; preds = %.8881, %26199, %JumpTable
  %26248 = load i64, i64* %remaing_gas, align 4
  %26249 = icmp ugt i64 224, %26248
  br i1 %26249, label %Abort, label %26250

26250:                                            ; preds = %.8886
  %26251 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26252 = xor i32 %26251, 2522
  %26253 = urem i32 %26252, 4096
  %26254 = getelementptr i8, i8 addrspace(1)* %4, i32 %26253
  %26255 = load i8, i8 addrspace(1)* %26254, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26254, align 1, !nosanitize !3
  store i32 1261, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26256 = sub i64 %26248, 224
  store i64 %26256, i64* %remaing_gas, align 4
  %26257 = load i64, i64* %STACK_DEP_PTR, align 4
  %26258 = getelementptr i256, i256* %STACK, i64 %26257
  %26259 = load i256, i256* %26258, align 4
  %26260 = load i64, i64* %STACK_DEP_PTR, align 4
  %26261 = sub i64 %26260, 1
  store i64 %26261, i64* %STACK_DEP_PTR, align 4
  %26262 = load i64, i64* %STACK_DEP_PTR, align 4
  %26263 = getelementptr i256, i256* %STACK, i64 %26262
  %26264 = load i256, i256* %26263, align 4
  %26265 = load i64, i64* %STACK_DEP_PTR, align 4
  %26266 = sub i64 %26265, 1
  store i64 %26266, i64* %STACK_DEP_PTR, align 4
  %26267 = load i64, i64* %STACK_DEP_PTR, align 4
  %26268 = getelementptr i256, i256* %STACK, i64 %26267
  %26269 = load i256, i256* %26268, align 4
  %26270 = load i64, i64* %STACK_DEP_PTR, align 4
  %26271 = sub i64 %26270, 1
  store i64 %26271, i64* %STACK_DEP_PTR, align 4
  %26272 = trunc i256 %26269 to i64
  store i64 %26272, i64* %JMP_TARGET_PTR, align 4
  %26273 = load i64, i64* %STACK_DEP_PTR, align 4
  %26274 = add i64 %26273, 1
  store i64 %26274, i64* %STACK_DEP_PTR, align 4
  %26275 = load i64, i64* %STACK_DEP_PTR, align 4
  %26276 = getelementptr i256, i256* %STACK, i64 %26275
  store i256 %26264, i256* %26276, align 4
  br label %JumpTable, !EVMBB !4

.8890:                                            ; preds = %2954, %JumpTable
  %26277 = load i64, i64* %remaing_gas, align 4
  %26278 = icmp ugt i64 880, %26277
  br i1 %26278, label %Abort, label %26279

26279:                                            ; preds = %.8890
  %26280 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26281 = xor i32 %26280, 3689
  %26282 = urem i32 %26281, 4096
  %26283 = getelementptr i8, i8 addrspace(1)* %4, i32 %26282
  %26284 = load i8, i8 addrspace(1)* %26283, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26283, align 1, !nosanitize !3
  store i32 1844, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26285 = sub i64 %26277, 880
  store i64 %26285, i64* %remaing_gas, align 4
  %26286 = alloca i256, align 8
  store i256 0, i256* %26286, align 4
  %26287 = alloca i256, align 8
  call void @__device_sload(i256* %26286, i256* %26287)
  %26288 = call i32 @__hashword(i256* %26286)
  %26289 = load i32, i32* %5, align 4
  %26290 = icmp eq i32 %26288, %26289
  %26291 = or i1 false, %26290
  %26292 = load i32, i32* %6, align 4
  %26293 = icmp eq i32 %26288, %26292
  %26294 = or i1 %26291, %26293
  %26295 = load i32, i32* %7, align 4
  %26296 = icmp eq i32 %26288, %26295
  %26297 = or i1 %26294, %26296
  %26298 = load i32, i32* %8, align 4
  %26299 = icmp eq i32 %26288, %26298
  %26300 = or i1 %26297, %26299
  %26301 = load i32, i32* %9, align 4
  %26302 = icmp eq i32 %26288, %26301
  %26303 = or i1 %26300, %26302
  %26304 = load i32, i32* %10, align 4
  %26305 = icmp eq i32 %26288, %26304
  %26306 = or i1 %26303, %26305
  %26307 = load i32, i32* %11, align 4
  %26308 = icmp eq i32 %26288, %26307
  %26309 = or i1 %26306, %26308
  %26310 = load i32, i32* %12, align 4
  %26311 = icmp eq i32 %26288, %26310
  %26312 = or i1 %26309, %26311
  %26313 = load i32, i32* %13, align 4
  %26314 = icmp eq i32 %26288, %26313
  %26315 = or i1 %26312, %26314
  %26316 = load i32, i32* %14, align 4
  %26317 = icmp eq i32 %26288, %26316
  %26318 = or i1 %26315, %26317
  %26319 = load i32, i32* %15, align 4
  %26320 = icmp eq i32 %26288, %26319
  %26321 = or i1 %26318, %26320
  %26322 = load i32, i32* %16, align 4
  %26323 = icmp eq i32 %26288, %26322
  %26324 = or i1 %26321, %26323
  %26325 = load i32, i32* %17, align 4
  %26326 = icmp eq i32 %26288, %26325
  %26327 = or i1 %26324, %26326
  %26328 = load i32, i32* %18, align 4
  %26329 = icmp eq i32 %26288, %26328
  %26330 = or i1 %26327, %26329
  %26331 = load i32, i32* %19, align 4
  %26332 = icmp eq i32 %26288, %26331
  %26333 = or i1 %26330, %26332
  %26334 = load i32, i32* %20, align 4
  %26335 = icmp eq i32 %26288, %26334
  %26336 = or i1 %26333, %26335
  %26337 = load i32, i32* %21, align 4
  %26338 = icmp eq i32 %26288, %26337
  %26339 = or i1 %26336, %26338
  %26340 = load i32, i32* %22, align 4
  %26341 = icmp eq i32 %26288, %26340
  %26342 = or i1 %26339, %26341
  %26343 = load i32, i32* %23, align 4
  %26344 = icmp eq i32 %26288, %26343
  %26345 = or i1 %26342, %26344
  %26346 = load i32, i32* %24, align 4
  %26347 = icmp eq i32 %26288, %26346
  %26348 = or i1 %26345, %26347
  %26349 = load i32, i32* %25, align 4
  %26350 = icmp eq i32 %26288, %26349
  %26351 = or i1 %26348, %26350
  %26352 = load i32, i32* %26, align 4
  %26353 = icmp eq i32 %26288, %26352
  %26354 = or i1 %26351, %26353
  %26355 = load i32, i32* %27, align 4
  %26356 = icmp eq i32 %26288, %26355
  %26357 = or i1 %26354, %26356
  %26358 = load i32, i32* %28, align 4
  %26359 = icmp eq i32 %26288, %26358
  %26360 = or i1 %26357, %26359
  %26361 = load i32, i32* %29, align 4
  %26362 = icmp eq i32 %26288, %26361
  %26363 = or i1 %26360, %26362
  %26364 = load i32, i32* %30, align 4
  %26365 = icmp eq i32 %26288, %26364
  %26366 = or i1 %26363, %26365
  %26367 = load i32, i32* %31, align 4
  %26368 = icmp eq i32 %26288, %26367
  %26369 = or i1 %26366, %26368
  %26370 = load i32, i32* %32, align 4
  %26371 = icmp eq i32 %26288, %26370
  %26372 = or i1 %26369, %26371
  %26373 = load i32, i32* %33, align 4
  %26374 = icmp eq i32 %26288, %26373
  %26375 = or i1 %26372, %26374
  %26376 = load i32, i32* %34, align 4
  %26377 = icmp eq i32 %26288, %26376
  %26378 = or i1 %26375, %26377
  %26379 = load i32, i32* %35, align 4
  %26380 = icmp eq i32 %26288, %26379
  %26381 = or i1 %26378, %26380
  %26382 = load i32, i32* %36, align 4
  %26383 = icmp eq i32 %26288, %26382
  %26384 = or i1 %26381, %26383
  %26385 = load i32, i32* %37, align 4
  %26386 = icmp eq i32 %26288, %26385
  %26387 = or i1 %26384, %26386
  %26388 = load i32, i32* %38, align 4
  %26389 = icmp eq i32 %26288, %26388
  %26390 = or i1 %26387, %26389
  %26391 = load i32, i32* %39, align 4
  %26392 = icmp eq i32 %26288, %26391
  %26393 = or i1 %26390, %26392
  %26394 = load i32, i32* %40, align 4
  %26395 = icmp eq i32 %26288, %26394
  %26396 = or i1 %26393, %26395
  %26397 = load i32, i32* %41, align 4
  %26398 = icmp eq i32 %26288, %26397
  %26399 = or i1 %26396, %26398
  %26400 = load i32, i32* %42, align 4
  %26401 = icmp eq i32 %26288, %26400
  %26402 = or i1 %26399, %26401
  %26403 = load i32, i32* %43, align 4
  %26404 = icmp eq i32 %26288, %26403
  %26405 = or i1 %26402, %26404
  %26406 = load i32, i32* %44, align 4
  %26407 = icmp eq i32 %26288, %26406
  %26408 = or i1 %26405, %26407
  %26409 = load i32, i32* %45, align 4
  %26410 = icmp eq i32 %26288, %26409
  %26411 = or i1 %26408, %26410
  %26412 = load i32, i32* %46, align 4
  %26413 = icmp eq i32 %26288, %26412
  %26414 = or i1 %26411, %26413
  %26415 = load i32, i32* %47, align 4
  %26416 = icmp eq i32 %26288, %26415
  %26417 = or i1 %26414, %26416
  %26418 = load i32, i32* %48, align 4
  %26419 = icmp eq i32 %26288, %26418
  %26420 = or i1 %26417, %26419
  %26421 = load i32, i32* %49, align 4
  %26422 = icmp eq i32 %26288, %26421
  %26423 = or i1 %26420, %26422
  %26424 = load i32, i32* %50, align 4
  %26425 = icmp eq i32 %26288, %26424
  %26426 = or i1 %26423, %26425
  %26427 = load i32, i32* %51, align 4
  %26428 = icmp eq i32 %26288, %26427
  %26429 = or i1 %26426, %26428
  %26430 = load i32, i32* %52, align 4
  %26431 = icmp eq i32 %26288, %26430
  %26432 = or i1 %26429, %26431
  %26433 = load i32, i32* %53, align 4
  %26434 = icmp eq i32 %26288, %26433
  %26435 = or i1 %26432, %26434
  %26436 = load i32, i32* %54, align 4
  %26437 = icmp eq i32 %26288, %26436
  %26438 = or i1 %26435, %26437
  %26439 = load i32, i32* %55, align 4
  %26440 = icmp eq i32 %26288, %26439
  %26441 = or i1 %26438, %26440
  %26442 = load i32, i32* %56, align 4
  %26443 = icmp eq i32 %26288, %26442
  %26444 = or i1 %26441, %26443
  %26445 = load i32, i32* %57, align 4
  %26446 = icmp eq i32 %26288, %26445
  %26447 = or i1 %26444, %26446
  %26448 = load i32, i32* %58, align 4
  %26449 = icmp eq i32 %26288, %26448
  %26450 = or i1 %26447, %26449
  %26451 = load i32, i32* %59, align 4
  %26452 = icmp eq i32 %26288, %26451
  %26453 = or i1 %26450, %26452
  %26454 = load i32, i32* %60, align 4
  %26455 = icmp eq i32 %26288, %26454
  %26456 = or i1 %26453, %26455
  %26457 = load i32, i32* %61, align 4
  %26458 = icmp eq i32 %26288, %26457
  %26459 = or i1 %26456, %26458
  %26460 = load i32, i32* %62, align 4
  %26461 = icmp eq i32 %26288, %26460
  %26462 = or i1 %26459, %26461
  %26463 = getelementptr i8, i8 addrspace(1)* %4, i32 92
  %26464 = zext i1 %26462 to i8
  store i8 %26464, i8 addrspace(1)* %26463, align 1, !nosanitize !3
  %26465 = load i256, i256* %26287, align 4
  %26466 = alloca i256, align 8
  store i256 %26465, i256* %26466, align 4
  %26467 = alloca i256, align 8
  store i256 1, i256* %26467, align 4
  %26468 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %26466, i256* %26467, i256* %26468), !pc !413, !intsan !6
  %26469 = load i256, i256* %26468, align 4
  %26470 = and i256 1461501637330902918203684832716283019655932542975, %26469
  %26471 = and i256 1461501637330902918203684832716283019655932542975, %26470
  %26472 = trunc i256 64 to i64
  %26473 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26472, i256* %26473)
  %26474 = load i256, i256* %26473, align 4
  %26475 = and i256 4294967295, 952911921
  %26476 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %26475, !pc !414, !intsan !45
  %26477 = trunc i256 %26474 to i64
  %26478 = alloca i256, align 8
  store i256 %26476, i256* %26478, align 4
  %26479 = bitcast i256* %26478 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26477, i8* %26479, i64 32)
  %26480 = add i256 4, %26474, !pc !415, !intsan !10
  %26481 = trunc i256 64 to i64
  %26482 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26481, i256* %26482)
  %26483 = load i256, i256* %26482, align 4
  %26484 = sub i256 %26480, %26483, !pc !416, !intsan !8
  %26485 = icmp eq i256 1, 0
  %26486 = icmp eq i1 %26485, false
  %26487 = trunc i256 9026 to i64
  %jump.check136 = icmp ne i1 %26486, false
  %26488 = load i64, i64* %STACK_DEP_PTR, align 4
  %26489 = add i64 %26488, 1
  store i64 %26489, i64* %STACK_DEP_PTR, align 4
  %26490 = load i64, i64* %STACK_DEP_PTR, align 4
  %26491 = getelementptr i256, i256* %STACK, i64 %26490
  store i256 0, i256* %26491, align 4
  %26492 = load i64, i64* %STACK_DEP_PTR, align 4
  %26493 = add i64 %26492, 1
  store i64 %26493, i64* %STACK_DEP_PTR, align 4
  %26494 = load i64, i64* %STACK_DEP_PTR, align 4
  %26495 = getelementptr i256, i256* %STACK, i64 %26494
  store i256 0, i256* %26495, align 4
  %26496 = load i64, i64* %STACK_DEP_PTR, align 4
  %26497 = add i64 %26496, 1
  store i64 %26497, i64* %STACK_DEP_PTR, align 4
  %26498 = load i64, i64* %STACK_DEP_PTR, align 4
  %26499 = getelementptr i256, i256* %STACK, i64 %26498
  store i256 %26471, i256* %26499, align 4
  %26500 = load i64, i64* %STACK_DEP_PTR, align 4
  %26501 = add i64 %26500, 1
  store i64 %26501, i64* %STACK_DEP_PTR, align 4
  %26502 = load i64, i64* %STACK_DEP_PTR, align 4
  %26503 = getelementptr i256, i256* %STACK, i64 %26502
  store i256 952911921, i256* %26503, align 4
  %26504 = load i64, i64* %STACK_DEP_PTR, align 4
  %26505 = add i64 %26504, 1
  store i64 %26505, i64* %STACK_DEP_PTR, align 4
  %26506 = load i64, i64* %STACK_DEP_PTR, align 4
  %26507 = getelementptr i256, i256* %STACK, i64 %26506
  store i256 %26480, i256* %26507, align 4
  %26508 = load i64, i64* %STACK_DEP_PTR, align 4
  %26509 = add i64 %26508, 1
  store i64 %26509, i64* %STACK_DEP_PTR, align 4
  %26510 = load i64, i64* %STACK_DEP_PTR, align 4
  %26511 = getelementptr i256, i256* %STACK, i64 %26510
  store i256 32, i256* %26511, align 4
  %26512 = load i64, i64* %STACK_DEP_PTR, align 4
  %26513 = add i64 %26512, 1
  store i64 %26513, i64* %STACK_DEP_PTR, align 4
  %26514 = load i64, i64* %STACK_DEP_PTR, align 4
  %26515 = getelementptr i256, i256* %STACK, i64 %26514
  store i256 %26483, i256* %26515, align 4
  %26516 = load i64, i64* %STACK_DEP_PTR, align 4
  %26517 = add i64 %26516, 1
  store i64 %26517, i64* %STACK_DEP_PTR, align 4
  %26518 = load i64, i64* %STACK_DEP_PTR, align 4
  %26519 = getelementptr i256, i256* %STACK, i64 %26518
  store i256 %26484, i256* %26519, align 4
  %26520 = load i64, i64* %STACK_DEP_PTR, align 4
  %26521 = add i64 %26520, 1
  store i64 %26521, i64* %STACK_DEP_PTR, align 4
  %26522 = load i64, i64* %STACK_DEP_PTR, align 4
  %26523 = getelementptr i256, i256* %STACK, i64 %26522
  store i256 %26483, i256* %26523, align 4
  %26524 = load i64, i64* %STACK_DEP_PTR, align 4
  %26525 = add i64 %26524, 1
  store i64 %26525, i64* %STACK_DEP_PTR, align 4
  %26526 = load i64, i64* %STACK_DEP_PTR, align 4
  %26527 = getelementptr i256, i256* %STACK, i64 %26526
  store i256 0, i256* %26527, align 4
  %26528 = load i64, i64* %STACK_DEP_PTR, align 4
  %26529 = add i64 %26528, 1
  store i64 %26529, i64* %STACK_DEP_PTR, align 4
  %26530 = load i64, i64* %STACK_DEP_PTR, align 4
  %26531 = getelementptr i256, i256* %STACK, i64 %26530
  store i256 %26471, i256* %26531, align 4
  %26532 = load i64, i64* %STACK_DEP_PTR, align 4
  %26533 = add i64 %26532, 1
  store i64 %26533, i64* %STACK_DEP_PTR, align 4
  %26534 = zext i1 %26485 to i256
  %26535 = load i64, i64* %STACK_DEP_PTR, align 4
  %26536 = getelementptr i256, i256* %STACK, i64 %26535
  store i256 %26534, i256* %26536, align 4
  br i1 %jump.check136, label %.9026, label %.9022, !EVMBB !4

.9022:                                            ; preds = %26279
  %26537 = load i64, i64* %remaing_gas, align 4
  %26538 = icmp ugt i64 40, %26537
  br i1 %26538, label %Abort, label %26539

26539:                                            ; preds = %.9022
  %26540 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26541 = xor i32 %26540, 1386
  %26542 = urem i32 %26541, 4096
  %26543 = getelementptr i8, i8 addrspace(1)* %4, i32 %26542
  %26544 = load i8, i8 addrspace(1)* %26543, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26543, align 1, !nosanitize !3
  store i32 693, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26545 = sub i64 %26537, 40
  store i64 %26545, i64* %remaing_gas, align 4
  %26546 = load i64, i64* %STACK_DEP_PTR, align 4
  %26547 = sub i64 %26546, 0
  store i64 %26547, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9026:                                            ; preds = %26279, %JumpTable
  %26548 = load i64, i64* %remaing_gas, align 4
  %26549 = icmp ugt i64 456, %26548
  br i1 %26549, label %Abort, label %26550

26550:                                            ; preds = %.9026
  %26551 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26552 = xor i32 %26551, 894
  %26553 = urem i32 %26552, 4096
  %26554 = getelementptr i8, i8 addrspace(1)* %4, i32 %26553
  %26555 = load i8, i8 addrspace(1)* %26554, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26554, align 1, !nosanitize !3
  store i32 447, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26556 = sub i64 %26548, 456
  store i64 %26556, i64* %remaing_gas, align 4
  %26557 = load i64, i64* %STACK_DEP_PTR, align 4
  %26558 = getelementptr i256, i256* %STACK, i64 %26557
  %26559 = load i256, i256* %26558, align 4
  %26560 = load i64, i64* %STACK_DEP_PTR, align 4
  %26561 = sub i64 %26560, 1
  store i64 %26561, i64* %STACK_DEP_PTR, align 4
  %26562 = load i64, i64* %STACK_DEP_PTR, align 4
  %26563 = getelementptr i256, i256* %STACK, i64 %26562
  %26564 = load i256, i256* %26563, align 4
  %26565 = load i64, i64* %STACK_DEP_PTR, align 4
  %26566 = sub i64 %26565, 1
  store i64 %26566, i64* %STACK_DEP_PTR, align 4
  %26567 = load i64, i64* %STACK_DEP_PTR, align 4
  %26568 = getelementptr i256, i256* %STACK, i64 %26567
  %26569 = load i256, i256* %26568, align 4
  %26570 = load i64, i64* %STACK_DEP_PTR, align 4
  %26571 = sub i64 %26570, 1
  store i64 %26571, i64* %STACK_DEP_PTR, align 4
  %26572 = load i64, i64* %STACK_DEP_PTR, align 4
  %26573 = getelementptr i256, i256* %STACK, i64 %26572
  %26574 = load i256, i256* %26573, align 4
  %26575 = load i64, i64* %STACK_DEP_PTR, align 4
  %26576 = sub i64 %26575, 1
  store i64 %26576, i64* %STACK_DEP_PTR, align 4
  %26577 = load i64, i64* %STACK_DEP_PTR, align 4
  %26578 = getelementptr i256, i256* %STACK, i64 %26577
  %26579 = load i256, i256* %26578, align 4
  %26580 = load i64, i64* %STACK_DEP_PTR, align 4
  %26581 = sub i64 %26580, 1
  store i64 %26581, i64* %STACK_DEP_PTR, align 4
  %26582 = load i64, i64* %STACK_DEP_PTR, align 4
  %26583 = getelementptr i256, i256* %STACK, i64 %26582
  %26584 = load i256, i256* %26583, align 4
  %26585 = load i64, i64* %STACK_DEP_PTR, align 4
  %26586 = sub i64 %26585, 1
  store i64 %26586, i64* %STACK_DEP_PTR, align 4
  %26587 = load i64, i64* %STACK_DEP_PTR, align 4
  %26588 = getelementptr i256, i256* %STACK, i64 %26587
  %26589 = load i256, i256* %26588, align 4
  %26590 = load i64, i64* %STACK_DEP_PTR, align 4
  %26591 = sub i64 %26590, 1
  store i64 %26591, i64* %STACK_DEP_PTR, align 4
  %26592 = trunc i256 %26564 to i160
  %26593 = call i1 @solidity_call(), !pc !417
  %26594 = icmp eq i1 %26593, false
  %26595 = icmp eq i1 %26594, false
  %26596 = trunc i256 9046 to i64
  %jump.check139 = icmp ne i1 %26595, false
  %26597 = load i64, i64* %STACK_DEP_PTR, align 4
  %26598 = add i64 %26597, 1
  store i64 %26598, i64* %STACK_DEP_PTR, align 4
  %26599 = zext i1 %26594 to i256
  %26600 = load i64, i64* %STACK_DEP_PTR, align 4
  %26601 = getelementptr i256, i256* %STACK, i64 %26600
  store i256 %26599, i256* %26601, align 4
  br i1 %jump.check139, label %.9046, label %.9037, !EVMBB !4

.9037:                                            ; preds = %26550
  %26602 = load i64, i64* %remaing_gas, align 4
  %26603 = icmp ugt i64 40, %26602
  br i1 %26603, label %Abort, label %26604

26604:                                            ; preds = %.9037
  %26605 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26606 = xor i32 %26605, 332
  %26607 = urem i32 %26606, 4096
  %26608 = getelementptr i8, i8 addrspace(1)* %4, i32 %26607
  %26609 = load i8, i8 addrspace(1)* %26608, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26608, align 1, !nosanitize !3
  store i32 166, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26610 = sub i64 %26602, 40
  store i64 %26610, i64* %remaing_gas, align 4
  %26611 = load i64, i64* %STACK_DEP_PTR, align 4
  %26612 = sub i64 %26611, 0
  store i64 %26612, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9046:                                            ; preds = %26550, %JumpTable
  %26613 = load i64, i64* %remaing_gas, align 4
  %26614 = icmp ugt i64 384, %26613
  br i1 %26614, label %Abort, label %26615

26615:                                            ; preds = %.9046
  %26616 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26617 = xor i32 %26616, 382
  %26618 = urem i32 %26617, 4096
  %26619 = getelementptr i8, i8 addrspace(1)* %4, i32 %26618
  %26620 = load i8, i8 addrspace(1)* %26619, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26619, align 1, !nosanitize !3
  store i32 191, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26621 = sub i64 %26613, 384
  store i64 %26621, i64* %remaing_gas, align 4
  %26622 = load i64, i64* %STACK_DEP_PTR, align 4
  %26623 = getelementptr i256, i256* %STACK, i64 %26622
  %26624 = load i256, i256* %26623, align 4
  %26625 = load i64, i64* %STACK_DEP_PTR, align 4
  %26626 = sub i64 %26625, 1
  store i64 %26626, i64* %STACK_DEP_PTR, align 4
  %26627 = load i64, i64* %STACK_DEP_PTR, align 4
  %26628 = getelementptr i256, i256* %STACK, i64 %26627
  %26629 = load i256, i256* %26628, align 4
  %26630 = load i64, i64* %STACK_DEP_PTR, align 4
  %26631 = sub i64 %26630, 1
  store i64 %26631, i64* %STACK_DEP_PTR, align 4
  %26632 = load i64, i64* %STACK_DEP_PTR, align 4
  %26633 = getelementptr i256, i256* %STACK, i64 %26632
  %26634 = load i256, i256* %26633, align 4
  %26635 = load i64, i64* %STACK_DEP_PTR, align 4
  %26636 = sub i64 %26635, 1
  store i64 %26636, i64* %STACK_DEP_PTR, align 4
  %26637 = load i64, i64* %STACK_DEP_PTR, align 4
  %26638 = getelementptr i256, i256* %STACK, i64 %26637
  %26639 = load i256, i256* %26638, align 4
  %26640 = load i64, i64* %STACK_DEP_PTR, align 4
  %26641 = sub i64 %26640, 1
  store i64 %26641, i64* %STACK_DEP_PTR, align 4
  %26642 = trunc i256 64 to i64
  %26643 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26642, i256* %26643)
  %26644 = load i256, i256* %26643, align 4
  %26645 = zext i64 0 to i256
  %26646 = icmp ult i256 %26645, 32
  %26647 = icmp eq i1 %26646, false
  %26648 = trunc i256 9068 to i64
  %jump.check144 = icmp ne i1 %26647, false
  %26649 = load i64, i64* %STACK_DEP_PTR, align 4
  %26650 = add i64 %26649, 1
  store i64 %26650, i64* %STACK_DEP_PTR, align 4
  %26651 = load i64, i64* %STACK_DEP_PTR, align 4
  %26652 = getelementptr i256, i256* %STACK, i64 %26651
  store i256 %26644, i256* %26652, align 4
  %26653 = load i64, i64* %STACK_DEP_PTR, align 4
  %26654 = add i64 %26653, 1
  store i64 %26654, i64* %STACK_DEP_PTR, align 4
  %26655 = zext i64 0 to i256
  %26656 = load i64, i64* %STACK_DEP_PTR, align 4
  %26657 = getelementptr i256, i256* %STACK, i64 %26656
  store i256 %26655, i256* %26657, align 4
  br i1 %jump.check144, label %.9068, label %.9064, !EVMBB !4

.9064:                                            ; preds = %26615
  %26658 = load i64, i64* %remaing_gas, align 4
  %26659 = icmp ugt i64 40, %26658
  br i1 %26659, label %Abort, label %26660

26660:                                            ; preds = %.9064
  %26661 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26662 = xor i32 %26661, 2897
  %26663 = urem i32 %26662, 4096
  %26664 = getelementptr i8, i8 addrspace(1)* %4, i32 %26663
  %26665 = load i8, i8 addrspace(1)* %26664, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26664, align 1, !nosanitize !3
  store i32 1448, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26666 = sub i64 %26658, 40
  store i64 %26666, i64* %remaing_gas, align 4
  %26667 = load i64, i64* %STACK_DEP_PTR, align 4
  %26668 = sub i64 %26667, 0
  store i64 %26668, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9068:                                            ; preds = %26615, %JumpTable
  %26669 = load i64, i64* %remaing_gas, align 4
  %26670 = icmp ugt i64 1072, %26669
  br i1 %26670, label %Abort, label %26671

26671:                                            ; preds = %.9068
  %26672 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26673 = xor i32 %26672, 3877
  %26674 = urem i32 %26673, 4096
  %26675 = getelementptr i8, i8 addrspace(1)* %4, i32 %26674
  %26676 = load i8, i8 addrspace(1)* %26675, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26675, align 1, !nosanitize !3
  store i32 1938, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26677 = sub i64 %26669, 1072
  store i64 %26677, i64* %remaing_gas, align 4
  %26678 = load i64, i64* %STACK_DEP_PTR, align 4
  %26679 = getelementptr i256, i256* %STACK, i64 %26678
  %26680 = load i256, i256* %26679, align 4
  %26681 = load i64, i64* %STACK_DEP_PTR, align 4
  %26682 = sub i64 %26681, 1
  store i64 %26682, i64* %STACK_DEP_PTR, align 4
  %26683 = load i64, i64* %STACK_DEP_PTR, align 4
  %26684 = getelementptr i256, i256* %STACK, i64 %26683
  %26685 = load i256, i256* %26684, align 4
  %26686 = load i64, i64* %STACK_DEP_PTR, align 4
  %26687 = sub i64 %26686, 1
  store i64 %26687, i64* %STACK_DEP_PTR, align 4
  %26688 = add i256 %26685, %26680, !pc !418, !intsan !10
  %26689 = trunc i256 %26685 to i64
  %26690 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26689, i256* %26690)
  %26691 = load i256, i256* %26690, align 4
  %26692 = add i256 32, %26685, !pc !419, !intsan !10
  %26693 = and i256 1461501637330902918203684832716283019655932542975, %26691
  %26694 = alloca i256, align 8
  store i256 2, i256* %26694, align 4
  %26695 = alloca i256, align 8
  call void @__device_sload(i256* %26694, i256* %26695)
  %26696 = call i32 @__hashword(i256* %26694)
  %26697 = load i32, i32* %5, align 4
  %26698 = icmp eq i32 %26696, %26697
  %26699 = or i1 false, %26698
  %26700 = load i32, i32* %6, align 4
  %26701 = icmp eq i32 %26696, %26700
  %26702 = or i1 %26699, %26701
  %26703 = load i32, i32* %7, align 4
  %26704 = icmp eq i32 %26696, %26703
  %26705 = or i1 %26702, %26704
  %26706 = load i32, i32* %8, align 4
  %26707 = icmp eq i32 %26696, %26706
  %26708 = or i1 %26705, %26707
  %26709 = load i32, i32* %9, align 4
  %26710 = icmp eq i32 %26696, %26709
  %26711 = or i1 %26708, %26710
  %26712 = load i32, i32* %10, align 4
  %26713 = icmp eq i32 %26696, %26712
  %26714 = or i1 %26711, %26713
  %26715 = load i32, i32* %11, align 4
  %26716 = icmp eq i32 %26696, %26715
  %26717 = or i1 %26714, %26716
  %26718 = load i32, i32* %12, align 4
  %26719 = icmp eq i32 %26696, %26718
  %26720 = or i1 %26717, %26719
  %26721 = load i32, i32* %13, align 4
  %26722 = icmp eq i32 %26696, %26721
  %26723 = or i1 %26720, %26722
  %26724 = load i32, i32* %14, align 4
  %26725 = icmp eq i32 %26696, %26724
  %26726 = or i1 %26723, %26725
  %26727 = load i32, i32* %15, align 4
  %26728 = icmp eq i32 %26696, %26727
  %26729 = or i1 %26726, %26728
  %26730 = load i32, i32* %16, align 4
  %26731 = icmp eq i32 %26696, %26730
  %26732 = or i1 %26729, %26731
  %26733 = load i32, i32* %17, align 4
  %26734 = icmp eq i32 %26696, %26733
  %26735 = or i1 %26732, %26734
  %26736 = load i32, i32* %18, align 4
  %26737 = icmp eq i32 %26696, %26736
  %26738 = or i1 %26735, %26737
  %26739 = load i32, i32* %19, align 4
  %26740 = icmp eq i32 %26696, %26739
  %26741 = or i1 %26738, %26740
  %26742 = load i32, i32* %20, align 4
  %26743 = icmp eq i32 %26696, %26742
  %26744 = or i1 %26741, %26743
  %26745 = load i32, i32* %21, align 4
  %26746 = icmp eq i32 %26696, %26745
  %26747 = or i1 %26744, %26746
  %26748 = load i32, i32* %22, align 4
  %26749 = icmp eq i32 %26696, %26748
  %26750 = or i1 %26747, %26749
  %26751 = load i32, i32* %23, align 4
  %26752 = icmp eq i32 %26696, %26751
  %26753 = or i1 %26750, %26752
  %26754 = load i32, i32* %24, align 4
  %26755 = icmp eq i32 %26696, %26754
  %26756 = or i1 %26753, %26755
  %26757 = load i32, i32* %25, align 4
  %26758 = icmp eq i32 %26696, %26757
  %26759 = or i1 %26756, %26758
  %26760 = load i32, i32* %26, align 4
  %26761 = icmp eq i32 %26696, %26760
  %26762 = or i1 %26759, %26761
  %26763 = load i32, i32* %27, align 4
  %26764 = icmp eq i32 %26696, %26763
  %26765 = or i1 %26762, %26764
  %26766 = load i32, i32* %28, align 4
  %26767 = icmp eq i32 %26696, %26766
  %26768 = or i1 %26765, %26767
  %26769 = load i32, i32* %29, align 4
  %26770 = icmp eq i32 %26696, %26769
  %26771 = or i1 %26768, %26770
  %26772 = load i32, i32* %30, align 4
  %26773 = icmp eq i32 %26696, %26772
  %26774 = or i1 %26771, %26773
  %26775 = load i32, i32* %31, align 4
  %26776 = icmp eq i32 %26696, %26775
  %26777 = or i1 %26774, %26776
  %26778 = load i32, i32* %32, align 4
  %26779 = icmp eq i32 %26696, %26778
  %26780 = or i1 %26777, %26779
  %26781 = load i32, i32* %33, align 4
  %26782 = icmp eq i32 %26696, %26781
  %26783 = or i1 %26780, %26782
  %26784 = load i32, i32* %34, align 4
  %26785 = icmp eq i32 %26696, %26784
  %26786 = or i1 %26783, %26785
  %26787 = load i32, i32* %35, align 4
  %26788 = icmp eq i32 %26696, %26787
  %26789 = or i1 %26786, %26788
  %26790 = load i32, i32* %36, align 4
  %26791 = icmp eq i32 %26696, %26790
  %26792 = or i1 %26789, %26791
  %26793 = load i32, i32* %37, align 4
  %26794 = icmp eq i32 %26696, %26793
  %26795 = or i1 %26792, %26794
  %26796 = load i32, i32* %38, align 4
  %26797 = icmp eq i32 %26696, %26796
  %26798 = or i1 %26795, %26797
  %26799 = load i32, i32* %39, align 4
  %26800 = icmp eq i32 %26696, %26799
  %26801 = or i1 %26798, %26800
  %26802 = load i32, i32* %40, align 4
  %26803 = icmp eq i32 %26696, %26802
  %26804 = or i1 %26801, %26803
  %26805 = load i32, i32* %41, align 4
  %26806 = icmp eq i32 %26696, %26805
  %26807 = or i1 %26804, %26806
  %26808 = load i32, i32* %42, align 4
  %26809 = icmp eq i32 %26696, %26808
  %26810 = or i1 %26807, %26809
  %26811 = load i32, i32* %43, align 4
  %26812 = icmp eq i32 %26696, %26811
  %26813 = or i1 %26810, %26812
  %26814 = load i32, i32* %44, align 4
  %26815 = icmp eq i32 %26696, %26814
  %26816 = or i1 %26813, %26815
  %26817 = load i32, i32* %45, align 4
  %26818 = icmp eq i32 %26696, %26817
  %26819 = or i1 %26816, %26818
  %26820 = load i32, i32* %46, align 4
  %26821 = icmp eq i32 %26696, %26820
  %26822 = or i1 %26819, %26821
  %26823 = load i32, i32* %47, align 4
  %26824 = icmp eq i32 %26696, %26823
  %26825 = or i1 %26822, %26824
  %26826 = load i32, i32* %48, align 4
  %26827 = icmp eq i32 %26696, %26826
  %26828 = or i1 %26825, %26827
  %26829 = load i32, i32* %49, align 4
  %26830 = icmp eq i32 %26696, %26829
  %26831 = or i1 %26828, %26830
  %26832 = load i32, i32* %50, align 4
  %26833 = icmp eq i32 %26696, %26832
  %26834 = or i1 %26831, %26833
  %26835 = load i32, i32* %51, align 4
  %26836 = icmp eq i32 %26696, %26835
  %26837 = or i1 %26834, %26836
  %26838 = load i32, i32* %52, align 4
  %26839 = icmp eq i32 %26696, %26838
  %26840 = or i1 %26837, %26839
  %26841 = load i32, i32* %53, align 4
  %26842 = icmp eq i32 %26696, %26841
  %26843 = or i1 %26840, %26842
  %26844 = load i32, i32* %54, align 4
  %26845 = icmp eq i32 %26696, %26844
  %26846 = or i1 %26843, %26845
  %26847 = load i32, i32* %55, align 4
  %26848 = icmp eq i32 %26696, %26847
  %26849 = or i1 %26846, %26848
  %26850 = load i32, i32* %56, align 4
  %26851 = icmp eq i32 %26696, %26850
  %26852 = or i1 %26849, %26851
  %26853 = load i32, i32* %57, align 4
  %26854 = icmp eq i32 %26696, %26853
  %26855 = or i1 %26852, %26854
  %26856 = load i32, i32* %58, align 4
  %26857 = icmp eq i32 %26696, %26856
  %26858 = or i1 %26855, %26857
  %26859 = load i32, i32* %59, align 4
  %26860 = icmp eq i32 %26696, %26859
  %26861 = or i1 %26858, %26860
  %26862 = load i32, i32* %60, align 4
  %26863 = icmp eq i32 %26696, %26862
  %26864 = or i1 %26861, %26863
  %26865 = load i32, i32* %61, align 4
  %26866 = icmp eq i32 %26696, %26865
  %26867 = or i1 %26864, %26866
  %26868 = load i32, i32* %62, align 4
  %26869 = icmp eq i32 %26696, %26868
  %26870 = or i1 %26867, %26869
  %26871 = getelementptr i8, i8 addrspace(1)* %4, i32 93
  %26872 = zext i1 %26870 to i8
  store i8 %26872, i8 addrspace(1)* %26871, align 1, !nosanitize !3
  %26873 = load i256, i256* %26695, align 4
  %26874 = add i256 175000, %26873, !pc !420, !intsan !10
  %26875 = trunc i256 64 to i64
  %26876 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26875, i256* %26876)
  %26877 = load i256, i256* %26876, align 4
  %26878 = and i256 4294967295, 787721420
  %26879 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %26878, !pc !421, !intsan !45
  %26880 = trunc i256 %26877 to i64
  %26881 = alloca i256, align 8
  store i256 %26879, i256* %26881, align 4
  %26882 = bitcast i256* %26881 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26880, i8* %26882, i64 32)
  %26883 = add i256 4, %26877, !pc !422, !intsan !10
  %26884 = add i256 32, %26883, !pc !423, !intsan !10
  %26885 = trunc i256 %26884 to i64
  %26886 = alloca i256, align 8
  store i256 %26874, i256* %26886, align 4
  %26887 = bitcast i256* %26886 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26885, i8* %26887, i64 32)
  %26888 = add i256 32, %26884, !pc !424, !intsan !10
  %26889 = sub i256 %26888, %26883, !pc !425, !intsan !8
  %26890 = trunc i256 %26883 to i64
  %26891 = alloca i256, align 8
  store i256 %26889, i256* %26891, align 4
  %26892 = bitcast i256* %26891 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26890, i8* %26892, i64 32)
  %26893 = trunc i256 %26888 to i64
  %26894 = alloca i256, align 8
  store i256 3, i256* %26894, align 4
  %26895 = bitcast i256* %26894 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26893, i8* %26895, i64 32)
  %26896 = add i256 32, %26888, !pc !426, !intsan !10
  %26897 = trunc i256 %26896 to i64
  %26898 = alloca i256, align 8
  store i256 38591998121611826609606229052672359276638289559839154232670315000474409893888, i256* %26898, align 4
  %26899 = bitcast i256* %26898 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %26897, i8* %26899, i64 32)
  %26900 = add i256 32, %26896, !pc !427, !intsan !10
  %26901 = trunc i256 64 to i64
  %26902 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %26901, i256* %26902)
  %26903 = load i256, i256* %26902, align 4
  %26904 = sub i256 %26900, %26903, !pc !428, !intsan !8
  %26905 = icmp eq i256 1, 0
  %26906 = icmp eq i1 %26905, false
  %26907 = trunc i256 9259 to i64
  %jump.check148 = icmp ne i1 %26906, false
  %26908 = load i64, i64* %STACK_DEP_PTR, align 4
  %26909 = add i64 %26908, 1
  store i64 %26909, i64* %STACK_DEP_PTR, align 4
  %26910 = load i64, i64* %STACK_DEP_PTR, align 4
  %26911 = getelementptr i256, i256* %STACK, i64 %26910
  store i256 %26693, i256* %26911, align 4
  %26912 = load i64, i64* %STACK_DEP_PTR, align 4
  %26913 = add i64 %26912, 1
  store i64 %26913, i64* %STACK_DEP_PTR, align 4
  %26914 = load i64, i64* %STACK_DEP_PTR, align 4
  %26915 = getelementptr i256, i256* %STACK, i64 %26914
  store i256 787721420, i256* %26915, align 4
  %26916 = load i64, i64* %STACK_DEP_PTR, align 4
  %26917 = add i64 %26916, 1
  store i64 %26917, i64* %STACK_DEP_PTR, align 4
  %26918 = load i64, i64* %STACK_DEP_PTR, align 4
  %26919 = getelementptr i256, i256* %STACK, i64 %26918
  store i256 %26900, i256* %26919, align 4
  %26920 = load i64, i64* %STACK_DEP_PTR, align 4
  %26921 = add i64 %26920, 1
  store i64 %26921, i64* %STACK_DEP_PTR, align 4
  %26922 = load i64, i64* %STACK_DEP_PTR, align 4
  %26923 = getelementptr i256, i256* %STACK, i64 %26922
  store i256 32, i256* %26923, align 4
  %26924 = load i64, i64* %STACK_DEP_PTR, align 4
  %26925 = add i64 %26924, 1
  store i64 %26925, i64* %STACK_DEP_PTR, align 4
  %26926 = load i64, i64* %STACK_DEP_PTR, align 4
  %26927 = getelementptr i256, i256* %STACK, i64 %26926
  store i256 %26903, i256* %26927, align 4
  %26928 = load i64, i64* %STACK_DEP_PTR, align 4
  %26929 = add i64 %26928, 1
  store i64 %26929, i64* %STACK_DEP_PTR, align 4
  %26930 = load i64, i64* %STACK_DEP_PTR, align 4
  %26931 = getelementptr i256, i256* %STACK, i64 %26930
  store i256 %26904, i256* %26931, align 4
  %26932 = load i64, i64* %STACK_DEP_PTR, align 4
  %26933 = add i64 %26932, 1
  store i64 %26933, i64* %STACK_DEP_PTR, align 4
  %26934 = load i64, i64* %STACK_DEP_PTR, align 4
  %26935 = getelementptr i256, i256* %STACK, i64 %26934
  store i256 %26903, i256* %26935, align 4
  %26936 = load i64, i64* %STACK_DEP_PTR, align 4
  %26937 = add i64 %26936, 1
  store i64 %26937, i64* %STACK_DEP_PTR, align 4
  %26938 = load i64, i64* %STACK_DEP_PTR, align 4
  %26939 = getelementptr i256, i256* %STACK, i64 %26938
  store i256 0, i256* %26939, align 4
  %26940 = load i64, i64* %STACK_DEP_PTR, align 4
  %26941 = add i64 %26940, 1
  store i64 %26941, i64* %STACK_DEP_PTR, align 4
  %26942 = load i64, i64* %STACK_DEP_PTR, align 4
  %26943 = getelementptr i256, i256* %STACK, i64 %26942
  store i256 %26693, i256* %26943, align 4
  %26944 = load i64, i64* %STACK_DEP_PTR, align 4
  %26945 = add i64 %26944, 1
  store i64 %26945, i64* %STACK_DEP_PTR, align 4
  %26946 = zext i1 %26905 to i256
  %26947 = load i64, i64* %STACK_DEP_PTR, align 4
  %26948 = getelementptr i256, i256* %STACK, i64 %26947
  store i256 %26946, i256* %26948, align 4
  br i1 %jump.check148, label %.9259, label %.9255, !EVMBB !4

.9255:                                            ; preds = %26671
  %26949 = load i64, i64* %remaing_gas, align 4
  %26950 = icmp ugt i64 40, %26949
  br i1 %26950, label %Abort, label %26951

26951:                                            ; preds = %.9255
  %26952 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26953 = xor i32 %26952, 2995
  %26954 = urem i32 %26953, 4096
  %26955 = getelementptr i8, i8 addrspace(1)* %4, i32 %26954
  %26956 = load i8, i8 addrspace(1)* %26955, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26955, align 1, !nosanitize !3
  store i32 1497, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26957 = sub i64 %26949, 40
  store i64 %26957, i64* %remaing_gas, align 4
  %26958 = load i64, i64* %STACK_DEP_PTR, align 4
  %26959 = sub i64 %26958, 0
  store i64 %26959, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9259:                                            ; preds = %26671, %JumpTable
  %26960 = load i64, i64* %remaing_gas, align 4
  %26961 = icmp ugt i64 456, %26960
  br i1 %26961, label %Abort, label %26962

26962:                                            ; preds = %.9259
  %26963 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26964 = xor i32 %26963, 2888
  %26965 = urem i32 %26964, 4096
  %26966 = getelementptr i8, i8 addrspace(1)* %4, i32 %26965
  %26967 = load i8, i8 addrspace(1)* %26966, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %26966, align 1, !nosanitize !3
  store i32 1444, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %26968 = sub i64 %26960, 456
  store i64 %26968, i64* %remaing_gas, align 4
  %26969 = load i64, i64* %STACK_DEP_PTR, align 4
  %26970 = getelementptr i256, i256* %STACK, i64 %26969
  %26971 = load i256, i256* %26970, align 4
  %26972 = load i64, i64* %STACK_DEP_PTR, align 4
  %26973 = sub i64 %26972, 1
  store i64 %26973, i64* %STACK_DEP_PTR, align 4
  %26974 = load i64, i64* %STACK_DEP_PTR, align 4
  %26975 = getelementptr i256, i256* %STACK, i64 %26974
  %26976 = load i256, i256* %26975, align 4
  %26977 = load i64, i64* %STACK_DEP_PTR, align 4
  %26978 = sub i64 %26977, 1
  store i64 %26978, i64* %STACK_DEP_PTR, align 4
  %26979 = load i64, i64* %STACK_DEP_PTR, align 4
  %26980 = getelementptr i256, i256* %STACK, i64 %26979
  %26981 = load i256, i256* %26980, align 4
  %26982 = load i64, i64* %STACK_DEP_PTR, align 4
  %26983 = sub i64 %26982, 1
  store i64 %26983, i64* %STACK_DEP_PTR, align 4
  %26984 = load i64, i64* %STACK_DEP_PTR, align 4
  %26985 = getelementptr i256, i256* %STACK, i64 %26984
  %26986 = load i256, i256* %26985, align 4
  %26987 = load i64, i64* %STACK_DEP_PTR, align 4
  %26988 = sub i64 %26987, 1
  store i64 %26988, i64* %STACK_DEP_PTR, align 4
  %26989 = load i64, i64* %STACK_DEP_PTR, align 4
  %26990 = getelementptr i256, i256* %STACK, i64 %26989
  %26991 = load i256, i256* %26990, align 4
  %26992 = load i64, i64* %STACK_DEP_PTR, align 4
  %26993 = sub i64 %26992, 1
  store i64 %26993, i64* %STACK_DEP_PTR, align 4
  %26994 = load i64, i64* %STACK_DEP_PTR, align 4
  %26995 = getelementptr i256, i256* %STACK, i64 %26994
  %26996 = load i256, i256* %26995, align 4
  %26997 = load i64, i64* %STACK_DEP_PTR, align 4
  %26998 = sub i64 %26997, 1
  store i64 %26998, i64* %STACK_DEP_PTR, align 4
  %26999 = load i64, i64* %STACK_DEP_PTR, align 4
  %27000 = getelementptr i256, i256* %STACK, i64 %26999
  %27001 = load i256, i256* %27000, align 4
  %27002 = load i64, i64* %STACK_DEP_PTR, align 4
  %27003 = sub i64 %27002, 1
  store i64 %27003, i64* %STACK_DEP_PTR, align 4
  %27004 = trunc i256 %26976 to i160
  %27005 = call i1 @solidity_call(), !pc !429
  %27006 = icmp eq i1 %27005, false
  %27007 = icmp eq i1 %27006, false
  %27008 = trunc i256 9279 to i64
  %jump.check153 = icmp ne i1 %27007, false
  %27009 = load i64, i64* %STACK_DEP_PTR, align 4
  %27010 = add i64 %27009, 1
  store i64 %27010, i64* %STACK_DEP_PTR, align 4
  %27011 = zext i1 %27006 to i256
  %27012 = load i64, i64* %STACK_DEP_PTR, align 4
  %27013 = getelementptr i256, i256* %STACK, i64 %27012
  store i256 %27011, i256* %27013, align 4
  br i1 %jump.check153, label %.9279, label %.9270, !EVMBB !4

.9270:                                            ; preds = %26962
  %27014 = load i64, i64* %remaing_gas, align 4
  %27015 = icmp ugt i64 40, %27014
  br i1 %27015, label %Abort, label %27016

27016:                                            ; preds = %.9270
  %27017 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27018 = xor i32 %27017, 900
  %27019 = urem i32 %27018, 4096
  %27020 = getelementptr i8, i8 addrspace(1)* %4, i32 %27019
  %27021 = load i8, i8 addrspace(1)* %27020, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27020, align 1, !nosanitize !3
  store i32 450, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27022 = sub i64 %27014, 40
  store i64 %27022, i64* %remaing_gas, align 4
  %27023 = load i64, i64* %STACK_DEP_PTR, align 4
  %27024 = sub i64 %27023, 0
  store i64 %27024, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9279:                                            ; preds = %26962, %JumpTable
  %27025 = load i64, i64* %remaing_gas, align 4
  %27026 = icmp ugt i64 384, %27025
  br i1 %27026, label %Abort, label %27027

27027:                                            ; preds = %.9279
  %27028 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27029 = xor i32 %27028, 2899
  %27030 = urem i32 %27029, 4096
  %27031 = getelementptr i8, i8 addrspace(1)* %4, i32 %27030
  %27032 = load i8, i8 addrspace(1)* %27031, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27031, align 1, !nosanitize !3
  store i32 1449, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27033 = sub i64 %27025, 384
  store i64 %27033, i64* %remaing_gas, align 4
  %27034 = load i64, i64* %STACK_DEP_PTR, align 4
  %27035 = getelementptr i256, i256* %STACK, i64 %27034
  %27036 = load i256, i256* %27035, align 4
  %27037 = load i64, i64* %STACK_DEP_PTR, align 4
  %27038 = sub i64 %27037, 1
  store i64 %27038, i64* %STACK_DEP_PTR, align 4
  %27039 = load i64, i64* %STACK_DEP_PTR, align 4
  %27040 = getelementptr i256, i256* %STACK, i64 %27039
  %27041 = load i256, i256* %27040, align 4
  %27042 = load i64, i64* %STACK_DEP_PTR, align 4
  %27043 = sub i64 %27042, 1
  store i64 %27043, i64* %STACK_DEP_PTR, align 4
  %27044 = load i64, i64* %STACK_DEP_PTR, align 4
  %27045 = getelementptr i256, i256* %STACK, i64 %27044
  %27046 = load i256, i256* %27045, align 4
  %27047 = load i64, i64* %STACK_DEP_PTR, align 4
  %27048 = sub i64 %27047, 1
  store i64 %27048, i64* %STACK_DEP_PTR, align 4
  %27049 = load i64, i64* %STACK_DEP_PTR, align 4
  %27050 = getelementptr i256, i256* %STACK, i64 %27049
  %27051 = load i256, i256* %27050, align 4
  %27052 = load i64, i64* %STACK_DEP_PTR, align 4
  %27053 = sub i64 %27052, 1
  store i64 %27053, i64* %STACK_DEP_PTR, align 4
  %27054 = trunc i256 64 to i64
  %27055 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %27054, i256* %27055)
  %27056 = load i256, i256* %27055, align 4
  %27057 = zext i64 0 to i256
  %27058 = icmp ult i256 %27057, 32
  %27059 = icmp eq i1 %27058, false
  %27060 = trunc i256 9301 to i64
  %jump.check156 = icmp ne i1 %27059, false
  %27061 = load i64, i64* %STACK_DEP_PTR, align 4
  %27062 = add i64 %27061, 1
  store i64 %27062, i64* %STACK_DEP_PTR, align 4
  %27063 = load i64, i64* %STACK_DEP_PTR, align 4
  %27064 = getelementptr i256, i256* %STACK, i64 %27063
  store i256 %27056, i256* %27064, align 4
  %27065 = load i64, i64* %STACK_DEP_PTR, align 4
  %27066 = add i64 %27065, 1
  store i64 %27066, i64* %STACK_DEP_PTR, align 4
  %27067 = zext i64 0 to i256
  %27068 = load i64, i64* %STACK_DEP_PTR, align 4
  %27069 = getelementptr i256, i256* %STACK, i64 %27068
  store i256 %27067, i256* %27069, align 4
  br i1 %jump.check156, label %.9301, label %.9297, !EVMBB !4

.9297:                                            ; preds = %27027
  %27070 = load i64, i64* %remaing_gas, align 4
  %27071 = icmp ugt i64 40, %27070
  br i1 %27071, label %Abort, label %27072

27072:                                            ; preds = %.9297
  %27073 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27074 = xor i32 %27073, 314
  %27075 = urem i32 %27074, 4096
  %27076 = getelementptr i8, i8 addrspace(1)* %4, i32 %27075
  %27077 = load i8, i8 addrspace(1)* %27076, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27076, align 1, !nosanitize !3
  store i32 157, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27078 = sub i64 %27070, 40
  store i64 %27078, i64* %remaing_gas, align 4
  %27079 = load i64, i64* %STACK_DEP_PTR, align 4
  %27080 = sub i64 %27079, 0
  store i64 %27080, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9301:                                            ; preds = %27027, %JumpTable
  %27081 = load i64, i64* %remaing_gas, align 4
  %27082 = icmp ugt i64 376, %27081
  br i1 %27082, label %Abort, label %27083

27083:                                            ; preds = %.9301
  %27084 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27085 = xor i32 %27084, 1172
  %27086 = urem i32 %27085, 4096
  %27087 = getelementptr i8, i8 addrspace(1)* %4, i32 %27086
  %27088 = load i8, i8 addrspace(1)* %27087, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27087, align 1, !nosanitize !3
  store i32 586, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27089 = sub i64 %27081, 376
  store i64 %27089, i64* %remaing_gas, align 4
  %27090 = load i64, i64* %STACK_DEP_PTR, align 4
  %27091 = getelementptr i256, i256* %STACK, i64 %27090
  %27092 = load i256, i256* %27091, align 4
  %27093 = load i64, i64* %STACK_DEP_PTR, align 4
  %27094 = sub i64 %27093, 1
  store i64 %27094, i64* %STACK_DEP_PTR, align 4
  %27095 = load i64, i64* %STACK_DEP_PTR, align 4
  %27096 = getelementptr i256, i256* %STACK, i64 %27095
  %27097 = load i256, i256* %27096, align 4
  %27098 = load i64, i64* %STACK_DEP_PTR, align 4
  %27099 = sub i64 %27098, 1
  store i64 %27099, i64* %STACK_DEP_PTR, align 4
  %27100 = load i64, i64* %STACK_DEP_PTR, align 4
  %27101 = getelementptr i256, i256* %STACK, i64 %27100
  %27102 = load i256, i256* %27101, align 4
  %27103 = load i64, i64* %STACK_DEP_PTR, align 4
  %27104 = sub i64 %27103, 1
  store i64 %27104, i64* %STACK_DEP_PTR, align 4
  %27105 = load i64, i64* %STACK_DEP_PTR, align 4
  %27106 = getelementptr i256, i256* %STACK, i64 %27105
  %27107 = load i256, i256* %27106, align 4
  %27108 = load i64, i64* %STACK_DEP_PTR, align 4
  %27109 = sub i64 %27108, 1
  store i64 %27109, i64* %STACK_DEP_PTR, align 4
  %27110 = load i64, i64* %STACK_DEP_PTR, align 4
  %27111 = getelementptr i256, i256* %STACK, i64 %27110
  %27112 = load i256, i256* %27111, align 4
  %27113 = load i64, i64* %STACK_DEP_PTR, align 4
  %27114 = sub i64 %27113, 1
  store i64 %27114, i64* %STACK_DEP_PTR, align 4
  %27115 = add i256 %27097, %27092, !pc !430, !intsan !10
  %27116 = trunc i256 %27097 to i64
  %27117 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %27116, i256* %27117)
  %27118 = load i256, i256* %27117, align 4
  %27119 = add i256 32, %27097, !pc !431, !intsan !10
  %27120 = add i256 %27118, 200000000000000000, !pc !432, !intsan !10
  %27121 = trunc i256 %27112 to i64
  store i64 %27121, i64* %JMP_TARGET_PTR, align 4
  %27122 = load i64, i64* %STACK_DEP_PTR, align 4
  %27123 = add i64 %27122, 1
  store i64 %27123, i64* %STACK_DEP_PTR, align 4
  %27124 = load i64, i64* %STACK_DEP_PTR, align 4
  %27125 = getelementptr i256, i256* %STACK, i64 %27124
  store i256 %27120, i256* %27125, align 4
  br label %JumpTable, !EVMBB !4

.9337:                                            ; preds = %3025, %JumpTable
  %27126 = load i64, i64* %remaing_gas, align 4
  %27127 = icmp ugt i64 184, %27126
  br i1 %27127, label %Abort, label %27128

27128:                                            ; preds = %.9337
  %27129 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27130 = xor i32 %27129, 763
  %27131 = urem i32 %27130, 4096
  %27132 = getelementptr i8, i8 addrspace(1)* %4, i32 %27131
  %27133 = load i8, i8 addrspace(1)* %27132, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27132, align 1, !nosanitize !3
  store i32 381, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27134 = sub i64 %27126, 184
  store i64 %27134, i64* %remaing_gas, align 4
  %27135 = load i256, i256* %0, align 4
  %27136 = and i256 1461501637330902918203684832716283019655932542975, %27135
  %27137 = alloca i256, align 8
  store i256 7, i256* %27137, align 4
  %27138 = alloca i256, align 8
  call void @__device_sload(i256* %27137, i256* %27138)
  %27139 = call i32 @__hashword(i256* %27137)
  %27140 = load i32, i32* %5, align 4
  %27141 = icmp eq i32 %27139, %27140
  %27142 = or i1 false, %27141
  %27143 = load i32, i32* %6, align 4
  %27144 = icmp eq i32 %27139, %27143
  %27145 = or i1 %27142, %27144
  %27146 = load i32, i32* %7, align 4
  %27147 = icmp eq i32 %27139, %27146
  %27148 = or i1 %27145, %27147
  %27149 = load i32, i32* %8, align 4
  %27150 = icmp eq i32 %27139, %27149
  %27151 = or i1 %27148, %27150
  %27152 = load i32, i32* %9, align 4
  %27153 = icmp eq i32 %27139, %27152
  %27154 = or i1 %27151, %27153
  %27155 = load i32, i32* %10, align 4
  %27156 = icmp eq i32 %27139, %27155
  %27157 = or i1 %27154, %27156
  %27158 = load i32, i32* %11, align 4
  %27159 = icmp eq i32 %27139, %27158
  %27160 = or i1 %27157, %27159
  %27161 = load i32, i32* %12, align 4
  %27162 = icmp eq i32 %27139, %27161
  %27163 = or i1 %27160, %27162
  %27164 = load i32, i32* %13, align 4
  %27165 = icmp eq i32 %27139, %27164
  %27166 = or i1 %27163, %27165
  %27167 = load i32, i32* %14, align 4
  %27168 = icmp eq i32 %27139, %27167
  %27169 = or i1 %27166, %27168
  %27170 = load i32, i32* %15, align 4
  %27171 = icmp eq i32 %27139, %27170
  %27172 = or i1 %27169, %27171
  %27173 = load i32, i32* %16, align 4
  %27174 = icmp eq i32 %27139, %27173
  %27175 = or i1 %27172, %27174
  %27176 = load i32, i32* %17, align 4
  %27177 = icmp eq i32 %27139, %27176
  %27178 = or i1 %27175, %27177
  %27179 = load i32, i32* %18, align 4
  %27180 = icmp eq i32 %27139, %27179
  %27181 = or i1 %27178, %27180
  %27182 = load i32, i32* %19, align 4
  %27183 = icmp eq i32 %27139, %27182
  %27184 = or i1 %27181, %27183
  %27185 = load i32, i32* %20, align 4
  %27186 = icmp eq i32 %27139, %27185
  %27187 = or i1 %27184, %27186
  %27188 = load i32, i32* %21, align 4
  %27189 = icmp eq i32 %27139, %27188
  %27190 = or i1 %27187, %27189
  %27191 = load i32, i32* %22, align 4
  %27192 = icmp eq i32 %27139, %27191
  %27193 = or i1 %27190, %27192
  %27194 = load i32, i32* %23, align 4
  %27195 = icmp eq i32 %27139, %27194
  %27196 = or i1 %27193, %27195
  %27197 = load i32, i32* %24, align 4
  %27198 = icmp eq i32 %27139, %27197
  %27199 = or i1 %27196, %27198
  %27200 = load i32, i32* %25, align 4
  %27201 = icmp eq i32 %27139, %27200
  %27202 = or i1 %27199, %27201
  %27203 = load i32, i32* %26, align 4
  %27204 = icmp eq i32 %27139, %27203
  %27205 = or i1 %27202, %27204
  %27206 = load i32, i32* %27, align 4
  %27207 = icmp eq i32 %27139, %27206
  %27208 = or i1 %27205, %27207
  %27209 = load i32, i32* %28, align 4
  %27210 = icmp eq i32 %27139, %27209
  %27211 = or i1 %27208, %27210
  %27212 = load i32, i32* %29, align 4
  %27213 = icmp eq i32 %27139, %27212
  %27214 = or i1 %27211, %27213
  %27215 = load i32, i32* %30, align 4
  %27216 = icmp eq i32 %27139, %27215
  %27217 = or i1 %27214, %27216
  %27218 = load i32, i32* %31, align 4
  %27219 = icmp eq i32 %27139, %27218
  %27220 = or i1 %27217, %27219
  %27221 = load i32, i32* %32, align 4
  %27222 = icmp eq i32 %27139, %27221
  %27223 = or i1 %27220, %27222
  %27224 = load i32, i32* %33, align 4
  %27225 = icmp eq i32 %27139, %27224
  %27226 = or i1 %27223, %27225
  %27227 = load i32, i32* %34, align 4
  %27228 = icmp eq i32 %27139, %27227
  %27229 = or i1 %27226, %27228
  %27230 = load i32, i32* %35, align 4
  %27231 = icmp eq i32 %27139, %27230
  %27232 = or i1 %27229, %27231
  %27233 = load i32, i32* %36, align 4
  %27234 = icmp eq i32 %27139, %27233
  %27235 = or i1 %27232, %27234
  %27236 = load i32, i32* %37, align 4
  %27237 = icmp eq i32 %27139, %27236
  %27238 = or i1 %27235, %27237
  %27239 = load i32, i32* %38, align 4
  %27240 = icmp eq i32 %27139, %27239
  %27241 = or i1 %27238, %27240
  %27242 = load i32, i32* %39, align 4
  %27243 = icmp eq i32 %27139, %27242
  %27244 = or i1 %27241, %27243
  %27245 = load i32, i32* %40, align 4
  %27246 = icmp eq i32 %27139, %27245
  %27247 = or i1 %27244, %27246
  %27248 = load i32, i32* %41, align 4
  %27249 = icmp eq i32 %27139, %27248
  %27250 = or i1 %27247, %27249
  %27251 = load i32, i32* %42, align 4
  %27252 = icmp eq i32 %27139, %27251
  %27253 = or i1 %27250, %27252
  %27254 = load i32, i32* %43, align 4
  %27255 = icmp eq i32 %27139, %27254
  %27256 = or i1 %27253, %27255
  %27257 = load i32, i32* %44, align 4
  %27258 = icmp eq i32 %27139, %27257
  %27259 = or i1 %27256, %27258
  %27260 = load i32, i32* %45, align 4
  %27261 = icmp eq i32 %27139, %27260
  %27262 = or i1 %27259, %27261
  %27263 = load i32, i32* %46, align 4
  %27264 = icmp eq i32 %27139, %27263
  %27265 = or i1 %27262, %27264
  %27266 = load i32, i32* %47, align 4
  %27267 = icmp eq i32 %27139, %27266
  %27268 = or i1 %27265, %27267
  %27269 = load i32, i32* %48, align 4
  %27270 = icmp eq i32 %27139, %27269
  %27271 = or i1 %27268, %27270
  %27272 = load i32, i32* %49, align 4
  %27273 = icmp eq i32 %27139, %27272
  %27274 = or i1 %27271, %27273
  %27275 = load i32, i32* %50, align 4
  %27276 = icmp eq i32 %27139, %27275
  %27277 = or i1 %27274, %27276
  %27278 = load i32, i32* %51, align 4
  %27279 = icmp eq i32 %27139, %27278
  %27280 = or i1 %27277, %27279
  %27281 = load i32, i32* %52, align 4
  %27282 = icmp eq i32 %27139, %27281
  %27283 = or i1 %27280, %27282
  %27284 = load i32, i32* %53, align 4
  %27285 = icmp eq i32 %27139, %27284
  %27286 = or i1 %27283, %27285
  %27287 = load i32, i32* %54, align 4
  %27288 = icmp eq i32 %27139, %27287
  %27289 = or i1 %27286, %27288
  %27290 = load i32, i32* %55, align 4
  %27291 = icmp eq i32 %27139, %27290
  %27292 = or i1 %27289, %27291
  %27293 = load i32, i32* %56, align 4
  %27294 = icmp eq i32 %27139, %27293
  %27295 = or i1 %27292, %27294
  %27296 = load i32, i32* %57, align 4
  %27297 = icmp eq i32 %27139, %27296
  %27298 = or i1 %27295, %27297
  %27299 = load i32, i32* %58, align 4
  %27300 = icmp eq i32 %27139, %27299
  %27301 = or i1 %27298, %27300
  %27302 = load i32, i32* %59, align 4
  %27303 = icmp eq i32 %27139, %27302
  %27304 = or i1 %27301, %27303
  %27305 = load i32, i32* %60, align 4
  %27306 = icmp eq i32 %27139, %27305
  %27307 = or i1 %27304, %27306
  %27308 = load i32, i32* %61, align 4
  %27309 = icmp eq i32 %27139, %27308
  %27310 = or i1 %27307, %27309
  %27311 = load i32, i32* %62, align 4
  %27312 = icmp eq i32 %27139, %27311
  %27313 = or i1 %27310, %27312
  %27314 = getelementptr i8, i8 addrspace(1)* %4, i32 94
  %27315 = zext i1 %27313 to i8
  store i8 %27315, i8 addrspace(1)* %27314, align 1, !nosanitize !3
  %27316 = load i256, i256* %27138, align 4
  %27317 = alloca i256, align 8
  store i256 %27316, i256* %27317, align 4
  %27318 = alloca i256, align 8
  store i256 1, i256* %27318, align 4
  %27319 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %27317, i256* %27318, i256* %27319), !pc !433, !intsan !6
  %27320 = load i256, i256* %27319, align 4
  %27321 = and i256 1461501637330902918203684832716283019655932542975, %27320
  %27322 = and i256 1461501637330902918203684832716283019655932542975, %27321
  %27323 = icmp eq i256 %27322, %27136
  %27324 = icmp eq i1 %27323, false
  %27325 = icmp eq i1 %27324, false
  %27326 = trunc i256 9429 to i64
  %jump.check138 = icmp ne i1 %27325, false
  br i1 %jump.check138, label %.9429, label %.9425, !EVMBB !4

.9425:                                            ; preds = %27128
  %27327 = load i64, i64* %remaing_gas, align 4
  %27328 = icmp ugt i64 16, %27327
  br i1 %27328, label %Abort, label %27329

27329:                                            ; preds = %.9425
  %27330 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27331 = xor i32 %27330, 2609
  %27332 = urem i32 %27331, 4096
  %27333 = getelementptr i8, i8 addrspace(1)* %4, i32 %27332
  %27334 = load i8, i8 addrspace(1)* %27333, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27333, align 1, !nosanitize !3
  store i32 1304, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27335 = sub i64 %27327, 16
  store i64 %27335, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.9429:                                            ; preds = %27128, %JumpTable
  %27336 = load i64, i64* %remaing_gas, align 4
  %27337 = icmp ugt i64 160, %27336
  br i1 %27337, label %Abort, label %27338

27338:                                            ; preds = %.9429
  %27339 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27340 = xor i32 %27339, 1433
  %27341 = urem i32 %27340, 4096
  %27342 = getelementptr i8, i8 addrspace(1)* %4, i32 %27341
  %27343 = load i8, i8 addrspace(1)* %27342, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27342, align 1, !nosanitize !3
  store i32 716, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27344 = sub i64 %27336, 160
  store i64 %27344, i64* %remaing_gas, align 4
  %27345 = load i64, i64* %STACK_DEP_PTR, align 4
  %27346 = getelementptr i256, i256* %STACK, i64 %27345
  %27347 = load i256, i256* %27346, align 4
  %27348 = load i64, i64* %STACK_DEP_PTR, align 4
  %27349 = sub i64 %27348, 1
  store i64 %27349, i64* %STACK_DEP_PTR, align 4
  %27350 = and i256 1461501637330902918203684832716283019655932542975, 0
  %27351 = and i256 1461501637330902918203684832716283019655932542975, %27347
  %27352 = icmp eq i256 %27351, %27350
  %27353 = icmp eq i1 %27352, false
  %27354 = trunc i256 9487 to i64
  %jump.check143 = icmp ne i1 %27353, false
  %27355 = load i64, i64* %STACK_DEP_PTR, align 4
  %27356 = add i64 %27355, 1
  store i64 %27356, i64* %STACK_DEP_PTR, align 4
  %27357 = load i64, i64* %STACK_DEP_PTR, align 4
  %27358 = getelementptr i256, i256* %STACK, i64 %27357
  store i256 %27347, i256* %27358, align 4
  br i1 %jump.check143, label %.9487, label %.9483, !EVMBB !4

.9483:                                            ; preds = %27338
  %27359 = load i64, i64* %remaing_gas, align 4
  %27360 = icmp ugt i64 40, %27359
  br i1 %27360, label %Abort, label %27361

27361:                                            ; preds = %.9483
  %27362 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27363 = xor i32 %27362, 1680
  %27364 = urem i32 %27363, 4096
  %27365 = getelementptr i8, i8 addrspace(1)* %4, i32 %27364
  %27366 = load i8, i8 addrspace(1)* %27365, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27365, align 1, !nosanitize !3
  store i32 840, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27367 = sub i64 %27359, 40
  store i64 %27367, i64* %remaing_gas, align 4
  %27368 = load i64, i64* %STACK_DEP_PTR, align 4
  %27369 = sub i64 %27368, 0
  store i64 %27369, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.9487:                                            ; preds = %27338, %JumpTable
  %27370 = load i64, i64* %remaing_gas, align 4
  %27371 = icmp ugt i64 576, %27370
  br i1 %27371, label %Abort, label %27372

27372:                                            ; preds = %.9487
  %27373 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27374 = xor i32 %27373, 3634
  %27375 = urem i32 %27374, 4096
  %27376 = getelementptr i8, i8 addrspace(1)* %4, i32 %27375
  %27377 = load i8, i8 addrspace(1)* %27376, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27376, align 1, !nosanitize !3
  store i32 1817, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27378 = sub i64 %27370, 576
  store i64 %27378, i64* %remaing_gas, align 4
  %27379 = load i64, i64* %STACK_DEP_PTR, align 4
  %27380 = getelementptr i256, i256* %STACK, i64 %27379
  %27381 = load i256, i256* %27380, align 4
  %27382 = load i64, i64* %STACK_DEP_PTR, align 4
  %27383 = sub i64 %27382, 1
  store i64 %27383, i64* %STACK_DEP_PTR, align 4
  %27384 = load i64, i64* %STACK_DEP_PTR, align 4
  %27385 = getelementptr i256, i256* %STACK, i64 %27384
  %27386 = load i256, i256* %27385, align 4
  %27387 = load i64, i64* %STACK_DEP_PTR, align 4
  %27388 = sub i64 %27387, 1
  store i64 %27388, i64* %STACK_DEP_PTR, align 4
  %27389 = alloca i256, align 8
  store i256 7, i256* %27389, align 4
  %27390 = alloca i256, align 8
  call void @__device_sload(i256* %27389, i256* %27390)
  %27391 = call i32 @__hashword(i256* %27389)
  %27392 = load i32, i32* %5, align 4
  %27393 = icmp eq i32 %27391, %27392
  %27394 = or i1 false, %27393
  %27395 = load i32, i32* %6, align 4
  %27396 = icmp eq i32 %27391, %27395
  %27397 = or i1 %27394, %27396
  %27398 = load i32, i32* %7, align 4
  %27399 = icmp eq i32 %27391, %27398
  %27400 = or i1 %27397, %27399
  %27401 = load i32, i32* %8, align 4
  %27402 = icmp eq i32 %27391, %27401
  %27403 = or i1 %27400, %27402
  %27404 = load i32, i32* %9, align 4
  %27405 = icmp eq i32 %27391, %27404
  %27406 = or i1 %27403, %27405
  %27407 = load i32, i32* %10, align 4
  %27408 = icmp eq i32 %27391, %27407
  %27409 = or i1 %27406, %27408
  %27410 = load i32, i32* %11, align 4
  %27411 = icmp eq i32 %27391, %27410
  %27412 = or i1 %27409, %27411
  %27413 = load i32, i32* %12, align 4
  %27414 = icmp eq i32 %27391, %27413
  %27415 = or i1 %27412, %27414
  %27416 = load i32, i32* %13, align 4
  %27417 = icmp eq i32 %27391, %27416
  %27418 = or i1 %27415, %27417
  %27419 = load i32, i32* %14, align 4
  %27420 = icmp eq i32 %27391, %27419
  %27421 = or i1 %27418, %27420
  %27422 = load i32, i32* %15, align 4
  %27423 = icmp eq i32 %27391, %27422
  %27424 = or i1 %27421, %27423
  %27425 = load i32, i32* %16, align 4
  %27426 = icmp eq i32 %27391, %27425
  %27427 = or i1 %27424, %27426
  %27428 = load i32, i32* %17, align 4
  %27429 = icmp eq i32 %27391, %27428
  %27430 = or i1 %27427, %27429
  %27431 = load i32, i32* %18, align 4
  %27432 = icmp eq i32 %27391, %27431
  %27433 = or i1 %27430, %27432
  %27434 = load i32, i32* %19, align 4
  %27435 = icmp eq i32 %27391, %27434
  %27436 = or i1 %27433, %27435
  %27437 = load i32, i32* %20, align 4
  %27438 = icmp eq i32 %27391, %27437
  %27439 = or i1 %27436, %27438
  %27440 = load i32, i32* %21, align 4
  %27441 = icmp eq i32 %27391, %27440
  %27442 = or i1 %27439, %27441
  %27443 = load i32, i32* %22, align 4
  %27444 = icmp eq i32 %27391, %27443
  %27445 = or i1 %27442, %27444
  %27446 = load i32, i32* %23, align 4
  %27447 = icmp eq i32 %27391, %27446
  %27448 = or i1 %27445, %27447
  %27449 = load i32, i32* %24, align 4
  %27450 = icmp eq i32 %27391, %27449
  %27451 = or i1 %27448, %27450
  %27452 = load i32, i32* %25, align 4
  %27453 = icmp eq i32 %27391, %27452
  %27454 = or i1 %27451, %27453
  %27455 = load i32, i32* %26, align 4
  %27456 = icmp eq i32 %27391, %27455
  %27457 = or i1 %27454, %27456
  %27458 = load i32, i32* %27, align 4
  %27459 = icmp eq i32 %27391, %27458
  %27460 = or i1 %27457, %27459
  %27461 = load i32, i32* %28, align 4
  %27462 = icmp eq i32 %27391, %27461
  %27463 = or i1 %27460, %27462
  %27464 = load i32, i32* %29, align 4
  %27465 = icmp eq i32 %27391, %27464
  %27466 = or i1 %27463, %27465
  %27467 = load i32, i32* %30, align 4
  %27468 = icmp eq i32 %27391, %27467
  %27469 = or i1 %27466, %27468
  %27470 = load i32, i32* %31, align 4
  %27471 = icmp eq i32 %27391, %27470
  %27472 = or i1 %27469, %27471
  %27473 = load i32, i32* %32, align 4
  %27474 = icmp eq i32 %27391, %27473
  %27475 = or i1 %27472, %27474
  %27476 = load i32, i32* %33, align 4
  %27477 = icmp eq i32 %27391, %27476
  %27478 = or i1 %27475, %27477
  %27479 = load i32, i32* %34, align 4
  %27480 = icmp eq i32 %27391, %27479
  %27481 = or i1 %27478, %27480
  %27482 = load i32, i32* %35, align 4
  %27483 = icmp eq i32 %27391, %27482
  %27484 = or i1 %27481, %27483
  %27485 = load i32, i32* %36, align 4
  %27486 = icmp eq i32 %27391, %27485
  %27487 = or i1 %27484, %27486
  %27488 = load i32, i32* %37, align 4
  %27489 = icmp eq i32 %27391, %27488
  %27490 = or i1 %27487, %27489
  %27491 = load i32, i32* %38, align 4
  %27492 = icmp eq i32 %27391, %27491
  %27493 = or i1 %27490, %27492
  %27494 = load i32, i32* %39, align 4
  %27495 = icmp eq i32 %27391, %27494
  %27496 = or i1 %27493, %27495
  %27497 = load i32, i32* %40, align 4
  %27498 = icmp eq i32 %27391, %27497
  %27499 = or i1 %27496, %27498
  %27500 = load i32, i32* %41, align 4
  %27501 = icmp eq i32 %27391, %27500
  %27502 = or i1 %27499, %27501
  %27503 = load i32, i32* %42, align 4
  %27504 = icmp eq i32 %27391, %27503
  %27505 = or i1 %27502, %27504
  %27506 = load i32, i32* %43, align 4
  %27507 = icmp eq i32 %27391, %27506
  %27508 = or i1 %27505, %27507
  %27509 = load i32, i32* %44, align 4
  %27510 = icmp eq i32 %27391, %27509
  %27511 = or i1 %27508, %27510
  %27512 = load i32, i32* %45, align 4
  %27513 = icmp eq i32 %27391, %27512
  %27514 = or i1 %27511, %27513
  %27515 = load i32, i32* %46, align 4
  %27516 = icmp eq i32 %27391, %27515
  %27517 = or i1 %27514, %27516
  %27518 = load i32, i32* %47, align 4
  %27519 = icmp eq i32 %27391, %27518
  %27520 = or i1 %27517, %27519
  %27521 = load i32, i32* %48, align 4
  %27522 = icmp eq i32 %27391, %27521
  %27523 = or i1 %27520, %27522
  %27524 = load i32, i32* %49, align 4
  %27525 = icmp eq i32 %27391, %27524
  %27526 = or i1 %27523, %27525
  %27527 = load i32, i32* %50, align 4
  %27528 = icmp eq i32 %27391, %27527
  %27529 = or i1 %27526, %27528
  %27530 = load i32, i32* %51, align 4
  %27531 = icmp eq i32 %27391, %27530
  %27532 = or i1 %27529, %27531
  %27533 = load i32, i32* %52, align 4
  %27534 = icmp eq i32 %27391, %27533
  %27535 = or i1 %27532, %27534
  %27536 = load i32, i32* %53, align 4
  %27537 = icmp eq i32 %27391, %27536
  %27538 = or i1 %27535, %27537
  %27539 = load i32, i32* %54, align 4
  %27540 = icmp eq i32 %27391, %27539
  %27541 = or i1 %27538, %27540
  %27542 = load i32, i32* %55, align 4
  %27543 = icmp eq i32 %27391, %27542
  %27544 = or i1 %27541, %27543
  %27545 = load i32, i32* %56, align 4
  %27546 = icmp eq i32 %27391, %27545
  %27547 = or i1 %27544, %27546
  %27548 = load i32, i32* %57, align 4
  %27549 = icmp eq i32 %27391, %27548
  %27550 = or i1 %27547, %27549
  %27551 = load i32, i32* %58, align 4
  %27552 = icmp eq i32 %27391, %27551
  %27553 = or i1 %27550, %27552
  %27554 = load i32, i32* %59, align 4
  %27555 = icmp eq i32 %27391, %27554
  %27556 = or i1 %27553, %27555
  %27557 = load i32, i32* %60, align 4
  %27558 = icmp eq i32 %27391, %27557
  %27559 = or i1 %27556, %27558
  %27560 = load i32, i32* %61, align 4
  %27561 = icmp eq i32 %27391, %27560
  %27562 = or i1 %27559, %27561
  %27563 = load i32, i32* %62, align 4
  %27564 = icmp eq i32 %27391, %27563
  %27565 = or i1 %27562, %27564
  %27566 = getelementptr i8, i8 addrspace(1)* %4, i32 95
  %27567 = zext i1 %27565 to i8
  store i8 %27567, i8 addrspace(1)* %27566, align 1, !nosanitize !3
  %27568 = load i256, i256* %27390, align 4
  %27569 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !434, !intsan !45
  %27570 = xor i256 %27569, -1
  %27571 = and i256 %27570, %27568
  %27572 = and i256 1461501637330902918203684832716283019655932542975, %27381
  %27573 = mul i256 %27572, 1, !pc !435, !intsan !45
  %27574 = or i256 %27573, %27571
  %27575 = alloca i256, align 8
  store i256 7, i256* %27575, align 4
  %27576 = alloca i256, align 8
  store i256 %27574, i256* %27576, align 4
  call void @__device_sstore(i256* %27575, i256* %27576)
  %27577 = call i32 @__hashword(i256* %27575)
  store i32 %27577, i32* %27, align 4, !nosanitize !3
  %27578 = alloca i256, align 8
  store i256 7, i256* %27578, align 4
  %27579 = alloca i256, align 8
  call void @__device_sload(i256* %27578, i256* %27579)
  %27580 = call i32 @__hashword(i256* %27578)
  %27581 = load i32, i32* %5, align 4
  %27582 = icmp eq i32 %27580, %27581
  %27583 = or i1 false, %27582
  %27584 = load i32, i32* %6, align 4
  %27585 = icmp eq i32 %27580, %27584
  %27586 = or i1 %27583, %27585
  %27587 = load i32, i32* %7, align 4
  %27588 = icmp eq i32 %27580, %27587
  %27589 = or i1 %27586, %27588
  %27590 = load i32, i32* %8, align 4
  %27591 = icmp eq i32 %27580, %27590
  %27592 = or i1 %27589, %27591
  %27593 = load i32, i32* %9, align 4
  %27594 = icmp eq i32 %27580, %27593
  %27595 = or i1 %27592, %27594
  %27596 = load i32, i32* %10, align 4
  %27597 = icmp eq i32 %27580, %27596
  %27598 = or i1 %27595, %27597
  %27599 = load i32, i32* %11, align 4
  %27600 = icmp eq i32 %27580, %27599
  %27601 = or i1 %27598, %27600
  %27602 = load i32, i32* %12, align 4
  %27603 = icmp eq i32 %27580, %27602
  %27604 = or i1 %27601, %27603
  %27605 = load i32, i32* %13, align 4
  %27606 = icmp eq i32 %27580, %27605
  %27607 = or i1 %27604, %27606
  %27608 = load i32, i32* %14, align 4
  %27609 = icmp eq i32 %27580, %27608
  %27610 = or i1 %27607, %27609
  %27611 = load i32, i32* %15, align 4
  %27612 = icmp eq i32 %27580, %27611
  %27613 = or i1 %27610, %27612
  %27614 = load i32, i32* %16, align 4
  %27615 = icmp eq i32 %27580, %27614
  %27616 = or i1 %27613, %27615
  %27617 = load i32, i32* %17, align 4
  %27618 = icmp eq i32 %27580, %27617
  %27619 = or i1 %27616, %27618
  %27620 = load i32, i32* %18, align 4
  %27621 = icmp eq i32 %27580, %27620
  %27622 = or i1 %27619, %27621
  %27623 = load i32, i32* %19, align 4
  %27624 = icmp eq i32 %27580, %27623
  %27625 = or i1 %27622, %27624
  %27626 = load i32, i32* %20, align 4
  %27627 = icmp eq i32 %27580, %27626
  %27628 = or i1 %27625, %27627
  %27629 = load i32, i32* %21, align 4
  %27630 = icmp eq i32 %27580, %27629
  %27631 = or i1 %27628, %27630
  %27632 = load i32, i32* %22, align 4
  %27633 = icmp eq i32 %27580, %27632
  %27634 = or i1 %27631, %27633
  %27635 = load i32, i32* %23, align 4
  %27636 = icmp eq i32 %27580, %27635
  %27637 = or i1 %27634, %27636
  %27638 = load i32, i32* %24, align 4
  %27639 = icmp eq i32 %27580, %27638
  %27640 = or i1 %27637, %27639
  %27641 = load i32, i32* %25, align 4
  %27642 = icmp eq i32 %27580, %27641
  %27643 = or i1 %27640, %27642
  %27644 = load i32, i32* %26, align 4
  %27645 = icmp eq i32 %27580, %27644
  %27646 = or i1 %27643, %27645
  %27647 = load i32, i32* %27, align 4
  %27648 = icmp eq i32 %27580, %27647
  %27649 = or i1 %27646, %27648
  %27650 = load i32, i32* %28, align 4
  %27651 = icmp eq i32 %27580, %27650
  %27652 = or i1 %27649, %27651
  %27653 = load i32, i32* %29, align 4
  %27654 = icmp eq i32 %27580, %27653
  %27655 = or i1 %27652, %27654
  %27656 = load i32, i32* %30, align 4
  %27657 = icmp eq i32 %27580, %27656
  %27658 = or i1 %27655, %27657
  %27659 = load i32, i32* %31, align 4
  %27660 = icmp eq i32 %27580, %27659
  %27661 = or i1 %27658, %27660
  %27662 = load i32, i32* %32, align 4
  %27663 = icmp eq i32 %27580, %27662
  %27664 = or i1 %27661, %27663
  %27665 = load i32, i32* %33, align 4
  %27666 = icmp eq i32 %27580, %27665
  %27667 = or i1 %27664, %27666
  %27668 = load i32, i32* %34, align 4
  %27669 = icmp eq i32 %27580, %27668
  %27670 = or i1 %27667, %27669
  %27671 = load i32, i32* %35, align 4
  %27672 = icmp eq i32 %27580, %27671
  %27673 = or i1 %27670, %27672
  %27674 = load i32, i32* %36, align 4
  %27675 = icmp eq i32 %27580, %27674
  %27676 = or i1 %27673, %27675
  %27677 = load i32, i32* %37, align 4
  %27678 = icmp eq i32 %27580, %27677
  %27679 = or i1 %27676, %27678
  %27680 = load i32, i32* %38, align 4
  %27681 = icmp eq i32 %27580, %27680
  %27682 = or i1 %27679, %27681
  %27683 = load i32, i32* %39, align 4
  %27684 = icmp eq i32 %27580, %27683
  %27685 = or i1 %27682, %27684
  %27686 = load i32, i32* %40, align 4
  %27687 = icmp eq i32 %27580, %27686
  %27688 = or i1 %27685, %27687
  %27689 = load i32, i32* %41, align 4
  %27690 = icmp eq i32 %27580, %27689
  %27691 = or i1 %27688, %27690
  %27692 = load i32, i32* %42, align 4
  %27693 = icmp eq i32 %27580, %27692
  %27694 = or i1 %27691, %27693
  %27695 = load i32, i32* %43, align 4
  %27696 = icmp eq i32 %27580, %27695
  %27697 = or i1 %27694, %27696
  %27698 = load i32, i32* %44, align 4
  %27699 = icmp eq i32 %27580, %27698
  %27700 = or i1 %27697, %27699
  %27701 = load i32, i32* %45, align 4
  %27702 = icmp eq i32 %27580, %27701
  %27703 = or i1 %27700, %27702
  %27704 = load i32, i32* %46, align 4
  %27705 = icmp eq i32 %27580, %27704
  %27706 = or i1 %27703, %27705
  %27707 = load i32, i32* %47, align 4
  %27708 = icmp eq i32 %27580, %27707
  %27709 = or i1 %27706, %27708
  %27710 = load i32, i32* %48, align 4
  %27711 = icmp eq i32 %27580, %27710
  %27712 = or i1 %27709, %27711
  %27713 = load i32, i32* %49, align 4
  %27714 = icmp eq i32 %27580, %27713
  %27715 = or i1 %27712, %27714
  %27716 = load i32, i32* %50, align 4
  %27717 = icmp eq i32 %27580, %27716
  %27718 = or i1 %27715, %27717
  %27719 = load i32, i32* %51, align 4
  %27720 = icmp eq i32 %27580, %27719
  %27721 = or i1 %27718, %27720
  %27722 = load i32, i32* %52, align 4
  %27723 = icmp eq i32 %27580, %27722
  %27724 = or i1 %27721, %27723
  %27725 = load i32, i32* %53, align 4
  %27726 = icmp eq i32 %27580, %27725
  %27727 = or i1 %27724, %27726
  %27728 = load i32, i32* %54, align 4
  %27729 = icmp eq i32 %27580, %27728
  %27730 = or i1 %27727, %27729
  %27731 = load i32, i32* %55, align 4
  %27732 = icmp eq i32 %27580, %27731
  %27733 = or i1 %27730, %27732
  %27734 = load i32, i32* %56, align 4
  %27735 = icmp eq i32 %27580, %27734
  %27736 = or i1 %27733, %27735
  %27737 = load i32, i32* %57, align 4
  %27738 = icmp eq i32 %27580, %27737
  %27739 = or i1 %27736, %27738
  %27740 = load i32, i32* %58, align 4
  %27741 = icmp eq i32 %27580, %27740
  %27742 = or i1 %27739, %27741
  %27743 = load i32, i32* %59, align 4
  %27744 = icmp eq i32 %27580, %27743
  %27745 = or i1 %27742, %27744
  %27746 = load i32, i32* %60, align 4
  %27747 = icmp eq i32 %27580, %27746
  %27748 = or i1 %27745, %27747
  %27749 = load i32, i32* %61, align 4
  %27750 = icmp eq i32 %27580, %27749
  %27751 = or i1 %27748, %27750
  %27752 = load i32, i32* %62, align 4
  %27753 = icmp eq i32 %27580, %27752
  %27754 = or i1 %27751, %27753
  %27755 = getelementptr i8, i8 addrspace(1)* %4, i32 96
  %27756 = zext i1 %27754 to i8
  store i8 %27756, i8 addrspace(1)* %27755, align 1, !nosanitize !3
  %27757 = load i256, i256* %27579, align 4
  %27758 = alloca i256, align 8
  store i256 %27757, i256* %27758, align 4
  %27759 = alloca i256, align 8
  store i256 1, i256* %27759, align 4
  %27760 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %27758, i256* %27759, i256* %27760), !pc !436, !intsan !6
  %27761 = load i256, i256* %27760, align 4
  %27762 = and i256 1461501637330902918203684832716283019655932542975, %27761
  %27763 = trunc i256 64 to i64
  %27764 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %27763, i256* %27764)
  %27765 = load i256, i256* %27764, align 4
  %27766 = and i256 1461501637330902918203684832716283019655932542975, %27762
  %27767 = and i256 1461501637330902918203684832716283019655932542975, %27766
  %27768 = trunc i256 %27765 to i64
  %27769 = alloca i256, align 8
  store i256 %27767, i256* %27769, align 4
  %27770 = bitcast i256* %27769 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %27768, i8* %27770, i64 32)
  %27771 = add i256 32, %27765, !pc !437, !intsan !10
  %27772 = and i256 1461501637330902918203684832716283019655932542975, %27381
  %27773 = and i256 1461501637330902918203684832716283019655932542975, %27772
  %27774 = trunc i256 %27771 to i64
  %27775 = alloca i256, align 8
  store i256 %27773, i256* %27775, align 4
  %27776 = bitcast i256* %27775 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %27774, i8* %27776, i64 32)
  %27777 = add i256 32, %27771, !pc !438, !intsan !10
  %27778 = trunc i256 64 to i64
  %27779 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %27778, i256* %27779)
  %27780 = load i256, i256* %27779, align 4
  %27781 = sub i256 %27777, %27780, !pc !439, !intsan !8
  %27782 = trunc i256 35916454252257183190983873685678270873999494224959345264533818168250400775211 to i64
  call void @addBugSet(i64 %27782)
  %27783 = trunc i256 %27386 to i64
  store i64 %27783, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.9740:                                            ; preds = %3093, %JumpTable
  %27784 = load i64, i64* %remaing_gas, align 4
  %27785 = icmp ugt i64 280, %27784
  br i1 %27785, label %Abort, label %27786

27786:                                            ; preds = %.9740
  %27787 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27788 = xor i32 %27787, 3927
  %27789 = urem i32 %27788, 4096
  %27790 = getelementptr i8, i8 addrspace(1)* %4, i32 %27789
  %27791 = load i8, i8 addrspace(1)* %27790, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27790, align 1, !nosanitize !3
  store i32 1963, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27792 = sub i64 %27784, 280
  store i64 %27792, i64* %remaing_gas, align 4
  %27793 = load i64, i64* %STACK_DEP_PTR, align 4
  %27794 = getelementptr i256, i256* %STACK, i64 %27793
  %27795 = load i256, i256* %27794, align 4
  %27796 = load i64, i64* %STACK_DEP_PTR, align 4
  %27797 = sub i64 %27796, 1
  store i64 %27797, i64* %STACK_DEP_PTR, align 4
  %27798 = alloca i256, align 8
  store i256 7, i256* %27798, align 4
  %27799 = alloca i256, align 8
  call void @__device_sload(i256* %27798, i256* %27799)
  %27800 = call i32 @__hashword(i256* %27798)
  %27801 = load i32, i32* %5, align 4
  %27802 = icmp eq i32 %27800, %27801
  %27803 = or i1 false, %27802
  %27804 = load i32, i32* %6, align 4
  %27805 = icmp eq i32 %27800, %27804
  %27806 = or i1 %27803, %27805
  %27807 = load i32, i32* %7, align 4
  %27808 = icmp eq i32 %27800, %27807
  %27809 = or i1 %27806, %27808
  %27810 = load i32, i32* %8, align 4
  %27811 = icmp eq i32 %27800, %27810
  %27812 = or i1 %27809, %27811
  %27813 = load i32, i32* %9, align 4
  %27814 = icmp eq i32 %27800, %27813
  %27815 = or i1 %27812, %27814
  %27816 = load i32, i32* %10, align 4
  %27817 = icmp eq i32 %27800, %27816
  %27818 = or i1 %27815, %27817
  %27819 = load i32, i32* %11, align 4
  %27820 = icmp eq i32 %27800, %27819
  %27821 = or i1 %27818, %27820
  %27822 = load i32, i32* %12, align 4
  %27823 = icmp eq i32 %27800, %27822
  %27824 = or i1 %27821, %27823
  %27825 = load i32, i32* %13, align 4
  %27826 = icmp eq i32 %27800, %27825
  %27827 = or i1 %27824, %27826
  %27828 = load i32, i32* %14, align 4
  %27829 = icmp eq i32 %27800, %27828
  %27830 = or i1 %27827, %27829
  %27831 = load i32, i32* %15, align 4
  %27832 = icmp eq i32 %27800, %27831
  %27833 = or i1 %27830, %27832
  %27834 = load i32, i32* %16, align 4
  %27835 = icmp eq i32 %27800, %27834
  %27836 = or i1 %27833, %27835
  %27837 = load i32, i32* %17, align 4
  %27838 = icmp eq i32 %27800, %27837
  %27839 = or i1 %27836, %27838
  %27840 = load i32, i32* %18, align 4
  %27841 = icmp eq i32 %27800, %27840
  %27842 = or i1 %27839, %27841
  %27843 = load i32, i32* %19, align 4
  %27844 = icmp eq i32 %27800, %27843
  %27845 = or i1 %27842, %27844
  %27846 = load i32, i32* %20, align 4
  %27847 = icmp eq i32 %27800, %27846
  %27848 = or i1 %27845, %27847
  %27849 = load i32, i32* %21, align 4
  %27850 = icmp eq i32 %27800, %27849
  %27851 = or i1 %27848, %27850
  %27852 = load i32, i32* %22, align 4
  %27853 = icmp eq i32 %27800, %27852
  %27854 = or i1 %27851, %27853
  %27855 = load i32, i32* %23, align 4
  %27856 = icmp eq i32 %27800, %27855
  %27857 = or i1 %27854, %27856
  %27858 = load i32, i32* %24, align 4
  %27859 = icmp eq i32 %27800, %27858
  %27860 = or i1 %27857, %27859
  %27861 = load i32, i32* %25, align 4
  %27862 = icmp eq i32 %27800, %27861
  %27863 = or i1 %27860, %27862
  %27864 = load i32, i32* %26, align 4
  %27865 = icmp eq i32 %27800, %27864
  %27866 = or i1 %27863, %27865
  %27867 = load i32, i32* %27, align 4
  %27868 = icmp eq i32 %27800, %27867
  %27869 = or i1 %27866, %27868
  %27870 = load i32, i32* %28, align 4
  %27871 = icmp eq i32 %27800, %27870
  %27872 = or i1 %27869, %27871
  %27873 = load i32, i32* %29, align 4
  %27874 = icmp eq i32 %27800, %27873
  %27875 = or i1 %27872, %27874
  %27876 = load i32, i32* %30, align 4
  %27877 = icmp eq i32 %27800, %27876
  %27878 = or i1 %27875, %27877
  %27879 = load i32, i32* %31, align 4
  %27880 = icmp eq i32 %27800, %27879
  %27881 = or i1 %27878, %27880
  %27882 = load i32, i32* %32, align 4
  %27883 = icmp eq i32 %27800, %27882
  %27884 = or i1 %27881, %27883
  %27885 = load i32, i32* %33, align 4
  %27886 = icmp eq i32 %27800, %27885
  %27887 = or i1 %27884, %27886
  %27888 = load i32, i32* %34, align 4
  %27889 = icmp eq i32 %27800, %27888
  %27890 = or i1 %27887, %27889
  %27891 = load i32, i32* %35, align 4
  %27892 = icmp eq i32 %27800, %27891
  %27893 = or i1 %27890, %27892
  %27894 = load i32, i32* %36, align 4
  %27895 = icmp eq i32 %27800, %27894
  %27896 = or i1 %27893, %27895
  %27897 = load i32, i32* %37, align 4
  %27898 = icmp eq i32 %27800, %27897
  %27899 = or i1 %27896, %27898
  %27900 = load i32, i32* %38, align 4
  %27901 = icmp eq i32 %27800, %27900
  %27902 = or i1 %27899, %27901
  %27903 = load i32, i32* %39, align 4
  %27904 = icmp eq i32 %27800, %27903
  %27905 = or i1 %27902, %27904
  %27906 = load i32, i32* %40, align 4
  %27907 = icmp eq i32 %27800, %27906
  %27908 = or i1 %27905, %27907
  %27909 = load i32, i32* %41, align 4
  %27910 = icmp eq i32 %27800, %27909
  %27911 = or i1 %27908, %27910
  %27912 = load i32, i32* %42, align 4
  %27913 = icmp eq i32 %27800, %27912
  %27914 = or i1 %27911, %27913
  %27915 = load i32, i32* %43, align 4
  %27916 = icmp eq i32 %27800, %27915
  %27917 = or i1 %27914, %27916
  %27918 = load i32, i32* %44, align 4
  %27919 = icmp eq i32 %27800, %27918
  %27920 = or i1 %27917, %27919
  %27921 = load i32, i32* %45, align 4
  %27922 = icmp eq i32 %27800, %27921
  %27923 = or i1 %27920, %27922
  %27924 = load i32, i32* %46, align 4
  %27925 = icmp eq i32 %27800, %27924
  %27926 = or i1 %27923, %27925
  %27927 = load i32, i32* %47, align 4
  %27928 = icmp eq i32 %27800, %27927
  %27929 = or i1 %27926, %27928
  %27930 = load i32, i32* %48, align 4
  %27931 = icmp eq i32 %27800, %27930
  %27932 = or i1 %27929, %27931
  %27933 = load i32, i32* %49, align 4
  %27934 = icmp eq i32 %27800, %27933
  %27935 = or i1 %27932, %27934
  %27936 = load i32, i32* %50, align 4
  %27937 = icmp eq i32 %27800, %27936
  %27938 = or i1 %27935, %27937
  %27939 = load i32, i32* %51, align 4
  %27940 = icmp eq i32 %27800, %27939
  %27941 = or i1 %27938, %27940
  %27942 = load i32, i32* %52, align 4
  %27943 = icmp eq i32 %27800, %27942
  %27944 = or i1 %27941, %27943
  %27945 = load i32, i32* %53, align 4
  %27946 = icmp eq i32 %27800, %27945
  %27947 = or i1 %27944, %27946
  %27948 = load i32, i32* %54, align 4
  %27949 = icmp eq i32 %27800, %27948
  %27950 = or i1 %27947, %27949
  %27951 = load i32, i32* %55, align 4
  %27952 = icmp eq i32 %27800, %27951
  %27953 = or i1 %27950, %27952
  %27954 = load i32, i32* %56, align 4
  %27955 = icmp eq i32 %27800, %27954
  %27956 = or i1 %27953, %27955
  %27957 = load i32, i32* %57, align 4
  %27958 = icmp eq i32 %27800, %27957
  %27959 = or i1 %27956, %27958
  %27960 = load i32, i32* %58, align 4
  %27961 = icmp eq i32 %27800, %27960
  %27962 = or i1 %27959, %27961
  %27963 = load i32, i32* %59, align 4
  %27964 = icmp eq i32 %27800, %27963
  %27965 = or i1 %27962, %27964
  %27966 = load i32, i32* %60, align 4
  %27967 = icmp eq i32 %27800, %27966
  %27968 = or i1 %27965, %27967
  %27969 = load i32, i32* %61, align 4
  %27970 = icmp eq i32 %27800, %27969
  %27971 = or i1 %27968, %27970
  %27972 = load i32, i32* %62, align 4
  %27973 = icmp eq i32 %27800, %27972
  %27974 = or i1 %27971, %27973
  %27975 = getelementptr i8, i8 addrspace(1)* %4, i32 97
  %27976 = zext i1 %27974 to i8
  store i8 %27976, i8 addrspace(1)* %27975, align 1, !nosanitize !3
  %27977 = load i256, i256* %27799, align 4
  %27978 = alloca i256, align 8
  store i256 %27977, i256* %27978, align 4
  %27979 = alloca i256, align 8
  store i256 1, i256* %27979, align 4
  %27980 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %27978, i256* %27979, i256* %27980), !pc !440, !intsan !6
  %27981 = load i256, i256* %27980, align 4
  %27982 = and i256 1461501637330902918203684832716283019655932542975, %27981
  %27983 = trunc i256 %27795 to i64
  store i64 %27983, i64* %JMP_TARGET_PTR, align 4
  %27984 = load i64, i64* %STACK_DEP_PTR, align 4
  %27985 = add i64 %27984, 1
  store i64 %27985, i64* %STACK_DEP_PTR, align 4
  %27986 = load i64, i64* %STACK_DEP_PTR, align 4
  %27987 = getelementptr i256, i256* %STACK, i64 %27986
  store i256 %27795, i256* %27987, align 4
  %27988 = load i64, i64* %STACK_DEP_PTR, align 4
  %27989 = add i64 %27988, 1
  store i64 %27989, i64* %STACK_DEP_PTR, align 4
  %27990 = load i64, i64* %STACK_DEP_PTR, align 4
  %27991 = getelementptr i256, i256* %STACK, i64 %27990
  store i256 %27982, i256* %27991, align 4
  br label %JumpTable, !EVMBB !4

.9778:                                            ; preds = %3139, %JumpTable
  %27992 = load i64, i64* %remaing_gas, align 4
  %27993 = icmp ugt i64 144, %27992
  br i1 %27993, label %Abort, label %27994

27994:                                            ; preds = %.9778
  %27995 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %27996 = xor i32 %27995, 2116
  %27997 = urem i32 %27996, 4096
  %27998 = getelementptr i8, i8 addrspace(1)* %4, i32 %27997
  %27999 = load i8, i8 addrspace(1)* %27998, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %27998, align 1, !nosanitize !3
  store i32 1058, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28000 = sub i64 %27992, 144
  store i64 %28000, i64* %remaing_gas, align 4
  %28001 = alloca i256, align 8
  store i256 8, i256* %28001, align 4
  %28002 = alloca i256, align 8
  call void @__device_sload(i256* %28001, i256* %28002)
  %28003 = call i32 @__hashword(i256* %28001)
  %28004 = load i32, i32* %5, align 4
  %28005 = icmp eq i32 %28003, %28004
  %28006 = or i1 false, %28005
  %28007 = load i32, i32* %6, align 4
  %28008 = icmp eq i32 %28003, %28007
  %28009 = or i1 %28006, %28008
  %28010 = load i32, i32* %7, align 4
  %28011 = icmp eq i32 %28003, %28010
  %28012 = or i1 %28009, %28011
  %28013 = load i32, i32* %8, align 4
  %28014 = icmp eq i32 %28003, %28013
  %28015 = or i1 %28012, %28014
  %28016 = load i32, i32* %9, align 4
  %28017 = icmp eq i32 %28003, %28016
  %28018 = or i1 %28015, %28017
  %28019 = load i32, i32* %10, align 4
  %28020 = icmp eq i32 %28003, %28019
  %28021 = or i1 %28018, %28020
  %28022 = load i32, i32* %11, align 4
  %28023 = icmp eq i32 %28003, %28022
  %28024 = or i1 %28021, %28023
  %28025 = load i32, i32* %12, align 4
  %28026 = icmp eq i32 %28003, %28025
  %28027 = or i1 %28024, %28026
  %28028 = load i32, i32* %13, align 4
  %28029 = icmp eq i32 %28003, %28028
  %28030 = or i1 %28027, %28029
  %28031 = load i32, i32* %14, align 4
  %28032 = icmp eq i32 %28003, %28031
  %28033 = or i1 %28030, %28032
  %28034 = load i32, i32* %15, align 4
  %28035 = icmp eq i32 %28003, %28034
  %28036 = or i1 %28033, %28035
  %28037 = load i32, i32* %16, align 4
  %28038 = icmp eq i32 %28003, %28037
  %28039 = or i1 %28036, %28038
  %28040 = load i32, i32* %17, align 4
  %28041 = icmp eq i32 %28003, %28040
  %28042 = or i1 %28039, %28041
  %28043 = load i32, i32* %18, align 4
  %28044 = icmp eq i32 %28003, %28043
  %28045 = or i1 %28042, %28044
  %28046 = load i32, i32* %19, align 4
  %28047 = icmp eq i32 %28003, %28046
  %28048 = or i1 %28045, %28047
  %28049 = load i32, i32* %20, align 4
  %28050 = icmp eq i32 %28003, %28049
  %28051 = or i1 %28048, %28050
  %28052 = load i32, i32* %21, align 4
  %28053 = icmp eq i32 %28003, %28052
  %28054 = or i1 %28051, %28053
  %28055 = load i32, i32* %22, align 4
  %28056 = icmp eq i32 %28003, %28055
  %28057 = or i1 %28054, %28056
  %28058 = load i32, i32* %23, align 4
  %28059 = icmp eq i32 %28003, %28058
  %28060 = or i1 %28057, %28059
  %28061 = load i32, i32* %24, align 4
  %28062 = icmp eq i32 %28003, %28061
  %28063 = or i1 %28060, %28062
  %28064 = load i32, i32* %25, align 4
  %28065 = icmp eq i32 %28003, %28064
  %28066 = or i1 %28063, %28065
  %28067 = load i32, i32* %26, align 4
  %28068 = icmp eq i32 %28003, %28067
  %28069 = or i1 %28066, %28068
  %28070 = load i32, i32* %27, align 4
  %28071 = icmp eq i32 %28003, %28070
  %28072 = or i1 %28069, %28071
  %28073 = load i32, i32* %28, align 4
  %28074 = icmp eq i32 %28003, %28073
  %28075 = or i1 %28072, %28074
  %28076 = load i32, i32* %29, align 4
  %28077 = icmp eq i32 %28003, %28076
  %28078 = or i1 %28075, %28077
  %28079 = load i32, i32* %30, align 4
  %28080 = icmp eq i32 %28003, %28079
  %28081 = or i1 %28078, %28080
  %28082 = load i32, i32* %31, align 4
  %28083 = icmp eq i32 %28003, %28082
  %28084 = or i1 %28081, %28083
  %28085 = load i32, i32* %32, align 4
  %28086 = icmp eq i32 %28003, %28085
  %28087 = or i1 %28084, %28086
  %28088 = load i32, i32* %33, align 4
  %28089 = icmp eq i32 %28003, %28088
  %28090 = or i1 %28087, %28089
  %28091 = load i32, i32* %34, align 4
  %28092 = icmp eq i32 %28003, %28091
  %28093 = or i1 %28090, %28092
  %28094 = load i32, i32* %35, align 4
  %28095 = icmp eq i32 %28003, %28094
  %28096 = or i1 %28093, %28095
  %28097 = load i32, i32* %36, align 4
  %28098 = icmp eq i32 %28003, %28097
  %28099 = or i1 %28096, %28098
  %28100 = load i32, i32* %37, align 4
  %28101 = icmp eq i32 %28003, %28100
  %28102 = or i1 %28099, %28101
  %28103 = load i32, i32* %38, align 4
  %28104 = icmp eq i32 %28003, %28103
  %28105 = or i1 %28102, %28104
  %28106 = load i32, i32* %39, align 4
  %28107 = icmp eq i32 %28003, %28106
  %28108 = or i1 %28105, %28107
  %28109 = load i32, i32* %40, align 4
  %28110 = icmp eq i32 %28003, %28109
  %28111 = or i1 %28108, %28110
  %28112 = load i32, i32* %41, align 4
  %28113 = icmp eq i32 %28003, %28112
  %28114 = or i1 %28111, %28113
  %28115 = load i32, i32* %42, align 4
  %28116 = icmp eq i32 %28003, %28115
  %28117 = or i1 %28114, %28116
  %28118 = load i32, i32* %43, align 4
  %28119 = icmp eq i32 %28003, %28118
  %28120 = or i1 %28117, %28119
  %28121 = load i32, i32* %44, align 4
  %28122 = icmp eq i32 %28003, %28121
  %28123 = or i1 %28120, %28122
  %28124 = load i32, i32* %45, align 4
  %28125 = icmp eq i32 %28003, %28124
  %28126 = or i1 %28123, %28125
  %28127 = load i32, i32* %46, align 4
  %28128 = icmp eq i32 %28003, %28127
  %28129 = or i1 %28126, %28128
  %28130 = load i32, i32* %47, align 4
  %28131 = icmp eq i32 %28003, %28130
  %28132 = or i1 %28129, %28131
  %28133 = load i32, i32* %48, align 4
  %28134 = icmp eq i32 %28003, %28133
  %28135 = or i1 %28132, %28134
  %28136 = load i32, i32* %49, align 4
  %28137 = icmp eq i32 %28003, %28136
  %28138 = or i1 %28135, %28137
  %28139 = load i32, i32* %50, align 4
  %28140 = icmp eq i32 %28003, %28139
  %28141 = or i1 %28138, %28140
  %28142 = load i32, i32* %51, align 4
  %28143 = icmp eq i32 %28003, %28142
  %28144 = or i1 %28141, %28143
  %28145 = load i32, i32* %52, align 4
  %28146 = icmp eq i32 %28003, %28145
  %28147 = or i1 %28144, %28146
  %28148 = load i32, i32* %53, align 4
  %28149 = icmp eq i32 %28003, %28148
  %28150 = or i1 %28147, %28149
  %28151 = load i32, i32* %54, align 4
  %28152 = icmp eq i32 %28003, %28151
  %28153 = or i1 %28150, %28152
  %28154 = load i32, i32* %55, align 4
  %28155 = icmp eq i32 %28003, %28154
  %28156 = or i1 %28153, %28155
  %28157 = load i32, i32* %56, align 4
  %28158 = icmp eq i32 %28003, %28157
  %28159 = or i1 %28156, %28158
  %28160 = load i32, i32* %57, align 4
  %28161 = icmp eq i32 %28003, %28160
  %28162 = or i1 %28159, %28161
  %28163 = load i32, i32* %58, align 4
  %28164 = icmp eq i32 %28003, %28163
  %28165 = or i1 %28162, %28164
  %28166 = load i32, i32* %59, align 4
  %28167 = icmp eq i32 %28003, %28166
  %28168 = or i1 %28165, %28167
  %28169 = load i32, i32* %60, align 4
  %28170 = icmp eq i32 %28003, %28169
  %28171 = or i1 %28168, %28170
  %28172 = load i32, i32* %61, align 4
  %28173 = icmp eq i32 %28003, %28172
  %28174 = or i1 %28171, %28173
  %28175 = load i32, i32* %62, align 4
  %28176 = icmp eq i32 %28003, %28175
  %28177 = or i1 %28174, %28176
  %28178 = getelementptr i8, i8 addrspace(1)* %4, i32 98
  %28179 = zext i1 %28177 to i8
  store i8 %28179, i8 addrspace(1)* %28178, align 1, !nosanitize !3
  %28180 = load i256, i256* %28002, align 4
  %28181 = alloca i256, align 8
  store i256 %28180, i256* %28181, align 4
  %28182 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %28182, align 4
  %28183 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %28181, i256* %28182, i256* %28183), !pc !441, !intsan !6
  %28184 = load i256, i256* %28183, align 4
  %28185 = and i256 255, %28184
  %28186 = icmp eq i256 %28185, 0
  %28187 = trunc i256 9804 to i64
  %jump.check142 = icmp ne i1 %28186, false
  br i1 %jump.check142, label %.9804, label %.9800, !EVMBB !4

.9800:                                            ; preds = %27994
  %28188 = load i64, i64* %remaing_gas, align 4
  %28189 = icmp ugt i64 16, %28188
  br i1 %28189, label %Abort, label %28190

28190:                                            ; preds = %.9800
  %28191 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28192 = xor i32 %28191, 2798
  %28193 = urem i32 %28192, 4096
  %28194 = getelementptr i8, i8 addrspace(1)* %4, i32 %28193
  %28195 = load i8, i8 addrspace(1)* %28194, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28194, align 1, !nosanitize !3
  store i32 1399, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28196 = sub i64 %28188, 16
  store i64 %28196, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.9804:                                            ; preds = %27994, %JumpTable
  %28197 = load i64, i64* %remaing_gas, align 4
  %28198 = icmp ugt i64 56, %28197
  br i1 %28198, label %Abort, label %28199

28199:                                            ; preds = %.9804
  %28200 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28201 = xor i32 %28200, 1179
  %28202 = urem i32 %28201, 4096
  %28203 = getelementptr i8, i8 addrspace(1)* %4, i32 %28202
  %28204 = load i8, i8 addrspace(1)* %28203, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28203, align 1, !nosanitize !3
  store i32 589, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28205 = sub i64 %28197, 56
  store i64 %28205, i64* %remaing_gas, align 4
  %28206 = load i256, i256* %1, align 4
  %28207 = icmp eq i256 %28206, 0
  %28208 = icmp eq i1 %28207, false
  %28209 = trunc i256 9818 to i64
  %jump.check147 = icmp ne i1 %28208, false
  br i1 %jump.check147, label %.9818, label %.9814, !EVMBB !4

.9814:                                            ; preds = %28199
  %28210 = load i64, i64* %remaing_gas, align 4
  %28211 = icmp ugt i64 16, %28210
  br i1 %28211, label %Abort, label %28212

28212:                                            ; preds = %.9814
  %28213 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28214 = xor i32 %28213, 1724
  %28215 = urem i32 %28214, 4096
  %28216 = getelementptr i8, i8 addrspace(1)* %4, i32 %28215
  %28217 = load i8, i8 addrspace(1)* %28216, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28216, align 1, !nosanitize !3
  store i32 862, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28218 = sub i64 %28210, 16
  store i64 %28218, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.9818:                                            ; preds = %28199, %JumpTable
  %28219 = load i64, i64* %remaing_gas, align 4
  %28220 = icmp ugt i64 264, %28219
  br i1 %28220, label %Abort, label %28221

28221:                                            ; preds = %.9818
  %28222 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28223 = xor i32 %28222, 3561
  %28224 = urem i32 %28223, 4096
  %28225 = getelementptr i8, i8 addrspace(1)* %4, i32 %28224
  %28226 = load i8, i8 addrspace(1)* %28225, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28225, align 1, !nosanitize !3
  store i32 1780, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28227 = sub i64 %28219, 264
  store i64 %28227, i64* %remaing_gas, align 4
  %28228 = load i256, i256* %0, align 4
  %28229 = and i256 1461501637330902918203684832716283019655932542975, %28228
  %28230 = and i256 1461501637330902918203684832716283019655932542975, %28229
  %28231 = trunc i256 0 to i64
  %28232 = alloca i256, align 8
  store i256 %28230, i256* %28232, align 4
  %28233 = bitcast i256* %28232 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28231, i8* %28233, i64 32)
  %28234 = add i256 32, 0, !pc !442, !intsan !10
  %28235 = trunc i256 %28234 to i64
  %28236 = alloca i256, align 8
  store i256 3, i256* %28236, align 4
  %28237 = bitcast i256* %28236 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28235, i8* %28237, i64 32)
  %28238 = add i256 32, %28234, !pc !443, !intsan !10
  %28239 = trunc i256 0 to i32
  %28240 = trunc i256 %28238 to i32
  %28241 = getelementptr inbounds i8, i8* %MEMORY, i32 %28239
  %28242 = alloca i256, align 8
  %28243 = bitcast i256* %28242 to i8*
  call void @__device_sha3(i8* %28241, i32 %28240, i8* %28243)
  %28244 = load i256, i256* %28242, align 4
  %28245 = alloca i256, align 8
  store i256 %28244, i256* %28245, align 4
  %28246 = alloca i256, align 8
  call void @__device_sload(i256* %28245, i256* %28246)
  %28247 = call i32 @__hashword(i256* %28245)
  %28248 = load i32, i32* %5, align 4
  %28249 = icmp eq i32 %28247, %28248
  %28250 = or i1 false, %28249
  %28251 = load i32, i32* %6, align 4
  %28252 = icmp eq i32 %28247, %28251
  %28253 = or i1 %28250, %28252
  %28254 = load i32, i32* %7, align 4
  %28255 = icmp eq i32 %28247, %28254
  %28256 = or i1 %28253, %28255
  %28257 = load i32, i32* %8, align 4
  %28258 = icmp eq i32 %28247, %28257
  %28259 = or i1 %28256, %28258
  %28260 = load i32, i32* %9, align 4
  %28261 = icmp eq i32 %28247, %28260
  %28262 = or i1 %28259, %28261
  %28263 = load i32, i32* %10, align 4
  %28264 = icmp eq i32 %28247, %28263
  %28265 = or i1 %28262, %28264
  %28266 = load i32, i32* %11, align 4
  %28267 = icmp eq i32 %28247, %28266
  %28268 = or i1 %28265, %28267
  %28269 = load i32, i32* %12, align 4
  %28270 = icmp eq i32 %28247, %28269
  %28271 = or i1 %28268, %28270
  %28272 = load i32, i32* %13, align 4
  %28273 = icmp eq i32 %28247, %28272
  %28274 = or i1 %28271, %28273
  %28275 = load i32, i32* %14, align 4
  %28276 = icmp eq i32 %28247, %28275
  %28277 = or i1 %28274, %28276
  %28278 = load i32, i32* %15, align 4
  %28279 = icmp eq i32 %28247, %28278
  %28280 = or i1 %28277, %28279
  %28281 = load i32, i32* %16, align 4
  %28282 = icmp eq i32 %28247, %28281
  %28283 = or i1 %28280, %28282
  %28284 = load i32, i32* %17, align 4
  %28285 = icmp eq i32 %28247, %28284
  %28286 = or i1 %28283, %28285
  %28287 = load i32, i32* %18, align 4
  %28288 = icmp eq i32 %28247, %28287
  %28289 = or i1 %28286, %28288
  %28290 = load i32, i32* %19, align 4
  %28291 = icmp eq i32 %28247, %28290
  %28292 = or i1 %28289, %28291
  %28293 = load i32, i32* %20, align 4
  %28294 = icmp eq i32 %28247, %28293
  %28295 = or i1 %28292, %28294
  %28296 = load i32, i32* %21, align 4
  %28297 = icmp eq i32 %28247, %28296
  %28298 = or i1 %28295, %28297
  %28299 = load i32, i32* %22, align 4
  %28300 = icmp eq i32 %28247, %28299
  %28301 = or i1 %28298, %28300
  %28302 = load i32, i32* %23, align 4
  %28303 = icmp eq i32 %28247, %28302
  %28304 = or i1 %28301, %28303
  %28305 = load i32, i32* %24, align 4
  %28306 = icmp eq i32 %28247, %28305
  %28307 = or i1 %28304, %28306
  %28308 = load i32, i32* %25, align 4
  %28309 = icmp eq i32 %28247, %28308
  %28310 = or i1 %28307, %28309
  %28311 = load i32, i32* %26, align 4
  %28312 = icmp eq i32 %28247, %28311
  %28313 = or i1 %28310, %28312
  %28314 = load i32, i32* %27, align 4
  %28315 = icmp eq i32 %28247, %28314
  %28316 = or i1 %28313, %28315
  %28317 = load i32, i32* %28, align 4
  %28318 = icmp eq i32 %28247, %28317
  %28319 = or i1 %28316, %28318
  %28320 = load i32, i32* %29, align 4
  %28321 = icmp eq i32 %28247, %28320
  %28322 = or i1 %28319, %28321
  %28323 = load i32, i32* %30, align 4
  %28324 = icmp eq i32 %28247, %28323
  %28325 = or i1 %28322, %28324
  %28326 = load i32, i32* %31, align 4
  %28327 = icmp eq i32 %28247, %28326
  %28328 = or i1 %28325, %28327
  %28329 = load i32, i32* %32, align 4
  %28330 = icmp eq i32 %28247, %28329
  %28331 = or i1 %28328, %28330
  %28332 = load i32, i32* %33, align 4
  %28333 = icmp eq i32 %28247, %28332
  %28334 = or i1 %28331, %28333
  %28335 = load i32, i32* %34, align 4
  %28336 = icmp eq i32 %28247, %28335
  %28337 = or i1 %28334, %28336
  %28338 = load i32, i32* %35, align 4
  %28339 = icmp eq i32 %28247, %28338
  %28340 = or i1 %28337, %28339
  %28341 = load i32, i32* %36, align 4
  %28342 = icmp eq i32 %28247, %28341
  %28343 = or i1 %28340, %28342
  %28344 = load i32, i32* %37, align 4
  %28345 = icmp eq i32 %28247, %28344
  %28346 = or i1 %28343, %28345
  %28347 = load i32, i32* %38, align 4
  %28348 = icmp eq i32 %28247, %28347
  %28349 = or i1 %28346, %28348
  %28350 = load i32, i32* %39, align 4
  %28351 = icmp eq i32 %28247, %28350
  %28352 = or i1 %28349, %28351
  %28353 = load i32, i32* %40, align 4
  %28354 = icmp eq i32 %28247, %28353
  %28355 = or i1 %28352, %28354
  %28356 = load i32, i32* %41, align 4
  %28357 = icmp eq i32 %28247, %28356
  %28358 = or i1 %28355, %28357
  %28359 = load i32, i32* %42, align 4
  %28360 = icmp eq i32 %28247, %28359
  %28361 = or i1 %28358, %28360
  %28362 = load i32, i32* %43, align 4
  %28363 = icmp eq i32 %28247, %28362
  %28364 = or i1 %28361, %28363
  %28365 = load i32, i32* %44, align 4
  %28366 = icmp eq i32 %28247, %28365
  %28367 = or i1 %28364, %28366
  %28368 = load i32, i32* %45, align 4
  %28369 = icmp eq i32 %28247, %28368
  %28370 = or i1 %28367, %28369
  %28371 = load i32, i32* %46, align 4
  %28372 = icmp eq i32 %28247, %28371
  %28373 = or i1 %28370, %28372
  %28374 = load i32, i32* %47, align 4
  %28375 = icmp eq i32 %28247, %28374
  %28376 = or i1 %28373, %28375
  %28377 = load i32, i32* %48, align 4
  %28378 = icmp eq i32 %28247, %28377
  %28379 = or i1 %28376, %28378
  %28380 = load i32, i32* %49, align 4
  %28381 = icmp eq i32 %28247, %28380
  %28382 = or i1 %28379, %28381
  %28383 = load i32, i32* %50, align 4
  %28384 = icmp eq i32 %28247, %28383
  %28385 = or i1 %28382, %28384
  %28386 = load i32, i32* %51, align 4
  %28387 = icmp eq i32 %28247, %28386
  %28388 = or i1 %28385, %28387
  %28389 = load i32, i32* %52, align 4
  %28390 = icmp eq i32 %28247, %28389
  %28391 = or i1 %28388, %28390
  %28392 = load i32, i32* %53, align 4
  %28393 = icmp eq i32 %28247, %28392
  %28394 = or i1 %28391, %28393
  %28395 = load i32, i32* %54, align 4
  %28396 = icmp eq i32 %28247, %28395
  %28397 = or i1 %28394, %28396
  %28398 = load i32, i32* %55, align 4
  %28399 = icmp eq i32 %28247, %28398
  %28400 = or i1 %28397, %28399
  %28401 = load i32, i32* %56, align 4
  %28402 = icmp eq i32 %28247, %28401
  %28403 = or i1 %28400, %28402
  %28404 = load i32, i32* %57, align 4
  %28405 = icmp eq i32 %28247, %28404
  %28406 = or i1 %28403, %28405
  %28407 = load i32, i32* %58, align 4
  %28408 = icmp eq i32 %28247, %28407
  %28409 = or i1 %28406, %28408
  %28410 = load i32, i32* %59, align 4
  %28411 = icmp eq i32 %28247, %28410
  %28412 = or i1 %28409, %28411
  %28413 = load i32, i32* %60, align 4
  %28414 = icmp eq i32 %28247, %28413
  %28415 = or i1 %28412, %28414
  %28416 = load i32, i32* %61, align 4
  %28417 = icmp eq i32 %28247, %28416
  %28418 = or i1 %28415, %28417
  %28419 = load i32, i32* %62, align 4
  %28420 = icmp eq i32 %28247, %28419
  %28421 = or i1 %28418, %28420
  %28422 = getelementptr i8, i8 addrspace(1)* %4, i32 99
  %28423 = zext i1 %28421 to i8
  store i8 %28423, i8 addrspace(1)* %28422, align 1, !nosanitize !3
  %28424 = load i256, i256* %28246, align 4
  %28425 = icmp eq i256 %28424, 0
  %28426 = icmp eq i1 %28425, false
  %28427 = trunc i256 9895 to i64
  %jump.check152 = icmp ne i1 %28426, false
  br i1 %jump.check152, label %.9895, label %.9891, !EVMBB !4

.9891:                                            ; preds = %28221
  %28428 = load i64, i64* %remaing_gas, align 4
  %28429 = icmp ugt i64 16, %28428
  br i1 %28429, label %Abort, label %28430

28430:                                            ; preds = %.9891
  %28431 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28432 = xor i32 %28431, 997
  %28433 = urem i32 %28432, 4096
  %28434 = getelementptr i8, i8 addrspace(1)* %4, i32 %28433
  %28435 = load i8, i8 addrspace(1)* %28434, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28434, align 1, !nosanitize !3
  store i32 498, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28436 = sub i64 %28428, 16
  store i64 %28436, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.9895:                                            ; preds = %28221, %JumpTable
  %28437 = load i64, i64* %remaing_gas, align 4
  %28438 = icmp ugt i64 72, %28437
  br i1 %28438, label %Abort, label %28439

28439:                                            ; preds = %.9895
  %28440 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28441 = xor i32 %28440, 1573
  %28442 = urem i32 %28441, 4096
  %28443 = getelementptr i8, i8 addrspace(1)* %4, i32 %28442
  %28444 = load i8, i8 addrspace(1)* %28443, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28443, align 1, !nosanitize !3
  store i32 786, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28445 = sub i64 %28437, 72
  store i64 %28445, i64* %remaing_gas, align 4
  %28446 = trunc i256 16448 to i64
  %28447 = load i64, i64* %STACK_DEP_PTR, align 4
  %28448 = add i64 %28447, 1
  store i64 %28448, i64* %STACK_DEP_PTR, align 4
  %28449 = load i64, i64* %STACK_DEP_PTR, align 4
  %28450 = getelementptr i256, i256* %STACK, i64 %28449
  store i256 9903, i256* %28450, align 4
  br label %.16448, !EVMBB !4

.9903:                                            ; preds = %JumpTable
  %28451 = load i64, i64* %remaing_gas, align 4
  %28452 = icmp ugt i64 648, %28451
  br i1 %28452, label %Abort, label %28453

28453:                                            ; preds = %.9903
  %28454 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28455 = xor i32 %28454, 3791
  %28456 = urem i32 %28455, 4096
  %28457 = getelementptr i8, i8 addrspace(1)* %4, i32 %28456
  %28458 = load i8, i8 addrspace(1)* %28457, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %28457, align 1, !nosanitize !3
  store i32 1895, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %28459 = sub i64 %28451, 648
  store i64 %28459, i64* %remaing_gas, align 4
  %28460 = load i64, i64* %STACK_DEP_PTR, align 4
  %28461 = getelementptr i256, i256* %STACK, i64 %28460
  %28462 = load i256, i256* %28461, align 4
  %28463 = load i64, i64* %STACK_DEP_PTR, align 4
  %28464 = sub i64 %28463, 1
  store i64 %28464, i64* %STACK_DEP_PTR, align 4
  %28465 = load i256, i256* %1, align 4
  %28466 = load i256, i256* %0, align 4
  %28467 = and i256 1461501637330902918203684832716283019655932542975, %28466
  %28468 = and i256 1461501637330902918203684832716283019655932542975, %28467
  %28469 = trunc i256 0 to i64
  %28470 = alloca i256, align 8
  store i256 %28468, i256* %28470, align 4
  %28471 = bitcast i256* %28470 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28469, i8* %28471, i64 32)
  %28472 = add i256 32, 0, !pc !444, !intsan !10
  %28473 = trunc i256 %28472 to i64
  %28474 = alloca i256, align 8
  store i256 3, i256* %28474, align 4
  %28475 = bitcast i256* %28474 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28473, i8* %28475, i64 32)
  %28476 = add i256 32, %28472, !pc !445, !intsan !10
  %28477 = trunc i256 0 to i32
  %28478 = trunc i256 %28476 to i32
  %28479 = getelementptr inbounds i8, i8* %MEMORY, i32 %28477
  %28480 = alloca i256, align 8
  %28481 = bitcast i256* %28480 to i8*
  call void @__device_sha3(i8* %28479, i32 %28478, i8* %28481)
  %28482 = load i256, i256* %28480, align 4
  %28483 = alloca i256, align 8
  store i256 %28482, i256* %28483, align 4
  %28484 = alloca i256, align 8
  call void @__device_sload(i256* %28483, i256* %28484)
  %28485 = call i32 @__hashword(i256* %28483)
  %28486 = load i32, i32* %5, align 4
  %28487 = icmp eq i32 %28485, %28486
  %28488 = or i1 false, %28487
  %28489 = load i32, i32* %6, align 4
  %28490 = icmp eq i32 %28485, %28489
  %28491 = or i1 %28488, %28490
  %28492 = load i32, i32* %7, align 4
  %28493 = icmp eq i32 %28485, %28492
  %28494 = or i1 %28491, %28493
  %28495 = load i32, i32* %8, align 4
  %28496 = icmp eq i32 %28485, %28495
  %28497 = or i1 %28494, %28496
  %28498 = load i32, i32* %9, align 4
  %28499 = icmp eq i32 %28485, %28498
  %28500 = or i1 %28497, %28499
  %28501 = load i32, i32* %10, align 4
  %28502 = icmp eq i32 %28485, %28501
  %28503 = or i1 %28500, %28502
  %28504 = load i32, i32* %11, align 4
  %28505 = icmp eq i32 %28485, %28504
  %28506 = or i1 %28503, %28505
  %28507 = load i32, i32* %12, align 4
  %28508 = icmp eq i32 %28485, %28507
  %28509 = or i1 %28506, %28508
  %28510 = load i32, i32* %13, align 4
  %28511 = icmp eq i32 %28485, %28510
  %28512 = or i1 %28509, %28511
  %28513 = load i32, i32* %14, align 4
  %28514 = icmp eq i32 %28485, %28513
  %28515 = or i1 %28512, %28514
  %28516 = load i32, i32* %15, align 4
  %28517 = icmp eq i32 %28485, %28516
  %28518 = or i1 %28515, %28517
  %28519 = load i32, i32* %16, align 4
  %28520 = icmp eq i32 %28485, %28519
  %28521 = or i1 %28518, %28520
  %28522 = load i32, i32* %17, align 4
  %28523 = icmp eq i32 %28485, %28522
  %28524 = or i1 %28521, %28523
  %28525 = load i32, i32* %18, align 4
  %28526 = icmp eq i32 %28485, %28525
  %28527 = or i1 %28524, %28526
  %28528 = load i32, i32* %19, align 4
  %28529 = icmp eq i32 %28485, %28528
  %28530 = or i1 %28527, %28529
  %28531 = load i32, i32* %20, align 4
  %28532 = icmp eq i32 %28485, %28531
  %28533 = or i1 %28530, %28532
  %28534 = load i32, i32* %21, align 4
  %28535 = icmp eq i32 %28485, %28534
  %28536 = or i1 %28533, %28535
  %28537 = load i32, i32* %22, align 4
  %28538 = icmp eq i32 %28485, %28537
  %28539 = or i1 %28536, %28538
  %28540 = load i32, i32* %23, align 4
  %28541 = icmp eq i32 %28485, %28540
  %28542 = or i1 %28539, %28541
  %28543 = load i32, i32* %24, align 4
  %28544 = icmp eq i32 %28485, %28543
  %28545 = or i1 %28542, %28544
  %28546 = load i32, i32* %25, align 4
  %28547 = icmp eq i32 %28485, %28546
  %28548 = or i1 %28545, %28547
  %28549 = load i32, i32* %26, align 4
  %28550 = icmp eq i32 %28485, %28549
  %28551 = or i1 %28548, %28550
  %28552 = load i32, i32* %27, align 4
  %28553 = icmp eq i32 %28485, %28552
  %28554 = or i1 %28551, %28553
  %28555 = load i32, i32* %28, align 4
  %28556 = icmp eq i32 %28485, %28555
  %28557 = or i1 %28554, %28556
  %28558 = load i32, i32* %29, align 4
  %28559 = icmp eq i32 %28485, %28558
  %28560 = or i1 %28557, %28559
  %28561 = load i32, i32* %30, align 4
  %28562 = icmp eq i32 %28485, %28561
  %28563 = or i1 %28560, %28562
  %28564 = load i32, i32* %31, align 4
  %28565 = icmp eq i32 %28485, %28564
  %28566 = or i1 %28563, %28565
  %28567 = load i32, i32* %32, align 4
  %28568 = icmp eq i32 %28485, %28567
  %28569 = or i1 %28566, %28568
  %28570 = load i32, i32* %33, align 4
  %28571 = icmp eq i32 %28485, %28570
  %28572 = or i1 %28569, %28571
  %28573 = load i32, i32* %34, align 4
  %28574 = icmp eq i32 %28485, %28573
  %28575 = or i1 %28572, %28574
  %28576 = load i32, i32* %35, align 4
  %28577 = icmp eq i32 %28485, %28576
  %28578 = or i1 %28575, %28577
  %28579 = load i32, i32* %36, align 4
  %28580 = icmp eq i32 %28485, %28579
  %28581 = or i1 %28578, %28580
  %28582 = load i32, i32* %37, align 4
  %28583 = icmp eq i32 %28485, %28582
  %28584 = or i1 %28581, %28583
  %28585 = load i32, i32* %38, align 4
  %28586 = icmp eq i32 %28485, %28585
  %28587 = or i1 %28584, %28586
  %28588 = load i32, i32* %39, align 4
  %28589 = icmp eq i32 %28485, %28588
  %28590 = or i1 %28587, %28589
  %28591 = load i32, i32* %40, align 4
  %28592 = icmp eq i32 %28485, %28591
  %28593 = or i1 %28590, %28592
  %28594 = load i32, i32* %41, align 4
  %28595 = icmp eq i32 %28485, %28594
  %28596 = or i1 %28593, %28595
  %28597 = load i32, i32* %42, align 4
  %28598 = icmp eq i32 %28485, %28597
  %28599 = or i1 %28596, %28598
  %28600 = load i32, i32* %43, align 4
  %28601 = icmp eq i32 %28485, %28600
  %28602 = or i1 %28599, %28601
  %28603 = load i32, i32* %44, align 4
  %28604 = icmp eq i32 %28485, %28603
  %28605 = or i1 %28602, %28604
  %28606 = load i32, i32* %45, align 4
  %28607 = icmp eq i32 %28485, %28606
  %28608 = or i1 %28605, %28607
  %28609 = load i32, i32* %46, align 4
  %28610 = icmp eq i32 %28485, %28609
  %28611 = or i1 %28608, %28610
  %28612 = load i32, i32* %47, align 4
  %28613 = icmp eq i32 %28485, %28612
  %28614 = or i1 %28611, %28613
  %28615 = load i32, i32* %48, align 4
  %28616 = icmp eq i32 %28485, %28615
  %28617 = or i1 %28614, %28616
  %28618 = load i32, i32* %49, align 4
  %28619 = icmp eq i32 %28485, %28618
  %28620 = or i1 %28617, %28619
  %28621 = load i32, i32* %50, align 4
  %28622 = icmp eq i32 %28485, %28621
  %28623 = or i1 %28620, %28622
  %28624 = load i32, i32* %51, align 4
  %28625 = icmp eq i32 %28485, %28624
  %28626 = or i1 %28623, %28625
  %28627 = load i32, i32* %52, align 4
  %28628 = icmp eq i32 %28485, %28627
  %28629 = or i1 %28626, %28628
  %28630 = load i32, i32* %53, align 4
  %28631 = icmp eq i32 %28485, %28630
  %28632 = or i1 %28629, %28631
  %28633 = load i32, i32* %54, align 4
  %28634 = icmp eq i32 %28485, %28633
  %28635 = or i1 %28632, %28634
  %28636 = load i32, i32* %55, align 4
  %28637 = icmp eq i32 %28485, %28636
  %28638 = or i1 %28635, %28637
  %28639 = load i32, i32* %56, align 4
  %28640 = icmp eq i32 %28485, %28639
  %28641 = or i1 %28638, %28640
  %28642 = load i32, i32* %57, align 4
  %28643 = icmp eq i32 %28485, %28642
  %28644 = or i1 %28641, %28643
  %28645 = load i32, i32* %58, align 4
  %28646 = icmp eq i32 %28485, %28645
  %28647 = or i1 %28644, %28646
  %28648 = load i32, i32* %59, align 4
  %28649 = icmp eq i32 %28485, %28648
  %28650 = or i1 %28647, %28649
  %28651 = load i32, i32* %60, align 4
  %28652 = icmp eq i32 %28485, %28651
  %28653 = or i1 %28650, %28652
  %28654 = load i32, i32* %61, align 4
  %28655 = icmp eq i32 %28485, %28654
  %28656 = or i1 %28653, %28655
  %28657 = load i32, i32* %62, align 4
  %28658 = icmp eq i32 %28485, %28657
  %28659 = or i1 %28656, %28658
  %28660 = getelementptr i8, i8 addrspace(1)* %4, i32 100
  %28661 = zext i1 %28659 to i8
  store i8 %28661, i8 addrspace(1)* %28660, align 1, !nosanitize !3
  %28662 = load i256, i256* %28484, align 4
  %28663 = trunc i256 0 to i64
  %28664 = alloca i256, align 8
  store i256 %28662, i256* %28664, align 4
  %28665 = bitcast i256* %28664 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28663, i8* %28665, i64 32)
  %28666 = add i256 32, 0, !pc !446, !intsan !10
  %28667 = trunc i256 %28666 to i64
  %28668 = alloca i256, align 8
  store i256 4, i256* %28668, align 4
  %28669 = bitcast i256* %28668 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %28667, i8* %28669, i64 32)
  %28670 = add i256 32, %28666, !pc !447, !intsan !10
  %28671 = trunc i256 0 to i32
  %28672 = trunc i256 %28670 to i32
  %28673 = getelementptr inbounds i8, i8* %MEMORY, i32 %28671
  %28674 = alloca i256, align 8
  %28675 = bitcast i256* %28674 to i8*
  call void @__device_sha3(i8* %28673, i32 %28672, i8* %28675)
  %28676 = load i256, i256* %28674, align 4
  %28677 = add i256 1, %28676, !pc !448, !intsan !10
  %28678 = alloca i256, align 8
  store i256 %28677, i256* %28678, align 4
  %28679 = alloca i256, align 8
  call void @__device_sload(i256* %28678, i256* %28679)
  %28680 = call i32 @__hashword(i256* %28678)
  %28681 = load i32, i32* %5, align 4
  %28682 = icmp eq i32 %28680, %28681
  %28683 = or i1 false, %28682
  %28684 = load i32, i32* %6, align 4
  %28685 = icmp eq i32 %28680, %28684
  %28686 = or i1 %28683, %28685
  %28687 = load i32, i32* %7, align 4
  %28688 = icmp eq i32 %28680, %28687
  %28689 = or i1 %28686, %28688
  %28690 = load i32, i32* %8, align 4
  %28691 = icmp eq i32 %28680, %28690
  %28692 = or i1 %28689, %28691
  %28693 = load i32, i32* %9, align 4
  %28694 = icmp eq i32 %28680, %28693
  %28695 = or i1 %28692, %28694
  %28696 = load i32, i32* %10, align 4
  %28697 = icmp eq i32 %28680, %28696
  %28698 = or i1 %28695, %28697
  %28699 = load i32, i32* %11, align 4
  %28700 = icmp eq i32 %28680, %28699
  %28701 = or i1 %28698, %28700
  %28702 = load i32, i32* %12, align 4
  %28703 = icmp eq i32 %28680, %28702
  %28704 = or i1 %28701, %28703
  %28705 = load i32, i32* %13, align 4
  %28706 = icmp eq i32 %28680, %28705
  %28707 = or i1 %28704, %28706
  %28708 = load i32, i32* %14, align 4
  %28709 = icmp eq i32 %28680, %28708
  %28710 = or i1 %28707, %28709
  %28711 = load i32, i32* %15, align 4
  %28712 = icmp eq i32 %28680, %28711
  %28713 = or i1 %28710, %28712
  %28714 = load i32, i32* %16, align 4
  %28715 = icmp eq i32 %28680, %28714
  %28716 = or i1 %28713, %28715
  %28717 = load i32, i32* %17, align 4
  %28718 = icmp eq i32 %28680, %28717
  %28719 = or i1 %28716, %28718
  %28720 = load i32, i32* %18, align 4
  %28721 = icmp eq i32 %28680, %28720
  %28722 = or i1 %28719, %28721
  %28723 = load i32, i32* %19, align 4
  %28724 = icmp eq i32 %28680, %28723
  %28725 = or i1 %28722, %28724
  %28726 = load i32, i32* %20, align 4
  %28727 = icmp eq i32 %28680, %28726
  %28728 = or i1 %28725, %28727
  %28729 = load i32, i32* %21, align 4
  %28730 = icmp eq i32 %28680, %28729
  %28731 = or i1 %28728, %28730
  %28732 = load i32, i32* %22, align 4
  %28733 = icmp eq i32 %28680, %28732
  %28734 = or i1 %28731, %28733
  %28735 = load i32, i32* %23, align 4
  %28736 = icmp eq i32 %28680, %28735
  %28737 = or i1 %28734, %28736
  %28738 = load i32, i32* %24, align 4
  %28739 = icmp eq i32 %28680, %28738
  %28740 = or i1 %28737, %28739
  %28741 = load i32, i32* %25, align 4
  %28742 = icmp eq i32 %28680, %28741
  %28743 = or i1 %28740, %28742
  %28744 = load i32, i32* %26, align 4
  %28745 = icmp eq i32 %28680, %28744
  %28746 = or i1 %28743, %28745
  %28747 = load i32, i32* %27, align 4
  %28748 = icmp eq i32 %28680, %28747
  %28749 = or i1 %28746, %28748
  %28750 = load i32, i32* %28, align 4
  %28751 = icmp eq i32 %28680, %28750
  %28752 = or i1 %28749, %28751
  %28753 = load i32, i32* %29, align 4
  %28754 = icmp eq i32 %28680, %28753
  %28755 = or i1 %28752, %28754
  %28756 = load i32, i32* %30, align 4
  %28757 = icmp eq i32 %28680, %28756
  %28758 = or i1 %28755, %28757
  %28759 = load i32, i32* %31, align 4
  %28760 = icmp eq i32 %28680, %28759
  %28761 = or i1 %28758, %28760
  %28762 = load i32, i32* %32, align 4
  %28763 = icmp eq i32 %28680, %28762
  %28764 = or i1 %28761, %28763
  %28765 = load i32, i32* %33, align 4
  %28766 = icmp eq i32 %28680, %28765
  %28767 = or i1 %28764, %28766
  %28768 = load i32, i32* %34, align 4
  %28769 = icmp eq i32 %28680, %28768
  %28770 = or i1 %28767, %28769
  %28771 = load i32, i32* %35, align 4
  %28772 = icmp eq i32 %28680, %28771
  %28773 = or i1 %28770, %28772
  %28774 = load i32, i32* %36, align 4
  %28775 = icmp eq i32 %28680, %28774
  %28776 = or i1 %28773, %28775
  %28777 = load i32, i32* %37, align 4
  %28778 = icmp eq i32 %28680, %28777
  %28779 = or i1 %28776, %28778
  %28780 = load i32, i32* %38, align 4
  %28781 = icmp eq i32 %28680, %28780
  %28782 = or i1 %28779, %28781
  %28783 = load i32, i32* %39, align 4
  %28784 = icmp eq i32 %28680, %28783
  %28785 = or i1 %28782, %28784
  %28786 = load i32, i32* %40, align 4
  %28787 = icmp eq i32 %28680, %28786
  %28788 = or i1 %28785, %28787
  %28789 = load i32, i32* %41, align 4
  %28790 = icmp eq i32 %28680, %28789
  %28791 = or i1 %28788, %28790
  %28792 = load i32, i32* %42, align 4
  %28793 = icmp eq i32 %28680, %28792
  %28794 = or i1 %28791, %28793
  %28795 = load i32, i32* %43, align 4
  %28796 = icmp eq i32 %28680, %28795
  %28797 = or i1 %28794, %28796
  %28798 = load i32, i32* %44, align 4
  %28799 = icmp eq i32 %28680, %28798
  %28800 = or i1 %28797, %28799
  %28801 = load i32, i32* %45, align 4
  %28802 = icmp eq i32 %28680, %28801
  %28803 = or i1 %28800, %28802
  %28804 = load i32, i32* %46, align 4
  %28805 = icmp eq i32 %28680, %28804
  %28806 = or i1 %28803, %28805
  %28807 = load i32, i32* %47, align 4
  %28808 = icmp eq i32 %28680, %28807
  %28809 = or i1 %28806, %28808
  %28810 = load i32, i32* %48, align 4
  %28811 = icmp eq i32 %28680, %28810
  %28812 = or i1 %28809, %28811
  %28813 = load i32, i32* %49, align 4
  %28814 = icmp eq i32 %28680, %28813
  %28815 = or i1 %28812, %28814
  %28816 = load i32, i32* %50, align 4
  %28817 = icmp eq i32 %28680, %28816
  %28818 = or i1 %28815, %28817
  %28819 = load i32, i32* %51, align 4
  %28820 = icmp eq i32 %28680, %28819
  %28821 = or i1 %28818, %28820
  %28822 = load i32, i32* %52, align 4
  %28823 = icmp eq i32 %28680, %28822
  %28824 = or i1 %28821, %28823
  %28825 = load i32, i32* %53, align 4
  %28826 = icmp eq i32 %28680, %28825
  %28827 = or i1 %28824, %28826
  %28828 = load i32, i32* %54, align 4
  %28829 = icmp eq i32 %28680, %28828
  %28830 = or i1 %28827, %28829
  %28831 = load i32, i32* %55, align 4
  %28832 = icmp eq i32 %28680, %28831
  %28833 = or i1 %28830, %28832
  %28834 = load i32, i32* %56, align 4
  %28835 = icmp eq i32 %28680, %28834
  %28836 = or i1 %28833, %28835
  %28837 = load i32, i32* %57, align 4
  %28838 = icmp eq i32 %28680, %28837
  %28839 = or i1 %28836, %28838
  %28840 = load i32, i32* %58, align 4
  %28841 = icmp eq i32 %28680, %28840
  %28842 = or i1 %28839, %28841
  %28843 = load i32, i32* %59, align 4
  %28844 = icmp eq i32 %28680, %28843
  %28845 = or i1 %28842, %28844
  %28846 = load i32, i32* %60, align 4
  %28847 = icmp eq i32 %28680, %28846
  %28848 = or i1 %28845, %28847
  %28849 = load i32, i32* %61, align 4
  %28850 = icmp eq i32 %28680, %28849
  %28851 = or i1 %28848, %28850
  %28852 = load i32, i32* %62, align 4
  %28853 = icmp eq i32 %28680, %28852
  %28854 = or i1 %28851, %28853
  %28855 = getelementptr i8, i8 addrspace(1)* %4, i32 101
  %28856 = zext i1 %28854 to i8
  store i8 %28856, i8 addrspace(1)* %28855, align 1, !nosanitize !3
  %28857 = load i256, i256* %28679, align 4
  %28858 = add i256 %28857, %28465, !pc !449, !intsan !10
  %28859 = alloca i256, align 8
  store i256 %28677, i256* %28859, align 4
  %28860 = alloca i256, align 8
  store i256 %28858, i256* %28860, align 4
  call void @__device_sstore(i256* %28859, i256* %28860)
  %28861 = call i32 @__hashword(i256* %28859)
  store i32 %28861, i32* %44, align 4, !nosanitize !3
  %28862 = load i256, i256* %1, align 4
  %28863 = alloca i256, align 8
  store i256 6, i256* %28863, align 4
  %28864 = alloca i256, align 8
  call void @__device_sload(i256* %28863, i256* %28864)
  %28865 = call i32 @__hashword(i256* %28863)
  %28866 = load i32, i32* %5, align 4
  %28867 = icmp eq i32 %28865, %28866
  %28868 = or i1 false, %28867
  %28869 = load i32, i32* %6, align 4
  %28870 = icmp eq i32 %28865, %28869
  %28871 = or i1 %28868, %28870
  %28872 = load i32, i32* %7, align 4
  %28873 = icmp eq i32 %28865, %28872
  %28874 = or i1 %28871, %28873
  %28875 = load i32, i32* %8, align 4
  %28876 = icmp eq i32 %28865, %28875
  %28877 = or i1 %28874, %28876
  %28878 = load i32, i32* %9, align 4
  %28879 = icmp eq i32 %28865, %28878
  %28880 = or i1 %28877, %28879
  %28881 = load i32, i32* %10, align 4
  %28882 = icmp eq i32 %28865, %28881
  %28883 = or i1 %28880, %28882
  %28884 = load i32, i32* %11, align 4
  %28885 = icmp eq i32 %28865, %28884
  %28886 = or i1 %28883, %28885
  %28887 = load i32, i32* %12, align 4
  %28888 = icmp eq i32 %28865, %28887
  %28889 = or i1 %28886, %28888
  %28890 = load i32, i32* %13, align 4
  %28891 = icmp eq i32 %28865, %28890
  %28892 = or i1 %28889, %28891
  %28893 = load i32, i32* %14, align 4
  %28894 = icmp eq i32 %28865, %28893
  %28895 = or i1 %28892, %28894
  %28896 = load i32, i32* %15, align 4
  %28897 = icmp eq i32 %28865, %28896
  %28898 = or i1 %28895, %28897
  %28899 = load i32, i32* %16, align 4
  %28900 = icmp eq i32 %28865, %28899
  %28901 = or i1 %28898, %28900
  %28902 = load i32, i32* %17, align 4
  %28903 = icmp eq i32 %28865, %28902
  %28904 = or i1 %28901, %28903
  %28905 = load i32, i32* %18, align 4
  %28906 = icmp eq i32 %28865, %28905
  %28907 = or i1 %28904, %28906
  %28908 = load i32, i32* %19, align 4
  %28909 = icmp eq i32 %28865, %28908
  %28910 = or i1 %28907, %28909
  %28911 = load i32, i32* %20, align 4
  %28912 = icmp eq i32 %28865, %28911
  %28913 = or i1 %28910, %28912
  %28914 = load i32, i32* %21, align 4
  %28915 = icmp eq i32 %28865, %28914
  %28916 = or i1 %28913, %28915
  %28917 = load i32, i32* %22, align 4
  %28918 = icmp eq i32 %28865, %28917
  %28919 = or i1 %28916, %28918
  %28920 = load i32, i32* %23, align 4
  %28921 = icmp eq i32 %28865, %28920
  %28922 = or i1 %28919, %28921
  %28923 = load i32, i32* %24, align 4
  %28924 = icmp eq i32 %28865, %28923
  %28925 = or i1 %28922, %28924
  %28926 = load i32, i32* %25, align 4
  %28927 = icmp eq i32 %28865, %28926
  %28928 = or i1 %28925, %28927
  %28929 = load i32, i32* %26, align 4
  %28930 = icmp eq i32 %28865, %28929
  %28931 = or i1 %28928, %28930
  %28932 = load i32, i32* %27, align 4
  %28933 = icmp eq i32 %28865, %28932
  %28934 = or i1 %28931, %28933
  %28935 = load i32, i32* %28, align 4
  %28936 = icmp eq i32 %28865, %28935
  %28937 = or i1 %28934, %28936
  %28938 = load i32, i32* %29, align 4
  %28939 = icmp eq i32 %28865, %28938
  %28940 = or i1 %28937, %28939
  %28941 = load i32, i32* %30, align 4
  %28942 = icmp eq i32 %28865, %28941
  %28943 = or i1 %28940, %28942
  %28944 = load i32, i32* %31, align 4
  %28945 = icmp eq i32 %28865, %28944
  %28946 = or i1 %28943, %28945
  %28947 = load i32, i32* %32, align 4
  %28948 = icmp eq i32 %28865, %28947
  %28949 = or i1 %28946, %28948
  %28950 = load i32, i32* %33, align 4
  %28951 = icmp eq i32 %28865, %28950
  %28952 = or i1 %28949, %28951
  %28953 = load i32, i32* %34, align 4
  %28954 = icmp eq i32 %28865, %28953
  %28955 = or i1 %28952, %28954
  %28956 = load i32, i32* %35, align 4
  %28957 = icmp eq i32 %28865, %28956
  %28958 = or i1 %28955, %28957
  %28959 = load i32, i32* %36, align 4
  %28960 = icmp eq i32 %28865, %28959
  %28961 = or i1 %28958, %28960
  %28962 = load i32, i32* %37, align 4
  %28963 = icmp eq i32 %28865, %28962
  %28964 = or i1 %28961, %28963
  %28965 = load i32, i32* %38, align 4
  %28966 = icmp eq i32 %28865, %28965
  %28967 = or i1 %28964, %28966
  %28968 = load i32, i32* %39, align 4
  %28969 = icmp eq i32 %28865, %28968
  %28970 = or i1 %28967, %28969
  %28971 = load i32, i32* %40, align 4
  %28972 = icmp eq i32 %28865, %28971
  %28973 = or i1 %28970, %28972
  %28974 = load i32, i32* %41, align 4
  %28975 = icmp eq i32 %28865, %28974
  %28976 = or i1 %28973, %28975
  %28977 = load i32, i32* %42, align 4
  %28978 = icmp eq i32 %28865, %28977
  %28979 = or i1 %28976, %28978
  %28980 = load i32, i32* %43, align 4
  %28981 = icmp eq i32 %28865, %28980
  %28982 = or i1 %28979, %28981
  %28983 = load i32, i32* %44, align 4
  %28984 = icmp eq i32 %28865, %28983
  %28985 = or i1 %28982, %28984
  %28986 = load i32, i32* %45, align 4
  %28987 = icmp eq i32 %28865, %28986
  %28988 = or i1 %28985, %28987
  %28989 = load i32, i32* %46, align 4
  %28990 = icmp eq i32 %28865, %28989
  %28991 = or i1 %28988, %28990
  %28992 = load i32, i32* %47, align 4
  %28993 = icmp eq i32 %28865, %28992
  %28994 = or i1 %28991, %28993
  %28995 = load i32, i32* %48, align 4
  %28996 = icmp eq i32 %28865, %28995
  %28997 = or i1 %28994, %28996
  %28998 = load i32, i32* %49, align 4
  %28999 = icmp eq i32 %28865, %28998
  %29000 = or i1 %28997, %28999
  %29001 = load i32, i32* %50, align 4
  %29002 = icmp eq i32 %28865, %29001
  %29003 = or i1 %29000, %29002
  %29004 = load i32, i32* %51, align 4
  %29005 = icmp eq i32 %28865, %29004
  %29006 = or i1 %29003, %29005
  %29007 = load i32, i32* %52, align 4
  %29008 = icmp eq i32 %28865, %29007
  %29009 = or i1 %29006, %29008
  %29010 = load i32, i32* %53, align 4
  %29011 = icmp eq i32 %28865, %29010
  %29012 = or i1 %29009, %29011
  %29013 = load i32, i32* %54, align 4
  %29014 = icmp eq i32 %28865, %29013
  %29015 = or i1 %29012, %29014
  %29016 = load i32, i32* %55, align 4
  %29017 = icmp eq i32 %28865, %29016
  %29018 = or i1 %29015, %29017
  %29019 = load i32, i32* %56, align 4
  %29020 = icmp eq i32 %28865, %29019
  %29021 = or i1 %29018, %29020
  %29022 = load i32, i32* %57, align 4
  %29023 = icmp eq i32 %28865, %29022
  %29024 = or i1 %29021, %29023
  %29025 = load i32, i32* %58, align 4
  %29026 = icmp eq i32 %28865, %29025
  %29027 = or i1 %29024, %29026
  %29028 = load i32, i32* %59, align 4
  %29029 = icmp eq i32 %28865, %29028
  %29030 = or i1 %29027, %29029
  %29031 = load i32, i32* %60, align 4
  %29032 = icmp eq i32 %28865, %29031
  %29033 = or i1 %29030, %29032
  %29034 = load i32, i32* %61, align 4
  %29035 = icmp eq i32 %28865, %29034
  %29036 = or i1 %29033, %29035
  %29037 = load i32, i32* %62, align 4
  %29038 = icmp eq i32 %28865, %29037
  %29039 = or i1 %29036, %29038
  %29040 = getelementptr i8, i8 addrspace(1)* %4, i32 102
  %29041 = zext i1 %29039 to i8
  store i8 %29041, i8 addrspace(1)* %29040, align 1, !nosanitize !3
  %29042 = load i256, i256* %28864, align 4
  %29043 = add i256 %29042, %28862, !pc !450, !intsan !10
  %29044 = alloca i256, align 8
  store i256 6, i256* %29044, align 4
  %29045 = alloca i256, align 8
  store i256 %29043, i256* %29045, align 4
  call void @__device_sstore(i256* %29044, i256* %29045)
  %29046 = call i32 @__hashword(i256* %29044)
  store i32 %29046, i32* %45, align 4, !nosanitize !3
  %29047 = trunc i256 %28462 to i64
  store i64 %29047, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.10020:                                           ; preds = %3189, %JumpTable
  %29048 = load i64, i64* %remaing_gas, align 4
  %29049 = icmp ugt i64 184, %29048
  br i1 %29049, label %Abort, label %29050

29050:                                            ; preds = %.10020
  %29051 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29052 = xor i32 %29051, 520
  %29053 = urem i32 %29052, 4096
  %29054 = getelementptr i8, i8 addrspace(1)* %4, i32 %29053
  %29055 = load i8, i8 addrspace(1)* %29054, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %29054, align 1, !nosanitize !3
  store i32 260, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29056 = sub i64 %29048, 184
  store i64 %29056, i64* %remaing_gas, align 4
  %29057 = load i256, i256* %0, align 4
  %29058 = and i256 1461501637330902918203684832716283019655932542975, %29057
  %29059 = alloca i256, align 8
  store i256 7, i256* %29059, align 4
  %29060 = alloca i256, align 8
  call void @__device_sload(i256* %29059, i256* %29060)
  %29061 = call i32 @__hashword(i256* %29059)
  %29062 = load i32, i32* %5, align 4
  %29063 = icmp eq i32 %29061, %29062
  %29064 = or i1 false, %29063
  %29065 = load i32, i32* %6, align 4
  %29066 = icmp eq i32 %29061, %29065
  %29067 = or i1 %29064, %29066
  %29068 = load i32, i32* %7, align 4
  %29069 = icmp eq i32 %29061, %29068
  %29070 = or i1 %29067, %29069
  %29071 = load i32, i32* %8, align 4
  %29072 = icmp eq i32 %29061, %29071
  %29073 = or i1 %29070, %29072
  %29074 = load i32, i32* %9, align 4
  %29075 = icmp eq i32 %29061, %29074
  %29076 = or i1 %29073, %29075
  %29077 = load i32, i32* %10, align 4
  %29078 = icmp eq i32 %29061, %29077
  %29079 = or i1 %29076, %29078
  %29080 = load i32, i32* %11, align 4
  %29081 = icmp eq i32 %29061, %29080
  %29082 = or i1 %29079, %29081
  %29083 = load i32, i32* %12, align 4
  %29084 = icmp eq i32 %29061, %29083
  %29085 = or i1 %29082, %29084
  %29086 = load i32, i32* %13, align 4
  %29087 = icmp eq i32 %29061, %29086
  %29088 = or i1 %29085, %29087
  %29089 = load i32, i32* %14, align 4
  %29090 = icmp eq i32 %29061, %29089
  %29091 = or i1 %29088, %29090
  %29092 = load i32, i32* %15, align 4
  %29093 = icmp eq i32 %29061, %29092
  %29094 = or i1 %29091, %29093
  %29095 = load i32, i32* %16, align 4
  %29096 = icmp eq i32 %29061, %29095
  %29097 = or i1 %29094, %29096
  %29098 = load i32, i32* %17, align 4
  %29099 = icmp eq i32 %29061, %29098
  %29100 = or i1 %29097, %29099
  %29101 = load i32, i32* %18, align 4
  %29102 = icmp eq i32 %29061, %29101
  %29103 = or i1 %29100, %29102
  %29104 = load i32, i32* %19, align 4
  %29105 = icmp eq i32 %29061, %29104
  %29106 = or i1 %29103, %29105
  %29107 = load i32, i32* %20, align 4
  %29108 = icmp eq i32 %29061, %29107
  %29109 = or i1 %29106, %29108
  %29110 = load i32, i32* %21, align 4
  %29111 = icmp eq i32 %29061, %29110
  %29112 = or i1 %29109, %29111
  %29113 = load i32, i32* %22, align 4
  %29114 = icmp eq i32 %29061, %29113
  %29115 = or i1 %29112, %29114
  %29116 = load i32, i32* %23, align 4
  %29117 = icmp eq i32 %29061, %29116
  %29118 = or i1 %29115, %29117
  %29119 = load i32, i32* %24, align 4
  %29120 = icmp eq i32 %29061, %29119
  %29121 = or i1 %29118, %29120
  %29122 = load i32, i32* %25, align 4
  %29123 = icmp eq i32 %29061, %29122
  %29124 = or i1 %29121, %29123
  %29125 = load i32, i32* %26, align 4
  %29126 = icmp eq i32 %29061, %29125
  %29127 = or i1 %29124, %29126
  %29128 = load i32, i32* %27, align 4
  %29129 = icmp eq i32 %29061, %29128
  %29130 = or i1 %29127, %29129
  %29131 = load i32, i32* %28, align 4
  %29132 = icmp eq i32 %29061, %29131
  %29133 = or i1 %29130, %29132
  %29134 = load i32, i32* %29, align 4
  %29135 = icmp eq i32 %29061, %29134
  %29136 = or i1 %29133, %29135
  %29137 = load i32, i32* %30, align 4
  %29138 = icmp eq i32 %29061, %29137
  %29139 = or i1 %29136, %29138
  %29140 = load i32, i32* %31, align 4
  %29141 = icmp eq i32 %29061, %29140
  %29142 = or i1 %29139, %29141
  %29143 = load i32, i32* %32, align 4
  %29144 = icmp eq i32 %29061, %29143
  %29145 = or i1 %29142, %29144
  %29146 = load i32, i32* %33, align 4
  %29147 = icmp eq i32 %29061, %29146
  %29148 = or i1 %29145, %29147
  %29149 = load i32, i32* %34, align 4
  %29150 = icmp eq i32 %29061, %29149
  %29151 = or i1 %29148, %29150
  %29152 = load i32, i32* %35, align 4
  %29153 = icmp eq i32 %29061, %29152
  %29154 = or i1 %29151, %29153
  %29155 = load i32, i32* %36, align 4
  %29156 = icmp eq i32 %29061, %29155
  %29157 = or i1 %29154, %29156
  %29158 = load i32, i32* %37, align 4
  %29159 = icmp eq i32 %29061, %29158
  %29160 = or i1 %29157, %29159
  %29161 = load i32, i32* %38, align 4
  %29162 = icmp eq i32 %29061, %29161
  %29163 = or i1 %29160, %29162
  %29164 = load i32, i32* %39, align 4
  %29165 = icmp eq i32 %29061, %29164
  %29166 = or i1 %29163, %29165
  %29167 = load i32, i32* %40, align 4
  %29168 = icmp eq i32 %29061, %29167
  %29169 = or i1 %29166, %29168
  %29170 = load i32, i32* %41, align 4
  %29171 = icmp eq i32 %29061, %29170
  %29172 = or i1 %29169, %29171
  %29173 = load i32, i32* %42, align 4
  %29174 = icmp eq i32 %29061, %29173
  %29175 = or i1 %29172, %29174
  %29176 = load i32, i32* %43, align 4
  %29177 = icmp eq i32 %29061, %29176
  %29178 = or i1 %29175, %29177
  %29179 = load i32, i32* %44, align 4
  %29180 = icmp eq i32 %29061, %29179
  %29181 = or i1 %29178, %29180
  %29182 = load i32, i32* %45, align 4
  %29183 = icmp eq i32 %29061, %29182
  %29184 = or i1 %29181, %29183
  %29185 = load i32, i32* %46, align 4
  %29186 = icmp eq i32 %29061, %29185
  %29187 = or i1 %29184, %29186
  %29188 = load i32, i32* %47, align 4
  %29189 = icmp eq i32 %29061, %29188
  %29190 = or i1 %29187, %29189
  %29191 = load i32, i32* %48, align 4
  %29192 = icmp eq i32 %29061, %29191
  %29193 = or i1 %29190, %29192
  %29194 = load i32, i32* %49, align 4
  %29195 = icmp eq i32 %29061, %29194
  %29196 = or i1 %29193, %29195
  %29197 = load i32, i32* %50, align 4
  %29198 = icmp eq i32 %29061, %29197
  %29199 = or i1 %29196, %29198
  %29200 = load i32, i32* %51, align 4
  %29201 = icmp eq i32 %29061, %29200
  %29202 = or i1 %29199, %29201
  %29203 = load i32, i32* %52, align 4
  %29204 = icmp eq i32 %29061, %29203
  %29205 = or i1 %29202, %29204
  %29206 = load i32, i32* %53, align 4
  %29207 = icmp eq i32 %29061, %29206
  %29208 = or i1 %29205, %29207
  %29209 = load i32, i32* %54, align 4
  %29210 = icmp eq i32 %29061, %29209
  %29211 = or i1 %29208, %29210
  %29212 = load i32, i32* %55, align 4
  %29213 = icmp eq i32 %29061, %29212
  %29214 = or i1 %29211, %29213
  %29215 = load i32, i32* %56, align 4
  %29216 = icmp eq i32 %29061, %29215
  %29217 = or i1 %29214, %29216
  %29218 = load i32, i32* %57, align 4
  %29219 = icmp eq i32 %29061, %29218
  %29220 = or i1 %29217, %29219
  %29221 = load i32, i32* %58, align 4
  %29222 = icmp eq i32 %29061, %29221
  %29223 = or i1 %29220, %29222
  %29224 = load i32, i32* %59, align 4
  %29225 = icmp eq i32 %29061, %29224
  %29226 = or i1 %29223, %29225
  %29227 = load i32, i32* %60, align 4
  %29228 = icmp eq i32 %29061, %29227
  %29229 = or i1 %29226, %29228
  %29230 = load i32, i32* %61, align 4
  %29231 = icmp eq i32 %29061, %29230
  %29232 = or i1 %29229, %29231
  %29233 = load i32, i32* %62, align 4
  %29234 = icmp eq i32 %29061, %29233
  %29235 = or i1 %29232, %29234
  %29236 = getelementptr i8, i8 addrspace(1)* %4, i32 103
  %29237 = zext i1 %29235 to i8
  store i8 %29237, i8 addrspace(1)* %29236, align 1, !nosanitize !3
  %29238 = load i256, i256* %29060, align 4
  %29239 = alloca i256, align 8
  store i256 %29238, i256* %29239, align 4
  %29240 = alloca i256, align 8
  store i256 1, i256* %29240, align 4
  %29241 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %29239, i256* %29240, i256* %29241), !pc !451, !intsan !6
  %29242 = load i256, i256* %29241, align 4
  %29243 = and i256 1461501637330902918203684832716283019655932542975, %29242
  %29244 = and i256 1461501637330902918203684832716283019655932542975, %29243
  %29245 = icmp eq i256 %29244, %29058
  %29246 = icmp eq i1 %29245, false
  %29247 = icmp eq i1 %29246, false
  %29248 = trunc i256 10112 to i64
  %jump.check151 = icmp ne i1 %29247, false
  br i1 %jump.check151, label %.10112, label %.10108, !EVMBB !4

.10108:                                           ; preds = %29050
  %29249 = load i64, i64* %remaing_gas, align 4
  %29250 = icmp ugt i64 16, %29249
  br i1 %29250, label %Abort, label %29251

29251:                                            ; preds = %.10108
  %29252 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29253 = xor i32 %29252, 3573
  %29254 = urem i32 %29253, 4096
  %29255 = getelementptr i8, i8 addrspace(1)* %4, i32 %29254
  %29256 = load i8, i8 addrspace(1)* %29255, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %29255, align 1, !nosanitize !3
  store i32 1786, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29257 = sub i64 %29249, 16
  store i64 %29257, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10112:                                           ; preds = %29050, %JumpTable
  %29258 = load i64, i64* %remaing_gas, align 4
  %29259 = icmp ugt i64 312, %29258
  br i1 %29259, label %Abort, label %29260

29260:                                            ; preds = %.10112
  %29261 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29262 = xor i32 %29261, 3049
  %29263 = urem i32 %29262, 4096
  %29264 = getelementptr i8, i8 addrspace(1)* %4, i32 %29263
  %29265 = load i8, i8 addrspace(1)* %29264, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %29264, align 1, !nosanitize !3
  store i32 1524, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29266 = sub i64 %29258, 312
  store i64 %29266, i64* %remaing_gas, align 4
  %29267 = load i64, i64* %STACK_DEP_PTR, align 4
  %29268 = getelementptr i256, i256* %STACK, i64 %29267
  %29269 = load i256, i256* %29268, align 4
  %29270 = load i64, i64* %STACK_DEP_PTR, align 4
  %29271 = sub i64 %29270, 1
  store i64 %29271, i64* %STACK_DEP_PTR, align 4
  %29272 = alloca i256, align 8
  store i256 8, i256* %29272, align 4
  %29273 = alloca i256, align 8
  call void @__device_sload(i256* %29272, i256* %29273)
  %29274 = call i32 @__hashword(i256* %29272)
  %29275 = load i32, i32* %5, align 4
  %29276 = icmp eq i32 %29274, %29275
  %29277 = or i1 false, %29276
  %29278 = load i32, i32* %6, align 4
  %29279 = icmp eq i32 %29274, %29278
  %29280 = or i1 %29277, %29279
  %29281 = load i32, i32* %7, align 4
  %29282 = icmp eq i32 %29274, %29281
  %29283 = or i1 %29280, %29282
  %29284 = load i32, i32* %8, align 4
  %29285 = icmp eq i32 %29274, %29284
  %29286 = or i1 %29283, %29285
  %29287 = load i32, i32* %9, align 4
  %29288 = icmp eq i32 %29274, %29287
  %29289 = or i1 %29286, %29288
  %29290 = load i32, i32* %10, align 4
  %29291 = icmp eq i32 %29274, %29290
  %29292 = or i1 %29289, %29291
  %29293 = load i32, i32* %11, align 4
  %29294 = icmp eq i32 %29274, %29293
  %29295 = or i1 %29292, %29294
  %29296 = load i32, i32* %12, align 4
  %29297 = icmp eq i32 %29274, %29296
  %29298 = or i1 %29295, %29297
  %29299 = load i32, i32* %13, align 4
  %29300 = icmp eq i32 %29274, %29299
  %29301 = or i1 %29298, %29300
  %29302 = load i32, i32* %14, align 4
  %29303 = icmp eq i32 %29274, %29302
  %29304 = or i1 %29301, %29303
  %29305 = load i32, i32* %15, align 4
  %29306 = icmp eq i32 %29274, %29305
  %29307 = or i1 %29304, %29306
  %29308 = load i32, i32* %16, align 4
  %29309 = icmp eq i32 %29274, %29308
  %29310 = or i1 %29307, %29309
  %29311 = load i32, i32* %17, align 4
  %29312 = icmp eq i32 %29274, %29311
  %29313 = or i1 %29310, %29312
  %29314 = load i32, i32* %18, align 4
  %29315 = icmp eq i32 %29274, %29314
  %29316 = or i1 %29313, %29315
  %29317 = load i32, i32* %19, align 4
  %29318 = icmp eq i32 %29274, %29317
  %29319 = or i1 %29316, %29318
  %29320 = load i32, i32* %20, align 4
  %29321 = icmp eq i32 %29274, %29320
  %29322 = or i1 %29319, %29321
  %29323 = load i32, i32* %21, align 4
  %29324 = icmp eq i32 %29274, %29323
  %29325 = or i1 %29322, %29324
  %29326 = load i32, i32* %22, align 4
  %29327 = icmp eq i32 %29274, %29326
  %29328 = or i1 %29325, %29327
  %29329 = load i32, i32* %23, align 4
  %29330 = icmp eq i32 %29274, %29329
  %29331 = or i1 %29328, %29330
  %29332 = load i32, i32* %24, align 4
  %29333 = icmp eq i32 %29274, %29332
  %29334 = or i1 %29331, %29333
  %29335 = load i32, i32* %25, align 4
  %29336 = icmp eq i32 %29274, %29335
  %29337 = or i1 %29334, %29336
  %29338 = load i32, i32* %26, align 4
  %29339 = icmp eq i32 %29274, %29338
  %29340 = or i1 %29337, %29339
  %29341 = load i32, i32* %27, align 4
  %29342 = icmp eq i32 %29274, %29341
  %29343 = or i1 %29340, %29342
  %29344 = load i32, i32* %28, align 4
  %29345 = icmp eq i32 %29274, %29344
  %29346 = or i1 %29343, %29345
  %29347 = load i32, i32* %29, align 4
  %29348 = icmp eq i32 %29274, %29347
  %29349 = or i1 %29346, %29348
  %29350 = load i32, i32* %30, align 4
  %29351 = icmp eq i32 %29274, %29350
  %29352 = or i1 %29349, %29351
  %29353 = load i32, i32* %31, align 4
  %29354 = icmp eq i32 %29274, %29353
  %29355 = or i1 %29352, %29354
  %29356 = load i32, i32* %32, align 4
  %29357 = icmp eq i32 %29274, %29356
  %29358 = or i1 %29355, %29357
  %29359 = load i32, i32* %33, align 4
  %29360 = icmp eq i32 %29274, %29359
  %29361 = or i1 %29358, %29360
  %29362 = load i32, i32* %34, align 4
  %29363 = icmp eq i32 %29274, %29362
  %29364 = or i1 %29361, %29363
  %29365 = load i32, i32* %35, align 4
  %29366 = icmp eq i32 %29274, %29365
  %29367 = or i1 %29364, %29366
  %29368 = load i32, i32* %36, align 4
  %29369 = icmp eq i32 %29274, %29368
  %29370 = or i1 %29367, %29369
  %29371 = load i32, i32* %37, align 4
  %29372 = icmp eq i32 %29274, %29371
  %29373 = or i1 %29370, %29372
  %29374 = load i32, i32* %38, align 4
  %29375 = icmp eq i32 %29274, %29374
  %29376 = or i1 %29373, %29375
  %29377 = load i32, i32* %39, align 4
  %29378 = icmp eq i32 %29274, %29377
  %29379 = or i1 %29376, %29378
  %29380 = load i32, i32* %40, align 4
  %29381 = icmp eq i32 %29274, %29380
  %29382 = or i1 %29379, %29381
  %29383 = load i32, i32* %41, align 4
  %29384 = icmp eq i32 %29274, %29383
  %29385 = or i1 %29382, %29384
  %29386 = load i32, i32* %42, align 4
  %29387 = icmp eq i32 %29274, %29386
  %29388 = or i1 %29385, %29387
  %29389 = load i32, i32* %43, align 4
  %29390 = icmp eq i32 %29274, %29389
  %29391 = or i1 %29388, %29390
  %29392 = load i32, i32* %44, align 4
  %29393 = icmp eq i32 %29274, %29392
  %29394 = or i1 %29391, %29393
  %29395 = load i32, i32* %45, align 4
  %29396 = icmp eq i32 %29274, %29395
  %29397 = or i1 %29394, %29396
  %29398 = load i32, i32* %46, align 4
  %29399 = icmp eq i32 %29274, %29398
  %29400 = or i1 %29397, %29399
  %29401 = load i32, i32* %47, align 4
  %29402 = icmp eq i32 %29274, %29401
  %29403 = or i1 %29400, %29402
  %29404 = load i32, i32* %48, align 4
  %29405 = icmp eq i32 %29274, %29404
  %29406 = or i1 %29403, %29405
  %29407 = load i32, i32* %49, align 4
  %29408 = icmp eq i32 %29274, %29407
  %29409 = or i1 %29406, %29408
  %29410 = load i32, i32* %50, align 4
  %29411 = icmp eq i32 %29274, %29410
  %29412 = or i1 %29409, %29411
  %29413 = load i32, i32* %51, align 4
  %29414 = icmp eq i32 %29274, %29413
  %29415 = or i1 %29412, %29414
  %29416 = load i32, i32* %52, align 4
  %29417 = icmp eq i32 %29274, %29416
  %29418 = or i1 %29415, %29417
  %29419 = load i32, i32* %53, align 4
  %29420 = icmp eq i32 %29274, %29419
  %29421 = or i1 %29418, %29420
  %29422 = load i32, i32* %54, align 4
  %29423 = icmp eq i32 %29274, %29422
  %29424 = or i1 %29421, %29423
  %29425 = load i32, i32* %55, align 4
  %29426 = icmp eq i32 %29274, %29425
  %29427 = or i1 %29424, %29426
  %29428 = load i32, i32* %56, align 4
  %29429 = icmp eq i32 %29274, %29428
  %29430 = or i1 %29427, %29429
  %29431 = load i32, i32* %57, align 4
  %29432 = icmp eq i32 %29274, %29431
  %29433 = or i1 %29430, %29432
  %29434 = load i32, i32* %58, align 4
  %29435 = icmp eq i32 %29274, %29434
  %29436 = or i1 %29433, %29435
  %29437 = load i32, i32* %59, align 4
  %29438 = icmp eq i32 %29274, %29437
  %29439 = or i1 %29436, %29438
  %29440 = load i32, i32* %60, align 4
  %29441 = icmp eq i32 %29274, %29440
  %29442 = or i1 %29439, %29441
  %29443 = load i32, i32* %61, align 4
  %29444 = icmp eq i32 %29274, %29443
  %29445 = or i1 %29442, %29444
  %29446 = load i32, i32* %62, align 4
  %29447 = icmp eq i32 %29274, %29446
  %29448 = or i1 %29445, %29447
  %29449 = getelementptr i8, i8 addrspace(1)* %4, i32 104
  %29450 = zext i1 %29448 to i8
  store i8 %29450, i8 addrspace(1)* %29449, align 1, !nosanitize !3
  %29451 = load i256, i256* %29273, align 4
  %29452 = mul i256 255, 1461501637330902918203684832716283019655932542976, !pc !452, !intsan !45
  %29453 = xor i256 %29452, -1
  %29454 = and i256 %29453, %29451
  %29455 = icmp eq i256 0, 0
  %29456 = icmp eq i1 %29455, false
  %29457 = zext i1 %29456 to i256
  %29458 = mul i256 %29457, 1461501637330902918203684832716283019655932542976, !pc !453, !intsan !45
  %29459 = or i256 %29458, %29454
  %29460 = alloca i256, align 8
  store i256 8, i256* %29460, align 4
  %29461 = alloca i256, align 8
  store i256 %29459, i256* %29461, align 4
  call void @__device_sstore(i256* %29460, i256* %29461)
  %29462 = call i32 @__hashword(i256* %29460)
  store i32 %29462, i32* %28, align 4, !nosanitize !3
  %29463 = trunc i256 64 to i64
  %29464 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %29463, i256* %29464)
  %29465 = load i256, i256* %29464, align 4
  %29466 = trunc i256 64 to i64
  %29467 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %29466, i256* %29467)
  %29468 = load i256, i256* %29467, align 4
  %29469 = sub i256 %29465, %29468, !pc !454, !intsan !8
  %29470 = trunc i256 -37102079373851706393549047746528126238530227433109643269702590601622118845341 to i64
  call void @addBugSet(i64 %29470)
  %29471 = trunc i256 %29269 to i64
  store i64 %29471, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.10185:                                           ; preds = %3244, %JumpTable
  %29472 = load i64, i64* %remaing_gas, align 4
  %29473 = icmp ugt i64 664, %29472
  br i1 %29473, label %Abort, label %29474

29474:                                            ; preds = %.10185
  %29475 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29476 = xor i32 %29475, 3042
  %29477 = urem i32 %29476, 4096
  %29478 = getelementptr i8, i8 addrspace(1)* %4, i32 %29477
  %29479 = load i8, i8 addrspace(1)* %29478, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %29478, align 1, !nosanitize !3
  store i32 1521, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %29480 = sub i64 %29472, 664
  store i64 %29480, i64* %remaing_gas, align 4
  %29481 = load i64, i64* %STACK_DEP_PTR, align 4
  %29482 = getelementptr i256, i256* %STACK, i64 %29481
  %29483 = load i256, i256* %29482, align 4
  %29484 = load i64, i64* %STACK_DEP_PTR, align 4
  %29485 = sub i64 %29484, 1
  store i64 %29485, i64* %STACK_DEP_PTR, align 4
  %29486 = load i64, i64* %STACK_DEP_PTR, align 4
  %29487 = getelementptr i256, i256* %STACK, i64 %29486
  %29488 = load i256, i256* %29487, align 4
  %29489 = load i64, i64* %STACK_DEP_PTR, align 4
  %29490 = sub i64 %29489, 1
  store i64 %29490, i64* %STACK_DEP_PTR, align 4
  %29491 = trunc i256 32 to i64
  %29492 = alloca i256, align 8
  store i256 11, i256* %29492, align 4
  %29493 = bitcast i256* %29492 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %29491, i8* %29493, i64 32)
  %29494 = trunc i256 0 to i64
  %29495 = alloca i256, align 8
  store i256 %29483, i256* %29495, align 4
  %29496 = bitcast i256* %29495 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %29494, i8* %29496, i64 32)
  %29497 = trunc i256 0 to i32
  %29498 = trunc i256 64 to i32
  %29499 = getelementptr inbounds i8, i8* %MEMORY, i32 %29497
  %29500 = alloca i256, align 8
  %29501 = bitcast i256* %29500 to i8*
  call void @__device_sha3(i8* %29499, i32 %29498, i8* %29501)
  %29502 = load i256, i256* %29500, align 4
  %29503 = add i256 0, %29502, !pc !455, !intsan !10
  %29504 = alloca i256, align 8
  store i256 %29503, i256* %29504, align 4
  %29505 = alloca i256, align 8
  call void @__device_sload(i256* %29504, i256* %29505)
  %29506 = call i32 @__hashword(i256* %29504)
  %29507 = load i32, i32* %5, align 4
  %29508 = icmp eq i32 %29506, %29507
  %29509 = or i1 false, %29508
  %29510 = load i32, i32* %6, align 4
  %29511 = icmp eq i32 %29506, %29510
  %29512 = or i1 %29509, %29511
  %29513 = load i32, i32* %7, align 4
  %29514 = icmp eq i32 %29506, %29513
  %29515 = or i1 %29512, %29514
  %29516 = load i32, i32* %8, align 4
  %29517 = icmp eq i32 %29506, %29516
  %29518 = or i1 %29515, %29517
  %29519 = load i32, i32* %9, align 4
  %29520 = icmp eq i32 %29506, %29519
  %29521 = or i1 %29518, %29520
  %29522 = load i32, i32* %10, align 4
  %29523 = icmp eq i32 %29506, %29522
  %29524 = or i1 %29521, %29523
  %29525 = load i32, i32* %11, align 4
  %29526 = icmp eq i32 %29506, %29525
  %29527 = or i1 %29524, %29526
  %29528 = load i32, i32* %12, align 4
  %29529 = icmp eq i32 %29506, %29528
  %29530 = or i1 %29527, %29529
  %29531 = load i32, i32* %13, align 4
  %29532 = icmp eq i32 %29506, %29531
  %29533 = or i1 %29530, %29532
  %29534 = load i32, i32* %14, align 4
  %29535 = icmp eq i32 %29506, %29534
  %29536 = or i1 %29533, %29535
  %29537 = load i32, i32* %15, align 4
  %29538 = icmp eq i32 %29506, %29537
  %29539 = or i1 %29536, %29538
  %29540 = load i32, i32* %16, align 4
  %29541 = icmp eq i32 %29506, %29540
  %29542 = or i1 %29539, %29541
  %29543 = load i32, i32* %17, align 4
  %29544 = icmp eq i32 %29506, %29543
  %29545 = or i1 %29542, %29544
  %29546 = load i32, i32* %18, align 4
  %29547 = icmp eq i32 %29506, %29546
  %29548 = or i1 %29545, %29547
  %29549 = load i32, i32* %19, align 4
  %29550 = icmp eq i32 %29506, %29549
  %29551 = or i1 %29548, %29550
  %29552 = load i32, i32* %20, align 4
  %29553 = icmp eq i32 %29506, %29552
  %29554 = or i1 %29551, %29553
  %29555 = load i32, i32* %21, align 4
  %29556 = icmp eq i32 %29506, %29555
  %29557 = or i1 %29554, %29556
  %29558 = load i32, i32* %22, align 4
  %29559 = icmp eq i32 %29506, %29558
  %29560 = or i1 %29557, %29559
  %29561 = load i32, i32* %23, align 4
  %29562 = icmp eq i32 %29506, %29561
  %29563 = or i1 %29560, %29562
  %29564 = load i32, i32* %24, align 4
  %29565 = icmp eq i32 %29506, %29564
  %29566 = or i1 %29563, %29565
  %29567 = load i32, i32* %25, align 4
  %29568 = icmp eq i32 %29506, %29567
  %29569 = or i1 %29566, %29568
  %29570 = load i32, i32* %26, align 4
  %29571 = icmp eq i32 %29506, %29570
  %29572 = or i1 %29569, %29571
  %29573 = load i32, i32* %27, align 4
  %29574 = icmp eq i32 %29506, %29573
  %29575 = or i1 %29572, %29574
  %29576 = load i32, i32* %28, align 4
  %29577 = icmp eq i32 %29506, %29576
  %29578 = or i1 %29575, %29577
  %29579 = load i32, i32* %29, align 4
  %29580 = icmp eq i32 %29506, %29579
  %29581 = or i1 %29578, %29580
  %29582 = load i32, i32* %30, align 4
  %29583 = icmp eq i32 %29506, %29582
  %29584 = or i1 %29581, %29583
  %29585 = load i32, i32* %31, align 4
  %29586 = icmp eq i32 %29506, %29585
  %29587 = or i1 %29584, %29586
  %29588 = load i32, i32* %32, align 4
  %29589 = icmp eq i32 %29506, %29588
  %29590 = or i1 %29587, %29589
  %29591 = load i32, i32* %33, align 4
  %29592 = icmp eq i32 %29506, %29591
  %29593 = or i1 %29590, %29592
  %29594 = load i32, i32* %34, align 4
  %29595 = icmp eq i32 %29506, %29594
  %29596 = or i1 %29593, %29595
  %29597 = load i32, i32* %35, align 4
  %29598 = icmp eq i32 %29506, %29597
  %29599 = or i1 %29596, %29598
  %29600 = load i32, i32* %36, align 4
  %29601 = icmp eq i32 %29506, %29600
  %29602 = or i1 %29599, %29601
  %29603 = load i32, i32* %37, align 4
  %29604 = icmp eq i32 %29506, %29603
  %29605 = or i1 %29602, %29604
  %29606 = load i32, i32* %38, align 4
  %29607 = icmp eq i32 %29506, %29606
  %29608 = or i1 %29605, %29607
  %29609 = load i32, i32* %39, align 4
  %29610 = icmp eq i32 %29506, %29609
  %29611 = or i1 %29608, %29610
  %29612 = load i32, i32* %40, align 4
  %29613 = icmp eq i32 %29506, %29612
  %29614 = or i1 %29611, %29613
  %29615 = load i32, i32* %41, align 4
  %29616 = icmp eq i32 %29506, %29615
  %29617 = or i1 %29614, %29616
  %29618 = load i32, i32* %42, align 4
  %29619 = icmp eq i32 %29506, %29618
  %29620 = or i1 %29617, %29619
  %29621 = load i32, i32* %43, align 4
  %29622 = icmp eq i32 %29506, %29621
  %29623 = or i1 %29620, %29622
  %29624 = load i32, i32* %44, align 4
  %29625 = icmp eq i32 %29506, %29624
  %29626 = or i1 %29623, %29625
  %29627 = load i32, i32* %45, align 4
  %29628 = icmp eq i32 %29506, %29627
  %29629 = or i1 %29626, %29628
  %29630 = load i32, i32* %46, align 4
  %29631 = icmp eq i32 %29506, %29630
  %29632 = or i1 %29629, %29631
  %29633 = load i32, i32* %47, align 4
  %29634 = icmp eq i32 %29506, %29633
  %29635 = or i1 %29632, %29634
  %29636 = load i32, i32* %48, align 4
  %29637 = icmp eq i32 %29506, %29636
  %29638 = or i1 %29635, %29637
  %29639 = load i32, i32* %49, align 4
  %29640 = icmp eq i32 %29506, %29639
  %29641 = or i1 %29638, %29640
  %29642 = load i32, i32* %50, align 4
  %29643 = icmp eq i32 %29506, %29642
  %29644 = or i1 %29641, %29643
  %29645 = load i32, i32* %51, align 4
  %29646 = icmp eq i32 %29506, %29645
  %29647 = or i1 %29644, %29646
  %29648 = load i32, i32* %52, align 4
  %29649 = icmp eq i32 %29506, %29648
  %29650 = or i1 %29647, %29649
  %29651 = load i32, i32* %53, align 4
  %29652 = icmp eq i32 %29506, %29651
  %29653 = or i1 %29650, %29652
  %29654 = load i32, i32* %54, align 4
  %29655 = icmp eq i32 %29506, %29654
  %29656 = or i1 %29653, %29655
  %29657 = load i32, i32* %55, align 4
  %29658 = icmp eq i32 %29506, %29657
  %29659 = or i1 %29656, %29658
  %29660 = load i32, i32* %56, align 4
  %29661 = icmp eq i32 %29506, %29660
  %29662 = or i1 %29659, %29661
  %29663 = load i32, i32* %57, align 4
  %29664 = icmp eq i32 %29506, %29663
  %29665 = or i1 %29662, %29664
  %29666 = load i32, i32* %58, align 4
  %29667 = icmp eq i32 %29506, %29666
  %29668 = or i1 %29665, %29667
  %29669 = load i32, i32* %59, align 4
  %29670 = icmp eq i32 %29506, %29669
  %29671 = or i1 %29668, %29670
  %29672 = load i32, i32* %60, align 4
  %29673 = icmp eq i32 %29506, %29672
  %29674 = or i1 %29671, %29673
  %29675 = load i32, i32* %61, align 4
  %29676 = icmp eq i32 %29506, %29675
  %29677 = or i1 %29674, %29676
  %29678 = load i32, i32* %62, align 4
  %29679 = icmp eq i32 %29506, %29678
  %29680 = or i1 %29677, %29679
  %29681 = getelementptr i8, i8 addrspace(1)* %4, i32 105
  %29682 = zext i1 %29680 to i8
  store i8 %29682, i8 addrspace(1)* %29681, align 1, !nosanitize !3
  %29683 = load i256, i256* %29505, align 4
  %29684 = alloca i256, align 8
  store i256 %29683, i256* %29684, align 4
  %29685 = alloca i256, align 8
  store i256 1, i256* %29685, align 4
  %29686 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %29684, i256* %29685, i256* %29686), !pc !456, !intsan !6
  %29687 = load i256, i256* %29686, align 4
  %29688 = and i256 1461501637330902918203684832716283019655932542975, %29687
  %29689 = add i256 1, %29502, !pc !457, !intsan !10
  %29690 = alloca i256, align 8
  store i256 %29689, i256* %29690, align 4
  %29691 = alloca i256, align 8
  call void @__device_sload(i256* %29690, i256* %29691)
  %29692 = call i32 @__hashword(i256* %29690)
  %29693 = load i32, i32* %5, align 4
  %29694 = icmp eq i32 %29692, %29693
  %29695 = or i1 false, %29694
  %29696 = load i32, i32* %6, align 4
  %29697 = icmp eq i32 %29692, %29696
  %29698 = or i1 %29695, %29697
  %29699 = load i32, i32* %7, align 4
  %29700 = icmp eq i32 %29692, %29699
  %29701 = or i1 %29698, %29700
  %29702 = load i32, i32* %8, align 4
  %29703 = icmp eq i32 %29692, %29702
  %29704 = or i1 %29701, %29703
  %29705 = load i32, i32* %9, align 4
  %29706 = icmp eq i32 %29692, %29705
  %29707 = or i1 %29704, %29706
  %29708 = load i32, i32* %10, align 4
  %29709 = icmp eq i32 %29692, %29708
  %29710 = or i1 %29707, %29709
  %29711 = load i32, i32* %11, align 4
  %29712 = icmp eq i32 %29692, %29711
  %29713 = or i1 %29710, %29712
  %29714 = load i32, i32* %12, align 4
  %29715 = icmp eq i32 %29692, %29714
  %29716 = or i1 %29713, %29715
  %29717 = load i32, i32* %13, align 4
  %29718 = icmp eq i32 %29692, %29717
  %29719 = or i1 %29716, %29718
  %29720 = load i32, i32* %14, align 4
  %29721 = icmp eq i32 %29692, %29720
  %29722 = or i1 %29719, %29721
  %29723 = load i32, i32* %15, align 4
  %29724 = icmp eq i32 %29692, %29723
  %29725 = or i1 %29722, %29724
  %29726 = load i32, i32* %16, align 4
  %29727 = icmp eq i32 %29692, %29726
  %29728 = or i1 %29725, %29727
  %29729 = load i32, i32* %17, align 4
  %29730 = icmp eq i32 %29692, %29729
  %29731 = or i1 %29728, %29730
  %29732 = load i32, i32* %18, align 4
  %29733 = icmp eq i32 %29692, %29732
  %29734 = or i1 %29731, %29733
  %29735 = load i32, i32* %19, align 4
  %29736 = icmp eq i32 %29692, %29735
  %29737 = or i1 %29734, %29736
  %29738 = load i32, i32* %20, align 4
  %29739 = icmp eq i32 %29692, %29738
  %29740 = or i1 %29737, %29739
  %29741 = load i32, i32* %21, align 4
  %29742 = icmp eq i32 %29692, %29741
  %29743 = or i1 %29740, %29742
  %29744 = load i32, i32* %22, align 4
  %29745 = icmp eq i32 %29692, %29744
  %29746 = or i1 %29743, %29745
  %29747 = load i32, i32* %23, align 4
  %29748 = icmp eq i32 %29692, %29747
  %29749 = or i1 %29746, %29748
  %29750 = load i32, i32* %24, align 4
  %29751 = icmp eq i32 %29692, %29750
  %29752 = or i1 %29749, %29751
  %29753 = load i32, i32* %25, align 4
  %29754 = icmp eq i32 %29692, %29753
  %29755 = or i1 %29752, %29754
  %29756 = load i32, i32* %26, align 4
  %29757 = icmp eq i32 %29692, %29756
  %29758 = or i1 %29755, %29757
  %29759 = load i32, i32* %27, align 4
  %29760 = icmp eq i32 %29692, %29759
  %29761 = or i1 %29758, %29760
  %29762 = load i32, i32* %28, align 4
  %29763 = icmp eq i32 %29692, %29762
  %29764 = or i1 %29761, %29763
  %29765 = load i32, i32* %29, align 4
  %29766 = icmp eq i32 %29692, %29765
  %29767 = or i1 %29764, %29766
  %29768 = load i32, i32* %30, align 4
  %29769 = icmp eq i32 %29692, %29768
  %29770 = or i1 %29767, %29769
  %29771 = load i32, i32* %31, align 4
  %29772 = icmp eq i32 %29692, %29771
  %29773 = or i1 %29770, %29772
  %29774 = load i32, i32* %32, align 4
  %29775 = icmp eq i32 %29692, %29774
  %29776 = or i1 %29773, %29775
  %29777 = load i32, i32* %33, align 4
  %29778 = icmp eq i32 %29692, %29777
  %29779 = or i1 %29776, %29778
  %29780 = load i32, i32* %34, align 4
  %29781 = icmp eq i32 %29692, %29780
  %29782 = or i1 %29779, %29781
  %29783 = load i32, i32* %35, align 4
  %29784 = icmp eq i32 %29692, %29783
  %29785 = or i1 %29782, %29784
  %29786 = load i32, i32* %36, align 4
  %29787 = icmp eq i32 %29692, %29786
  %29788 = or i1 %29785, %29787
  %29789 = load i32, i32* %37, align 4
  %29790 = icmp eq i32 %29692, %29789
  %29791 = or i1 %29788, %29790
  %29792 = load i32, i32* %38, align 4
  %29793 = icmp eq i32 %29692, %29792
  %29794 = or i1 %29791, %29793
  %29795 = load i32, i32* %39, align 4
  %29796 = icmp eq i32 %29692, %29795
  %29797 = or i1 %29794, %29796
  %29798 = load i32, i32* %40, align 4
  %29799 = icmp eq i32 %29692, %29798
  %29800 = or i1 %29797, %29799
  %29801 = load i32, i32* %41, align 4
  %29802 = icmp eq i32 %29692, %29801
  %29803 = or i1 %29800, %29802
  %29804 = load i32, i32* %42, align 4
  %29805 = icmp eq i32 %29692, %29804
  %29806 = or i1 %29803, %29805
  %29807 = load i32, i32* %43, align 4
  %29808 = icmp eq i32 %29692, %29807
  %29809 = or i1 %29806, %29808
  %29810 = load i32, i32* %44, align 4
  %29811 = icmp eq i32 %29692, %29810
  %29812 = or i1 %29809, %29811
  %29813 = load i32, i32* %45, align 4
  %29814 = icmp eq i32 %29692, %29813
  %29815 = or i1 %29812, %29814
  %29816 = load i32, i32* %46, align 4
  %29817 = icmp eq i32 %29692, %29816
  %29818 = or i1 %29815, %29817
  %29819 = load i32, i32* %47, align 4
  %29820 = icmp eq i32 %29692, %29819
  %29821 = or i1 %29818, %29820
  %29822 = load i32, i32* %48, align 4
  %29823 = icmp eq i32 %29692, %29822
  %29824 = or i1 %29821, %29823
  %29825 = load i32, i32* %49, align 4
  %29826 = icmp eq i32 %29692, %29825
  %29827 = or i1 %29824, %29826
  %29828 = load i32, i32* %50, align 4
  %29829 = icmp eq i32 %29692, %29828
  %29830 = or i1 %29827, %29829
  %29831 = load i32, i32* %51, align 4
  %29832 = icmp eq i32 %29692, %29831
  %29833 = or i1 %29830, %29832
  %29834 = load i32, i32* %52, align 4
  %29835 = icmp eq i32 %29692, %29834
  %29836 = or i1 %29833, %29835
  %29837 = load i32, i32* %53, align 4
  %29838 = icmp eq i32 %29692, %29837
  %29839 = or i1 %29836, %29838
  %29840 = load i32, i32* %54, align 4
  %29841 = icmp eq i32 %29692, %29840
  %29842 = or i1 %29839, %29841
  %29843 = load i32, i32* %55, align 4
  %29844 = icmp eq i32 %29692, %29843
  %29845 = or i1 %29842, %29844
  %29846 = load i32, i32* %56, align 4
  %29847 = icmp eq i32 %29692, %29846
  %29848 = or i1 %29845, %29847
  %29849 = load i32, i32* %57, align 4
  %29850 = icmp eq i32 %29692, %29849
  %29851 = or i1 %29848, %29850
  %29852 = load i32, i32* %58, align 4
  %29853 = icmp eq i32 %29692, %29852
  %29854 = or i1 %29851, %29853
  %29855 = load i32, i32* %59, align 4
  %29856 = icmp eq i32 %29692, %29855
  %29857 = or i1 %29854, %29856
  %29858 = load i32, i32* %60, align 4
  %29859 = icmp eq i32 %29692, %29858
  %29860 = or i1 %29857, %29859
  %29861 = load i32, i32* %61, align 4
  %29862 = icmp eq i32 %29692, %29861
  %29863 = or i1 %29860, %29862
  %29864 = load i32, i32* %62, align 4
  %29865 = icmp eq i32 %29692, %29864
  %29866 = or i1 %29863, %29865
  %29867 = getelementptr i8, i8 addrspace(1)* %4, i32 106
  %29868 = zext i1 %29866 to i8
  store i8 %29868, i8 addrspace(1)* %29867, align 1, !nosanitize !3
  %29869 = load i256, i256* %29691, align 4
  %29870 = add i256 2, %29502, !pc !458, !intsan !10
  %29871 = alloca i256, align 8
  store i256 %29870, i256* %29871, align 4
  %29872 = alloca i256, align 8
  call void @__device_sload(i256* %29871, i256* %29872)
  %29873 = call i32 @__hashword(i256* %29871)
  %29874 = load i32, i32* %5, align 4
  %29875 = icmp eq i32 %29873, %29874
  %29876 = or i1 false, %29875
  %29877 = load i32, i32* %6, align 4
  %29878 = icmp eq i32 %29873, %29877
  %29879 = or i1 %29876, %29878
  %29880 = load i32, i32* %7, align 4
  %29881 = icmp eq i32 %29873, %29880
  %29882 = or i1 %29879, %29881
  %29883 = load i32, i32* %8, align 4
  %29884 = icmp eq i32 %29873, %29883
  %29885 = or i1 %29882, %29884
  %29886 = load i32, i32* %9, align 4
  %29887 = icmp eq i32 %29873, %29886
  %29888 = or i1 %29885, %29887
  %29889 = load i32, i32* %10, align 4
  %29890 = icmp eq i32 %29873, %29889
  %29891 = or i1 %29888, %29890
  %29892 = load i32, i32* %11, align 4
  %29893 = icmp eq i32 %29873, %29892
  %29894 = or i1 %29891, %29893
  %29895 = load i32, i32* %12, align 4
  %29896 = icmp eq i32 %29873, %29895
  %29897 = or i1 %29894, %29896
  %29898 = load i32, i32* %13, align 4
  %29899 = icmp eq i32 %29873, %29898
  %29900 = or i1 %29897, %29899
  %29901 = load i32, i32* %14, align 4
  %29902 = icmp eq i32 %29873, %29901
  %29903 = or i1 %29900, %29902
  %29904 = load i32, i32* %15, align 4
  %29905 = icmp eq i32 %29873, %29904
  %29906 = or i1 %29903, %29905
  %29907 = load i32, i32* %16, align 4
  %29908 = icmp eq i32 %29873, %29907
  %29909 = or i1 %29906, %29908
  %29910 = load i32, i32* %17, align 4
  %29911 = icmp eq i32 %29873, %29910
  %29912 = or i1 %29909, %29911
  %29913 = load i32, i32* %18, align 4
  %29914 = icmp eq i32 %29873, %29913
  %29915 = or i1 %29912, %29914
  %29916 = load i32, i32* %19, align 4
  %29917 = icmp eq i32 %29873, %29916
  %29918 = or i1 %29915, %29917
  %29919 = load i32, i32* %20, align 4
  %29920 = icmp eq i32 %29873, %29919
  %29921 = or i1 %29918, %29920
  %29922 = load i32, i32* %21, align 4
  %29923 = icmp eq i32 %29873, %29922
  %29924 = or i1 %29921, %29923
  %29925 = load i32, i32* %22, align 4
  %29926 = icmp eq i32 %29873, %29925
  %29927 = or i1 %29924, %29926
  %29928 = load i32, i32* %23, align 4
  %29929 = icmp eq i32 %29873, %29928
  %29930 = or i1 %29927, %29929
  %29931 = load i32, i32* %24, align 4
  %29932 = icmp eq i32 %29873, %29931
  %29933 = or i1 %29930, %29932
  %29934 = load i32, i32* %25, align 4
  %29935 = icmp eq i32 %29873, %29934
  %29936 = or i1 %29933, %29935
  %29937 = load i32, i32* %26, align 4
  %29938 = icmp eq i32 %29873, %29937
  %29939 = or i1 %29936, %29938
  %29940 = load i32, i32* %27, align 4
  %29941 = icmp eq i32 %29873, %29940
  %29942 = or i1 %29939, %29941
  %29943 = load i32, i32* %28, align 4
  %29944 = icmp eq i32 %29873, %29943
  %29945 = or i1 %29942, %29944
  %29946 = load i32, i32* %29, align 4
  %29947 = icmp eq i32 %29873, %29946
  %29948 = or i1 %29945, %29947
  %29949 = load i32, i32* %30, align 4
  %29950 = icmp eq i32 %29873, %29949
  %29951 = or i1 %29948, %29950
  %29952 = load i32, i32* %31, align 4
  %29953 = icmp eq i32 %29873, %29952
  %29954 = or i1 %29951, %29953
  %29955 = load i32, i32* %32, align 4
  %29956 = icmp eq i32 %29873, %29955
  %29957 = or i1 %29954, %29956
  %29958 = load i32, i32* %33, align 4
  %29959 = icmp eq i32 %29873, %29958
  %29960 = or i1 %29957, %29959
  %29961 = load i32, i32* %34, align 4
  %29962 = icmp eq i32 %29873, %29961
  %29963 = or i1 %29960, %29962
  %29964 = load i32, i32* %35, align 4
  %29965 = icmp eq i32 %29873, %29964
  %29966 = or i1 %29963, %29965
  %29967 = load i32, i32* %36, align 4
  %29968 = icmp eq i32 %29873, %29967
  %29969 = or i1 %29966, %29968
  %29970 = load i32, i32* %37, align 4
  %29971 = icmp eq i32 %29873, %29970
  %29972 = or i1 %29969, %29971
  %29973 = load i32, i32* %38, align 4
  %29974 = icmp eq i32 %29873, %29973
  %29975 = or i1 %29972, %29974
  %29976 = load i32, i32* %39, align 4
  %29977 = icmp eq i32 %29873, %29976
  %29978 = or i1 %29975, %29977
  %29979 = load i32, i32* %40, align 4
  %29980 = icmp eq i32 %29873, %29979
  %29981 = or i1 %29978, %29980
  %29982 = load i32, i32* %41, align 4
  %29983 = icmp eq i32 %29873, %29982
  %29984 = or i1 %29981, %29983
  %29985 = load i32, i32* %42, align 4
  %29986 = icmp eq i32 %29873, %29985
  %29987 = or i1 %29984, %29986
  %29988 = load i32, i32* %43, align 4
  %29989 = icmp eq i32 %29873, %29988
  %29990 = or i1 %29987, %29989
  %29991 = load i32, i32* %44, align 4
  %29992 = icmp eq i32 %29873, %29991
  %29993 = or i1 %29990, %29992
  %29994 = load i32, i32* %45, align 4
  %29995 = icmp eq i32 %29873, %29994
  %29996 = or i1 %29993, %29995
  %29997 = load i32, i32* %46, align 4
  %29998 = icmp eq i32 %29873, %29997
  %29999 = or i1 %29996, %29998
  %30000 = load i32, i32* %47, align 4
  %30001 = icmp eq i32 %29873, %30000
  %30002 = or i1 %29999, %30001
  %30003 = load i32, i32* %48, align 4
  %30004 = icmp eq i32 %29873, %30003
  %30005 = or i1 %30002, %30004
  %30006 = load i32, i32* %49, align 4
  %30007 = icmp eq i32 %29873, %30006
  %30008 = or i1 %30005, %30007
  %30009 = load i32, i32* %50, align 4
  %30010 = icmp eq i32 %29873, %30009
  %30011 = or i1 %30008, %30010
  %30012 = load i32, i32* %51, align 4
  %30013 = icmp eq i32 %29873, %30012
  %30014 = or i1 %30011, %30013
  %30015 = load i32, i32* %52, align 4
  %30016 = icmp eq i32 %29873, %30015
  %30017 = or i1 %30014, %30016
  %30018 = load i32, i32* %53, align 4
  %30019 = icmp eq i32 %29873, %30018
  %30020 = or i1 %30017, %30019
  %30021 = load i32, i32* %54, align 4
  %30022 = icmp eq i32 %29873, %30021
  %30023 = or i1 %30020, %30022
  %30024 = load i32, i32* %55, align 4
  %30025 = icmp eq i32 %29873, %30024
  %30026 = or i1 %30023, %30025
  %30027 = load i32, i32* %56, align 4
  %30028 = icmp eq i32 %29873, %30027
  %30029 = or i1 %30026, %30028
  %30030 = load i32, i32* %57, align 4
  %30031 = icmp eq i32 %29873, %30030
  %30032 = or i1 %30029, %30031
  %30033 = load i32, i32* %58, align 4
  %30034 = icmp eq i32 %29873, %30033
  %30035 = or i1 %30032, %30034
  %30036 = load i32, i32* %59, align 4
  %30037 = icmp eq i32 %29873, %30036
  %30038 = or i1 %30035, %30037
  %30039 = load i32, i32* %60, align 4
  %30040 = icmp eq i32 %29873, %30039
  %30041 = or i1 %30038, %30040
  %30042 = load i32, i32* %61, align 4
  %30043 = icmp eq i32 %29873, %30042
  %30044 = or i1 %30041, %30043
  %30045 = load i32, i32* %62, align 4
  %30046 = icmp eq i32 %29873, %30045
  %30047 = or i1 %30044, %30046
  %30048 = getelementptr i8, i8 addrspace(1)* %4, i32 107
  %30049 = zext i1 %30047 to i8
  store i8 %30049, i8 addrspace(1)* %30048, align 1, !nosanitize !3
  %30050 = load i256, i256* %29872, align 4
  %30051 = trunc i256 %29488 to i64
  store i64 %30051, i64* %JMP_TARGET_PTR, align 4
  %30052 = load i64, i64* %STACK_DEP_PTR, align 4
  %30053 = add i64 %30052, 1
  store i64 %30053, i64* %STACK_DEP_PTR, align 4
  %30054 = load i64, i64* %STACK_DEP_PTR, align 4
  %30055 = getelementptr i256, i256* %STACK, i64 %30054
  store i256 %29488, i256* %30055, align 4
  %30056 = load i64, i64* %STACK_DEP_PTR, align 4
  %30057 = add i64 %30056, 1
  store i64 %30057, i64* %STACK_DEP_PTR, align 4
  %30058 = load i64, i64* %STACK_DEP_PTR, align 4
  %30059 = getelementptr i256, i256* %STACK, i64 %30058
  store i256 %29688, i256* %30059, align 4
  %30060 = load i64, i64* %STACK_DEP_PTR, align 4
  %30061 = add i64 %30060, 1
  store i64 %30061, i64* %STACK_DEP_PTR, align 4
  %30062 = load i64, i64* %STACK_DEP_PTR, align 4
  %30063 = getelementptr i256, i256* %STACK, i64 %30062
  store i256 %29869, i256* %30063, align 4
  %30064 = load i64, i64* %STACK_DEP_PTR, align 4
  %30065 = add i64 %30064, 1
  store i64 %30065, i64* %STACK_DEP_PTR, align 4
  %30066 = load i64, i64* %STACK_DEP_PTR, align 4
  %30067 = getelementptr i256, i256* %STACK, i64 %30066
  store i256 %30050, i256* %30067, align 4
  br label %JumpTable, !EVMBB !4

.10259:                                           ; preds = %3349, %JumpTable
  %30068 = load i64, i64* %remaing_gas, align 4
  %30069 = icmp ugt i64 216, %30068
  br i1 %30069, label %Abort, label %30070

30070:                                            ; preds = %.10259
  %30071 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30072 = xor i32 %30071, 3166
  %30073 = urem i32 %30072, 4096
  %30074 = getelementptr i8, i8 addrspace(1)* %4, i32 %30073
  %30075 = load i8, i8 addrspace(1)* %30074, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30074, align 1, !nosanitize !3
  store i32 1583, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30076 = sub i64 %30068, 216
  store i64 %30076, i64* %remaing_gas, align 4
  %30077 = load i64, i64* %STACK_DEP_PTR, align 4
  %30078 = getelementptr i256, i256* %STACK, i64 %30077
  %30079 = load i256, i256* %30078, align 4
  %30080 = load i64, i64* %STACK_DEP_PTR, align 4
  %30081 = sub i64 %30080, 1
  store i64 %30081, i64* %STACK_DEP_PTR, align 4
  %30082 = alloca i256, align 8
  store i256 6, i256* %30082, align 4
  %30083 = alloca i256, align 8
  call void @__device_sload(i256* %30082, i256* %30083)
  %30084 = call i32 @__hashword(i256* %30082)
  %30085 = load i32, i32* %5, align 4
  %30086 = icmp eq i32 %30084, %30085
  %30087 = or i1 false, %30086
  %30088 = load i32, i32* %6, align 4
  %30089 = icmp eq i32 %30084, %30088
  %30090 = or i1 %30087, %30089
  %30091 = load i32, i32* %7, align 4
  %30092 = icmp eq i32 %30084, %30091
  %30093 = or i1 %30090, %30092
  %30094 = load i32, i32* %8, align 4
  %30095 = icmp eq i32 %30084, %30094
  %30096 = or i1 %30093, %30095
  %30097 = load i32, i32* %9, align 4
  %30098 = icmp eq i32 %30084, %30097
  %30099 = or i1 %30096, %30098
  %30100 = load i32, i32* %10, align 4
  %30101 = icmp eq i32 %30084, %30100
  %30102 = or i1 %30099, %30101
  %30103 = load i32, i32* %11, align 4
  %30104 = icmp eq i32 %30084, %30103
  %30105 = or i1 %30102, %30104
  %30106 = load i32, i32* %12, align 4
  %30107 = icmp eq i32 %30084, %30106
  %30108 = or i1 %30105, %30107
  %30109 = load i32, i32* %13, align 4
  %30110 = icmp eq i32 %30084, %30109
  %30111 = or i1 %30108, %30110
  %30112 = load i32, i32* %14, align 4
  %30113 = icmp eq i32 %30084, %30112
  %30114 = or i1 %30111, %30113
  %30115 = load i32, i32* %15, align 4
  %30116 = icmp eq i32 %30084, %30115
  %30117 = or i1 %30114, %30116
  %30118 = load i32, i32* %16, align 4
  %30119 = icmp eq i32 %30084, %30118
  %30120 = or i1 %30117, %30119
  %30121 = load i32, i32* %17, align 4
  %30122 = icmp eq i32 %30084, %30121
  %30123 = or i1 %30120, %30122
  %30124 = load i32, i32* %18, align 4
  %30125 = icmp eq i32 %30084, %30124
  %30126 = or i1 %30123, %30125
  %30127 = load i32, i32* %19, align 4
  %30128 = icmp eq i32 %30084, %30127
  %30129 = or i1 %30126, %30128
  %30130 = load i32, i32* %20, align 4
  %30131 = icmp eq i32 %30084, %30130
  %30132 = or i1 %30129, %30131
  %30133 = load i32, i32* %21, align 4
  %30134 = icmp eq i32 %30084, %30133
  %30135 = or i1 %30132, %30134
  %30136 = load i32, i32* %22, align 4
  %30137 = icmp eq i32 %30084, %30136
  %30138 = or i1 %30135, %30137
  %30139 = load i32, i32* %23, align 4
  %30140 = icmp eq i32 %30084, %30139
  %30141 = or i1 %30138, %30140
  %30142 = load i32, i32* %24, align 4
  %30143 = icmp eq i32 %30084, %30142
  %30144 = or i1 %30141, %30143
  %30145 = load i32, i32* %25, align 4
  %30146 = icmp eq i32 %30084, %30145
  %30147 = or i1 %30144, %30146
  %30148 = load i32, i32* %26, align 4
  %30149 = icmp eq i32 %30084, %30148
  %30150 = or i1 %30147, %30149
  %30151 = load i32, i32* %27, align 4
  %30152 = icmp eq i32 %30084, %30151
  %30153 = or i1 %30150, %30152
  %30154 = load i32, i32* %28, align 4
  %30155 = icmp eq i32 %30084, %30154
  %30156 = or i1 %30153, %30155
  %30157 = load i32, i32* %29, align 4
  %30158 = icmp eq i32 %30084, %30157
  %30159 = or i1 %30156, %30158
  %30160 = load i32, i32* %30, align 4
  %30161 = icmp eq i32 %30084, %30160
  %30162 = or i1 %30159, %30161
  %30163 = load i32, i32* %31, align 4
  %30164 = icmp eq i32 %30084, %30163
  %30165 = or i1 %30162, %30164
  %30166 = load i32, i32* %32, align 4
  %30167 = icmp eq i32 %30084, %30166
  %30168 = or i1 %30165, %30167
  %30169 = load i32, i32* %33, align 4
  %30170 = icmp eq i32 %30084, %30169
  %30171 = or i1 %30168, %30170
  %30172 = load i32, i32* %34, align 4
  %30173 = icmp eq i32 %30084, %30172
  %30174 = or i1 %30171, %30173
  %30175 = load i32, i32* %35, align 4
  %30176 = icmp eq i32 %30084, %30175
  %30177 = or i1 %30174, %30176
  %30178 = load i32, i32* %36, align 4
  %30179 = icmp eq i32 %30084, %30178
  %30180 = or i1 %30177, %30179
  %30181 = load i32, i32* %37, align 4
  %30182 = icmp eq i32 %30084, %30181
  %30183 = or i1 %30180, %30182
  %30184 = load i32, i32* %38, align 4
  %30185 = icmp eq i32 %30084, %30184
  %30186 = or i1 %30183, %30185
  %30187 = load i32, i32* %39, align 4
  %30188 = icmp eq i32 %30084, %30187
  %30189 = or i1 %30186, %30188
  %30190 = load i32, i32* %40, align 4
  %30191 = icmp eq i32 %30084, %30190
  %30192 = or i1 %30189, %30191
  %30193 = load i32, i32* %41, align 4
  %30194 = icmp eq i32 %30084, %30193
  %30195 = or i1 %30192, %30194
  %30196 = load i32, i32* %42, align 4
  %30197 = icmp eq i32 %30084, %30196
  %30198 = or i1 %30195, %30197
  %30199 = load i32, i32* %43, align 4
  %30200 = icmp eq i32 %30084, %30199
  %30201 = or i1 %30198, %30200
  %30202 = load i32, i32* %44, align 4
  %30203 = icmp eq i32 %30084, %30202
  %30204 = or i1 %30201, %30203
  %30205 = load i32, i32* %45, align 4
  %30206 = icmp eq i32 %30084, %30205
  %30207 = or i1 %30204, %30206
  %30208 = load i32, i32* %46, align 4
  %30209 = icmp eq i32 %30084, %30208
  %30210 = or i1 %30207, %30209
  %30211 = load i32, i32* %47, align 4
  %30212 = icmp eq i32 %30084, %30211
  %30213 = or i1 %30210, %30212
  %30214 = load i32, i32* %48, align 4
  %30215 = icmp eq i32 %30084, %30214
  %30216 = or i1 %30213, %30215
  %30217 = load i32, i32* %49, align 4
  %30218 = icmp eq i32 %30084, %30217
  %30219 = or i1 %30216, %30218
  %30220 = load i32, i32* %50, align 4
  %30221 = icmp eq i32 %30084, %30220
  %30222 = or i1 %30219, %30221
  %30223 = load i32, i32* %51, align 4
  %30224 = icmp eq i32 %30084, %30223
  %30225 = or i1 %30222, %30224
  %30226 = load i32, i32* %52, align 4
  %30227 = icmp eq i32 %30084, %30226
  %30228 = or i1 %30225, %30227
  %30229 = load i32, i32* %53, align 4
  %30230 = icmp eq i32 %30084, %30229
  %30231 = or i1 %30228, %30230
  %30232 = load i32, i32* %54, align 4
  %30233 = icmp eq i32 %30084, %30232
  %30234 = or i1 %30231, %30233
  %30235 = load i32, i32* %55, align 4
  %30236 = icmp eq i32 %30084, %30235
  %30237 = or i1 %30234, %30236
  %30238 = load i32, i32* %56, align 4
  %30239 = icmp eq i32 %30084, %30238
  %30240 = or i1 %30237, %30239
  %30241 = load i32, i32* %57, align 4
  %30242 = icmp eq i32 %30084, %30241
  %30243 = or i1 %30240, %30242
  %30244 = load i32, i32* %58, align 4
  %30245 = icmp eq i32 %30084, %30244
  %30246 = or i1 %30243, %30245
  %30247 = load i32, i32* %59, align 4
  %30248 = icmp eq i32 %30084, %30247
  %30249 = or i1 %30246, %30248
  %30250 = load i32, i32* %60, align 4
  %30251 = icmp eq i32 %30084, %30250
  %30252 = or i1 %30249, %30251
  %30253 = load i32, i32* %61, align 4
  %30254 = icmp eq i32 %30084, %30253
  %30255 = or i1 %30252, %30254
  %30256 = load i32, i32* %62, align 4
  %30257 = icmp eq i32 %30084, %30256
  %30258 = or i1 %30255, %30257
  %30259 = getelementptr i8, i8 addrspace(1)* %4, i32 108
  %30260 = zext i1 %30258 to i8
  store i8 %30260, i8 addrspace(1)* %30259, align 1, !nosanitize !3
  %30261 = load i256, i256* %30083, align 4
  %30262 = trunc i256 %30079 to i64
  store i64 %30262, i64* %JMP_TARGET_PTR, align 4
  %30263 = load i64, i64* %STACK_DEP_PTR, align 4
  %30264 = add i64 %30263, 1
  store i64 %30264, i64* %STACK_DEP_PTR, align 4
  %30265 = load i64, i64* %STACK_DEP_PTR, align 4
  %30266 = getelementptr i256, i256* %STACK, i64 %30265
  store i256 %30079, i256* %30266, align 4
  %30267 = load i64, i64* %STACK_DEP_PTR, align 4
  %30268 = add i64 %30267, 1
  store i64 %30268, i64* %STACK_DEP_PTR, align 4
  %30269 = load i64, i64* %STACK_DEP_PTR, align 4
  %30270 = getelementptr i256, i256* %STACK, i64 %30269
  store i256 %30261, i256* %30270, align 4
  br label %JumpTable, !EVMBB !4

.10265:                                           ; preds = %3420, %JumpTable
  %30271 = load i64, i64* %remaing_gas, align 4
  %30272 = icmp ugt i64 184, %30271
  br i1 %30272, label %Abort, label %30273

30273:                                            ; preds = %.10265
  %30274 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30275 = xor i32 %30274, 339
  %30276 = urem i32 %30275, 4096
  %30277 = getelementptr i8, i8 addrspace(1)* %4, i32 %30276
  %30278 = load i8, i8 addrspace(1)* %30277, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30277, align 1, !nosanitize !3
  store i32 169, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30279 = sub i64 %30271, 184
  store i64 %30279, i64* %remaing_gas, align 4
  %30280 = load i256, i256* %0, align 4
  %30281 = and i256 1461501637330902918203684832716283019655932542975, %30280
  %30282 = alloca i256, align 8
  store i256 7, i256* %30282, align 4
  %30283 = alloca i256, align 8
  call void @__device_sload(i256* %30282, i256* %30283)
  %30284 = call i32 @__hashword(i256* %30282)
  %30285 = load i32, i32* %5, align 4
  %30286 = icmp eq i32 %30284, %30285
  %30287 = or i1 false, %30286
  %30288 = load i32, i32* %6, align 4
  %30289 = icmp eq i32 %30284, %30288
  %30290 = or i1 %30287, %30289
  %30291 = load i32, i32* %7, align 4
  %30292 = icmp eq i32 %30284, %30291
  %30293 = or i1 %30290, %30292
  %30294 = load i32, i32* %8, align 4
  %30295 = icmp eq i32 %30284, %30294
  %30296 = or i1 %30293, %30295
  %30297 = load i32, i32* %9, align 4
  %30298 = icmp eq i32 %30284, %30297
  %30299 = or i1 %30296, %30298
  %30300 = load i32, i32* %10, align 4
  %30301 = icmp eq i32 %30284, %30300
  %30302 = or i1 %30299, %30301
  %30303 = load i32, i32* %11, align 4
  %30304 = icmp eq i32 %30284, %30303
  %30305 = or i1 %30302, %30304
  %30306 = load i32, i32* %12, align 4
  %30307 = icmp eq i32 %30284, %30306
  %30308 = or i1 %30305, %30307
  %30309 = load i32, i32* %13, align 4
  %30310 = icmp eq i32 %30284, %30309
  %30311 = or i1 %30308, %30310
  %30312 = load i32, i32* %14, align 4
  %30313 = icmp eq i32 %30284, %30312
  %30314 = or i1 %30311, %30313
  %30315 = load i32, i32* %15, align 4
  %30316 = icmp eq i32 %30284, %30315
  %30317 = or i1 %30314, %30316
  %30318 = load i32, i32* %16, align 4
  %30319 = icmp eq i32 %30284, %30318
  %30320 = or i1 %30317, %30319
  %30321 = load i32, i32* %17, align 4
  %30322 = icmp eq i32 %30284, %30321
  %30323 = or i1 %30320, %30322
  %30324 = load i32, i32* %18, align 4
  %30325 = icmp eq i32 %30284, %30324
  %30326 = or i1 %30323, %30325
  %30327 = load i32, i32* %19, align 4
  %30328 = icmp eq i32 %30284, %30327
  %30329 = or i1 %30326, %30328
  %30330 = load i32, i32* %20, align 4
  %30331 = icmp eq i32 %30284, %30330
  %30332 = or i1 %30329, %30331
  %30333 = load i32, i32* %21, align 4
  %30334 = icmp eq i32 %30284, %30333
  %30335 = or i1 %30332, %30334
  %30336 = load i32, i32* %22, align 4
  %30337 = icmp eq i32 %30284, %30336
  %30338 = or i1 %30335, %30337
  %30339 = load i32, i32* %23, align 4
  %30340 = icmp eq i32 %30284, %30339
  %30341 = or i1 %30338, %30340
  %30342 = load i32, i32* %24, align 4
  %30343 = icmp eq i32 %30284, %30342
  %30344 = or i1 %30341, %30343
  %30345 = load i32, i32* %25, align 4
  %30346 = icmp eq i32 %30284, %30345
  %30347 = or i1 %30344, %30346
  %30348 = load i32, i32* %26, align 4
  %30349 = icmp eq i32 %30284, %30348
  %30350 = or i1 %30347, %30349
  %30351 = load i32, i32* %27, align 4
  %30352 = icmp eq i32 %30284, %30351
  %30353 = or i1 %30350, %30352
  %30354 = load i32, i32* %28, align 4
  %30355 = icmp eq i32 %30284, %30354
  %30356 = or i1 %30353, %30355
  %30357 = load i32, i32* %29, align 4
  %30358 = icmp eq i32 %30284, %30357
  %30359 = or i1 %30356, %30358
  %30360 = load i32, i32* %30, align 4
  %30361 = icmp eq i32 %30284, %30360
  %30362 = or i1 %30359, %30361
  %30363 = load i32, i32* %31, align 4
  %30364 = icmp eq i32 %30284, %30363
  %30365 = or i1 %30362, %30364
  %30366 = load i32, i32* %32, align 4
  %30367 = icmp eq i32 %30284, %30366
  %30368 = or i1 %30365, %30367
  %30369 = load i32, i32* %33, align 4
  %30370 = icmp eq i32 %30284, %30369
  %30371 = or i1 %30368, %30370
  %30372 = load i32, i32* %34, align 4
  %30373 = icmp eq i32 %30284, %30372
  %30374 = or i1 %30371, %30373
  %30375 = load i32, i32* %35, align 4
  %30376 = icmp eq i32 %30284, %30375
  %30377 = or i1 %30374, %30376
  %30378 = load i32, i32* %36, align 4
  %30379 = icmp eq i32 %30284, %30378
  %30380 = or i1 %30377, %30379
  %30381 = load i32, i32* %37, align 4
  %30382 = icmp eq i32 %30284, %30381
  %30383 = or i1 %30380, %30382
  %30384 = load i32, i32* %38, align 4
  %30385 = icmp eq i32 %30284, %30384
  %30386 = or i1 %30383, %30385
  %30387 = load i32, i32* %39, align 4
  %30388 = icmp eq i32 %30284, %30387
  %30389 = or i1 %30386, %30388
  %30390 = load i32, i32* %40, align 4
  %30391 = icmp eq i32 %30284, %30390
  %30392 = or i1 %30389, %30391
  %30393 = load i32, i32* %41, align 4
  %30394 = icmp eq i32 %30284, %30393
  %30395 = or i1 %30392, %30394
  %30396 = load i32, i32* %42, align 4
  %30397 = icmp eq i32 %30284, %30396
  %30398 = or i1 %30395, %30397
  %30399 = load i32, i32* %43, align 4
  %30400 = icmp eq i32 %30284, %30399
  %30401 = or i1 %30398, %30400
  %30402 = load i32, i32* %44, align 4
  %30403 = icmp eq i32 %30284, %30402
  %30404 = or i1 %30401, %30403
  %30405 = load i32, i32* %45, align 4
  %30406 = icmp eq i32 %30284, %30405
  %30407 = or i1 %30404, %30406
  %30408 = load i32, i32* %46, align 4
  %30409 = icmp eq i32 %30284, %30408
  %30410 = or i1 %30407, %30409
  %30411 = load i32, i32* %47, align 4
  %30412 = icmp eq i32 %30284, %30411
  %30413 = or i1 %30410, %30412
  %30414 = load i32, i32* %48, align 4
  %30415 = icmp eq i32 %30284, %30414
  %30416 = or i1 %30413, %30415
  %30417 = load i32, i32* %49, align 4
  %30418 = icmp eq i32 %30284, %30417
  %30419 = or i1 %30416, %30418
  %30420 = load i32, i32* %50, align 4
  %30421 = icmp eq i32 %30284, %30420
  %30422 = or i1 %30419, %30421
  %30423 = load i32, i32* %51, align 4
  %30424 = icmp eq i32 %30284, %30423
  %30425 = or i1 %30422, %30424
  %30426 = load i32, i32* %52, align 4
  %30427 = icmp eq i32 %30284, %30426
  %30428 = or i1 %30425, %30427
  %30429 = load i32, i32* %53, align 4
  %30430 = icmp eq i32 %30284, %30429
  %30431 = or i1 %30428, %30430
  %30432 = load i32, i32* %54, align 4
  %30433 = icmp eq i32 %30284, %30432
  %30434 = or i1 %30431, %30433
  %30435 = load i32, i32* %55, align 4
  %30436 = icmp eq i32 %30284, %30435
  %30437 = or i1 %30434, %30436
  %30438 = load i32, i32* %56, align 4
  %30439 = icmp eq i32 %30284, %30438
  %30440 = or i1 %30437, %30439
  %30441 = load i32, i32* %57, align 4
  %30442 = icmp eq i32 %30284, %30441
  %30443 = or i1 %30440, %30442
  %30444 = load i32, i32* %58, align 4
  %30445 = icmp eq i32 %30284, %30444
  %30446 = or i1 %30443, %30445
  %30447 = load i32, i32* %59, align 4
  %30448 = icmp eq i32 %30284, %30447
  %30449 = or i1 %30446, %30448
  %30450 = load i32, i32* %60, align 4
  %30451 = icmp eq i32 %30284, %30450
  %30452 = or i1 %30449, %30451
  %30453 = load i32, i32* %61, align 4
  %30454 = icmp eq i32 %30284, %30453
  %30455 = or i1 %30452, %30454
  %30456 = load i32, i32* %62, align 4
  %30457 = icmp eq i32 %30284, %30456
  %30458 = or i1 %30455, %30457
  %30459 = getelementptr i8, i8 addrspace(1)* %4, i32 109
  %30460 = zext i1 %30458 to i8
  store i8 %30460, i8 addrspace(1)* %30459, align 1, !nosanitize !3
  %30461 = load i256, i256* %30283, align 4
  %30462 = alloca i256, align 8
  store i256 %30461, i256* %30462, align 4
  %30463 = alloca i256, align 8
  store i256 1, i256* %30463, align 4
  %30464 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %30462, i256* %30463, i256* %30464), !pc !459, !intsan !6
  %30465 = load i256, i256* %30464, align 4
  %30466 = and i256 1461501637330902918203684832716283019655932542975, %30465
  %30467 = and i256 1461501637330902918203684832716283019655932542975, %30466
  %30468 = icmp eq i256 %30467, %30281
  %30469 = icmp eq i1 %30468, false
  %30470 = icmp eq i1 %30469, false
  %30471 = trunc i256 10357 to i64
  %jump.check161 = icmp ne i1 %30470, false
  br i1 %jump.check161, label %.10357, label %.10353, !EVMBB !4

.10353:                                           ; preds = %30273
  %30472 = load i64, i64* %remaing_gas, align 4
  %30473 = icmp ugt i64 16, %30472
  br i1 %30473, label %Abort, label %30474

30474:                                            ; preds = %.10353
  %30475 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30476 = xor i32 %30475, 3936
  %30477 = urem i32 %30476, 4096
  %30478 = getelementptr i8, i8 addrspace(1)* %4, i32 %30477
  %30479 = load i8, i8 addrspace(1)* %30478, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30478, align 1, !nosanitize !3
  store i32 1968, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30480 = sub i64 %30472, 16
  store i64 %30480, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10357:                                           ; preds = %30273, %JumpTable
  %30481 = load i64, i64* %remaing_gas, align 4
  %30482 = icmp ugt i64 200, %30481
  br i1 %30482, label %Abort, label %30483

30483:                                            ; preds = %.10357
  %30484 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30485 = xor i32 %30484, 3498
  %30486 = urem i32 %30485, 4096
  %30487 = getelementptr i8, i8 addrspace(1)* %4, i32 %30486
  %30488 = load i8, i8 addrspace(1)* %30487, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30487, align 1, !nosanitize !3
  store i32 1749, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30489 = sub i64 %30481, 200
  store i64 %30489, i64* %remaing_gas, align 4
  %30490 = load i64, i64* %STACK_DEP_PTR, align 4
  %30491 = getelementptr i256, i256* %STACK, i64 %30490
  %30492 = load i256, i256* %30491, align 4
  %30493 = load i64, i64* %STACK_DEP_PTR, align 4
  %30494 = sub i64 %30493, 1
  store i64 %30494, i64* %STACK_DEP_PTR, align 4
  %30495 = add i256 175000, %30492, !pc !460, !intsan !10
  %30496 = icmp ult i256 %30495, 175000
  %30497 = icmp eq i1 %30496, false
  %30498 = trunc i256 10379 to i64
  %jump.check164 = icmp ne i1 %30497, false
  %30499 = load i64, i64* %STACK_DEP_PTR, align 4
  %30500 = add i64 %30499, 1
  store i64 %30500, i64* %STACK_DEP_PTR, align 4
  %30501 = load i64, i64* %STACK_DEP_PTR, align 4
  %30502 = getelementptr i256, i256* %STACK, i64 %30501
  store i256 %30492, i256* %30502, align 4
  %30503 = load i64, i64* %STACK_DEP_PTR, align 4
  %30504 = add i64 %30503, 1
  store i64 %30504, i64* %STACK_DEP_PTR, align 4
  %30505 = load i64, i64* %STACK_DEP_PTR, align 4
  %30506 = getelementptr i256, i256* %STACK, i64 %30505
  store i256 %30492, i256* %30506, align 4
  br i1 %jump.check164, label %.10379, label %.10375, !EVMBB !4

.10375:                                           ; preds = %30483
  %30507 = load i64, i64* %remaing_gas, align 4
  %30508 = icmp ugt i64 40, %30507
  br i1 %30508, label %Abort, label %30509

30509:                                            ; preds = %.10375
  %30510 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30511 = xor i32 %30510, 722
  %30512 = urem i32 %30511, 4096
  %30513 = getelementptr i8, i8 addrspace(1)* %4, i32 %30512
  %30514 = load i8, i8 addrspace(1)* %30513, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30513, align 1, !nosanitize !3
  store i32 361, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30515 = sub i64 %30507, 40
  store i64 %30515, i64* %remaing_gas, align 4
  %30516 = load i64, i64* %STACK_DEP_PTR, align 4
  %30517 = sub i64 %30516, 0
  store i64 %30517, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.10379:                                           ; preds = %30483, %JumpTable
  %30518 = load i64, i64* %remaing_gas, align 4
  %30519 = icmp ugt i64 144, %30518
  br i1 %30519, label %Abort, label %30520

30520:                                            ; preds = %.10379
  %30521 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30522 = xor i32 %30521, 2738
  %30523 = urem i32 %30522, 4096
  %30524 = getelementptr i8, i8 addrspace(1)* %4, i32 %30523
  %30525 = load i8, i8 addrspace(1)* %30524, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30524, align 1, !nosanitize !3
  store i32 1369, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30526 = sub i64 %30518, 144
  store i64 %30526, i64* %remaing_gas, align 4
  %30527 = load i64, i64* %STACK_DEP_PTR, align 4
  %30528 = getelementptr i256, i256* %STACK, i64 %30527
  %30529 = load i256, i256* %30528, align 4
  %30530 = load i64, i64* %STACK_DEP_PTR, align 4
  %30531 = sub i64 %30530, 1
  store i64 %30531, i64* %STACK_DEP_PTR, align 4
  %30532 = icmp ult i256 %30529, 25000
  %30533 = icmp eq i1 %30532, false
  %30534 = trunc i256 10394 to i64
  %jump.check168 = icmp ne i1 %30533, false
  %30535 = load i64, i64* %STACK_DEP_PTR, align 4
  %30536 = add i64 %30535, 1
  store i64 %30536, i64* %STACK_DEP_PTR, align 4
  %30537 = load i64, i64* %STACK_DEP_PTR, align 4
  %30538 = getelementptr i256, i256* %STACK, i64 %30537
  store i256 %30529, i256* %30538, align 4
  br i1 %jump.check168, label %.10394, label %.10390, !EVMBB !4

.10390:                                           ; preds = %30520
  %30539 = load i64, i64* %remaing_gas, align 4
  %30540 = icmp ugt i64 40, %30539
  br i1 %30540, label %Abort, label %30541

30541:                                            ; preds = %.10390
  %30542 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30543 = xor i32 %30542, 3280
  %30544 = urem i32 %30543, 4096
  %30545 = getelementptr i8, i8 addrspace(1)* %4, i32 %30544
  %30546 = load i8, i8 addrspace(1)* %30545, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30545, align 1, !nosanitize !3
  store i32 1640, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30547 = sub i64 %30539, 40
  store i64 %30547, i64* %remaing_gas, align 4
  %30548 = load i64, i64* %STACK_DEP_PTR, align 4
  %30549 = sub i64 %30548, 0
  store i64 %30549, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.10394:                                           ; preds = %30520, %JumpTable
  %30550 = load i64, i64* %remaing_gas, align 4
  %30551 = icmp ugt i64 440, %30550
  br i1 %30551, label %Abort, label %30552

30552:                                            ; preds = %.10394
  %30553 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30554 = xor i32 %30553, 3717
  %30555 = urem i32 %30554, 4096
  %30556 = getelementptr i8, i8 addrspace(1)* %4, i32 %30555
  %30557 = load i8, i8 addrspace(1)* %30556, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30556, align 1, !nosanitize !3
  store i32 1858, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30558 = sub i64 %30550, 440
  store i64 %30558, i64* %remaing_gas, align 4
  %30559 = load i64, i64* %STACK_DEP_PTR, align 4
  %30560 = getelementptr i256, i256* %STACK, i64 %30559
  %30561 = load i256, i256* %30560, align 4
  %30562 = load i64, i64* %STACK_DEP_PTR, align 4
  %30563 = sub i64 %30562, 1
  store i64 %30563, i64* %STACK_DEP_PTR, align 4
  %30564 = load i64, i64* %STACK_DEP_PTR, align 4
  %30565 = getelementptr i256, i256* %STACK, i64 %30564
  %30566 = load i256, i256* %30565, align 4
  %30567 = load i64, i64* %STACK_DEP_PTR, align 4
  %30568 = sub i64 %30567, 1
  store i64 %30568, i64* %STACK_DEP_PTR, align 4
  %30569 = load i64, i64* %STACK_DEP_PTR, align 4
  %30570 = getelementptr i256, i256* %STACK, i64 %30569
  %30571 = load i256, i256* %30570, align 4
  %30572 = load i64, i64* %STACK_DEP_PTR, align 4
  %30573 = sub i64 %30572, 1
  store i64 %30573, i64* %STACK_DEP_PTR, align 4
  %30574 = alloca i256, align 8
  store i256 2, i256* %30574, align 4
  %30575 = alloca i256, align 8
  store i256 %30566, i256* %30575, align 4
  call void @__device_sstore(i256* %30574, i256* %30575)
  %30576 = call i32 @__hashword(i256* %30574)
  store i32 %30576, i32* %29, align 4, !nosanitize !3
  %30577 = alloca i256, align 8
  store i256 2, i256* %30577, align 4
  %30578 = alloca i256, align 8
  call void @__device_sload(i256* %30577, i256* %30578)
  %30579 = call i32 @__hashword(i256* %30577)
  %30580 = load i32, i32* %5, align 4
  %30581 = icmp eq i32 %30579, %30580
  %30582 = or i1 false, %30581
  %30583 = load i32, i32* %6, align 4
  %30584 = icmp eq i32 %30579, %30583
  %30585 = or i1 %30582, %30584
  %30586 = load i32, i32* %7, align 4
  %30587 = icmp eq i32 %30579, %30586
  %30588 = or i1 %30585, %30587
  %30589 = load i32, i32* %8, align 4
  %30590 = icmp eq i32 %30579, %30589
  %30591 = or i1 %30588, %30590
  %30592 = load i32, i32* %9, align 4
  %30593 = icmp eq i32 %30579, %30592
  %30594 = or i1 %30591, %30593
  %30595 = load i32, i32* %10, align 4
  %30596 = icmp eq i32 %30579, %30595
  %30597 = or i1 %30594, %30596
  %30598 = load i32, i32* %11, align 4
  %30599 = icmp eq i32 %30579, %30598
  %30600 = or i1 %30597, %30599
  %30601 = load i32, i32* %12, align 4
  %30602 = icmp eq i32 %30579, %30601
  %30603 = or i1 %30600, %30602
  %30604 = load i32, i32* %13, align 4
  %30605 = icmp eq i32 %30579, %30604
  %30606 = or i1 %30603, %30605
  %30607 = load i32, i32* %14, align 4
  %30608 = icmp eq i32 %30579, %30607
  %30609 = or i1 %30606, %30608
  %30610 = load i32, i32* %15, align 4
  %30611 = icmp eq i32 %30579, %30610
  %30612 = or i1 %30609, %30611
  %30613 = load i32, i32* %16, align 4
  %30614 = icmp eq i32 %30579, %30613
  %30615 = or i1 %30612, %30614
  %30616 = load i32, i32* %17, align 4
  %30617 = icmp eq i32 %30579, %30616
  %30618 = or i1 %30615, %30617
  %30619 = load i32, i32* %18, align 4
  %30620 = icmp eq i32 %30579, %30619
  %30621 = or i1 %30618, %30620
  %30622 = load i32, i32* %19, align 4
  %30623 = icmp eq i32 %30579, %30622
  %30624 = or i1 %30621, %30623
  %30625 = load i32, i32* %20, align 4
  %30626 = icmp eq i32 %30579, %30625
  %30627 = or i1 %30624, %30626
  %30628 = load i32, i32* %21, align 4
  %30629 = icmp eq i32 %30579, %30628
  %30630 = or i1 %30627, %30629
  %30631 = load i32, i32* %22, align 4
  %30632 = icmp eq i32 %30579, %30631
  %30633 = or i1 %30630, %30632
  %30634 = load i32, i32* %23, align 4
  %30635 = icmp eq i32 %30579, %30634
  %30636 = or i1 %30633, %30635
  %30637 = load i32, i32* %24, align 4
  %30638 = icmp eq i32 %30579, %30637
  %30639 = or i1 %30636, %30638
  %30640 = load i32, i32* %25, align 4
  %30641 = icmp eq i32 %30579, %30640
  %30642 = or i1 %30639, %30641
  %30643 = load i32, i32* %26, align 4
  %30644 = icmp eq i32 %30579, %30643
  %30645 = or i1 %30642, %30644
  %30646 = load i32, i32* %27, align 4
  %30647 = icmp eq i32 %30579, %30646
  %30648 = or i1 %30645, %30647
  %30649 = load i32, i32* %28, align 4
  %30650 = icmp eq i32 %30579, %30649
  %30651 = or i1 %30648, %30650
  %30652 = load i32, i32* %29, align 4
  %30653 = icmp eq i32 %30579, %30652
  %30654 = or i1 %30651, %30653
  %30655 = load i32, i32* %30, align 4
  %30656 = icmp eq i32 %30579, %30655
  %30657 = or i1 %30654, %30656
  %30658 = load i32, i32* %31, align 4
  %30659 = icmp eq i32 %30579, %30658
  %30660 = or i1 %30657, %30659
  %30661 = load i32, i32* %32, align 4
  %30662 = icmp eq i32 %30579, %30661
  %30663 = or i1 %30660, %30662
  %30664 = load i32, i32* %33, align 4
  %30665 = icmp eq i32 %30579, %30664
  %30666 = or i1 %30663, %30665
  %30667 = load i32, i32* %34, align 4
  %30668 = icmp eq i32 %30579, %30667
  %30669 = or i1 %30666, %30668
  %30670 = load i32, i32* %35, align 4
  %30671 = icmp eq i32 %30579, %30670
  %30672 = or i1 %30669, %30671
  %30673 = load i32, i32* %36, align 4
  %30674 = icmp eq i32 %30579, %30673
  %30675 = or i1 %30672, %30674
  %30676 = load i32, i32* %37, align 4
  %30677 = icmp eq i32 %30579, %30676
  %30678 = or i1 %30675, %30677
  %30679 = load i32, i32* %38, align 4
  %30680 = icmp eq i32 %30579, %30679
  %30681 = or i1 %30678, %30680
  %30682 = load i32, i32* %39, align 4
  %30683 = icmp eq i32 %30579, %30682
  %30684 = or i1 %30681, %30683
  %30685 = load i32, i32* %40, align 4
  %30686 = icmp eq i32 %30579, %30685
  %30687 = or i1 %30684, %30686
  %30688 = load i32, i32* %41, align 4
  %30689 = icmp eq i32 %30579, %30688
  %30690 = or i1 %30687, %30689
  %30691 = load i32, i32* %42, align 4
  %30692 = icmp eq i32 %30579, %30691
  %30693 = or i1 %30690, %30692
  %30694 = load i32, i32* %43, align 4
  %30695 = icmp eq i32 %30579, %30694
  %30696 = or i1 %30693, %30695
  %30697 = load i32, i32* %44, align 4
  %30698 = icmp eq i32 %30579, %30697
  %30699 = or i1 %30696, %30698
  %30700 = load i32, i32* %45, align 4
  %30701 = icmp eq i32 %30579, %30700
  %30702 = or i1 %30699, %30701
  %30703 = load i32, i32* %46, align 4
  %30704 = icmp eq i32 %30579, %30703
  %30705 = or i1 %30702, %30704
  %30706 = load i32, i32* %47, align 4
  %30707 = icmp eq i32 %30579, %30706
  %30708 = or i1 %30705, %30707
  %30709 = load i32, i32* %48, align 4
  %30710 = icmp eq i32 %30579, %30709
  %30711 = or i1 %30708, %30710
  %30712 = load i32, i32* %49, align 4
  %30713 = icmp eq i32 %30579, %30712
  %30714 = or i1 %30711, %30713
  %30715 = load i32, i32* %50, align 4
  %30716 = icmp eq i32 %30579, %30715
  %30717 = or i1 %30714, %30716
  %30718 = load i32, i32* %51, align 4
  %30719 = icmp eq i32 %30579, %30718
  %30720 = or i1 %30717, %30719
  %30721 = load i32, i32* %52, align 4
  %30722 = icmp eq i32 %30579, %30721
  %30723 = or i1 %30720, %30722
  %30724 = load i32, i32* %53, align 4
  %30725 = icmp eq i32 %30579, %30724
  %30726 = or i1 %30723, %30725
  %30727 = load i32, i32* %54, align 4
  %30728 = icmp eq i32 %30579, %30727
  %30729 = or i1 %30726, %30728
  %30730 = load i32, i32* %55, align 4
  %30731 = icmp eq i32 %30579, %30730
  %30732 = or i1 %30729, %30731
  %30733 = load i32, i32* %56, align 4
  %30734 = icmp eq i32 %30579, %30733
  %30735 = or i1 %30732, %30734
  %30736 = load i32, i32* %57, align 4
  %30737 = icmp eq i32 %30579, %30736
  %30738 = or i1 %30735, %30737
  %30739 = load i32, i32* %58, align 4
  %30740 = icmp eq i32 %30579, %30739
  %30741 = or i1 %30738, %30740
  %30742 = load i32, i32* %59, align 4
  %30743 = icmp eq i32 %30579, %30742
  %30744 = or i1 %30741, %30743
  %30745 = load i32, i32* %60, align 4
  %30746 = icmp eq i32 %30579, %30745
  %30747 = or i1 %30744, %30746
  %30748 = load i32, i32* %61, align 4
  %30749 = icmp eq i32 %30579, %30748
  %30750 = or i1 %30747, %30749
  %30751 = load i32, i32* %62, align 4
  %30752 = icmp eq i32 %30579, %30751
  %30753 = or i1 %30750, %30752
  %30754 = getelementptr i8, i8 addrspace(1)* %4, i32 110
  %30755 = zext i1 %30753 to i8
  store i8 %30755, i8 addrspace(1)* %30754, align 1, !nosanitize !3
  %30756 = load i256, i256* %30578, align 4
  %30757 = trunc i256 64 to i64
  %30758 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %30757, i256* %30758)
  %30759 = load i256, i256* %30758, align 4
  %30760 = trunc i256 %30759 to i64
  %30761 = alloca i256, align 8
  store i256 %30756, i256* %30761, align 4
  %30762 = bitcast i256* %30761 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %30760, i8* %30762, i64 32)
  %30763 = add i256 32, %30759, !pc !461, !intsan !10
  %30764 = trunc i256 %30763 to i64
  %30765 = alloca i256, align 8
  store i256 %30566, i256* %30765, align 4
  %30766 = bitcast i256* %30765 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %30764, i8* %30766, i64 32)
  %30767 = add i256 32, %30763, !pc !462, !intsan !10
  %30768 = trunc i256 64 to i64
  %30769 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %30768, i256* %30769)
  %30770 = load i256, i256* %30769, align 4
  %30771 = sub i256 %30767, %30770, !pc !463, !intsan !8
  %30772 = trunc i256 -33518987608582164772302295636886579929693169657696094701834436680700510305102 to i64
  call void @addBugSet(i64 %30772)
  %30773 = trunc i256 %30571 to i64
  store i64 %30773, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.10470:                                           ; preds = %3487, %JumpTable
  %30774 = load i64, i64* %remaing_gas, align 4
  %30775 = icmp ugt i64 280, %30774
  br i1 %30775, label %Abort, label %30776

30776:                                            ; preds = %.10470
  %30777 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30778 = xor i32 %30777, 1530
  %30779 = urem i32 %30778, 4096
  %30780 = getelementptr i8, i8 addrspace(1)* %4, i32 %30779
  %30781 = load i8, i8 addrspace(1)* %30780, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30780, align 1, !nosanitize !3
  store i32 765, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30782 = sub i64 %30774, 280
  store i64 %30782, i64* %remaing_gas, align 4
  %30783 = load i64, i64* %STACK_DEP_PTR, align 4
  %30784 = getelementptr i256, i256* %STACK, i64 %30783
  %30785 = load i256, i256* %30784, align 4
  %30786 = load i64, i64* %STACK_DEP_PTR, align 4
  %30787 = sub i64 %30786, 1
  store i64 %30787, i64* %STACK_DEP_PTR, align 4
  %30788 = alloca i256, align 8
  store i256 8, i256* %30788, align 4
  %30789 = alloca i256, align 8
  call void @__device_sload(i256* %30788, i256* %30789)
  %30790 = call i32 @__hashword(i256* %30788)
  %30791 = load i32, i32* %5, align 4
  %30792 = icmp eq i32 %30790, %30791
  %30793 = or i1 false, %30792
  %30794 = load i32, i32* %6, align 4
  %30795 = icmp eq i32 %30790, %30794
  %30796 = or i1 %30793, %30795
  %30797 = load i32, i32* %7, align 4
  %30798 = icmp eq i32 %30790, %30797
  %30799 = or i1 %30796, %30798
  %30800 = load i32, i32* %8, align 4
  %30801 = icmp eq i32 %30790, %30800
  %30802 = or i1 %30799, %30801
  %30803 = load i32, i32* %9, align 4
  %30804 = icmp eq i32 %30790, %30803
  %30805 = or i1 %30802, %30804
  %30806 = load i32, i32* %10, align 4
  %30807 = icmp eq i32 %30790, %30806
  %30808 = or i1 %30805, %30807
  %30809 = load i32, i32* %11, align 4
  %30810 = icmp eq i32 %30790, %30809
  %30811 = or i1 %30808, %30810
  %30812 = load i32, i32* %12, align 4
  %30813 = icmp eq i32 %30790, %30812
  %30814 = or i1 %30811, %30813
  %30815 = load i32, i32* %13, align 4
  %30816 = icmp eq i32 %30790, %30815
  %30817 = or i1 %30814, %30816
  %30818 = load i32, i32* %14, align 4
  %30819 = icmp eq i32 %30790, %30818
  %30820 = or i1 %30817, %30819
  %30821 = load i32, i32* %15, align 4
  %30822 = icmp eq i32 %30790, %30821
  %30823 = or i1 %30820, %30822
  %30824 = load i32, i32* %16, align 4
  %30825 = icmp eq i32 %30790, %30824
  %30826 = or i1 %30823, %30825
  %30827 = load i32, i32* %17, align 4
  %30828 = icmp eq i32 %30790, %30827
  %30829 = or i1 %30826, %30828
  %30830 = load i32, i32* %18, align 4
  %30831 = icmp eq i32 %30790, %30830
  %30832 = or i1 %30829, %30831
  %30833 = load i32, i32* %19, align 4
  %30834 = icmp eq i32 %30790, %30833
  %30835 = or i1 %30832, %30834
  %30836 = load i32, i32* %20, align 4
  %30837 = icmp eq i32 %30790, %30836
  %30838 = or i1 %30835, %30837
  %30839 = load i32, i32* %21, align 4
  %30840 = icmp eq i32 %30790, %30839
  %30841 = or i1 %30838, %30840
  %30842 = load i32, i32* %22, align 4
  %30843 = icmp eq i32 %30790, %30842
  %30844 = or i1 %30841, %30843
  %30845 = load i32, i32* %23, align 4
  %30846 = icmp eq i32 %30790, %30845
  %30847 = or i1 %30844, %30846
  %30848 = load i32, i32* %24, align 4
  %30849 = icmp eq i32 %30790, %30848
  %30850 = or i1 %30847, %30849
  %30851 = load i32, i32* %25, align 4
  %30852 = icmp eq i32 %30790, %30851
  %30853 = or i1 %30850, %30852
  %30854 = load i32, i32* %26, align 4
  %30855 = icmp eq i32 %30790, %30854
  %30856 = or i1 %30853, %30855
  %30857 = load i32, i32* %27, align 4
  %30858 = icmp eq i32 %30790, %30857
  %30859 = or i1 %30856, %30858
  %30860 = load i32, i32* %28, align 4
  %30861 = icmp eq i32 %30790, %30860
  %30862 = or i1 %30859, %30861
  %30863 = load i32, i32* %29, align 4
  %30864 = icmp eq i32 %30790, %30863
  %30865 = or i1 %30862, %30864
  %30866 = load i32, i32* %30, align 4
  %30867 = icmp eq i32 %30790, %30866
  %30868 = or i1 %30865, %30867
  %30869 = load i32, i32* %31, align 4
  %30870 = icmp eq i32 %30790, %30869
  %30871 = or i1 %30868, %30870
  %30872 = load i32, i32* %32, align 4
  %30873 = icmp eq i32 %30790, %30872
  %30874 = or i1 %30871, %30873
  %30875 = load i32, i32* %33, align 4
  %30876 = icmp eq i32 %30790, %30875
  %30877 = or i1 %30874, %30876
  %30878 = load i32, i32* %34, align 4
  %30879 = icmp eq i32 %30790, %30878
  %30880 = or i1 %30877, %30879
  %30881 = load i32, i32* %35, align 4
  %30882 = icmp eq i32 %30790, %30881
  %30883 = or i1 %30880, %30882
  %30884 = load i32, i32* %36, align 4
  %30885 = icmp eq i32 %30790, %30884
  %30886 = or i1 %30883, %30885
  %30887 = load i32, i32* %37, align 4
  %30888 = icmp eq i32 %30790, %30887
  %30889 = or i1 %30886, %30888
  %30890 = load i32, i32* %38, align 4
  %30891 = icmp eq i32 %30790, %30890
  %30892 = or i1 %30889, %30891
  %30893 = load i32, i32* %39, align 4
  %30894 = icmp eq i32 %30790, %30893
  %30895 = or i1 %30892, %30894
  %30896 = load i32, i32* %40, align 4
  %30897 = icmp eq i32 %30790, %30896
  %30898 = or i1 %30895, %30897
  %30899 = load i32, i32* %41, align 4
  %30900 = icmp eq i32 %30790, %30899
  %30901 = or i1 %30898, %30900
  %30902 = load i32, i32* %42, align 4
  %30903 = icmp eq i32 %30790, %30902
  %30904 = or i1 %30901, %30903
  %30905 = load i32, i32* %43, align 4
  %30906 = icmp eq i32 %30790, %30905
  %30907 = or i1 %30904, %30906
  %30908 = load i32, i32* %44, align 4
  %30909 = icmp eq i32 %30790, %30908
  %30910 = or i1 %30907, %30909
  %30911 = load i32, i32* %45, align 4
  %30912 = icmp eq i32 %30790, %30911
  %30913 = or i1 %30910, %30912
  %30914 = load i32, i32* %46, align 4
  %30915 = icmp eq i32 %30790, %30914
  %30916 = or i1 %30913, %30915
  %30917 = load i32, i32* %47, align 4
  %30918 = icmp eq i32 %30790, %30917
  %30919 = or i1 %30916, %30918
  %30920 = load i32, i32* %48, align 4
  %30921 = icmp eq i32 %30790, %30920
  %30922 = or i1 %30919, %30921
  %30923 = load i32, i32* %49, align 4
  %30924 = icmp eq i32 %30790, %30923
  %30925 = or i1 %30922, %30924
  %30926 = load i32, i32* %50, align 4
  %30927 = icmp eq i32 %30790, %30926
  %30928 = or i1 %30925, %30927
  %30929 = load i32, i32* %51, align 4
  %30930 = icmp eq i32 %30790, %30929
  %30931 = or i1 %30928, %30930
  %30932 = load i32, i32* %52, align 4
  %30933 = icmp eq i32 %30790, %30932
  %30934 = or i1 %30931, %30933
  %30935 = load i32, i32* %53, align 4
  %30936 = icmp eq i32 %30790, %30935
  %30937 = or i1 %30934, %30936
  %30938 = load i32, i32* %54, align 4
  %30939 = icmp eq i32 %30790, %30938
  %30940 = or i1 %30937, %30939
  %30941 = load i32, i32* %55, align 4
  %30942 = icmp eq i32 %30790, %30941
  %30943 = or i1 %30940, %30942
  %30944 = load i32, i32* %56, align 4
  %30945 = icmp eq i32 %30790, %30944
  %30946 = or i1 %30943, %30945
  %30947 = load i32, i32* %57, align 4
  %30948 = icmp eq i32 %30790, %30947
  %30949 = or i1 %30946, %30948
  %30950 = load i32, i32* %58, align 4
  %30951 = icmp eq i32 %30790, %30950
  %30952 = or i1 %30949, %30951
  %30953 = load i32, i32* %59, align 4
  %30954 = icmp eq i32 %30790, %30953
  %30955 = or i1 %30952, %30954
  %30956 = load i32, i32* %60, align 4
  %30957 = icmp eq i32 %30790, %30956
  %30958 = or i1 %30955, %30957
  %30959 = load i32, i32* %61, align 4
  %30960 = icmp eq i32 %30790, %30959
  %30961 = or i1 %30958, %30960
  %30962 = load i32, i32* %62, align 4
  %30963 = icmp eq i32 %30790, %30962
  %30964 = or i1 %30961, %30963
  %30965 = getelementptr i8, i8 addrspace(1)* %4, i32 111
  %30966 = zext i1 %30964 to i8
  store i8 %30966, i8 addrspace(1)* %30965, align 1, !nosanitize !3
  %30967 = load i256, i256* %30789, align 4
  %30968 = alloca i256, align 8
  store i256 %30967, i256* %30968, align 4
  %30969 = alloca i256, align 8
  store i256 1, i256* %30969, align 4
  %30970 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %30968, i256* %30969, i256* %30970), !pc !464, !intsan !6
  %30971 = load i256, i256* %30970, align 4
  %30972 = and i256 1461501637330902918203684832716283019655932542975, %30971
  %30973 = trunc i256 %30785 to i64
  store i64 %30973, i64* %JMP_TARGET_PTR, align 4
  %30974 = load i64, i64* %STACK_DEP_PTR, align 4
  %30975 = add i64 %30974, 1
  store i64 %30975, i64* %STACK_DEP_PTR, align 4
  %30976 = load i64, i64* %STACK_DEP_PTR, align 4
  %30977 = getelementptr i256, i256* %STACK, i64 %30976
  store i256 %30785, i256* %30977, align 4
  %30978 = load i64, i64* %STACK_DEP_PTR, align 4
  %30979 = add i64 %30978, 1
  store i64 %30979, i64* %STACK_DEP_PTR, align 4
  %30980 = load i64, i64* %STACK_DEP_PTR, align 4
  %30981 = getelementptr i256, i256* %STACK, i64 %30980
  store i256 %30972, i256* %30981, align 4
  br label %JumpTable, !EVMBB !4

.10508:                                           ; preds = %3560, %JumpTable
  %30982 = load i64, i64* %remaing_gas, align 4
  %30983 = icmp ugt i64 184, %30982
  br i1 %30983, label %Abort, label %30984

30984:                                            ; preds = %.10508
  %30985 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30986 = xor i32 %30985, 84
  %30987 = urem i32 %30986, 4096
  %30988 = getelementptr i8, i8 addrspace(1)* %4, i32 %30987
  %30989 = load i8, i8 addrspace(1)* %30988, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %30988, align 1, !nosanitize !3
  store i32 42, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %30990 = sub i64 %30982, 184
  store i64 %30990, i64* %remaing_gas, align 4
  %30991 = load i256, i256* %0, align 4
  %30992 = and i256 1461501637330902918203684832716283019655932542975, %30991
  %30993 = alloca i256, align 8
  store i256 7, i256* %30993, align 4
  %30994 = alloca i256, align 8
  call void @__device_sload(i256* %30993, i256* %30994)
  %30995 = call i32 @__hashword(i256* %30993)
  %30996 = load i32, i32* %5, align 4
  %30997 = icmp eq i32 %30995, %30996
  %30998 = or i1 false, %30997
  %30999 = load i32, i32* %6, align 4
  %31000 = icmp eq i32 %30995, %30999
  %31001 = or i1 %30998, %31000
  %31002 = load i32, i32* %7, align 4
  %31003 = icmp eq i32 %30995, %31002
  %31004 = or i1 %31001, %31003
  %31005 = load i32, i32* %8, align 4
  %31006 = icmp eq i32 %30995, %31005
  %31007 = or i1 %31004, %31006
  %31008 = load i32, i32* %9, align 4
  %31009 = icmp eq i32 %30995, %31008
  %31010 = or i1 %31007, %31009
  %31011 = load i32, i32* %10, align 4
  %31012 = icmp eq i32 %30995, %31011
  %31013 = or i1 %31010, %31012
  %31014 = load i32, i32* %11, align 4
  %31015 = icmp eq i32 %30995, %31014
  %31016 = or i1 %31013, %31015
  %31017 = load i32, i32* %12, align 4
  %31018 = icmp eq i32 %30995, %31017
  %31019 = or i1 %31016, %31018
  %31020 = load i32, i32* %13, align 4
  %31021 = icmp eq i32 %30995, %31020
  %31022 = or i1 %31019, %31021
  %31023 = load i32, i32* %14, align 4
  %31024 = icmp eq i32 %30995, %31023
  %31025 = or i1 %31022, %31024
  %31026 = load i32, i32* %15, align 4
  %31027 = icmp eq i32 %30995, %31026
  %31028 = or i1 %31025, %31027
  %31029 = load i32, i32* %16, align 4
  %31030 = icmp eq i32 %30995, %31029
  %31031 = or i1 %31028, %31030
  %31032 = load i32, i32* %17, align 4
  %31033 = icmp eq i32 %30995, %31032
  %31034 = or i1 %31031, %31033
  %31035 = load i32, i32* %18, align 4
  %31036 = icmp eq i32 %30995, %31035
  %31037 = or i1 %31034, %31036
  %31038 = load i32, i32* %19, align 4
  %31039 = icmp eq i32 %30995, %31038
  %31040 = or i1 %31037, %31039
  %31041 = load i32, i32* %20, align 4
  %31042 = icmp eq i32 %30995, %31041
  %31043 = or i1 %31040, %31042
  %31044 = load i32, i32* %21, align 4
  %31045 = icmp eq i32 %30995, %31044
  %31046 = or i1 %31043, %31045
  %31047 = load i32, i32* %22, align 4
  %31048 = icmp eq i32 %30995, %31047
  %31049 = or i1 %31046, %31048
  %31050 = load i32, i32* %23, align 4
  %31051 = icmp eq i32 %30995, %31050
  %31052 = or i1 %31049, %31051
  %31053 = load i32, i32* %24, align 4
  %31054 = icmp eq i32 %30995, %31053
  %31055 = or i1 %31052, %31054
  %31056 = load i32, i32* %25, align 4
  %31057 = icmp eq i32 %30995, %31056
  %31058 = or i1 %31055, %31057
  %31059 = load i32, i32* %26, align 4
  %31060 = icmp eq i32 %30995, %31059
  %31061 = or i1 %31058, %31060
  %31062 = load i32, i32* %27, align 4
  %31063 = icmp eq i32 %30995, %31062
  %31064 = or i1 %31061, %31063
  %31065 = load i32, i32* %28, align 4
  %31066 = icmp eq i32 %30995, %31065
  %31067 = or i1 %31064, %31066
  %31068 = load i32, i32* %29, align 4
  %31069 = icmp eq i32 %30995, %31068
  %31070 = or i1 %31067, %31069
  %31071 = load i32, i32* %30, align 4
  %31072 = icmp eq i32 %30995, %31071
  %31073 = or i1 %31070, %31072
  %31074 = load i32, i32* %31, align 4
  %31075 = icmp eq i32 %30995, %31074
  %31076 = or i1 %31073, %31075
  %31077 = load i32, i32* %32, align 4
  %31078 = icmp eq i32 %30995, %31077
  %31079 = or i1 %31076, %31078
  %31080 = load i32, i32* %33, align 4
  %31081 = icmp eq i32 %30995, %31080
  %31082 = or i1 %31079, %31081
  %31083 = load i32, i32* %34, align 4
  %31084 = icmp eq i32 %30995, %31083
  %31085 = or i1 %31082, %31084
  %31086 = load i32, i32* %35, align 4
  %31087 = icmp eq i32 %30995, %31086
  %31088 = or i1 %31085, %31087
  %31089 = load i32, i32* %36, align 4
  %31090 = icmp eq i32 %30995, %31089
  %31091 = or i1 %31088, %31090
  %31092 = load i32, i32* %37, align 4
  %31093 = icmp eq i32 %30995, %31092
  %31094 = or i1 %31091, %31093
  %31095 = load i32, i32* %38, align 4
  %31096 = icmp eq i32 %30995, %31095
  %31097 = or i1 %31094, %31096
  %31098 = load i32, i32* %39, align 4
  %31099 = icmp eq i32 %30995, %31098
  %31100 = or i1 %31097, %31099
  %31101 = load i32, i32* %40, align 4
  %31102 = icmp eq i32 %30995, %31101
  %31103 = or i1 %31100, %31102
  %31104 = load i32, i32* %41, align 4
  %31105 = icmp eq i32 %30995, %31104
  %31106 = or i1 %31103, %31105
  %31107 = load i32, i32* %42, align 4
  %31108 = icmp eq i32 %30995, %31107
  %31109 = or i1 %31106, %31108
  %31110 = load i32, i32* %43, align 4
  %31111 = icmp eq i32 %30995, %31110
  %31112 = or i1 %31109, %31111
  %31113 = load i32, i32* %44, align 4
  %31114 = icmp eq i32 %30995, %31113
  %31115 = or i1 %31112, %31114
  %31116 = load i32, i32* %45, align 4
  %31117 = icmp eq i32 %30995, %31116
  %31118 = or i1 %31115, %31117
  %31119 = load i32, i32* %46, align 4
  %31120 = icmp eq i32 %30995, %31119
  %31121 = or i1 %31118, %31120
  %31122 = load i32, i32* %47, align 4
  %31123 = icmp eq i32 %30995, %31122
  %31124 = or i1 %31121, %31123
  %31125 = load i32, i32* %48, align 4
  %31126 = icmp eq i32 %30995, %31125
  %31127 = or i1 %31124, %31126
  %31128 = load i32, i32* %49, align 4
  %31129 = icmp eq i32 %30995, %31128
  %31130 = or i1 %31127, %31129
  %31131 = load i32, i32* %50, align 4
  %31132 = icmp eq i32 %30995, %31131
  %31133 = or i1 %31130, %31132
  %31134 = load i32, i32* %51, align 4
  %31135 = icmp eq i32 %30995, %31134
  %31136 = or i1 %31133, %31135
  %31137 = load i32, i32* %52, align 4
  %31138 = icmp eq i32 %30995, %31137
  %31139 = or i1 %31136, %31138
  %31140 = load i32, i32* %53, align 4
  %31141 = icmp eq i32 %30995, %31140
  %31142 = or i1 %31139, %31141
  %31143 = load i32, i32* %54, align 4
  %31144 = icmp eq i32 %30995, %31143
  %31145 = or i1 %31142, %31144
  %31146 = load i32, i32* %55, align 4
  %31147 = icmp eq i32 %30995, %31146
  %31148 = or i1 %31145, %31147
  %31149 = load i32, i32* %56, align 4
  %31150 = icmp eq i32 %30995, %31149
  %31151 = or i1 %31148, %31150
  %31152 = load i32, i32* %57, align 4
  %31153 = icmp eq i32 %30995, %31152
  %31154 = or i1 %31151, %31153
  %31155 = load i32, i32* %58, align 4
  %31156 = icmp eq i32 %30995, %31155
  %31157 = or i1 %31154, %31156
  %31158 = load i32, i32* %59, align 4
  %31159 = icmp eq i32 %30995, %31158
  %31160 = or i1 %31157, %31159
  %31161 = load i32, i32* %60, align 4
  %31162 = icmp eq i32 %30995, %31161
  %31163 = or i1 %31160, %31162
  %31164 = load i32, i32* %61, align 4
  %31165 = icmp eq i32 %30995, %31164
  %31166 = or i1 %31163, %31165
  %31167 = load i32, i32* %62, align 4
  %31168 = icmp eq i32 %30995, %31167
  %31169 = or i1 %31166, %31168
  %31170 = getelementptr i8, i8 addrspace(1)* %4, i32 112
  %31171 = zext i1 %31169 to i8
  store i8 %31171, i8 addrspace(1)* %31170, align 1, !nosanitize !3
  %31172 = load i256, i256* %30994, align 4
  %31173 = alloca i256, align 8
  store i256 %31172, i256* %31173, align 4
  %31174 = alloca i256, align 8
  store i256 1, i256* %31174, align 4
  %31175 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %31173, i256* %31174, i256* %31175), !pc !465, !intsan !6
  %31176 = load i256, i256* %31175, align 4
  %31177 = and i256 1461501637330902918203684832716283019655932542975, %31176
  %31178 = and i256 1461501637330902918203684832716283019655932542975, %31177
  %31179 = icmp eq i256 %31178, %30992
  %31180 = icmp eq i1 %31179, false
  %31181 = icmp eq i1 %31180, false
  %31182 = trunc i256 10600 to i64
  %jump.check167 = icmp ne i1 %31181, false
  br i1 %jump.check167, label %.10600, label %.10596, !EVMBB !4

.10596:                                           ; preds = %30984
  %31183 = load i64, i64* %remaing_gas, align 4
  %31184 = icmp ugt i64 16, %31183
  br i1 %31184, label %Abort, label %31185

31185:                                            ; preds = %.10596
  %31186 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31187 = xor i32 %31186, 2520
  %31188 = urem i32 %31187, 4096
  %31189 = getelementptr i8, i8 addrspace(1)* %4, i32 %31188
  %31190 = load i8, i8 addrspace(1)* %31189, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31189, align 1, !nosanitize !3
  store i32 1260, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31191 = sub i64 %31183, 16
  store i64 %31191, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10600:                                           ; preds = %30984, %JumpTable
  %31192 = load i64, i64* %remaing_gas, align 4
  %31193 = icmp ugt i64 216, %31192
  br i1 %31193, label %Abort, label %31194

31194:                                            ; preds = %.10600
  %31195 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31196 = xor i32 %31195, 1845
  %31197 = urem i32 %31196, 4096
  %31198 = getelementptr i8, i8 addrspace(1)* %4, i32 %31197
  %31199 = load i8, i8 addrspace(1)* %31198, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31198, align 1, !nosanitize !3
  store i32 922, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31200 = sub i64 %31192, 216
  store i64 %31200, i64* %remaing_gas, align 4
  %31201 = load i64, i64* %STACK_DEP_PTR, align 4
  %31202 = getelementptr i256, i256* %STACK, i64 %31201
  %31203 = load i256, i256* %31202, align 4
  %31204 = load i64, i64* %STACK_DEP_PTR, align 4
  %31205 = sub i64 %31204, 1
  store i64 %31205, i64* %STACK_DEP_PTR, align 4
  %31206 = trunc i256 17016 to i64
  %31207 = load i64, i64* %STACK_DEP_PTR, align 4
  %31208 = add i64 %31207, 1
  store i64 %31208, i64* %STACK_DEP_PTR, align 4
  %31209 = load i64, i64* %STACK_DEP_PTR, align 4
  %31210 = getelementptr i256, i256* %STACK, i64 %31209
  store i256 %31203, i256* %31210, align 4
  %31211 = load i64, i64* %STACK_DEP_PTR, align 4
  %31212 = add i64 %31211, 1
  store i64 %31212, i64* %STACK_DEP_PTR, align 4
  %31213 = load i64, i64* %STACK_DEP_PTR, align 4
  %31214 = getelementptr i256, i256* %STACK, i64 %31213
  store i256 10609, i256* %31214, align 4
  %31215 = load i64, i64* %STACK_DEP_PTR, align 4
  %31216 = add i64 %31215, 1
  store i64 %31216, i64* %STACK_DEP_PTR, align 4
  %31217 = load i64, i64* %STACK_DEP_PTR, align 4
  %31218 = getelementptr i256, i256* %STACK, i64 %31217
  store i256 %31203, i256* %31218, align 4
  br label %.17016, !EVMBB !4

.10609:                                           ; preds = %JumpTable
  %31219 = load i64, i64* %remaing_gas, align 4
  %31220 = icmp ugt i64 128, %31219
  br i1 %31220, label %Abort, label %31221

31221:                                            ; preds = %.10609
  %31222 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31223 = xor i32 %31222, 1256
  %31224 = urem i32 %31223, 4096
  %31225 = getelementptr i8, i8 addrspace(1)* %4, i32 %31224
  %31226 = load i8, i8 addrspace(1)* %31225, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31225, align 1, !nosanitize !3
  store i32 628, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31227 = sub i64 %31219, 128
  store i64 %31227, i64* %remaing_gas, align 4
  %31228 = load i64, i64* %STACK_DEP_PTR, align 4
  %31229 = getelementptr i256, i256* %STACK, i64 %31228
  %31230 = load i256, i256* %31229, align 4
  %31231 = load i64, i64* %STACK_DEP_PTR, align 4
  %31232 = sub i64 %31231, 1
  store i64 %31232, i64* %STACK_DEP_PTR, align 4
  %31233 = load i64, i64* %STACK_DEP_PTR, align 4
  %31234 = getelementptr i256, i256* %STACK, i64 %31233
  %31235 = load i256, i256* %31234, align 4
  %31236 = load i64, i64* %STACK_DEP_PTR, align 4
  %31237 = sub i64 %31236, 1
  store i64 %31237, i64* %STACK_DEP_PTR, align 4
  %31238 = trunc i256 %31235 to i64
  store i64 %31238, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.10612:                                           ; preds = %3629, %JumpTable
  %31239 = load i64, i64* %remaing_gas, align 4
  %31240 = icmp ugt i64 168, %31239
  br i1 %31240, label %Abort, label %31241

31241:                                            ; preds = %.10612
  %31242 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31243 = xor i32 %31242, 3284
  %31244 = urem i32 %31243, 4096
  %31245 = getelementptr i8, i8 addrspace(1)* %4, i32 %31244
  %31246 = load i8, i8 addrspace(1)* %31245, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31245, align 1, !nosanitize !3
  store i32 1642, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31247 = sub i64 %31239, 168
  store i64 %31247, i64* %remaing_gas, align 4
  %31248 = load i64, i64* %STACK_DEP_PTR, align 4
  %31249 = getelementptr i256, i256* %STACK, i64 %31248
  %31250 = load i256, i256* %31249, align 4
  %31251 = load i64, i64* %STACK_DEP_PTR, align 4
  %31252 = sub i64 %31251, 1
  store i64 %31252, i64* %STACK_DEP_PTR, align 4
  %31253 = alloca i256, align 8
  store i256 12, i256* %31253, align 4
  %31254 = alloca i256, align 8
  call void @__device_sload(i256* %31253, i256* %31254)
  %31255 = call i32 @__hashword(i256* %31253)
  %31256 = load i32, i32* %5, align 4
  %31257 = icmp eq i32 %31255, %31256
  %31258 = or i1 false, %31257
  %31259 = load i32, i32* %6, align 4
  %31260 = icmp eq i32 %31255, %31259
  %31261 = or i1 %31258, %31260
  %31262 = load i32, i32* %7, align 4
  %31263 = icmp eq i32 %31255, %31262
  %31264 = or i1 %31261, %31263
  %31265 = load i32, i32* %8, align 4
  %31266 = icmp eq i32 %31255, %31265
  %31267 = or i1 %31264, %31266
  %31268 = load i32, i32* %9, align 4
  %31269 = icmp eq i32 %31255, %31268
  %31270 = or i1 %31267, %31269
  %31271 = load i32, i32* %10, align 4
  %31272 = icmp eq i32 %31255, %31271
  %31273 = or i1 %31270, %31272
  %31274 = load i32, i32* %11, align 4
  %31275 = icmp eq i32 %31255, %31274
  %31276 = or i1 %31273, %31275
  %31277 = load i32, i32* %12, align 4
  %31278 = icmp eq i32 %31255, %31277
  %31279 = or i1 %31276, %31278
  %31280 = load i32, i32* %13, align 4
  %31281 = icmp eq i32 %31255, %31280
  %31282 = or i1 %31279, %31281
  %31283 = load i32, i32* %14, align 4
  %31284 = icmp eq i32 %31255, %31283
  %31285 = or i1 %31282, %31284
  %31286 = load i32, i32* %15, align 4
  %31287 = icmp eq i32 %31255, %31286
  %31288 = or i1 %31285, %31287
  %31289 = load i32, i32* %16, align 4
  %31290 = icmp eq i32 %31255, %31289
  %31291 = or i1 %31288, %31290
  %31292 = load i32, i32* %17, align 4
  %31293 = icmp eq i32 %31255, %31292
  %31294 = or i1 %31291, %31293
  %31295 = load i32, i32* %18, align 4
  %31296 = icmp eq i32 %31255, %31295
  %31297 = or i1 %31294, %31296
  %31298 = load i32, i32* %19, align 4
  %31299 = icmp eq i32 %31255, %31298
  %31300 = or i1 %31297, %31299
  %31301 = load i32, i32* %20, align 4
  %31302 = icmp eq i32 %31255, %31301
  %31303 = or i1 %31300, %31302
  %31304 = load i32, i32* %21, align 4
  %31305 = icmp eq i32 %31255, %31304
  %31306 = or i1 %31303, %31305
  %31307 = load i32, i32* %22, align 4
  %31308 = icmp eq i32 %31255, %31307
  %31309 = or i1 %31306, %31308
  %31310 = load i32, i32* %23, align 4
  %31311 = icmp eq i32 %31255, %31310
  %31312 = or i1 %31309, %31311
  %31313 = load i32, i32* %24, align 4
  %31314 = icmp eq i32 %31255, %31313
  %31315 = or i1 %31312, %31314
  %31316 = load i32, i32* %25, align 4
  %31317 = icmp eq i32 %31255, %31316
  %31318 = or i1 %31315, %31317
  %31319 = load i32, i32* %26, align 4
  %31320 = icmp eq i32 %31255, %31319
  %31321 = or i1 %31318, %31320
  %31322 = load i32, i32* %27, align 4
  %31323 = icmp eq i32 %31255, %31322
  %31324 = or i1 %31321, %31323
  %31325 = load i32, i32* %28, align 4
  %31326 = icmp eq i32 %31255, %31325
  %31327 = or i1 %31324, %31326
  %31328 = load i32, i32* %29, align 4
  %31329 = icmp eq i32 %31255, %31328
  %31330 = or i1 %31327, %31329
  %31331 = load i32, i32* %30, align 4
  %31332 = icmp eq i32 %31255, %31331
  %31333 = or i1 %31330, %31332
  %31334 = load i32, i32* %31, align 4
  %31335 = icmp eq i32 %31255, %31334
  %31336 = or i1 %31333, %31335
  %31337 = load i32, i32* %32, align 4
  %31338 = icmp eq i32 %31255, %31337
  %31339 = or i1 %31336, %31338
  %31340 = load i32, i32* %33, align 4
  %31341 = icmp eq i32 %31255, %31340
  %31342 = or i1 %31339, %31341
  %31343 = load i32, i32* %34, align 4
  %31344 = icmp eq i32 %31255, %31343
  %31345 = or i1 %31342, %31344
  %31346 = load i32, i32* %35, align 4
  %31347 = icmp eq i32 %31255, %31346
  %31348 = or i1 %31345, %31347
  %31349 = load i32, i32* %36, align 4
  %31350 = icmp eq i32 %31255, %31349
  %31351 = or i1 %31348, %31350
  %31352 = load i32, i32* %37, align 4
  %31353 = icmp eq i32 %31255, %31352
  %31354 = or i1 %31351, %31353
  %31355 = load i32, i32* %38, align 4
  %31356 = icmp eq i32 %31255, %31355
  %31357 = or i1 %31354, %31356
  %31358 = load i32, i32* %39, align 4
  %31359 = icmp eq i32 %31255, %31358
  %31360 = or i1 %31357, %31359
  %31361 = load i32, i32* %40, align 4
  %31362 = icmp eq i32 %31255, %31361
  %31363 = or i1 %31360, %31362
  %31364 = load i32, i32* %41, align 4
  %31365 = icmp eq i32 %31255, %31364
  %31366 = or i1 %31363, %31365
  %31367 = load i32, i32* %42, align 4
  %31368 = icmp eq i32 %31255, %31367
  %31369 = or i1 %31366, %31368
  %31370 = load i32, i32* %43, align 4
  %31371 = icmp eq i32 %31255, %31370
  %31372 = or i1 %31369, %31371
  %31373 = load i32, i32* %44, align 4
  %31374 = icmp eq i32 %31255, %31373
  %31375 = or i1 %31372, %31374
  %31376 = load i32, i32* %45, align 4
  %31377 = icmp eq i32 %31255, %31376
  %31378 = or i1 %31375, %31377
  %31379 = load i32, i32* %46, align 4
  %31380 = icmp eq i32 %31255, %31379
  %31381 = or i1 %31378, %31380
  %31382 = load i32, i32* %47, align 4
  %31383 = icmp eq i32 %31255, %31382
  %31384 = or i1 %31381, %31383
  %31385 = load i32, i32* %48, align 4
  %31386 = icmp eq i32 %31255, %31385
  %31387 = or i1 %31384, %31386
  %31388 = load i32, i32* %49, align 4
  %31389 = icmp eq i32 %31255, %31388
  %31390 = or i1 %31387, %31389
  %31391 = load i32, i32* %50, align 4
  %31392 = icmp eq i32 %31255, %31391
  %31393 = or i1 %31390, %31392
  %31394 = load i32, i32* %51, align 4
  %31395 = icmp eq i32 %31255, %31394
  %31396 = or i1 %31393, %31395
  %31397 = load i32, i32* %52, align 4
  %31398 = icmp eq i32 %31255, %31397
  %31399 = or i1 %31396, %31398
  %31400 = load i32, i32* %53, align 4
  %31401 = icmp eq i32 %31255, %31400
  %31402 = or i1 %31399, %31401
  %31403 = load i32, i32* %54, align 4
  %31404 = icmp eq i32 %31255, %31403
  %31405 = or i1 %31402, %31404
  %31406 = load i32, i32* %55, align 4
  %31407 = icmp eq i32 %31255, %31406
  %31408 = or i1 %31405, %31407
  %31409 = load i32, i32* %56, align 4
  %31410 = icmp eq i32 %31255, %31409
  %31411 = or i1 %31408, %31410
  %31412 = load i32, i32* %57, align 4
  %31413 = icmp eq i32 %31255, %31412
  %31414 = or i1 %31411, %31413
  %31415 = load i32, i32* %58, align 4
  %31416 = icmp eq i32 %31255, %31415
  %31417 = or i1 %31414, %31416
  %31418 = load i32, i32* %59, align 4
  %31419 = icmp eq i32 %31255, %31418
  %31420 = or i1 %31417, %31419
  %31421 = load i32, i32* %60, align 4
  %31422 = icmp eq i32 %31255, %31421
  %31423 = or i1 %31420, %31422
  %31424 = load i32, i32* %61, align 4
  %31425 = icmp eq i32 %31255, %31424
  %31426 = or i1 %31423, %31425
  %31427 = load i32, i32* %62, align 4
  %31428 = icmp eq i32 %31255, %31427
  %31429 = or i1 %31426, %31428
  %31430 = getelementptr i8, i8 addrspace(1)* %4, i32 113
  %31431 = zext i1 %31429 to i8
  store i8 %31431, i8 addrspace(1)* %31430, align 1, !nosanitize !3
  %31432 = load i256, i256* %31254, align 4
  %31433 = trunc i256 %31250 to i64
  store i64 %31433, i64* %JMP_TARGET_PTR, align 4
  %31434 = load i64, i64* %STACK_DEP_PTR, align 4
  %31435 = add i64 %31434, 1
  store i64 %31435, i64* %STACK_DEP_PTR, align 4
  %31436 = load i64, i64* %STACK_DEP_PTR, align 4
  %31437 = getelementptr i256, i256* %STACK, i64 %31436
  store i256 %31432, i256* %31437, align 4
  br label %JumpTable, !EVMBB !4

.10625:                                           ; preds = %3700, %JumpTable
  %31438 = load i64, i64* %remaing_gas, align 4
  %31439 = icmp ugt i64 328, %31438
  br i1 %31439, label %Abort, label %31440

31440:                                            ; preds = %.10625
  %31441 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31442 = xor i32 %31441, 358
  %31443 = urem i32 %31442, 4096
  %31444 = getelementptr i8, i8 addrspace(1)* %4, i32 %31443
  %31445 = load i8, i8 addrspace(1)* %31444, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31444, align 1, !nosanitize !3
  store i32 179, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31446 = sub i64 %31438, 328
  store i64 %31446, i64* %remaing_gas, align 4
  %31447 = load i256, i256* %0, align 4
  %31448 = and i256 1461501637330902918203684832716283019655932542975, %31447
  %31449 = alloca i256, align 8
  store i256 7, i256* %31449, align 4
  %31450 = alloca i256, align 8
  call void @__device_sload(i256* %31449, i256* %31450)
  %31451 = call i32 @__hashword(i256* %31449)
  %31452 = load i32, i32* %5, align 4
  %31453 = icmp eq i32 %31451, %31452
  %31454 = or i1 false, %31453
  %31455 = load i32, i32* %6, align 4
  %31456 = icmp eq i32 %31451, %31455
  %31457 = or i1 %31454, %31456
  %31458 = load i32, i32* %7, align 4
  %31459 = icmp eq i32 %31451, %31458
  %31460 = or i1 %31457, %31459
  %31461 = load i32, i32* %8, align 4
  %31462 = icmp eq i32 %31451, %31461
  %31463 = or i1 %31460, %31462
  %31464 = load i32, i32* %9, align 4
  %31465 = icmp eq i32 %31451, %31464
  %31466 = or i1 %31463, %31465
  %31467 = load i32, i32* %10, align 4
  %31468 = icmp eq i32 %31451, %31467
  %31469 = or i1 %31466, %31468
  %31470 = load i32, i32* %11, align 4
  %31471 = icmp eq i32 %31451, %31470
  %31472 = or i1 %31469, %31471
  %31473 = load i32, i32* %12, align 4
  %31474 = icmp eq i32 %31451, %31473
  %31475 = or i1 %31472, %31474
  %31476 = load i32, i32* %13, align 4
  %31477 = icmp eq i32 %31451, %31476
  %31478 = or i1 %31475, %31477
  %31479 = load i32, i32* %14, align 4
  %31480 = icmp eq i32 %31451, %31479
  %31481 = or i1 %31478, %31480
  %31482 = load i32, i32* %15, align 4
  %31483 = icmp eq i32 %31451, %31482
  %31484 = or i1 %31481, %31483
  %31485 = load i32, i32* %16, align 4
  %31486 = icmp eq i32 %31451, %31485
  %31487 = or i1 %31484, %31486
  %31488 = load i32, i32* %17, align 4
  %31489 = icmp eq i32 %31451, %31488
  %31490 = or i1 %31487, %31489
  %31491 = load i32, i32* %18, align 4
  %31492 = icmp eq i32 %31451, %31491
  %31493 = or i1 %31490, %31492
  %31494 = load i32, i32* %19, align 4
  %31495 = icmp eq i32 %31451, %31494
  %31496 = or i1 %31493, %31495
  %31497 = load i32, i32* %20, align 4
  %31498 = icmp eq i32 %31451, %31497
  %31499 = or i1 %31496, %31498
  %31500 = load i32, i32* %21, align 4
  %31501 = icmp eq i32 %31451, %31500
  %31502 = or i1 %31499, %31501
  %31503 = load i32, i32* %22, align 4
  %31504 = icmp eq i32 %31451, %31503
  %31505 = or i1 %31502, %31504
  %31506 = load i32, i32* %23, align 4
  %31507 = icmp eq i32 %31451, %31506
  %31508 = or i1 %31505, %31507
  %31509 = load i32, i32* %24, align 4
  %31510 = icmp eq i32 %31451, %31509
  %31511 = or i1 %31508, %31510
  %31512 = load i32, i32* %25, align 4
  %31513 = icmp eq i32 %31451, %31512
  %31514 = or i1 %31511, %31513
  %31515 = load i32, i32* %26, align 4
  %31516 = icmp eq i32 %31451, %31515
  %31517 = or i1 %31514, %31516
  %31518 = load i32, i32* %27, align 4
  %31519 = icmp eq i32 %31451, %31518
  %31520 = or i1 %31517, %31519
  %31521 = load i32, i32* %28, align 4
  %31522 = icmp eq i32 %31451, %31521
  %31523 = or i1 %31520, %31522
  %31524 = load i32, i32* %29, align 4
  %31525 = icmp eq i32 %31451, %31524
  %31526 = or i1 %31523, %31525
  %31527 = load i32, i32* %30, align 4
  %31528 = icmp eq i32 %31451, %31527
  %31529 = or i1 %31526, %31528
  %31530 = load i32, i32* %31, align 4
  %31531 = icmp eq i32 %31451, %31530
  %31532 = or i1 %31529, %31531
  %31533 = load i32, i32* %32, align 4
  %31534 = icmp eq i32 %31451, %31533
  %31535 = or i1 %31532, %31534
  %31536 = load i32, i32* %33, align 4
  %31537 = icmp eq i32 %31451, %31536
  %31538 = or i1 %31535, %31537
  %31539 = load i32, i32* %34, align 4
  %31540 = icmp eq i32 %31451, %31539
  %31541 = or i1 %31538, %31540
  %31542 = load i32, i32* %35, align 4
  %31543 = icmp eq i32 %31451, %31542
  %31544 = or i1 %31541, %31543
  %31545 = load i32, i32* %36, align 4
  %31546 = icmp eq i32 %31451, %31545
  %31547 = or i1 %31544, %31546
  %31548 = load i32, i32* %37, align 4
  %31549 = icmp eq i32 %31451, %31548
  %31550 = or i1 %31547, %31549
  %31551 = load i32, i32* %38, align 4
  %31552 = icmp eq i32 %31451, %31551
  %31553 = or i1 %31550, %31552
  %31554 = load i32, i32* %39, align 4
  %31555 = icmp eq i32 %31451, %31554
  %31556 = or i1 %31553, %31555
  %31557 = load i32, i32* %40, align 4
  %31558 = icmp eq i32 %31451, %31557
  %31559 = or i1 %31556, %31558
  %31560 = load i32, i32* %41, align 4
  %31561 = icmp eq i32 %31451, %31560
  %31562 = or i1 %31559, %31561
  %31563 = load i32, i32* %42, align 4
  %31564 = icmp eq i32 %31451, %31563
  %31565 = or i1 %31562, %31564
  %31566 = load i32, i32* %43, align 4
  %31567 = icmp eq i32 %31451, %31566
  %31568 = or i1 %31565, %31567
  %31569 = load i32, i32* %44, align 4
  %31570 = icmp eq i32 %31451, %31569
  %31571 = or i1 %31568, %31570
  %31572 = load i32, i32* %45, align 4
  %31573 = icmp eq i32 %31451, %31572
  %31574 = or i1 %31571, %31573
  %31575 = load i32, i32* %46, align 4
  %31576 = icmp eq i32 %31451, %31575
  %31577 = or i1 %31574, %31576
  %31578 = load i32, i32* %47, align 4
  %31579 = icmp eq i32 %31451, %31578
  %31580 = or i1 %31577, %31579
  %31581 = load i32, i32* %48, align 4
  %31582 = icmp eq i32 %31451, %31581
  %31583 = or i1 %31580, %31582
  %31584 = load i32, i32* %49, align 4
  %31585 = icmp eq i32 %31451, %31584
  %31586 = or i1 %31583, %31585
  %31587 = load i32, i32* %50, align 4
  %31588 = icmp eq i32 %31451, %31587
  %31589 = or i1 %31586, %31588
  %31590 = load i32, i32* %51, align 4
  %31591 = icmp eq i32 %31451, %31590
  %31592 = or i1 %31589, %31591
  %31593 = load i32, i32* %52, align 4
  %31594 = icmp eq i32 %31451, %31593
  %31595 = or i1 %31592, %31594
  %31596 = load i32, i32* %53, align 4
  %31597 = icmp eq i32 %31451, %31596
  %31598 = or i1 %31595, %31597
  %31599 = load i32, i32* %54, align 4
  %31600 = icmp eq i32 %31451, %31599
  %31601 = or i1 %31598, %31600
  %31602 = load i32, i32* %55, align 4
  %31603 = icmp eq i32 %31451, %31602
  %31604 = or i1 %31601, %31603
  %31605 = load i32, i32* %56, align 4
  %31606 = icmp eq i32 %31451, %31605
  %31607 = or i1 %31604, %31606
  %31608 = load i32, i32* %57, align 4
  %31609 = icmp eq i32 %31451, %31608
  %31610 = or i1 %31607, %31609
  %31611 = load i32, i32* %58, align 4
  %31612 = icmp eq i32 %31451, %31611
  %31613 = or i1 %31610, %31612
  %31614 = load i32, i32* %59, align 4
  %31615 = icmp eq i32 %31451, %31614
  %31616 = or i1 %31613, %31615
  %31617 = load i32, i32* %60, align 4
  %31618 = icmp eq i32 %31451, %31617
  %31619 = or i1 %31616, %31618
  %31620 = load i32, i32* %61, align 4
  %31621 = icmp eq i32 %31451, %31620
  %31622 = or i1 %31619, %31621
  %31623 = load i32, i32* %62, align 4
  %31624 = icmp eq i32 %31451, %31623
  %31625 = or i1 %31622, %31624
  %31626 = getelementptr i8, i8 addrspace(1)* %4, i32 114
  %31627 = zext i1 %31625 to i8
  store i8 %31627, i8 addrspace(1)* %31626, align 1, !nosanitize !3
  %31628 = load i256, i256* %31450, align 4
  %31629 = alloca i256, align 8
  store i256 %31628, i256* %31629, align 4
  %31630 = alloca i256, align 8
  store i256 1, i256* %31630, align 4
  %31631 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %31629, i256* %31630, i256* %31631), !pc !466, !intsan !6
  %31632 = load i256, i256* %31631, align 4
  %31633 = and i256 1461501637330902918203684832716283019655932542975, %31632
  %31634 = and i256 1461501637330902918203684832716283019655932542975, %31633
  %31635 = icmp eq i256 %31634, %31448
  %31636 = icmp eq i1 %31635, false
  %31637 = icmp eq i1 %31636, false
  %31638 = trunc i256 10722 to i64
  %jump.check171 = icmp ne i1 %31637, false
  %31639 = load i64, i64* %STACK_DEP_PTR, align 4
  %31640 = add i64 %31639, 1
  store i64 %31640, i64* %STACK_DEP_PTR, align 4
  %31641 = load i64, i64* %STACK_DEP_PTR, align 4
  %31642 = getelementptr i256, i256* %STACK, i64 %31641
  store i256 0, i256* %31642, align 4
  %31643 = load i64, i64* %STACK_DEP_PTR, align 4
  %31644 = add i64 %31643, 1
  store i64 %31644, i64* %STACK_DEP_PTR, align 4
  %31645 = load i64, i64* %STACK_DEP_PTR, align 4
  %31646 = getelementptr i256, i256* %STACK, i64 %31645
  store i256 0, i256* %31646, align 4
  %31647 = load i64, i64* %STACK_DEP_PTR, align 4
  %31648 = add i64 %31647, 1
  store i64 %31648, i64* %STACK_DEP_PTR, align 4
  %31649 = load i64, i64* %STACK_DEP_PTR, align 4
  %31650 = getelementptr i256, i256* %STACK, i64 %31649
  store i256 0, i256* %31650, align 4
  br i1 %jump.check171, label %.10722, label %.10718, !EVMBB !4

.10718:                                           ; preds = %31440
  %31651 = load i64, i64* %remaing_gas, align 4
  %31652 = icmp ugt i64 40, %31651
  br i1 %31652, label %Abort, label %31653

31653:                                            ; preds = %.10718
  %31654 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31655 = xor i32 %31654, 2690
  %31656 = urem i32 %31655, 4096
  %31657 = getelementptr i8, i8 addrspace(1)* %4, i32 %31656
  %31658 = load i8, i8 addrspace(1)* %31657, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31657, align 1, !nosanitize !3
  store i32 1345, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31659 = sub i64 %31651, 40
  store i64 %31659, i64* %remaing_gas, align 4
  %31660 = load i64, i64* %STACK_DEP_PTR, align 4
  %31661 = sub i64 %31660, 0
  store i64 %31661, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.10722:                                           ; preds = %31440, %JumpTable
  %31662 = load i64, i64* %remaing_gas, align 4
  %31663 = icmp ugt i64 168, %31662
  br i1 %31663, label %Abort, label %31664

31664:                                            ; preds = %.10722
  %31665 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31666 = xor i32 %31665, 868
  %31667 = urem i32 %31666, 4096
  %31668 = getelementptr i8, i8 addrspace(1)* %4, i32 %31667
  %31669 = load i8, i8 addrspace(1)* %31668, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31668, align 1, !nosanitize !3
  store i32 434, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31670 = sub i64 %31662, 168
  store i64 %31670, i64* %remaing_gas, align 4
  %31671 = add i256 0, 9, !pc !467, !intsan !10
  %31672 = alloca i256, align 8
  store i256 %31671, i256* %31672, align 4
  %31673 = alloca i256, align 8
  call void @__device_sload(i256* %31672, i256* %31673)
  %31674 = call i32 @__hashword(i256* %31672)
  %31675 = load i32, i32* %5, align 4
  %31676 = icmp eq i32 %31674, %31675
  %31677 = or i1 false, %31676
  %31678 = load i32, i32* %6, align 4
  %31679 = icmp eq i32 %31674, %31678
  %31680 = or i1 %31677, %31679
  %31681 = load i32, i32* %7, align 4
  %31682 = icmp eq i32 %31674, %31681
  %31683 = or i1 %31680, %31682
  %31684 = load i32, i32* %8, align 4
  %31685 = icmp eq i32 %31674, %31684
  %31686 = or i1 %31683, %31685
  %31687 = load i32, i32* %9, align 4
  %31688 = icmp eq i32 %31674, %31687
  %31689 = or i1 %31686, %31688
  %31690 = load i32, i32* %10, align 4
  %31691 = icmp eq i32 %31674, %31690
  %31692 = or i1 %31689, %31691
  %31693 = load i32, i32* %11, align 4
  %31694 = icmp eq i32 %31674, %31693
  %31695 = or i1 %31692, %31694
  %31696 = load i32, i32* %12, align 4
  %31697 = icmp eq i32 %31674, %31696
  %31698 = or i1 %31695, %31697
  %31699 = load i32, i32* %13, align 4
  %31700 = icmp eq i32 %31674, %31699
  %31701 = or i1 %31698, %31700
  %31702 = load i32, i32* %14, align 4
  %31703 = icmp eq i32 %31674, %31702
  %31704 = or i1 %31701, %31703
  %31705 = load i32, i32* %15, align 4
  %31706 = icmp eq i32 %31674, %31705
  %31707 = or i1 %31704, %31706
  %31708 = load i32, i32* %16, align 4
  %31709 = icmp eq i32 %31674, %31708
  %31710 = or i1 %31707, %31709
  %31711 = load i32, i32* %17, align 4
  %31712 = icmp eq i32 %31674, %31711
  %31713 = or i1 %31710, %31712
  %31714 = load i32, i32* %18, align 4
  %31715 = icmp eq i32 %31674, %31714
  %31716 = or i1 %31713, %31715
  %31717 = load i32, i32* %19, align 4
  %31718 = icmp eq i32 %31674, %31717
  %31719 = or i1 %31716, %31718
  %31720 = load i32, i32* %20, align 4
  %31721 = icmp eq i32 %31674, %31720
  %31722 = or i1 %31719, %31721
  %31723 = load i32, i32* %21, align 4
  %31724 = icmp eq i32 %31674, %31723
  %31725 = or i1 %31722, %31724
  %31726 = load i32, i32* %22, align 4
  %31727 = icmp eq i32 %31674, %31726
  %31728 = or i1 %31725, %31727
  %31729 = load i32, i32* %23, align 4
  %31730 = icmp eq i32 %31674, %31729
  %31731 = or i1 %31728, %31730
  %31732 = load i32, i32* %24, align 4
  %31733 = icmp eq i32 %31674, %31732
  %31734 = or i1 %31731, %31733
  %31735 = load i32, i32* %25, align 4
  %31736 = icmp eq i32 %31674, %31735
  %31737 = or i1 %31734, %31736
  %31738 = load i32, i32* %26, align 4
  %31739 = icmp eq i32 %31674, %31738
  %31740 = or i1 %31737, %31739
  %31741 = load i32, i32* %27, align 4
  %31742 = icmp eq i32 %31674, %31741
  %31743 = or i1 %31740, %31742
  %31744 = load i32, i32* %28, align 4
  %31745 = icmp eq i32 %31674, %31744
  %31746 = or i1 %31743, %31745
  %31747 = load i32, i32* %29, align 4
  %31748 = icmp eq i32 %31674, %31747
  %31749 = or i1 %31746, %31748
  %31750 = load i32, i32* %30, align 4
  %31751 = icmp eq i32 %31674, %31750
  %31752 = or i1 %31749, %31751
  %31753 = load i32, i32* %31, align 4
  %31754 = icmp eq i32 %31674, %31753
  %31755 = or i1 %31752, %31754
  %31756 = load i32, i32* %32, align 4
  %31757 = icmp eq i32 %31674, %31756
  %31758 = or i1 %31755, %31757
  %31759 = load i32, i32* %33, align 4
  %31760 = icmp eq i32 %31674, %31759
  %31761 = or i1 %31758, %31760
  %31762 = load i32, i32* %34, align 4
  %31763 = icmp eq i32 %31674, %31762
  %31764 = or i1 %31761, %31763
  %31765 = load i32, i32* %35, align 4
  %31766 = icmp eq i32 %31674, %31765
  %31767 = or i1 %31764, %31766
  %31768 = load i32, i32* %36, align 4
  %31769 = icmp eq i32 %31674, %31768
  %31770 = or i1 %31767, %31769
  %31771 = load i32, i32* %37, align 4
  %31772 = icmp eq i32 %31674, %31771
  %31773 = or i1 %31770, %31772
  %31774 = load i32, i32* %38, align 4
  %31775 = icmp eq i32 %31674, %31774
  %31776 = or i1 %31773, %31775
  %31777 = load i32, i32* %39, align 4
  %31778 = icmp eq i32 %31674, %31777
  %31779 = or i1 %31776, %31778
  %31780 = load i32, i32* %40, align 4
  %31781 = icmp eq i32 %31674, %31780
  %31782 = or i1 %31779, %31781
  %31783 = load i32, i32* %41, align 4
  %31784 = icmp eq i32 %31674, %31783
  %31785 = or i1 %31782, %31784
  %31786 = load i32, i32* %42, align 4
  %31787 = icmp eq i32 %31674, %31786
  %31788 = or i1 %31785, %31787
  %31789 = load i32, i32* %43, align 4
  %31790 = icmp eq i32 %31674, %31789
  %31791 = or i1 %31788, %31790
  %31792 = load i32, i32* %44, align 4
  %31793 = icmp eq i32 %31674, %31792
  %31794 = or i1 %31791, %31793
  %31795 = load i32, i32* %45, align 4
  %31796 = icmp eq i32 %31674, %31795
  %31797 = or i1 %31794, %31796
  %31798 = load i32, i32* %46, align 4
  %31799 = icmp eq i32 %31674, %31798
  %31800 = or i1 %31797, %31799
  %31801 = load i32, i32* %47, align 4
  %31802 = icmp eq i32 %31674, %31801
  %31803 = or i1 %31800, %31802
  %31804 = load i32, i32* %48, align 4
  %31805 = icmp eq i32 %31674, %31804
  %31806 = or i1 %31803, %31805
  %31807 = load i32, i32* %49, align 4
  %31808 = icmp eq i32 %31674, %31807
  %31809 = or i1 %31806, %31808
  %31810 = load i32, i32* %50, align 4
  %31811 = icmp eq i32 %31674, %31810
  %31812 = or i1 %31809, %31811
  %31813 = load i32, i32* %51, align 4
  %31814 = icmp eq i32 %31674, %31813
  %31815 = or i1 %31812, %31814
  %31816 = load i32, i32* %52, align 4
  %31817 = icmp eq i32 %31674, %31816
  %31818 = or i1 %31815, %31817
  %31819 = load i32, i32* %53, align 4
  %31820 = icmp eq i32 %31674, %31819
  %31821 = or i1 %31818, %31820
  %31822 = load i32, i32* %54, align 4
  %31823 = icmp eq i32 %31674, %31822
  %31824 = or i1 %31821, %31823
  %31825 = load i32, i32* %55, align 4
  %31826 = icmp eq i32 %31674, %31825
  %31827 = or i1 %31824, %31826
  %31828 = load i32, i32* %56, align 4
  %31829 = icmp eq i32 %31674, %31828
  %31830 = or i1 %31827, %31829
  %31831 = load i32, i32* %57, align 4
  %31832 = icmp eq i32 %31674, %31831
  %31833 = or i1 %31830, %31832
  %31834 = load i32, i32* %58, align 4
  %31835 = icmp eq i32 %31674, %31834
  %31836 = or i1 %31833, %31835
  %31837 = load i32, i32* %59, align 4
  %31838 = icmp eq i32 %31674, %31837
  %31839 = or i1 %31836, %31838
  %31840 = load i32, i32* %60, align 4
  %31841 = icmp eq i32 %31674, %31840
  %31842 = or i1 %31839, %31841
  %31843 = load i32, i32* %61, align 4
  %31844 = icmp eq i32 %31674, %31843
  %31845 = or i1 %31842, %31844
  %31846 = load i32, i32* %62, align 4
  %31847 = icmp eq i32 %31674, %31846
  %31848 = or i1 %31845, %31847
  %31849 = getelementptr i8, i8 addrspace(1)* %4, i32 115
  %31850 = zext i1 %31848 to i8
  store i8 %31850, i8 addrspace(1)* %31849, align 1, !nosanitize !3
  %31851 = load i256, i256* %31673, align 4
  %31852 = alloca i256, align 8
  store i256 %31851, i256* %31852, align 4
  %31853 = alloca i256, align 8
  store i256 1, i256* %31853, align 4
  %31854 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %31852, i256* %31853, i256* %31854), !pc !468, !intsan !6
  %31855 = load i256, i256* %31854, align 4
  %31856 = and i256 1461501637330902918203684832716283019655932542975, %31855
  %31857 = and i256 1461501637330902918203684832716283019655932542975, %31856
  %31858 = icmp eq i256 %31857, 0
  %31859 = icmp eq i1 %31858, false
  %31860 = trunc i256 10795 to i64
  %jump.check174 = icmp ne i1 %31859, false
  br i1 %jump.check174, label %.10795, label %.10791, !EVMBB !4

.10791:                                           ; preds = %31664
  %31861 = load i64, i64* %remaing_gas, align 4
  %31862 = icmp ugt i64 16, %31861
  br i1 %31862, label %Abort, label %31863

31863:                                            ; preds = %.10791
  %31864 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31865 = xor i32 %31864, 3992
  %31866 = urem i32 %31865, 4096
  %31867 = getelementptr i8, i8 addrspace(1)* %4, i32 %31866
  %31868 = load i8, i8 addrspace(1)* %31867, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31867, align 1, !nosanitize !3
  store i32 1996, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31869 = sub i64 %31861, 16
  store i64 %31869, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10795:                                           ; preds = %31664, %JumpTable
  %31870 = load i64, i64* %remaing_gas, align 4
  %31871 = icmp ugt i64 152, %31870
  br i1 %31871, label %Abort, label %31872

31872:                                            ; preds = %.10795
  %31873 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31874 = xor i32 %31873, 2521
  %31875 = urem i32 %31874, 4096
  %31876 = getelementptr i8, i8 addrspace(1)* %4, i32 %31875
  %31877 = load i8, i8 addrspace(1)* %31876, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %31876, align 1, !nosanitize !3
  store i32 1260, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %31878 = sub i64 %31870, 152
  store i64 %31878, i64* %remaing_gas, align 4
  %31879 = alloca i256, align 8
  store i256 8, i256* %31879, align 4
  %31880 = alloca i256, align 8
  call void @__device_sload(i256* %31879, i256* %31880)
  %31881 = call i32 @__hashword(i256* %31879)
  %31882 = load i32, i32* %5, align 4
  %31883 = icmp eq i32 %31881, %31882
  %31884 = or i1 false, %31883
  %31885 = load i32, i32* %6, align 4
  %31886 = icmp eq i32 %31881, %31885
  %31887 = or i1 %31884, %31886
  %31888 = load i32, i32* %7, align 4
  %31889 = icmp eq i32 %31881, %31888
  %31890 = or i1 %31887, %31889
  %31891 = load i32, i32* %8, align 4
  %31892 = icmp eq i32 %31881, %31891
  %31893 = or i1 %31890, %31892
  %31894 = load i32, i32* %9, align 4
  %31895 = icmp eq i32 %31881, %31894
  %31896 = or i1 %31893, %31895
  %31897 = load i32, i32* %10, align 4
  %31898 = icmp eq i32 %31881, %31897
  %31899 = or i1 %31896, %31898
  %31900 = load i32, i32* %11, align 4
  %31901 = icmp eq i32 %31881, %31900
  %31902 = or i1 %31899, %31901
  %31903 = load i32, i32* %12, align 4
  %31904 = icmp eq i32 %31881, %31903
  %31905 = or i1 %31902, %31904
  %31906 = load i32, i32* %13, align 4
  %31907 = icmp eq i32 %31881, %31906
  %31908 = or i1 %31905, %31907
  %31909 = load i32, i32* %14, align 4
  %31910 = icmp eq i32 %31881, %31909
  %31911 = or i1 %31908, %31910
  %31912 = load i32, i32* %15, align 4
  %31913 = icmp eq i32 %31881, %31912
  %31914 = or i1 %31911, %31913
  %31915 = load i32, i32* %16, align 4
  %31916 = icmp eq i32 %31881, %31915
  %31917 = or i1 %31914, %31916
  %31918 = load i32, i32* %17, align 4
  %31919 = icmp eq i32 %31881, %31918
  %31920 = or i1 %31917, %31919
  %31921 = load i32, i32* %18, align 4
  %31922 = icmp eq i32 %31881, %31921
  %31923 = or i1 %31920, %31922
  %31924 = load i32, i32* %19, align 4
  %31925 = icmp eq i32 %31881, %31924
  %31926 = or i1 %31923, %31925
  %31927 = load i32, i32* %20, align 4
  %31928 = icmp eq i32 %31881, %31927
  %31929 = or i1 %31926, %31928
  %31930 = load i32, i32* %21, align 4
  %31931 = icmp eq i32 %31881, %31930
  %31932 = or i1 %31929, %31931
  %31933 = load i32, i32* %22, align 4
  %31934 = icmp eq i32 %31881, %31933
  %31935 = or i1 %31932, %31934
  %31936 = load i32, i32* %23, align 4
  %31937 = icmp eq i32 %31881, %31936
  %31938 = or i1 %31935, %31937
  %31939 = load i32, i32* %24, align 4
  %31940 = icmp eq i32 %31881, %31939
  %31941 = or i1 %31938, %31940
  %31942 = load i32, i32* %25, align 4
  %31943 = icmp eq i32 %31881, %31942
  %31944 = or i1 %31941, %31943
  %31945 = load i32, i32* %26, align 4
  %31946 = icmp eq i32 %31881, %31945
  %31947 = or i1 %31944, %31946
  %31948 = load i32, i32* %27, align 4
  %31949 = icmp eq i32 %31881, %31948
  %31950 = or i1 %31947, %31949
  %31951 = load i32, i32* %28, align 4
  %31952 = icmp eq i32 %31881, %31951
  %31953 = or i1 %31950, %31952
  %31954 = load i32, i32* %29, align 4
  %31955 = icmp eq i32 %31881, %31954
  %31956 = or i1 %31953, %31955
  %31957 = load i32, i32* %30, align 4
  %31958 = icmp eq i32 %31881, %31957
  %31959 = or i1 %31956, %31958
  %31960 = load i32, i32* %31, align 4
  %31961 = icmp eq i32 %31881, %31960
  %31962 = or i1 %31959, %31961
  %31963 = load i32, i32* %32, align 4
  %31964 = icmp eq i32 %31881, %31963
  %31965 = or i1 %31962, %31964
  %31966 = load i32, i32* %33, align 4
  %31967 = icmp eq i32 %31881, %31966
  %31968 = or i1 %31965, %31967
  %31969 = load i32, i32* %34, align 4
  %31970 = icmp eq i32 %31881, %31969
  %31971 = or i1 %31968, %31970
  %31972 = load i32, i32* %35, align 4
  %31973 = icmp eq i32 %31881, %31972
  %31974 = or i1 %31971, %31973
  %31975 = load i32, i32* %36, align 4
  %31976 = icmp eq i32 %31881, %31975
  %31977 = or i1 %31974, %31976
  %31978 = load i32, i32* %37, align 4
  %31979 = icmp eq i32 %31881, %31978
  %31980 = or i1 %31977, %31979
  %31981 = load i32, i32* %38, align 4
  %31982 = icmp eq i32 %31881, %31981
  %31983 = or i1 %31980, %31982
  %31984 = load i32, i32* %39, align 4
  %31985 = icmp eq i32 %31881, %31984
  %31986 = or i1 %31983, %31985
  %31987 = load i32, i32* %40, align 4
  %31988 = icmp eq i32 %31881, %31987
  %31989 = or i1 %31986, %31988
  %31990 = load i32, i32* %41, align 4
  %31991 = icmp eq i32 %31881, %31990
  %31992 = or i1 %31989, %31991
  %31993 = load i32, i32* %42, align 4
  %31994 = icmp eq i32 %31881, %31993
  %31995 = or i1 %31992, %31994
  %31996 = load i32, i32* %43, align 4
  %31997 = icmp eq i32 %31881, %31996
  %31998 = or i1 %31995, %31997
  %31999 = load i32, i32* %44, align 4
  %32000 = icmp eq i32 %31881, %31999
  %32001 = or i1 %31998, %32000
  %32002 = load i32, i32* %45, align 4
  %32003 = icmp eq i32 %31881, %32002
  %32004 = or i1 %32001, %32003
  %32005 = load i32, i32* %46, align 4
  %32006 = icmp eq i32 %31881, %32005
  %32007 = or i1 %32004, %32006
  %32008 = load i32, i32* %47, align 4
  %32009 = icmp eq i32 %31881, %32008
  %32010 = or i1 %32007, %32009
  %32011 = load i32, i32* %48, align 4
  %32012 = icmp eq i32 %31881, %32011
  %32013 = or i1 %32010, %32012
  %32014 = load i32, i32* %49, align 4
  %32015 = icmp eq i32 %31881, %32014
  %32016 = or i1 %32013, %32015
  %32017 = load i32, i32* %50, align 4
  %32018 = icmp eq i32 %31881, %32017
  %32019 = or i1 %32016, %32018
  %32020 = load i32, i32* %51, align 4
  %32021 = icmp eq i32 %31881, %32020
  %32022 = or i1 %32019, %32021
  %32023 = load i32, i32* %52, align 4
  %32024 = icmp eq i32 %31881, %32023
  %32025 = or i1 %32022, %32024
  %32026 = load i32, i32* %53, align 4
  %32027 = icmp eq i32 %31881, %32026
  %32028 = or i1 %32025, %32027
  %32029 = load i32, i32* %54, align 4
  %32030 = icmp eq i32 %31881, %32029
  %32031 = or i1 %32028, %32030
  %32032 = load i32, i32* %55, align 4
  %32033 = icmp eq i32 %31881, %32032
  %32034 = or i1 %32031, %32033
  %32035 = load i32, i32* %56, align 4
  %32036 = icmp eq i32 %31881, %32035
  %32037 = or i1 %32034, %32036
  %32038 = load i32, i32* %57, align 4
  %32039 = icmp eq i32 %31881, %32038
  %32040 = or i1 %32037, %32039
  %32041 = load i32, i32* %58, align 4
  %32042 = icmp eq i32 %31881, %32041
  %32043 = or i1 %32040, %32042
  %32044 = load i32, i32* %59, align 4
  %32045 = icmp eq i32 %31881, %32044
  %32046 = or i1 %32043, %32045
  %32047 = load i32, i32* %60, align 4
  %32048 = icmp eq i32 %31881, %32047
  %32049 = or i1 %32046, %32048
  %32050 = load i32, i32* %61, align 4
  %32051 = icmp eq i32 %31881, %32050
  %32052 = or i1 %32049, %32051
  %32053 = load i32, i32* %62, align 4
  %32054 = icmp eq i32 %31881, %32053
  %32055 = or i1 %32052, %32054
  %32056 = getelementptr i8, i8 addrspace(1)* %4, i32 116
  %32057 = zext i1 %32055 to i8
  store i8 %32057, i8 addrspace(1)* %32056, align 1, !nosanitize !3
  %32058 = load i256, i256* %31880, align 4
  %32059 = alloca i256, align 8
  store i256 %32058, i256* %32059, align 4
  %32060 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %32060, align 4
  %32061 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %32059, i256* %32060, i256* %32061), !pc !469, !intsan !6
  %32062 = load i256, i256* %32061, align 4
  %32063 = and i256 255, %32062
  %32064 = icmp eq i256 %32063, 0
  %32065 = icmp eq i1 %32064, false
  %32066 = trunc i256 10822 to i64
  %jump.check177 = icmp ne i1 %32065, false
  br i1 %jump.check177, label %.10822, label %.10818, !EVMBB !4

.10818:                                           ; preds = %31872
  %32067 = load i64, i64* %remaing_gas, align 4
  %32068 = icmp ugt i64 16, %32067
  br i1 %32068, label %Abort, label %32069

32069:                                            ; preds = %.10818
  %32070 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32071 = xor i32 %32070, 2984
  %32072 = urem i32 %32071, 4096
  %32073 = getelementptr i8, i8 addrspace(1)* %4, i32 %32072
  %32074 = load i8, i8 addrspace(1)* %32073, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32073, align 1, !nosanitize !3
  store i32 1492, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32075 = sub i64 %32067, 16
  store i64 %32075, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10822:                                           ; preds = %31872, %JumpTable
  %32076 = load i64, i64* %remaing_gas, align 4
  %32077 = icmp ugt i64 112, %32076
  br i1 %32077, label %Abort, label %32078

32078:                                            ; preds = %.10822
  %32079 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32080 = xor i32 %32079, 2695
  %32081 = urem i32 %32080, 4096
  %32082 = getelementptr i8, i8 addrspace(1)* %4, i32 %32081
  %32083 = load i8, i8 addrspace(1)* %32082, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32082, align 1, !nosanitize !3
  store i32 1347, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32084 = sub i64 %32076, 112
  store i64 %32084, i64* %remaing_gas, align 4
  %timestamp = load i256, i256 addrspace(4)* @TIMESTAMP, align 4, !pc !470, !bsdsan !3
  %32085 = add i256 1, 9, !pc !471, !intsan !10
  %32086 = alloca i256, align 8
  store i256 %32085, i256* %32086, align 4
  %32087 = alloca i256, align 8
  call void @__device_sload(i256* %32086, i256* %32087)
  %32088 = call i32 @__hashword(i256* %32086)
  %32089 = load i32, i32* %5, align 4
  %32090 = icmp eq i32 %32088, %32089
  %32091 = or i1 false, %32090
  %32092 = load i32, i32* %6, align 4
  %32093 = icmp eq i32 %32088, %32092
  %32094 = or i1 %32091, %32093
  %32095 = load i32, i32* %7, align 4
  %32096 = icmp eq i32 %32088, %32095
  %32097 = or i1 %32094, %32096
  %32098 = load i32, i32* %8, align 4
  %32099 = icmp eq i32 %32088, %32098
  %32100 = or i1 %32097, %32099
  %32101 = load i32, i32* %9, align 4
  %32102 = icmp eq i32 %32088, %32101
  %32103 = or i1 %32100, %32102
  %32104 = load i32, i32* %10, align 4
  %32105 = icmp eq i32 %32088, %32104
  %32106 = or i1 %32103, %32105
  %32107 = load i32, i32* %11, align 4
  %32108 = icmp eq i32 %32088, %32107
  %32109 = or i1 %32106, %32108
  %32110 = load i32, i32* %12, align 4
  %32111 = icmp eq i32 %32088, %32110
  %32112 = or i1 %32109, %32111
  %32113 = load i32, i32* %13, align 4
  %32114 = icmp eq i32 %32088, %32113
  %32115 = or i1 %32112, %32114
  %32116 = load i32, i32* %14, align 4
  %32117 = icmp eq i32 %32088, %32116
  %32118 = or i1 %32115, %32117
  %32119 = load i32, i32* %15, align 4
  %32120 = icmp eq i32 %32088, %32119
  %32121 = or i1 %32118, %32120
  %32122 = load i32, i32* %16, align 4
  %32123 = icmp eq i32 %32088, %32122
  %32124 = or i1 %32121, %32123
  %32125 = load i32, i32* %17, align 4
  %32126 = icmp eq i32 %32088, %32125
  %32127 = or i1 %32124, %32126
  %32128 = load i32, i32* %18, align 4
  %32129 = icmp eq i32 %32088, %32128
  %32130 = or i1 %32127, %32129
  %32131 = load i32, i32* %19, align 4
  %32132 = icmp eq i32 %32088, %32131
  %32133 = or i1 %32130, %32132
  %32134 = load i32, i32* %20, align 4
  %32135 = icmp eq i32 %32088, %32134
  %32136 = or i1 %32133, %32135
  %32137 = load i32, i32* %21, align 4
  %32138 = icmp eq i32 %32088, %32137
  %32139 = or i1 %32136, %32138
  %32140 = load i32, i32* %22, align 4
  %32141 = icmp eq i32 %32088, %32140
  %32142 = or i1 %32139, %32141
  %32143 = load i32, i32* %23, align 4
  %32144 = icmp eq i32 %32088, %32143
  %32145 = or i1 %32142, %32144
  %32146 = load i32, i32* %24, align 4
  %32147 = icmp eq i32 %32088, %32146
  %32148 = or i1 %32145, %32147
  %32149 = load i32, i32* %25, align 4
  %32150 = icmp eq i32 %32088, %32149
  %32151 = or i1 %32148, %32150
  %32152 = load i32, i32* %26, align 4
  %32153 = icmp eq i32 %32088, %32152
  %32154 = or i1 %32151, %32153
  %32155 = load i32, i32* %27, align 4
  %32156 = icmp eq i32 %32088, %32155
  %32157 = or i1 %32154, %32156
  %32158 = load i32, i32* %28, align 4
  %32159 = icmp eq i32 %32088, %32158
  %32160 = or i1 %32157, %32159
  %32161 = load i32, i32* %29, align 4
  %32162 = icmp eq i32 %32088, %32161
  %32163 = or i1 %32160, %32162
  %32164 = load i32, i32* %30, align 4
  %32165 = icmp eq i32 %32088, %32164
  %32166 = or i1 %32163, %32165
  %32167 = load i32, i32* %31, align 4
  %32168 = icmp eq i32 %32088, %32167
  %32169 = or i1 %32166, %32168
  %32170 = load i32, i32* %32, align 4
  %32171 = icmp eq i32 %32088, %32170
  %32172 = or i1 %32169, %32171
  %32173 = load i32, i32* %33, align 4
  %32174 = icmp eq i32 %32088, %32173
  %32175 = or i1 %32172, %32174
  %32176 = load i32, i32* %34, align 4
  %32177 = icmp eq i32 %32088, %32176
  %32178 = or i1 %32175, %32177
  %32179 = load i32, i32* %35, align 4
  %32180 = icmp eq i32 %32088, %32179
  %32181 = or i1 %32178, %32180
  %32182 = load i32, i32* %36, align 4
  %32183 = icmp eq i32 %32088, %32182
  %32184 = or i1 %32181, %32183
  %32185 = load i32, i32* %37, align 4
  %32186 = icmp eq i32 %32088, %32185
  %32187 = or i1 %32184, %32186
  %32188 = load i32, i32* %38, align 4
  %32189 = icmp eq i32 %32088, %32188
  %32190 = or i1 %32187, %32189
  %32191 = load i32, i32* %39, align 4
  %32192 = icmp eq i32 %32088, %32191
  %32193 = or i1 %32190, %32192
  %32194 = load i32, i32* %40, align 4
  %32195 = icmp eq i32 %32088, %32194
  %32196 = or i1 %32193, %32195
  %32197 = load i32, i32* %41, align 4
  %32198 = icmp eq i32 %32088, %32197
  %32199 = or i1 %32196, %32198
  %32200 = load i32, i32* %42, align 4
  %32201 = icmp eq i32 %32088, %32200
  %32202 = or i1 %32199, %32201
  %32203 = load i32, i32* %43, align 4
  %32204 = icmp eq i32 %32088, %32203
  %32205 = or i1 %32202, %32204
  %32206 = load i32, i32* %44, align 4
  %32207 = icmp eq i32 %32088, %32206
  %32208 = or i1 %32205, %32207
  %32209 = load i32, i32* %45, align 4
  %32210 = icmp eq i32 %32088, %32209
  %32211 = or i1 %32208, %32210
  %32212 = load i32, i32* %46, align 4
  %32213 = icmp eq i32 %32088, %32212
  %32214 = or i1 %32211, %32213
  %32215 = load i32, i32* %47, align 4
  %32216 = icmp eq i32 %32088, %32215
  %32217 = or i1 %32214, %32216
  %32218 = load i32, i32* %48, align 4
  %32219 = icmp eq i32 %32088, %32218
  %32220 = or i1 %32217, %32219
  %32221 = load i32, i32* %49, align 4
  %32222 = icmp eq i32 %32088, %32221
  %32223 = or i1 %32220, %32222
  %32224 = load i32, i32* %50, align 4
  %32225 = icmp eq i32 %32088, %32224
  %32226 = or i1 %32223, %32225
  %32227 = load i32, i32* %51, align 4
  %32228 = icmp eq i32 %32088, %32227
  %32229 = or i1 %32226, %32228
  %32230 = load i32, i32* %52, align 4
  %32231 = icmp eq i32 %32088, %32230
  %32232 = or i1 %32229, %32231
  %32233 = load i32, i32* %53, align 4
  %32234 = icmp eq i32 %32088, %32233
  %32235 = or i1 %32232, %32234
  %32236 = load i32, i32* %54, align 4
  %32237 = icmp eq i32 %32088, %32236
  %32238 = or i1 %32235, %32237
  %32239 = load i32, i32* %55, align 4
  %32240 = icmp eq i32 %32088, %32239
  %32241 = or i1 %32238, %32240
  %32242 = load i32, i32* %56, align 4
  %32243 = icmp eq i32 %32088, %32242
  %32244 = or i1 %32241, %32243
  %32245 = load i32, i32* %57, align 4
  %32246 = icmp eq i32 %32088, %32245
  %32247 = or i1 %32244, %32246
  %32248 = load i32, i32* %58, align 4
  %32249 = icmp eq i32 %32088, %32248
  %32250 = or i1 %32247, %32249
  %32251 = load i32, i32* %59, align 4
  %32252 = icmp eq i32 %32088, %32251
  %32253 = or i1 %32250, %32252
  %32254 = load i32, i32* %60, align 4
  %32255 = icmp eq i32 %32088, %32254
  %32256 = or i1 %32253, %32255
  %32257 = load i32, i32* %61, align 4
  %32258 = icmp eq i32 %32088, %32257
  %32259 = or i1 %32256, %32258
  %32260 = load i32, i32* %62, align 4
  %32261 = icmp eq i32 %32088, %32260
  %32262 = or i1 %32259, %32261
  %32263 = getelementptr i8, i8 addrspace(1)* %4, i32 117
  %32264 = zext i1 %32262 to i8
  store i8 %32264, i8 addrspace(1)* %32263, align 1, !nosanitize !3
  %32265 = load i256, i256* %32087, align 4
  %32266 = add i256 %32265, 259200, !pc !472, !intsan !10
  %32267 = icmp ugt i256 %32266, %timestamp
  %32268 = icmp eq i1 %32267, false
  %32269 = trunc i256 10845 to i64
  %jump.check180 = icmp ne i1 %32268, false
  br i1 %jump.check180, label %.10845, label %.10841, !EVMBB !4

.10841:                                           ; preds = %32078
  %32270 = load i64, i64* %remaing_gas, align 4
  %32271 = icmp ugt i64 16, %32270
  br i1 %32271, label %Abort, label %32272

32272:                                            ; preds = %.10841
  %32273 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32274 = xor i32 %32273, 3701
  %32275 = urem i32 %32274, 4096
  %32276 = getelementptr i8, i8 addrspace(1)* %4, i32 %32275
  %32277 = load i8, i8 addrspace(1)* %32276, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32276, align 1, !nosanitize !3
  store i32 1850, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32278 = sub i64 %32270, 16
  store i64 %32278, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.10845:                                           ; preds = %32078, %JumpTable
  %32279 = load i64, i64* %STACK_DEP_PTR, align 4
  %32280 = getelementptr i256, i256* %STACK, i64 %32279
  %32281 = load i256, i256* %32280, align 4
  %32282 = load i64, i64* %STACK_DEP_PTR, align 4
  %32283 = sub i64 %32282, 1
  store i64 %32283, i64* %STACK_DEP_PTR, align 4
  %32284 = load i64, i64* %STACK_DEP_PTR, align 4
  %32285 = getelementptr i256, i256* %STACK, i64 %32284
  %32286 = load i256, i256* %32285, align 4
  %32287 = load i64, i64* %STACK_DEP_PTR, align 4
  %32288 = sub i64 %32287, 1
  store i64 %32288, i64* %STACK_DEP_PTR, align 4
  %32289 = load i160, i160 addrspace(4)* @SELFADDRESS, align 4
  %32290 = zext i160 %32289 to i256
  %32291 = and i256 1461501637330902918203684832716283019655932542975, %32290
  %32292 = load i64, i64* %STACK_DEP_PTR, align 4
  %32293 = add i64 %32292, 1
  store i64 %32293, i64* %STACK_DEP_PTR, align 4
  %32294 = load i64, i64* %STACK_DEP_PTR, align 4
  %32295 = getelementptr i256, i256* %STACK, i64 %32294
  store i256 -57896044618658097711785492504343953926634992332820282019728792003956564819968, i256* %32295, align 4
  %32296 = load i64, i64* %STACK_DEP_PTR, align 4
  %32297 = add i64 %32296, 1
  store i64 %32297, i64* %STACK_DEP_PTR, align 4
  %32298 = load i64, i64* %STACK_DEP_PTR, align 4
  %32299 = getelementptr i256, i256* %STACK, i64 %32298
  store i256 1, i256* %32299, align 4
  br label %.10876

.10876:                                           ; preds = %32958, %.10845, %JumpTable
  %32300 = load i64, i64* %remaing_gas, align 4
  %32301 = icmp ugt i64 192, %32300
  br i1 %32301, label %Abort, label %32302

32302:                                            ; preds = %.10876
  %32303 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32304 = xor i32 %32303, 613
  %32305 = urem i32 %32304, 4096
  %32306 = getelementptr i8, i8 addrspace(1)* %4, i32 %32305
  %32307 = load i8, i8 addrspace(1)* %32306, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32306, align 1, !nosanitize !3
  store i32 306, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32308 = sub i64 %32300, 192
  store i64 %32308, i64* %remaing_gas, align 4
  %32309 = load i64, i64* %STACK_DEP_PTR, align 4
  %32310 = getelementptr i256, i256* %STACK, i64 %32309
  %32311 = load i256, i256* %32310, align 4
  %32312 = load i64, i64* %STACK_DEP_PTR, align 4
  %32313 = sub i64 %32312, 1
  store i64 %32313, i64* %STACK_DEP_PTR, align 4
  %32314 = alloca i256, align 8
  store i256 5, i256* %32314, align 4
  %32315 = alloca i256, align 8
  call void @__device_sload(i256* %32314, i256* %32315)
  %32316 = call i32 @__hashword(i256* %32314)
  %32317 = load i32, i32* %5, align 4
  %32318 = icmp eq i32 %32316, %32317
  %32319 = or i1 false, %32318
  %32320 = load i32, i32* %6, align 4
  %32321 = icmp eq i32 %32316, %32320
  %32322 = or i1 %32319, %32321
  %32323 = load i32, i32* %7, align 4
  %32324 = icmp eq i32 %32316, %32323
  %32325 = or i1 %32322, %32324
  %32326 = load i32, i32* %8, align 4
  %32327 = icmp eq i32 %32316, %32326
  %32328 = or i1 %32325, %32327
  %32329 = load i32, i32* %9, align 4
  %32330 = icmp eq i32 %32316, %32329
  %32331 = or i1 %32328, %32330
  %32332 = load i32, i32* %10, align 4
  %32333 = icmp eq i32 %32316, %32332
  %32334 = or i1 %32331, %32333
  %32335 = load i32, i32* %11, align 4
  %32336 = icmp eq i32 %32316, %32335
  %32337 = or i1 %32334, %32336
  %32338 = load i32, i32* %12, align 4
  %32339 = icmp eq i32 %32316, %32338
  %32340 = or i1 %32337, %32339
  %32341 = load i32, i32* %13, align 4
  %32342 = icmp eq i32 %32316, %32341
  %32343 = or i1 %32340, %32342
  %32344 = load i32, i32* %14, align 4
  %32345 = icmp eq i32 %32316, %32344
  %32346 = or i1 %32343, %32345
  %32347 = load i32, i32* %15, align 4
  %32348 = icmp eq i32 %32316, %32347
  %32349 = or i1 %32346, %32348
  %32350 = load i32, i32* %16, align 4
  %32351 = icmp eq i32 %32316, %32350
  %32352 = or i1 %32349, %32351
  %32353 = load i32, i32* %17, align 4
  %32354 = icmp eq i32 %32316, %32353
  %32355 = or i1 %32352, %32354
  %32356 = load i32, i32* %18, align 4
  %32357 = icmp eq i32 %32316, %32356
  %32358 = or i1 %32355, %32357
  %32359 = load i32, i32* %19, align 4
  %32360 = icmp eq i32 %32316, %32359
  %32361 = or i1 %32358, %32360
  %32362 = load i32, i32* %20, align 4
  %32363 = icmp eq i32 %32316, %32362
  %32364 = or i1 %32361, %32363
  %32365 = load i32, i32* %21, align 4
  %32366 = icmp eq i32 %32316, %32365
  %32367 = or i1 %32364, %32366
  %32368 = load i32, i32* %22, align 4
  %32369 = icmp eq i32 %32316, %32368
  %32370 = or i1 %32367, %32369
  %32371 = load i32, i32* %23, align 4
  %32372 = icmp eq i32 %32316, %32371
  %32373 = or i1 %32370, %32372
  %32374 = load i32, i32* %24, align 4
  %32375 = icmp eq i32 %32316, %32374
  %32376 = or i1 %32373, %32375
  %32377 = load i32, i32* %25, align 4
  %32378 = icmp eq i32 %32316, %32377
  %32379 = or i1 %32376, %32378
  %32380 = load i32, i32* %26, align 4
  %32381 = icmp eq i32 %32316, %32380
  %32382 = or i1 %32379, %32381
  %32383 = load i32, i32* %27, align 4
  %32384 = icmp eq i32 %32316, %32383
  %32385 = or i1 %32382, %32384
  %32386 = load i32, i32* %28, align 4
  %32387 = icmp eq i32 %32316, %32386
  %32388 = or i1 %32385, %32387
  %32389 = load i32, i32* %29, align 4
  %32390 = icmp eq i32 %32316, %32389
  %32391 = or i1 %32388, %32390
  %32392 = load i32, i32* %30, align 4
  %32393 = icmp eq i32 %32316, %32392
  %32394 = or i1 %32391, %32393
  %32395 = load i32, i32* %31, align 4
  %32396 = icmp eq i32 %32316, %32395
  %32397 = or i1 %32394, %32396
  %32398 = load i32, i32* %32, align 4
  %32399 = icmp eq i32 %32316, %32398
  %32400 = or i1 %32397, %32399
  %32401 = load i32, i32* %33, align 4
  %32402 = icmp eq i32 %32316, %32401
  %32403 = or i1 %32400, %32402
  %32404 = load i32, i32* %34, align 4
  %32405 = icmp eq i32 %32316, %32404
  %32406 = or i1 %32403, %32405
  %32407 = load i32, i32* %35, align 4
  %32408 = icmp eq i32 %32316, %32407
  %32409 = or i1 %32406, %32408
  %32410 = load i32, i32* %36, align 4
  %32411 = icmp eq i32 %32316, %32410
  %32412 = or i1 %32409, %32411
  %32413 = load i32, i32* %37, align 4
  %32414 = icmp eq i32 %32316, %32413
  %32415 = or i1 %32412, %32414
  %32416 = load i32, i32* %38, align 4
  %32417 = icmp eq i32 %32316, %32416
  %32418 = or i1 %32415, %32417
  %32419 = load i32, i32* %39, align 4
  %32420 = icmp eq i32 %32316, %32419
  %32421 = or i1 %32418, %32420
  %32422 = load i32, i32* %40, align 4
  %32423 = icmp eq i32 %32316, %32422
  %32424 = or i1 %32421, %32423
  %32425 = load i32, i32* %41, align 4
  %32426 = icmp eq i32 %32316, %32425
  %32427 = or i1 %32424, %32426
  %32428 = load i32, i32* %42, align 4
  %32429 = icmp eq i32 %32316, %32428
  %32430 = or i1 %32427, %32429
  %32431 = load i32, i32* %43, align 4
  %32432 = icmp eq i32 %32316, %32431
  %32433 = or i1 %32430, %32432
  %32434 = load i32, i32* %44, align 4
  %32435 = icmp eq i32 %32316, %32434
  %32436 = or i1 %32433, %32435
  %32437 = load i32, i32* %45, align 4
  %32438 = icmp eq i32 %32316, %32437
  %32439 = or i1 %32436, %32438
  %32440 = load i32, i32* %46, align 4
  %32441 = icmp eq i32 %32316, %32440
  %32442 = or i1 %32439, %32441
  %32443 = load i32, i32* %47, align 4
  %32444 = icmp eq i32 %32316, %32443
  %32445 = or i1 %32442, %32444
  %32446 = load i32, i32* %48, align 4
  %32447 = icmp eq i32 %32316, %32446
  %32448 = or i1 %32445, %32447
  %32449 = load i32, i32* %49, align 4
  %32450 = icmp eq i32 %32316, %32449
  %32451 = or i1 %32448, %32450
  %32452 = load i32, i32* %50, align 4
  %32453 = icmp eq i32 %32316, %32452
  %32454 = or i1 %32451, %32453
  %32455 = load i32, i32* %51, align 4
  %32456 = icmp eq i32 %32316, %32455
  %32457 = or i1 %32454, %32456
  %32458 = load i32, i32* %52, align 4
  %32459 = icmp eq i32 %32316, %32458
  %32460 = or i1 %32457, %32459
  %32461 = load i32, i32* %53, align 4
  %32462 = icmp eq i32 %32316, %32461
  %32463 = or i1 %32460, %32462
  %32464 = load i32, i32* %54, align 4
  %32465 = icmp eq i32 %32316, %32464
  %32466 = or i1 %32463, %32465
  %32467 = load i32, i32* %55, align 4
  %32468 = icmp eq i32 %32316, %32467
  %32469 = or i1 %32466, %32468
  %32470 = load i32, i32* %56, align 4
  %32471 = icmp eq i32 %32316, %32470
  %32472 = or i1 %32469, %32471
  %32473 = load i32, i32* %57, align 4
  %32474 = icmp eq i32 %32316, %32473
  %32475 = or i1 %32472, %32474
  %32476 = load i32, i32* %58, align 4
  %32477 = icmp eq i32 %32316, %32476
  %32478 = or i1 %32475, %32477
  %32479 = load i32, i32* %59, align 4
  %32480 = icmp eq i32 %32316, %32479
  %32481 = or i1 %32478, %32480
  %32482 = load i32, i32* %60, align 4
  %32483 = icmp eq i32 %32316, %32482
  %32484 = or i1 %32481, %32483
  %32485 = load i32, i32* %61, align 4
  %32486 = icmp eq i32 %32316, %32485
  %32487 = or i1 %32484, %32486
  %32488 = load i32, i32* %62, align 4
  %32489 = icmp eq i32 %32316, %32488
  %32490 = or i1 %32487, %32489
  %32491 = getelementptr i8, i8 addrspace(1)* %4, i32 118
  %32492 = zext i1 %32490 to i8
  store i8 %32492, i8 addrspace(1)* %32491, align 1, !nosanitize !3
  %32493 = load i256, i256* %32315, align 4
  %32494 = icmp ugt i256 %32311, %32493
  %32495 = icmp eq i1 %32494, false
  %32496 = icmp eq i1 %32495, false
  %32497 = trunc i256 10995 to i64
  %jump.check197 = icmp ne i1 %32496, false
  %32498 = load i64, i64* %STACK_DEP_PTR, align 4
  %32499 = add i64 %32498, 1
  store i64 %32499, i64* %STACK_DEP_PTR, align 4
  %32500 = load i64, i64* %STACK_DEP_PTR, align 4
  %32501 = getelementptr i256, i256* %STACK, i64 %32500
  store i256 %32311, i256* %32501, align 4
  br i1 %jump.check197, label %.10995, label %.10888, !EVMBB !4

.10888:                                           ; preds = %32302
  %32502 = load i64, i64* %remaing_gas, align 4
  %32503 = icmp ugt i64 440, %32502
  br i1 %32503, label %Abort, label %32504

32504:                                            ; preds = %.10888
  %32505 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32506 = xor i32 %32505, 2160
  %32507 = urem i32 %32506, 4096
  %32508 = getelementptr i8, i8 addrspace(1)* %4, i32 %32507
  %32509 = load i8, i8 addrspace(1)* %32508, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32508, align 1, !nosanitize !3
  store i32 1080, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32510 = sub i64 %32502, 440
  store i64 %32510, i64* %remaing_gas, align 4
  %32511 = load i64, i64* %STACK_DEP_PTR, align 4
  %32512 = getelementptr i256, i256* %STACK, i64 %32511
  %32513 = load i256, i256* %32512, align 4
  %32514 = load i64, i64* %STACK_DEP_PTR, align 4
  %32515 = sub i64 %32514, 1
  store i64 %32515, i64* %STACK_DEP_PTR, align 4
  %32516 = icmp eq i256 1, 0
  %32517 = icmp eq i1 %32516, false
  %32518 = trunc i256 0 to i64
  %32519 = alloca i256, align 8
  store i256 %32513, i256* %32519, align 4
  %32520 = bitcast i256* %32519 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %32518, i8* %32520, i64 32)
  %32521 = add i256 32, 0, !pc !473, !intsan !10
  %32522 = trunc i256 %32521 to i64
  %32523 = alloca i256, align 8
  store i256 4, i256* %32523, align 4
  %32524 = bitcast i256* %32523 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %32522, i8* %32524, i64 32)
  %32525 = add i256 32, %32521, !pc !474, !intsan !10
  %32526 = trunc i256 0 to i32
  %32527 = trunc i256 %32525 to i32
  %32528 = getelementptr inbounds i8, i8* %MEMORY, i32 %32526
  %32529 = alloca i256, align 8
  %32530 = bitcast i256* %32529 to i8*
  call void @__device_sha3(i8* %32528, i32 %32527, i8* %32530)
  %32531 = load i256, i256* %32529, align 4
  %32532 = add i256 2, %32531, !pc !475, !intsan !10
  %32533 = alloca i256, align 8
  store i256 %32532, i256* %32533, align 4
  %32534 = alloca i256, align 8
  call void @__device_sload(i256* %32533, i256* %32534)
  %32535 = call i32 @__hashword(i256* %32533)
  %32536 = load i32, i32* %5, align 4
  %32537 = icmp eq i32 %32535, %32536
  %32538 = or i1 false, %32537
  %32539 = load i32, i32* %6, align 4
  %32540 = icmp eq i32 %32535, %32539
  %32541 = or i1 %32538, %32540
  %32542 = load i32, i32* %7, align 4
  %32543 = icmp eq i32 %32535, %32542
  %32544 = or i1 %32541, %32543
  %32545 = load i32, i32* %8, align 4
  %32546 = icmp eq i32 %32535, %32545
  %32547 = or i1 %32544, %32546
  %32548 = load i32, i32* %9, align 4
  %32549 = icmp eq i32 %32535, %32548
  %32550 = or i1 %32547, %32549
  %32551 = load i32, i32* %10, align 4
  %32552 = icmp eq i32 %32535, %32551
  %32553 = or i1 %32550, %32552
  %32554 = load i32, i32* %11, align 4
  %32555 = icmp eq i32 %32535, %32554
  %32556 = or i1 %32553, %32555
  %32557 = load i32, i32* %12, align 4
  %32558 = icmp eq i32 %32535, %32557
  %32559 = or i1 %32556, %32558
  %32560 = load i32, i32* %13, align 4
  %32561 = icmp eq i32 %32535, %32560
  %32562 = or i1 %32559, %32561
  %32563 = load i32, i32* %14, align 4
  %32564 = icmp eq i32 %32535, %32563
  %32565 = or i1 %32562, %32564
  %32566 = load i32, i32* %15, align 4
  %32567 = icmp eq i32 %32535, %32566
  %32568 = or i1 %32565, %32567
  %32569 = load i32, i32* %16, align 4
  %32570 = icmp eq i32 %32535, %32569
  %32571 = or i1 %32568, %32570
  %32572 = load i32, i32* %17, align 4
  %32573 = icmp eq i32 %32535, %32572
  %32574 = or i1 %32571, %32573
  %32575 = load i32, i32* %18, align 4
  %32576 = icmp eq i32 %32535, %32575
  %32577 = or i1 %32574, %32576
  %32578 = load i32, i32* %19, align 4
  %32579 = icmp eq i32 %32535, %32578
  %32580 = or i1 %32577, %32579
  %32581 = load i32, i32* %20, align 4
  %32582 = icmp eq i32 %32535, %32581
  %32583 = or i1 %32580, %32582
  %32584 = load i32, i32* %21, align 4
  %32585 = icmp eq i32 %32535, %32584
  %32586 = or i1 %32583, %32585
  %32587 = load i32, i32* %22, align 4
  %32588 = icmp eq i32 %32535, %32587
  %32589 = or i1 %32586, %32588
  %32590 = load i32, i32* %23, align 4
  %32591 = icmp eq i32 %32535, %32590
  %32592 = or i1 %32589, %32591
  %32593 = load i32, i32* %24, align 4
  %32594 = icmp eq i32 %32535, %32593
  %32595 = or i1 %32592, %32594
  %32596 = load i32, i32* %25, align 4
  %32597 = icmp eq i32 %32535, %32596
  %32598 = or i1 %32595, %32597
  %32599 = load i32, i32* %26, align 4
  %32600 = icmp eq i32 %32535, %32599
  %32601 = or i1 %32598, %32600
  %32602 = load i32, i32* %27, align 4
  %32603 = icmp eq i32 %32535, %32602
  %32604 = or i1 %32601, %32603
  %32605 = load i32, i32* %28, align 4
  %32606 = icmp eq i32 %32535, %32605
  %32607 = or i1 %32604, %32606
  %32608 = load i32, i32* %29, align 4
  %32609 = icmp eq i32 %32535, %32608
  %32610 = or i1 %32607, %32609
  %32611 = load i32, i32* %30, align 4
  %32612 = icmp eq i32 %32535, %32611
  %32613 = or i1 %32610, %32612
  %32614 = load i32, i32* %31, align 4
  %32615 = icmp eq i32 %32535, %32614
  %32616 = or i1 %32613, %32615
  %32617 = load i32, i32* %32, align 4
  %32618 = icmp eq i32 %32535, %32617
  %32619 = or i1 %32616, %32618
  %32620 = load i32, i32* %33, align 4
  %32621 = icmp eq i32 %32535, %32620
  %32622 = or i1 %32619, %32621
  %32623 = load i32, i32* %34, align 4
  %32624 = icmp eq i32 %32535, %32623
  %32625 = or i1 %32622, %32624
  %32626 = load i32, i32* %35, align 4
  %32627 = icmp eq i32 %32535, %32626
  %32628 = or i1 %32625, %32627
  %32629 = load i32, i32* %36, align 4
  %32630 = icmp eq i32 %32535, %32629
  %32631 = or i1 %32628, %32630
  %32632 = load i32, i32* %37, align 4
  %32633 = icmp eq i32 %32535, %32632
  %32634 = or i1 %32631, %32633
  %32635 = load i32, i32* %38, align 4
  %32636 = icmp eq i32 %32535, %32635
  %32637 = or i1 %32634, %32636
  %32638 = load i32, i32* %39, align 4
  %32639 = icmp eq i32 %32535, %32638
  %32640 = or i1 %32637, %32639
  %32641 = load i32, i32* %40, align 4
  %32642 = icmp eq i32 %32535, %32641
  %32643 = or i1 %32640, %32642
  %32644 = load i32, i32* %41, align 4
  %32645 = icmp eq i32 %32535, %32644
  %32646 = or i1 %32643, %32645
  %32647 = load i32, i32* %42, align 4
  %32648 = icmp eq i32 %32535, %32647
  %32649 = or i1 %32646, %32648
  %32650 = load i32, i32* %43, align 4
  %32651 = icmp eq i32 %32535, %32650
  %32652 = or i1 %32649, %32651
  %32653 = load i32, i32* %44, align 4
  %32654 = icmp eq i32 %32535, %32653
  %32655 = or i1 %32652, %32654
  %32656 = load i32, i32* %45, align 4
  %32657 = icmp eq i32 %32535, %32656
  %32658 = or i1 %32655, %32657
  %32659 = load i32, i32* %46, align 4
  %32660 = icmp eq i32 %32535, %32659
  %32661 = or i1 %32658, %32660
  %32662 = load i32, i32* %47, align 4
  %32663 = icmp eq i32 %32535, %32662
  %32664 = or i1 %32661, %32663
  %32665 = load i32, i32* %48, align 4
  %32666 = icmp eq i32 %32535, %32665
  %32667 = or i1 %32664, %32666
  %32668 = load i32, i32* %49, align 4
  %32669 = icmp eq i32 %32535, %32668
  %32670 = or i1 %32667, %32669
  %32671 = load i32, i32* %50, align 4
  %32672 = icmp eq i32 %32535, %32671
  %32673 = or i1 %32670, %32672
  %32674 = load i32, i32* %51, align 4
  %32675 = icmp eq i32 %32535, %32674
  %32676 = or i1 %32673, %32675
  %32677 = load i32, i32* %52, align 4
  %32678 = icmp eq i32 %32535, %32677
  %32679 = or i1 %32676, %32678
  %32680 = load i32, i32* %53, align 4
  %32681 = icmp eq i32 %32535, %32680
  %32682 = or i1 %32679, %32681
  %32683 = load i32, i32* %54, align 4
  %32684 = icmp eq i32 %32535, %32683
  %32685 = or i1 %32682, %32684
  %32686 = load i32, i32* %55, align 4
  %32687 = icmp eq i32 %32535, %32686
  %32688 = or i1 %32685, %32687
  %32689 = load i32, i32* %56, align 4
  %32690 = icmp eq i32 %32535, %32689
  %32691 = or i1 %32688, %32690
  %32692 = load i32, i32* %57, align 4
  %32693 = icmp eq i32 %32535, %32692
  %32694 = or i1 %32691, %32693
  %32695 = load i32, i32* %58, align 4
  %32696 = icmp eq i32 %32535, %32695
  %32697 = or i1 %32694, %32696
  %32698 = load i32, i32* %59, align 4
  %32699 = icmp eq i32 %32535, %32698
  %32700 = or i1 %32697, %32699
  %32701 = load i32, i32* %60, align 4
  %32702 = icmp eq i32 %32535, %32701
  %32703 = or i1 %32700, %32702
  %32704 = load i32, i32* %61, align 4
  %32705 = icmp eq i32 %32535, %32704
  %32706 = or i1 %32703, %32705
  %32707 = load i32, i32* %62, align 4
  %32708 = icmp eq i32 %32535, %32707
  %32709 = or i1 %32706, %32708
  %32710 = getelementptr i8, i8 addrspace(1)* %4, i32 119
  %32711 = zext i1 %32709 to i8
  store i8 %32711, i8 addrspace(1)* %32710, align 1, !nosanitize !3
  %32712 = load i256, i256* %32534, align 4
  %32713 = alloca i256, align 8
  store i256 %32712, i256* %32713, align 4
  %32714 = alloca i256, align 8
  store i256 1, i256* %32714, align 4
  %32715 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %32713, i256* %32714, i256* %32715), !pc !476, !intsan !6
  %32716 = load i256, i256* %32715, align 4
  %32717 = and i256 255, %32716
  %32718 = icmp eq i256 %32717, 0
  %32719 = icmp eq i1 %32718, false
  %32720 = icmp eq i1 %32719, %32517
  %32721 = icmp eq i1 %32720, false
  %32722 = trunc i256 10982 to i64
  %jump.check198 = icmp ne i1 %32721, false
  %32723 = load i64, i64* %STACK_DEP_PTR, align 4
  %32724 = add i64 %32723, 1
  store i64 %32724, i64* %STACK_DEP_PTR, align 4
  %32725 = load i64, i64* %STACK_DEP_PTR, align 4
  %32726 = getelementptr i256, i256* %STACK, i64 %32725
  store i256 %32513, i256* %32726, align 4
  br i1 %jump.check198, label %.10982, label %.10936, !EVMBB !4

.10936:                                           ; preds = %32504
  %32727 = load i64, i64* %STACK_DEP_PTR, align 4
  %32728 = getelementptr i256, i256* %STACK, i64 %32727
  %32729 = load i256, i256* %32728, align 4
  %32730 = load i64, i64* %STACK_DEP_PTR, align 4
  %32731 = sub i64 %32730, 1
  store i64 %32731, i64* %STACK_DEP_PTR, align 4
  %32732 = load i64, i64* %STACK_DEP_PTR, align 4
  %32733 = getelementptr i256, i256* %STACK, i64 %32732
  %32734 = load i256, i256* %32733, align 4
  %32735 = load i64, i64* %STACK_DEP_PTR, align 4
  %32736 = sub i64 %32735, 1
  store i64 %32736, i64* %STACK_DEP_PTR, align 4
  %32737 = load i64, i64* %STACK_DEP_PTR, align 4
  %32738 = getelementptr i256, i256* %STACK, i64 %32737
  %32739 = load i256, i256* %32738, align 4
  %32740 = load i64, i64* %STACK_DEP_PTR, align 4
  %32741 = sub i64 %32740, 1
  store i64 %32741, i64* %STACK_DEP_PTR, align 4
  %32742 = add i256 1, %32739, !pc !477, !intsan !10
  %32743 = trunc i256 0 to i64
  %32744 = alloca i256, align 8
  store i256 %32729, i256* %32744, align 4
  %32745 = bitcast i256* %32744 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %32743, i8* %32745, i64 32)
  %32746 = add i256 32, 0, !pc !478, !intsan !10
  %32747 = trunc i256 %32746 to i64
  %32748 = alloca i256, align 8
  store i256 4, i256* %32748, align 4
  %32749 = bitcast i256* %32748 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %32747, i8* %32749, i64 32)
  %32750 = add i256 32, %32746, !pc !479, !intsan !10
  %32751 = trunc i256 0 to i32
  %32752 = trunc i256 %32750 to i32
  %32753 = getelementptr inbounds i8, i8* %MEMORY, i32 %32751
  %32754 = alloca i256, align 8
  %32755 = bitcast i256* %32754 to i8*
  call void @__device_sha3(i8* %32753, i32 %32752, i8* %32755)
  %32756 = load i256, i256* %32754, align 4
  %32757 = add i256 2, %32756, !pc !480, !intsan !10
  %32758 = alloca i256, align 8
  store i256 %32757, i256* %32758, align 4
  %32759 = alloca i256, align 8
  call void @__device_sload(i256* %32758, i256* %32759)
  %32760 = call i32 @__hashword(i256* %32758)
  %32761 = load i32, i32* %5, align 4
  %32762 = icmp eq i32 %32760, %32761
  %32763 = or i1 false, %32762
  %32764 = load i32, i32* %6, align 4
  %32765 = icmp eq i32 %32760, %32764
  %32766 = or i1 %32763, %32765
  %32767 = load i32, i32* %7, align 4
  %32768 = icmp eq i32 %32760, %32767
  %32769 = or i1 %32766, %32768
  %32770 = load i32, i32* %8, align 4
  %32771 = icmp eq i32 %32760, %32770
  %32772 = or i1 %32769, %32771
  %32773 = load i32, i32* %9, align 4
  %32774 = icmp eq i32 %32760, %32773
  %32775 = or i1 %32772, %32774
  %32776 = load i32, i32* %10, align 4
  %32777 = icmp eq i32 %32760, %32776
  %32778 = or i1 %32775, %32777
  %32779 = load i32, i32* %11, align 4
  %32780 = icmp eq i32 %32760, %32779
  %32781 = or i1 %32778, %32780
  %32782 = load i32, i32* %12, align 4
  %32783 = icmp eq i32 %32760, %32782
  %32784 = or i1 %32781, %32783
  %32785 = load i32, i32* %13, align 4
  %32786 = icmp eq i32 %32760, %32785
  %32787 = or i1 %32784, %32786
  %32788 = load i32, i32* %14, align 4
  %32789 = icmp eq i32 %32760, %32788
  %32790 = or i1 %32787, %32789
  %32791 = load i32, i32* %15, align 4
  %32792 = icmp eq i32 %32760, %32791
  %32793 = or i1 %32790, %32792
  %32794 = load i32, i32* %16, align 4
  %32795 = icmp eq i32 %32760, %32794
  %32796 = or i1 %32793, %32795
  %32797 = load i32, i32* %17, align 4
  %32798 = icmp eq i32 %32760, %32797
  %32799 = or i1 %32796, %32798
  %32800 = load i32, i32* %18, align 4
  %32801 = icmp eq i32 %32760, %32800
  %32802 = or i1 %32799, %32801
  %32803 = load i32, i32* %19, align 4
  %32804 = icmp eq i32 %32760, %32803
  %32805 = or i1 %32802, %32804
  %32806 = load i32, i32* %20, align 4
  %32807 = icmp eq i32 %32760, %32806
  %32808 = or i1 %32805, %32807
  %32809 = load i32, i32* %21, align 4
  %32810 = icmp eq i32 %32760, %32809
  %32811 = or i1 %32808, %32810
  %32812 = load i32, i32* %22, align 4
  %32813 = icmp eq i32 %32760, %32812
  %32814 = or i1 %32811, %32813
  %32815 = load i32, i32* %23, align 4
  %32816 = icmp eq i32 %32760, %32815
  %32817 = or i1 %32814, %32816
  %32818 = load i32, i32* %24, align 4
  %32819 = icmp eq i32 %32760, %32818
  %32820 = or i1 %32817, %32819
  %32821 = load i32, i32* %25, align 4
  %32822 = icmp eq i32 %32760, %32821
  %32823 = or i1 %32820, %32822
  %32824 = load i32, i32* %26, align 4
  %32825 = icmp eq i32 %32760, %32824
  %32826 = or i1 %32823, %32825
  %32827 = load i32, i32* %27, align 4
  %32828 = icmp eq i32 %32760, %32827
  %32829 = or i1 %32826, %32828
  %32830 = load i32, i32* %28, align 4
  %32831 = icmp eq i32 %32760, %32830
  %32832 = or i1 %32829, %32831
  %32833 = load i32, i32* %29, align 4
  %32834 = icmp eq i32 %32760, %32833
  %32835 = or i1 %32832, %32834
  %32836 = load i32, i32* %30, align 4
  %32837 = icmp eq i32 %32760, %32836
  %32838 = or i1 %32835, %32837
  %32839 = load i32, i32* %31, align 4
  %32840 = icmp eq i32 %32760, %32839
  %32841 = or i1 %32838, %32840
  %32842 = load i32, i32* %32, align 4
  %32843 = icmp eq i32 %32760, %32842
  %32844 = or i1 %32841, %32843
  %32845 = load i32, i32* %33, align 4
  %32846 = icmp eq i32 %32760, %32845
  %32847 = or i1 %32844, %32846
  %32848 = load i32, i32* %34, align 4
  %32849 = icmp eq i32 %32760, %32848
  %32850 = or i1 %32847, %32849
  %32851 = load i32, i32* %35, align 4
  %32852 = icmp eq i32 %32760, %32851
  %32853 = or i1 %32850, %32852
  %32854 = load i32, i32* %36, align 4
  %32855 = icmp eq i32 %32760, %32854
  %32856 = or i1 %32853, %32855
  %32857 = load i32, i32* %37, align 4
  %32858 = icmp eq i32 %32760, %32857
  %32859 = or i1 %32856, %32858
  %32860 = load i32, i32* %38, align 4
  %32861 = icmp eq i32 %32760, %32860
  %32862 = or i1 %32859, %32861
  %32863 = load i32, i32* %39, align 4
  %32864 = icmp eq i32 %32760, %32863
  %32865 = or i1 %32862, %32864
  %32866 = load i32, i32* %40, align 4
  %32867 = icmp eq i32 %32760, %32866
  %32868 = or i1 %32865, %32867
  %32869 = load i32, i32* %41, align 4
  %32870 = icmp eq i32 %32760, %32869
  %32871 = or i1 %32868, %32870
  %32872 = load i32, i32* %42, align 4
  %32873 = icmp eq i32 %32760, %32872
  %32874 = or i1 %32871, %32873
  %32875 = load i32, i32* %43, align 4
  %32876 = icmp eq i32 %32760, %32875
  %32877 = or i1 %32874, %32876
  %32878 = load i32, i32* %44, align 4
  %32879 = icmp eq i32 %32760, %32878
  %32880 = or i1 %32877, %32879
  %32881 = load i32, i32* %45, align 4
  %32882 = icmp eq i32 %32760, %32881
  %32883 = or i1 %32880, %32882
  %32884 = load i32, i32* %46, align 4
  %32885 = icmp eq i32 %32760, %32884
  %32886 = or i1 %32883, %32885
  %32887 = load i32, i32* %47, align 4
  %32888 = icmp eq i32 %32760, %32887
  %32889 = or i1 %32886, %32888
  %32890 = load i32, i32* %48, align 4
  %32891 = icmp eq i32 %32760, %32890
  %32892 = or i1 %32889, %32891
  %32893 = load i32, i32* %49, align 4
  %32894 = icmp eq i32 %32760, %32893
  %32895 = or i1 %32892, %32894
  %32896 = load i32, i32* %50, align 4
  %32897 = icmp eq i32 %32760, %32896
  %32898 = or i1 %32895, %32897
  %32899 = load i32, i32* %51, align 4
  %32900 = icmp eq i32 %32760, %32899
  %32901 = or i1 %32898, %32900
  %32902 = load i32, i32* %52, align 4
  %32903 = icmp eq i32 %32760, %32902
  %32904 = or i1 %32901, %32903
  %32905 = load i32, i32* %53, align 4
  %32906 = icmp eq i32 %32760, %32905
  %32907 = or i1 %32904, %32906
  %32908 = load i32, i32* %54, align 4
  %32909 = icmp eq i32 %32760, %32908
  %32910 = or i1 %32907, %32909
  %32911 = load i32, i32* %55, align 4
  %32912 = icmp eq i32 %32760, %32911
  %32913 = or i1 %32910, %32912
  %32914 = load i32, i32* %56, align 4
  %32915 = icmp eq i32 %32760, %32914
  %32916 = or i1 %32913, %32915
  %32917 = load i32, i32* %57, align 4
  %32918 = icmp eq i32 %32760, %32917
  %32919 = or i1 %32916, %32918
  %32920 = load i32, i32* %58, align 4
  %32921 = icmp eq i32 %32760, %32920
  %32922 = or i1 %32919, %32921
  %32923 = load i32, i32* %59, align 4
  %32924 = icmp eq i32 %32760, %32923
  %32925 = or i1 %32922, %32924
  %32926 = load i32, i32* %60, align 4
  %32927 = icmp eq i32 %32760, %32926
  %32928 = or i1 %32925, %32927
  %32929 = load i32, i32* %61, align 4
  %32930 = icmp eq i32 %32760, %32929
  %32931 = or i1 %32928, %32930
  %32932 = load i32, i32* %62, align 4
  %32933 = icmp eq i32 %32760, %32932
  %32934 = or i1 %32931, %32933
  %32935 = getelementptr i8, i8 addrspace(1)* %4, i32 120
  %32936 = zext i1 %32934 to i8
  store i8 %32936, i8 addrspace(1)* %32935, align 1, !nosanitize !3
  %32937 = load i256, i256* %32759, align 4
  %32938 = mul i256 255, 1, !pc !481, !intsan !45
  %32939 = xor i256 %32938, -1
  %32940 = and i256 %32939, %32937
  %32941 = alloca i256, align 8
  store i256 %32757, i256* %32941, align 4
  %32942 = alloca i256, align 8
  store i256 %32940, i256* %32942, align 4
  call void @__device_sstore(i256* %32941, i256* %32942)
  %32943 = call i32 @__hashword(i256* %32941)
  store i32 %32943, i32* %46, align 4, !nosanitize !3
  %32944 = load i64, i64* %STACK_DEP_PTR, align 4
  %32945 = add i64 %32944, 1
  store i64 %32945, i64* %STACK_DEP_PTR, align 4
  %32946 = load i64, i64* %STACK_DEP_PTR, align 4
  %32947 = getelementptr i256, i256* %STACK, i64 %32946
  store i256 %32742, i256* %32947, align 4
  %32948 = load i64, i64* %STACK_DEP_PTR, align 4
  %32949 = add i64 %32948, 1
  store i64 %32949, i64* %STACK_DEP_PTR, align 4
  %32950 = load i64, i64* %STACK_DEP_PTR, align 4
  %32951 = getelementptr i256, i256* %STACK, i64 %32950
  store i256 %32734, i256* %32951, align 4
  %32952 = load i64, i64* %STACK_DEP_PTR, align 4
  %32953 = add i64 %32952, 1
  store i64 %32953, i64* %STACK_DEP_PTR, align 4
  %32954 = load i64, i64* %STACK_DEP_PTR, align 4
  %32955 = getelementptr i256, i256* %STACK, i64 %32954
  store i256 %32729, i256* %32955, align 4
  br label %.10982

.10982:                                           ; preds = %.10936, %32504, %JumpTable
  %32956 = load i64, i64* %remaing_gas, align 4
  %32957 = icmp ugt i64 128, %32956
  br i1 %32957, label %Abort, label %32958

32958:                                            ; preds = %.10982
  %32959 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32960 = xor i32 %32959, 602
  %32961 = urem i32 %32960, 4096
  %32962 = getelementptr i8, i8 addrspace(1)* %4, i32 %32961
  %32963 = load i8, i8 addrspace(1)* %32962, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32962, align 1, !nosanitize !3
  store i32 301, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32964 = sub i64 %32956, 128
  store i64 %32964, i64* %remaing_gas, align 4
  %32965 = load i64, i64* %STACK_DEP_PTR, align 4
  %32966 = getelementptr i256, i256* %STACK, i64 %32965
  %32967 = load i256, i256* %32966, align 4
  %32968 = load i64, i64* %STACK_DEP_PTR, align 4
  %32969 = sub i64 %32968, 1
  store i64 %32969, i64* %STACK_DEP_PTR, align 4
  %32970 = add i256 1, %32967, !pc !482, !intsan !10
  %32971 = trunc i256 10876 to i64
  %32972 = load i64, i64* %STACK_DEP_PTR, align 4
  %32973 = add i64 %32972, 1
  store i64 %32973, i64* %STACK_DEP_PTR, align 4
  %32974 = load i64, i64* %STACK_DEP_PTR, align 4
  %32975 = getelementptr i256, i256* %STACK, i64 %32974
  store i256 %32970, i256* %32975, align 4
  br label %.10876, !EVMBB !4

.10995:                                           ; preds = %32302, %JumpTable
  %32976 = load i64, i64* %remaing_gas, align 4
  %32977 = icmp ugt i64 192, %32976
  br i1 %32977, label %Abort, label %32978

32978:                                            ; preds = %.10995
  %32979 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32980 = xor i32 %32979, 2186
  %32981 = urem i32 %32980, 4096
  %32982 = getelementptr i8, i8 addrspace(1)* %4, i32 %32981
  %32983 = load i8, i8 addrspace(1)* %32982, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %32982, align 1, !nosanitize !3
  store i32 1093, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %32984 = sub i64 %32976, 192
  store i64 %32984, i64* %remaing_gas, align 4
  %32985 = alloca i256, align 8
  store i256 5, i256* %32985, align 4
  %32986 = alloca i256, align 8
  call void @__device_sload(i256* %32985, i256* %32986)
  %32987 = call i32 @__hashword(i256* %32985)
  %32988 = load i32, i32* %5, align 4
  %32989 = icmp eq i32 %32987, %32988
  %32990 = or i1 false, %32989
  %32991 = load i32, i32* %6, align 4
  %32992 = icmp eq i32 %32987, %32991
  %32993 = or i1 %32990, %32992
  %32994 = load i32, i32* %7, align 4
  %32995 = icmp eq i32 %32987, %32994
  %32996 = or i1 %32993, %32995
  %32997 = load i32, i32* %8, align 4
  %32998 = icmp eq i32 %32987, %32997
  %32999 = or i1 %32996, %32998
  %33000 = load i32, i32* %9, align 4
  %33001 = icmp eq i32 %32987, %33000
  %33002 = or i1 %32999, %33001
  %33003 = load i32, i32* %10, align 4
  %33004 = icmp eq i32 %32987, %33003
  %33005 = or i1 %33002, %33004
  %33006 = load i32, i32* %11, align 4
  %33007 = icmp eq i32 %32987, %33006
  %33008 = or i1 %33005, %33007
  %33009 = load i32, i32* %12, align 4
  %33010 = icmp eq i32 %32987, %33009
  %33011 = or i1 %33008, %33010
  %33012 = load i32, i32* %13, align 4
  %33013 = icmp eq i32 %32987, %33012
  %33014 = or i1 %33011, %33013
  %33015 = load i32, i32* %14, align 4
  %33016 = icmp eq i32 %32987, %33015
  %33017 = or i1 %33014, %33016
  %33018 = load i32, i32* %15, align 4
  %33019 = icmp eq i32 %32987, %33018
  %33020 = or i1 %33017, %33019
  %33021 = load i32, i32* %16, align 4
  %33022 = icmp eq i32 %32987, %33021
  %33023 = or i1 %33020, %33022
  %33024 = load i32, i32* %17, align 4
  %33025 = icmp eq i32 %32987, %33024
  %33026 = or i1 %33023, %33025
  %33027 = load i32, i32* %18, align 4
  %33028 = icmp eq i32 %32987, %33027
  %33029 = or i1 %33026, %33028
  %33030 = load i32, i32* %19, align 4
  %33031 = icmp eq i32 %32987, %33030
  %33032 = or i1 %33029, %33031
  %33033 = load i32, i32* %20, align 4
  %33034 = icmp eq i32 %32987, %33033
  %33035 = or i1 %33032, %33034
  %33036 = load i32, i32* %21, align 4
  %33037 = icmp eq i32 %32987, %33036
  %33038 = or i1 %33035, %33037
  %33039 = load i32, i32* %22, align 4
  %33040 = icmp eq i32 %32987, %33039
  %33041 = or i1 %33038, %33040
  %33042 = load i32, i32* %23, align 4
  %33043 = icmp eq i32 %32987, %33042
  %33044 = or i1 %33041, %33043
  %33045 = load i32, i32* %24, align 4
  %33046 = icmp eq i32 %32987, %33045
  %33047 = or i1 %33044, %33046
  %33048 = load i32, i32* %25, align 4
  %33049 = icmp eq i32 %32987, %33048
  %33050 = or i1 %33047, %33049
  %33051 = load i32, i32* %26, align 4
  %33052 = icmp eq i32 %32987, %33051
  %33053 = or i1 %33050, %33052
  %33054 = load i32, i32* %27, align 4
  %33055 = icmp eq i32 %32987, %33054
  %33056 = or i1 %33053, %33055
  %33057 = load i32, i32* %28, align 4
  %33058 = icmp eq i32 %32987, %33057
  %33059 = or i1 %33056, %33058
  %33060 = load i32, i32* %29, align 4
  %33061 = icmp eq i32 %32987, %33060
  %33062 = or i1 %33059, %33061
  %33063 = load i32, i32* %30, align 4
  %33064 = icmp eq i32 %32987, %33063
  %33065 = or i1 %33062, %33064
  %33066 = load i32, i32* %31, align 4
  %33067 = icmp eq i32 %32987, %33066
  %33068 = or i1 %33065, %33067
  %33069 = load i32, i32* %32, align 4
  %33070 = icmp eq i32 %32987, %33069
  %33071 = or i1 %33068, %33070
  %33072 = load i32, i32* %33, align 4
  %33073 = icmp eq i32 %32987, %33072
  %33074 = or i1 %33071, %33073
  %33075 = load i32, i32* %34, align 4
  %33076 = icmp eq i32 %32987, %33075
  %33077 = or i1 %33074, %33076
  %33078 = load i32, i32* %35, align 4
  %33079 = icmp eq i32 %32987, %33078
  %33080 = or i1 %33077, %33079
  %33081 = load i32, i32* %36, align 4
  %33082 = icmp eq i32 %32987, %33081
  %33083 = or i1 %33080, %33082
  %33084 = load i32, i32* %37, align 4
  %33085 = icmp eq i32 %32987, %33084
  %33086 = or i1 %33083, %33085
  %33087 = load i32, i32* %38, align 4
  %33088 = icmp eq i32 %32987, %33087
  %33089 = or i1 %33086, %33088
  %33090 = load i32, i32* %39, align 4
  %33091 = icmp eq i32 %32987, %33090
  %33092 = or i1 %33089, %33091
  %33093 = load i32, i32* %40, align 4
  %33094 = icmp eq i32 %32987, %33093
  %33095 = or i1 %33092, %33094
  %33096 = load i32, i32* %41, align 4
  %33097 = icmp eq i32 %32987, %33096
  %33098 = or i1 %33095, %33097
  %33099 = load i32, i32* %42, align 4
  %33100 = icmp eq i32 %32987, %33099
  %33101 = or i1 %33098, %33100
  %33102 = load i32, i32* %43, align 4
  %33103 = icmp eq i32 %32987, %33102
  %33104 = or i1 %33101, %33103
  %33105 = load i32, i32* %44, align 4
  %33106 = icmp eq i32 %32987, %33105
  %33107 = or i1 %33104, %33106
  %33108 = load i32, i32* %45, align 4
  %33109 = icmp eq i32 %32987, %33108
  %33110 = or i1 %33107, %33109
  %33111 = load i32, i32* %46, align 4
  %33112 = icmp eq i32 %32987, %33111
  %33113 = or i1 %33110, %33112
  %33114 = load i32, i32* %47, align 4
  %33115 = icmp eq i32 %32987, %33114
  %33116 = or i1 %33113, %33115
  %33117 = load i32, i32* %48, align 4
  %33118 = icmp eq i32 %32987, %33117
  %33119 = or i1 %33116, %33118
  %33120 = load i32, i32* %49, align 4
  %33121 = icmp eq i32 %32987, %33120
  %33122 = or i1 %33119, %33121
  %33123 = load i32, i32* %50, align 4
  %33124 = icmp eq i32 %32987, %33123
  %33125 = or i1 %33122, %33124
  %33126 = load i32, i32* %51, align 4
  %33127 = icmp eq i32 %32987, %33126
  %33128 = or i1 %33125, %33127
  %33129 = load i32, i32* %52, align 4
  %33130 = icmp eq i32 %32987, %33129
  %33131 = or i1 %33128, %33130
  %33132 = load i32, i32* %53, align 4
  %33133 = icmp eq i32 %32987, %33132
  %33134 = or i1 %33131, %33133
  %33135 = load i32, i32* %54, align 4
  %33136 = icmp eq i32 %32987, %33135
  %33137 = or i1 %33134, %33136
  %33138 = load i32, i32* %55, align 4
  %33139 = icmp eq i32 %32987, %33138
  %33140 = or i1 %33137, %33139
  %33141 = load i32, i32* %56, align 4
  %33142 = icmp eq i32 %32987, %33141
  %33143 = or i1 %33140, %33142
  %33144 = load i32, i32* %57, align 4
  %33145 = icmp eq i32 %32987, %33144
  %33146 = or i1 %33143, %33145
  %33147 = load i32, i32* %58, align 4
  %33148 = icmp eq i32 %32987, %33147
  %33149 = or i1 %33146, %33148
  %33150 = load i32, i32* %59, align 4
  %33151 = icmp eq i32 %32987, %33150
  %33152 = or i1 %33149, %33151
  %33153 = load i32, i32* %60, align 4
  %33154 = icmp eq i32 %32987, %33153
  %33155 = or i1 %33152, %33154
  %33156 = load i32, i32* %61, align 4
  %33157 = icmp eq i32 %32987, %33156
  %33158 = or i1 %33155, %33157
  %33159 = load i32, i32* %62, align 4
  %33160 = icmp eq i32 %32987, %33159
  %33161 = or i1 %33158, %33160
  %33162 = getelementptr i8, i8 addrspace(1)* %4, i32 121
  %33163 = zext i1 %33161 to i8
  store i8 %33163, i8 addrspace(1)* %33162, align 1, !nosanitize !3
  %33164 = load i256, i256* %32986, align 4
  %33165 = mul i256 10, %33164, !pc !483, !intsan !45
  %33166 = icmp eq i256 100, 0
  %33167 = icmp eq i1 %33166, false
  %33168 = trunc i256 11012 to i64
  %jump.check199 = icmp ne i1 %33167, false
  %33169 = load i64, i64* %STACK_DEP_PTR, align 4
  %33170 = add i64 %33169, 1
  store i64 %33170, i64* %STACK_DEP_PTR, align 4
  %33171 = load i64, i64* %STACK_DEP_PTR, align 4
  %33172 = getelementptr i256, i256* %STACK, i64 %33171
  store i256 100, i256* %33172, align 4
  %33173 = load i64, i64* %STACK_DEP_PTR, align 4
  %33174 = add i64 %33173, 1
  store i64 %33174, i64* %STACK_DEP_PTR, align 4
  %33175 = load i64, i64* %STACK_DEP_PTR, align 4
  %33176 = getelementptr i256, i256* %STACK, i64 %33175
  store i256 %33165, i256* %33176, align 4
  br i1 %jump.check199, label %.11012, label %.11011, !EVMBB !4

.11011:                                           ; preds = %32978
  %33177 = load i64, i64* %remaing_gas, align 4
  %33178 = icmp ugt i64 16, %33177
  br i1 %33178, label %Abort, label %33179

33179:                                            ; preds = %.11011
  %33180 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33181 = xor i32 %33180, 1855
  %33182 = urem i32 %33181, 4096
  %33183 = getelementptr i8, i8 addrspace(1)* %4, i32 %33182
  %33184 = load i8, i8 addrspace(1)* %33183, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33183, align 1, !nosanitize !3
  store i32 927, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33185 = sub i64 %33177, 16
  store i64 %33185, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11012:                                           ; preds = %32978, %JumpTable
  %33186 = load i64, i64* %remaing_gas, align 4
  %33187 = icmp ugt i64 496, %33186
  br i1 %33187, label %Abort, label %33188

33188:                                            ; preds = %.11012
  %33189 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33190 = xor i32 %33189, 1122
  %33191 = urem i32 %33190, 4096
  %33192 = getelementptr i8, i8 addrspace(1)* %4, i32 %33191
  %33193 = load i8, i8 addrspace(1)* %33192, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33192, align 1, !nosanitize !3
  store i32 561, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33194 = sub i64 %33186, 496
  store i64 %33194, i64* %remaing_gas, align 4
  %33195 = load i64, i64* %STACK_DEP_PTR, align 4
  %33196 = getelementptr i256, i256* %STACK, i64 %33195
  %33197 = load i256, i256* %33196, align 4
  %33198 = load i64, i64* %STACK_DEP_PTR, align 4
  %33199 = sub i64 %33198, 1
  store i64 %33199, i64* %STACK_DEP_PTR, align 4
  %33200 = load i64, i64* %STACK_DEP_PTR, align 4
  %33201 = getelementptr i256, i256* %STACK, i64 %33200
  %33202 = load i256, i256* %33201, align 4
  %33203 = load i64, i64* %STACK_DEP_PTR, align 4
  %33204 = sub i64 %33203, 1
  store i64 %33204, i64* %STACK_DEP_PTR, align 4
  %33205 = load i64, i64* %STACK_DEP_PTR, align 4
  %33206 = getelementptr i256, i256* %STACK, i64 %33205
  %33207 = load i256, i256* %33206, align 4
  %33208 = load i64, i64* %STACK_DEP_PTR, align 4
  %33209 = sub i64 %33208, 1
  store i64 %33209, i64* %STACK_DEP_PTR, align 4
  %33210 = load i64, i64* %STACK_DEP_PTR, align 4
  %33211 = getelementptr i256, i256* %STACK, i64 %33210
  %33212 = load i256, i256* %33211, align 4
  %33213 = load i64, i64* %STACK_DEP_PTR, align 4
  %33214 = sub i64 %33213, 1
  store i64 %33214, i64* %STACK_DEP_PTR, align 4
  %33215 = load i64, i64* %STACK_DEP_PTR, align 4
  %33216 = getelementptr i256, i256* %STACK, i64 %33215
  %33217 = load i256, i256* %33216, align 4
  %33218 = load i64, i64* %STACK_DEP_PTR, align 4
  %33219 = sub i64 %33218, 1
  store i64 %33219, i64* %STACK_DEP_PTR, align 4
  %33220 = alloca i256, align 8
  store i256 %33197, i256* %33220, align 4
  %33221 = alloca i256, align 8
  store i256 %33202, i256* %33221, align 4
  %33222 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %33220, i256* %33221, i256* %33222), !pc !484, !intsan !6
  %33223 = load i256, i256* %33222, align 4
  %33224 = icmp ult i256 %33217, %33223
  %33225 = icmp eq i1 %33224, false
  %33226 = icmp eq i1 %33225, false
  %33227 = trunc i256 11408 to i64
  %jump.check200 = icmp ne i1 %33226, false
  %33228 = load i64, i64* %STACK_DEP_PTR, align 4
  %33229 = add i64 %33228, 1
  store i64 %33229, i64* %STACK_DEP_PTR, align 4
  %33230 = load i64, i64* %STACK_DEP_PTR, align 4
  %33231 = getelementptr i256, i256* %STACK, i64 %33230
  store i256 %33217, i256* %33231, align 4
  %33232 = load i64, i64* %STACK_DEP_PTR, align 4
  %33233 = add i64 %33232, 1
  store i64 %33233, i64* %STACK_DEP_PTR, align 4
  %33234 = load i64, i64* %STACK_DEP_PTR, align 4
  %33235 = getelementptr i256, i256* %STACK, i64 %33234
  store i256 %33212, i256* %33235, align 4
  %33236 = load i64, i64* %STACK_DEP_PTR, align 4
  %33237 = add i64 %33236, 1
  store i64 %33237, i64* %STACK_DEP_PTR, align 4
  %33238 = load i64, i64* %STACK_DEP_PTR, align 4
  %33239 = getelementptr i256, i256* %STACK, i64 %33238
  store i256 %33207, i256* %33239, align 4
  br i1 %jump.check200, label %.11408, label %.11022, !EVMBB !4

.11022:                                           ; preds = %33188
  %33240 = load i64, i64* %remaing_gas, align 4
  %33241 = icmp ugt i64 480, %33240
  br i1 %33241, label %Abort, label %33242

33242:                                            ; preds = %.11022
  %33243 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33244 = xor i32 %33243, 1664
  %33245 = urem i32 %33244, 4096
  %33246 = getelementptr i8, i8 addrspace(1)* %4, i32 %33245
  %33247 = load i8, i8 addrspace(1)* %33246, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33246, align 1, !nosanitize !3
  store i32 832, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33248 = sub i64 %33240, 480
  store i64 %33248, i64* %remaing_gas, align 4
  %33249 = load i64, i64* %STACK_DEP_PTR, align 4
  %33250 = getelementptr i256, i256* %STACK, i64 %33249
  %33251 = load i256, i256* %33250, align 4
  %33252 = load i64, i64* %STACK_DEP_PTR, align 4
  %33253 = sub i64 %33252, 1
  store i64 %33253, i64* %STACK_DEP_PTR, align 4
  %33254 = load i64, i64* %STACK_DEP_PTR, align 4
  %33255 = getelementptr i256, i256* %STACK, i64 %33254
  %33256 = load i256, i256* %33255, align 4
  %33257 = load i64, i64* %STACK_DEP_PTR, align 4
  %33258 = sub i64 %33257, 1
  store i64 %33258, i64* %STACK_DEP_PTR, align 4
  %33259 = add i256 0, 9, !pc !485, !intsan !10
  %33260 = alloca i256, align 8
  store i256 %33259, i256* %33260, align 4
  %33261 = alloca i256, align 8
  call void @__device_sload(i256* %33260, i256* %33261)
  %33262 = call i32 @__hashword(i256* %33260)
  %33263 = load i32, i32* %5, align 4
  %33264 = icmp eq i32 %33262, %33263
  %33265 = or i1 false, %33264
  %33266 = load i32, i32* %6, align 4
  %33267 = icmp eq i32 %33262, %33266
  %33268 = or i1 %33265, %33267
  %33269 = load i32, i32* %7, align 4
  %33270 = icmp eq i32 %33262, %33269
  %33271 = or i1 %33268, %33270
  %33272 = load i32, i32* %8, align 4
  %33273 = icmp eq i32 %33262, %33272
  %33274 = or i1 %33271, %33273
  %33275 = load i32, i32* %9, align 4
  %33276 = icmp eq i32 %33262, %33275
  %33277 = or i1 %33274, %33276
  %33278 = load i32, i32* %10, align 4
  %33279 = icmp eq i32 %33262, %33278
  %33280 = or i1 %33277, %33279
  %33281 = load i32, i32* %11, align 4
  %33282 = icmp eq i32 %33262, %33281
  %33283 = or i1 %33280, %33282
  %33284 = load i32, i32* %12, align 4
  %33285 = icmp eq i32 %33262, %33284
  %33286 = or i1 %33283, %33285
  %33287 = load i32, i32* %13, align 4
  %33288 = icmp eq i32 %33262, %33287
  %33289 = or i1 %33286, %33288
  %33290 = load i32, i32* %14, align 4
  %33291 = icmp eq i32 %33262, %33290
  %33292 = or i1 %33289, %33291
  %33293 = load i32, i32* %15, align 4
  %33294 = icmp eq i32 %33262, %33293
  %33295 = or i1 %33292, %33294
  %33296 = load i32, i32* %16, align 4
  %33297 = icmp eq i32 %33262, %33296
  %33298 = or i1 %33295, %33297
  %33299 = load i32, i32* %17, align 4
  %33300 = icmp eq i32 %33262, %33299
  %33301 = or i1 %33298, %33300
  %33302 = load i32, i32* %18, align 4
  %33303 = icmp eq i32 %33262, %33302
  %33304 = or i1 %33301, %33303
  %33305 = load i32, i32* %19, align 4
  %33306 = icmp eq i32 %33262, %33305
  %33307 = or i1 %33304, %33306
  %33308 = load i32, i32* %20, align 4
  %33309 = icmp eq i32 %33262, %33308
  %33310 = or i1 %33307, %33309
  %33311 = load i32, i32* %21, align 4
  %33312 = icmp eq i32 %33262, %33311
  %33313 = or i1 %33310, %33312
  %33314 = load i32, i32* %22, align 4
  %33315 = icmp eq i32 %33262, %33314
  %33316 = or i1 %33313, %33315
  %33317 = load i32, i32* %23, align 4
  %33318 = icmp eq i32 %33262, %33317
  %33319 = or i1 %33316, %33318
  %33320 = load i32, i32* %24, align 4
  %33321 = icmp eq i32 %33262, %33320
  %33322 = or i1 %33319, %33321
  %33323 = load i32, i32* %25, align 4
  %33324 = icmp eq i32 %33262, %33323
  %33325 = or i1 %33322, %33324
  %33326 = load i32, i32* %26, align 4
  %33327 = icmp eq i32 %33262, %33326
  %33328 = or i1 %33325, %33327
  %33329 = load i32, i32* %27, align 4
  %33330 = icmp eq i32 %33262, %33329
  %33331 = or i1 %33328, %33330
  %33332 = load i32, i32* %28, align 4
  %33333 = icmp eq i32 %33262, %33332
  %33334 = or i1 %33331, %33333
  %33335 = load i32, i32* %29, align 4
  %33336 = icmp eq i32 %33262, %33335
  %33337 = or i1 %33334, %33336
  %33338 = load i32, i32* %30, align 4
  %33339 = icmp eq i32 %33262, %33338
  %33340 = or i1 %33337, %33339
  %33341 = load i32, i32* %31, align 4
  %33342 = icmp eq i32 %33262, %33341
  %33343 = or i1 %33340, %33342
  %33344 = load i32, i32* %32, align 4
  %33345 = icmp eq i32 %33262, %33344
  %33346 = or i1 %33343, %33345
  %33347 = load i32, i32* %33, align 4
  %33348 = icmp eq i32 %33262, %33347
  %33349 = or i1 %33346, %33348
  %33350 = load i32, i32* %34, align 4
  %33351 = icmp eq i32 %33262, %33350
  %33352 = or i1 %33349, %33351
  %33353 = load i32, i32* %35, align 4
  %33354 = icmp eq i32 %33262, %33353
  %33355 = or i1 %33352, %33354
  %33356 = load i32, i32* %36, align 4
  %33357 = icmp eq i32 %33262, %33356
  %33358 = or i1 %33355, %33357
  %33359 = load i32, i32* %37, align 4
  %33360 = icmp eq i32 %33262, %33359
  %33361 = or i1 %33358, %33360
  %33362 = load i32, i32* %38, align 4
  %33363 = icmp eq i32 %33262, %33362
  %33364 = or i1 %33361, %33363
  %33365 = load i32, i32* %39, align 4
  %33366 = icmp eq i32 %33262, %33365
  %33367 = or i1 %33364, %33366
  %33368 = load i32, i32* %40, align 4
  %33369 = icmp eq i32 %33262, %33368
  %33370 = or i1 %33367, %33369
  %33371 = load i32, i32* %41, align 4
  %33372 = icmp eq i32 %33262, %33371
  %33373 = or i1 %33370, %33372
  %33374 = load i32, i32* %42, align 4
  %33375 = icmp eq i32 %33262, %33374
  %33376 = or i1 %33373, %33375
  %33377 = load i32, i32* %43, align 4
  %33378 = icmp eq i32 %33262, %33377
  %33379 = or i1 %33376, %33378
  %33380 = load i32, i32* %44, align 4
  %33381 = icmp eq i32 %33262, %33380
  %33382 = or i1 %33379, %33381
  %33383 = load i32, i32* %45, align 4
  %33384 = icmp eq i32 %33262, %33383
  %33385 = or i1 %33382, %33384
  %33386 = load i32, i32* %46, align 4
  %33387 = icmp eq i32 %33262, %33386
  %33388 = or i1 %33385, %33387
  %33389 = load i32, i32* %47, align 4
  %33390 = icmp eq i32 %33262, %33389
  %33391 = or i1 %33388, %33390
  %33392 = load i32, i32* %48, align 4
  %33393 = icmp eq i32 %33262, %33392
  %33394 = or i1 %33391, %33393
  %33395 = load i32, i32* %49, align 4
  %33396 = icmp eq i32 %33262, %33395
  %33397 = or i1 %33394, %33396
  %33398 = load i32, i32* %50, align 4
  %33399 = icmp eq i32 %33262, %33398
  %33400 = or i1 %33397, %33399
  %33401 = load i32, i32* %51, align 4
  %33402 = icmp eq i32 %33262, %33401
  %33403 = or i1 %33400, %33402
  %33404 = load i32, i32* %52, align 4
  %33405 = icmp eq i32 %33262, %33404
  %33406 = or i1 %33403, %33405
  %33407 = load i32, i32* %53, align 4
  %33408 = icmp eq i32 %33262, %33407
  %33409 = or i1 %33406, %33408
  %33410 = load i32, i32* %54, align 4
  %33411 = icmp eq i32 %33262, %33410
  %33412 = or i1 %33409, %33411
  %33413 = load i32, i32* %55, align 4
  %33414 = icmp eq i32 %33262, %33413
  %33415 = or i1 %33412, %33414
  %33416 = load i32, i32* %56, align 4
  %33417 = icmp eq i32 %33262, %33416
  %33418 = or i1 %33415, %33417
  %33419 = load i32, i32* %57, align 4
  %33420 = icmp eq i32 %33262, %33419
  %33421 = or i1 %33418, %33420
  %33422 = load i32, i32* %58, align 4
  %33423 = icmp eq i32 %33262, %33422
  %33424 = or i1 %33421, %33423
  %33425 = load i32, i32* %59, align 4
  %33426 = icmp eq i32 %33262, %33425
  %33427 = or i1 %33424, %33426
  %33428 = load i32, i32* %60, align 4
  %33429 = icmp eq i32 %33262, %33428
  %33430 = or i1 %33427, %33429
  %33431 = load i32, i32* %61, align 4
  %33432 = icmp eq i32 %33262, %33431
  %33433 = or i1 %33430, %33432
  %33434 = load i32, i32* %62, align 4
  %33435 = icmp eq i32 %33262, %33434
  %33436 = or i1 %33433, %33435
  %33437 = getelementptr i8, i8 addrspace(1)* %4, i32 122
  %33438 = zext i1 %33436 to i8
  store i8 %33438, i8 addrspace(1)* %33437, align 1, !nosanitize !3
  %33439 = load i256, i256* %33261, align 4
  %33440 = alloca i256, align 8
  store i256 %33439, i256* %33440, align 4
  %33441 = alloca i256, align 8
  store i256 1, i256* %33441, align 4
  %33442 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %33440, i256* %33441, i256* %33442), !pc !486, !intsan !6
  %33443 = load i256, i256* %33442, align 4
  %33444 = and i256 1461501637330902918203684832716283019655932542975, %33443
  %33445 = and i256 1461501637330902918203684832716283019655932542975, %33444
  %33446 = icmp eq i256 %33256, 0
  %33447 = zext i1 %33446 to i256
  %33448 = mul i256 %33447, 2300, !pc !487, !intsan !45
  %33449 = trunc i256 64 to i64
  %33450 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33449, i256* %33450)
  %33451 = load i256, i256* %33450, align 4
  %33452 = trunc i256 64 to i64
  %33453 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33452, i256* %33453)
  %33454 = load i256, i256* %33453, align 4
  %33455 = sub i256 %33451, %33454, !pc !488, !intsan !8
  %33456 = trunc i256 %33448 to i64
  %33457 = trunc i256 %33445 to i160
  %33458 = call i1 @solidity_call(), !pc !489
  %33459 = icmp eq i1 %33458, false
  %33460 = icmp eq i1 %33459, false
  %33461 = trunc i256 11258 to i64
  %jump.check201 = icmp ne i1 %33460, false
  %33462 = load i64, i64* %STACK_DEP_PTR, align 4
  %33463 = add i64 %33462, 1
  store i64 %33463, i64* %STACK_DEP_PTR, align 4
  %33464 = load i64, i64* %STACK_DEP_PTR, align 4
  %33465 = getelementptr i256, i256* %STACK, i64 %33464
  store i256 %33256, i256* %33465, align 4
  %33466 = load i64, i64* %STACK_DEP_PTR, align 4
  %33467 = add i64 %33466, 1
  store i64 %33467, i64* %STACK_DEP_PTR, align 4
  %33468 = load i64, i64* %STACK_DEP_PTR, align 4
  %33469 = getelementptr i256, i256* %STACK, i64 %33468
  store i256 %33251, i256* %33469, align 4
  br i1 %jump.check201, label %.11258, label %.11118, !EVMBB !4

.11118:                                           ; preds = %33242
  %33470 = load i64, i64* %remaing_gas, align 4
  %33471 = icmp ugt i64 288, %33470
  br i1 %33471, label %Abort, label %33472

33472:                                            ; preds = %.11118
  %33473 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33474 = xor i32 %33473, 809
  %33475 = urem i32 %33474, 4096
  %33476 = getelementptr i8, i8 addrspace(1)* %4, i32 %33475
  %33477 = load i8, i8 addrspace(1)* %33476, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33476, align 1, !nosanitize !3
  store i32 404, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33478 = sub i64 %33470, 288
  store i64 %33478, i64* %remaing_gas, align 4
  %33479 = add i256 0, 9, !pc !490, !intsan !10
  %33480 = alloca i256, align 8
  store i256 %33479, i256* %33480, align 4
  %33481 = alloca i256, align 8
  call void @__device_sload(i256* %33480, i256* %33481)
  %33482 = call i32 @__hashword(i256* %33480)
  %33483 = load i32, i32* %5, align 4
  %33484 = icmp eq i32 %33482, %33483
  %33485 = or i1 false, %33484
  %33486 = load i32, i32* %6, align 4
  %33487 = icmp eq i32 %33482, %33486
  %33488 = or i1 %33485, %33487
  %33489 = load i32, i32* %7, align 4
  %33490 = icmp eq i32 %33482, %33489
  %33491 = or i1 %33488, %33490
  %33492 = load i32, i32* %8, align 4
  %33493 = icmp eq i32 %33482, %33492
  %33494 = or i1 %33491, %33493
  %33495 = load i32, i32* %9, align 4
  %33496 = icmp eq i32 %33482, %33495
  %33497 = or i1 %33494, %33496
  %33498 = load i32, i32* %10, align 4
  %33499 = icmp eq i32 %33482, %33498
  %33500 = or i1 %33497, %33499
  %33501 = load i32, i32* %11, align 4
  %33502 = icmp eq i32 %33482, %33501
  %33503 = or i1 %33500, %33502
  %33504 = load i32, i32* %12, align 4
  %33505 = icmp eq i32 %33482, %33504
  %33506 = or i1 %33503, %33505
  %33507 = load i32, i32* %13, align 4
  %33508 = icmp eq i32 %33482, %33507
  %33509 = or i1 %33506, %33508
  %33510 = load i32, i32* %14, align 4
  %33511 = icmp eq i32 %33482, %33510
  %33512 = or i1 %33509, %33511
  %33513 = load i32, i32* %15, align 4
  %33514 = icmp eq i32 %33482, %33513
  %33515 = or i1 %33512, %33514
  %33516 = load i32, i32* %16, align 4
  %33517 = icmp eq i32 %33482, %33516
  %33518 = or i1 %33515, %33517
  %33519 = load i32, i32* %17, align 4
  %33520 = icmp eq i32 %33482, %33519
  %33521 = or i1 %33518, %33520
  %33522 = load i32, i32* %18, align 4
  %33523 = icmp eq i32 %33482, %33522
  %33524 = or i1 %33521, %33523
  %33525 = load i32, i32* %19, align 4
  %33526 = icmp eq i32 %33482, %33525
  %33527 = or i1 %33524, %33526
  %33528 = load i32, i32* %20, align 4
  %33529 = icmp eq i32 %33482, %33528
  %33530 = or i1 %33527, %33529
  %33531 = load i32, i32* %21, align 4
  %33532 = icmp eq i32 %33482, %33531
  %33533 = or i1 %33530, %33532
  %33534 = load i32, i32* %22, align 4
  %33535 = icmp eq i32 %33482, %33534
  %33536 = or i1 %33533, %33535
  %33537 = load i32, i32* %23, align 4
  %33538 = icmp eq i32 %33482, %33537
  %33539 = or i1 %33536, %33538
  %33540 = load i32, i32* %24, align 4
  %33541 = icmp eq i32 %33482, %33540
  %33542 = or i1 %33539, %33541
  %33543 = load i32, i32* %25, align 4
  %33544 = icmp eq i32 %33482, %33543
  %33545 = or i1 %33542, %33544
  %33546 = load i32, i32* %26, align 4
  %33547 = icmp eq i32 %33482, %33546
  %33548 = or i1 %33545, %33547
  %33549 = load i32, i32* %27, align 4
  %33550 = icmp eq i32 %33482, %33549
  %33551 = or i1 %33548, %33550
  %33552 = load i32, i32* %28, align 4
  %33553 = icmp eq i32 %33482, %33552
  %33554 = or i1 %33551, %33553
  %33555 = load i32, i32* %29, align 4
  %33556 = icmp eq i32 %33482, %33555
  %33557 = or i1 %33554, %33556
  %33558 = load i32, i32* %30, align 4
  %33559 = icmp eq i32 %33482, %33558
  %33560 = or i1 %33557, %33559
  %33561 = load i32, i32* %31, align 4
  %33562 = icmp eq i32 %33482, %33561
  %33563 = or i1 %33560, %33562
  %33564 = load i32, i32* %32, align 4
  %33565 = icmp eq i32 %33482, %33564
  %33566 = or i1 %33563, %33565
  %33567 = load i32, i32* %33, align 4
  %33568 = icmp eq i32 %33482, %33567
  %33569 = or i1 %33566, %33568
  %33570 = load i32, i32* %34, align 4
  %33571 = icmp eq i32 %33482, %33570
  %33572 = or i1 %33569, %33571
  %33573 = load i32, i32* %35, align 4
  %33574 = icmp eq i32 %33482, %33573
  %33575 = or i1 %33572, %33574
  %33576 = load i32, i32* %36, align 4
  %33577 = icmp eq i32 %33482, %33576
  %33578 = or i1 %33575, %33577
  %33579 = load i32, i32* %37, align 4
  %33580 = icmp eq i32 %33482, %33579
  %33581 = or i1 %33578, %33580
  %33582 = load i32, i32* %38, align 4
  %33583 = icmp eq i32 %33482, %33582
  %33584 = or i1 %33581, %33583
  %33585 = load i32, i32* %39, align 4
  %33586 = icmp eq i32 %33482, %33585
  %33587 = or i1 %33584, %33586
  %33588 = load i32, i32* %40, align 4
  %33589 = icmp eq i32 %33482, %33588
  %33590 = or i1 %33587, %33589
  %33591 = load i32, i32* %41, align 4
  %33592 = icmp eq i32 %33482, %33591
  %33593 = or i1 %33590, %33592
  %33594 = load i32, i32* %42, align 4
  %33595 = icmp eq i32 %33482, %33594
  %33596 = or i1 %33593, %33595
  %33597 = load i32, i32* %43, align 4
  %33598 = icmp eq i32 %33482, %33597
  %33599 = or i1 %33596, %33598
  %33600 = load i32, i32* %44, align 4
  %33601 = icmp eq i32 %33482, %33600
  %33602 = or i1 %33599, %33601
  %33603 = load i32, i32* %45, align 4
  %33604 = icmp eq i32 %33482, %33603
  %33605 = or i1 %33602, %33604
  %33606 = load i32, i32* %46, align 4
  %33607 = icmp eq i32 %33482, %33606
  %33608 = or i1 %33605, %33607
  %33609 = load i32, i32* %47, align 4
  %33610 = icmp eq i32 %33482, %33609
  %33611 = or i1 %33608, %33610
  %33612 = load i32, i32* %48, align 4
  %33613 = icmp eq i32 %33482, %33612
  %33614 = or i1 %33611, %33613
  %33615 = load i32, i32* %49, align 4
  %33616 = icmp eq i32 %33482, %33615
  %33617 = or i1 %33614, %33616
  %33618 = load i32, i32* %50, align 4
  %33619 = icmp eq i32 %33482, %33618
  %33620 = or i1 %33617, %33619
  %33621 = load i32, i32* %51, align 4
  %33622 = icmp eq i32 %33482, %33621
  %33623 = or i1 %33620, %33622
  %33624 = load i32, i32* %52, align 4
  %33625 = icmp eq i32 %33482, %33624
  %33626 = or i1 %33623, %33625
  %33627 = load i32, i32* %53, align 4
  %33628 = icmp eq i32 %33482, %33627
  %33629 = or i1 %33626, %33628
  %33630 = load i32, i32* %54, align 4
  %33631 = icmp eq i32 %33482, %33630
  %33632 = or i1 %33629, %33631
  %33633 = load i32, i32* %55, align 4
  %33634 = icmp eq i32 %33482, %33633
  %33635 = or i1 %33632, %33634
  %33636 = load i32, i32* %56, align 4
  %33637 = icmp eq i32 %33482, %33636
  %33638 = or i1 %33635, %33637
  %33639 = load i32, i32* %57, align 4
  %33640 = icmp eq i32 %33482, %33639
  %33641 = or i1 %33638, %33640
  %33642 = load i32, i32* %58, align 4
  %33643 = icmp eq i32 %33482, %33642
  %33644 = or i1 %33641, %33643
  %33645 = load i32, i32* %59, align 4
  %33646 = icmp eq i32 %33482, %33645
  %33647 = or i1 %33644, %33646
  %33648 = load i32, i32* %60, align 4
  %33649 = icmp eq i32 %33482, %33648
  %33650 = or i1 %33647, %33649
  %33651 = load i32, i32* %61, align 4
  %33652 = icmp eq i32 %33482, %33651
  %33653 = or i1 %33650, %33652
  %33654 = load i32, i32* %62, align 4
  %33655 = icmp eq i32 %33482, %33654
  %33656 = or i1 %33653, %33655
  %33657 = getelementptr i8, i8 addrspace(1)* %4, i32 123
  %33658 = zext i1 %33656 to i8
  store i8 %33658, i8 addrspace(1)* %33657, align 1, !nosanitize !3
  %33659 = load i256, i256* %33481, align 4
  %33660 = alloca i256, align 8
  store i256 %33659, i256* %33660, align 4
  %33661 = alloca i256, align 8
  store i256 1, i256* %33661, align 4
  %33662 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %33660, i256* %33661, i256* %33662), !pc !491, !intsan !6
  %33663 = load i256, i256* %33662, align 4
  %33664 = and i256 1461501637330902918203684832716283019655932542975, %33663
  %33665 = trunc i256 64 to i64
  %33666 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33665, i256* %33666)
  %33667 = load i256, i256* %33666, align 4
  %33668 = and i256 1461501637330902918203684832716283019655932542975, %33664
  %33669 = and i256 1461501637330902918203684832716283019655932542975, %33668
  %33670 = trunc i256 %33667 to i64
  %33671 = alloca i256, align 8
  store i256 %33669, i256* %33671, align 4
  %33672 = bitcast i256* %33671 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %33670, i8* %33672, i64 32)
  %33673 = add i256 32, %33667, !pc !492, !intsan !10
  %33674 = trunc i256 64 to i64
  %33675 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33674, i256* %33675)
  %33676 = load i256, i256* %33675, align 4
  %33677 = sub i256 %33673, %33676, !pc !493, !intsan !8
  %33678 = trunc i256 7155602720681454585969760487994778355711330073987255661834597545509106654009 to i64
  call void @addBugSet(i64 %33678)
  %33679 = trunc i256 11403 to i64
  br label %.11403, !EVMBB !4

.11258:                                           ; preds = %33242, %JumpTable
  %33680 = load i64, i64* %STACK_DEP_PTR, align 4
  %33681 = getelementptr i256, i256* %STACK, i64 %33680
  %33682 = load i256, i256* %33681, align 4
  %33683 = load i64, i64* %STACK_DEP_PTR, align 4
  %33684 = sub i64 %33683, 1
  store i64 %33684, i64* %STACK_DEP_PTR, align 4
  %33685 = load i64, i64* %STACK_DEP_PTR, align 4
  %33686 = getelementptr i256, i256* %STACK, i64 %33685
  %33687 = load i256, i256* %33686, align 4
  %33688 = load i64, i64* %STACK_DEP_PTR, align 4
  %33689 = sub i64 %33688, 1
  store i64 %33689, i64* %STACK_DEP_PTR, align 4
  %33690 = add i256 0, 9, !pc !494, !intsan !10
  %33691 = alloca i256, align 8
  store i256 %33690, i256* %33691, align 4
  %33692 = alloca i256, align 8
  call void @__device_sload(i256* %33691, i256* %33692)
  %33693 = call i32 @__hashword(i256* %33691)
  %33694 = load i32, i32* %5, align 4
  %33695 = icmp eq i32 %33693, %33694
  %33696 = or i1 false, %33695
  %33697 = load i32, i32* %6, align 4
  %33698 = icmp eq i32 %33693, %33697
  %33699 = or i1 %33696, %33698
  %33700 = load i32, i32* %7, align 4
  %33701 = icmp eq i32 %33693, %33700
  %33702 = or i1 %33699, %33701
  %33703 = load i32, i32* %8, align 4
  %33704 = icmp eq i32 %33693, %33703
  %33705 = or i1 %33702, %33704
  %33706 = load i32, i32* %9, align 4
  %33707 = icmp eq i32 %33693, %33706
  %33708 = or i1 %33705, %33707
  %33709 = load i32, i32* %10, align 4
  %33710 = icmp eq i32 %33693, %33709
  %33711 = or i1 %33708, %33710
  %33712 = load i32, i32* %11, align 4
  %33713 = icmp eq i32 %33693, %33712
  %33714 = or i1 %33711, %33713
  %33715 = load i32, i32* %12, align 4
  %33716 = icmp eq i32 %33693, %33715
  %33717 = or i1 %33714, %33716
  %33718 = load i32, i32* %13, align 4
  %33719 = icmp eq i32 %33693, %33718
  %33720 = or i1 %33717, %33719
  %33721 = load i32, i32* %14, align 4
  %33722 = icmp eq i32 %33693, %33721
  %33723 = or i1 %33720, %33722
  %33724 = load i32, i32* %15, align 4
  %33725 = icmp eq i32 %33693, %33724
  %33726 = or i1 %33723, %33725
  %33727 = load i32, i32* %16, align 4
  %33728 = icmp eq i32 %33693, %33727
  %33729 = or i1 %33726, %33728
  %33730 = load i32, i32* %17, align 4
  %33731 = icmp eq i32 %33693, %33730
  %33732 = or i1 %33729, %33731
  %33733 = load i32, i32* %18, align 4
  %33734 = icmp eq i32 %33693, %33733
  %33735 = or i1 %33732, %33734
  %33736 = load i32, i32* %19, align 4
  %33737 = icmp eq i32 %33693, %33736
  %33738 = or i1 %33735, %33737
  %33739 = load i32, i32* %20, align 4
  %33740 = icmp eq i32 %33693, %33739
  %33741 = or i1 %33738, %33740
  %33742 = load i32, i32* %21, align 4
  %33743 = icmp eq i32 %33693, %33742
  %33744 = or i1 %33741, %33743
  %33745 = load i32, i32* %22, align 4
  %33746 = icmp eq i32 %33693, %33745
  %33747 = or i1 %33744, %33746
  %33748 = load i32, i32* %23, align 4
  %33749 = icmp eq i32 %33693, %33748
  %33750 = or i1 %33747, %33749
  %33751 = load i32, i32* %24, align 4
  %33752 = icmp eq i32 %33693, %33751
  %33753 = or i1 %33750, %33752
  %33754 = load i32, i32* %25, align 4
  %33755 = icmp eq i32 %33693, %33754
  %33756 = or i1 %33753, %33755
  %33757 = load i32, i32* %26, align 4
  %33758 = icmp eq i32 %33693, %33757
  %33759 = or i1 %33756, %33758
  %33760 = load i32, i32* %27, align 4
  %33761 = icmp eq i32 %33693, %33760
  %33762 = or i1 %33759, %33761
  %33763 = load i32, i32* %28, align 4
  %33764 = icmp eq i32 %33693, %33763
  %33765 = or i1 %33762, %33764
  %33766 = load i32, i32* %29, align 4
  %33767 = icmp eq i32 %33693, %33766
  %33768 = or i1 %33765, %33767
  %33769 = load i32, i32* %30, align 4
  %33770 = icmp eq i32 %33693, %33769
  %33771 = or i1 %33768, %33770
  %33772 = load i32, i32* %31, align 4
  %33773 = icmp eq i32 %33693, %33772
  %33774 = or i1 %33771, %33773
  %33775 = load i32, i32* %32, align 4
  %33776 = icmp eq i32 %33693, %33775
  %33777 = or i1 %33774, %33776
  %33778 = load i32, i32* %33, align 4
  %33779 = icmp eq i32 %33693, %33778
  %33780 = or i1 %33777, %33779
  %33781 = load i32, i32* %34, align 4
  %33782 = icmp eq i32 %33693, %33781
  %33783 = or i1 %33780, %33782
  %33784 = load i32, i32* %35, align 4
  %33785 = icmp eq i32 %33693, %33784
  %33786 = or i1 %33783, %33785
  %33787 = load i32, i32* %36, align 4
  %33788 = icmp eq i32 %33693, %33787
  %33789 = or i1 %33786, %33788
  %33790 = load i32, i32* %37, align 4
  %33791 = icmp eq i32 %33693, %33790
  %33792 = or i1 %33789, %33791
  %33793 = load i32, i32* %38, align 4
  %33794 = icmp eq i32 %33693, %33793
  %33795 = or i1 %33792, %33794
  %33796 = load i32, i32* %39, align 4
  %33797 = icmp eq i32 %33693, %33796
  %33798 = or i1 %33795, %33797
  %33799 = load i32, i32* %40, align 4
  %33800 = icmp eq i32 %33693, %33799
  %33801 = or i1 %33798, %33800
  %33802 = load i32, i32* %41, align 4
  %33803 = icmp eq i32 %33693, %33802
  %33804 = or i1 %33801, %33803
  %33805 = load i32, i32* %42, align 4
  %33806 = icmp eq i32 %33693, %33805
  %33807 = or i1 %33804, %33806
  %33808 = load i32, i32* %43, align 4
  %33809 = icmp eq i32 %33693, %33808
  %33810 = or i1 %33807, %33809
  %33811 = load i32, i32* %44, align 4
  %33812 = icmp eq i32 %33693, %33811
  %33813 = or i1 %33810, %33812
  %33814 = load i32, i32* %45, align 4
  %33815 = icmp eq i32 %33693, %33814
  %33816 = or i1 %33813, %33815
  %33817 = load i32, i32* %46, align 4
  %33818 = icmp eq i32 %33693, %33817
  %33819 = or i1 %33816, %33818
  %33820 = load i32, i32* %47, align 4
  %33821 = icmp eq i32 %33693, %33820
  %33822 = or i1 %33819, %33821
  %33823 = load i32, i32* %48, align 4
  %33824 = icmp eq i32 %33693, %33823
  %33825 = or i1 %33822, %33824
  %33826 = load i32, i32* %49, align 4
  %33827 = icmp eq i32 %33693, %33826
  %33828 = or i1 %33825, %33827
  %33829 = load i32, i32* %50, align 4
  %33830 = icmp eq i32 %33693, %33829
  %33831 = or i1 %33828, %33830
  %33832 = load i32, i32* %51, align 4
  %33833 = icmp eq i32 %33693, %33832
  %33834 = or i1 %33831, %33833
  %33835 = load i32, i32* %52, align 4
  %33836 = icmp eq i32 %33693, %33835
  %33837 = or i1 %33834, %33836
  %33838 = load i32, i32* %53, align 4
  %33839 = icmp eq i32 %33693, %33838
  %33840 = or i1 %33837, %33839
  %33841 = load i32, i32* %54, align 4
  %33842 = icmp eq i32 %33693, %33841
  %33843 = or i1 %33840, %33842
  %33844 = load i32, i32* %55, align 4
  %33845 = icmp eq i32 %33693, %33844
  %33846 = or i1 %33843, %33845
  %33847 = load i32, i32* %56, align 4
  %33848 = icmp eq i32 %33693, %33847
  %33849 = or i1 %33846, %33848
  %33850 = load i32, i32* %57, align 4
  %33851 = icmp eq i32 %33693, %33850
  %33852 = or i1 %33849, %33851
  %33853 = load i32, i32* %58, align 4
  %33854 = icmp eq i32 %33693, %33853
  %33855 = or i1 %33852, %33854
  %33856 = load i32, i32* %59, align 4
  %33857 = icmp eq i32 %33693, %33856
  %33858 = or i1 %33855, %33857
  %33859 = load i32, i32* %60, align 4
  %33860 = icmp eq i32 %33693, %33859
  %33861 = or i1 %33858, %33860
  %33862 = load i32, i32* %61, align 4
  %33863 = icmp eq i32 %33693, %33862
  %33864 = or i1 %33861, %33863
  %33865 = load i32, i32* %62, align 4
  %33866 = icmp eq i32 %33693, %33865
  %33867 = or i1 %33864, %33866
  %33868 = getelementptr i8, i8 addrspace(1)* %4, i32 124
  %33869 = zext i1 %33867 to i8
  store i8 %33869, i8 addrspace(1)* %33868, align 1, !nosanitize !3
  %33870 = load i256, i256* %33692, align 4
  %33871 = alloca i256, align 8
  store i256 %33870, i256* %33871, align 4
  %33872 = alloca i256, align 8
  store i256 1, i256* %33872, align 4
  %33873 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %33871, i256* %33872, i256* %33873), !pc !495, !intsan !6
  %33874 = load i256, i256* %33873, align 4
  %33875 = and i256 1461501637330902918203684832716283019655932542975, %33874
  %33876 = trunc i256 64 to i64
  %33877 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33876, i256* %33877)
  %33878 = load i256, i256* %33877, align 4
  %33879 = and i256 1461501637330902918203684832716283019655932542975, %33875
  %33880 = and i256 1461501637330902918203684832716283019655932542975, %33879
  %33881 = trunc i256 %33878 to i64
  %33882 = alloca i256, align 8
  store i256 %33880, i256* %33882, align 4
  %33883 = bitcast i256* %33882 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %33881, i8* %33883, i64 32)
  %33884 = add i256 32, %33878, !pc !496, !intsan !10
  %33885 = trunc i256 %33884 to i64
  %33886 = alloca i256, align 8
  store i256 %33687, i256* %33886, align 4
  %33887 = bitcast i256* %33886 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %33885, i8* %33887, i64 32)
  %33888 = add i256 32, %33884, !pc !497, !intsan !10
  %33889 = trunc i256 64 to i64
  %33890 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %33889, i256* %33890)
  %33891 = load i256, i256* %33890, align 4
  %33892 = sub i256 %33888, %33891, !pc !498, !intsan !8
  %33893 = trunc i256 -14376072245180912860070868870355120589304503384260103040251489196527440959694 to i64
  call void @addBugSet(i64 %33893)
  %33894 = load i64, i64* %STACK_DEP_PTR, align 4
  %33895 = add i64 %33894, 1
  store i64 %33895, i64* %STACK_DEP_PTR, align 4
  %33896 = load i64, i64* %STACK_DEP_PTR, align 4
  %33897 = getelementptr i256, i256* %STACK, i64 %33896
  store i256 %33687, i256* %33897, align 4
  %33898 = load i64, i64* %STACK_DEP_PTR, align 4
  %33899 = add i64 %33898, 1
  store i64 %33899, i64* %STACK_DEP_PTR, align 4
  %33900 = load i64, i64* %STACK_DEP_PTR, align 4
  %33901 = getelementptr i256, i256* %STACK, i64 %33900
  store i256 %33682, i256* %33901, align 4
  br label %.11403

.11403:                                           ; preds = %.11258, %33472, %JumpTable
  %33902 = load i64, i64* %remaing_gas, align 4
  %33903 = icmp ugt i64 24, %33902
  br i1 %33903, label %Abort, label %33904

33904:                                            ; preds = %.11403
  %33905 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33906 = xor i32 %33905, 68
  %33907 = urem i32 %33906, 4096
  %33908 = getelementptr i8, i8 addrspace(1)* %4, i32 %33907
  %33909 = load i8, i8 addrspace(1)* %33908, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33908, align 1, !nosanitize !3
  store i32 34, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33910 = sub i64 %33902, 24
  store i64 %33910, i64* %remaing_gas, align 4
  %33911 = trunc i256 11413 to i64
  br label %.11413, !EVMBB !4

.11408:                                           ; preds = %33188, %JumpTable
  %33912 = load i64, i64* %remaing_gas, align 4
  %33913 = icmp ugt i64 16, %33912
  br i1 %33913, label %Abort, label %33914

33914:                                            ; preds = %.11408
  %33915 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33916 = xor i32 %33915, 734
  %33917 = urem i32 %33916, 4096
  %33918 = getelementptr i8, i8 addrspace(1)* %4, i32 %33917
  %33919 = load i8, i8 addrspace(1)* %33918, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33918, align 1, !nosanitize !3
  store i32 367, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33920 = sub i64 %33912, 16
  store i64 %33920, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11413:                                           ; preds = %33904, %JumpTable
  %33921 = load i64, i64* %remaing_gas, align 4
  %33922 = icmp ugt i64 224, %33921
  br i1 %33922, label %Abort, label %33923

33923:                                            ; preds = %.11413
  %33924 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33925 = xor i32 %33924, 1148
  %33926 = urem i32 %33925, 4096
  %33927 = getelementptr i8, i8 addrspace(1)* %4, i32 %33926
  %33928 = load i8, i8 addrspace(1)* %33927, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33927, align 1, !nosanitize !3
  store i32 574, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33929 = sub i64 %33921, 224
  store i64 %33929, i64* %remaing_gas, align 4
  %33930 = load i64, i64* %STACK_DEP_PTR, align 4
  %33931 = getelementptr i256, i256* %STACK, i64 %33930
  %33932 = load i256, i256* %33931, align 4
  %33933 = load i64, i64* %STACK_DEP_PTR, align 4
  %33934 = sub i64 %33933, 1
  store i64 %33934, i64* %STACK_DEP_PTR, align 4
  %33935 = load i64, i64* %STACK_DEP_PTR, align 4
  %33936 = getelementptr i256, i256* %STACK, i64 %33935
  %33937 = load i256, i256* %33936, align 4
  %33938 = load i64, i64* %STACK_DEP_PTR, align 4
  %33939 = sub i64 %33938, 1
  store i64 %33939, i64* %STACK_DEP_PTR, align 4
  %33940 = load i64, i64* %STACK_DEP_PTR, align 4
  %33941 = getelementptr i256, i256* %STACK, i64 %33940
  %33942 = load i256, i256* %33941, align 4
  %33943 = load i64, i64* %STACK_DEP_PTR, align 4
  %33944 = sub i64 %33943, 1
  store i64 %33944, i64* %STACK_DEP_PTR, align 4
  %33945 = load i64, i64* %STACK_DEP_PTR, align 4
  %33946 = getelementptr i256, i256* %STACK, i64 %33945
  %33947 = load i256, i256* %33946, align 4
  %33948 = load i64, i64* %STACK_DEP_PTR, align 4
  %33949 = sub i64 %33948, 1
  store i64 %33949, i64* %STACK_DEP_PTR, align 4
  %33950 = trunc i256 %33947 to i64
  store i64 %33950, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.11418:                                           ; preds = %39055, %25967, %20207, %19971, %3755, %JumpTable
  %33951 = load i64, i64* %remaing_gas, align 4
  %33952 = icmp ugt i64 816, %33951
  br i1 %33952, label %Abort, label %33953

33953:                                            ; preds = %.11418
  %33954 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33955 = xor i32 %33954, 4005
  %33956 = urem i32 %33955, 4096
  %33957 = getelementptr i8, i8 addrspace(1)* %4, i32 %33956
  %33958 = load i8, i8 addrspace(1)* %33957, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %33957, align 1, !nosanitize !3
  store i32 2002, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %33959 = sub i64 %33951, 816
  store i64 %33959, i64* %remaing_gas, align 4
  %33960 = load i64, i64* %STACK_DEP_PTR, align 4
  %33961 = getelementptr i256, i256* %STACK, i64 %33960
  %33962 = load i256, i256* %33961, align 4
  %33963 = load i64, i64* %STACK_DEP_PTR, align 4
  %33964 = sub i64 %33963, 1
  store i64 %33964, i64* %STACK_DEP_PTR, align 4
  %33965 = and i256 1461501637330902918203684832716283019655932542975, %33962
  %33966 = and i256 1461501637330902918203684832716283019655932542975, %33965
  %33967 = trunc i256 0 to i64
  %33968 = alloca i256, align 8
  store i256 %33966, i256* %33968, align 4
  %33969 = bitcast i256* %33968 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %33967, i8* %33969, i64 32)
  %33970 = add i256 32, 0, !pc !499, !intsan !10
  %33971 = trunc i256 %33970 to i64
  %33972 = alloca i256, align 8
  store i256 3, i256* %33972, align 4
  %33973 = bitcast i256* %33972 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %33971, i8* %33973, i64 32)
  %33974 = add i256 32, %33970, !pc !500, !intsan !10
  %33975 = trunc i256 0 to i32
  %33976 = trunc i256 %33974 to i32
  %33977 = getelementptr inbounds i8, i8* %MEMORY, i32 %33975
  %33978 = alloca i256, align 8
  %33979 = bitcast i256* %33978 to i8*
  call void @__device_sha3(i8* %33977, i32 %33976, i8* %33979)
  %33980 = load i256, i256* %33978, align 4
  %33981 = alloca i256, align 8
  store i256 %33980, i256* %33981, align 4
  %33982 = alloca i256, align 8
  call void @__device_sload(i256* %33981, i256* %33982)
  %33983 = call i32 @__hashword(i256* %33981)
  %33984 = load i32, i32* %5, align 4
  %33985 = icmp eq i32 %33983, %33984
  %33986 = or i1 false, %33985
  %33987 = load i32, i32* %6, align 4
  %33988 = icmp eq i32 %33983, %33987
  %33989 = or i1 %33986, %33988
  %33990 = load i32, i32* %7, align 4
  %33991 = icmp eq i32 %33983, %33990
  %33992 = or i1 %33989, %33991
  %33993 = load i32, i32* %8, align 4
  %33994 = icmp eq i32 %33983, %33993
  %33995 = or i1 %33992, %33994
  %33996 = load i32, i32* %9, align 4
  %33997 = icmp eq i32 %33983, %33996
  %33998 = or i1 %33995, %33997
  %33999 = load i32, i32* %10, align 4
  %34000 = icmp eq i32 %33983, %33999
  %34001 = or i1 %33998, %34000
  %34002 = load i32, i32* %11, align 4
  %34003 = icmp eq i32 %33983, %34002
  %34004 = or i1 %34001, %34003
  %34005 = load i32, i32* %12, align 4
  %34006 = icmp eq i32 %33983, %34005
  %34007 = or i1 %34004, %34006
  %34008 = load i32, i32* %13, align 4
  %34009 = icmp eq i32 %33983, %34008
  %34010 = or i1 %34007, %34009
  %34011 = load i32, i32* %14, align 4
  %34012 = icmp eq i32 %33983, %34011
  %34013 = or i1 %34010, %34012
  %34014 = load i32, i32* %15, align 4
  %34015 = icmp eq i32 %33983, %34014
  %34016 = or i1 %34013, %34015
  %34017 = load i32, i32* %16, align 4
  %34018 = icmp eq i32 %33983, %34017
  %34019 = or i1 %34016, %34018
  %34020 = load i32, i32* %17, align 4
  %34021 = icmp eq i32 %33983, %34020
  %34022 = or i1 %34019, %34021
  %34023 = load i32, i32* %18, align 4
  %34024 = icmp eq i32 %33983, %34023
  %34025 = or i1 %34022, %34024
  %34026 = load i32, i32* %19, align 4
  %34027 = icmp eq i32 %33983, %34026
  %34028 = or i1 %34025, %34027
  %34029 = load i32, i32* %20, align 4
  %34030 = icmp eq i32 %33983, %34029
  %34031 = or i1 %34028, %34030
  %34032 = load i32, i32* %21, align 4
  %34033 = icmp eq i32 %33983, %34032
  %34034 = or i1 %34031, %34033
  %34035 = load i32, i32* %22, align 4
  %34036 = icmp eq i32 %33983, %34035
  %34037 = or i1 %34034, %34036
  %34038 = load i32, i32* %23, align 4
  %34039 = icmp eq i32 %33983, %34038
  %34040 = or i1 %34037, %34039
  %34041 = load i32, i32* %24, align 4
  %34042 = icmp eq i32 %33983, %34041
  %34043 = or i1 %34040, %34042
  %34044 = load i32, i32* %25, align 4
  %34045 = icmp eq i32 %33983, %34044
  %34046 = or i1 %34043, %34045
  %34047 = load i32, i32* %26, align 4
  %34048 = icmp eq i32 %33983, %34047
  %34049 = or i1 %34046, %34048
  %34050 = load i32, i32* %27, align 4
  %34051 = icmp eq i32 %33983, %34050
  %34052 = or i1 %34049, %34051
  %34053 = load i32, i32* %28, align 4
  %34054 = icmp eq i32 %33983, %34053
  %34055 = or i1 %34052, %34054
  %34056 = load i32, i32* %29, align 4
  %34057 = icmp eq i32 %33983, %34056
  %34058 = or i1 %34055, %34057
  %34059 = load i32, i32* %30, align 4
  %34060 = icmp eq i32 %33983, %34059
  %34061 = or i1 %34058, %34060
  %34062 = load i32, i32* %31, align 4
  %34063 = icmp eq i32 %33983, %34062
  %34064 = or i1 %34061, %34063
  %34065 = load i32, i32* %32, align 4
  %34066 = icmp eq i32 %33983, %34065
  %34067 = or i1 %34064, %34066
  %34068 = load i32, i32* %33, align 4
  %34069 = icmp eq i32 %33983, %34068
  %34070 = or i1 %34067, %34069
  %34071 = load i32, i32* %34, align 4
  %34072 = icmp eq i32 %33983, %34071
  %34073 = or i1 %34070, %34072
  %34074 = load i32, i32* %35, align 4
  %34075 = icmp eq i32 %33983, %34074
  %34076 = or i1 %34073, %34075
  %34077 = load i32, i32* %36, align 4
  %34078 = icmp eq i32 %33983, %34077
  %34079 = or i1 %34076, %34078
  %34080 = load i32, i32* %37, align 4
  %34081 = icmp eq i32 %33983, %34080
  %34082 = or i1 %34079, %34081
  %34083 = load i32, i32* %38, align 4
  %34084 = icmp eq i32 %33983, %34083
  %34085 = or i1 %34082, %34084
  %34086 = load i32, i32* %39, align 4
  %34087 = icmp eq i32 %33983, %34086
  %34088 = or i1 %34085, %34087
  %34089 = load i32, i32* %40, align 4
  %34090 = icmp eq i32 %33983, %34089
  %34091 = or i1 %34088, %34090
  %34092 = load i32, i32* %41, align 4
  %34093 = icmp eq i32 %33983, %34092
  %34094 = or i1 %34091, %34093
  %34095 = load i32, i32* %42, align 4
  %34096 = icmp eq i32 %33983, %34095
  %34097 = or i1 %34094, %34096
  %34098 = load i32, i32* %43, align 4
  %34099 = icmp eq i32 %33983, %34098
  %34100 = or i1 %34097, %34099
  %34101 = load i32, i32* %44, align 4
  %34102 = icmp eq i32 %33983, %34101
  %34103 = or i1 %34100, %34102
  %34104 = load i32, i32* %45, align 4
  %34105 = icmp eq i32 %33983, %34104
  %34106 = or i1 %34103, %34105
  %34107 = load i32, i32* %46, align 4
  %34108 = icmp eq i32 %33983, %34107
  %34109 = or i1 %34106, %34108
  %34110 = load i32, i32* %47, align 4
  %34111 = icmp eq i32 %33983, %34110
  %34112 = or i1 %34109, %34111
  %34113 = load i32, i32* %48, align 4
  %34114 = icmp eq i32 %33983, %34113
  %34115 = or i1 %34112, %34114
  %34116 = load i32, i32* %49, align 4
  %34117 = icmp eq i32 %33983, %34116
  %34118 = or i1 %34115, %34117
  %34119 = load i32, i32* %50, align 4
  %34120 = icmp eq i32 %33983, %34119
  %34121 = or i1 %34118, %34120
  %34122 = load i32, i32* %51, align 4
  %34123 = icmp eq i32 %33983, %34122
  %34124 = or i1 %34121, %34123
  %34125 = load i32, i32* %52, align 4
  %34126 = icmp eq i32 %33983, %34125
  %34127 = or i1 %34124, %34126
  %34128 = load i32, i32* %53, align 4
  %34129 = icmp eq i32 %33983, %34128
  %34130 = or i1 %34127, %34129
  %34131 = load i32, i32* %54, align 4
  %34132 = icmp eq i32 %33983, %34131
  %34133 = or i1 %34130, %34132
  %34134 = load i32, i32* %55, align 4
  %34135 = icmp eq i32 %33983, %34134
  %34136 = or i1 %34133, %34135
  %34137 = load i32, i32* %56, align 4
  %34138 = icmp eq i32 %33983, %34137
  %34139 = or i1 %34136, %34138
  %34140 = load i32, i32* %57, align 4
  %34141 = icmp eq i32 %33983, %34140
  %34142 = or i1 %34139, %34141
  %34143 = load i32, i32* %58, align 4
  %34144 = icmp eq i32 %33983, %34143
  %34145 = or i1 %34142, %34144
  %34146 = load i32, i32* %59, align 4
  %34147 = icmp eq i32 %33983, %34146
  %34148 = or i1 %34145, %34147
  %34149 = load i32, i32* %60, align 4
  %34150 = icmp eq i32 %33983, %34149
  %34151 = or i1 %34148, %34150
  %34152 = load i32, i32* %61, align 4
  %34153 = icmp eq i32 %33983, %34152
  %34154 = or i1 %34151, %34153
  %34155 = load i32, i32* %62, align 4
  %34156 = icmp eq i32 %33983, %34155
  %34157 = or i1 %34154, %34156
  %34158 = getelementptr i8, i8 addrspace(1)* %4, i32 125
  %34159 = zext i1 %34157 to i8
  store i8 %34159, i8 addrspace(1)* %34158, align 1, !nosanitize !3
  %34160 = load i256, i256* %33982, align 4
  %34161 = trunc i256 0 to i64
  %34162 = alloca i256, align 8
  store i256 %34160, i256* %34162, align 4
  %34163 = bitcast i256* %34162 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %34161, i8* %34163, i64 32)
  %34164 = add i256 32, 0, !pc !501, !intsan !10
  %34165 = trunc i256 %34164 to i64
  %34166 = alloca i256, align 8
  store i256 4, i256* %34166, align 4
  %34167 = bitcast i256* %34166 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %34165, i8* %34167, i64 32)
  %34168 = add i256 32, %34164, !pc !502, !intsan !10
  %34169 = trunc i256 0 to i32
  %34170 = trunc i256 %34168 to i32
  %34171 = getelementptr inbounds i8, i8* %MEMORY, i32 %34169
  %34172 = alloca i256, align 8
  %34173 = bitcast i256* %34172 to i8*
  call void @__device_sha3(i8* %34171, i32 %34170, i8* %34173)
  %34174 = load i256, i256* %34172, align 4
  %34175 = add i256 1, %34174, !pc !503, !intsan !10
  %34176 = alloca i256, align 8
  store i256 %34175, i256* %34176, align 4
  %34177 = alloca i256, align 8
  call void @__device_sload(i256* %34176, i256* %34177)
  %34178 = call i32 @__hashword(i256* %34176)
  %34179 = load i32, i32* %5, align 4
  %34180 = icmp eq i32 %34178, %34179
  %34181 = or i1 false, %34180
  %34182 = load i32, i32* %6, align 4
  %34183 = icmp eq i32 %34178, %34182
  %34184 = or i1 %34181, %34183
  %34185 = load i32, i32* %7, align 4
  %34186 = icmp eq i32 %34178, %34185
  %34187 = or i1 %34184, %34186
  %34188 = load i32, i32* %8, align 4
  %34189 = icmp eq i32 %34178, %34188
  %34190 = or i1 %34187, %34189
  %34191 = load i32, i32* %9, align 4
  %34192 = icmp eq i32 %34178, %34191
  %34193 = or i1 %34190, %34192
  %34194 = load i32, i32* %10, align 4
  %34195 = icmp eq i32 %34178, %34194
  %34196 = or i1 %34193, %34195
  %34197 = load i32, i32* %11, align 4
  %34198 = icmp eq i32 %34178, %34197
  %34199 = or i1 %34196, %34198
  %34200 = load i32, i32* %12, align 4
  %34201 = icmp eq i32 %34178, %34200
  %34202 = or i1 %34199, %34201
  %34203 = load i32, i32* %13, align 4
  %34204 = icmp eq i32 %34178, %34203
  %34205 = or i1 %34202, %34204
  %34206 = load i32, i32* %14, align 4
  %34207 = icmp eq i32 %34178, %34206
  %34208 = or i1 %34205, %34207
  %34209 = load i32, i32* %15, align 4
  %34210 = icmp eq i32 %34178, %34209
  %34211 = or i1 %34208, %34210
  %34212 = load i32, i32* %16, align 4
  %34213 = icmp eq i32 %34178, %34212
  %34214 = or i1 %34211, %34213
  %34215 = load i32, i32* %17, align 4
  %34216 = icmp eq i32 %34178, %34215
  %34217 = or i1 %34214, %34216
  %34218 = load i32, i32* %18, align 4
  %34219 = icmp eq i32 %34178, %34218
  %34220 = or i1 %34217, %34219
  %34221 = load i32, i32* %19, align 4
  %34222 = icmp eq i32 %34178, %34221
  %34223 = or i1 %34220, %34222
  %34224 = load i32, i32* %20, align 4
  %34225 = icmp eq i32 %34178, %34224
  %34226 = or i1 %34223, %34225
  %34227 = load i32, i32* %21, align 4
  %34228 = icmp eq i32 %34178, %34227
  %34229 = or i1 %34226, %34228
  %34230 = load i32, i32* %22, align 4
  %34231 = icmp eq i32 %34178, %34230
  %34232 = or i1 %34229, %34231
  %34233 = load i32, i32* %23, align 4
  %34234 = icmp eq i32 %34178, %34233
  %34235 = or i1 %34232, %34234
  %34236 = load i32, i32* %24, align 4
  %34237 = icmp eq i32 %34178, %34236
  %34238 = or i1 %34235, %34237
  %34239 = load i32, i32* %25, align 4
  %34240 = icmp eq i32 %34178, %34239
  %34241 = or i1 %34238, %34240
  %34242 = load i32, i32* %26, align 4
  %34243 = icmp eq i32 %34178, %34242
  %34244 = or i1 %34241, %34243
  %34245 = load i32, i32* %27, align 4
  %34246 = icmp eq i32 %34178, %34245
  %34247 = or i1 %34244, %34246
  %34248 = load i32, i32* %28, align 4
  %34249 = icmp eq i32 %34178, %34248
  %34250 = or i1 %34247, %34249
  %34251 = load i32, i32* %29, align 4
  %34252 = icmp eq i32 %34178, %34251
  %34253 = or i1 %34250, %34252
  %34254 = load i32, i32* %30, align 4
  %34255 = icmp eq i32 %34178, %34254
  %34256 = or i1 %34253, %34255
  %34257 = load i32, i32* %31, align 4
  %34258 = icmp eq i32 %34178, %34257
  %34259 = or i1 %34256, %34258
  %34260 = load i32, i32* %32, align 4
  %34261 = icmp eq i32 %34178, %34260
  %34262 = or i1 %34259, %34261
  %34263 = load i32, i32* %33, align 4
  %34264 = icmp eq i32 %34178, %34263
  %34265 = or i1 %34262, %34264
  %34266 = load i32, i32* %34, align 4
  %34267 = icmp eq i32 %34178, %34266
  %34268 = or i1 %34265, %34267
  %34269 = load i32, i32* %35, align 4
  %34270 = icmp eq i32 %34178, %34269
  %34271 = or i1 %34268, %34270
  %34272 = load i32, i32* %36, align 4
  %34273 = icmp eq i32 %34178, %34272
  %34274 = or i1 %34271, %34273
  %34275 = load i32, i32* %37, align 4
  %34276 = icmp eq i32 %34178, %34275
  %34277 = or i1 %34274, %34276
  %34278 = load i32, i32* %38, align 4
  %34279 = icmp eq i32 %34178, %34278
  %34280 = or i1 %34277, %34279
  %34281 = load i32, i32* %39, align 4
  %34282 = icmp eq i32 %34178, %34281
  %34283 = or i1 %34280, %34282
  %34284 = load i32, i32* %40, align 4
  %34285 = icmp eq i32 %34178, %34284
  %34286 = or i1 %34283, %34285
  %34287 = load i32, i32* %41, align 4
  %34288 = icmp eq i32 %34178, %34287
  %34289 = or i1 %34286, %34288
  %34290 = load i32, i32* %42, align 4
  %34291 = icmp eq i32 %34178, %34290
  %34292 = or i1 %34289, %34291
  %34293 = load i32, i32* %43, align 4
  %34294 = icmp eq i32 %34178, %34293
  %34295 = or i1 %34292, %34294
  %34296 = load i32, i32* %44, align 4
  %34297 = icmp eq i32 %34178, %34296
  %34298 = or i1 %34295, %34297
  %34299 = load i32, i32* %45, align 4
  %34300 = icmp eq i32 %34178, %34299
  %34301 = or i1 %34298, %34300
  %34302 = load i32, i32* %46, align 4
  %34303 = icmp eq i32 %34178, %34302
  %34304 = or i1 %34301, %34303
  %34305 = load i32, i32* %47, align 4
  %34306 = icmp eq i32 %34178, %34305
  %34307 = or i1 %34304, %34306
  %34308 = load i32, i32* %48, align 4
  %34309 = icmp eq i32 %34178, %34308
  %34310 = or i1 %34307, %34309
  %34311 = load i32, i32* %49, align 4
  %34312 = icmp eq i32 %34178, %34311
  %34313 = or i1 %34310, %34312
  %34314 = load i32, i32* %50, align 4
  %34315 = icmp eq i32 %34178, %34314
  %34316 = or i1 %34313, %34315
  %34317 = load i32, i32* %51, align 4
  %34318 = icmp eq i32 %34178, %34317
  %34319 = or i1 %34316, %34318
  %34320 = load i32, i32* %52, align 4
  %34321 = icmp eq i32 %34178, %34320
  %34322 = or i1 %34319, %34321
  %34323 = load i32, i32* %53, align 4
  %34324 = icmp eq i32 %34178, %34323
  %34325 = or i1 %34322, %34324
  %34326 = load i32, i32* %54, align 4
  %34327 = icmp eq i32 %34178, %34326
  %34328 = or i1 %34325, %34327
  %34329 = load i32, i32* %55, align 4
  %34330 = icmp eq i32 %34178, %34329
  %34331 = or i1 %34328, %34330
  %34332 = load i32, i32* %56, align 4
  %34333 = icmp eq i32 %34178, %34332
  %34334 = or i1 %34331, %34333
  %34335 = load i32, i32* %57, align 4
  %34336 = icmp eq i32 %34178, %34335
  %34337 = or i1 %34334, %34336
  %34338 = load i32, i32* %58, align 4
  %34339 = icmp eq i32 %34178, %34338
  %34340 = or i1 %34337, %34339
  %34341 = load i32, i32* %59, align 4
  %34342 = icmp eq i32 %34178, %34341
  %34343 = or i1 %34340, %34342
  %34344 = load i32, i32* %60, align 4
  %34345 = icmp eq i32 %34178, %34344
  %34346 = or i1 %34343, %34345
  %34347 = load i32, i32* %61, align 4
  %34348 = icmp eq i32 %34178, %34347
  %34349 = or i1 %34346, %34348
  %34350 = load i32, i32* %62, align 4
  %34351 = icmp eq i32 %34178, %34350
  %34352 = or i1 %34349, %34351
  %34353 = getelementptr i8, i8 addrspace(1)* %4, i32 126
  %34354 = zext i1 %34352 to i8
  store i8 %34354, i8 addrspace(1)* %34353, align 1, !nosanitize !3
  %34355 = load i256, i256* %34177, align 4
  %34356 = trunc i256 4443 to i64
  %34357 = load i64, i64* %STACK_DEP_PTR, align 4
  %34358 = add i64 %34357, 1
  store i64 %34358, i64* %STACK_DEP_PTR, align 4
  %34359 = load i64, i64* %STACK_DEP_PTR, align 4
  %34360 = getelementptr i256, i256* %STACK, i64 %34359
  store i256 %33962, i256* %34360, align 4
  %34361 = load i64, i64* %STACK_DEP_PTR, align 4
  %34362 = add i64 %34361, 1
  store i64 %34362, i64* %STACK_DEP_PTR, align 4
  %34363 = load i64, i64* %STACK_DEP_PTR, align 4
  %34364 = getelementptr i256, i256* %STACK, i64 %34363
  store i256 0, i256* %34364, align 4
  %34365 = load i64, i64* %STACK_DEP_PTR, align 4
  %34366 = add i64 %34365, 1
  store i64 %34366, i64* %STACK_DEP_PTR, align 4
  %34367 = load i64, i64* %STACK_DEP_PTR, align 4
  %34368 = getelementptr i256, i256* %STACK, i64 %34367
  store i256 %34355, i256* %34368, align 4
  %34369 = load i64, i64* %STACK_DEP_PTR, align 4
  %34370 = add i64 %34369, 1
  store i64 %34370, i64* %STACK_DEP_PTR, align 4
  %34371 = load i64, i64* %STACK_DEP_PTR, align 4
  %34372 = getelementptr i256, i256* %STACK, i64 %34371
  store i256 0, i256* %34372, align 4
  %34373 = load i64, i64* %STACK_DEP_PTR, align 4
  %34374 = add i64 %34373, 1
  store i64 %34374, i64* %STACK_DEP_PTR, align 4
  %34375 = load i64, i64* %STACK_DEP_PTR, align 4
  %34376 = getelementptr i256, i256* %STACK, i64 %34375
  store i256 0, i256* %34376, align 4
  %34377 = load i64, i64* %STACK_DEP_PTR, align 4
  %34378 = add i64 %34377, 1
  store i64 %34378, i64* %STACK_DEP_PTR, align 4
  %34379 = load i64, i64* %STACK_DEP_PTR, align 4
  %34380 = getelementptr i256, i256* %STACK, i64 %34379
  store i256 11521, i256* %34380, align 4
  %34381 = load i64, i64* %STACK_DEP_PTR, align 4
  %34382 = add i64 %34381, 1
  store i64 %34382, i64* %STACK_DEP_PTR, align 4
  %34383 = load i64, i64* %STACK_DEP_PTR, align 4
  %34384 = getelementptr i256, i256* %STACK, i64 %34383
  store i256 %33962, i256* %34384, align 4
  br label %.4443, !EVMBB !4

.11521:                                           ; preds = %JumpTable
  %34385 = load i64, i64* %remaing_gas, align 4
  %34386 = icmp ugt i64 648, %34385
  br i1 %34386, label %Abort, label %34387

34387:                                            ; preds = %.11521
  %34388 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34389 = xor i32 %34388, 137
  %34390 = urem i32 %34389, 4096
  %34391 = getelementptr i8, i8 addrspace(1)* %4, i32 %34390
  %34392 = load i8, i8 addrspace(1)* %34391, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34391, align 1, !nosanitize !3
  store i32 68, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34393 = sub i64 %34385, 648
  store i64 %34393, i64* %remaing_gas, align 4
  %34394 = load i64, i64* %STACK_DEP_PTR, align 4
  %34395 = getelementptr i256, i256* %STACK, i64 %34394
  %34396 = load i256, i256* %34395, align 4
  %34397 = load i64, i64* %STACK_DEP_PTR, align 4
  %34398 = sub i64 %34397, 1
  store i64 %34398, i64* %STACK_DEP_PTR, align 4
  %34399 = load i64, i64* %STACK_DEP_PTR, align 4
  %34400 = getelementptr i256, i256* %STACK, i64 %34399
  %34401 = load i256, i256* %34400, align 4
  %34402 = load i64, i64* %STACK_DEP_PTR, align 4
  %34403 = sub i64 %34402, 1
  store i64 %34403, i64* %STACK_DEP_PTR, align 4
  %34404 = load i64, i64* %STACK_DEP_PTR, align 4
  %34405 = getelementptr i256, i256* %STACK, i64 %34404
  %34406 = load i256, i256* %34405, align 4
  %34407 = load i64, i64* %STACK_DEP_PTR, align 4
  %34408 = sub i64 %34407, 1
  store i64 %34408, i64* %STACK_DEP_PTR, align 4
  %34409 = load i64, i64* %STACK_DEP_PTR, align 4
  %34410 = getelementptr i256, i256* %STACK, i64 %34409
  %34411 = load i256, i256* %34410, align 4
  %34412 = load i64, i64* %STACK_DEP_PTR, align 4
  %34413 = sub i64 %34412, 1
  store i64 %34413, i64* %STACK_DEP_PTR, align 4
  %34414 = load i64, i64* %STACK_DEP_PTR, align 4
  %34415 = getelementptr i256, i256* %STACK, i64 %34414
  %34416 = load i256, i256* %34415, align 4
  %34417 = load i64, i64* %STACK_DEP_PTR, align 4
  %34418 = sub i64 %34417, 1
  store i64 %34418, i64* %STACK_DEP_PTR, align 4
  %34419 = load i64, i64* %STACK_DEP_PTR, align 4
  %34420 = getelementptr i256, i256* %STACK, i64 %34419
  %34421 = load i256, i256* %34420, align 4
  %34422 = load i64, i64* %STACK_DEP_PTR, align 4
  %34423 = sub i64 %34422, 1
  store i64 %34423, i64* %STACK_DEP_PTR, align 4
  %34424 = trunc i256 4726 to i64
  %34425 = load i64, i64* %STACK_DEP_PTR, align 4
  %34426 = add i64 %34425, 1
  store i64 %34426, i64* %STACK_DEP_PTR, align 4
  %34427 = load i64, i64* %STACK_DEP_PTR, align 4
  %34428 = getelementptr i256, i256* %STACK, i64 %34427
  store i256 %34421, i256* %34428, align 4
  %34429 = load i64, i64* %STACK_DEP_PTR, align 4
  %34430 = add i64 %34429, 1
  store i64 %34430, i64* %STACK_DEP_PTR, align 4
  %34431 = load i64, i64* %STACK_DEP_PTR, align 4
  %34432 = getelementptr i256, i256* %STACK, i64 %34431
  store i256 %34416, i256* %34432, align 4
  %34433 = load i64, i64* %STACK_DEP_PTR, align 4
  %34434 = add i64 %34433, 1
  store i64 %34434, i64* %STACK_DEP_PTR, align 4
  %34435 = load i64, i64* %STACK_DEP_PTR, align 4
  %34436 = getelementptr i256, i256* %STACK, i64 %34435
  store i256 %34411, i256* %34436, align 4
  %34437 = load i64, i64* %STACK_DEP_PTR, align 4
  %34438 = add i64 %34437, 1
  store i64 %34438, i64* %STACK_DEP_PTR, align 4
  %34439 = load i64, i64* %STACK_DEP_PTR, align 4
  %34440 = getelementptr i256, i256* %STACK, i64 %34439
  store i256 %34396, i256* %34440, align 4
  %34441 = load i64, i64* %STACK_DEP_PTR, align 4
  %34442 = add i64 %34441, 1
  store i64 %34442, i64* %STACK_DEP_PTR, align 4
  %34443 = load i64, i64* %STACK_DEP_PTR, align 4
  %34444 = getelementptr i256, i256* %STACK, i64 %34443
  store i256 %34401, i256* %34444, align 4
  %34445 = load i64, i64* %STACK_DEP_PTR, align 4
  %34446 = add i64 %34445, 1
  store i64 %34446, i64* %STACK_DEP_PTR, align 4
  %34447 = load i64, i64* %STACK_DEP_PTR, align 4
  %34448 = getelementptr i256, i256* %STACK, i64 %34447
  store i256 11532, i256* %34448, align 4
  %34449 = load i64, i64* %STACK_DEP_PTR, align 4
  %34450 = add i64 %34449, 1
  store i64 %34450, i64* %STACK_DEP_PTR, align 4
  %34451 = load i64, i64* %STACK_DEP_PTR, align 4
  %34452 = getelementptr i256, i256* %STACK, i64 %34451
  store i256 %34421, i256* %34452, align 4
  br label %.4726, !EVMBB !4

.11532:                                           ; preds = %JumpTable
  %34453 = load i64, i64* %remaing_gas, align 4
  %34454 = icmp ugt i64 440, %34453
  br i1 %34454, label %Abort, label %34455

34455:                                            ; preds = %.11532
  %34456 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34457 = xor i32 %34456, 1870
  %34458 = urem i32 %34457, 4096
  %34459 = getelementptr i8, i8 addrspace(1)* %4, i32 %34458
  %34460 = load i8, i8 addrspace(1)* %34459, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34459, align 1, !nosanitize !3
  store i32 935, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34461 = sub i64 %34453, 440
  store i64 %34461, i64* %remaing_gas, align 4
  %34462 = load i64, i64* %STACK_DEP_PTR, align 4
  %34463 = getelementptr i256, i256* %STACK, i64 %34462
  %34464 = load i256, i256* %34463, align 4
  %34465 = load i64, i64* %STACK_DEP_PTR, align 4
  %34466 = sub i64 %34465, 1
  store i64 %34466, i64* %STACK_DEP_PTR, align 4
  %34467 = load i64, i64* %STACK_DEP_PTR, align 4
  %34468 = getelementptr i256, i256* %STACK, i64 %34467
  %34469 = load i256, i256* %34468, align 4
  %34470 = load i64, i64* %STACK_DEP_PTR, align 4
  %34471 = sub i64 %34470, 1
  store i64 %34471, i64* %STACK_DEP_PTR, align 4
  %34472 = load i64, i64* %STACK_DEP_PTR, align 4
  %34473 = getelementptr i256, i256* %STACK, i64 %34472
  %34474 = load i256, i256* %34473, align 4
  %34475 = load i64, i64* %STACK_DEP_PTR, align 4
  %34476 = sub i64 %34475, 1
  store i64 %34476, i64* %STACK_DEP_PTR, align 4
  %34477 = load i64, i64* %STACK_DEP_PTR, align 4
  %34478 = getelementptr i256, i256* %STACK, i64 %34477
  %34479 = load i256, i256* %34478, align 4
  %34480 = load i64, i64* %STACK_DEP_PTR, align 4
  %34481 = sub i64 %34480, 1
  store i64 %34481, i64* %STACK_DEP_PTR, align 4
  %34482 = add i256 %34479, %34474, !pc !504, !intsan !10
  %34483 = icmp ult i256 %34482, %34474
  %34484 = trunc i256 11551 to i64
  %jump.check48 = icmp ne i1 %34483, false
  %34485 = load i64, i64* %STACK_DEP_PTR, align 4
  %34486 = add i64 %34485, 1
  store i64 %34486, i64* %STACK_DEP_PTR, align 4
  %34487 = load i64, i64* %STACK_DEP_PTR, align 4
  %34488 = getelementptr i256, i256* %STACK, i64 %34487
  store i256 %34479, i256* %34488, align 4
  %34489 = load i64, i64* %STACK_DEP_PTR, align 4
  %34490 = add i64 %34489, 1
  store i64 %34490, i64* %STACK_DEP_PTR, align 4
  %34491 = load i64, i64* %STACK_DEP_PTR, align 4
  %34492 = getelementptr i256, i256* %STACK, i64 %34491
  store i256 %34474, i256* %34492, align 4
  %34493 = load i64, i64* %STACK_DEP_PTR, align 4
  %34494 = add i64 %34493, 1
  store i64 %34494, i64* %STACK_DEP_PTR, align 4
  %34495 = load i64, i64* %STACK_DEP_PTR, align 4
  %34496 = getelementptr i256, i256* %STACK, i64 %34495
  store i256 %34464, i256* %34496, align 4
  %34497 = load i64, i64* %STACK_DEP_PTR, align 4
  %34498 = add i64 %34497, 1
  store i64 %34498, i64* %STACK_DEP_PTR, align 4
  %34499 = zext i1 %34483 to i256
  %34500 = load i64, i64* %STACK_DEP_PTR, align 4
  %34501 = getelementptr i256, i256* %STACK, i64 %34500
  store i256 %34499, i256* %34501, align 4
  br i1 %jump.check48, label %.11551, label %.11545, !EVMBB !4

.11545:                                           ; preds = %34455
  %34502 = load i64, i64* %STACK_DEP_PTR, align 4
  %34503 = sub i64 %34502, 4
  store i64 %34503, i64* %STACK_DEP_PTR, align 4
  %34504 = add i256 %34479, %34474, !pc !505, !intsan !10
  %34505 = icmp ult i256 %34504, %34479
  %34506 = load i64, i64* %STACK_DEP_PTR, align 4
  %34507 = add i64 %34506, 1
  store i64 %34507, i64* %STACK_DEP_PTR, align 4
  %34508 = load i64, i64* %STACK_DEP_PTR, align 4
  %34509 = getelementptr i256, i256* %STACK, i64 %34508
  store i256 %34479, i256* %34509, align 4
  %34510 = load i64, i64* %STACK_DEP_PTR, align 4
  %34511 = add i64 %34510, 1
  store i64 %34511, i64* %STACK_DEP_PTR, align 4
  %34512 = load i64, i64* %STACK_DEP_PTR, align 4
  %34513 = getelementptr i256, i256* %STACK, i64 %34512
  store i256 %34474, i256* %34513, align 4
  %34514 = load i64, i64* %STACK_DEP_PTR, align 4
  %34515 = add i64 %34514, 1
  store i64 %34515, i64* %STACK_DEP_PTR, align 4
  %34516 = load i64, i64* %STACK_DEP_PTR, align 4
  %34517 = getelementptr i256, i256* %STACK, i64 %34516
  store i256 %34464, i256* %34517, align 4
  %34518 = load i64, i64* %STACK_DEP_PTR, align 4
  %34519 = add i64 %34518, 1
  store i64 %34519, i64* %STACK_DEP_PTR, align 4
  %34520 = zext i1 %34505 to i256
  %34521 = load i64, i64* %STACK_DEP_PTR, align 4
  %34522 = getelementptr i256, i256* %STACK, i64 %34521
  store i256 %34520, i256* %34522, align 4
  br label %.11551

.11551:                                           ; preds = %.11545, %34455, %JumpTable
  %34523 = load i64, i64* %remaing_gas, align 4
  %34524 = icmp ugt i64 128, %34523
  br i1 %34524, label %Abort, label %34525

34525:                                            ; preds = %.11551
  %34526 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34527 = xor i32 %34526, 2647
  %34528 = urem i32 %34527, 4096
  %34529 = getelementptr i8, i8 addrspace(1)* %4, i32 %34528
  %34530 = load i8, i8 addrspace(1)* %34529, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34529, align 1, !nosanitize !3
  store i32 1323, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34531 = sub i64 %34523, 128
  store i64 %34531, i64* %remaing_gas, align 4
  %34532 = load i64, i64* %STACK_DEP_PTR, align 4
  %34533 = getelementptr i256, i256* %STACK, i64 %34532
  %34534 = load i256, i256* %34533, align 4
  %34535 = load i64, i64* %STACK_DEP_PTR, align 4
  %34536 = sub i64 %34535, 1
  store i64 %34536, i64* %STACK_DEP_PTR, align 4
  %34537 = trunc i256 11563 to i64
  %jump.check55 = icmp ne i256 %34534, 0
  %34538 = load i64, i64* %STACK_DEP_PTR, align 4
  %34539 = add i64 %34538, 1
  store i64 %34539, i64* %STACK_DEP_PTR, align 4
  %34540 = load i64, i64* %STACK_DEP_PTR, align 4
  %34541 = getelementptr i256, i256* %STACK, i64 %34540
  store i256 %34534, i256* %34541, align 4
  br i1 %jump.check55, label %.11563, label %.11557, !EVMBB !4

.11557:                                           ; preds = %34525
  %34542 = load i64, i64* %STACK_DEP_PTR, align 4
  %34543 = sub i64 %34542, 1
  store i64 %34543, i64* %STACK_DEP_PTR, align 4
  %34544 = load i64, i64* %STACK_DEP_PTR, align 4
  %34545 = getelementptr i256, i256* %STACK, i64 %34544
  %34546 = load i256, i256* %34545, align 4
  %34547 = load i64, i64* %STACK_DEP_PTR, align 4
  %34548 = sub i64 %34547, 1
  store i64 %34548, i64* %STACK_DEP_PTR, align 4
  %34549 = load i64, i64* %STACK_DEP_PTR, align 4
  %34550 = getelementptr i256, i256* %STACK, i64 %34549
  %34551 = load i256, i256* %34550, align 4
  %34552 = load i64, i64* %STACK_DEP_PTR, align 4
  %34553 = sub i64 %34552, 1
  store i64 %34553, i64* %STACK_DEP_PTR, align 4
  %34554 = load i64, i64* %STACK_DEP_PTR, align 4
  %34555 = getelementptr i256, i256* %STACK, i64 %34554
  %34556 = load i256, i256* %34555, align 4
  %34557 = load i64, i64* %STACK_DEP_PTR, align 4
  %34558 = sub i64 %34557, 1
  store i64 %34558, i64* %STACK_DEP_PTR, align 4
  %34559 = add i256 %34556, %34551, !pc !506, !intsan !10
  %34560 = icmp ult i256 %34559, %34546
  %34561 = load i64, i64* %STACK_DEP_PTR, align 4
  %34562 = add i64 %34561, 1
  store i64 %34562, i64* %STACK_DEP_PTR, align 4
  %34563 = load i64, i64* %STACK_DEP_PTR, align 4
  %34564 = getelementptr i256, i256* %STACK, i64 %34563
  store i256 %34556, i256* %34564, align 4
  %34565 = load i64, i64* %STACK_DEP_PTR, align 4
  %34566 = add i64 %34565, 1
  store i64 %34566, i64* %STACK_DEP_PTR, align 4
  %34567 = load i64, i64* %STACK_DEP_PTR, align 4
  %34568 = getelementptr i256, i256* %STACK, i64 %34567
  store i256 %34551, i256* %34568, align 4
  %34569 = load i64, i64* %STACK_DEP_PTR, align 4
  %34570 = add i64 %34569, 1
  store i64 %34570, i64* %STACK_DEP_PTR, align 4
  %34571 = load i64, i64* %STACK_DEP_PTR, align 4
  %34572 = getelementptr i256, i256* %STACK, i64 %34571
  store i256 %34546, i256* %34572, align 4
  %34573 = load i64, i64* %STACK_DEP_PTR, align 4
  %34574 = add i64 %34573, 1
  store i64 %34574, i64* %STACK_DEP_PTR, align 4
  %34575 = zext i1 %34560 to i256
  %34576 = load i64, i64* %STACK_DEP_PTR, align 4
  %34577 = getelementptr i256, i256* %STACK, i64 %34576
  store i256 %34575, i256* %34577, align 4
  br label %.11563

.11563:                                           ; preds = %.11557, %34525, %JumpTable
  %34578 = load i64, i64* %remaing_gas, align 4
  %34579 = icmp ugt i64 88, %34578
  br i1 %34579, label %Abort, label %34580

34580:                                            ; preds = %.11563
  %34581 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34582 = xor i32 %34581, 3417
  %34583 = urem i32 %34582, 4096
  %34584 = getelementptr i8, i8 addrspace(1)* %4, i32 %34583
  %34585 = load i8, i8 addrspace(1)* %34584, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34584, align 1, !nosanitize !3
  store i32 1708, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34586 = sub i64 %34578, 88
  store i64 %34586, i64* %remaing_gas, align 4
  %34587 = load i64, i64* %STACK_DEP_PTR, align 4
  %34588 = getelementptr i256, i256* %STACK, i64 %34587
  %34589 = load i256, i256* %34588, align 4
  %34590 = load i64, i64* %STACK_DEP_PTR, align 4
  %34591 = sub i64 %34590, 1
  store i64 %34591, i64* %STACK_DEP_PTR, align 4
  %34592 = icmp eq i256 %34589, 0
  %34593 = trunc i256 11577 to i64
  %jump.check60 = icmp ne i1 %34592, false
  br i1 %jump.check60, label %.11577, label %.11569, !EVMBB !4

.11569:                                           ; preds = %34580
  %34594 = load i64, i64* %remaing_gas, align 4
  %34595 = icmp ugt i64 408, %34594
  br i1 %34595, label %Abort, label %34596

34596:                                            ; preds = %.11569
  %34597 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34598 = xor i32 %34597, 1491
  %34599 = urem i32 %34598, 4096
  %34600 = getelementptr i8, i8 addrspace(1)* %4, i32 %34599
  %34601 = load i8, i8 addrspace(1)* %34600, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34600, align 1, !nosanitize !3
  store i32 745, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34602 = sub i64 %34594, 408
  store i64 %34602, i64* %remaing_gas, align 4
  %34603 = load i64, i64* %STACK_DEP_PTR, align 4
  %34604 = getelementptr i256, i256* %STACK, i64 %34603
  %34605 = load i256, i256* %34604, align 4
  %34606 = load i64, i64* %STACK_DEP_PTR, align 4
  %34607 = sub i64 %34606, 1
  store i64 %34607, i64* %STACK_DEP_PTR, align 4
  %34608 = load i64, i64* %STACK_DEP_PTR, align 4
  %34609 = getelementptr i256, i256* %STACK, i64 %34608
  %34610 = load i256, i256* %34609, align 4
  %34611 = load i64, i64* %STACK_DEP_PTR, align 4
  %34612 = sub i64 %34611, 1
  store i64 %34612, i64* %STACK_DEP_PTR, align 4
  %34613 = load i64, i64* %STACK_DEP_PTR, align 4
  %34614 = getelementptr i256, i256* %STACK, i64 %34613
  %34615 = load i256, i256* %34614, align 4
  %34616 = load i64, i64* %STACK_DEP_PTR, align 4
  %34617 = sub i64 %34616, 1
  store i64 %34617, i64* %STACK_DEP_PTR, align 4
  %34618 = load i64, i64* %STACK_DEP_PTR, align 4
  %34619 = getelementptr i256, i256* %STACK, i64 %34618
  %34620 = load i256, i256* %34619, align 4
  %34621 = load i64, i64* %STACK_DEP_PTR, align 4
  %34622 = sub i64 %34621, 1
  store i64 %34622, i64* %STACK_DEP_PTR, align 4
  %34623 = trunc i256 11585 to i64
  %34624 = load i64, i64* %STACK_DEP_PTR, align 4
  %34625 = add i64 %34624, 1
  store i64 %34625, i64* %STACK_DEP_PTR, align 4
  %34626 = load i64, i64* %STACK_DEP_PTR, align 4
  %34627 = getelementptr i256, i256* %STACK, i64 %34626
  store i256 0, i256* %34627, align 4
  %34628 = load i64, i64* %STACK_DEP_PTR, align 4
  %34629 = add i64 %34628, 1
  store i64 %34629, i64* %STACK_DEP_PTR, align 4
  %34630 = load i64, i64* %STACK_DEP_PTR, align 4
  %34631 = getelementptr i256, i256* %STACK, i64 %34630
  store i256 %34615, i256* %34631, align 4
  %34632 = load i64, i64* %STACK_DEP_PTR, align 4
  %34633 = add i64 %34632, 1
  store i64 %34633, i64* %STACK_DEP_PTR, align 4
  %34634 = load i64, i64* %STACK_DEP_PTR, align 4
  %34635 = getelementptr i256, i256* %STACK, i64 %34634
  store i256 %34610, i256* %34635, align 4
  %34636 = load i64, i64* %STACK_DEP_PTR, align 4
  %34637 = add i64 %34636, 1
  store i64 %34637, i64* %STACK_DEP_PTR, align 4
  %34638 = load i64, i64* %STACK_DEP_PTR, align 4
  %34639 = getelementptr i256, i256* %STACK, i64 %34638
  store i256 %34605, i256* %34639, align 4
  br label %.11585, !EVMBB !4

.11577:                                           ; preds = %34580, %JumpTable
  %34640 = load i64, i64* %STACK_DEP_PTR, align 4
  %34641 = getelementptr i256, i256* %STACK, i64 %34640
  %34642 = load i256, i256* %34641, align 4
  %34643 = load i64, i64* %STACK_DEP_PTR, align 4
  %34644 = sub i64 %34643, 1
  store i64 %34644, i64* %STACK_DEP_PTR, align 4
  %34645 = load i64, i64* %STACK_DEP_PTR, align 4
  %34646 = getelementptr i256, i256* %STACK, i64 %34645
  %34647 = load i256, i256* %34646, align 4
  %34648 = load i64, i64* %STACK_DEP_PTR, align 4
  %34649 = sub i64 %34648, 1
  store i64 %34649, i64* %STACK_DEP_PTR, align 4
  %34650 = load i64, i64* %STACK_DEP_PTR, align 4
  %34651 = getelementptr i256, i256* %STACK, i64 %34650
  %34652 = load i256, i256* %34651, align 4
  %34653 = load i64, i64* %STACK_DEP_PTR, align 4
  %34654 = sub i64 %34653, 1
  store i64 %34654, i64* %STACK_DEP_PTR, align 4
  %34655 = load i64, i64* %STACK_DEP_PTR, align 4
  %34656 = getelementptr i256, i256* %STACK, i64 %34655
  %34657 = load i256, i256* %34656, align 4
  %34658 = load i64, i64* %STACK_DEP_PTR, align 4
  %34659 = sub i64 %34658, 1
  store i64 %34659, i64* %STACK_DEP_PTR, align 4
  %34660 = add i256 %34652, %34647, !pc !507, !intsan !10
  %34661 = sub i256 %34660, %34642, !pc !508, !intsan !8
  %34662 = load i64, i64* %STACK_DEP_PTR, align 4
  %34663 = add i64 %34662, 1
  store i64 %34663, i64* %STACK_DEP_PTR, align 4
  %34664 = load i64, i64* %STACK_DEP_PTR, align 4
  %34665 = getelementptr i256, i256* %STACK, i64 %34664
  store i256 %34661, i256* %34665, align 4
  %34666 = load i64, i64* %STACK_DEP_PTR, align 4
  %34667 = add i64 %34666, 1
  store i64 %34667, i64* %STACK_DEP_PTR, align 4
  %34668 = load i64, i64* %STACK_DEP_PTR, align 4
  %34669 = getelementptr i256, i256* %STACK, i64 %34668
  store i256 %34652, i256* %34669, align 4
  %34670 = load i64, i64* %STACK_DEP_PTR, align 4
  %34671 = add i64 %34670, 1
  store i64 %34671, i64* %STACK_DEP_PTR, align 4
  %34672 = load i64, i64* %STACK_DEP_PTR, align 4
  %34673 = getelementptr i256, i256* %STACK, i64 %34672
  store i256 %34647, i256* %34673, align 4
  %34674 = load i64, i64* %STACK_DEP_PTR, align 4
  %34675 = add i64 %34674, 1
  store i64 %34675, i64* %STACK_DEP_PTR, align 4
  %34676 = load i64, i64* %STACK_DEP_PTR, align 4
  %34677 = getelementptr i256, i256* %STACK, i64 %34676
  store i256 %34642, i256* %34677, align 4
  br label %.11585

.11585:                                           ; preds = %.11577, %34596, %JumpTable
  %34678 = load i64, i64* %remaing_gas, align 4
  %34679 = icmp ugt i64 368, %34678
  br i1 %34679, label %Abort, label %34680

34680:                                            ; preds = %.11585
  %34681 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34682 = xor i32 %34681, 81
  %34683 = urem i32 %34682, 4096
  %34684 = getelementptr i8, i8 addrspace(1)* %4, i32 %34683
  %34685 = load i8, i8 addrspace(1)* %34684, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34684, align 1, !nosanitize !3
  store i32 40, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34686 = sub i64 %34678, 368
  store i64 %34686, i64* %remaing_gas, align 4
  %34687 = load i64, i64* %STACK_DEP_PTR, align 4
  %34688 = getelementptr i256, i256* %STACK, i64 %34687
  %34689 = load i256, i256* %34688, align 4
  %34690 = load i64, i64* %STACK_DEP_PTR, align 4
  %34691 = sub i64 %34690, 1
  store i64 %34691, i64* %STACK_DEP_PTR, align 4
  %34692 = load i64, i64* %STACK_DEP_PTR, align 4
  %34693 = getelementptr i256, i256* %STACK, i64 %34692
  %34694 = load i256, i256* %34693, align 4
  %34695 = load i64, i64* %STACK_DEP_PTR, align 4
  %34696 = sub i64 %34695, 1
  store i64 %34696, i64* %STACK_DEP_PTR, align 4
  %34697 = load i64, i64* %STACK_DEP_PTR, align 4
  %34698 = getelementptr i256, i256* %STACK, i64 %34697
  %34699 = load i256, i256* %34698, align 4
  %34700 = load i64, i64* %STACK_DEP_PTR, align 4
  %34701 = sub i64 %34700, 1
  store i64 %34701, i64* %STACK_DEP_PTR, align 4
  %34702 = load i64, i64* %STACK_DEP_PTR, align 4
  %34703 = getelementptr i256, i256* %STACK, i64 %34702
  %34704 = load i256, i256* %34703, align 4
  %34705 = load i64, i64* %STACK_DEP_PTR, align 4
  %34706 = sub i64 %34705, 1
  store i64 %34706, i64* %STACK_DEP_PTR, align 4
  %34707 = load i64, i64* %STACK_DEP_PTR, align 4
  %34708 = getelementptr i256, i256* %STACK, i64 %34707
  %34709 = load i256, i256* %34708, align 4
  %34710 = load i64, i64* %STACK_DEP_PTR, align 4
  %34711 = sub i64 %34710, 1
  store i64 %34711, i64* %STACK_DEP_PTR, align 4
  %34712 = load i64, i64* %STACK_DEP_PTR, align 4
  %34713 = getelementptr i256, i256* %STACK, i64 %34712
  %34714 = load i256, i256* %34713, align 4
  %34715 = load i64, i64* %STACK_DEP_PTR, align 4
  %34716 = sub i64 %34715, 1
  store i64 %34716, i64* %STACK_DEP_PTR, align 4
  %34717 = trunc i256 %34714 to i64
  store i64 %34717, i64* %JMP_TARGET_PTR, align 4
  %34718 = load i64, i64* %STACK_DEP_PTR, align 4
  %34719 = add i64 %34718, 1
  store i64 %34719, i64* %STACK_DEP_PTR, align 4
  %34720 = load i64, i64* %STACK_DEP_PTR, align 4
  %34721 = getelementptr i256, i256* %STACK, i64 %34720
  store i256 %34704, i256* %34721, align 4
  br label %JumpTable, !EVMBB !4

.11593:                                           ; preds = %3812, %JumpTable
  %34722 = load i64, i64* %remaing_gas, align 4
  %34723 = icmp ugt i64 192, %34722
  br i1 %34723, label %Abort, label %34724

34724:                                            ; preds = %.11593
  %34725 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34726 = xor i32 %34725, 3501
  %34727 = urem i32 %34726, 4096
  %34728 = getelementptr i8, i8 addrspace(1)* %4, i32 %34727
  %34729 = load i8, i8 addrspace(1)* %34728, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34728, align 1, !nosanitize !3
  store i32 1750, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34730 = sub i64 %34722, 192
  store i64 %34730, i64* %remaing_gas, align 4
  %34731 = alloca i256, align 8
  store i256 8, i256* %34731, align 4
  %34732 = alloca i256, align 8
  call void @__device_sload(i256* %34731, i256* %34732)
  %34733 = call i32 @__hashword(i256* %34731)
  %34734 = load i32, i32* %5, align 4
  %34735 = icmp eq i32 %34733, %34734
  %34736 = or i1 false, %34735
  %34737 = load i32, i32* %6, align 4
  %34738 = icmp eq i32 %34733, %34737
  %34739 = or i1 %34736, %34738
  %34740 = load i32, i32* %7, align 4
  %34741 = icmp eq i32 %34733, %34740
  %34742 = or i1 %34739, %34741
  %34743 = load i32, i32* %8, align 4
  %34744 = icmp eq i32 %34733, %34743
  %34745 = or i1 %34742, %34744
  %34746 = load i32, i32* %9, align 4
  %34747 = icmp eq i32 %34733, %34746
  %34748 = or i1 %34745, %34747
  %34749 = load i32, i32* %10, align 4
  %34750 = icmp eq i32 %34733, %34749
  %34751 = or i1 %34748, %34750
  %34752 = load i32, i32* %11, align 4
  %34753 = icmp eq i32 %34733, %34752
  %34754 = or i1 %34751, %34753
  %34755 = load i32, i32* %12, align 4
  %34756 = icmp eq i32 %34733, %34755
  %34757 = or i1 %34754, %34756
  %34758 = load i32, i32* %13, align 4
  %34759 = icmp eq i32 %34733, %34758
  %34760 = or i1 %34757, %34759
  %34761 = load i32, i32* %14, align 4
  %34762 = icmp eq i32 %34733, %34761
  %34763 = or i1 %34760, %34762
  %34764 = load i32, i32* %15, align 4
  %34765 = icmp eq i32 %34733, %34764
  %34766 = or i1 %34763, %34765
  %34767 = load i32, i32* %16, align 4
  %34768 = icmp eq i32 %34733, %34767
  %34769 = or i1 %34766, %34768
  %34770 = load i32, i32* %17, align 4
  %34771 = icmp eq i32 %34733, %34770
  %34772 = or i1 %34769, %34771
  %34773 = load i32, i32* %18, align 4
  %34774 = icmp eq i32 %34733, %34773
  %34775 = or i1 %34772, %34774
  %34776 = load i32, i32* %19, align 4
  %34777 = icmp eq i32 %34733, %34776
  %34778 = or i1 %34775, %34777
  %34779 = load i32, i32* %20, align 4
  %34780 = icmp eq i32 %34733, %34779
  %34781 = or i1 %34778, %34780
  %34782 = load i32, i32* %21, align 4
  %34783 = icmp eq i32 %34733, %34782
  %34784 = or i1 %34781, %34783
  %34785 = load i32, i32* %22, align 4
  %34786 = icmp eq i32 %34733, %34785
  %34787 = or i1 %34784, %34786
  %34788 = load i32, i32* %23, align 4
  %34789 = icmp eq i32 %34733, %34788
  %34790 = or i1 %34787, %34789
  %34791 = load i32, i32* %24, align 4
  %34792 = icmp eq i32 %34733, %34791
  %34793 = or i1 %34790, %34792
  %34794 = load i32, i32* %25, align 4
  %34795 = icmp eq i32 %34733, %34794
  %34796 = or i1 %34793, %34795
  %34797 = load i32, i32* %26, align 4
  %34798 = icmp eq i32 %34733, %34797
  %34799 = or i1 %34796, %34798
  %34800 = load i32, i32* %27, align 4
  %34801 = icmp eq i32 %34733, %34800
  %34802 = or i1 %34799, %34801
  %34803 = load i32, i32* %28, align 4
  %34804 = icmp eq i32 %34733, %34803
  %34805 = or i1 %34802, %34804
  %34806 = load i32, i32* %29, align 4
  %34807 = icmp eq i32 %34733, %34806
  %34808 = or i1 %34805, %34807
  %34809 = load i32, i32* %30, align 4
  %34810 = icmp eq i32 %34733, %34809
  %34811 = or i1 %34808, %34810
  %34812 = load i32, i32* %31, align 4
  %34813 = icmp eq i32 %34733, %34812
  %34814 = or i1 %34811, %34813
  %34815 = load i32, i32* %32, align 4
  %34816 = icmp eq i32 %34733, %34815
  %34817 = or i1 %34814, %34816
  %34818 = load i32, i32* %33, align 4
  %34819 = icmp eq i32 %34733, %34818
  %34820 = or i1 %34817, %34819
  %34821 = load i32, i32* %34, align 4
  %34822 = icmp eq i32 %34733, %34821
  %34823 = or i1 %34820, %34822
  %34824 = load i32, i32* %35, align 4
  %34825 = icmp eq i32 %34733, %34824
  %34826 = or i1 %34823, %34825
  %34827 = load i32, i32* %36, align 4
  %34828 = icmp eq i32 %34733, %34827
  %34829 = or i1 %34826, %34828
  %34830 = load i32, i32* %37, align 4
  %34831 = icmp eq i32 %34733, %34830
  %34832 = or i1 %34829, %34831
  %34833 = load i32, i32* %38, align 4
  %34834 = icmp eq i32 %34733, %34833
  %34835 = or i1 %34832, %34834
  %34836 = load i32, i32* %39, align 4
  %34837 = icmp eq i32 %34733, %34836
  %34838 = or i1 %34835, %34837
  %34839 = load i32, i32* %40, align 4
  %34840 = icmp eq i32 %34733, %34839
  %34841 = or i1 %34838, %34840
  %34842 = load i32, i32* %41, align 4
  %34843 = icmp eq i32 %34733, %34842
  %34844 = or i1 %34841, %34843
  %34845 = load i32, i32* %42, align 4
  %34846 = icmp eq i32 %34733, %34845
  %34847 = or i1 %34844, %34846
  %34848 = load i32, i32* %43, align 4
  %34849 = icmp eq i32 %34733, %34848
  %34850 = or i1 %34847, %34849
  %34851 = load i32, i32* %44, align 4
  %34852 = icmp eq i32 %34733, %34851
  %34853 = or i1 %34850, %34852
  %34854 = load i32, i32* %45, align 4
  %34855 = icmp eq i32 %34733, %34854
  %34856 = or i1 %34853, %34855
  %34857 = load i32, i32* %46, align 4
  %34858 = icmp eq i32 %34733, %34857
  %34859 = or i1 %34856, %34858
  %34860 = load i32, i32* %47, align 4
  %34861 = icmp eq i32 %34733, %34860
  %34862 = or i1 %34859, %34861
  %34863 = load i32, i32* %48, align 4
  %34864 = icmp eq i32 %34733, %34863
  %34865 = or i1 %34862, %34864
  %34866 = load i32, i32* %49, align 4
  %34867 = icmp eq i32 %34733, %34866
  %34868 = or i1 %34865, %34867
  %34869 = load i32, i32* %50, align 4
  %34870 = icmp eq i32 %34733, %34869
  %34871 = or i1 %34868, %34870
  %34872 = load i32, i32* %51, align 4
  %34873 = icmp eq i32 %34733, %34872
  %34874 = or i1 %34871, %34873
  %34875 = load i32, i32* %52, align 4
  %34876 = icmp eq i32 %34733, %34875
  %34877 = or i1 %34874, %34876
  %34878 = load i32, i32* %53, align 4
  %34879 = icmp eq i32 %34733, %34878
  %34880 = or i1 %34877, %34879
  %34881 = load i32, i32* %54, align 4
  %34882 = icmp eq i32 %34733, %34881
  %34883 = or i1 %34880, %34882
  %34884 = load i32, i32* %55, align 4
  %34885 = icmp eq i32 %34733, %34884
  %34886 = or i1 %34883, %34885
  %34887 = load i32, i32* %56, align 4
  %34888 = icmp eq i32 %34733, %34887
  %34889 = or i1 %34886, %34888
  %34890 = load i32, i32* %57, align 4
  %34891 = icmp eq i32 %34733, %34890
  %34892 = or i1 %34889, %34891
  %34893 = load i32, i32* %58, align 4
  %34894 = icmp eq i32 %34733, %34893
  %34895 = or i1 %34892, %34894
  %34896 = load i32, i32* %59, align 4
  %34897 = icmp eq i32 %34733, %34896
  %34898 = or i1 %34895, %34897
  %34899 = load i32, i32* %60, align 4
  %34900 = icmp eq i32 %34733, %34899
  %34901 = or i1 %34898, %34900
  %34902 = load i32, i32* %61, align 4
  %34903 = icmp eq i32 %34733, %34902
  %34904 = or i1 %34901, %34903
  %34905 = load i32, i32* %62, align 4
  %34906 = icmp eq i32 %34733, %34905
  %34907 = or i1 %34904, %34906
  %34908 = getelementptr i8, i8 addrspace(1)* %4, i32 127
  %34909 = zext i1 %34907 to i8
  store i8 %34909, i8 addrspace(1)* %34908, align 1, !nosanitize !3
  %34910 = load i256, i256* %34732, align 4
  %34911 = alloca i256, align 8
  store i256 %34910, i256* %34911, align 4
  %34912 = alloca i256, align 8
  store i256 1461501637330902918203684832716283019655932542976, i256* %34912, align 4
  %34913 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %34911, i256* %34912, i256* %34913), !pc !509, !intsan !6
  %34914 = load i256, i256* %34913, align 4
  %34915 = and i256 255, %34914
  %34916 = icmp eq i256 %34915, 0
  %34917 = trunc i256 11621 to i64
  %jump.check173 = icmp ne i1 %34916, false
  %34918 = load i64, i64* %STACK_DEP_PTR, align 4
  %34919 = add i64 %34918, 1
  store i64 %34919, i64* %STACK_DEP_PTR, align 4
  %34920 = load i64, i64* %STACK_DEP_PTR, align 4
  %34921 = getelementptr i256, i256* %STACK, i64 %34920
  store i256 0, i256* %34921, align 4
  br i1 %jump.check173, label %.11621, label %.11617, !EVMBB !4

.11617:                                           ; preds = %34724
  %34922 = load i64, i64* %remaing_gas, align 4
  %34923 = icmp ugt i64 40, %34922
  br i1 %34923, label %Abort, label %34924

34924:                                            ; preds = %.11617
  %34925 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34926 = xor i32 %34925, 4012
  %34927 = urem i32 %34926, 4096
  %34928 = getelementptr i8, i8 addrspace(1)* %4, i32 %34927
  %34929 = load i8, i8 addrspace(1)* %34928, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34928, align 1, !nosanitize !3
  store i32 2006, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34930 = sub i64 %34922, 40
  store i64 %34930, i64* %remaing_gas, align 4
  %34931 = load i64, i64* %STACK_DEP_PTR, align 4
  %34932 = sub i64 %34931, 0
  store i64 %34932, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.11621:                                           ; preds = %34724, %JumpTable
  %34933 = load i64, i64* %remaing_gas, align 4
  %34934 = icmp ugt i64 56, %34933
  br i1 %34934, label %Abort, label %34935

34935:                                            ; preds = %.11621
  %34936 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34937 = xor i32 %34936, 1926
  %34938 = urem i32 %34937, 4096
  %34939 = getelementptr i8, i8 addrspace(1)* %4, i32 %34938
  %34940 = load i8, i8 addrspace(1)* %34939, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34939, align 1, !nosanitize !3
  store i32 963, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34941 = sub i64 %34933, 56
  store i64 %34941, i64* %remaing_gas, align 4
  %34942 = load i256, i256* %1, align 4
  %34943 = icmp eq i256 %34942, 0
  %34944 = icmp eq i1 %34943, false
  %34945 = trunc i256 11635 to i64
  %jump.check176 = icmp ne i1 %34944, false
  br i1 %jump.check176, label %.11635, label %.11631, !EVMBB !4

.11631:                                           ; preds = %34935
  %34946 = load i64, i64* %remaing_gas, align 4
  %34947 = icmp ugt i64 16, %34946
  br i1 %34947, label %Abort, label %34948

34948:                                            ; preds = %.11631
  %34949 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34950 = xor i32 %34949, 661
  %34951 = urem i32 %34950, 4096
  %34952 = getelementptr i8, i8 addrspace(1)* %4, i32 %34951
  %34953 = load i8, i8 addrspace(1)* %34952, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34952, align 1, !nosanitize !3
  store i32 330, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34954 = sub i64 %34946, 16
  store i64 %34954, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11635:                                           ; preds = %34935, %JumpTable
  %34955 = load i64, i64* %remaing_gas, align 4
  %34956 = icmp ugt i64 272, %34955
  br i1 %34956, label %Abort, label %34957

34957:                                            ; preds = %.11635
  %34958 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34959 = xor i32 %34958, 3200
  %34960 = urem i32 %34959, 4096
  %34961 = getelementptr i8, i8 addrspace(1)* %4, i32 %34960
  %34962 = load i8, i8 addrspace(1)* %34961, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %34961, align 1, !nosanitize !3
  store i32 1600, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %34963 = sub i64 %34955, 272
  store i64 %34963, i64* %remaing_gas, align 4
  %34964 = load i256, i256* %0, align 4
  %34965 = and i256 1461501637330902918203684832716283019655932542975, %34964
  %34966 = and i256 1461501637330902918203684832716283019655932542975, %34965
  %34967 = trunc i256 0 to i64
  %34968 = alloca i256, align 8
  store i256 %34966, i256* %34968, align 4
  %34969 = bitcast i256* %34968 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %34967, i8* %34969, i64 32)
  %34970 = add i256 32, 0, !pc !510, !intsan !10
  %34971 = trunc i256 %34970 to i64
  %34972 = alloca i256, align 8
  store i256 3, i256* %34972, align 4
  %34973 = bitcast i256* %34972 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %34971, i8* %34973, i64 32)
  %34974 = add i256 32, %34970, !pc !511, !intsan !10
  %34975 = trunc i256 0 to i32
  %34976 = trunc i256 %34974 to i32
  %34977 = getelementptr inbounds i8, i8* %MEMORY, i32 %34975
  %34978 = alloca i256, align 8
  %34979 = bitcast i256* %34978 to i8*
  call void @__device_sha3(i8* %34977, i32 %34976, i8* %34979)
  %34980 = load i256, i256* %34978, align 4
  %34981 = alloca i256, align 8
  store i256 %34980, i256* %34981, align 4
  %34982 = alloca i256, align 8
  call void @__device_sload(i256* %34981, i256* %34982)
  %34983 = call i32 @__hashword(i256* %34981)
  %34984 = load i32, i32* %5, align 4
  %34985 = icmp eq i32 %34983, %34984
  %34986 = or i1 false, %34985
  %34987 = load i32, i32* %6, align 4
  %34988 = icmp eq i32 %34983, %34987
  %34989 = or i1 %34986, %34988
  %34990 = load i32, i32* %7, align 4
  %34991 = icmp eq i32 %34983, %34990
  %34992 = or i1 %34989, %34991
  %34993 = load i32, i32* %8, align 4
  %34994 = icmp eq i32 %34983, %34993
  %34995 = or i1 %34992, %34994
  %34996 = load i32, i32* %9, align 4
  %34997 = icmp eq i32 %34983, %34996
  %34998 = or i1 %34995, %34997
  %34999 = load i32, i32* %10, align 4
  %35000 = icmp eq i32 %34983, %34999
  %35001 = or i1 %34998, %35000
  %35002 = load i32, i32* %11, align 4
  %35003 = icmp eq i32 %34983, %35002
  %35004 = or i1 %35001, %35003
  %35005 = load i32, i32* %12, align 4
  %35006 = icmp eq i32 %34983, %35005
  %35007 = or i1 %35004, %35006
  %35008 = load i32, i32* %13, align 4
  %35009 = icmp eq i32 %34983, %35008
  %35010 = or i1 %35007, %35009
  %35011 = load i32, i32* %14, align 4
  %35012 = icmp eq i32 %34983, %35011
  %35013 = or i1 %35010, %35012
  %35014 = load i32, i32* %15, align 4
  %35015 = icmp eq i32 %34983, %35014
  %35016 = or i1 %35013, %35015
  %35017 = load i32, i32* %16, align 4
  %35018 = icmp eq i32 %34983, %35017
  %35019 = or i1 %35016, %35018
  %35020 = load i32, i32* %17, align 4
  %35021 = icmp eq i32 %34983, %35020
  %35022 = or i1 %35019, %35021
  %35023 = load i32, i32* %18, align 4
  %35024 = icmp eq i32 %34983, %35023
  %35025 = or i1 %35022, %35024
  %35026 = load i32, i32* %19, align 4
  %35027 = icmp eq i32 %34983, %35026
  %35028 = or i1 %35025, %35027
  %35029 = load i32, i32* %20, align 4
  %35030 = icmp eq i32 %34983, %35029
  %35031 = or i1 %35028, %35030
  %35032 = load i32, i32* %21, align 4
  %35033 = icmp eq i32 %34983, %35032
  %35034 = or i1 %35031, %35033
  %35035 = load i32, i32* %22, align 4
  %35036 = icmp eq i32 %34983, %35035
  %35037 = or i1 %35034, %35036
  %35038 = load i32, i32* %23, align 4
  %35039 = icmp eq i32 %34983, %35038
  %35040 = or i1 %35037, %35039
  %35041 = load i32, i32* %24, align 4
  %35042 = icmp eq i32 %34983, %35041
  %35043 = or i1 %35040, %35042
  %35044 = load i32, i32* %25, align 4
  %35045 = icmp eq i32 %34983, %35044
  %35046 = or i1 %35043, %35045
  %35047 = load i32, i32* %26, align 4
  %35048 = icmp eq i32 %34983, %35047
  %35049 = or i1 %35046, %35048
  %35050 = load i32, i32* %27, align 4
  %35051 = icmp eq i32 %34983, %35050
  %35052 = or i1 %35049, %35051
  %35053 = load i32, i32* %28, align 4
  %35054 = icmp eq i32 %34983, %35053
  %35055 = or i1 %35052, %35054
  %35056 = load i32, i32* %29, align 4
  %35057 = icmp eq i32 %34983, %35056
  %35058 = or i1 %35055, %35057
  %35059 = load i32, i32* %30, align 4
  %35060 = icmp eq i32 %34983, %35059
  %35061 = or i1 %35058, %35060
  %35062 = load i32, i32* %31, align 4
  %35063 = icmp eq i32 %34983, %35062
  %35064 = or i1 %35061, %35063
  %35065 = load i32, i32* %32, align 4
  %35066 = icmp eq i32 %34983, %35065
  %35067 = or i1 %35064, %35066
  %35068 = load i32, i32* %33, align 4
  %35069 = icmp eq i32 %34983, %35068
  %35070 = or i1 %35067, %35069
  %35071 = load i32, i32* %34, align 4
  %35072 = icmp eq i32 %34983, %35071
  %35073 = or i1 %35070, %35072
  %35074 = load i32, i32* %35, align 4
  %35075 = icmp eq i32 %34983, %35074
  %35076 = or i1 %35073, %35075
  %35077 = load i32, i32* %36, align 4
  %35078 = icmp eq i32 %34983, %35077
  %35079 = or i1 %35076, %35078
  %35080 = load i32, i32* %37, align 4
  %35081 = icmp eq i32 %34983, %35080
  %35082 = or i1 %35079, %35081
  %35083 = load i32, i32* %38, align 4
  %35084 = icmp eq i32 %34983, %35083
  %35085 = or i1 %35082, %35084
  %35086 = load i32, i32* %39, align 4
  %35087 = icmp eq i32 %34983, %35086
  %35088 = or i1 %35085, %35087
  %35089 = load i32, i32* %40, align 4
  %35090 = icmp eq i32 %34983, %35089
  %35091 = or i1 %35088, %35090
  %35092 = load i32, i32* %41, align 4
  %35093 = icmp eq i32 %34983, %35092
  %35094 = or i1 %35091, %35093
  %35095 = load i32, i32* %42, align 4
  %35096 = icmp eq i32 %34983, %35095
  %35097 = or i1 %35094, %35096
  %35098 = load i32, i32* %43, align 4
  %35099 = icmp eq i32 %34983, %35098
  %35100 = or i1 %35097, %35099
  %35101 = load i32, i32* %44, align 4
  %35102 = icmp eq i32 %34983, %35101
  %35103 = or i1 %35100, %35102
  %35104 = load i32, i32* %45, align 4
  %35105 = icmp eq i32 %34983, %35104
  %35106 = or i1 %35103, %35105
  %35107 = load i32, i32* %46, align 4
  %35108 = icmp eq i32 %34983, %35107
  %35109 = or i1 %35106, %35108
  %35110 = load i32, i32* %47, align 4
  %35111 = icmp eq i32 %34983, %35110
  %35112 = or i1 %35109, %35111
  %35113 = load i32, i32* %48, align 4
  %35114 = icmp eq i32 %34983, %35113
  %35115 = or i1 %35112, %35114
  %35116 = load i32, i32* %49, align 4
  %35117 = icmp eq i32 %34983, %35116
  %35118 = or i1 %35115, %35117
  %35119 = load i32, i32* %50, align 4
  %35120 = icmp eq i32 %34983, %35119
  %35121 = or i1 %35118, %35120
  %35122 = load i32, i32* %51, align 4
  %35123 = icmp eq i32 %34983, %35122
  %35124 = or i1 %35121, %35123
  %35125 = load i32, i32* %52, align 4
  %35126 = icmp eq i32 %34983, %35125
  %35127 = or i1 %35124, %35126
  %35128 = load i32, i32* %53, align 4
  %35129 = icmp eq i32 %34983, %35128
  %35130 = or i1 %35127, %35129
  %35131 = load i32, i32* %54, align 4
  %35132 = icmp eq i32 %34983, %35131
  %35133 = or i1 %35130, %35132
  %35134 = load i32, i32* %55, align 4
  %35135 = icmp eq i32 %34983, %35134
  %35136 = or i1 %35133, %35135
  %35137 = load i32, i32* %56, align 4
  %35138 = icmp eq i32 %34983, %35137
  %35139 = or i1 %35136, %35138
  %35140 = load i32, i32* %57, align 4
  %35141 = icmp eq i32 %34983, %35140
  %35142 = or i1 %35139, %35141
  %35143 = load i32, i32* %58, align 4
  %35144 = icmp eq i32 %34983, %35143
  %35145 = or i1 %35142, %35144
  %35146 = load i32, i32* %59, align 4
  %35147 = icmp eq i32 %34983, %35146
  %35148 = or i1 %35145, %35147
  %35149 = load i32, i32* %60, align 4
  %35150 = icmp eq i32 %34983, %35149
  %35151 = or i1 %35148, %35150
  %35152 = load i32, i32* %61, align 4
  %35153 = icmp eq i32 %34983, %35152
  %35154 = or i1 %35151, %35153
  %35155 = load i32, i32* %62, align 4
  %35156 = icmp eq i32 %34983, %35155
  %35157 = or i1 %35154, %35156
  %35158 = getelementptr i8, i8 addrspace(1)* %4, i32 128
  %35159 = zext i1 %35157 to i8
  store i8 %35159, i8 addrspace(1)* %35158, align 1, !nosanitize !3
  %35160 = load i256, i256* %34982, align 4
  %35161 = icmp eq i256 %35160, 0
  %35162 = icmp eq i1 %35161, false
  %35163 = icmp eq i1 %35162, false
  %35164 = trunc i256 11713 to i64
  %jump.check179 = icmp ne i1 %35163, false
  br i1 %jump.check179, label %.11713, label %.11709, !EVMBB !4

.11709:                                           ; preds = %34957
  %35165 = load i64, i64* %remaing_gas, align 4
  %35166 = icmp ugt i64 16, %35165
  br i1 %35166, label %Abort, label %35167

35167:                                            ; preds = %.11709
  %35168 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35169 = xor i32 %35168, 2284
  %35170 = urem i32 %35169, 4096
  %35171 = getelementptr i8, i8 addrspace(1)* %4, i32 %35170
  %35172 = load i8, i8 addrspace(1)* %35171, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35171, align 1, !nosanitize !3
  store i32 1142, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35173 = sub i64 %35165, 16
  store i64 %35173, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11713:                                           ; preds = %34957, %JumpTable
  %35174 = load i64, i64* %remaing_gas, align 4
  %35175 = icmp ugt i64 72, %35174
  br i1 %35175, label %Abort, label %35176

35176:                                            ; preds = %.11713
  %35177 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35178 = xor i32 %35177, 3351
  %35179 = urem i32 %35178, 4096
  %35180 = getelementptr i8, i8 addrspace(1)* %4, i32 %35179
  %35181 = load i8, i8 addrspace(1)* %35180, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35180, align 1, !nosanitize !3
  store i32 1675, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35182 = sub i64 %35174, 72
  store i64 %35182, i64* %remaing_gas, align 4
  %35183 = trunc i256 8787 to i64
  %35184 = load i64, i64* %STACK_DEP_PTR, align 4
  %35185 = add i64 %35184, 1
  store i64 %35185, i64* %STACK_DEP_PTR, align 4
  %35186 = load i64, i64* %STACK_DEP_PTR, align 4
  %35187 = getelementptr i256, i256* %STACK, i64 %35186
  store i256 11721, i256* %35187, align 4
  br label %.8787, !EVMBB !4

.11721:                                           ; preds = %JumpTable
  %35188 = load i64, i64* %remaing_gas, align 4
  %35189 = icmp ugt i64 112, %35188
  br i1 %35189, label %Abort, label %35190

35190:                                            ; preds = %.11721
  %35191 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35192 = xor i32 %35191, 4068
  %35193 = urem i32 %35192, 4096
  %35194 = getelementptr i8, i8 addrspace(1)* %4, i32 %35193
  %35195 = load i8, i8 addrspace(1)* %35194, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35194, align 1, !nosanitize !3
  store i32 2034, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35196 = sub i64 %35188, 112
  store i64 %35196, i64* %remaing_gas, align 4
  %35197 = load i64, i64* %STACK_DEP_PTR, align 4
  %35198 = getelementptr i256, i256* %STACK, i64 %35197
  %35199 = load i256, i256* %35198, align 4
  %35200 = load i64, i64* %STACK_DEP_PTR, align 4
  %35201 = sub i64 %35200, 1
  store i64 %35201, i64* %STACK_DEP_PTR, align 4
  %35202 = load i256, i256* %1, align 4
  %35203 = icmp ugt i256 %35202, %35199
  %35204 = icmp eq i1 %35203, false
  %35205 = icmp eq i1 %35204, false
  %35206 = trunc i256 11734 to i64
  %jump.check202 = icmp ne i1 %35205, false
  br i1 %jump.check202, label %.11734, label %.11730, !EVMBB !4

.11730:                                           ; preds = %35190
  %35207 = load i64, i64* %remaing_gas, align 4
  %35208 = icmp ugt i64 16, %35207
  br i1 %35208, label %Abort, label %35209

35209:                                            ; preds = %.11730
  %35210 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35211 = xor i32 %35210, 2181
  %35212 = urem i32 %35211, 4096
  %35213 = getelementptr i8, i8 addrspace(1)* %4, i32 %35212
  %35214 = load i8, i8 addrspace(1)* %35213, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35213, align 1, !nosanitize !3
  store i32 1090, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35215 = sub i64 %35207, 16
  store i64 %35215, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11734:                                           ; preds = %35190, %JumpTable
  %35216 = load i64, i64* %remaing_gas, align 4
  %35217 = icmp ugt i64 72, %35216
  br i1 %35217, label %Abort, label %35218

35218:                                            ; preds = %.11734
  %35219 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35220 = xor i32 %35219, 1777
  %35221 = urem i32 %35220, 4096
  %35222 = getelementptr i8, i8 addrspace(1)* %4, i32 %35221
  %35223 = load i8, i8 addrspace(1)* %35222, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35222, align 1, !nosanitize !3
  store i32 888, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35224 = sub i64 %35216, 72
  store i64 %35224, i64* %remaing_gas, align 4
  %35225 = trunc i256 16448 to i64
  %35226 = load i64, i64* %STACK_DEP_PTR, align 4
  %35227 = add i64 %35226, 1
  store i64 %35227, i64* %STACK_DEP_PTR, align 4
  %35228 = load i64, i64* %STACK_DEP_PTR, align 4
  %35229 = getelementptr i256, i256* %STACK, i64 %35228
  store i256 11742, i256* %35229, align 4
  br label %.16448, !EVMBB !4

.11742:                                           ; preds = %JumpTable
  %35230 = load i64, i64* %remaing_gas, align 4
  %35231 = icmp ugt i64 88, %35230
  br i1 %35231, label %Abort, label %35232

35232:                                            ; preds = %.11742
  %35233 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35234 = xor i32 %35233, 2956
  %35235 = urem i32 %35234, 4096
  %35236 = getelementptr i8, i8 addrspace(1)* %4, i32 %35235
  %35237 = load i8, i8 addrspace(1)* %35236, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35236, align 1, !nosanitize !3
  store i32 1478, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35238 = sub i64 %35230, 88
  store i64 %35238, i64* %remaing_gas, align 4
  %35239 = alloca i256, align 8
  store i256 5, i256* %35239, align 4
  %35240 = alloca i256, align 8
  call void @__device_sload(i256* %35239, i256* %35240)
  %35241 = call i32 @__hashword(i256* %35239)
  %35242 = load i32, i32* %5, align 4
  %35243 = icmp eq i32 %35241, %35242
  %35244 = or i1 false, %35243
  %35245 = load i32, i32* %6, align 4
  %35246 = icmp eq i32 %35241, %35245
  %35247 = or i1 %35244, %35246
  %35248 = load i32, i32* %7, align 4
  %35249 = icmp eq i32 %35241, %35248
  %35250 = or i1 %35247, %35249
  %35251 = load i32, i32* %8, align 4
  %35252 = icmp eq i32 %35241, %35251
  %35253 = or i1 %35250, %35252
  %35254 = load i32, i32* %9, align 4
  %35255 = icmp eq i32 %35241, %35254
  %35256 = or i1 %35253, %35255
  %35257 = load i32, i32* %10, align 4
  %35258 = icmp eq i32 %35241, %35257
  %35259 = or i1 %35256, %35258
  %35260 = load i32, i32* %11, align 4
  %35261 = icmp eq i32 %35241, %35260
  %35262 = or i1 %35259, %35261
  %35263 = load i32, i32* %12, align 4
  %35264 = icmp eq i32 %35241, %35263
  %35265 = or i1 %35262, %35264
  %35266 = load i32, i32* %13, align 4
  %35267 = icmp eq i32 %35241, %35266
  %35268 = or i1 %35265, %35267
  %35269 = load i32, i32* %14, align 4
  %35270 = icmp eq i32 %35241, %35269
  %35271 = or i1 %35268, %35270
  %35272 = load i32, i32* %15, align 4
  %35273 = icmp eq i32 %35241, %35272
  %35274 = or i1 %35271, %35273
  %35275 = load i32, i32* %16, align 4
  %35276 = icmp eq i32 %35241, %35275
  %35277 = or i1 %35274, %35276
  %35278 = load i32, i32* %17, align 4
  %35279 = icmp eq i32 %35241, %35278
  %35280 = or i1 %35277, %35279
  %35281 = load i32, i32* %18, align 4
  %35282 = icmp eq i32 %35241, %35281
  %35283 = or i1 %35280, %35282
  %35284 = load i32, i32* %19, align 4
  %35285 = icmp eq i32 %35241, %35284
  %35286 = or i1 %35283, %35285
  %35287 = load i32, i32* %20, align 4
  %35288 = icmp eq i32 %35241, %35287
  %35289 = or i1 %35286, %35288
  %35290 = load i32, i32* %21, align 4
  %35291 = icmp eq i32 %35241, %35290
  %35292 = or i1 %35289, %35291
  %35293 = load i32, i32* %22, align 4
  %35294 = icmp eq i32 %35241, %35293
  %35295 = or i1 %35292, %35294
  %35296 = load i32, i32* %23, align 4
  %35297 = icmp eq i32 %35241, %35296
  %35298 = or i1 %35295, %35297
  %35299 = load i32, i32* %24, align 4
  %35300 = icmp eq i32 %35241, %35299
  %35301 = or i1 %35298, %35300
  %35302 = load i32, i32* %25, align 4
  %35303 = icmp eq i32 %35241, %35302
  %35304 = or i1 %35301, %35303
  %35305 = load i32, i32* %26, align 4
  %35306 = icmp eq i32 %35241, %35305
  %35307 = or i1 %35304, %35306
  %35308 = load i32, i32* %27, align 4
  %35309 = icmp eq i32 %35241, %35308
  %35310 = or i1 %35307, %35309
  %35311 = load i32, i32* %28, align 4
  %35312 = icmp eq i32 %35241, %35311
  %35313 = or i1 %35310, %35312
  %35314 = load i32, i32* %29, align 4
  %35315 = icmp eq i32 %35241, %35314
  %35316 = or i1 %35313, %35315
  %35317 = load i32, i32* %30, align 4
  %35318 = icmp eq i32 %35241, %35317
  %35319 = or i1 %35316, %35318
  %35320 = load i32, i32* %31, align 4
  %35321 = icmp eq i32 %35241, %35320
  %35322 = or i1 %35319, %35321
  %35323 = load i32, i32* %32, align 4
  %35324 = icmp eq i32 %35241, %35323
  %35325 = or i1 %35322, %35324
  %35326 = load i32, i32* %33, align 4
  %35327 = icmp eq i32 %35241, %35326
  %35328 = or i1 %35325, %35327
  %35329 = load i32, i32* %34, align 4
  %35330 = icmp eq i32 %35241, %35329
  %35331 = or i1 %35328, %35330
  %35332 = load i32, i32* %35, align 4
  %35333 = icmp eq i32 %35241, %35332
  %35334 = or i1 %35331, %35333
  %35335 = load i32, i32* %36, align 4
  %35336 = icmp eq i32 %35241, %35335
  %35337 = or i1 %35334, %35336
  %35338 = load i32, i32* %37, align 4
  %35339 = icmp eq i32 %35241, %35338
  %35340 = or i1 %35337, %35339
  %35341 = load i32, i32* %38, align 4
  %35342 = icmp eq i32 %35241, %35341
  %35343 = or i1 %35340, %35342
  %35344 = load i32, i32* %39, align 4
  %35345 = icmp eq i32 %35241, %35344
  %35346 = or i1 %35343, %35345
  %35347 = load i32, i32* %40, align 4
  %35348 = icmp eq i32 %35241, %35347
  %35349 = or i1 %35346, %35348
  %35350 = load i32, i32* %41, align 4
  %35351 = icmp eq i32 %35241, %35350
  %35352 = or i1 %35349, %35351
  %35353 = load i32, i32* %42, align 4
  %35354 = icmp eq i32 %35241, %35353
  %35355 = or i1 %35352, %35354
  %35356 = load i32, i32* %43, align 4
  %35357 = icmp eq i32 %35241, %35356
  %35358 = or i1 %35355, %35357
  %35359 = load i32, i32* %44, align 4
  %35360 = icmp eq i32 %35241, %35359
  %35361 = or i1 %35358, %35360
  %35362 = load i32, i32* %45, align 4
  %35363 = icmp eq i32 %35241, %35362
  %35364 = or i1 %35361, %35363
  %35365 = load i32, i32* %46, align 4
  %35366 = icmp eq i32 %35241, %35365
  %35367 = or i1 %35364, %35366
  %35368 = load i32, i32* %47, align 4
  %35369 = icmp eq i32 %35241, %35368
  %35370 = or i1 %35367, %35369
  %35371 = load i32, i32* %48, align 4
  %35372 = icmp eq i32 %35241, %35371
  %35373 = or i1 %35370, %35372
  %35374 = load i32, i32* %49, align 4
  %35375 = icmp eq i32 %35241, %35374
  %35376 = or i1 %35373, %35375
  %35377 = load i32, i32* %50, align 4
  %35378 = icmp eq i32 %35241, %35377
  %35379 = or i1 %35376, %35378
  %35380 = load i32, i32* %51, align 4
  %35381 = icmp eq i32 %35241, %35380
  %35382 = or i1 %35379, %35381
  %35383 = load i32, i32* %52, align 4
  %35384 = icmp eq i32 %35241, %35383
  %35385 = or i1 %35382, %35384
  %35386 = load i32, i32* %53, align 4
  %35387 = icmp eq i32 %35241, %35386
  %35388 = or i1 %35385, %35387
  %35389 = load i32, i32* %54, align 4
  %35390 = icmp eq i32 %35241, %35389
  %35391 = or i1 %35388, %35390
  %35392 = load i32, i32* %55, align 4
  %35393 = icmp eq i32 %35241, %35392
  %35394 = or i1 %35391, %35393
  %35395 = load i32, i32* %56, align 4
  %35396 = icmp eq i32 %35241, %35395
  %35397 = or i1 %35394, %35396
  %35398 = load i32, i32* %57, align 4
  %35399 = icmp eq i32 %35241, %35398
  %35400 = or i1 %35397, %35399
  %35401 = load i32, i32* %58, align 4
  %35402 = icmp eq i32 %35241, %35401
  %35403 = or i1 %35400, %35402
  %35404 = load i32, i32* %59, align 4
  %35405 = icmp eq i32 %35241, %35404
  %35406 = or i1 %35403, %35405
  %35407 = load i32, i32* %60, align 4
  %35408 = icmp eq i32 %35241, %35407
  %35409 = or i1 %35406, %35408
  %35410 = load i32, i32* %61, align 4
  %35411 = icmp eq i32 %35241, %35410
  %35412 = or i1 %35409, %35411
  %35413 = load i32, i32* %62, align 4
  %35414 = icmp eq i32 %35241, %35413
  %35415 = or i1 %35412, %35414
  %35416 = getelementptr i8, i8 addrspace(1)* %4, i32 129
  %35417 = zext i1 %35415 to i8
  store i8 %35417, i8 addrspace(1)* %35416, align 1, !nosanitize !3
  %35418 = load i256, i256* %35240, align 4
  %35419 = icmp eq i256 %35418, 10
  %35420 = icmp eq i1 %35419, false
  %35421 = trunc i256 11827 to i64
  %jump.check203 = icmp ne i1 %35420, false
  br i1 %jump.check203, label %.11827, label %.11754, !EVMBB !4

.11754:                                           ; preds = %35232
  %35422 = load i64, i64* %remaing_gas, align 4
  %35423 = icmp ugt i64 72, %35422
  br i1 %35423, label %Abort, label %35424

35424:                                            ; preds = %.11754
  %35425 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35426 = xor i32 %35425, 780
  %35427 = urem i32 %35426, 4096
  %35428 = getelementptr i8, i8 addrspace(1)* %4, i32 %35427
  %35429 = load i8, i8 addrspace(1)* %35428, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35428, align 1, !nosanitize !3
  store i32 390, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35430 = sub i64 %35422, 72
  store i64 %35430, i64* %remaing_gas, align 4
  %35431 = trunc i256 7136 to i64
  %35432 = load i64, i64* %STACK_DEP_PTR, align 4
  %35433 = add i64 %35432, 1
  store i64 %35433, i64* %STACK_DEP_PTR, align 4
  %35434 = load i64, i64* %STACK_DEP_PTR, align 4
  %35435 = getelementptr i256, i256* %STACK, i64 %35434
  store i256 11761, i256* %35435, align 4
  br label %.7136, !EVMBB !4

.11761:                                           ; preds = %JumpTable
  %35436 = load i64, i64* %remaing_gas, align 4
  %35437 = icmp ugt i64 528, %35436
  br i1 %35437, label %Abort, label %35438

35438:                                            ; preds = %.11761
  %35439 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35440 = xor i32 %35439, 1382
  %35441 = urem i32 %35440, 4096
  %35442 = getelementptr i8, i8 addrspace(1)* %4, i32 %35441
  %35443 = load i8, i8 addrspace(1)* %35442, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35442, align 1, !nosanitize !3
  store i32 691, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35444 = sub i64 %35436, 528
  store i64 %35444, i64* %remaing_gas, align 4
  %35445 = load i64, i64* %STACK_DEP_PTR, align 4
  %35446 = getelementptr i256, i256* %STACK, i64 %35445
  %35447 = load i256, i256* %35446, align 4
  %35448 = load i64, i64* %STACK_DEP_PTR, align 4
  %35449 = sub i64 %35448, 1
  store i64 %35449, i64* %STACK_DEP_PTR, align 4
  %35450 = load i64, i64* %STACK_DEP_PTR, align 4
  %35451 = getelementptr i256, i256* %STACK, i64 %35450
  %35452 = load i256, i256* %35451, align 4
  %35453 = load i64, i64* %STACK_DEP_PTR, align 4
  %35454 = sub i64 %35453, 1
  store i64 %35454, i64* %STACK_DEP_PTR, align 4
  %35455 = trunc i256 0 to i64
  %35456 = alloca i256, align 8
  store i256 %35447, i256* %35456, align 4
  %35457 = bitcast i256* %35456 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %35455, i8* %35457, i64 32)
  %35458 = add i256 32, 0, !pc !512, !intsan !10
  %35459 = trunc i256 %35458 to i64
  %35460 = alloca i256, align 8
  store i256 4, i256* %35460, align 4
  %35461 = bitcast i256* %35460 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %35459, i8* %35461, i64 32)
  %35462 = add i256 32, %35458, !pc !513, !intsan !10
  %35463 = trunc i256 0 to i32
  %35464 = trunc i256 %35462 to i32
  %35465 = getelementptr inbounds i8, i8* %MEMORY, i32 %35463
  %35466 = alloca i256, align 8
  %35467 = bitcast i256* %35466 to i8*
  call void @__device_sha3(i8* %35465, i32 %35464, i8* %35467)
  %35468 = load i256, i256* %35466, align 4
  %35469 = add i256 0, %35468, !pc !514, !intsan !10
  %35470 = alloca i256, align 8
  store i256 %35469, i256* %35470, align 4
  %35471 = alloca i256, align 8
  call void @__device_sload(i256* %35470, i256* %35471)
  %35472 = call i32 @__hashword(i256* %35470)
  %35473 = load i32, i32* %5, align 4
  %35474 = icmp eq i32 %35472, %35473
  %35475 = or i1 false, %35474
  %35476 = load i32, i32* %6, align 4
  %35477 = icmp eq i32 %35472, %35476
  %35478 = or i1 %35475, %35477
  %35479 = load i32, i32* %7, align 4
  %35480 = icmp eq i32 %35472, %35479
  %35481 = or i1 %35478, %35480
  %35482 = load i32, i32* %8, align 4
  %35483 = icmp eq i32 %35472, %35482
  %35484 = or i1 %35481, %35483
  %35485 = load i32, i32* %9, align 4
  %35486 = icmp eq i32 %35472, %35485
  %35487 = or i1 %35484, %35486
  %35488 = load i32, i32* %10, align 4
  %35489 = icmp eq i32 %35472, %35488
  %35490 = or i1 %35487, %35489
  %35491 = load i32, i32* %11, align 4
  %35492 = icmp eq i32 %35472, %35491
  %35493 = or i1 %35490, %35492
  %35494 = load i32, i32* %12, align 4
  %35495 = icmp eq i32 %35472, %35494
  %35496 = or i1 %35493, %35495
  %35497 = load i32, i32* %13, align 4
  %35498 = icmp eq i32 %35472, %35497
  %35499 = or i1 %35496, %35498
  %35500 = load i32, i32* %14, align 4
  %35501 = icmp eq i32 %35472, %35500
  %35502 = or i1 %35499, %35501
  %35503 = load i32, i32* %15, align 4
  %35504 = icmp eq i32 %35472, %35503
  %35505 = or i1 %35502, %35504
  %35506 = load i32, i32* %16, align 4
  %35507 = icmp eq i32 %35472, %35506
  %35508 = or i1 %35505, %35507
  %35509 = load i32, i32* %17, align 4
  %35510 = icmp eq i32 %35472, %35509
  %35511 = or i1 %35508, %35510
  %35512 = load i32, i32* %18, align 4
  %35513 = icmp eq i32 %35472, %35512
  %35514 = or i1 %35511, %35513
  %35515 = load i32, i32* %19, align 4
  %35516 = icmp eq i32 %35472, %35515
  %35517 = or i1 %35514, %35516
  %35518 = load i32, i32* %20, align 4
  %35519 = icmp eq i32 %35472, %35518
  %35520 = or i1 %35517, %35519
  %35521 = load i32, i32* %21, align 4
  %35522 = icmp eq i32 %35472, %35521
  %35523 = or i1 %35520, %35522
  %35524 = load i32, i32* %22, align 4
  %35525 = icmp eq i32 %35472, %35524
  %35526 = or i1 %35523, %35525
  %35527 = load i32, i32* %23, align 4
  %35528 = icmp eq i32 %35472, %35527
  %35529 = or i1 %35526, %35528
  %35530 = load i32, i32* %24, align 4
  %35531 = icmp eq i32 %35472, %35530
  %35532 = or i1 %35529, %35531
  %35533 = load i32, i32* %25, align 4
  %35534 = icmp eq i32 %35472, %35533
  %35535 = or i1 %35532, %35534
  %35536 = load i32, i32* %26, align 4
  %35537 = icmp eq i32 %35472, %35536
  %35538 = or i1 %35535, %35537
  %35539 = load i32, i32* %27, align 4
  %35540 = icmp eq i32 %35472, %35539
  %35541 = or i1 %35538, %35540
  %35542 = load i32, i32* %28, align 4
  %35543 = icmp eq i32 %35472, %35542
  %35544 = or i1 %35541, %35543
  %35545 = load i32, i32* %29, align 4
  %35546 = icmp eq i32 %35472, %35545
  %35547 = or i1 %35544, %35546
  %35548 = load i32, i32* %30, align 4
  %35549 = icmp eq i32 %35472, %35548
  %35550 = or i1 %35547, %35549
  %35551 = load i32, i32* %31, align 4
  %35552 = icmp eq i32 %35472, %35551
  %35553 = or i1 %35550, %35552
  %35554 = load i32, i32* %32, align 4
  %35555 = icmp eq i32 %35472, %35554
  %35556 = or i1 %35553, %35555
  %35557 = load i32, i32* %33, align 4
  %35558 = icmp eq i32 %35472, %35557
  %35559 = or i1 %35556, %35558
  %35560 = load i32, i32* %34, align 4
  %35561 = icmp eq i32 %35472, %35560
  %35562 = or i1 %35559, %35561
  %35563 = load i32, i32* %35, align 4
  %35564 = icmp eq i32 %35472, %35563
  %35565 = or i1 %35562, %35564
  %35566 = load i32, i32* %36, align 4
  %35567 = icmp eq i32 %35472, %35566
  %35568 = or i1 %35565, %35567
  %35569 = load i32, i32* %37, align 4
  %35570 = icmp eq i32 %35472, %35569
  %35571 = or i1 %35568, %35570
  %35572 = load i32, i32* %38, align 4
  %35573 = icmp eq i32 %35472, %35572
  %35574 = or i1 %35571, %35573
  %35575 = load i32, i32* %39, align 4
  %35576 = icmp eq i32 %35472, %35575
  %35577 = or i1 %35574, %35576
  %35578 = load i32, i32* %40, align 4
  %35579 = icmp eq i32 %35472, %35578
  %35580 = or i1 %35577, %35579
  %35581 = load i32, i32* %41, align 4
  %35582 = icmp eq i32 %35472, %35581
  %35583 = or i1 %35580, %35582
  %35584 = load i32, i32* %42, align 4
  %35585 = icmp eq i32 %35472, %35584
  %35586 = or i1 %35583, %35585
  %35587 = load i32, i32* %43, align 4
  %35588 = icmp eq i32 %35472, %35587
  %35589 = or i1 %35586, %35588
  %35590 = load i32, i32* %44, align 4
  %35591 = icmp eq i32 %35472, %35590
  %35592 = or i1 %35589, %35591
  %35593 = load i32, i32* %45, align 4
  %35594 = icmp eq i32 %35472, %35593
  %35595 = or i1 %35592, %35594
  %35596 = load i32, i32* %46, align 4
  %35597 = icmp eq i32 %35472, %35596
  %35598 = or i1 %35595, %35597
  %35599 = load i32, i32* %47, align 4
  %35600 = icmp eq i32 %35472, %35599
  %35601 = or i1 %35598, %35600
  %35602 = load i32, i32* %48, align 4
  %35603 = icmp eq i32 %35472, %35602
  %35604 = or i1 %35601, %35603
  %35605 = load i32, i32* %49, align 4
  %35606 = icmp eq i32 %35472, %35605
  %35607 = or i1 %35604, %35606
  %35608 = load i32, i32* %50, align 4
  %35609 = icmp eq i32 %35472, %35608
  %35610 = or i1 %35607, %35609
  %35611 = load i32, i32* %51, align 4
  %35612 = icmp eq i32 %35472, %35611
  %35613 = or i1 %35610, %35612
  %35614 = load i32, i32* %52, align 4
  %35615 = icmp eq i32 %35472, %35614
  %35616 = or i1 %35613, %35615
  %35617 = load i32, i32* %53, align 4
  %35618 = icmp eq i32 %35472, %35617
  %35619 = or i1 %35616, %35618
  %35620 = load i32, i32* %54, align 4
  %35621 = icmp eq i32 %35472, %35620
  %35622 = or i1 %35619, %35621
  %35623 = load i32, i32* %55, align 4
  %35624 = icmp eq i32 %35472, %35623
  %35625 = or i1 %35622, %35624
  %35626 = load i32, i32* %56, align 4
  %35627 = icmp eq i32 %35472, %35626
  %35628 = or i1 %35625, %35627
  %35629 = load i32, i32* %57, align 4
  %35630 = icmp eq i32 %35472, %35629
  %35631 = or i1 %35628, %35630
  %35632 = load i32, i32* %58, align 4
  %35633 = icmp eq i32 %35472, %35632
  %35634 = or i1 %35631, %35633
  %35635 = load i32, i32* %59, align 4
  %35636 = icmp eq i32 %35472, %35635
  %35637 = or i1 %35634, %35636
  %35638 = load i32, i32* %60, align 4
  %35639 = icmp eq i32 %35472, %35638
  %35640 = or i1 %35637, %35639
  %35641 = load i32, i32* %61, align 4
  %35642 = icmp eq i32 %35472, %35641
  %35643 = or i1 %35640, %35642
  %35644 = load i32, i32* %62, align 4
  %35645 = icmp eq i32 %35472, %35644
  %35646 = or i1 %35643, %35645
  %35647 = getelementptr i8, i8 addrspace(1)* %4, i32 130
  %35648 = zext i1 %35646 to i8
  store i8 %35648, i8 addrspace(1)* %35647, align 1, !nosanitize !3
  %35649 = load i256, i256* %35471, align 4
  %35650 = alloca i256, align 8
  store i256 %35649, i256* %35650, align 4
  %35651 = alloca i256, align 8
  store i256 1, i256* %35651, align 4
  %35652 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %35650, i256* %35651, i256* %35652), !pc !515, !intsan !6
  %35653 = load i256, i256* %35652, align 4
  %35654 = and i256 1461501637330902918203684832716283019655932542975, %35653
  %35655 = trunc i256 13000 to i64
  %35656 = load i64, i64* %STACK_DEP_PTR, align 4
  %35657 = add i64 %35656, 1
  store i64 %35657, i64* %STACK_DEP_PTR, align 4
  %35658 = load i64, i64* %STACK_DEP_PTR, align 4
  %35659 = getelementptr i256, i256* %STACK, i64 %35658
  store i256 %35447, i256* %35659, align 4
  %35660 = load i64, i64* %STACK_DEP_PTR, align 4
  %35661 = add i64 %35660, 1
  store i64 %35661, i64* %STACK_DEP_PTR, align 4
  %35662 = load i64, i64* %STACK_DEP_PTR, align 4
  %35663 = getelementptr i256, i256* %STACK, i64 %35662
  store i256 11826, i256* %35663, align 4
  %35664 = load i64, i64* %STACK_DEP_PTR, align 4
  %35665 = add i64 %35664, 1
  store i64 %35665, i64* %STACK_DEP_PTR, align 4
  %35666 = load i64, i64* %STACK_DEP_PTR, align 4
  %35667 = getelementptr i256, i256* %STACK, i64 %35666
  store i256 %35654, i256* %35667, align 4
  br label %.13000, !EVMBB !4

.11826:                                           ; preds = %JumpTable
  br label %.11827

.11827:                                           ; preds = %.11826, %35232, %JumpTable
  %35668 = load i64, i64* %remaing_gas, align 4
  %35669 = icmp ugt i64 248, %35668
  br i1 %35669, label %Abort, label %35670

35670:                                            ; preds = %.11827
  %35671 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35672 = xor i32 %35671, 3569
  %35673 = urem i32 %35672, 4096
  %35674 = getelementptr i8, i8 addrspace(1)* %4, i32 %35673
  %35675 = load i8, i8 addrspace(1)* %35674, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %35674, align 1, !nosanitize !3
  store i32 1784, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %35676 = sub i64 %35668, 248
  store i64 %35676, i64* %remaing_gas, align 4
  %35677 = alloca i256, align 8
  store i256 5, i256* %35677, align 4
  %35678 = alloca i256, align 8
  call void @__device_sload(i256* %35677, i256* %35678)
  %35679 = call i32 @__hashword(i256* %35677)
  %35680 = load i32, i32* %5, align 4
  %35681 = icmp eq i32 %35679, %35680
  %35682 = or i1 false, %35681
  %35683 = load i32, i32* %6, align 4
  %35684 = icmp eq i32 %35679, %35683
  %35685 = or i1 %35682, %35684
  %35686 = load i32, i32* %7, align 4
  %35687 = icmp eq i32 %35679, %35686
  %35688 = or i1 %35685, %35687
  %35689 = load i32, i32* %8, align 4
  %35690 = icmp eq i32 %35679, %35689
  %35691 = or i1 %35688, %35690
  %35692 = load i32, i32* %9, align 4
  %35693 = icmp eq i32 %35679, %35692
  %35694 = or i1 %35691, %35693
  %35695 = load i32, i32* %10, align 4
  %35696 = icmp eq i32 %35679, %35695
  %35697 = or i1 %35694, %35696
  %35698 = load i32, i32* %11, align 4
  %35699 = icmp eq i32 %35679, %35698
  %35700 = or i1 %35697, %35699
  %35701 = load i32, i32* %12, align 4
  %35702 = icmp eq i32 %35679, %35701
  %35703 = or i1 %35700, %35702
  %35704 = load i32, i32* %13, align 4
  %35705 = icmp eq i32 %35679, %35704
  %35706 = or i1 %35703, %35705
  %35707 = load i32, i32* %14, align 4
  %35708 = icmp eq i32 %35679, %35707
  %35709 = or i1 %35706, %35708
  %35710 = load i32, i32* %15, align 4
  %35711 = icmp eq i32 %35679, %35710
  %35712 = or i1 %35709, %35711
  %35713 = load i32, i32* %16, align 4
  %35714 = icmp eq i32 %35679, %35713
  %35715 = or i1 %35712, %35714
  %35716 = load i32, i32* %17, align 4
  %35717 = icmp eq i32 %35679, %35716
  %35718 = or i1 %35715, %35717
  %35719 = load i32, i32* %18, align 4
  %35720 = icmp eq i32 %35679, %35719
  %35721 = or i1 %35718, %35720
  %35722 = load i32, i32* %19, align 4
  %35723 = icmp eq i32 %35679, %35722
  %35724 = or i1 %35721, %35723
  %35725 = load i32, i32* %20, align 4
  %35726 = icmp eq i32 %35679, %35725
  %35727 = or i1 %35724, %35726
  %35728 = load i32, i32* %21, align 4
  %35729 = icmp eq i32 %35679, %35728
  %35730 = or i1 %35727, %35729
  %35731 = load i32, i32* %22, align 4
  %35732 = icmp eq i32 %35679, %35731
  %35733 = or i1 %35730, %35732
  %35734 = load i32, i32* %23, align 4
  %35735 = icmp eq i32 %35679, %35734
  %35736 = or i1 %35733, %35735
  %35737 = load i32, i32* %24, align 4
  %35738 = icmp eq i32 %35679, %35737
  %35739 = or i1 %35736, %35738
  %35740 = load i32, i32* %25, align 4
  %35741 = icmp eq i32 %35679, %35740
  %35742 = or i1 %35739, %35741
  %35743 = load i32, i32* %26, align 4
  %35744 = icmp eq i32 %35679, %35743
  %35745 = or i1 %35742, %35744
  %35746 = load i32, i32* %27, align 4
  %35747 = icmp eq i32 %35679, %35746
  %35748 = or i1 %35745, %35747
  %35749 = load i32, i32* %28, align 4
  %35750 = icmp eq i32 %35679, %35749
  %35751 = or i1 %35748, %35750
  %35752 = load i32, i32* %29, align 4
  %35753 = icmp eq i32 %35679, %35752
  %35754 = or i1 %35751, %35753
  %35755 = load i32, i32* %30, align 4
  %35756 = icmp eq i32 %35679, %35755
  %35757 = or i1 %35754, %35756
  %35758 = load i32, i32* %31, align 4
  %35759 = icmp eq i32 %35679, %35758
  %35760 = or i1 %35757, %35759
  %35761 = load i32, i32* %32, align 4
  %35762 = icmp eq i32 %35679, %35761
  %35763 = or i1 %35760, %35762
  %35764 = load i32, i32* %33, align 4
  %35765 = icmp eq i32 %35679, %35764
  %35766 = or i1 %35763, %35765
  %35767 = load i32, i32* %34, align 4
  %35768 = icmp eq i32 %35679, %35767
  %35769 = or i1 %35766, %35768
  %35770 = load i32, i32* %35, align 4
  %35771 = icmp eq i32 %35679, %35770
  %35772 = or i1 %35769, %35771
  %35773 = load i32, i32* %36, align 4
  %35774 = icmp eq i32 %35679, %35773
  %35775 = or i1 %35772, %35774
  %35776 = load i32, i32* %37, align 4
  %35777 = icmp eq i32 %35679, %35776
  %35778 = or i1 %35775, %35777
  %35779 = load i32, i32* %38, align 4
  %35780 = icmp eq i32 %35679, %35779
  %35781 = or i1 %35778, %35780
  %35782 = load i32, i32* %39, align 4
  %35783 = icmp eq i32 %35679, %35782
  %35784 = or i1 %35781, %35783
  %35785 = load i32, i32* %40, align 4
  %35786 = icmp eq i32 %35679, %35785
  %35787 = or i1 %35784, %35786
  %35788 = load i32, i32* %41, align 4
  %35789 = icmp eq i32 %35679, %35788
  %35790 = or i1 %35787, %35789
  %35791 = load i32, i32* %42, align 4
  %35792 = icmp eq i32 %35679, %35791
  %35793 = or i1 %35790, %35792
  %35794 = load i32, i32* %43, align 4
  %35795 = icmp eq i32 %35679, %35794
  %35796 = or i1 %35793, %35795
  %35797 = load i32, i32* %44, align 4
  %35798 = icmp eq i32 %35679, %35797
  %35799 = or i1 %35796, %35798
  %35800 = load i32, i32* %45, align 4
  %35801 = icmp eq i32 %35679, %35800
  %35802 = or i1 %35799, %35801
  %35803 = load i32, i32* %46, align 4
  %35804 = icmp eq i32 %35679, %35803
  %35805 = or i1 %35802, %35804
  %35806 = load i32, i32* %47, align 4
  %35807 = icmp eq i32 %35679, %35806
  %35808 = or i1 %35805, %35807
  %35809 = load i32, i32* %48, align 4
  %35810 = icmp eq i32 %35679, %35809
  %35811 = or i1 %35808, %35810
  %35812 = load i32, i32* %49, align 4
  %35813 = icmp eq i32 %35679, %35812
  %35814 = or i1 %35811, %35813
  %35815 = load i32, i32* %50, align 4
  %35816 = icmp eq i32 %35679, %35815
  %35817 = or i1 %35814, %35816
  %35818 = load i32, i32* %51, align 4
  %35819 = icmp eq i32 %35679, %35818
  %35820 = or i1 %35817, %35819
  %35821 = load i32, i32* %52, align 4
  %35822 = icmp eq i32 %35679, %35821
  %35823 = or i1 %35820, %35822
  %35824 = load i32, i32* %53, align 4
  %35825 = icmp eq i32 %35679, %35824
  %35826 = or i1 %35823, %35825
  %35827 = load i32, i32* %54, align 4
  %35828 = icmp eq i32 %35679, %35827
  %35829 = or i1 %35826, %35828
  %35830 = load i32, i32* %55, align 4
  %35831 = icmp eq i32 %35679, %35830
  %35832 = or i1 %35829, %35831
  %35833 = load i32, i32* %56, align 4
  %35834 = icmp eq i32 %35679, %35833
  %35835 = or i1 %35832, %35834
  %35836 = load i32, i32* %57, align 4
  %35837 = icmp eq i32 %35679, %35836
  %35838 = or i1 %35835, %35837
  %35839 = load i32, i32* %58, align 4
  %35840 = icmp eq i32 %35679, %35839
  %35841 = or i1 %35838, %35840
  %35842 = load i32, i32* %59, align 4
  %35843 = icmp eq i32 %35679, %35842
  %35844 = or i1 %35841, %35843
  %35845 = load i32, i32* %60, align 4
  %35846 = icmp eq i32 %35679, %35845
  %35847 = or i1 %35844, %35846
  %35848 = load i32, i32* %61, align 4
  %35849 = icmp eq i32 %35679, %35848
  %35850 = or i1 %35847, %35849
  %35851 = load i32, i32* %62, align 4
  %35852 = icmp eq i32 %35679, %35851
  %35853 = or i1 %35850, %35852
  %35854 = getelementptr i8, i8 addrspace(1)* %4, i32 131
  %35855 = zext i1 %35853 to i8
  store i8 %35855, i8 addrspace(1)* %35854, align 1, !nosanitize !3
  %35856 = load i256, i256* %35678, align 4
  %35857 = add i256 1, %35856, !pc !516, !intsan !10
  %35858 = alloca i256, align 8
  store i256 5, i256* %35858, align 4
  %35859 = alloca i256, align 8
  store i256 %35857, i256* %35859, align 4
  call void @__device_sstore(i256* %35858, i256* %35859)
  %35860 = call i32 @__hashword(i256* %35858)
  store i32 %35860, i32* %47, align 4, !nosanitize !3
  %35861 = alloca i256, align 8
  store i256 5, i256* %35861, align 4
  %35862 = alloca i256, align 8
  call void @__device_sload(i256* %35861, i256* %35862)
  %35863 = call i32 @__hashword(i256* %35861)
  %35864 = load i32, i32* %5, align 4
  %35865 = icmp eq i32 %35863, %35864
  %35866 = or i1 false, %35865
  %35867 = load i32, i32* %6, align 4
  %35868 = icmp eq i32 %35863, %35867
  %35869 = or i1 %35866, %35868
  %35870 = load i32, i32* %7, align 4
  %35871 = icmp eq i32 %35863, %35870
  %35872 = or i1 %35869, %35871
  %35873 = load i32, i32* %8, align 4
  %35874 = icmp eq i32 %35863, %35873
  %35875 = or i1 %35872, %35874
  %35876 = load i32, i32* %9, align 4
  %35877 = icmp eq i32 %35863, %35876
  %35878 = or i1 %35875, %35877
  %35879 = load i32, i32* %10, align 4
  %35880 = icmp eq i32 %35863, %35879
  %35881 = or i1 %35878, %35880
  %35882 = load i32, i32* %11, align 4
  %35883 = icmp eq i32 %35863, %35882
  %35884 = or i1 %35881, %35883
  %35885 = load i32, i32* %12, align 4
  %35886 = icmp eq i32 %35863, %35885
  %35887 = or i1 %35884, %35886
  %35888 = load i32, i32* %13, align 4
  %35889 = icmp eq i32 %35863, %35888
  %35890 = or i1 %35887, %35889
  %35891 = load i32, i32* %14, align 4
  %35892 = icmp eq i32 %35863, %35891
  %35893 = or i1 %35890, %35892
  %35894 = load i32, i32* %15, align 4
  %35895 = icmp eq i32 %35863, %35894
  %35896 = or i1 %35893, %35895
  %35897 = load i32, i32* %16, align 4
  %35898 = icmp eq i32 %35863, %35897
  %35899 = or i1 %35896, %35898
  %35900 = load i32, i32* %17, align 4
  %35901 = icmp eq i32 %35863, %35900
  %35902 = or i1 %35899, %35901
  %35903 = load i32, i32* %18, align 4
  %35904 = icmp eq i32 %35863, %35903
  %35905 = or i1 %35902, %35904
  %35906 = load i32, i32* %19, align 4
  %35907 = icmp eq i32 %35863, %35906
  %35908 = or i1 %35905, %35907
  %35909 = load i32, i32* %20, align 4
  %35910 = icmp eq i32 %35863, %35909
  %35911 = or i1 %35908, %35910
  %35912 = load i32, i32* %21, align 4
  %35913 = icmp eq i32 %35863, %35912
  %35914 = or i1 %35911, %35913
  %35915 = load i32, i32* %22, align 4
  %35916 = icmp eq i32 %35863, %35915
  %35917 = or i1 %35914, %35916
  %35918 = load i32, i32* %23, align 4
  %35919 = icmp eq i32 %35863, %35918
  %35920 = or i1 %35917, %35919
  %35921 = load i32, i32* %24, align 4
  %35922 = icmp eq i32 %35863, %35921
  %35923 = or i1 %35920, %35922
  %35924 = load i32, i32* %25, align 4
  %35925 = icmp eq i32 %35863, %35924
  %35926 = or i1 %35923, %35925
  %35927 = load i32, i32* %26, align 4
  %35928 = icmp eq i32 %35863, %35927
  %35929 = or i1 %35926, %35928
  %35930 = load i32, i32* %27, align 4
  %35931 = icmp eq i32 %35863, %35930
  %35932 = or i1 %35929, %35931
  %35933 = load i32, i32* %28, align 4
  %35934 = icmp eq i32 %35863, %35933
  %35935 = or i1 %35932, %35934
  %35936 = load i32, i32* %29, align 4
  %35937 = icmp eq i32 %35863, %35936
  %35938 = or i1 %35935, %35937
  %35939 = load i32, i32* %30, align 4
  %35940 = icmp eq i32 %35863, %35939
  %35941 = or i1 %35938, %35940
  %35942 = load i32, i32* %31, align 4
  %35943 = icmp eq i32 %35863, %35942
  %35944 = or i1 %35941, %35943
  %35945 = load i32, i32* %32, align 4
  %35946 = icmp eq i32 %35863, %35945
  %35947 = or i1 %35944, %35946
  %35948 = load i32, i32* %33, align 4
  %35949 = icmp eq i32 %35863, %35948
  %35950 = or i1 %35947, %35949
  %35951 = load i32, i32* %34, align 4
  %35952 = icmp eq i32 %35863, %35951
  %35953 = or i1 %35950, %35952
  %35954 = load i32, i32* %35, align 4
  %35955 = icmp eq i32 %35863, %35954
  %35956 = or i1 %35953, %35955
  %35957 = load i32, i32* %36, align 4
  %35958 = icmp eq i32 %35863, %35957
  %35959 = or i1 %35956, %35958
  %35960 = load i32, i32* %37, align 4
  %35961 = icmp eq i32 %35863, %35960
  %35962 = or i1 %35959, %35961
  %35963 = load i32, i32* %38, align 4
  %35964 = icmp eq i32 %35863, %35963
  %35965 = or i1 %35962, %35964
  %35966 = load i32, i32* %39, align 4
  %35967 = icmp eq i32 %35863, %35966
  %35968 = or i1 %35965, %35967
  %35969 = load i32, i32* %40, align 4
  %35970 = icmp eq i32 %35863, %35969
  %35971 = or i1 %35968, %35970
  %35972 = load i32, i32* %41, align 4
  %35973 = icmp eq i32 %35863, %35972
  %35974 = or i1 %35971, %35973
  %35975 = load i32, i32* %42, align 4
  %35976 = icmp eq i32 %35863, %35975
  %35977 = or i1 %35974, %35976
  %35978 = load i32, i32* %43, align 4
  %35979 = icmp eq i32 %35863, %35978
  %35980 = or i1 %35977, %35979
  %35981 = load i32, i32* %44, align 4
  %35982 = icmp eq i32 %35863, %35981
  %35983 = or i1 %35980, %35982
  %35984 = load i32, i32* %45, align 4
  %35985 = icmp eq i32 %35863, %35984
  %35986 = or i1 %35983, %35985
  %35987 = load i32, i32* %46, align 4
  %35988 = icmp eq i32 %35863, %35987
  %35989 = or i1 %35986, %35988
  %35990 = load i32, i32* %47, align 4
  %35991 = icmp eq i32 %35863, %35990
  %35992 = or i1 %35989, %35991
  %35993 = load i32, i32* %48, align 4
  %35994 = icmp eq i32 %35863, %35993
  %35995 = or i1 %35992, %35994
  %35996 = load i32, i32* %49, align 4
  %35997 = icmp eq i32 %35863, %35996
  %35998 = or i1 %35995, %35997
  %35999 = load i32, i32* %50, align 4
  %36000 = icmp eq i32 %35863, %35999
  %36001 = or i1 %35998, %36000
  %36002 = load i32, i32* %51, align 4
  %36003 = icmp eq i32 %35863, %36002
  %36004 = or i1 %36001, %36003
  %36005 = load i32, i32* %52, align 4
  %36006 = icmp eq i32 %35863, %36005
  %36007 = or i1 %36004, %36006
  %36008 = load i32, i32* %53, align 4
  %36009 = icmp eq i32 %35863, %36008
  %36010 = or i1 %36007, %36009
  %36011 = load i32, i32* %54, align 4
  %36012 = icmp eq i32 %35863, %36011
  %36013 = or i1 %36010, %36012
  %36014 = load i32, i32* %55, align 4
  %36015 = icmp eq i32 %35863, %36014
  %36016 = or i1 %36013, %36015
  %36017 = load i32, i32* %56, align 4
  %36018 = icmp eq i32 %35863, %36017
  %36019 = or i1 %36016, %36018
  %36020 = load i32, i32* %57, align 4
  %36021 = icmp eq i32 %35863, %36020
  %36022 = or i1 %36019, %36021
  %36023 = load i32, i32* %58, align 4
  %36024 = icmp eq i32 %35863, %36023
  %36025 = or i1 %36022, %36024
  %36026 = load i32, i32* %59, align 4
  %36027 = icmp eq i32 %35863, %36026
  %36028 = or i1 %36025, %36027
  %36029 = load i32, i32* %60, align 4
  %36030 = icmp eq i32 %35863, %36029
  %36031 = or i1 %36028, %36030
  %36032 = load i32, i32* %61, align 4
  %36033 = icmp eq i32 %35863, %36032
  %36034 = or i1 %36031, %36033
  %36035 = load i32, i32* %62, align 4
  %36036 = icmp eq i32 %35863, %36035
  %36037 = or i1 %36034, %36036
  %36038 = getelementptr i8, i8 addrspace(1)* %4, i32 132
  %36039 = zext i1 %36037 to i8
  store i8 %36039, i8 addrspace(1)* %36038, align 1, !nosanitize !3
  %36040 = load i256, i256* %35862, align 4
  %36041 = trunc i256 17528 to i64
  %36042 = load i64, i64* %STACK_DEP_PTR, align 4
  %36043 = add i64 %36042, 1
  store i64 %36043, i64* %STACK_DEP_PTR, align 4
  %36044 = load i64, i64* %STACK_DEP_PTR, align 4
  %36045 = getelementptr i256, i256* %STACK, i64 %36044
  store i256 11856, i256* %36045, align 4
  %36046 = load i64, i64* %STACK_DEP_PTR, align 4
  %36047 = add i64 %36046, 1
  store i64 %36047, i64* %STACK_DEP_PTR, align 4
  %36048 = load i64, i64* %STACK_DEP_PTR, align 4
  %36049 = getelementptr i256, i256* %STACK, i64 %36048
  store i256 %36040, i256* %36049, align 4
  br label %.17528, !EVMBB !4

.11856:                                           ; preds = %JumpTable
  %36050 = load i64, i64* %remaing_gas, align 4
  %36051 = icmp ugt i64 88, %36050
  br i1 %36051, label %Abort, label %36052

36052:                                            ; preds = %.11856
  %36053 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36054 = xor i32 %36053, 2940
  %36055 = urem i32 %36054, 4096
  %36056 = getelementptr i8, i8 addrspace(1)* %4, i32 %36055
  %36057 = load i8, i8 addrspace(1)* %36056, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36056, align 1, !nosanitize !3
  store i32 1470, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36058 = sub i64 %36050, 88
  store i64 %36058, i64* %remaing_gas, align 4
  %36059 = alloca i256, align 8
  store i256 5, i256* %36059, align 4
  %36060 = alloca i256, align 8
  call void @__device_sload(i256* %36059, i256* %36060)
  %36061 = call i32 @__hashword(i256* %36059)
  %36062 = load i32, i32* %5, align 4
  %36063 = icmp eq i32 %36061, %36062
  %36064 = or i1 false, %36063
  %36065 = load i32, i32* %6, align 4
  %36066 = icmp eq i32 %36061, %36065
  %36067 = or i1 %36064, %36066
  %36068 = load i32, i32* %7, align 4
  %36069 = icmp eq i32 %36061, %36068
  %36070 = or i1 %36067, %36069
  %36071 = load i32, i32* %8, align 4
  %36072 = icmp eq i32 %36061, %36071
  %36073 = or i1 %36070, %36072
  %36074 = load i32, i32* %9, align 4
  %36075 = icmp eq i32 %36061, %36074
  %36076 = or i1 %36073, %36075
  %36077 = load i32, i32* %10, align 4
  %36078 = icmp eq i32 %36061, %36077
  %36079 = or i1 %36076, %36078
  %36080 = load i32, i32* %11, align 4
  %36081 = icmp eq i32 %36061, %36080
  %36082 = or i1 %36079, %36081
  %36083 = load i32, i32* %12, align 4
  %36084 = icmp eq i32 %36061, %36083
  %36085 = or i1 %36082, %36084
  %36086 = load i32, i32* %13, align 4
  %36087 = icmp eq i32 %36061, %36086
  %36088 = or i1 %36085, %36087
  %36089 = load i32, i32* %14, align 4
  %36090 = icmp eq i32 %36061, %36089
  %36091 = or i1 %36088, %36090
  %36092 = load i32, i32* %15, align 4
  %36093 = icmp eq i32 %36061, %36092
  %36094 = or i1 %36091, %36093
  %36095 = load i32, i32* %16, align 4
  %36096 = icmp eq i32 %36061, %36095
  %36097 = or i1 %36094, %36096
  %36098 = load i32, i32* %17, align 4
  %36099 = icmp eq i32 %36061, %36098
  %36100 = or i1 %36097, %36099
  %36101 = load i32, i32* %18, align 4
  %36102 = icmp eq i32 %36061, %36101
  %36103 = or i1 %36100, %36102
  %36104 = load i32, i32* %19, align 4
  %36105 = icmp eq i32 %36061, %36104
  %36106 = or i1 %36103, %36105
  %36107 = load i32, i32* %20, align 4
  %36108 = icmp eq i32 %36061, %36107
  %36109 = or i1 %36106, %36108
  %36110 = load i32, i32* %21, align 4
  %36111 = icmp eq i32 %36061, %36110
  %36112 = or i1 %36109, %36111
  %36113 = load i32, i32* %22, align 4
  %36114 = icmp eq i32 %36061, %36113
  %36115 = or i1 %36112, %36114
  %36116 = load i32, i32* %23, align 4
  %36117 = icmp eq i32 %36061, %36116
  %36118 = or i1 %36115, %36117
  %36119 = load i32, i32* %24, align 4
  %36120 = icmp eq i32 %36061, %36119
  %36121 = or i1 %36118, %36120
  %36122 = load i32, i32* %25, align 4
  %36123 = icmp eq i32 %36061, %36122
  %36124 = or i1 %36121, %36123
  %36125 = load i32, i32* %26, align 4
  %36126 = icmp eq i32 %36061, %36125
  %36127 = or i1 %36124, %36126
  %36128 = load i32, i32* %27, align 4
  %36129 = icmp eq i32 %36061, %36128
  %36130 = or i1 %36127, %36129
  %36131 = load i32, i32* %28, align 4
  %36132 = icmp eq i32 %36061, %36131
  %36133 = or i1 %36130, %36132
  %36134 = load i32, i32* %29, align 4
  %36135 = icmp eq i32 %36061, %36134
  %36136 = or i1 %36133, %36135
  %36137 = load i32, i32* %30, align 4
  %36138 = icmp eq i32 %36061, %36137
  %36139 = or i1 %36136, %36138
  %36140 = load i32, i32* %31, align 4
  %36141 = icmp eq i32 %36061, %36140
  %36142 = or i1 %36139, %36141
  %36143 = load i32, i32* %32, align 4
  %36144 = icmp eq i32 %36061, %36143
  %36145 = or i1 %36142, %36144
  %36146 = load i32, i32* %33, align 4
  %36147 = icmp eq i32 %36061, %36146
  %36148 = or i1 %36145, %36147
  %36149 = load i32, i32* %34, align 4
  %36150 = icmp eq i32 %36061, %36149
  %36151 = or i1 %36148, %36150
  %36152 = load i32, i32* %35, align 4
  %36153 = icmp eq i32 %36061, %36152
  %36154 = or i1 %36151, %36153
  %36155 = load i32, i32* %36, align 4
  %36156 = icmp eq i32 %36061, %36155
  %36157 = or i1 %36154, %36156
  %36158 = load i32, i32* %37, align 4
  %36159 = icmp eq i32 %36061, %36158
  %36160 = or i1 %36157, %36159
  %36161 = load i32, i32* %38, align 4
  %36162 = icmp eq i32 %36061, %36161
  %36163 = or i1 %36160, %36162
  %36164 = load i32, i32* %39, align 4
  %36165 = icmp eq i32 %36061, %36164
  %36166 = or i1 %36163, %36165
  %36167 = load i32, i32* %40, align 4
  %36168 = icmp eq i32 %36061, %36167
  %36169 = or i1 %36166, %36168
  %36170 = load i32, i32* %41, align 4
  %36171 = icmp eq i32 %36061, %36170
  %36172 = or i1 %36169, %36171
  %36173 = load i32, i32* %42, align 4
  %36174 = icmp eq i32 %36061, %36173
  %36175 = or i1 %36172, %36174
  %36176 = load i32, i32* %43, align 4
  %36177 = icmp eq i32 %36061, %36176
  %36178 = or i1 %36175, %36177
  %36179 = load i32, i32* %44, align 4
  %36180 = icmp eq i32 %36061, %36179
  %36181 = or i1 %36178, %36180
  %36182 = load i32, i32* %45, align 4
  %36183 = icmp eq i32 %36061, %36182
  %36184 = or i1 %36181, %36183
  %36185 = load i32, i32* %46, align 4
  %36186 = icmp eq i32 %36061, %36185
  %36187 = or i1 %36184, %36186
  %36188 = load i32, i32* %47, align 4
  %36189 = icmp eq i32 %36061, %36188
  %36190 = or i1 %36187, %36189
  %36191 = load i32, i32* %48, align 4
  %36192 = icmp eq i32 %36061, %36191
  %36193 = or i1 %36190, %36192
  %36194 = load i32, i32* %49, align 4
  %36195 = icmp eq i32 %36061, %36194
  %36196 = or i1 %36193, %36195
  %36197 = load i32, i32* %50, align 4
  %36198 = icmp eq i32 %36061, %36197
  %36199 = or i1 %36196, %36198
  %36200 = load i32, i32* %51, align 4
  %36201 = icmp eq i32 %36061, %36200
  %36202 = or i1 %36199, %36201
  %36203 = load i32, i32* %52, align 4
  %36204 = icmp eq i32 %36061, %36203
  %36205 = or i1 %36202, %36204
  %36206 = load i32, i32* %53, align 4
  %36207 = icmp eq i32 %36061, %36206
  %36208 = or i1 %36205, %36207
  %36209 = load i32, i32* %54, align 4
  %36210 = icmp eq i32 %36061, %36209
  %36211 = or i1 %36208, %36210
  %36212 = load i32, i32* %55, align 4
  %36213 = icmp eq i32 %36061, %36212
  %36214 = or i1 %36211, %36213
  %36215 = load i32, i32* %56, align 4
  %36216 = icmp eq i32 %36061, %36215
  %36217 = or i1 %36214, %36216
  %36218 = load i32, i32* %57, align 4
  %36219 = icmp eq i32 %36061, %36218
  %36220 = or i1 %36217, %36219
  %36221 = load i32, i32* %58, align 4
  %36222 = icmp eq i32 %36061, %36221
  %36223 = or i1 %36220, %36222
  %36224 = load i32, i32* %59, align 4
  %36225 = icmp eq i32 %36061, %36224
  %36226 = or i1 %36223, %36225
  %36227 = load i32, i32* %60, align 4
  %36228 = icmp eq i32 %36061, %36227
  %36229 = or i1 %36226, %36228
  %36230 = load i32, i32* %61, align 4
  %36231 = icmp eq i32 %36061, %36230
  %36232 = or i1 %36229, %36231
  %36233 = load i32, i32* %62, align 4
  %36234 = icmp eq i32 %36061, %36233
  %36235 = or i1 %36232, %36234
  %36236 = getelementptr i8, i8 addrspace(1)* %4, i32 133
  %36237 = zext i1 %36235 to i8
  store i8 %36237, i8 addrspace(1)* %36236, align 1, !nosanitize !3
  %36238 = load i256, i256* %36060, align 4
  %36239 = icmp ugt i256 %36238, 10
  %36240 = icmp eq i1 %36239, false
  %36241 = trunc i256 11872 to i64
  %jump.check204 = icmp ne i1 %36240, false
  br i1 %jump.check204, label %.11872, label %.11868, !EVMBB !4

.11868:                                           ; preds = %36052
  %36242 = load i64, i64* %remaing_gas, align 4
  %36243 = icmp ugt i64 16, %36242
  br i1 %36243, label %Abort, label %36244

36244:                                            ; preds = %.11868
  %36245 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36246 = xor i32 %36245, 1984
  %36247 = urem i32 %36246, 4096
  %36248 = getelementptr i8, i8 addrspace(1)* %4, i32 %36247
  %36249 = load i8, i8 addrspace(1)* %36248, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36248, align 1, !nosanitize !3
  store i32 992, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36250 = sub i64 %36242, 16
  store i64 %36250, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.11872:                                           ; preds = %36052, %JumpTable
  %36251 = load i64, i64* %remaing_gas, align 4
  %36252 = icmp ugt i64 128, %36251
  br i1 %36252, label %Abort, label %36253

36253:                                            ; preds = %.11872
  %36254 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36255 = xor i32 %36254, 1660
  %36256 = urem i32 %36255, 4096
  %36257 = getelementptr i8, i8 addrspace(1)* %4, i32 %36256
  %36258 = load i8, i8 addrspace(1)* %36257, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36257, align 1, !nosanitize !3
  store i32 830, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36259 = sub i64 %36251, 128
  store i64 %36259, i64* %remaing_gas, align 4
  %36260 = load i64, i64* %STACK_DEP_PTR, align 4
  %36261 = getelementptr i256, i256* %STACK, i64 %36260
  %36262 = load i256, i256* %36261, align 4
  %36263 = load i64, i64* %STACK_DEP_PTR, align 4
  %36264 = sub i64 %36263, 1
  store i64 %36264, i64* %STACK_DEP_PTR, align 4
  %36265 = load i64, i64* %STACK_DEP_PTR, align 4
  %36266 = getelementptr i256, i256* %STACK, i64 %36265
  %36267 = load i256, i256* %36266, align 4
  %36268 = load i64, i64* %STACK_DEP_PTR, align 4
  %36269 = sub i64 %36268, 1
  store i64 %36269, i64* %STACK_DEP_PTR, align 4
  %36270 = trunc i256 %36267 to i64
  store i64 %36270, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.11875:                                           ; preds = %5152, %JumpTable
  %36271 = load i64, i64* %remaing_gas, align 4
  %36272 = icmp ugt i64 256, %36271
  br i1 %36272, label %Abort, label %36273

36273:                                            ; preds = %.11875
  %36274 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36275 = xor i32 %36274, 699
  %36276 = urem i32 %36275, 4096
  %36277 = getelementptr i8, i8 addrspace(1)* %4, i32 %36276
  %36278 = load i8, i8 addrspace(1)* %36277, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36277, align 1, !nosanitize !3
  store i32 349, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36279 = sub i64 %36271, 256
  store i64 %36279, i64* %remaing_gas, align 4
  %36280 = alloca i256, align 8
  store i256 0, i256* %36280, align 4
  %36281 = alloca i256, align 8
  call void @__device_sload(i256* %36280, i256* %36281)
  %36282 = call i32 @__hashword(i256* %36280)
  %36283 = load i32, i32* %5, align 4
  %36284 = icmp eq i32 %36282, %36283
  %36285 = or i1 false, %36284
  %36286 = load i32, i32* %6, align 4
  %36287 = icmp eq i32 %36282, %36286
  %36288 = or i1 %36285, %36287
  %36289 = load i32, i32* %7, align 4
  %36290 = icmp eq i32 %36282, %36289
  %36291 = or i1 %36288, %36290
  %36292 = load i32, i32* %8, align 4
  %36293 = icmp eq i32 %36282, %36292
  %36294 = or i1 %36291, %36293
  %36295 = load i32, i32* %9, align 4
  %36296 = icmp eq i32 %36282, %36295
  %36297 = or i1 %36294, %36296
  %36298 = load i32, i32* %10, align 4
  %36299 = icmp eq i32 %36282, %36298
  %36300 = or i1 %36297, %36299
  %36301 = load i32, i32* %11, align 4
  %36302 = icmp eq i32 %36282, %36301
  %36303 = or i1 %36300, %36302
  %36304 = load i32, i32* %12, align 4
  %36305 = icmp eq i32 %36282, %36304
  %36306 = or i1 %36303, %36305
  %36307 = load i32, i32* %13, align 4
  %36308 = icmp eq i32 %36282, %36307
  %36309 = or i1 %36306, %36308
  %36310 = load i32, i32* %14, align 4
  %36311 = icmp eq i32 %36282, %36310
  %36312 = or i1 %36309, %36311
  %36313 = load i32, i32* %15, align 4
  %36314 = icmp eq i32 %36282, %36313
  %36315 = or i1 %36312, %36314
  %36316 = load i32, i32* %16, align 4
  %36317 = icmp eq i32 %36282, %36316
  %36318 = or i1 %36315, %36317
  %36319 = load i32, i32* %17, align 4
  %36320 = icmp eq i32 %36282, %36319
  %36321 = or i1 %36318, %36320
  %36322 = load i32, i32* %18, align 4
  %36323 = icmp eq i32 %36282, %36322
  %36324 = or i1 %36321, %36323
  %36325 = load i32, i32* %19, align 4
  %36326 = icmp eq i32 %36282, %36325
  %36327 = or i1 %36324, %36326
  %36328 = load i32, i32* %20, align 4
  %36329 = icmp eq i32 %36282, %36328
  %36330 = or i1 %36327, %36329
  %36331 = load i32, i32* %21, align 4
  %36332 = icmp eq i32 %36282, %36331
  %36333 = or i1 %36330, %36332
  %36334 = load i32, i32* %22, align 4
  %36335 = icmp eq i32 %36282, %36334
  %36336 = or i1 %36333, %36335
  %36337 = load i32, i32* %23, align 4
  %36338 = icmp eq i32 %36282, %36337
  %36339 = or i1 %36336, %36338
  %36340 = load i32, i32* %24, align 4
  %36341 = icmp eq i32 %36282, %36340
  %36342 = or i1 %36339, %36341
  %36343 = load i32, i32* %25, align 4
  %36344 = icmp eq i32 %36282, %36343
  %36345 = or i1 %36342, %36344
  %36346 = load i32, i32* %26, align 4
  %36347 = icmp eq i32 %36282, %36346
  %36348 = or i1 %36345, %36347
  %36349 = load i32, i32* %27, align 4
  %36350 = icmp eq i32 %36282, %36349
  %36351 = or i1 %36348, %36350
  %36352 = load i32, i32* %28, align 4
  %36353 = icmp eq i32 %36282, %36352
  %36354 = or i1 %36351, %36353
  %36355 = load i32, i32* %29, align 4
  %36356 = icmp eq i32 %36282, %36355
  %36357 = or i1 %36354, %36356
  %36358 = load i32, i32* %30, align 4
  %36359 = icmp eq i32 %36282, %36358
  %36360 = or i1 %36357, %36359
  %36361 = load i32, i32* %31, align 4
  %36362 = icmp eq i32 %36282, %36361
  %36363 = or i1 %36360, %36362
  %36364 = load i32, i32* %32, align 4
  %36365 = icmp eq i32 %36282, %36364
  %36366 = or i1 %36363, %36365
  %36367 = load i32, i32* %33, align 4
  %36368 = icmp eq i32 %36282, %36367
  %36369 = or i1 %36366, %36368
  %36370 = load i32, i32* %34, align 4
  %36371 = icmp eq i32 %36282, %36370
  %36372 = or i1 %36369, %36371
  %36373 = load i32, i32* %35, align 4
  %36374 = icmp eq i32 %36282, %36373
  %36375 = or i1 %36372, %36374
  %36376 = load i32, i32* %36, align 4
  %36377 = icmp eq i32 %36282, %36376
  %36378 = or i1 %36375, %36377
  %36379 = load i32, i32* %37, align 4
  %36380 = icmp eq i32 %36282, %36379
  %36381 = or i1 %36378, %36380
  %36382 = load i32, i32* %38, align 4
  %36383 = icmp eq i32 %36282, %36382
  %36384 = or i1 %36381, %36383
  %36385 = load i32, i32* %39, align 4
  %36386 = icmp eq i32 %36282, %36385
  %36387 = or i1 %36384, %36386
  %36388 = load i32, i32* %40, align 4
  %36389 = icmp eq i32 %36282, %36388
  %36390 = or i1 %36387, %36389
  %36391 = load i32, i32* %41, align 4
  %36392 = icmp eq i32 %36282, %36391
  %36393 = or i1 %36390, %36392
  %36394 = load i32, i32* %42, align 4
  %36395 = icmp eq i32 %36282, %36394
  %36396 = or i1 %36393, %36395
  %36397 = load i32, i32* %43, align 4
  %36398 = icmp eq i32 %36282, %36397
  %36399 = or i1 %36396, %36398
  %36400 = load i32, i32* %44, align 4
  %36401 = icmp eq i32 %36282, %36400
  %36402 = or i1 %36399, %36401
  %36403 = load i32, i32* %45, align 4
  %36404 = icmp eq i32 %36282, %36403
  %36405 = or i1 %36402, %36404
  %36406 = load i32, i32* %46, align 4
  %36407 = icmp eq i32 %36282, %36406
  %36408 = or i1 %36405, %36407
  %36409 = load i32, i32* %47, align 4
  %36410 = icmp eq i32 %36282, %36409
  %36411 = or i1 %36408, %36410
  %36412 = load i32, i32* %48, align 4
  %36413 = icmp eq i32 %36282, %36412
  %36414 = or i1 %36411, %36413
  %36415 = load i32, i32* %49, align 4
  %36416 = icmp eq i32 %36282, %36415
  %36417 = or i1 %36414, %36416
  %36418 = load i32, i32* %50, align 4
  %36419 = icmp eq i32 %36282, %36418
  %36420 = or i1 %36417, %36419
  %36421 = load i32, i32* %51, align 4
  %36422 = icmp eq i32 %36282, %36421
  %36423 = or i1 %36420, %36422
  %36424 = load i32, i32* %52, align 4
  %36425 = icmp eq i32 %36282, %36424
  %36426 = or i1 %36423, %36425
  %36427 = load i32, i32* %53, align 4
  %36428 = icmp eq i32 %36282, %36427
  %36429 = or i1 %36426, %36428
  %36430 = load i32, i32* %54, align 4
  %36431 = icmp eq i32 %36282, %36430
  %36432 = or i1 %36429, %36431
  %36433 = load i32, i32* %55, align 4
  %36434 = icmp eq i32 %36282, %36433
  %36435 = or i1 %36432, %36434
  %36436 = load i32, i32* %56, align 4
  %36437 = icmp eq i32 %36282, %36436
  %36438 = or i1 %36435, %36437
  %36439 = load i32, i32* %57, align 4
  %36440 = icmp eq i32 %36282, %36439
  %36441 = or i1 %36438, %36440
  %36442 = load i32, i32* %58, align 4
  %36443 = icmp eq i32 %36282, %36442
  %36444 = or i1 %36441, %36443
  %36445 = load i32, i32* %59, align 4
  %36446 = icmp eq i32 %36282, %36445
  %36447 = or i1 %36444, %36446
  %36448 = load i32, i32* %60, align 4
  %36449 = icmp eq i32 %36282, %36448
  %36450 = or i1 %36447, %36449
  %36451 = load i32, i32* %61, align 4
  %36452 = icmp eq i32 %36282, %36451
  %36453 = or i1 %36450, %36452
  %36454 = load i32, i32* %62, align 4
  %36455 = icmp eq i32 %36282, %36454
  %36456 = or i1 %36453, %36455
  %36457 = getelementptr i8, i8 addrspace(1)* %4, i32 134
  %36458 = zext i1 %36456 to i8
  store i8 %36458, i8 addrspace(1)* %36457, align 1, !nosanitize !3
  %36459 = load i256, i256* %36281, align 4
  %36460 = alloca i256, align 8
  store i256 %36459, i256* %36460, align 4
  %36461 = alloca i256, align 8
  store i256 1, i256* %36461, align 4
  %36462 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %36460, i256* %36461, i256* %36462), !pc !517, !intsan !6
  %36463 = load i256, i256* %36462, align 4
  %36464 = and i256 1461501637330902918203684832716283019655932542975, %36463
  %36465 = and i256 1461501637330902918203684832716283019655932542975, %36464
  %36466 = icmp eq i256 %36465, 0
  %36467 = icmp eq i1 %36466, false
  %36468 = trunc i256 11954 to i64
  %jump.check63 = icmp ne i1 %36467, false
  %36469 = load i64, i64* %STACK_DEP_PTR, align 4
  %36470 = add i64 %36469, 1
  store i64 %36470, i64* %STACK_DEP_PTR, align 4
  %36471 = load i64, i64* %STACK_DEP_PTR, align 4
  %36472 = getelementptr i256, i256* %STACK, i64 %36471
  store i256 0, i256* %36472, align 4
  %36473 = load i64, i64* %STACK_DEP_PTR, align 4
  %36474 = add i64 %36473, 1
  store i64 %36474, i64* %STACK_DEP_PTR, align 4
  %36475 = load i64, i64* %STACK_DEP_PTR, align 4
  %36476 = getelementptr i256, i256* %STACK, i64 %36475
  store i256 0, i256* %36476, align 4
  br i1 %jump.check63, label %.11954, label %.11943, !EVMBB !4

.11943:                                           ; preds = %36273
  %36477 = load i64, i64* %remaing_gas, align 4
  %36478 = icmp ugt i64 144, %36477
  br i1 %36478, label %Abort, label %36479

36479:                                            ; preds = %.11943
  %36480 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36481 = xor i32 %36480, 3106
  %36482 = urem i32 %36481, 4096
  %36483 = getelementptr i8, i8 addrspace(1)* %4, i32 %36482
  %36484 = load i8, i8 addrspace(1)* %36483, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36483, align 1, !nosanitize !3
  store i32 1553, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36485 = sub i64 %36477, 144
  store i64 %36485, i64* %remaing_gas, align 4
  %36486 = load i64, i64* %STACK_DEP_PTR, align 4
  %36487 = sub i64 %36486, 0
  store i64 %36487, i64* %STACK_DEP_PTR, align 4
  %36488 = trunc i256 17834 to i64
  %36489 = load i64, i64* %STACK_DEP_PTR, align 4
  %36490 = add i64 %36489, 1
  store i64 %36490, i64* %STACK_DEP_PTR, align 4
  %36491 = load i64, i64* %STACK_DEP_PTR, align 4
  %36492 = getelementptr i256, i256* %STACK, i64 %36491
  store i256 11952, i256* %36492, align 4
  %36493 = load i64, i64* %STACK_DEP_PTR, align 4
  %36494 = add i64 %36493, 1
  store i64 %36494, i64* %STACK_DEP_PTR, align 4
  %36495 = load i64, i64* %STACK_DEP_PTR, align 4
  %36496 = getelementptr i256, i256* %STACK, i64 %36495
  store i256 0, i256* %36496, align 4
  br label %.17834, !EVMBB !4

.11952:                                           ; preds = %JumpTable
  %36497 = load i64, i64* %STACK_DEP_PTR, align 4
  %36498 = getelementptr i256, i256* %STACK, i64 %36497
  %36499 = load i256, i256* %36498, align 4
  %36500 = load i64, i64* %STACK_DEP_PTR, align 4
  %36501 = sub i64 %36500, 1
  store i64 %36501, i64* %STACK_DEP_PTR, align 4
  br label %.11954

.11954:                                           ; preds = %.11952, %36273, %JumpTable
  %36502 = load i64, i64* %remaing_gas, align 4
  %36503 = icmp ugt i64 784, %36502
  br i1 %36503, label %Abort, label %36504

36504:                                            ; preds = %.11954
  %36505 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36506 = xor i32 %36505, 3324
  %36507 = urem i32 %36506, 4096
  %36508 = getelementptr i8, i8 addrspace(1)* %4, i32 %36507
  %36509 = load i8, i8 addrspace(1)* %36508, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36508, align 1, !nosanitize !3
  store i32 1662, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36510 = sub i64 %36502, 784
  store i64 %36510, i64* %remaing_gas, align 4
  %36511 = alloca i256, align 8
  store i256 0, i256* %36511, align 4
  %36512 = alloca i256, align 8
  call void @__device_sload(i256* %36511, i256* %36512)
  %36513 = call i32 @__hashword(i256* %36511)
  %36514 = load i32, i32* %5, align 4
  %36515 = icmp eq i32 %36513, %36514
  %36516 = or i1 false, %36515
  %36517 = load i32, i32* %6, align 4
  %36518 = icmp eq i32 %36513, %36517
  %36519 = or i1 %36516, %36518
  %36520 = load i32, i32* %7, align 4
  %36521 = icmp eq i32 %36513, %36520
  %36522 = or i1 %36519, %36521
  %36523 = load i32, i32* %8, align 4
  %36524 = icmp eq i32 %36513, %36523
  %36525 = or i1 %36522, %36524
  %36526 = load i32, i32* %9, align 4
  %36527 = icmp eq i32 %36513, %36526
  %36528 = or i1 %36525, %36527
  %36529 = load i32, i32* %10, align 4
  %36530 = icmp eq i32 %36513, %36529
  %36531 = or i1 %36528, %36530
  %36532 = load i32, i32* %11, align 4
  %36533 = icmp eq i32 %36513, %36532
  %36534 = or i1 %36531, %36533
  %36535 = load i32, i32* %12, align 4
  %36536 = icmp eq i32 %36513, %36535
  %36537 = or i1 %36534, %36536
  %36538 = load i32, i32* %13, align 4
  %36539 = icmp eq i32 %36513, %36538
  %36540 = or i1 %36537, %36539
  %36541 = load i32, i32* %14, align 4
  %36542 = icmp eq i32 %36513, %36541
  %36543 = or i1 %36540, %36542
  %36544 = load i32, i32* %15, align 4
  %36545 = icmp eq i32 %36513, %36544
  %36546 = or i1 %36543, %36545
  %36547 = load i32, i32* %16, align 4
  %36548 = icmp eq i32 %36513, %36547
  %36549 = or i1 %36546, %36548
  %36550 = load i32, i32* %17, align 4
  %36551 = icmp eq i32 %36513, %36550
  %36552 = or i1 %36549, %36551
  %36553 = load i32, i32* %18, align 4
  %36554 = icmp eq i32 %36513, %36553
  %36555 = or i1 %36552, %36554
  %36556 = load i32, i32* %19, align 4
  %36557 = icmp eq i32 %36513, %36556
  %36558 = or i1 %36555, %36557
  %36559 = load i32, i32* %20, align 4
  %36560 = icmp eq i32 %36513, %36559
  %36561 = or i1 %36558, %36560
  %36562 = load i32, i32* %21, align 4
  %36563 = icmp eq i32 %36513, %36562
  %36564 = or i1 %36561, %36563
  %36565 = load i32, i32* %22, align 4
  %36566 = icmp eq i32 %36513, %36565
  %36567 = or i1 %36564, %36566
  %36568 = load i32, i32* %23, align 4
  %36569 = icmp eq i32 %36513, %36568
  %36570 = or i1 %36567, %36569
  %36571 = load i32, i32* %24, align 4
  %36572 = icmp eq i32 %36513, %36571
  %36573 = or i1 %36570, %36572
  %36574 = load i32, i32* %25, align 4
  %36575 = icmp eq i32 %36513, %36574
  %36576 = or i1 %36573, %36575
  %36577 = load i32, i32* %26, align 4
  %36578 = icmp eq i32 %36513, %36577
  %36579 = or i1 %36576, %36578
  %36580 = load i32, i32* %27, align 4
  %36581 = icmp eq i32 %36513, %36580
  %36582 = or i1 %36579, %36581
  %36583 = load i32, i32* %28, align 4
  %36584 = icmp eq i32 %36513, %36583
  %36585 = or i1 %36582, %36584
  %36586 = load i32, i32* %29, align 4
  %36587 = icmp eq i32 %36513, %36586
  %36588 = or i1 %36585, %36587
  %36589 = load i32, i32* %30, align 4
  %36590 = icmp eq i32 %36513, %36589
  %36591 = or i1 %36588, %36590
  %36592 = load i32, i32* %31, align 4
  %36593 = icmp eq i32 %36513, %36592
  %36594 = or i1 %36591, %36593
  %36595 = load i32, i32* %32, align 4
  %36596 = icmp eq i32 %36513, %36595
  %36597 = or i1 %36594, %36596
  %36598 = load i32, i32* %33, align 4
  %36599 = icmp eq i32 %36513, %36598
  %36600 = or i1 %36597, %36599
  %36601 = load i32, i32* %34, align 4
  %36602 = icmp eq i32 %36513, %36601
  %36603 = or i1 %36600, %36602
  %36604 = load i32, i32* %35, align 4
  %36605 = icmp eq i32 %36513, %36604
  %36606 = or i1 %36603, %36605
  %36607 = load i32, i32* %36, align 4
  %36608 = icmp eq i32 %36513, %36607
  %36609 = or i1 %36606, %36608
  %36610 = load i32, i32* %37, align 4
  %36611 = icmp eq i32 %36513, %36610
  %36612 = or i1 %36609, %36611
  %36613 = load i32, i32* %38, align 4
  %36614 = icmp eq i32 %36513, %36613
  %36615 = or i1 %36612, %36614
  %36616 = load i32, i32* %39, align 4
  %36617 = icmp eq i32 %36513, %36616
  %36618 = or i1 %36615, %36617
  %36619 = load i32, i32* %40, align 4
  %36620 = icmp eq i32 %36513, %36619
  %36621 = or i1 %36618, %36620
  %36622 = load i32, i32* %41, align 4
  %36623 = icmp eq i32 %36513, %36622
  %36624 = or i1 %36621, %36623
  %36625 = load i32, i32* %42, align 4
  %36626 = icmp eq i32 %36513, %36625
  %36627 = or i1 %36624, %36626
  %36628 = load i32, i32* %43, align 4
  %36629 = icmp eq i32 %36513, %36628
  %36630 = or i1 %36627, %36629
  %36631 = load i32, i32* %44, align 4
  %36632 = icmp eq i32 %36513, %36631
  %36633 = or i1 %36630, %36632
  %36634 = load i32, i32* %45, align 4
  %36635 = icmp eq i32 %36513, %36634
  %36636 = or i1 %36633, %36635
  %36637 = load i32, i32* %46, align 4
  %36638 = icmp eq i32 %36513, %36637
  %36639 = or i1 %36636, %36638
  %36640 = load i32, i32* %47, align 4
  %36641 = icmp eq i32 %36513, %36640
  %36642 = or i1 %36639, %36641
  %36643 = load i32, i32* %48, align 4
  %36644 = icmp eq i32 %36513, %36643
  %36645 = or i1 %36642, %36644
  %36646 = load i32, i32* %49, align 4
  %36647 = icmp eq i32 %36513, %36646
  %36648 = or i1 %36645, %36647
  %36649 = load i32, i32* %50, align 4
  %36650 = icmp eq i32 %36513, %36649
  %36651 = or i1 %36648, %36650
  %36652 = load i32, i32* %51, align 4
  %36653 = icmp eq i32 %36513, %36652
  %36654 = or i1 %36651, %36653
  %36655 = load i32, i32* %52, align 4
  %36656 = icmp eq i32 %36513, %36655
  %36657 = or i1 %36654, %36656
  %36658 = load i32, i32* %53, align 4
  %36659 = icmp eq i32 %36513, %36658
  %36660 = or i1 %36657, %36659
  %36661 = load i32, i32* %54, align 4
  %36662 = icmp eq i32 %36513, %36661
  %36663 = or i1 %36660, %36662
  %36664 = load i32, i32* %55, align 4
  %36665 = icmp eq i32 %36513, %36664
  %36666 = or i1 %36663, %36665
  %36667 = load i32, i32* %56, align 4
  %36668 = icmp eq i32 %36513, %36667
  %36669 = or i1 %36666, %36668
  %36670 = load i32, i32* %57, align 4
  %36671 = icmp eq i32 %36513, %36670
  %36672 = or i1 %36669, %36671
  %36673 = load i32, i32* %58, align 4
  %36674 = icmp eq i32 %36513, %36673
  %36675 = or i1 %36672, %36674
  %36676 = load i32, i32* %59, align 4
  %36677 = icmp eq i32 %36513, %36676
  %36678 = or i1 %36675, %36677
  %36679 = load i32, i32* %60, align 4
  %36680 = icmp eq i32 %36513, %36679
  %36681 = or i1 %36678, %36680
  %36682 = load i32, i32* %61, align 4
  %36683 = icmp eq i32 %36513, %36682
  %36684 = or i1 %36681, %36683
  %36685 = load i32, i32* %62, align 4
  %36686 = icmp eq i32 %36513, %36685
  %36687 = or i1 %36684, %36686
  %36688 = getelementptr i8, i8 addrspace(1)* %4, i32 135
  %36689 = zext i1 %36687 to i8
  store i8 %36689, i8 addrspace(1)* %36688, align 1, !nosanitize !3
  %36690 = load i256, i256* %36512, align 4
  %36691 = alloca i256, align 8
  store i256 %36690, i256* %36691, align 4
  %36692 = alloca i256, align 8
  store i256 1, i256* %36692, align 4
  %36693 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %36691, i256* %36692, i256* %36693), !pc !518, !intsan !6
  %36694 = load i256, i256* %36693, align 4
  %36695 = and i256 1461501637330902918203684832716283019655932542975, %36694
  %36696 = and i256 1461501637330902918203684832716283019655932542975, %36695
  %36697 = trunc i256 64 to i64
  %36698 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %36697, i256* %36698)
  %36699 = load i256, i256* %36698, align 4
  %36700 = and i256 4294967295, 952911921
  %36701 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %36700, !pc !519, !intsan !45
  %36702 = trunc i256 %36699 to i64
  %36703 = alloca i256, align 8
  store i256 %36701, i256* %36703, align 4
  %36704 = bitcast i256* %36703 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %36702, i8* %36704, i64 32)
  %36705 = add i256 4, %36699, !pc !520, !intsan !10
  %36706 = trunc i256 64 to i64
  %36707 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %36706, i256* %36707)
  %36708 = load i256, i256* %36707, align 4
  %36709 = sub i256 %36705, %36708, !pc !521, !intsan !8
  %36710 = icmp eq i256 1, 0
  %36711 = icmp eq i1 %36710, false
  %36712 = trunc i256 12087 to i64
  %jump.check67 = icmp ne i1 %36711, false
  %36713 = load i64, i64* %STACK_DEP_PTR, align 4
  %36714 = add i64 %36713, 1
  store i64 %36714, i64* %STACK_DEP_PTR, align 4
  %36715 = load i64, i64* %STACK_DEP_PTR, align 4
  %36716 = getelementptr i256, i256* %STACK, i64 %36715
  store i256 %36696, i256* %36716, align 4
  %36717 = load i64, i64* %STACK_DEP_PTR, align 4
  %36718 = add i64 %36717, 1
  store i64 %36718, i64* %STACK_DEP_PTR, align 4
  %36719 = load i64, i64* %STACK_DEP_PTR, align 4
  %36720 = getelementptr i256, i256* %STACK, i64 %36719
  store i256 952911921, i256* %36720, align 4
  %36721 = load i64, i64* %STACK_DEP_PTR, align 4
  %36722 = add i64 %36721, 1
  store i64 %36722, i64* %STACK_DEP_PTR, align 4
  %36723 = load i64, i64* %STACK_DEP_PTR, align 4
  %36724 = getelementptr i256, i256* %STACK, i64 %36723
  store i256 %36705, i256* %36724, align 4
  %36725 = load i64, i64* %STACK_DEP_PTR, align 4
  %36726 = add i64 %36725, 1
  store i64 %36726, i64* %STACK_DEP_PTR, align 4
  %36727 = load i64, i64* %STACK_DEP_PTR, align 4
  %36728 = getelementptr i256, i256* %STACK, i64 %36727
  store i256 32, i256* %36728, align 4
  %36729 = load i64, i64* %STACK_DEP_PTR, align 4
  %36730 = add i64 %36729, 1
  store i64 %36730, i64* %STACK_DEP_PTR, align 4
  %36731 = load i64, i64* %STACK_DEP_PTR, align 4
  %36732 = getelementptr i256, i256* %STACK, i64 %36731
  store i256 %36708, i256* %36732, align 4
  %36733 = load i64, i64* %STACK_DEP_PTR, align 4
  %36734 = add i64 %36733, 1
  store i64 %36734, i64* %STACK_DEP_PTR, align 4
  %36735 = load i64, i64* %STACK_DEP_PTR, align 4
  %36736 = getelementptr i256, i256* %STACK, i64 %36735
  store i256 %36709, i256* %36736, align 4
  %36737 = load i64, i64* %STACK_DEP_PTR, align 4
  %36738 = add i64 %36737, 1
  store i64 %36738, i64* %STACK_DEP_PTR, align 4
  %36739 = load i64, i64* %STACK_DEP_PTR, align 4
  %36740 = getelementptr i256, i256* %STACK, i64 %36739
  store i256 %36708, i256* %36740, align 4
  %36741 = load i64, i64* %STACK_DEP_PTR, align 4
  %36742 = add i64 %36741, 1
  store i64 %36742, i64* %STACK_DEP_PTR, align 4
  %36743 = load i64, i64* %STACK_DEP_PTR, align 4
  %36744 = getelementptr i256, i256* %STACK, i64 %36743
  store i256 0, i256* %36744, align 4
  %36745 = load i64, i64* %STACK_DEP_PTR, align 4
  %36746 = add i64 %36745, 1
  store i64 %36746, i64* %STACK_DEP_PTR, align 4
  %36747 = load i64, i64* %STACK_DEP_PTR, align 4
  %36748 = getelementptr i256, i256* %STACK, i64 %36747
  store i256 %36696, i256* %36748, align 4
  %36749 = load i64, i64* %STACK_DEP_PTR, align 4
  %36750 = add i64 %36749, 1
  store i64 %36750, i64* %STACK_DEP_PTR, align 4
  %36751 = zext i1 %36710 to i256
  %36752 = load i64, i64* %STACK_DEP_PTR, align 4
  %36753 = getelementptr i256, i256* %STACK, i64 %36752
  store i256 %36751, i256* %36753, align 4
  br i1 %jump.check67, label %.12087, label %.12083, !EVMBB !4

.12083:                                           ; preds = %36504
  %36754 = load i64, i64* %remaing_gas, align 4
  %36755 = icmp ugt i64 40, %36754
  br i1 %36755, label %Abort, label %36756

36756:                                            ; preds = %.12083
  %36757 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36758 = xor i32 %36757, 1508
  %36759 = urem i32 %36758, 4096
  %36760 = getelementptr i8, i8 addrspace(1)* %4, i32 %36759
  %36761 = load i8, i8 addrspace(1)* %36760, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36760, align 1, !nosanitize !3
  store i32 754, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36762 = sub i64 %36754, 40
  store i64 %36762, i64* %remaing_gas, align 4
  %36763 = load i64, i64* %STACK_DEP_PTR, align 4
  %36764 = sub i64 %36763, 0
  store i64 %36764, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.12087:                                           ; preds = %36504, %JumpTable
  %36765 = load i64, i64* %remaing_gas, align 4
  %36766 = icmp ugt i64 456, %36765
  br i1 %36766, label %Abort, label %36767

36767:                                            ; preds = %.12087
  %36768 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36769 = xor i32 %36768, 3174
  %36770 = urem i32 %36769, 4096
  %36771 = getelementptr i8, i8 addrspace(1)* %4, i32 %36770
  %36772 = load i8, i8 addrspace(1)* %36771, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36771, align 1, !nosanitize !3
  store i32 1587, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36773 = sub i64 %36765, 456
  store i64 %36773, i64* %remaing_gas, align 4
  %36774 = load i64, i64* %STACK_DEP_PTR, align 4
  %36775 = getelementptr i256, i256* %STACK, i64 %36774
  %36776 = load i256, i256* %36775, align 4
  %36777 = load i64, i64* %STACK_DEP_PTR, align 4
  %36778 = sub i64 %36777, 1
  store i64 %36778, i64* %STACK_DEP_PTR, align 4
  %36779 = load i64, i64* %STACK_DEP_PTR, align 4
  %36780 = getelementptr i256, i256* %STACK, i64 %36779
  %36781 = load i256, i256* %36780, align 4
  %36782 = load i64, i64* %STACK_DEP_PTR, align 4
  %36783 = sub i64 %36782, 1
  store i64 %36783, i64* %STACK_DEP_PTR, align 4
  %36784 = load i64, i64* %STACK_DEP_PTR, align 4
  %36785 = getelementptr i256, i256* %STACK, i64 %36784
  %36786 = load i256, i256* %36785, align 4
  %36787 = load i64, i64* %STACK_DEP_PTR, align 4
  %36788 = sub i64 %36787, 1
  store i64 %36788, i64* %STACK_DEP_PTR, align 4
  %36789 = load i64, i64* %STACK_DEP_PTR, align 4
  %36790 = getelementptr i256, i256* %STACK, i64 %36789
  %36791 = load i256, i256* %36790, align 4
  %36792 = load i64, i64* %STACK_DEP_PTR, align 4
  %36793 = sub i64 %36792, 1
  store i64 %36793, i64* %STACK_DEP_PTR, align 4
  %36794 = load i64, i64* %STACK_DEP_PTR, align 4
  %36795 = getelementptr i256, i256* %STACK, i64 %36794
  %36796 = load i256, i256* %36795, align 4
  %36797 = load i64, i64* %STACK_DEP_PTR, align 4
  %36798 = sub i64 %36797, 1
  store i64 %36798, i64* %STACK_DEP_PTR, align 4
  %36799 = load i64, i64* %STACK_DEP_PTR, align 4
  %36800 = getelementptr i256, i256* %STACK, i64 %36799
  %36801 = load i256, i256* %36800, align 4
  %36802 = load i64, i64* %STACK_DEP_PTR, align 4
  %36803 = sub i64 %36802, 1
  store i64 %36803, i64* %STACK_DEP_PTR, align 4
  %36804 = load i64, i64* %STACK_DEP_PTR, align 4
  %36805 = getelementptr i256, i256* %STACK, i64 %36804
  %36806 = load i256, i256* %36805, align 4
  %36807 = load i64, i64* %STACK_DEP_PTR, align 4
  %36808 = sub i64 %36807, 1
  store i64 %36808, i64* %STACK_DEP_PTR, align 4
  %36809 = trunc i256 %36781 to i160
  %36810 = call i1 @solidity_call(), !pc !522
  %36811 = icmp eq i1 %36810, false
  %36812 = icmp eq i1 %36811, false
  %36813 = trunc i256 12107 to i64
  %jump.check72 = icmp ne i1 %36812, false
  %36814 = load i64, i64* %STACK_DEP_PTR, align 4
  %36815 = add i64 %36814, 1
  store i64 %36815, i64* %STACK_DEP_PTR, align 4
  %36816 = zext i1 %36811 to i256
  %36817 = load i64, i64* %STACK_DEP_PTR, align 4
  %36818 = getelementptr i256, i256* %STACK, i64 %36817
  store i256 %36816, i256* %36818, align 4
  br i1 %jump.check72, label %.12107, label %.12098, !EVMBB !4

.12098:                                           ; preds = %36767
  %36819 = load i64, i64* %remaing_gas, align 4
  %36820 = icmp ugt i64 40, %36819
  br i1 %36820, label %Abort, label %36821

36821:                                            ; preds = %.12098
  %36822 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36823 = xor i32 %36822, 4058
  %36824 = urem i32 %36823, 4096
  %36825 = getelementptr i8, i8 addrspace(1)* %4, i32 %36824
  %36826 = load i8, i8 addrspace(1)* %36825, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36825, align 1, !nosanitize !3
  store i32 2029, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36827 = sub i64 %36819, 40
  store i64 %36827, i64* %remaing_gas, align 4
  %36828 = load i64, i64* %STACK_DEP_PTR, align 4
  %36829 = sub i64 %36828, 0
  store i64 %36829, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.12107:                                           ; preds = %36767, %JumpTable
  %36830 = load i64, i64* %remaing_gas, align 4
  %36831 = icmp ugt i64 384, %36830
  br i1 %36831, label %Abort, label %36832

36832:                                            ; preds = %.12107
  %36833 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36834 = xor i32 %36833, 2657
  %36835 = urem i32 %36834, 4096
  %36836 = getelementptr i8, i8 addrspace(1)* %4, i32 %36835
  %36837 = load i8, i8 addrspace(1)* %36836, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36836, align 1, !nosanitize !3
  store i32 1328, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36838 = sub i64 %36830, 384
  store i64 %36838, i64* %remaing_gas, align 4
  %36839 = load i64, i64* %STACK_DEP_PTR, align 4
  %36840 = getelementptr i256, i256* %STACK, i64 %36839
  %36841 = load i256, i256* %36840, align 4
  %36842 = load i64, i64* %STACK_DEP_PTR, align 4
  %36843 = sub i64 %36842, 1
  store i64 %36843, i64* %STACK_DEP_PTR, align 4
  %36844 = load i64, i64* %STACK_DEP_PTR, align 4
  %36845 = getelementptr i256, i256* %STACK, i64 %36844
  %36846 = load i256, i256* %36845, align 4
  %36847 = load i64, i64* %STACK_DEP_PTR, align 4
  %36848 = sub i64 %36847, 1
  store i64 %36848, i64* %STACK_DEP_PTR, align 4
  %36849 = load i64, i64* %STACK_DEP_PTR, align 4
  %36850 = getelementptr i256, i256* %STACK, i64 %36849
  %36851 = load i256, i256* %36850, align 4
  %36852 = load i64, i64* %STACK_DEP_PTR, align 4
  %36853 = sub i64 %36852, 1
  store i64 %36853, i64* %STACK_DEP_PTR, align 4
  %36854 = load i64, i64* %STACK_DEP_PTR, align 4
  %36855 = getelementptr i256, i256* %STACK, i64 %36854
  %36856 = load i256, i256* %36855, align 4
  %36857 = load i64, i64* %STACK_DEP_PTR, align 4
  %36858 = sub i64 %36857, 1
  store i64 %36858, i64* %STACK_DEP_PTR, align 4
  %36859 = trunc i256 64 to i64
  %36860 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %36859, i256* %36860)
  %36861 = load i256, i256* %36860, align 4
  %36862 = zext i64 0 to i256
  %36863 = icmp ult i256 %36862, 32
  %36864 = icmp eq i1 %36863, false
  %36865 = trunc i256 12129 to i64
  %jump.check77 = icmp ne i1 %36864, false
  %36866 = load i64, i64* %STACK_DEP_PTR, align 4
  %36867 = add i64 %36866, 1
  store i64 %36867, i64* %STACK_DEP_PTR, align 4
  %36868 = load i64, i64* %STACK_DEP_PTR, align 4
  %36869 = getelementptr i256, i256* %STACK, i64 %36868
  store i256 %36861, i256* %36869, align 4
  %36870 = load i64, i64* %STACK_DEP_PTR, align 4
  %36871 = add i64 %36870, 1
  store i64 %36871, i64* %STACK_DEP_PTR, align 4
  %36872 = zext i64 0 to i256
  %36873 = load i64, i64* %STACK_DEP_PTR, align 4
  %36874 = getelementptr i256, i256* %STACK, i64 %36873
  store i256 %36872, i256* %36874, align 4
  br i1 %jump.check77, label %.12129, label %.12125, !EVMBB !4

.12125:                                           ; preds = %36832
  %36875 = load i64, i64* %remaing_gas, align 4
  %36876 = icmp ugt i64 40, %36875
  br i1 %36876, label %Abort, label %36877

36877:                                            ; preds = %.12125
  %36878 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36879 = xor i32 %36878, 3083
  %36880 = urem i32 %36879, 4096
  %36881 = getelementptr i8, i8 addrspace(1)* %4, i32 %36880
  %36882 = load i8, i8 addrspace(1)* %36881, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %36881, align 1, !nosanitize !3
  store i32 1541, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %36883 = sub i64 %36875, 40
  store i64 %36883, i64* %remaing_gas, align 4
  %36884 = load i64, i64* %STACK_DEP_PTR, align 4
  %36885 = sub i64 %36884, 0
  store i64 %36885, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.12129:                                           ; preds = %36832, %JumpTable
  %36886 = load i64, i64* %STACK_DEP_PTR, align 4
  %36887 = getelementptr i256, i256* %STACK, i64 %36886
  %36888 = load i256, i256* %36887, align 4
  %36889 = load i64, i64* %STACK_DEP_PTR, align 4
  %36890 = sub i64 %36889, 1
  store i64 %36890, i64* %STACK_DEP_PTR, align 4
  %36891 = load i64, i64* %STACK_DEP_PTR, align 4
  %36892 = getelementptr i256, i256* %STACK, i64 %36891
  %36893 = load i256, i256* %36892, align 4
  %36894 = load i64, i64* %STACK_DEP_PTR, align 4
  %36895 = sub i64 %36894, 1
  store i64 %36895, i64* %STACK_DEP_PTR, align 4
  %36896 = load i64, i64* %STACK_DEP_PTR, align 4
  %36897 = getelementptr i256, i256* %STACK, i64 %36896
  %36898 = load i256, i256* %36897, align 4
  %36899 = load i64, i64* %STACK_DEP_PTR, align 4
  %36900 = sub i64 %36899, 1
  store i64 %36900, i64* %STACK_DEP_PTR, align 4
  %36901 = load i64, i64* %STACK_DEP_PTR, align 4
  %36902 = getelementptr i256, i256* %STACK, i64 %36901
  %36903 = load i256, i256* %36902, align 4
  %36904 = load i64, i64* %STACK_DEP_PTR, align 4
  %36905 = sub i64 %36904, 1
  store i64 %36905, i64* %STACK_DEP_PTR, align 4
  %36906 = load i64, i64* %STACK_DEP_PTR, align 4
  %36907 = getelementptr i256, i256* %STACK, i64 %36906
  %36908 = load i256, i256* %36907, align 4
  %36909 = load i64, i64* %STACK_DEP_PTR, align 4
  %36910 = sub i64 %36909, 1
  store i64 %36910, i64* %STACK_DEP_PTR, align 4
  %36911 = load i64, i64* %STACK_DEP_PTR, align 4
  %36912 = getelementptr i256, i256* %STACK, i64 %36911
  %36913 = load i256, i256* %36912, align 4
  %36914 = load i64, i64* %STACK_DEP_PTR, align 4
  %36915 = sub i64 %36914, 1
  store i64 %36915, i64* %STACK_DEP_PTR, align 4
  %36916 = load i64, i64* %STACK_DEP_PTR, align 4
  %36917 = getelementptr i256, i256* %STACK, i64 %36916
  %36918 = load i256, i256* %36917, align 4
  %36919 = load i64, i64* %STACK_DEP_PTR, align 4
  %36920 = sub i64 %36919, 1
  store i64 %36920, i64* %STACK_DEP_PTR, align 4
  %36921 = add i256 %36893, %36888, !pc !523, !intsan !10
  %36922 = trunc i256 %36893 to i64
  %36923 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %36922, i256* %36923)
  %36924 = load i256, i256* %36923, align 4
  %36925 = add i256 32, %36893, !pc !524, !intsan !10
  %36926 = alloca i256, align 8
  store i256 1, i256* %36926, align 4
  %36927 = alloca i256, align 8
  call void @__device_sload(i256* %36926, i256* %36927)
  %36928 = call i32 @__hashword(i256* %36926)
  %36929 = load i32, i32* %5, align 4
  %36930 = icmp eq i32 %36928, %36929
  %36931 = or i1 false, %36930
  %36932 = load i32, i32* %6, align 4
  %36933 = icmp eq i32 %36928, %36932
  %36934 = or i1 %36931, %36933
  %36935 = load i32, i32* %7, align 4
  %36936 = icmp eq i32 %36928, %36935
  %36937 = or i1 %36934, %36936
  %36938 = load i32, i32* %8, align 4
  %36939 = icmp eq i32 %36928, %36938
  %36940 = or i1 %36937, %36939
  %36941 = load i32, i32* %9, align 4
  %36942 = icmp eq i32 %36928, %36941
  %36943 = or i1 %36940, %36942
  %36944 = load i32, i32* %10, align 4
  %36945 = icmp eq i32 %36928, %36944
  %36946 = or i1 %36943, %36945
  %36947 = load i32, i32* %11, align 4
  %36948 = icmp eq i32 %36928, %36947
  %36949 = or i1 %36946, %36948
  %36950 = load i32, i32* %12, align 4
  %36951 = icmp eq i32 %36928, %36950
  %36952 = or i1 %36949, %36951
  %36953 = load i32, i32* %13, align 4
  %36954 = icmp eq i32 %36928, %36953
  %36955 = or i1 %36952, %36954
  %36956 = load i32, i32* %14, align 4
  %36957 = icmp eq i32 %36928, %36956
  %36958 = or i1 %36955, %36957
  %36959 = load i32, i32* %15, align 4
  %36960 = icmp eq i32 %36928, %36959
  %36961 = or i1 %36958, %36960
  %36962 = load i32, i32* %16, align 4
  %36963 = icmp eq i32 %36928, %36962
  %36964 = or i1 %36961, %36963
  %36965 = load i32, i32* %17, align 4
  %36966 = icmp eq i32 %36928, %36965
  %36967 = or i1 %36964, %36966
  %36968 = load i32, i32* %18, align 4
  %36969 = icmp eq i32 %36928, %36968
  %36970 = or i1 %36967, %36969
  %36971 = load i32, i32* %19, align 4
  %36972 = icmp eq i32 %36928, %36971
  %36973 = or i1 %36970, %36972
  %36974 = load i32, i32* %20, align 4
  %36975 = icmp eq i32 %36928, %36974
  %36976 = or i1 %36973, %36975
  %36977 = load i32, i32* %21, align 4
  %36978 = icmp eq i32 %36928, %36977
  %36979 = or i1 %36976, %36978
  %36980 = load i32, i32* %22, align 4
  %36981 = icmp eq i32 %36928, %36980
  %36982 = or i1 %36979, %36981
  %36983 = load i32, i32* %23, align 4
  %36984 = icmp eq i32 %36928, %36983
  %36985 = or i1 %36982, %36984
  %36986 = load i32, i32* %24, align 4
  %36987 = icmp eq i32 %36928, %36986
  %36988 = or i1 %36985, %36987
  %36989 = load i32, i32* %25, align 4
  %36990 = icmp eq i32 %36928, %36989
  %36991 = or i1 %36988, %36990
  %36992 = load i32, i32* %26, align 4
  %36993 = icmp eq i32 %36928, %36992
  %36994 = or i1 %36991, %36993
  %36995 = load i32, i32* %27, align 4
  %36996 = icmp eq i32 %36928, %36995
  %36997 = or i1 %36994, %36996
  %36998 = load i32, i32* %28, align 4
  %36999 = icmp eq i32 %36928, %36998
  %37000 = or i1 %36997, %36999
  %37001 = load i32, i32* %29, align 4
  %37002 = icmp eq i32 %36928, %37001
  %37003 = or i1 %37000, %37002
  %37004 = load i32, i32* %30, align 4
  %37005 = icmp eq i32 %36928, %37004
  %37006 = or i1 %37003, %37005
  %37007 = load i32, i32* %31, align 4
  %37008 = icmp eq i32 %36928, %37007
  %37009 = or i1 %37006, %37008
  %37010 = load i32, i32* %32, align 4
  %37011 = icmp eq i32 %36928, %37010
  %37012 = or i1 %37009, %37011
  %37013 = load i32, i32* %33, align 4
  %37014 = icmp eq i32 %36928, %37013
  %37015 = or i1 %37012, %37014
  %37016 = load i32, i32* %34, align 4
  %37017 = icmp eq i32 %36928, %37016
  %37018 = or i1 %37015, %37017
  %37019 = load i32, i32* %35, align 4
  %37020 = icmp eq i32 %36928, %37019
  %37021 = or i1 %37018, %37020
  %37022 = load i32, i32* %36, align 4
  %37023 = icmp eq i32 %36928, %37022
  %37024 = or i1 %37021, %37023
  %37025 = load i32, i32* %37, align 4
  %37026 = icmp eq i32 %36928, %37025
  %37027 = or i1 %37024, %37026
  %37028 = load i32, i32* %38, align 4
  %37029 = icmp eq i32 %36928, %37028
  %37030 = or i1 %37027, %37029
  %37031 = load i32, i32* %39, align 4
  %37032 = icmp eq i32 %36928, %37031
  %37033 = or i1 %37030, %37032
  %37034 = load i32, i32* %40, align 4
  %37035 = icmp eq i32 %36928, %37034
  %37036 = or i1 %37033, %37035
  %37037 = load i32, i32* %41, align 4
  %37038 = icmp eq i32 %36928, %37037
  %37039 = or i1 %37036, %37038
  %37040 = load i32, i32* %42, align 4
  %37041 = icmp eq i32 %36928, %37040
  %37042 = or i1 %37039, %37041
  %37043 = load i32, i32* %43, align 4
  %37044 = icmp eq i32 %36928, %37043
  %37045 = or i1 %37042, %37044
  %37046 = load i32, i32* %44, align 4
  %37047 = icmp eq i32 %36928, %37046
  %37048 = or i1 %37045, %37047
  %37049 = load i32, i32* %45, align 4
  %37050 = icmp eq i32 %36928, %37049
  %37051 = or i1 %37048, %37050
  %37052 = load i32, i32* %46, align 4
  %37053 = icmp eq i32 %36928, %37052
  %37054 = or i1 %37051, %37053
  %37055 = load i32, i32* %47, align 4
  %37056 = icmp eq i32 %36928, %37055
  %37057 = or i1 %37054, %37056
  %37058 = load i32, i32* %48, align 4
  %37059 = icmp eq i32 %36928, %37058
  %37060 = or i1 %37057, %37059
  %37061 = load i32, i32* %49, align 4
  %37062 = icmp eq i32 %36928, %37061
  %37063 = or i1 %37060, %37062
  %37064 = load i32, i32* %50, align 4
  %37065 = icmp eq i32 %36928, %37064
  %37066 = or i1 %37063, %37065
  %37067 = load i32, i32* %51, align 4
  %37068 = icmp eq i32 %36928, %37067
  %37069 = or i1 %37066, %37068
  %37070 = load i32, i32* %52, align 4
  %37071 = icmp eq i32 %36928, %37070
  %37072 = or i1 %37069, %37071
  %37073 = load i32, i32* %53, align 4
  %37074 = icmp eq i32 %36928, %37073
  %37075 = or i1 %37072, %37074
  %37076 = load i32, i32* %54, align 4
  %37077 = icmp eq i32 %36928, %37076
  %37078 = or i1 %37075, %37077
  %37079 = load i32, i32* %55, align 4
  %37080 = icmp eq i32 %36928, %37079
  %37081 = or i1 %37078, %37080
  %37082 = load i32, i32* %56, align 4
  %37083 = icmp eq i32 %36928, %37082
  %37084 = or i1 %37081, %37083
  %37085 = load i32, i32* %57, align 4
  %37086 = icmp eq i32 %36928, %37085
  %37087 = or i1 %37084, %37086
  %37088 = load i32, i32* %58, align 4
  %37089 = icmp eq i32 %36928, %37088
  %37090 = or i1 %37087, %37089
  %37091 = load i32, i32* %59, align 4
  %37092 = icmp eq i32 %36928, %37091
  %37093 = or i1 %37090, %37092
  %37094 = load i32, i32* %60, align 4
  %37095 = icmp eq i32 %36928, %37094
  %37096 = or i1 %37093, %37095
  %37097 = load i32, i32* %61, align 4
  %37098 = icmp eq i32 %36928, %37097
  %37099 = or i1 %37096, %37098
  %37100 = load i32, i32* %62, align 4
  %37101 = icmp eq i32 %36928, %37100
  %37102 = or i1 %37099, %37101
  %37103 = getelementptr i8, i8 addrspace(1)* %4, i32 136
  %37104 = zext i1 %37102 to i8
  store i8 %37104, i8 addrspace(1)* %37103, align 1, !nosanitize !3
  %37105 = load i256, i256* %36927, align 4
  %37106 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !525, !intsan !45
  %37107 = xor i256 %37106, -1
  %37108 = and i256 %37107, %37105
  %37109 = and i256 1461501637330902918203684832716283019655932542975, %36924
  %37110 = mul i256 %37109, 1, !pc !526, !intsan !45
  %37111 = or i256 %37110, %37108
  %37112 = alloca i256, align 8
  store i256 1, i256* %37112, align 4
  %37113 = alloca i256, align 8
  store i256 %37111, i256* %37113, align 4
  call void @__device_sstore(i256* %37112, i256* %37113)
  %37114 = call i32 @__hashword(i256* %37112)
  store i32 %37114, i32* %23, align 4, !nosanitize !3
  %37115 = alloca i256, align 8
  store i256 1, i256* %37115, align 4
  %37116 = alloca i256, align 8
  call void @__device_sload(i256* %37115, i256* %37116)
  %37117 = call i32 @__hashword(i256* %37115)
  %37118 = load i32, i32* %5, align 4
  %37119 = icmp eq i32 %37117, %37118
  %37120 = or i1 false, %37119
  %37121 = load i32, i32* %6, align 4
  %37122 = icmp eq i32 %37117, %37121
  %37123 = or i1 %37120, %37122
  %37124 = load i32, i32* %7, align 4
  %37125 = icmp eq i32 %37117, %37124
  %37126 = or i1 %37123, %37125
  %37127 = load i32, i32* %8, align 4
  %37128 = icmp eq i32 %37117, %37127
  %37129 = or i1 %37126, %37128
  %37130 = load i32, i32* %9, align 4
  %37131 = icmp eq i32 %37117, %37130
  %37132 = or i1 %37129, %37131
  %37133 = load i32, i32* %10, align 4
  %37134 = icmp eq i32 %37117, %37133
  %37135 = or i1 %37132, %37134
  %37136 = load i32, i32* %11, align 4
  %37137 = icmp eq i32 %37117, %37136
  %37138 = or i1 %37135, %37137
  %37139 = load i32, i32* %12, align 4
  %37140 = icmp eq i32 %37117, %37139
  %37141 = or i1 %37138, %37140
  %37142 = load i32, i32* %13, align 4
  %37143 = icmp eq i32 %37117, %37142
  %37144 = or i1 %37141, %37143
  %37145 = load i32, i32* %14, align 4
  %37146 = icmp eq i32 %37117, %37145
  %37147 = or i1 %37144, %37146
  %37148 = load i32, i32* %15, align 4
  %37149 = icmp eq i32 %37117, %37148
  %37150 = or i1 %37147, %37149
  %37151 = load i32, i32* %16, align 4
  %37152 = icmp eq i32 %37117, %37151
  %37153 = or i1 %37150, %37152
  %37154 = load i32, i32* %17, align 4
  %37155 = icmp eq i32 %37117, %37154
  %37156 = or i1 %37153, %37155
  %37157 = load i32, i32* %18, align 4
  %37158 = icmp eq i32 %37117, %37157
  %37159 = or i1 %37156, %37158
  %37160 = load i32, i32* %19, align 4
  %37161 = icmp eq i32 %37117, %37160
  %37162 = or i1 %37159, %37161
  %37163 = load i32, i32* %20, align 4
  %37164 = icmp eq i32 %37117, %37163
  %37165 = or i1 %37162, %37164
  %37166 = load i32, i32* %21, align 4
  %37167 = icmp eq i32 %37117, %37166
  %37168 = or i1 %37165, %37167
  %37169 = load i32, i32* %22, align 4
  %37170 = icmp eq i32 %37117, %37169
  %37171 = or i1 %37168, %37170
  %37172 = load i32, i32* %23, align 4
  %37173 = icmp eq i32 %37117, %37172
  %37174 = or i1 %37171, %37173
  %37175 = load i32, i32* %24, align 4
  %37176 = icmp eq i32 %37117, %37175
  %37177 = or i1 %37174, %37176
  %37178 = load i32, i32* %25, align 4
  %37179 = icmp eq i32 %37117, %37178
  %37180 = or i1 %37177, %37179
  %37181 = load i32, i32* %26, align 4
  %37182 = icmp eq i32 %37117, %37181
  %37183 = or i1 %37180, %37182
  %37184 = load i32, i32* %27, align 4
  %37185 = icmp eq i32 %37117, %37184
  %37186 = or i1 %37183, %37185
  %37187 = load i32, i32* %28, align 4
  %37188 = icmp eq i32 %37117, %37187
  %37189 = or i1 %37186, %37188
  %37190 = load i32, i32* %29, align 4
  %37191 = icmp eq i32 %37117, %37190
  %37192 = or i1 %37189, %37191
  %37193 = load i32, i32* %30, align 4
  %37194 = icmp eq i32 %37117, %37193
  %37195 = or i1 %37192, %37194
  %37196 = load i32, i32* %31, align 4
  %37197 = icmp eq i32 %37117, %37196
  %37198 = or i1 %37195, %37197
  %37199 = load i32, i32* %32, align 4
  %37200 = icmp eq i32 %37117, %37199
  %37201 = or i1 %37198, %37200
  %37202 = load i32, i32* %33, align 4
  %37203 = icmp eq i32 %37117, %37202
  %37204 = or i1 %37201, %37203
  %37205 = load i32, i32* %34, align 4
  %37206 = icmp eq i32 %37117, %37205
  %37207 = or i1 %37204, %37206
  %37208 = load i32, i32* %35, align 4
  %37209 = icmp eq i32 %37117, %37208
  %37210 = or i1 %37207, %37209
  %37211 = load i32, i32* %36, align 4
  %37212 = icmp eq i32 %37117, %37211
  %37213 = or i1 %37210, %37212
  %37214 = load i32, i32* %37, align 4
  %37215 = icmp eq i32 %37117, %37214
  %37216 = or i1 %37213, %37215
  %37217 = load i32, i32* %38, align 4
  %37218 = icmp eq i32 %37117, %37217
  %37219 = or i1 %37216, %37218
  %37220 = load i32, i32* %39, align 4
  %37221 = icmp eq i32 %37117, %37220
  %37222 = or i1 %37219, %37221
  %37223 = load i32, i32* %40, align 4
  %37224 = icmp eq i32 %37117, %37223
  %37225 = or i1 %37222, %37224
  %37226 = load i32, i32* %41, align 4
  %37227 = icmp eq i32 %37117, %37226
  %37228 = or i1 %37225, %37227
  %37229 = load i32, i32* %42, align 4
  %37230 = icmp eq i32 %37117, %37229
  %37231 = or i1 %37228, %37230
  %37232 = load i32, i32* %43, align 4
  %37233 = icmp eq i32 %37117, %37232
  %37234 = or i1 %37231, %37233
  %37235 = load i32, i32* %44, align 4
  %37236 = icmp eq i32 %37117, %37235
  %37237 = or i1 %37234, %37236
  %37238 = load i32, i32* %45, align 4
  %37239 = icmp eq i32 %37117, %37238
  %37240 = or i1 %37237, %37239
  %37241 = load i32, i32* %46, align 4
  %37242 = icmp eq i32 %37117, %37241
  %37243 = or i1 %37240, %37242
  %37244 = load i32, i32* %47, align 4
  %37245 = icmp eq i32 %37117, %37244
  %37246 = or i1 %37243, %37245
  %37247 = load i32, i32* %48, align 4
  %37248 = icmp eq i32 %37117, %37247
  %37249 = or i1 %37246, %37248
  %37250 = load i32, i32* %49, align 4
  %37251 = icmp eq i32 %37117, %37250
  %37252 = or i1 %37249, %37251
  %37253 = load i32, i32* %50, align 4
  %37254 = icmp eq i32 %37117, %37253
  %37255 = or i1 %37252, %37254
  %37256 = load i32, i32* %51, align 4
  %37257 = icmp eq i32 %37117, %37256
  %37258 = or i1 %37255, %37257
  %37259 = load i32, i32* %52, align 4
  %37260 = icmp eq i32 %37117, %37259
  %37261 = or i1 %37258, %37260
  %37262 = load i32, i32* %53, align 4
  %37263 = icmp eq i32 %37117, %37262
  %37264 = or i1 %37261, %37263
  %37265 = load i32, i32* %54, align 4
  %37266 = icmp eq i32 %37117, %37265
  %37267 = or i1 %37264, %37266
  %37268 = load i32, i32* %55, align 4
  %37269 = icmp eq i32 %37117, %37268
  %37270 = or i1 %37267, %37269
  %37271 = load i32, i32* %56, align 4
  %37272 = icmp eq i32 %37117, %37271
  %37273 = or i1 %37270, %37272
  %37274 = load i32, i32* %57, align 4
  %37275 = icmp eq i32 %37117, %37274
  %37276 = or i1 %37273, %37275
  %37277 = load i32, i32* %58, align 4
  %37278 = icmp eq i32 %37117, %37277
  %37279 = or i1 %37276, %37278
  %37280 = load i32, i32* %59, align 4
  %37281 = icmp eq i32 %37117, %37280
  %37282 = or i1 %37279, %37281
  %37283 = load i32, i32* %60, align 4
  %37284 = icmp eq i32 %37117, %37283
  %37285 = or i1 %37282, %37284
  %37286 = load i32, i32* %61, align 4
  %37287 = icmp eq i32 %37117, %37286
  %37288 = or i1 %37285, %37287
  %37289 = load i32, i32* %62, align 4
  %37290 = icmp eq i32 %37117, %37289
  %37291 = or i1 %37288, %37290
  %37292 = getelementptr i8, i8 addrspace(1)* %4, i32 137
  %37293 = zext i1 %37291 to i8
  store i8 %37293, i8 addrspace(1)* %37292, align 1, !nosanitize !3
  %37294 = load i256, i256* %37116, align 4
  %37295 = alloca i256, align 8
  store i256 %37294, i256* %37295, align 4
  %37296 = alloca i256, align 8
  store i256 1, i256* %37296, align 4
  %37297 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %37295, i256* %37296, i256* %37297), !pc !527, !intsan !6
  %37298 = load i256, i256* %37297, align 4
  %37299 = and i256 1461501637330902918203684832716283019655932542975, %37298
  %37300 = and i256 1461501637330902918203684832716283019655932542975, %37299
  %37301 = trunc i256 64 to i64
  %37302 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37301, i256* %37302)
  %37303 = load i256, i256* %37302, align 4
  %37304 = and i256 4294967295, 787721420
  %37305 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %37304, !pc !528, !intsan !45
  %37306 = trunc i256 %37303 to i64
  %37307 = alloca i256, align 8
  store i256 %37305, i256* %37307, align 4
  %37308 = bitcast i256* %37307 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37306, i8* %37308, i64 32)
  %37309 = add i256 4, %37303, !pc !529, !intsan !10
  %37310 = add i256 32, %37309, !pc !530, !intsan !10
  %37311 = trunc i256 %37310 to i64
  %37312 = alloca i256, align 8
  store i256 %36908, i256* %37312, align 4
  %37313 = bitcast i256* %37312 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37311, i8* %37313, i64 32)
  %37314 = add i256 32, %37310, !pc !531, !intsan !10
  %37315 = sub i256 %37314, %37309, !pc !532, !intsan !8
  %37316 = trunc i256 %37309 to i64
  %37317 = alloca i256, align 8
  store i256 %37315, i256* %37317, align 4
  %37318 = bitcast i256* %37317 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37316, i8* %37318, i64 32)
  %37319 = trunc i256 %36918 to i64
  %37320 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37319, i256* %37320)
  %37321 = load i256, i256* %37320, align 4
  %37322 = trunc i256 %37314 to i64
  %37323 = alloca i256, align 8
  store i256 %37321, i256* %37323, align 4
  %37324 = bitcast i256* %37323 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37322, i8* %37324, i64 32)
  %37325 = add i256 32, %37314, !pc !533, !intsan !10
  %37326 = trunc i256 %36918 to i64
  %37327 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37326, i256* %37327)
  %37328 = load i256, i256* %37327, align 4
  %37329 = add i256 32, %36918, !pc !534, !intsan !10
  %37330 = load i64, i64* %STACK_DEP_PTR, align 4
  %37331 = add i64 %37330, 1
  store i64 %37331, i64* %STACK_DEP_PTR, align 4
  %37332 = load i64, i64* %STACK_DEP_PTR, align 4
  %37333 = getelementptr i256, i256* %STACK, i64 %37332
  store i256 %36918, i256* %37333, align 4
  %37334 = load i64, i64* %STACK_DEP_PTR, align 4
  %37335 = add i64 %37334, 1
  store i64 %37335, i64* %STACK_DEP_PTR, align 4
  %37336 = load i64, i64* %STACK_DEP_PTR, align 4
  %37337 = getelementptr i256, i256* %STACK, i64 %37336
  store i256 %36913, i256* %37337, align 4
  %37338 = load i64, i64* %STACK_DEP_PTR, align 4
  %37339 = add i64 %37338, 1
  store i64 %37339, i64* %STACK_DEP_PTR, align 4
  %37340 = load i64, i64* %STACK_DEP_PTR, align 4
  %37341 = getelementptr i256, i256* %STACK, i64 %37340
  store i256 %36908, i256* %37341, align 4
  %37342 = load i64, i64* %STACK_DEP_PTR, align 4
  %37343 = add i64 %37342, 1
  store i64 %37343, i64* %STACK_DEP_PTR, align 4
  %37344 = load i64, i64* %STACK_DEP_PTR, align 4
  %37345 = getelementptr i256, i256* %STACK, i64 %37344
  store i256 %36903, i256* %37345, align 4
  %37346 = load i64, i64* %STACK_DEP_PTR, align 4
  %37347 = add i64 %37346, 1
  store i64 %37347, i64* %STACK_DEP_PTR, align 4
  %37348 = load i64, i64* %STACK_DEP_PTR, align 4
  %37349 = getelementptr i256, i256* %STACK, i64 %37348
  store i256 %36898, i256* %37349, align 4
  %37350 = load i64, i64* %STACK_DEP_PTR, align 4
  %37351 = add i64 %37350, 1
  store i64 %37351, i64* %STACK_DEP_PTR, align 4
  %37352 = load i64, i64* %STACK_DEP_PTR, align 4
  %37353 = getelementptr i256, i256* %STACK, i64 %37352
  store i256 %37300, i256* %37353, align 4
  %37354 = load i64, i64* %STACK_DEP_PTR, align 4
  %37355 = add i64 %37354, 1
  store i64 %37355, i64* %STACK_DEP_PTR, align 4
  %37356 = load i64, i64* %STACK_DEP_PTR, align 4
  %37357 = getelementptr i256, i256* %STACK, i64 %37356
  store i256 787721420, i256* %37357, align 4
  %37358 = load i64, i64* %STACK_DEP_PTR, align 4
  %37359 = add i64 %37358, 1
  store i64 %37359, i64* %STACK_DEP_PTR, align 4
  %37360 = load i64, i64* %STACK_DEP_PTR, align 4
  %37361 = getelementptr i256, i256* %STACK, i64 %37360
  store i256 %36918, i256* %37361, align 4
  %37362 = load i64, i64* %STACK_DEP_PTR, align 4
  %37363 = add i64 %37362, 1
  store i64 %37363, i64* %STACK_DEP_PTR, align 4
  %37364 = load i64, i64* %STACK_DEP_PTR, align 4
  %37365 = getelementptr i256, i256* %STACK, i64 %37364
  store i256 %36908, i256* %37365, align 4
  %37366 = load i64, i64* %STACK_DEP_PTR, align 4
  %37367 = add i64 %37366, 1
  store i64 %37367, i64* %STACK_DEP_PTR, align 4
  %37368 = load i64, i64* %STACK_DEP_PTR, align 4
  %37369 = getelementptr i256, i256* %STACK, i64 %37368
  store i256 %37309, i256* %37369, align 4
  %37370 = load i64, i64* %STACK_DEP_PTR, align 4
  %37371 = add i64 %37370, 1
  store i64 %37371, i64* %STACK_DEP_PTR, align 4
  %37372 = load i64, i64* %STACK_DEP_PTR, align 4
  %37373 = getelementptr i256, i256* %STACK, i64 %37372
  store i256 %37309, i256* %37373, align 4
  %37374 = load i64, i64* %STACK_DEP_PTR, align 4
  %37375 = add i64 %37374, 1
  store i64 %37375, i64* %STACK_DEP_PTR, align 4
  %37376 = load i64, i64* %STACK_DEP_PTR, align 4
  %37377 = getelementptr i256, i256* %STACK, i64 %37376
  store i256 %37325, i256* %37377, align 4
  %37378 = load i64, i64* %STACK_DEP_PTR, align 4
  %37379 = add i64 %37378, 1
  store i64 %37379, i64* %STACK_DEP_PTR, align 4
  %37380 = load i64, i64* %STACK_DEP_PTR, align 4
  %37381 = getelementptr i256, i256* %STACK, i64 %37380
  store i256 %37329, i256* %37381, align 4
  %37382 = load i64, i64* %STACK_DEP_PTR, align 4
  %37383 = add i64 %37382, 1
  store i64 %37383, i64* %STACK_DEP_PTR, align 4
  %37384 = load i64, i64* %STACK_DEP_PTR, align 4
  %37385 = getelementptr i256, i256* %STACK, i64 %37384
  store i256 %37328, i256* %37385, align 4
  %37386 = load i64, i64* %STACK_DEP_PTR, align 4
  %37387 = add i64 %37386, 1
  store i64 %37387, i64* %STACK_DEP_PTR, align 4
  %37388 = load i64, i64* %STACK_DEP_PTR, align 4
  %37389 = getelementptr i256, i256* %STACK, i64 %37388
  store i256 %37328, i256* %37389, align 4
  %37390 = load i64, i64* %STACK_DEP_PTR, align 4
  %37391 = add i64 %37390, 1
  store i64 %37391, i64* %STACK_DEP_PTR, align 4
  %37392 = load i64, i64* %STACK_DEP_PTR, align 4
  %37393 = getelementptr i256, i256* %STACK, i64 %37392
  store i256 %37325, i256* %37393, align 4
  %37394 = load i64, i64* %STACK_DEP_PTR, align 4
  %37395 = add i64 %37394, 1
  store i64 %37395, i64* %STACK_DEP_PTR, align 4
  %37396 = load i64, i64* %STACK_DEP_PTR, align 4
  %37397 = getelementptr i256, i256* %STACK, i64 %37396
  store i256 %37329, i256* %37397, align 4
  %37398 = load i64, i64* %STACK_DEP_PTR, align 4
  %37399 = add i64 %37398, 1
  store i64 %37399, i64* %STACK_DEP_PTR, align 4
  %37400 = load i64, i64* %STACK_DEP_PTR, align 4
  %37401 = getelementptr i256, i256* %STACK, i64 %37400
  store i256 0, i256* %37401, align 4
  br label %.12360

.12360:                                           ; preds = %37452, %.12129, %JumpTable
  %37402 = load i64, i64* %remaing_gas, align 4
  %37403 = icmp ugt i64 432, %37402
  br i1 %37403, label %Abort, label %37404

37404:                                            ; preds = %.12360
  %37405 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37406 = xor i32 %37405, 99
  %37407 = urem i32 %37406, 4096
  %37408 = getelementptr i8, i8 addrspace(1)* %4, i32 %37407
  %37409 = load i8, i8 addrspace(1)* %37408, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37408, align 1, !nosanitize !3
  store i32 49, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37410 = sub i64 %37402, 432
  store i64 %37410, i64* %remaing_gas, align 4
  %37411 = load i64, i64* %STACK_DEP_PTR, align 4
  %37412 = getelementptr i256, i256* %STACK, i64 %37411
  %37413 = load i256, i256* %37412, align 4
  %37414 = load i64, i64* %STACK_DEP_PTR, align 4
  %37415 = sub i64 %37414, 1
  store i64 %37415, i64* %STACK_DEP_PTR, align 4
  %37416 = load i64, i64* %STACK_DEP_PTR, align 4
  %37417 = getelementptr i256, i256* %STACK, i64 %37416
  %37418 = load i256, i256* %37417, align 4
  %37419 = load i64, i64* %STACK_DEP_PTR, align 4
  %37420 = sub i64 %37419, 1
  store i64 %37420, i64* %STACK_DEP_PTR, align 4
  %37421 = load i64, i64* %STACK_DEP_PTR, align 4
  %37422 = getelementptr i256, i256* %STACK, i64 %37421
  %37423 = load i256, i256* %37422, align 4
  %37424 = load i64, i64* %STACK_DEP_PTR, align 4
  %37425 = sub i64 %37424, 1
  store i64 %37425, i64* %STACK_DEP_PTR, align 4
  %37426 = load i64, i64* %STACK_DEP_PTR, align 4
  %37427 = getelementptr i256, i256* %STACK, i64 %37426
  %37428 = load i256, i256* %37427, align 4
  %37429 = load i64, i64* %STACK_DEP_PTR, align 4
  %37430 = sub i64 %37429, 1
  store i64 %37430, i64* %STACK_DEP_PTR, align 4
  %37431 = icmp ult i256 %37413, %37428
  %37432 = icmp eq i1 %37431, false
  %37433 = trunc i256 12387 to i64
  %jump.check205 = icmp ne i1 %37432, false
  %37434 = load i64, i64* %STACK_DEP_PTR, align 4
  %37435 = add i64 %37434, 1
  store i64 %37435, i64* %STACK_DEP_PTR, align 4
  %37436 = load i64, i64* %STACK_DEP_PTR, align 4
  %37437 = getelementptr i256, i256* %STACK, i64 %37436
  store i256 %37428, i256* %37437, align 4
  %37438 = load i64, i64* %STACK_DEP_PTR, align 4
  %37439 = add i64 %37438, 1
  store i64 %37439, i64* %STACK_DEP_PTR, align 4
  %37440 = load i64, i64* %STACK_DEP_PTR, align 4
  %37441 = getelementptr i256, i256* %STACK, i64 %37440
  store i256 %37423, i256* %37441, align 4
  %37442 = load i64, i64* %STACK_DEP_PTR, align 4
  %37443 = add i64 %37442, 1
  store i64 %37443, i64* %STACK_DEP_PTR, align 4
  %37444 = load i64, i64* %STACK_DEP_PTR, align 4
  %37445 = getelementptr i256, i256* %STACK, i64 %37444
  store i256 %37418, i256* %37445, align 4
  %37446 = load i64, i64* %STACK_DEP_PTR, align 4
  %37447 = add i64 %37446, 1
  store i64 %37447, i64* %STACK_DEP_PTR, align 4
  %37448 = load i64, i64* %STACK_DEP_PTR, align 4
  %37449 = getelementptr i256, i256* %STACK, i64 %37448
  store i256 %37413, i256* %37449, align 4
  br i1 %jump.check205, label %.12387, label %.12369, !EVMBB !4

.12369:                                           ; preds = %37404
  %37450 = load i64, i64* %remaing_gas, align 4
  %37451 = icmp ugt i64 408, %37450
  br i1 %37451, label %Abort, label %37452

37452:                                            ; preds = %.12369
  %37453 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37454 = xor i32 %37453, 431
  %37455 = urem i32 %37454, 4096
  %37456 = getelementptr i8, i8 addrspace(1)* %4, i32 %37455
  %37457 = load i8, i8 addrspace(1)* %37456, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37456, align 1, !nosanitize !3
  store i32 215, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37458 = sub i64 %37450, 408
  store i64 %37458, i64* %remaing_gas, align 4
  %37459 = load i64, i64* %STACK_DEP_PTR, align 4
  %37460 = getelementptr i256, i256* %STACK, i64 %37459
  %37461 = load i256, i256* %37460, align 4
  %37462 = load i64, i64* %STACK_DEP_PTR, align 4
  %37463 = sub i64 %37462, 1
  store i64 %37463, i64* %STACK_DEP_PTR, align 4
  %37464 = load i64, i64* %STACK_DEP_PTR, align 4
  %37465 = getelementptr i256, i256* %STACK, i64 %37464
  %37466 = load i256, i256* %37465, align 4
  %37467 = load i64, i64* %STACK_DEP_PTR, align 4
  %37468 = sub i64 %37467, 1
  store i64 %37468, i64* %STACK_DEP_PTR, align 4
  %37469 = load i64, i64* %STACK_DEP_PTR, align 4
  %37470 = getelementptr i256, i256* %STACK, i64 %37469
  %37471 = load i256, i256* %37470, align 4
  %37472 = load i64, i64* %STACK_DEP_PTR, align 4
  %37473 = sub i64 %37472, 1
  store i64 %37473, i64* %STACK_DEP_PTR, align 4
  %37474 = add i256 %37466, %37461, !pc !535, !intsan !10
  %37475 = trunc i256 %37474 to i64
  %37476 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37475, i256* %37476)
  %37477 = load i256, i256* %37476, align 4
  %37478 = add i256 %37471, %37461, !pc !536, !intsan !10
  %37479 = trunc i256 %37478 to i64
  %37480 = alloca i256, align 8
  store i256 %37477, i256* %37480, align 4
  %37481 = bitcast i256* %37480 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37479, i8* %37481, i64 32)
  %37482 = add i256 %37461, 32, !pc !537, !intsan !10
  %37483 = trunc i256 12360 to i64
  %37484 = load i64, i64* %STACK_DEP_PTR, align 4
  %37485 = add i64 %37484, 1
  store i64 %37485, i64* %STACK_DEP_PTR, align 4
  %37486 = load i64, i64* %STACK_DEP_PTR, align 4
  %37487 = getelementptr i256, i256* %STACK, i64 %37486
  store i256 %37471, i256* %37487, align 4
  %37488 = load i64, i64* %STACK_DEP_PTR, align 4
  %37489 = add i64 %37488, 1
  store i64 %37489, i64* %STACK_DEP_PTR, align 4
  %37490 = load i64, i64* %STACK_DEP_PTR, align 4
  %37491 = getelementptr i256, i256* %STACK, i64 %37490
  store i256 %37466, i256* %37491, align 4
  %37492 = load i64, i64* %STACK_DEP_PTR, align 4
  %37493 = add i64 %37492, 1
  store i64 %37493, i64* %STACK_DEP_PTR, align 4
  %37494 = load i64, i64* %STACK_DEP_PTR, align 4
  %37495 = getelementptr i256, i256* %STACK, i64 %37494
  store i256 %37482, i256* %37495, align 4
  br label %.12360, !EVMBB !4

.12387:                                           ; preds = %37404, %JumpTable
  %37496 = load i64, i64* %remaing_gas, align 4
  %37497 = icmp ugt i64 488, %37496
  br i1 %37497, label %Abort, label %37498

37498:                                            ; preds = %.12387
  %37499 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37500 = xor i32 %37499, 1634
  %37501 = urem i32 %37500, 4096
  %37502 = getelementptr i8, i8 addrspace(1)* %4, i32 %37501
  %37503 = load i8, i8 addrspace(1)* %37502, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37502, align 1, !nosanitize !3
  store i32 817, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37504 = sub i64 %37496, 488
  store i64 %37504, i64* %remaing_gas, align 4
  %37505 = load i64, i64* %STACK_DEP_PTR, align 4
  %37506 = getelementptr i256, i256* %STACK, i64 %37505
  %37507 = load i256, i256* %37506, align 4
  %37508 = load i64, i64* %STACK_DEP_PTR, align 4
  %37509 = sub i64 %37508, 1
  store i64 %37509, i64* %STACK_DEP_PTR, align 4
  %37510 = load i64, i64* %STACK_DEP_PTR, align 4
  %37511 = getelementptr i256, i256* %STACK, i64 %37510
  %37512 = load i256, i256* %37511, align 4
  %37513 = load i64, i64* %STACK_DEP_PTR, align 4
  %37514 = sub i64 %37513, 1
  store i64 %37514, i64* %STACK_DEP_PTR, align 4
  %37515 = load i64, i64* %STACK_DEP_PTR, align 4
  %37516 = getelementptr i256, i256* %STACK, i64 %37515
  %37517 = load i256, i256* %37516, align 4
  %37518 = load i64, i64* %STACK_DEP_PTR, align 4
  %37519 = sub i64 %37518, 1
  store i64 %37519, i64* %STACK_DEP_PTR, align 4
  %37520 = load i64, i64* %STACK_DEP_PTR, align 4
  %37521 = getelementptr i256, i256* %STACK, i64 %37520
  %37522 = load i256, i256* %37521, align 4
  %37523 = load i64, i64* %STACK_DEP_PTR, align 4
  %37524 = sub i64 %37523, 1
  store i64 %37524, i64* %STACK_DEP_PTR, align 4
  %37525 = load i64, i64* %STACK_DEP_PTR, align 4
  %37526 = getelementptr i256, i256* %STACK, i64 %37525
  %37527 = load i256, i256* %37526, align 4
  %37528 = load i64, i64* %STACK_DEP_PTR, align 4
  %37529 = sub i64 %37528, 1
  store i64 %37529, i64* %STACK_DEP_PTR, align 4
  %37530 = load i64, i64* %STACK_DEP_PTR, align 4
  %37531 = getelementptr i256, i256* %STACK, i64 %37530
  %37532 = load i256, i256* %37531, align 4
  %37533 = load i64, i64* %STACK_DEP_PTR, align 4
  %37534 = sub i64 %37533, 1
  store i64 %37534, i64* %STACK_DEP_PTR, align 4
  %37535 = load i64, i64* %STACK_DEP_PTR, align 4
  %37536 = getelementptr i256, i256* %STACK, i64 %37535
  %37537 = load i256, i256* %37536, align 4
  %37538 = load i64, i64* %STACK_DEP_PTR, align 4
  %37539 = sub i64 %37538, 1
  store i64 %37539, i64* %STACK_DEP_PTR, align 4
  %37540 = add i256 %37527, %37537, !pc !538, !intsan !10
  %37541 = and i256 31, %37527
  %37542 = icmp eq i256 %37541, 0
  %37543 = trunc i256 12432 to i64
  %jump.check206 = icmp ne i1 %37542, false
  %37544 = load i64, i64* %STACK_DEP_PTR, align 4
  %37545 = add i64 %37544, 1
  store i64 %37545, i64* %STACK_DEP_PTR, align 4
  %37546 = load i64, i64* %STACK_DEP_PTR, align 4
  %37547 = getelementptr i256, i256* %STACK, i64 %37546
  store i256 %37540, i256* %37547, align 4
  %37548 = load i64, i64* %STACK_DEP_PTR, align 4
  %37549 = add i64 %37548, 1
  store i64 %37549, i64* %STACK_DEP_PTR, align 4
  %37550 = load i64, i64* %STACK_DEP_PTR, align 4
  %37551 = getelementptr i256, i256* %STACK, i64 %37550
  store i256 %37541, i256* %37551, align 4
  br i1 %jump.check206, label %.12432, label %.12407, !EVMBB !4

.12407:                                           ; preds = %37498
  %37552 = load i64, i64* %STACK_DEP_PTR, align 4
  %37553 = getelementptr i256, i256* %STACK, i64 %37552
  %37554 = load i256, i256* %37553, align 4
  %37555 = load i64, i64* %STACK_DEP_PTR, align 4
  %37556 = sub i64 %37555, 1
  store i64 %37556, i64* %STACK_DEP_PTR, align 4
  %37557 = load i64, i64* %STACK_DEP_PTR, align 4
  %37558 = getelementptr i256, i256* %STACK, i64 %37557
  %37559 = load i256, i256* %37558, align 4
  %37560 = load i64, i64* %STACK_DEP_PTR, align 4
  %37561 = sub i64 %37560, 1
  store i64 %37561, i64* %STACK_DEP_PTR, align 4
  %37562 = sub i256 %37559, %37554, !pc !539, !intsan !8
  %37563 = trunc i256 %37562 to i64
  %37564 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37563, i256* %37564)
  %37565 = load i256, i256* %37564, align 4
  %37566 = sub i256 32, %37554, !pc !540, !intsan !8
  %37567 = alloca i256, align 8
  store i256 256, i256* %37567, align 4
  %37568 = alloca i256, align 8
  store i256 %37566, i256* %37568, align 4
  %37569 = alloca i256, align 8
  call void @__power_word(i256* %37567, i256* %37568, i256* %37569)
  %37570 = load volatile i256, i256* %37569, align 4
  %37571 = sub i256 %37570, 1, !pc !541, !intsan !8
  %37572 = xor i256 %37571, -1
  %37573 = and i256 %37572, %37565
  %37574 = trunc i256 %37562 to i64
  %37575 = alloca i256, align 8
  store i256 %37573, i256* %37575, align 4
  %37576 = bitcast i256* %37575 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %37574, i8* %37576, i64 32)
  %37577 = add i256 32, %37562, !pc !542, !intsan !10
  %37578 = load i64, i64* %STACK_DEP_PTR, align 4
  %37579 = add i64 %37578, 1
  store i64 %37579, i64* %STACK_DEP_PTR, align 4
  %37580 = load i64, i64* %STACK_DEP_PTR, align 4
  %37581 = getelementptr i256, i256* %STACK, i64 %37580
  store i256 %37577, i256* %37581, align 4
  %37582 = load i64, i64* %STACK_DEP_PTR, align 4
  %37583 = add i64 %37582, 1
  store i64 %37583, i64* %STACK_DEP_PTR, align 4
  %37584 = load i64, i64* %STACK_DEP_PTR, align 4
  %37585 = getelementptr i256, i256* %STACK, i64 %37584
  store i256 %37554, i256* %37585, align 4
  br label %.12432

.12432:                                           ; preds = %.12407, %37498, %JumpTable
  %37586 = load i64, i64* %remaing_gas, align 4
  %37587 = icmp ugt i64 960, %37586
  br i1 %37587, label %Abort, label %37588

37588:                                            ; preds = %.12432
  %37589 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37590 = xor i32 %37589, 3516
  %37591 = urem i32 %37590, 4096
  %37592 = getelementptr i8, i8 addrspace(1)* %4, i32 %37591
  %37593 = load i8, i8 addrspace(1)* %37592, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37592, align 1, !nosanitize !3
  store i32 1758, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37594 = sub i64 %37586, 960
  store i64 %37594, i64* %remaing_gas, align 4
  %37595 = load i64, i64* %STACK_DEP_PTR, align 4
  %37596 = getelementptr i256, i256* %STACK, i64 %37595
  %37597 = load i256, i256* %37596, align 4
  %37598 = load i64, i64* %STACK_DEP_PTR, align 4
  %37599 = sub i64 %37598, 1
  store i64 %37599, i64* %STACK_DEP_PTR, align 4
  %37600 = load i64, i64* %STACK_DEP_PTR, align 4
  %37601 = getelementptr i256, i256* %STACK, i64 %37600
  %37602 = load i256, i256* %37601, align 4
  %37603 = load i64, i64* %STACK_DEP_PTR, align 4
  %37604 = sub i64 %37603, 1
  store i64 %37604, i64* %STACK_DEP_PTR, align 4
  %37605 = load i64, i64* %STACK_DEP_PTR, align 4
  %37606 = getelementptr i256, i256* %STACK, i64 %37605
  %37607 = load i256, i256* %37606, align 4
  %37608 = load i64, i64* %STACK_DEP_PTR, align 4
  %37609 = sub i64 %37608, 1
  store i64 %37609, i64* %STACK_DEP_PTR, align 4
  %37610 = load i64, i64* %STACK_DEP_PTR, align 4
  %37611 = getelementptr i256, i256* %STACK, i64 %37610
  %37612 = load i256, i256* %37611, align 4
  %37613 = load i64, i64* %STACK_DEP_PTR, align 4
  %37614 = sub i64 %37613, 1
  store i64 %37614, i64* %STACK_DEP_PTR, align 4
  %37615 = load i64, i64* %STACK_DEP_PTR, align 4
  %37616 = getelementptr i256, i256* %STACK, i64 %37615
  %37617 = load i256, i256* %37616, align 4
  %37618 = load i64, i64* %STACK_DEP_PTR, align 4
  %37619 = sub i64 %37618, 1
  store i64 %37619, i64* %STACK_DEP_PTR, align 4
  %37620 = load i64, i64* %STACK_DEP_PTR, align 4
  %37621 = getelementptr i256, i256* %STACK, i64 %37620
  %37622 = load i256, i256* %37621, align 4
  %37623 = load i64, i64* %STACK_DEP_PTR, align 4
  %37624 = sub i64 %37623, 1
  store i64 %37624, i64* %STACK_DEP_PTR, align 4
  %37625 = load i64, i64* %STACK_DEP_PTR, align 4
  %37626 = getelementptr i256, i256* %STACK, i64 %37625
  %37627 = load i256, i256* %37626, align 4
  %37628 = load i64, i64* %STACK_DEP_PTR, align 4
  %37629 = sub i64 %37628, 1
  store i64 %37629, i64* %STACK_DEP_PTR, align 4
  %37630 = load i64, i64* %STACK_DEP_PTR, align 4
  %37631 = getelementptr i256, i256* %STACK, i64 %37630
  %37632 = load i256, i256* %37631, align 4
  %37633 = load i64, i64* %STACK_DEP_PTR, align 4
  %37634 = sub i64 %37633, 1
  store i64 %37634, i64* %STACK_DEP_PTR, align 4
  %37635 = trunc i256 64 to i64
  %37636 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37635, i256* %37636)
  %37637 = load i256, i256* %37636, align 4
  %37638 = sub i256 %37602, %37637, !pc !543, !intsan !8
  %37639 = icmp eq i256 1, 0
  %37640 = icmp eq i1 %37639, false
  %37641 = trunc i256 12464 to i64
  %jump.check207 = icmp ne i1 %37640, false
  %37642 = load i64, i64* %STACK_DEP_PTR, align 4
  %37643 = add i64 %37642, 1
  store i64 %37643, i64* %STACK_DEP_PTR, align 4
  %37644 = load i64, i64* %STACK_DEP_PTR, align 4
  %37645 = getelementptr i256, i256* %STACK, i64 %37644
  store i256 %37632, i256* %37645, align 4
  %37646 = load i64, i64* %STACK_DEP_PTR, align 4
  %37647 = add i64 %37646, 1
  store i64 %37647, i64* %STACK_DEP_PTR, align 4
  %37648 = load i64, i64* %STACK_DEP_PTR, align 4
  %37649 = getelementptr i256, i256* %STACK, i64 %37648
  store i256 %37627, i256* %37649, align 4
  %37650 = load i64, i64* %STACK_DEP_PTR, align 4
  %37651 = add i64 %37650, 1
  store i64 %37651, i64* %STACK_DEP_PTR, align 4
  %37652 = load i64, i64* %STACK_DEP_PTR, align 4
  %37653 = getelementptr i256, i256* %STACK, i64 %37652
  store i256 %37602, i256* %37653, align 4
  %37654 = load i64, i64* %STACK_DEP_PTR, align 4
  %37655 = add i64 %37654, 1
  store i64 %37655, i64* %STACK_DEP_PTR, align 4
  %37656 = load i64, i64* %STACK_DEP_PTR, align 4
  %37657 = getelementptr i256, i256* %STACK, i64 %37656
  store i256 32, i256* %37657, align 4
  %37658 = load i64, i64* %STACK_DEP_PTR, align 4
  %37659 = add i64 %37658, 1
  store i64 %37659, i64* %STACK_DEP_PTR, align 4
  %37660 = load i64, i64* %STACK_DEP_PTR, align 4
  %37661 = getelementptr i256, i256* %STACK, i64 %37660
  store i256 %37637, i256* %37661, align 4
  %37662 = load i64, i64* %STACK_DEP_PTR, align 4
  %37663 = add i64 %37662, 1
  store i64 %37663, i64* %STACK_DEP_PTR, align 4
  %37664 = load i64, i64* %STACK_DEP_PTR, align 4
  %37665 = getelementptr i256, i256* %STACK, i64 %37664
  store i256 %37638, i256* %37665, align 4
  %37666 = load i64, i64* %STACK_DEP_PTR, align 4
  %37667 = add i64 %37666, 1
  store i64 %37667, i64* %STACK_DEP_PTR, align 4
  %37668 = load i64, i64* %STACK_DEP_PTR, align 4
  %37669 = getelementptr i256, i256* %STACK, i64 %37668
  store i256 %37637, i256* %37669, align 4
  %37670 = load i64, i64* %STACK_DEP_PTR, align 4
  %37671 = add i64 %37670, 1
  store i64 %37671, i64* %STACK_DEP_PTR, align 4
  %37672 = load i64, i64* %STACK_DEP_PTR, align 4
  %37673 = getelementptr i256, i256* %STACK, i64 %37672
  store i256 0, i256* %37673, align 4
  %37674 = load i64, i64* %STACK_DEP_PTR, align 4
  %37675 = add i64 %37674, 1
  store i64 %37675, i64* %STACK_DEP_PTR, align 4
  %37676 = load i64, i64* %STACK_DEP_PTR, align 4
  %37677 = getelementptr i256, i256* %STACK, i64 %37676
  store i256 %37632, i256* %37677, align 4
  %37678 = load i64, i64* %STACK_DEP_PTR, align 4
  %37679 = add i64 %37678, 1
  store i64 %37679, i64* %STACK_DEP_PTR, align 4
  %37680 = zext i1 %37639 to i256
  %37681 = load i64, i64* %STACK_DEP_PTR, align 4
  %37682 = getelementptr i256, i256* %STACK, i64 %37681
  store i256 %37680, i256* %37682, align 4
  br i1 %jump.check207, label %.12464, label %.12460, !EVMBB !4

.12460:                                           ; preds = %37588
  %37683 = load i64, i64* %remaing_gas, align 4
  %37684 = icmp ugt i64 16, %37683
  br i1 %37684, label %Abort, label %37685

37685:                                            ; preds = %.12460
  %37686 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37687 = xor i32 %37686, 1923
  %37688 = urem i32 %37687, 4096
  %37689 = getelementptr i8, i8 addrspace(1)* %4, i32 %37688
  %37690 = load i8, i8 addrspace(1)* %37689, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37689, align 1, !nosanitize !3
  store i32 961, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37691 = sub i64 %37683, 16
  store i64 %37691, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12464:                                           ; preds = %37588, %JumpTable
  %37692 = load i64, i64* %remaing_gas, align 4
  %37693 = icmp ugt i64 456, %37692
  br i1 %37693, label %Abort, label %37694

37694:                                            ; preds = %.12464
  %37695 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37696 = xor i32 %37695, 1716
  %37697 = urem i32 %37696, 4096
  %37698 = getelementptr i8, i8 addrspace(1)* %4, i32 %37697
  %37699 = load i8, i8 addrspace(1)* %37698, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37698, align 1, !nosanitize !3
  store i32 858, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37700 = sub i64 %37692, 456
  store i64 %37700, i64* %remaing_gas, align 4
  %37701 = load i64, i64* %STACK_DEP_PTR, align 4
  %37702 = getelementptr i256, i256* %STACK, i64 %37701
  %37703 = load i256, i256* %37702, align 4
  %37704 = load i64, i64* %STACK_DEP_PTR, align 4
  %37705 = sub i64 %37704, 1
  store i64 %37705, i64* %STACK_DEP_PTR, align 4
  %37706 = load i64, i64* %STACK_DEP_PTR, align 4
  %37707 = getelementptr i256, i256* %STACK, i64 %37706
  %37708 = load i256, i256* %37707, align 4
  %37709 = load i64, i64* %STACK_DEP_PTR, align 4
  %37710 = sub i64 %37709, 1
  store i64 %37710, i64* %STACK_DEP_PTR, align 4
  %37711 = load i64, i64* %STACK_DEP_PTR, align 4
  %37712 = getelementptr i256, i256* %STACK, i64 %37711
  %37713 = load i256, i256* %37712, align 4
  %37714 = load i64, i64* %STACK_DEP_PTR, align 4
  %37715 = sub i64 %37714, 1
  store i64 %37715, i64* %STACK_DEP_PTR, align 4
  %37716 = load i64, i64* %STACK_DEP_PTR, align 4
  %37717 = getelementptr i256, i256* %STACK, i64 %37716
  %37718 = load i256, i256* %37717, align 4
  %37719 = load i64, i64* %STACK_DEP_PTR, align 4
  %37720 = sub i64 %37719, 1
  store i64 %37720, i64* %STACK_DEP_PTR, align 4
  %37721 = load i64, i64* %STACK_DEP_PTR, align 4
  %37722 = getelementptr i256, i256* %STACK, i64 %37721
  %37723 = load i256, i256* %37722, align 4
  %37724 = load i64, i64* %STACK_DEP_PTR, align 4
  %37725 = sub i64 %37724, 1
  store i64 %37725, i64* %STACK_DEP_PTR, align 4
  %37726 = load i64, i64* %STACK_DEP_PTR, align 4
  %37727 = getelementptr i256, i256* %STACK, i64 %37726
  %37728 = load i256, i256* %37727, align 4
  %37729 = load i64, i64* %STACK_DEP_PTR, align 4
  %37730 = sub i64 %37729, 1
  store i64 %37730, i64* %STACK_DEP_PTR, align 4
  %37731 = load i64, i64* %STACK_DEP_PTR, align 4
  %37732 = getelementptr i256, i256* %STACK, i64 %37731
  %37733 = load i256, i256* %37732, align 4
  %37734 = load i64, i64* %STACK_DEP_PTR, align 4
  %37735 = sub i64 %37734, 1
  store i64 %37735, i64* %STACK_DEP_PTR, align 4
  %37736 = trunc i256 %37708 to i160
  %37737 = call i1 @solidity_call(), !pc !544
  %37738 = icmp eq i1 %37737, false
  %37739 = icmp eq i1 %37738, false
  %37740 = trunc i256 12484 to i64
  %jump.check208 = icmp ne i1 %37739, false
  %37741 = load i64, i64* %STACK_DEP_PTR, align 4
  %37742 = add i64 %37741, 1
  store i64 %37742, i64* %STACK_DEP_PTR, align 4
  %37743 = zext i1 %37738 to i256
  %37744 = load i64, i64* %STACK_DEP_PTR, align 4
  %37745 = getelementptr i256, i256* %STACK, i64 %37744
  store i256 %37743, i256* %37745, align 4
  br i1 %jump.check208, label %.12484, label %.12475, !EVMBB !4

.12475:                                           ; preds = %37694
  %37746 = load i64, i64* %remaing_gas, align 4
  %37747 = icmp ugt i64 16, %37746
  br i1 %37747, label %Abort, label %37748

37748:                                            ; preds = %.12475
  %37749 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37750 = xor i32 %37749, 2921
  %37751 = urem i32 %37750, 4096
  %37752 = getelementptr i8, i8 addrspace(1)* %4, i32 %37751
  %37753 = load i8, i8 addrspace(1)* %37752, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37752, align 1, !nosanitize !3
  store i32 1460, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37754 = sub i64 %37746, 16
  store i64 %37754, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12484:                                           ; preds = %37694, %JumpTable
  %37755 = load i64, i64* %remaing_gas, align 4
  %37756 = icmp ugt i64 384, %37755
  br i1 %37756, label %Abort, label %37757

37757:                                            ; preds = %.12484
  %37758 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37759 = xor i32 %37758, 1839
  %37760 = urem i32 %37759, 4096
  %37761 = getelementptr i8, i8 addrspace(1)* %4, i32 %37760
  %37762 = load i8, i8 addrspace(1)* %37761, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37761, align 1, !nosanitize !3
  store i32 919, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37763 = sub i64 %37755, 384
  store i64 %37763, i64* %remaing_gas, align 4
  %37764 = load i64, i64* %STACK_DEP_PTR, align 4
  %37765 = getelementptr i256, i256* %STACK, i64 %37764
  %37766 = load i256, i256* %37765, align 4
  %37767 = load i64, i64* %STACK_DEP_PTR, align 4
  %37768 = sub i64 %37767, 1
  store i64 %37768, i64* %STACK_DEP_PTR, align 4
  %37769 = load i64, i64* %STACK_DEP_PTR, align 4
  %37770 = getelementptr i256, i256* %STACK, i64 %37769
  %37771 = load i256, i256* %37770, align 4
  %37772 = load i64, i64* %STACK_DEP_PTR, align 4
  %37773 = sub i64 %37772, 1
  store i64 %37773, i64* %STACK_DEP_PTR, align 4
  %37774 = load i64, i64* %STACK_DEP_PTR, align 4
  %37775 = getelementptr i256, i256* %STACK, i64 %37774
  %37776 = load i256, i256* %37775, align 4
  %37777 = load i64, i64* %STACK_DEP_PTR, align 4
  %37778 = sub i64 %37777, 1
  store i64 %37778, i64* %STACK_DEP_PTR, align 4
  %37779 = load i64, i64* %STACK_DEP_PTR, align 4
  %37780 = getelementptr i256, i256* %STACK, i64 %37779
  %37781 = load i256, i256* %37780, align 4
  %37782 = load i64, i64* %STACK_DEP_PTR, align 4
  %37783 = sub i64 %37782, 1
  store i64 %37783, i64* %STACK_DEP_PTR, align 4
  %37784 = trunc i256 64 to i64
  %37785 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37784, i256* %37785)
  %37786 = load i256, i256* %37785, align 4
  %37787 = zext i64 0 to i256
  %37788 = icmp ult i256 %37787, 32
  %37789 = icmp eq i1 %37788, false
  %37790 = trunc i256 12506 to i64
  %jump.check209 = icmp ne i1 %37789, false
  %37791 = load i64, i64* %STACK_DEP_PTR, align 4
  %37792 = add i64 %37791, 1
  store i64 %37792, i64* %STACK_DEP_PTR, align 4
  %37793 = load i64, i64* %STACK_DEP_PTR, align 4
  %37794 = getelementptr i256, i256* %STACK, i64 %37793
  store i256 %37786, i256* %37794, align 4
  %37795 = load i64, i64* %STACK_DEP_PTR, align 4
  %37796 = add i64 %37795, 1
  store i64 %37796, i64* %STACK_DEP_PTR, align 4
  %37797 = zext i64 0 to i256
  %37798 = load i64, i64* %STACK_DEP_PTR, align 4
  %37799 = getelementptr i256, i256* %STACK, i64 %37798
  store i256 %37797, i256* %37799, align 4
  br i1 %jump.check209, label %.12506, label %.12502, !EVMBB !4

.12502:                                           ; preds = %37757
  %37800 = load i64, i64* %remaing_gas, align 4
  %37801 = icmp ugt i64 16, %37800
  br i1 %37801, label %Abort, label %37802

37802:                                            ; preds = %.12502
  %37803 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37804 = xor i32 %37803, 3642
  %37805 = urem i32 %37804, 4096
  %37806 = getelementptr i8, i8 addrspace(1)* %4, i32 %37805
  %37807 = load i8, i8 addrspace(1)* %37806, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37806, align 1, !nosanitize !3
  store i32 1821, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37808 = sub i64 %37800, 16
  store i64 %37808, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12506:                                           ; preds = %37757, %JumpTable
  %37809 = load i64, i64* %remaing_gas, align 4
  %37810 = icmp ugt i64 504, %37809
  br i1 %37810, label %Abort, label %37811

37811:                                            ; preds = %.12506
  %37812 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37813 = xor i32 %37812, 3583
  %37814 = urem i32 %37813, 4096
  %37815 = getelementptr i8, i8 addrspace(1)* %4, i32 %37814
  %37816 = load i8, i8 addrspace(1)* %37815, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37815, align 1, !nosanitize !3
  store i32 1791, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37817 = sub i64 %37809, 504
  store i64 %37817, i64* %remaing_gas, align 4
  %37818 = load i64, i64* %STACK_DEP_PTR, align 4
  %37819 = getelementptr i256, i256* %STACK, i64 %37818
  %37820 = load i256, i256* %37819, align 4
  %37821 = load i64, i64* %STACK_DEP_PTR, align 4
  %37822 = sub i64 %37821, 1
  store i64 %37822, i64* %STACK_DEP_PTR, align 4
  %37823 = load i64, i64* %STACK_DEP_PTR, align 4
  %37824 = getelementptr i256, i256* %STACK, i64 %37823
  %37825 = load i256, i256* %37824, align 4
  %37826 = load i64, i64* %STACK_DEP_PTR, align 4
  %37827 = sub i64 %37826, 1
  store i64 %37827, i64* %STACK_DEP_PTR, align 4
  %37828 = load i64, i64* %STACK_DEP_PTR, align 4
  %37829 = getelementptr i256, i256* %STACK, i64 %37828
  %37830 = load i256, i256* %37829, align 4
  %37831 = load i64, i64* %STACK_DEP_PTR, align 4
  %37832 = sub i64 %37831, 1
  store i64 %37832, i64* %STACK_DEP_PTR, align 4
  %37833 = load i64, i64* %STACK_DEP_PTR, align 4
  %37834 = getelementptr i256, i256* %STACK, i64 %37833
  %37835 = load i256, i256* %37834, align 4
  %37836 = load i64, i64* %STACK_DEP_PTR, align 4
  %37837 = sub i64 %37836, 1
  store i64 %37837, i64* %STACK_DEP_PTR, align 4
  %37838 = load i64, i64* %STACK_DEP_PTR, align 4
  %37839 = getelementptr i256, i256* %STACK, i64 %37838
  %37840 = load i256, i256* %37839, align 4
  %37841 = load i64, i64* %STACK_DEP_PTR, align 4
  %37842 = sub i64 %37841, 1
  store i64 %37842, i64* %STACK_DEP_PTR, align 4
  %37843 = add i256 %37825, %37820, !pc !545, !intsan !10
  %37844 = trunc i256 %37825 to i64
  %37845 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %37844, i256* %37845)
  %37846 = load i256, i256* %37845, align 4
  %37847 = add i256 32, %37825, !pc !546, !intsan !10
  %37848 = zext i64 100 to i256
  %37849 = mul i256 %37848, %37840, !pc !547, !intsan !45
  %37850 = add i256 1000000000000000000, %37849, !pc !548, !intsan !10
  %37851 = icmp ugt i256 %37846, %37850
  %37852 = icmp eq i1 %37851, false
  %37853 = trunc i256 12557 to i64
  %jump.check210 = icmp ne i1 %37852, false
  %37854 = load i64, i64* %STACK_DEP_PTR, align 4
  %37855 = add i64 %37854, 1
  store i64 %37855, i64* %STACK_DEP_PTR, align 4
  %37856 = load i64, i64* %STACK_DEP_PTR, align 4
  %37857 = getelementptr i256, i256* %STACK, i64 %37856
  store i256 %37840, i256* %37857, align 4
  %37858 = load i64, i64* %STACK_DEP_PTR, align 4
  %37859 = add i64 %37858, 1
  store i64 %37859, i64* %STACK_DEP_PTR, align 4
  %37860 = load i64, i64* %STACK_DEP_PTR, align 4
  %37861 = getelementptr i256, i256* %STACK, i64 %37860
  store i256 %37835, i256* %37861, align 4
  %37862 = load i64, i64* %STACK_DEP_PTR, align 4
  %37863 = add i64 %37862, 1
  store i64 %37863, i64* %STACK_DEP_PTR, align 4
  %37864 = load i64, i64* %STACK_DEP_PTR, align 4
  %37865 = getelementptr i256, i256* %STACK, i64 %37864
  store i256 %37846, i256* %37865, align 4
  br i1 %jump.check210, label %.12557, label %.12546, !EVMBB !4

.12546:                                           ; preds = %37811
  %37866 = load i64, i64* %remaing_gas, align 4
  %37867 = icmp ugt i64 224, %37866
  br i1 %37867, label %Abort, label %37868

37868:                                            ; preds = %.12546
  %37869 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37870 = xor i32 %37869, 943
  %37871 = urem i32 %37870, 4096
  %37872 = getelementptr i8, i8 addrspace(1)* %4, i32 %37871
  %37873 = load i8, i8 addrspace(1)* %37872, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %37872, align 1, !nosanitize !3
  store i32 471, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %37874 = sub i64 %37866, 224
  store i64 %37874, i64* %remaing_gas, align 4
  %37875 = load i64, i64* %STACK_DEP_PTR, align 4
  %37876 = getelementptr i256, i256* %STACK, i64 %37875
  %37877 = load i256, i256* %37876, align 4
  %37878 = load i64, i64* %STACK_DEP_PTR, align 4
  %37879 = sub i64 %37878, 1
  store i64 %37879, i64* %STACK_DEP_PTR, align 4
  %37880 = load i64, i64* %STACK_DEP_PTR, align 4
  %37881 = getelementptr i256, i256* %STACK, i64 %37880
  %37882 = load i256, i256* %37881, align 4
  %37883 = load i64, i64* %STACK_DEP_PTR, align 4
  %37884 = sub i64 %37883, 1
  store i64 %37884, i64* %STACK_DEP_PTR, align 4
  %37885 = mul i256 1, 0, !pc !549, !intsan !45
  %37886 = trunc i256 12992 to i64
  %37887 = load i64, i64* %STACK_DEP_PTR, align 4
  %37888 = add i64 %37887, 1
  store i64 %37888, i64* %STACK_DEP_PTR, align 4
  %37889 = load i64, i64* %STACK_DEP_PTR, align 4
  %37890 = getelementptr i256, i256* %STACK, i64 %37889
  store i256 %37885, i256* %37890, align 4
  %37891 = load i64, i64* %STACK_DEP_PTR, align 4
  %37892 = add i64 %37891, 1
  store i64 %37892, i64* %STACK_DEP_PTR, align 4
  %37893 = load i64, i64* %STACK_DEP_PTR, align 4
  %37894 = getelementptr i256, i256* %STACK, i64 %37893
  store i256 %37877, i256* %37894, align 4
  br label %.12992, !EVMBB !4

.12557:                                           ; preds = %37811, %JumpTable
  %37895 = load i64, i64* %STACK_DEP_PTR, align 4
  %37896 = getelementptr i256, i256* %STACK, i64 %37895
  %37897 = load i256, i256* %37896, align 4
  %37898 = load i64, i64* %STACK_DEP_PTR, align 4
  %37899 = sub i64 %37898, 1
  store i64 %37899, i64* %STACK_DEP_PTR, align 4
  %37900 = load i64, i64* %STACK_DEP_PTR, align 4
  %37901 = getelementptr i256, i256* %STACK, i64 %37900
  %37902 = load i256, i256* %37901, align 4
  %37903 = load i64, i64* %STACK_DEP_PTR, align 4
  %37904 = sub i64 %37903, 1
  store i64 %37904, i64* %STACK_DEP_PTR, align 4
  %37905 = load i64, i64* %STACK_DEP_PTR, align 4
  %37906 = getelementptr i256, i256* %STACK, i64 %37905
  %37907 = load i256, i256* %37906, align 4
  %37908 = load i64, i64* %STACK_DEP_PTR, align 4
  %37909 = sub i64 %37908, 1
  store i64 %37909, i64* %STACK_DEP_PTR, align 4
  %37910 = load i64, i64* %STACK_DEP_PTR, align 4
  %37911 = getelementptr i256, i256* %STACK, i64 %37910
  %37912 = load i256, i256* %37911, align 4
  %37913 = load i64, i64* %STACK_DEP_PTR, align 4
  %37914 = sub i64 %37913, 1
  store i64 %37914, i64* %STACK_DEP_PTR, align 4
  %37915 = load i64, i64* %STACK_DEP_PTR, align 4
  %37916 = getelementptr i256, i256* %STACK, i64 %37915
  %37917 = load i256, i256* %37916, align 4
  %37918 = load i64, i64* %STACK_DEP_PTR, align 4
  %37919 = sub i64 %37918, 1
  store i64 %37919, i64* %STACK_DEP_PTR, align 4
  %37920 = alloca i256, align 8
  store i256 1, i256* %37920, align 4
  %37921 = alloca i256, align 8
  call void @__device_sload(i256* %37920, i256* %37921)
  %37922 = call i32 @__hashword(i256* %37920)
  %37923 = load i32, i32* %5, align 4
  %37924 = icmp eq i32 %37922, %37923
  %37925 = or i1 false, %37924
  %37926 = load i32, i32* %6, align 4
  %37927 = icmp eq i32 %37922, %37926
  %37928 = or i1 %37925, %37927
  %37929 = load i32, i32* %7, align 4
  %37930 = icmp eq i32 %37922, %37929
  %37931 = or i1 %37928, %37930
  %37932 = load i32, i32* %8, align 4
  %37933 = icmp eq i32 %37922, %37932
  %37934 = or i1 %37931, %37933
  %37935 = load i32, i32* %9, align 4
  %37936 = icmp eq i32 %37922, %37935
  %37937 = or i1 %37934, %37936
  %37938 = load i32, i32* %10, align 4
  %37939 = icmp eq i32 %37922, %37938
  %37940 = or i1 %37937, %37939
  %37941 = load i32, i32* %11, align 4
  %37942 = icmp eq i32 %37922, %37941
  %37943 = or i1 %37940, %37942
  %37944 = load i32, i32* %12, align 4
  %37945 = icmp eq i32 %37922, %37944
  %37946 = or i1 %37943, %37945
  %37947 = load i32, i32* %13, align 4
  %37948 = icmp eq i32 %37922, %37947
  %37949 = or i1 %37946, %37948
  %37950 = load i32, i32* %14, align 4
  %37951 = icmp eq i32 %37922, %37950
  %37952 = or i1 %37949, %37951
  %37953 = load i32, i32* %15, align 4
  %37954 = icmp eq i32 %37922, %37953
  %37955 = or i1 %37952, %37954
  %37956 = load i32, i32* %16, align 4
  %37957 = icmp eq i32 %37922, %37956
  %37958 = or i1 %37955, %37957
  %37959 = load i32, i32* %17, align 4
  %37960 = icmp eq i32 %37922, %37959
  %37961 = or i1 %37958, %37960
  %37962 = load i32, i32* %18, align 4
  %37963 = icmp eq i32 %37922, %37962
  %37964 = or i1 %37961, %37963
  %37965 = load i32, i32* %19, align 4
  %37966 = icmp eq i32 %37922, %37965
  %37967 = or i1 %37964, %37966
  %37968 = load i32, i32* %20, align 4
  %37969 = icmp eq i32 %37922, %37968
  %37970 = or i1 %37967, %37969
  %37971 = load i32, i32* %21, align 4
  %37972 = icmp eq i32 %37922, %37971
  %37973 = or i1 %37970, %37972
  %37974 = load i32, i32* %22, align 4
  %37975 = icmp eq i32 %37922, %37974
  %37976 = or i1 %37973, %37975
  %37977 = load i32, i32* %23, align 4
  %37978 = icmp eq i32 %37922, %37977
  %37979 = or i1 %37976, %37978
  %37980 = load i32, i32* %24, align 4
  %37981 = icmp eq i32 %37922, %37980
  %37982 = or i1 %37979, %37981
  %37983 = load i32, i32* %25, align 4
  %37984 = icmp eq i32 %37922, %37983
  %37985 = or i1 %37982, %37984
  %37986 = load i32, i32* %26, align 4
  %37987 = icmp eq i32 %37922, %37986
  %37988 = or i1 %37985, %37987
  %37989 = load i32, i32* %27, align 4
  %37990 = icmp eq i32 %37922, %37989
  %37991 = or i1 %37988, %37990
  %37992 = load i32, i32* %28, align 4
  %37993 = icmp eq i32 %37922, %37992
  %37994 = or i1 %37991, %37993
  %37995 = load i32, i32* %29, align 4
  %37996 = icmp eq i32 %37922, %37995
  %37997 = or i1 %37994, %37996
  %37998 = load i32, i32* %30, align 4
  %37999 = icmp eq i32 %37922, %37998
  %38000 = or i1 %37997, %37999
  %38001 = load i32, i32* %31, align 4
  %38002 = icmp eq i32 %37922, %38001
  %38003 = or i1 %38000, %38002
  %38004 = load i32, i32* %32, align 4
  %38005 = icmp eq i32 %37922, %38004
  %38006 = or i1 %38003, %38005
  %38007 = load i32, i32* %33, align 4
  %38008 = icmp eq i32 %37922, %38007
  %38009 = or i1 %38006, %38008
  %38010 = load i32, i32* %34, align 4
  %38011 = icmp eq i32 %37922, %38010
  %38012 = or i1 %38009, %38011
  %38013 = load i32, i32* %35, align 4
  %38014 = icmp eq i32 %37922, %38013
  %38015 = or i1 %38012, %38014
  %38016 = load i32, i32* %36, align 4
  %38017 = icmp eq i32 %37922, %38016
  %38018 = or i1 %38015, %38017
  %38019 = load i32, i32* %37, align 4
  %38020 = icmp eq i32 %37922, %38019
  %38021 = or i1 %38018, %38020
  %38022 = load i32, i32* %38, align 4
  %38023 = icmp eq i32 %37922, %38022
  %38024 = or i1 %38021, %38023
  %38025 = load i32, i32* %39, align 4
  %38026 = icmp eq i32 %37922, %38025
  %38027 = or i1 %38024, %38026
  %38028 = load i32, i32* %40, align 4
  %38029 = icmp eq i32 %37922, %38028
  %38030 = or i1 %38027, %38029
  %38031 = load i32, i32* %41, align 4
  %38032 = icmp eq i32 %37922, %38031
  %38033 = or i1 %38030, %38032
  %38034 = load i32, i32* %42, align 4
  %38035 = icmp eq i32 %37922, %38034
  %38036 = or i1 %38033, %38035
  %38037 = load i32, i32* %43, align 4
  %38038 = icmp eq i32 %37922, %38037
  %38039 = or i1 %38036, %38038
  %38040 = load i32, i32* %44, align 4
  %38041 = icmp eq i32 %37922, %38040
  %38042 = or i1 %38039, %38041
  %38043 = load i32, i32* %45, align 4
  %38044 = icmp eq i32 %37922, %38043
  %38045 = or i1 %38042, %38044
  %38046 = load i32, i32* %46, align 4
  %38047 = icmp eq i32 %37922, %38046
  %38048 = or i1 %38045, %38047
  %38049 = load i32, i32* %47, align 4
  %38050 = icmp eq i32 %37922, %38049
  %38051 = or i1 %38048, %38050
  %38052 = load i32, i32* %48, align 4
  %38053 = icmp eq i32 %37922, %38052
  %38054 = or i1 %38051, %38053
  %38055 = load i32, i32* %49, align 4
  %38056 = icmp eq i32 %37922, %38055
  %38057 = or i1 %38054, %38056
  %38058 = load i32, i32* %50, align 4
  %38059 = icmp eq i32 %37922, %38058
  %38060 = or i1 %38057, %38059
  %38061 = load i32, i32* %51, align 4
  %38062 = icmp eq i32 %37922, %38061
  %38063 = or i1 %38060, %38062
  %38064 = load i32, i32* %52, align 4
  %38065 = icmp eq i32 %37922, %38064
  %38066 = or i1 %38063, %38065
  %38067 = load i32, i32* %53, align 4
  %38068 = icmp eq i32 %37922, %38067
  %38069 = or i1 %38066, %38068
  %38070 = load i32, i32* %54, align 4
  %38071 = icmp eq i32 %37922, %38070
  %38072 = or i1 %38069, %38071
  %38073 = load i32, i32* %55, align 4
  %38074 = icmp eq i32 %37922, %38073
  %38075 = or i1 %38072, %38074
  %38076 = load i32, i32* %56, align 4
  %38077 = icmp eq i32 %37922, %38076
  %38078 = or i1 %38075, %38077
  %38079 = load i32, i32* %57, align 4
  %38080 = icmp eq i32 %37922, %38079
  %38081 = or i1 %38078, %38080
  %38082 = load i32, i32* %58, align 4
  %38083 = icmp eq i32 %37922, %38082
  %38084 = or i1 %38081, %38083
  %38085 = load i32, i32* %59, align 4
  %38086 = icmp eq i32 %37922, %38085
  %38087 = or i1 %38084, %38086
  %38088 = load i32, i32* %60, align 4
  %38089 = icmp eq i32 %37922, %38088
  %38090 = or i1 %38087, %38089
  %38091 = load i32, i32* %61, align 4
  %38092 = icmp eq i32 %37922, %38091
  %38093 = or i1 %38090, %38092
  %38094 = load i32, i32* %62, align 4
  %38095 = icmp eq i32 %37922, %38094
  %38096 = or i1 %38093, %38095
  %38097 = getelementptr i8, i8 addrspace(1)* %4, i32 138
  %38098 = zext i1 %38096 to i8
  store i8 %38098, i8 addrspace(1)* %38097, align 1, !nosanitize !3
  %38099 = load i256, i256* %37921, align 4
  %38100 = alloca i256, align 8
  store i256 %38099, i256* %38100, align 4
  %38101 = alloca i256, align 8
  store i256 1, i256* %38101, align 4
  %38102 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %38100, i256* %38101, i256* %38102), !pc !550, !intsan !6
  %38103 = load i256, i256* %38102, align 4
  %38104 = and i256 1461501637330902918203684832716283019655932542975, %38103
  %38105 = and i256 1461501637330902918203684832716283019655932542975, %38104
  %38106 = trunc i256 64 to i64
  %38107 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38106, i256* %38107)
  %38108 = load i256, i256* %38107, align 4
  %38109 = and i256 4294967295, 3306940687
  %38110 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %38109, !pc !551, !intsan !45
  %38111 = trunc i256 %38108 to i64
  %38112 = alloca i256, align 8
  store i256 %38110, i256* %38112, align 4
  %38113 = bitcast i256* %38112 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38111, i8* %38113, i64 32)
  %38114 = add i256 4, %38108, !pc !552, !intsan !10
  %38115 = trunc i256 %38114 to i64
  %38116 = alloca i256, align 8
  store i256 0, i256* %38116, align 4
  %38117 = bitcast i256* %38116 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38115, i8* %38117, i64 32)
  %38118 = add i256 32, %38114, !pc !553, !intsan !10
  %38119 = add i256 32, %38118, !pc !554, !intsan !10
  %38120 = add i256 32, %38119, !pc !555, !intsan !10
  %38121 = trunc i256 %38120 to i64
  %38122 = alloca i256, align 8
  store i256 %37907, i256* %38122, align 4
  %38123 = bitcast i256* %38122 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38121, i8* %38123, i64 32)
  %38124 = add i256 32, %38120, !pc !556, !intsan !10
  %38125 = sub i256 %38124, %38114, !pc !557, !intsan !8
  %38126 = trunc i256 %38118 to i64
  %38127 = alloca i256, align 8
  store i256 %38125, i256* %38127, align 4
  %38128 = bitcast i256* %38127 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38126, i8* %38128, i64 32)
  %38129 = trunc i256 %37917 to i64
  %38130 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38129, i256* %38130)
  %38131 = load i256, i256* %38130, align 4
  %38132 = trunc i256 %38124 to i64
  %38133 = alloca i256, align 8
  store i256 %38131, i256* %38133, align 4
  %38134 = bitcast i256* %38133 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38132, i8* %38134, i64 32)
  %38135 = add i256 32, %38124, !pc !558, !intsan !10
  %38136 = trunc i256 %37917 to i64
  %38137 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38136, i256* %38137)
  %38138 = load i256, i256* %38137, align 4
  %38139 = add i256 32, %37917, !pc !559, !intsan !10
  %38140 = load i64, i64* %STACK_DEP_PTR, align 4
  %38141 = add i64 %38140, 1
  store i64 %38141, i64* %STACK_DEP_PTR, align 4
  %38142 = load i64, i64* %STACK_DEP_PTR, align 4
  %38143 = getelementptr i256, i256* %STACK, i64 %38142
  store i256 %37917, i256* %38143, align 4
  %38144 = load i64, i64* %STACK_DEP_PTR, align 4
  %38145 = add i64 %38144, 1
  store i64 %38145, i64* %STACK_DEP_PTR, align 4
  %38146 = load i64, i64* %STACK_DEP_PTR, align 4
  %38147 = getelementptr i256, i256* %STACK, i64 %38146
  store i256 %37912, i256* %38147, align 4
  %38148 = load i64, i64* %STACK_DEP_PTR, align 4
  %38149 = add i64 %38148, 1
  store i64 %38149, i64* %STACK_DEP_PTR, align 4
  %38150 = load i64, i64* %STACK_DEP_PTR, align 4
  %38151 = getelementptr i256, i256* %STACK, i64 %38150
  store i256 %37907, i256* %38151, align 4
  %38152 = load i64, i64* %STACK_DEP_PTR, align 4
  %38153 = add i64 %38152, 1
  store i64 %38153, i64* %STACK_DEP_PTR, align 4
  %38154 = load i64, i64* %STACK_DEP_PTR, align 4
  %38155 = getelementptr i256, i256* %STACK, i64 %38154
  store i256 %37902, i256* %38155, align 4
  %38156 = load i64, i64* %STACK_DEP_PTR, align 4
  %38157 = add i64 %38156, 1
  store i64 %38157, i64* %STACK_DEP_PTR, align 4
  %38158 = load i64, i64* %STACK_DEP_PTR, align 4
  %38159 = getelementptr i256, i256* %STACK, i64 %38158
  store i256 %37897, i256* %38159, align 4
  %38160 = load i64, i64* %STACK_DEP_PTR, align 4
  %38161 = add i64 %38160, 1
  store i64 %38161, i64* %STACK_DEP_PTR, align 4
  %38162 = load i64, i64* %STACK_DEP_PTR, align 4
  %38163 = getelementptr i256, i256* %STACK, i64 %38162
  store i256 %38105, i256* %38163, align 4
  %38164 = load i64, i64* %STACK_DEP_PTR, align 4
  %38165 = add i64 %38164, 1
  store i64 %38165, i64* %STACK_DEP_PTR, align 4
  %38166 = load i64, i64* %STACK_DEP_PTR, align 4
  %38167 = getelementptr i256, i256* %STACK, i64 %38166
  store i256 3306940687, i256* %38167, align 4
  %38168 = load i64, i64* %STACK_DEP_PTR, align 4
  %38169 = add i64 %38168, 1
  store i64 %38169, i64* %STACK_DEP_PTR, align 4
  %38170 = load i64, i64* %STACK_DEP_PTR, align 4
  %38171 = getelementptr i256, i256* %STACK, i64 %38170
  store i256 %37897, i256* %38171, align 4
  %38172 = load i64, i64* %STACK_DEP_PTR, align 4
  %38173 = add i64 %38172, 1
  store i64 %38173, i64* %STACK_DEP_PTR, align 4
  %38174 = load i64, i64* %STACK_DEP_PTR, align 4
  %38175 = getelementptr i256, i256* %STACK, i64 %38174
  store i256 0, i256* %38175, align 4
  %38176 = load i64, i64* %STACK_DEP_PTR, align 4
  %38177 = add i64 %38176, 1
  store i64 %38177, i64* %STACK_DEP_PTR, align 4
  %38178 = load i64, i64* %STACK_DEP_PTR, align 4
  %38179 = getelementptr i256, i256* %STACK, i64 %38178
  store i256 %37917, i256* %38179, align 4
  %38180 = load i64, i64* %STACK_DEP_PTR, align 4
  %38181 = add i64 %38180, 1
  store i64 %38181, i64* %STACK_DEP_PTR, align 4
  %38182 = load i64, i64* %STACK_DEP_PTR, align 4
  %38183 = getelementptr i256, i256* %STACK, i64 %38182
  store i256 %37912, i256* %38183, align 4
  %38184 = load i64, i64* %STACK_DEP_PTR, align 4
  %38185 = add i64 %38184, 1
  store i64 %38185, i64* %STACK_DEP_PTR, align 4
  %38186 = load i64, i64* %STACK_DEP_PTR, align 4
  %38187 = getelementptr i256, i256* %STACK, i64 %38186
  store i256 %37907, i256* %38187, align 4
  %38188 = load i64, i64* %STACK_DEP_PTR, align 4
  %38189 = add i64 %38188, 1
  store i64 %38189, i64* %STACK_DEP_PTR, align 4
  %38190 = load i64, i64* %STACK_DEP_PTR, align 4
  %38191 = getelementptr i256, i256* %STACK, i64 %38190
  store i256 %38114, i256* %38191, align 4
  %38192 = load i64, i64* %STACK_DEP_PTR, align 4
  %38193 = add i64 %38192, 1
  store i64 %38193, i64* %STACK_DEP_PTR, align 4
  %38194 = load i64, i64* %STACK_DEP_PTR, align 4
  %38195 = getelementptr i256, i256* %STACK, i64 %38194
  store i256 %38118, i256* %38195, align 4
  %38196 = load i64, i64* %STACK_DEP_PTR, align 4
  %38197 = add i64 %38196, 1
  store i64 %38197, i64* %STACK_DEP_PTR, align 4
  %38198 = load i64, i64* %STACK_DEP_PTR, align 4
  %38199 = getelementptr i256, i256* %STACK, i64 %38198
  store i256 %38119, i256* %38199, align 4
  %38200 = load i64, i64* %STACK_DEP_PTR, align 4
  %38201 = add i64 %38200, 1
  store i64 %38201, i64* %STACK_DEP_PTR, align 4
  %38202 = load i64, i64* %STACK_DEP_PTR, align 4
  %38203 = getelementptr i256, i256* %STACK, i64 %38202
  store i256 %38135, i256* %38203, align 4
  %38204 = load i64, i64* %STACK_DEP_PTR, align 4
  %38205 = add i64 %38204, 1
  store i64 %38205, i64* %STACK_DEP_PTR, align 4
  %38206 = load i64, i64* %STACK_DEP_PTR, align 4
  %38207 = getelementptr i256, i256* %STACK, i64 %38206
  store i256 %38139, i256* %38207, align 4
  %38208 = load i64, i64* %STACK_DEP_PTR, align 4
  %38209 = add i64 %38208, 1
  store i64 %38209, i64* %STACK_DEP_PTR, align 4
  %38210 = load i64, i64* %STACK_DEP_PTR, align 4
  %38211 = getelementptr i256, i256* %STACK, i64 %38210
  store i256 %38138, i256* %38211, align 4
  %38212 = load i64, i64* %STACK_DEP_PTR, align 4
  %38213 = add i64 %38212, 1
  store i64 %38213, i64* %STACK_DEP_PTR, align 4
  %38214 = load i64, i64* %STACK_DEP_PTR, align 4
  %38215 = getelementptr i256, i256* %STACK, i64 %38214
  store i256 %38138, i256* %38215, align 4
  %38216 = load i64, i64* %STACK_DEP_PTR, align 4
  %38217 = add i64 %38216, 1
  store i64 %38217, i64* %STACK_DEP_PTR, align 4
  %38218 = load i64, i64* %STACK_DEP_PTR, align 4
  %38219 = getelementptr i256, i256* %STACK, i64 %38218
  store i256 %38135, i256* %38219, align 4
  %38220 = load i64, i64* %STACK_DEP_PTR, align 4
  %38221 = add i64 %38220, 1
  store i64 %38221, i64* %STACK_DEP_PTR, align 4
  %38222 = load i64, i64* %STACK_DEP_PTR, align 4
  %38223 = getelementptr i256, i256* %STACK, i64 %38222
  store i256 %38139, i256* %38223, align 4
  %38224 = load i64, i64* %STACK_DEP_PTR, align 4
  %38225 = add i64 %38224, 1
  store i64 %38225, i64* %STACK_DEP_PTR, align 4
  %38226 = load i64, i64* %STACK_DEP_PTR, align 4
  %38227 = getelementptr i256, i256* %STACK, i64 %38226
  store i256 0, i256* %38227, align 4
  br label %.12721

.12721:                                           ; preds = %38278, %.12557, %JumpTable
  %38228 = load i64, i64* %remaing_gas, align 4
  %38229 = icmp ugt i64 432, %38228
  br i1 %38229, label %Abort, label %38230

38230:                                            ; preds = %.12721
  %38231 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38232 = xor i32 %38231, 1831
  %38233 = urem i32 %38232, 4096
  %38234 = getelementptr i8, i8 addrspace(1)* %4, i32 %38233
  %38235 = load i8, i8 addrspace(1)* %38234, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38234, align 1, !nosanitize !3
  store i32 915, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38236 = sub i64 %38228, 432
  store i64 %38236, i64* %remaing_gas, align 4
  %38237 = load i64, i64* %STACK_DEP_PTR, align 4
  %38238 = getelementptr i256, i256* %STACK, i64 %38237
  %38239 = load i256, i256* %38238, align 4
  %38240 = load i64, i64* %STACK_DEP_PTR, align 4
  %38241 = sub i64 %38240, 1
  store i64 %38241, i64* %STACK_DEP_PTR, align 4
  %38242 = load i64, i64* %STACK_DEP_PTR, align 4
  %38243 = getelementptr i256, i256* %STACK, i64 %38242
  %38244 = load i256, i256* %38243, align 4
  %38245 = load i64, i64* %STACK_DEP_PTR, align 4
  %38246 = sub i64 %38245, 1
  store i64 %38246, i64* %STACK_DEP_PTR, align 4
  %38247 = load i64, i64* %STACK_DEP_PTR, align 4
  %38248 = getelementptr i256, i256* %STACK, i64 %38247
  %38249 = load i256, i256* %38248, align 4
  %38250 = load i64, i64* %STACK_DEP_PTR, align 4
  %38251 = sub i64 %38250, 1
  store i64 %38251, i64* %STACK_DEP_PTR, align 4
  %38252 = load i64, i64* %STACK_DEP_PTR, align 4
  %38253 = getelementptr i256, i256* %STACK, i64 %38252
  %38254 = load i256, i256* %38253, align 4
  %38255 = load i64, i64* %STACK_DEP_PTR, align 4
  %38256 = sub i64 %38255, 1
  store i64 %38256, i64* %STACK_DEP_PTR, align 4
  %38257 = icmp ult i256 %38239, %38254
  %38258 = icmp eq i1 %38257, false
  %38259 = trunc i256 12748 to i64
  %jump.check211 = icmp ne i1 %38258, false
  %38260 = load i64, i64* %STACK_DEP_PTR, align 4
  %38261 = add i64 %38260, 1
  store i64 %38261, i64* %STACK_DEP_PTR, align 4
  %38262 = load i64, i64* %STACK_DEP_PTR, align 4
  %38263 = getelementptr i256, i256* %STACK, i64 %38262
  store i256 %38254, i256* %38263, align 4
  %38264 = load i64, i64* %STACK_DEP_PTR, align 4
  %38265 = add i64 %38264, 1
  store i64 %38265, i64* %STACK_DEP_PTR, align 4
  %38266 = load i64, i64* %STACK_DEP_PTR, align 4
  %38267 = getelementptr i256, i256* %STACK, i64 %38266
  store i256 %38249, i256* %38267, align 4
  %38268 = load i64, i64* %STACK_DEP_PTR, align 4
  %38269 = add i64 %38268, 1
  store i64 %38269, i64* %STACK_DEP_PTR, align 4
  %38270 = load i64, i64* %STACK_DEP_PTR, align 4
  %38271 = getelementptr i256, i256* %STACK, i64 %38270
  store i256 %38244, i256* %38271, align 4
  %38272 = load i64, i64* %STACK_DEP_PTR, align 4
  %38273 = add i64 %38272, 1
  store i64 %38273, i64* %STACK_DEP_PTR, align 4
  %38274 = load i64, i64* %STACK_DEP_PTR, align 4
  %38275 = getelementptr i256, i256* %STACK, i64 %38274
  store i256 %38239, i256* %38275, align 4
  br i1 %jump.check211, label %.12748, label %.12730, !EVMBB !4

.12730:                                           ; preds = %38230
  %38276 = load i64, i64* %remaing_gas, align 4
  %38277 = icmp ugt i64 408, %38276
  br i1 %38277, label %Abort, label %38278

38278:                                            ; preds = %.12730
  %38279 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38280 = xor i32 %38279, 2838
  %38281 = urem i32 %38280, 4096
  %38282 = getelementptr i8, i8 addrspace(1)* %4, i32 %38281
  %38283 = load i8, i8 addrspace(1)* %38282, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38282, align 1, !nosanitize !3
  store i32 1419, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38284 = sub i64 %38276, 408
  store i64 %38284, i64* %remaing_gas, align 4
  %38285 = load i64, i64* %STACK_DEP_PTR, align 4
  %38286 = getelementptr i256, i256* %STACK, i64 %38285
  %38287 = load i256, i256* %38286, align 4
  %38288 = load i64, i64* %STACK_DEP_PTR, align 4
  %38289 = sub i64 %38288, 1
  store i64 %38289, i64* %STACK_DEP_PTR, align 4
  %38290 = load i64, i64* %STACK_DEP_PTR, align 4
  %38291 = getelementptr i256, i256* %STACK, i64 %38290
  %38292 = load i256, i256* %38291, align 4
  %38293 = load i64, i64* %STACK_DEP_PTR, align 4
  %38294 = sub i64 %38293, 1
  store i64 %38294, i64* %STACK_DEP_PTR, align 4
  %38295 = load i64, i64* %STACK_DEP_PTR, align 4
  %38296 = getelementptr i256, i256* %STACK, i64 %38295
  %38297 = load i256, i256* %38296, align 4
  %38298 = load i64, i64* %STACK_DEP_PTR, align 4
  %38299 = sub i64 %38298, 1
  store i64 %38299, i64* %STACK_DEP_PTR, align 4
  %38300 = add i256 %38292, %38287, !pc !560, !intsan !10
  %38301 = trunc i256 %38300 to i64
  %38302 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38301, i256* %38302)
  %38303 = load i256, i256* %38302, align 4
  %38304 = add i256 %38297, %38287, !pc !561, !intsan !10
  %38305 = trunc i256 %38304 to i64
  %38306 = alloca i256, align 8
  store i256 %38303, i256* %38306, align 4
  %38307 = bitcast i256* %38306 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38305, i8* %38307, i64 32)
  %38308 = add i256 %38287, 32, !pc !562, !intsan !10
  %38309 = trunc i256 12721 to i64
  %38310 = load i64, i64* %STACK_DEP_PTR, align 4
  %38311 = add i64 %38310, 1
  store i64 %38311, i64* %STACK_DEP_PTR, align 4
  %38312 = load i64, i64* %STACK_DEP_PTR, align 4
  %38313 = getelementptr i256, i256* %STACK, i64 %38312
  store i256 %38297, i256* %38313, align 4
  %38314 = load i64, i64* %STACK_DEP_PTR, align 4
  %38315 = add i64 %38314, 1
  store i64 %38315, i64* %STACK_DEP_PTR, align 4
  %38316 = load i64, i64* %STACK_DEP_PTR, align 4
  %38317 = getelementptr i256, i256* %STACK, i64 %38316
  store i256 %38292, i256* %38317, align 4
  %38318 = load i64, i64* %STACK_DEP_PTR, align 4
  %38319 = add i64 %38318, 1
  store i64 %38319, i64* %STACK_DEP_PTR, align 4
  %38320 = load i64, i64* %STACK_DEP_PTR, align 4
  %38321 = getelementptr i256, i256* %STACK, i64 %38320
  store i256 %38308, i256* %38321, align 4
  br label %.12721, !EVMBB !4

.12748:                                           ; preds = %38230, %JumpTable
  %38322 = load i64, i64* %remaing_gas, align 4
  %38323 = icmp ugt i64 488, %38322
  br i1 %38323, label %Abort, label %38324

38324:                                            ; preds = %.12748
  %38325 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38326 = xor i32 %38325, 915
  %38327 = urem i32 %38326, 4096
  %38328 = getelementptr i8, i8 addrspace(1)* %4, i32 %38327
  %38329 = load i8, i8 addrspace(1)* %38328, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38328, align 1, !nosanitize !3
  store i32 457, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38330 = sub i64 %38322, 488
  store i64 %38330, i64* %remaing_gas, align 4
  %38331 = load i64, i64* %STACK_DEP_PTR, align 4
  %38332 = getelementptr i256, i256* %STACK, i64 %38331
  %38333 = load i256, i256* %38332, align 4
  %38334 = load i64, i64* %STACK_DEP_PTR, align 4
  %38335 = sub i64 %38334, 1
  store i64 %38335, i64* %STACK_DEP_PTR, align 4
  %38336 = load i64, i64* %STACK_DEP_PTR, align 4
  %38337 = getelementptr i256, i256* %STACK, i64 %38336
  %38338 = load i256, i256* %38337, align 4
  %38339 = load i64, i64* %STACK_DEP_PTR, align 4
  %38340 = sub i64 %38339, 1
  store i64 %38340, i64* %STACK_DEP_PTR, align 4
  %38341 = load i64, i64* %STACK_DEP_PTR, align 4
  %38342 = getelementptr i256, i256* %STACK, i64 %38341
  %38343 = load i256, i256* %38342, align 4
  %38344 = load i64, i64* %STACK_DEP_PTR, align 4
  %38345 = sub i64 %38344, 1
  store i64 %38345, i64* %STACK_DEP_PTR, align 4
  %38346 = load i64, i64* %STACK_DEP_PTR, align 4
  %38347 = getelementptr i256, i256* %STACK, i64 %38346
  %38348 = load i256, i256* %38347, align 4
  %38349 = load i64, i64* %STACK_DEP_PTR, align 4
  %38350 = sub i64 %38349, 1
  store i64 %38350, i64* %STACK_DEP_PTR, align 4
  %38351 = load i64, i64* %STACK_DEP_PTR, align 4
  %38352 = getelementptr i256, i256* %STACK, i64 %38351
  %38353 = load i256, i256* %38352, align 4
  %38354 = load i64, i64* %STACK_DEP_PTR, align 4
  %38355 = sub i64 %38354, 1
  store i64 %38355, i64* %STACK_DEP_PTR, align 4
  %38356 = load i64, i64* %STACK_DEP_PTR, align 4
  %38357 = getelementptr i256, i256* %STACK, i64 %38356
  %38358 = load i256, i256* %38357, align 4
  %38359 = load i64, i64* %STACK_DEP_PTR, align 4
  %38360 = sub i64 %38359, 1
  store i64 %38360, i64* %STACK_DEP_PTR, align 4
  %38361 = load i64, i64* %STACK_DEP_PTR, align 4
  %38362 = getelementptr i256, i256* %STACK, i64 %38361
  %38363 = load i256, i256* %38362, align 4
  %38364 = load i64, i64* %STACK_DEP_PTR, align 4
  %38365 = sub i64 %38364, 1
  store i64 %38365, i64* %STACK_DEP_PTR, align 4
  %38366 = add i256 %38353, %38363, !pc !563, !intsan !10
  %38367 = and i256 31, %38353
  %38368 = icmp eq i256 %38367, 0
  %38369 = trunc i256 12793 to i64
  %jump.check212 = icmp ne i1 %38368, false
  %38370 = load i64, i64* %STACK_DEP_PTR, align 4
  %38371 = add i64 %38370, 1
  store i64 %38371, i64* %STACK_DEP_PTR, align 4
  %38372 = load i64, i64* %STACK_DEP_PTR, align 4
  %38373 = getelementptr i256, i256* %STACK, i64 %38372
  store i256 %38366, i256* %38373, align 4
  %38374 = load i64, i64* %STACK_DEP_PTR, align 4
  %38375 = add i64 %38374, 1
  store i64 %38375, i64* %STACK_DEP_PTR, align 4
  %38376 = load i64, i64* %STACK_DEP_PTR, align 4
  %38377 = getelementptr i256, i256* %STACK, i64 %38376
  store i256 %38367, i256* %38377, align 4
  br i1 %jump.check212, label %.12793, label %.12768, !EVMBB !4

.12768:                                           ; preds = %38324
  %38378 = load i64, i64* %STACK_DEP_PTR, align 4
  %38379 = getelementptr i256, i256* %STACK, i64 %38378
  %38380 = load i256, i256* %38379, align 4
  %38381 = load i64, i64* %STACK_DEP_PTR, align 4
  %38382 = sub i64 %38381, 1
  store i64 %38382, i64* %STACK_DEP_PTR, align 4
  %38383 = load i64, i64* %STACK_DEP_PTR, align 4
  %38384 = getelementptr i256, i256* %STACK, i64 %38383
  %38385 = load i256, i256* %38384, align 4
  %38386 = load i64, i64* %STACK_DEP_PTR, align 4
  %38387 = sub i64 %38386, 1
  store i64 %38387, i64* %STACK_DEP_PTR, align 4
  %38388 = sub i256 %38385, %38380, !pc !564, !intsan !8
  %38389 = trunc i256 %38388 to i64
  %38390 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38389, i256* %38390)
  %38391 = load i256, i256* %38390, align 4
  %38392 = sub i256 32, %38380, !pc !565, !intsan !8
  %38393 = alloca i256, align 8
  store i256 256, i256* %38393, align 4
  %38394 = alloca i256, align 8
  store i256 %38392, i256* %38394, align 4
  %38395 = alloca i256, align 8
  call void @__power_word(i256* %38393, i256* %38394, i256* %38395)
  %38396 = load volatile i256, i256* %38395, align 4
  %38397 = sub i256 %38396, 1, !pc !566, !intsan !8
  %38398 = xor i256 %38397, -1
  %38399 = and i256 %38398, %38391
  %38400 = trunc i256 %38388 to i64
  %38401 = alloca i256, align 8
  store i256 %38399, i256* %38401, align 4
  %38402 = bitcast i256* %38401 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38400, i8* %38402, i64 32)
  %38403 = add i256 32, %38388, !pc !567, !intsan !10
  %38404 = load i64, i64* %STACK_DEP_PTR, align 4
  %38405 = add i64 %38404, 1
  store i64 %38405, i64* %STACK_DEP_PTR, align 4
  %38406 = load i64, i64* %STACK_DEP_PTR, align 4
  %38407 = getelementptr i256, i256* %STACK, i64 %38406
  store i256 %38403, i256* %38407, align 4
  %38408 = load i64, i64* %STACK_DEP_PTR, align 4
  %38409 = add i64 %38408, 1
  store i64 %38409, i64* %STACK_DEP_PTR, align 4
  %38410 = load i64, i64* %STACK_DEP_PTR, align 4
  %38411 = getelementptr i256, i256* %STACK, i64 %38410
  store i256 %38380, i256* %38411, align 4
  br label %.12793

.12793:                                           ; preds = %.12768, %38324, %JumpTable
  %38412 = load i64, i64* %STACK_DEP_PTR, align 4
  %38413 = getelementptr i256, i256* %STACK, i64 %38412
  %38414 = load i256, i256* %38413, align 4
  %38415 = load i64, i64* %STACK_DEP_PTR, align 4
  %38416 = sub i64 %38415, 1
  store i64 %38416, i64* %STACK_DEP_PTR, align 4
  %38417 = load i64, i64* %STACK_DEP_PTR, align 4
  %38418 = getelementptr i256, i256* %STACK, i64 %38417
  %38419 = load i256, i256* %38418, align 4
  %38420 = load i64, i64* %STACK_DEP_PTR, align 4
  %38421 = sub i64 %38420, 1
  store i64 %38421, i64* %STACK_DEP_PTR, align 4
  %38422 = load i64, i64* %STACK_DEP_PTR, align 4
  %38423 = getelementptr i256, i256* %STACK, i64 %38422
  %38424 = load i256, i256* %38423, align 4
  %38425 = load i64, i64* %STACK_DEP_PTR, align 4
  %38426 = sub i64 %38425, 1
  store i64 %38426, i64* %STACK_DEP_PTR, align 4
  %38427 = load i64, i64* %STACK_DEP_PTR, align 4
  %38428 = getelementptr i256, i256* %STACK, i64 %38427
  %38429 = load i256, i256* %38428, align 4
  %38430 = load i64, i64* %STACK_DEP_PTR, align 4
  %38431 = sub i64 %38430, 1
  store i64 %38431, i64* %STACK_DEP_PTR, align 4
  %38432 = load i64, i64* %STACK_DEP_PTR, align 4
  %38433 = getelementptr i256, i256* %STACK, i64 %38432
  %38434 = load i256, i256* %38433, align 4
  %38435 = load i64, i64* %STACK_DEP_PTR, align 4
  %38436 = sub i64 %38435, 1
  store i64 %38436, i64* %STACK_DEP_PTR, align 4
  %38437 = load i64, i64* %STACK_DEP_PTR, align 4
  %38438 = getelementptr i256, i256* %STACK, i64 %38437
  %38439 = load i256, i256* %38438, align 4
  %38440 = load i64, i64* %STACK_DEP_PTR, align 4
  %38441 = sub i64 %38440, 1
  store i64 %38441, i64* %STACK_DEP_PTR, align 4
  %38442 = load i64, i64* %STACK_DEP_PTR, align 4
  %38443 = getelementptr i256, i256* %STACK, i64 %38442
  %38444 = load i256, i256* %38443, align 4
  %38445 = load i64, i64* %STACK_DEP_PTR, align 4
  %38446 = sub i64 %38445, 1
  store i64 %38446, i64* %STACK_DEP_PTR, align 4
  %38447 = sub i256 %38419, %38434, !pc !568, !intsan !8
  %38448 = trunc i256 %38424 to i64
  %38449 = alloca i256, align 8
  store i256 %38447, i256* %38449, align 4
  %38450 = bitcast i256* %38449 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38448, i8* %38450, i64 32)
  %38451 = trunc i256 %38444 to i64
  %38452 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38451, i256* %38452)
  %38453 = load i256, i256* %38452, align 4
  %38454 = trunc i256 %38419 to i64
  %38455 = alloca i256, align 8
  store i256 %38453, i256* %38455, align 4
  %38456 = bitcast i256* %38455 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38454, i8* %38456, i64 32)
  %38457 = add i256 32, %38419, !pc !569, !intsan !10
  %38458 = trunc i256 %38444 to i64
  %38459 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38458, i256* %38459)
  %38460 = load i256, i256* %38459, align 4
  %38461 = add i256 32, %38444, !pc !570, !intsan !10
  %38462 = load i64, i64* %STACK_DEP_PTR, align 4
  %38463 = add i64 %38462, 1
  store i64 %38463, i64* %STACK_DEP_PTR, align 4
  %38464 = load i64, i64* %STACK_DEP_PTR, align 4
  %38465 = getelementptr i256, i256* %STACK, i64 %38464
  store i256 %38444, i256* %38465, align 4
  %38466 = load i64, i64* %STACK_DEP_PTR, align 4
  %38467 = add i64 %38466, 1
  store i64 %38467, i64* %STACK_DEP_PTR, align 4
  %38468 = load i64, i64* %STACK_DEP_PTR, align 4
  %38469 = getelementptr i256, i256* %STACK, i64 %38468
  store i256 %38439, i256* %38469, align 4
  %38470 = load i64, i64* %STACK_DEP_PTR, align 4
  %38471 = add i64 %38470, 1
  store i64 %38471, i64* %STACK_DEP_PTR, align 4
  %38472 = load i64, i64* %STACK_DEP_PTR, align 4
  %38473 = getelementptr i256, i256* %STACK, i64 %38472
  store i256 %38434, i256* %38473, align 4
  %38474 = load i64, i64* %STACK_DEP_PTR, align 4
  %38475 = add i64 %38474, 1
  store i64 %38475, i64* %STACK_DEP_PTR, align 4
  %38476 = load i64, i64* %STACK_DEP_PTR, align 4
  %38477 = getelementptr i256, i256* %STACK, i64 %38476
  store i256 %38429, i256* %38477, align 4
  %38478 = load i64, i64* %STACK_DEP_PTR, align 4
  %38479 = add i64 %38478, 1
  store i64 %38479, i64* %STACK_DEP_PTR, align 4
  %38480 = load i64, i64* %STACK_DEP_PTR, align 4
  %38481 = getelementptr i256, i256* %STACK, i64 %38480
  store i256 %38424, i256* %38481, align 4
  %38482 = load i64, i64* %STACK_DEP_PTR, align 4
  %38483 = add i64 %38482, 1
  store i64 %38483, i64* %STACK_DEP_PTR, align 4
  %38484 = load i64, i64* %STACK_DEP_PTR, align 4
  %38485 = getelementptr i256, i256* %STACK, i64 %38484
  store i256 %38457, i256* %38485, align 4
  %38486 = load i64, i64* %STACK_DEP_PTR, align 4
  %38487 = add i64 %38486, 1
  store i64 %38487, i64* %STACK_DEP_PTR, align 4
  %38488 = load i64, i64* %STACK_DEP_PTR, align 4
  %38489 = getelementptr i256, i256* %STACK, i64 %38488
  store i256 %38461, i256* %38489, align 4
  %38490 = load i64, i64* %STACK_DEP_PTR, align 4
  %38491 = add i64 %38490, 1
  store i64 %38491, i64* %STACK_DEP_PTR, align 4
  %38492 = load i64, i64* %STACK_DEP_PTR, align 4
  %38493 = getelementptr i256, i256* %STACK, i64 %38492
  store i256 %38460, i256* %38493, align 4
  %38494 = load i64, i64* %STACK_DEP_PTR, align 4
  %38495 = add i64 %38494, 1
  store i64 %38495, i64* %STACK_DEP_PTR, align 4
  %38496 = load i64, i64* %STACK_DEP_PTR, align 4
  %38497 = getelementptr i256, i256* %STACK, i64 %38496
  store i256 %38460, i256* %38497, align 4
  %38498 = load i64, i64* %STACK_DEP_PTR, align 4
  %38499 = add i64 %38498, 1
  store i64 %38499, i64* %STACK_DEP_PTR, align 4
  %38500 = load i64, i64* %STACK_DEP_PTR, align 4
  %38501 = getelementptr i256, i256* %STACK, i64 %38500
  store i256 %38457, i256* %38501, align 4
  %38502 = load i64, i64* %STACK_DEP_PTR, align 4
  %38503 = add i64 %38502, 1
  store i64 %38503, i64* %STACK_DEP_PTR, align 4
  %38504 = load i64, i64* %STACK_DEP_PTR, align 4
  %38505 = getelementptr i256, i256* %STACK, i64 %38504
  store i256 %38461, i256* %38505, align 4
  %38506 = load i64, i64* %STACK_DEP_PTR, align 4
  %38507 = add i64 %38506, 1
  store i64 %38507, i64* %STACK_DEP_PTR, align 4
  %38508 = load i64, i64* %STACK_DEP_PTR, align 4
  %38509 = getelementptr i256, i256* %STACK, i64 %38508
  store i256 0, i256* %38509, align 4
  br label %.12823

.12823:                                           ; preds = %38560, %.12793, %JumpTable
  %38510 = load i64, i64* %remaing_gas, align 4
  %38511 = icmp ugt i64 432, %38510
  br i1 %38511, label %Abort, label %38512

38512:                                            ; preds = %.12823
  %38513 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38514 = xor i32 %38513, 4012
  %38515 = urem i32 %38514, 4096
  %38516 = getelementptr i8, i8 addrspace(1)* %4, i32 %38515
  %38517 = load i8, i8 addrspace(1)* %38516, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38516, align 1, !nosanitize !3
  store i32 2006, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38518 = sub i64 %38510, 432
  store i64 %38518, i64* %remaing_gas, align 4
  %38519 = load i64, i64* %STACK_DEP_PTR, align 4
  %38520 = getelementptr i256, i256* %STACK, i64 %38519
  %38521 = load i256, i256* %38520, align 4
  %38522 = load i64, i64* %STACK_DEP_PTR, align 4
  %38523 = sub i64 %38522, 1
  store i64 %38523, i64* %STACK_DEP_PTR, align 4
  %38524 = load i64, i64* %STACK_DEP_PTR, align 4
  %38525 = getelementptr i256, i256* %STACK, i64 %38524
  %38526 = load i256, i256* %38525, align 4
  %38527 = load i64, i64* %STACK_DEP_PTR, align 4
  %38528 = sub i64 %38527, 1
  store i64 %38528, i64* %STACK_DEP_PTR, align 4
  %38529 = load i64, i64* %STACK_DEP_PTR, align 4
  %38530 = getelementptr i256, i256* %STACK, i64 %38529
  %38531 = load i256, i256* %38530, align 4
  %38532 = load i64, i64* %STACK_DEP_PTR, align 4
  %38533 = sub i64 %38532, 1
  store i64 %38533, i64* %STACK_DEP_PTR, align 4
  %38534 = load i64, i64* %STACK_DEP_PTR, align 4
  %38535 = getelementptr i256, i256* %STACK, i64 %38534
  %38536 = load i256, i256* %38535, align 4
  %38537 = load i64, i64* %STACK_DEP_PTR, align 4
  %38538 = sub i64 %38537, 1
  store i64 %38538, i64* %STACK_DEP_PTR, align 4
  %38539 = icmp ult i256 %38521, %38536
  %38540 = icmp eq i1 %38539, false
  %38541 = trunc i256 12850 to i64
  %jump.check213 = icmp ne i1 %38540, false
  %38542 = load i64, i64* %STACK_DEP_PTR, align 4
  %38543 = add i64 %38542, 1
  store i64 %38543, i64* %STACK_DEP_PTR, align 4
  %38544 = load i64, i64* %STACK_DEP_PTR, align 4
  %38545 = getelementptr i256, i256* %STACK, i64 %38544
  store i256 %38536, i256* %38545, align 4
  %38546 = load i64, i64* %STACK_DEP_PTR, align 4
  %38547 = add i64 %38546, 1
  store i64 %38547, i64* %STACK_DEP_PTR, align 4
  %38548 = load i64, i64* %STACK_DEP_PTR, align 4
  %38549 = getelementptr i256, i256* %STACK, i64 %38548
  store i256 %38531, i256* %38549, align 4
  %38550 = load i64, i64* %STACK_DEP_PTR, align 4
  %38551 = add i64 %38550, 1
  store i64 %38551, i64* %STACK_DEP_PTR, align 4
  %38552 = load i64, i64* %STACK_DEP_PTR, align 4
  %38553 = getelementptr i256, i256* %STACK, i64 %38552
  store i256 %38526, i256* %38553, align 4
  %38554 = load i64, i64* %STACK_DEP_PTR, align 4
  %38555 = add i64 %38554, 1
  store i64 %38555, i64* %STACK_DEP_PTR, align 4
  %38556 = load i64, i64* %STACK_DEP_PTR, align 4
  %38557 = getelementptr i256, i256* %STACK, i64 %38556
  store i256 %38521, i256* %38557, align 4
  br i1 %jump.check213, label %.12850, label %.12832, !EVMBB !4

.12832:                                           ; preds = %38512
  %38558 = load i64, i64* %remaing_gas, align 4
  %38559 = icmp ugt i64 408, %38558
  br i1 %38559, label %Abort, label %38560

38560:                                            ; preds = %.12832
  %38561 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38562 = xor i32 %38561, 519
  %38563 = urem i32 %38562, 4096
  %38564 = getelementptr i8, i8 addrspace(1)* %4, i32 %38563
  %38565 = load i8, i8 addrspace(1)* %38564, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38564, align 1, !nosanitize !3
  store i32 259, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38566 = sub i64 %38558, 408
  store i64 %38566, i64* %remaing_gas, align 4
  %38567 = load i64, i64* %STACK_DEP_PTR, align 4
  %38568 = getelementptr i256, i256* %STACK, i64 %38567
  %38569 = load i256, i256* %38568, align 4
  %38570 = load i64, i64* %STACK_DEP_PTR, align 4
  %38571 = sub i64 %38570, 1
  store i64 %38571, i64* %STACK_DEP_PTR, align 4
  %38572 = load i64, i64* %STACK_DEP_PTR, align 4
  %38573 = getelementptr i256, i256* %STACK, i64 %38572
  %38574 = load i256, i256* %38573, align 4
  %38575 = load i64, i64* %STACK_DEP_PTR, align 4
  %38576 = sub i64 %38575, 1
  store i64 %38576, i64* %STACK_DEP_PTR, align 4
  %38577 = load i64, i64* %STACK_DEP_PTR, align 4
  %38578 = getelementptr i256, i256* %STACK, i64 %38577
  %38579 = load i256, i256* %38578, align 4
  %38580 = load i64, i64* %STACK_DEP_PTR, align 4
  %38581 = sub i64 %38580, 1
  store i64 %38581, i64* %STACK_DEP_PTR, align 4
  %38582 = add i256 %38574, %38569, !pc !571, !intsan !10
  %38583 = trunc i256 %38582 to i64
  %38584 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38583, i256* %38584)
  %38585 = load i256, i256* %38584, align 4
  %38586 = add i256 %38579, %38569, !pc !572, !intsan !10
  %38587 = trunc i256 %38586 to i64
  %38588 = alloca i256, align 8
  store i256 %38585, i256* %38588, align 4
  %38589 = bitcast i256* %38588 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38587, i8* %38589, i64 32)
  %38590 = add i256 %38569, 32, !pc !573, !intsan !10
  %38591 = trunc i256 12823 to i64
  %38592 = load i64, i64* %STACK_DEP_PTR, align 4
  %38593 = add i64 %38592, 1
  store i64 %38593, i64* %STACK_DEP_PTR, align 4
  %38594 = load i64, i64* %STACK_DEP_PTR, align 4
  %38595 = getelementptr i256, i256* %STACK, i64 %38594
  store i256 %38579, i256* %38595, align 4
  %38596 = load i64, i64* %STACK_DEP_PTR, align 4
  %38597 = add i64 %38596, 1
  store i64 %38597, i64* %STACK_DEP_PTR, align 4
  %38598 = load i64, i64* %STACK_DEP_PTR, align 4
  %38599 = getelementptr i256, i256* %STACK, i64 %38598
  store i256 %38574, i256* %38599, align 4
  %38600 = load i64, i64* %STACK_DEP_PTR, align 4
  %38601 = add i64 %38600, 1
  store i64 %38601, i64* %STACK_DEP_PTR, align 4
  %38602 = load i64, i64* %STACK_DEP_PTR, align 4
  %38603 = getelementptr i256, i256* %STACK, i64 %38602
  store i256 %38590, i256* %38603, align 4
  br label %.12823, !EVMBB !4

.12850:                                           ; preds = %38512, %JumpTable
  %38604 = load i64, i64* %remaing_gas, align 4
  %38605 = icmp ugt i64 488, %38604
  br i1 %38605, label %Abort, label %38606

38606:                                            ; preds = %.12850
  %38607 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38608 = xor i32 %38607, 3871
  %38609 = urem i32 %38608, 4096
  %38610 = getelementptr i8, i8 addrspace(1)* %4, i32 %38609
  %38611 = load i8, i8 addrspace(1)* %38610, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38610, align 1, !nosanitize !3
  store i32 1935, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38612 = sub i64 %38604, 488
  store i64 %38612, i64* %remaing_gas, align 4
  %38613 = load i64, i64* %STACK_DEP_PTR, align 4
  %38614 = getelementptr i256, i256* %STACK, i64 %38613
  %38615 = load i256, i256* %38614, align 4
  %38616 = load i64, i64* %STACK_DEP_PTR, align 4
  %38617 = sub i64 %38616, 1
  store i64 %38617, i64* %STACK_DEP_PTR, align 4
  %38618 = load i64, i64* %STACK_DEP_PTR, align 4
  %38619 = getelementptr i256, i256* %STACK, i64 %38618
  %38620 = load i256, i256* %38619, align 4
  %38621 = load i64, i64* %STACK_DEP_PTR, align 4
  %38622 = sub i64 %38621, 1
  store i64 %38622, i64* %STACK_DEP_PTR, align 4
  %38623 = load i64, i64* %STACK_DEP_PTR, align 4
  %38624 = getelementptr i256, i256* %STACK, i64 %38623
  %38625 = load i256, i256* %38624, align 4
  %38626 = load i64, i64* %STACK_DEP_PTR, align 4
  %38627 = sub i64 %38626, 1
  store i64 %38627, i64* %STACK_DEP_PTR, align 4
  %38628 = load i64, i64* %STACK_DEP_PTR, align 4
  %38629 = getelementptr i256, i256* %STACK, i64 %38628
  %38630 = load i256, i256* %38629, align 4
  %38631 = load i64, i64* %STACK_DEP_PTR, align 4
  %38632 = sub i64 %38631, 1
  store i64 %38632, i64* %STACK_DEP_PTR, align 4
  %38633 = load i64, i64* %STACK_DEP_PTR, align 4
  %38634 = getelementptr i256, i256* %STACK, i64 %38633
  %38635 = load i256, i256* %38634, align 4
  %38636 = load i64, i64* %STACK_DEP_PTR, align 4
  %38637 = sub i64 %38636, 1
  store i64 %38637, i64* %STACK_DEP_PTR, align 4
  %38638 = load i64, i64* %STACK_DEP_PTR, align 4
  %38639 = getelementptr i256, i256* %STACK, i64 %38638
  %38640 = load i256, i256* %38639, align 4
  %38641 = load i64, i64* %STACK_DEP_PTR, align 4
  %38642 = sub i64 %38641, 1
  store i64 %38642, i64* %STACK_DEP_PTR, align 4
  %38643 = load i64, i64* %STACK_DEP_PTR, align 4
  %38644 = getelementptr i256, i256* %STACK, i64 %38643
  %38645 = load i256, i256* %38644, align 4
  %38646 = load i64, i64* %STACK_DEP_PTR, align 4
  %38647 = sub i64 %38646, 1
  store i64 %38647, i64* %STACK_DEP_PTR, align 4
  %38648 = add i256 %38635, %38645, !pc !574, !intsan !10
  %38649 = and i256 31, %38635
  %38650 = icmp eq i256 %38649, 0
  %38651 = trunc i256 12895 to i64
  %jump.check214 = icmp ne i1 %38650, false
  %38652 = load i64, i64* %STACK_DEP_PTR, align 4
  %38653 = add i64 %38652, 1
  store i64 %38653, i64* %STACK_DEP_PTR, align 4
  %38654 = load i64, i64* %STACK_DEP_PTR, align 4
  %38655 = getelementptr i256, i256* %STACK, i64 %38654
  store i256 %38648, i256* %38655, align 4
  %38656 = load i64, i64* %STACK_DEP_PTR, align 4
  %38657 = add i64 %38656, 1
  store i64 %38657, i64* %STACK_DEP_PTR, align 4
  %38658 = load i64, i64* %STACK_DEP_PTR, align 4
  %38659 = getelementptr i256, i256* %STACK, i64 %38658
  store i256 %38649, i256* %38659, align 4
  br i1 %jump.check214, label %.12895, label %.12870, !EVMBB !4

.12870:                                           ; preds = %38606
  %38660 = load i64, i64* %STACK_DEP_PTR, align 4
  %38661 = getelementptr i256, i256* %STACK, i64 %38660
  %38662 = load i256, i256* %38661, align 4
  %38663 = load i64, i64* %STACK_DEP_PTR, align 4
  %38664 = sub i64 %38663, 1
  store i64 %38664, i64* %STACK_DEP_PTR, align 4
  %38665 = load i64, i64* %STACK_DEP_PTR, align 4
  %38666 = getelementptr i256, i256* %STACK, i64 %38665
  %38667 = load i256, i256* %38666, align 4
  %38668 = load i64, i64* %STACK_DEP_PTR, align 4
  %38669 = sub i64 %38668, 1
  store i64 %38669, i64* %STACK_DEP_PTR, align 4
  %38670 = sub i256 %38667, %38662, !pc !575, !intsan !8
  %38671 = trunc i256 %38670 to i64
  %38672 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38671, i256* %38672)
  %38673 = load i256, i256* %38672, align 4
  %38674 = sub i256 32, %38662, !pc !576, !intsan !8
  %38675 = alloca i256, align 8
  store i256 256, i256* %38675, align 4
  %38676 = alloca i256, align 8
  store i256 %38674, i256* %38676, align 4
  %38677 = alloca i256, align 8
  call void @__power_word(i256* %38675, i256* %38676, i256* %38677)
  %38678 = load volatile i256, i256* %38677, align 4
  %38679 = sub i256 %38678, 1, !pc !577, !intsan !8
  %38680 = xor i256 %38679, -1
  %38681 = and i256 %38680, %38673
  %38682 = trunc i256 %38670 to i64
  %38683 = alloca i256, align 8
  store i256 %38681, i256* %38683, align 4
  %38684 = bitcast i256* %38683 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %38682, i8* %38684, i64 32)
  %38685 = add i256 32, %38670, !pc !578, !intsan !10
  %38686 = load i64, i64* %STACK_DEP_PTR, align 4
  %38687 = add i64 %38686, 1
  store i64 %38687, i64* %STACK_DEP_PTR, align 4
  %38688 = load i64, i64* %STACK_DEP_PTR, align 4
  %38689 = getelementptr i256, i256* %STACK, i64 %38688
  store i256 %38685, i256* %38689, align 4
  %38690 = load i64, i64* %STACK_DEP_PTR, align 4
  %38691 = add i64 %38690, 1
  store i64 %38691, i64* %STACK_DEP_PTR, align 4
  %38692 = load i64, i64* %STACK_DEP_PTR, align 4
  %38693 = getelementptr i256, i256* %STACK, i64 %38692
  store i256 %38662, i256* %38693, align 4
  br label %.12895

.12895:                                           ; preds = %.12870, %38606, %JumpTable
  %38694 = load i64, i64* %remaing_gas, align 4
  %38695 = icmp ugt i64 1200, %38694
  br i1 %38695, label %Abort, label %38696

38696:                                            ; preds = %.12895
  %38697 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38698 = xor i32 %38697, 696
  %38699 = urem i32 %38698, 4096
  %38700 = getelementptr i8, i8 addrspace(1)* %4, i32 %38699
  %38701 = load i8, i8 addrspace(1)* %38700, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38700, align 1, !nosanitize !3
  store i32 348, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38702 = sub i64 %38694, 1200
  store i64 %38702, i64* %remaing_gas, align 4
  %38703 = load i64, i64* %STACK_DEP_PTR, align 4
  %38704 = getelementptr i256, i256* %STACK, i64 %38703
  %38705 = load i256, i256* %38704, align 4
  %38706 = load i64, i64* %STACK_DEP_PTR, align 4
  %38707 = sub i64 %38706, 1
  store i64 %38707, i64* %STACK_DEP_PTR, align 4
  %38708 = load i64, i64* %STACK_DEP_PTR, align 4
  %38709 = getelementptr i256, i256* %STACK, i64 %38708
  %38710 = load i256, i256* %38709, align 4
  %38711 = load i64, i64* %STACK_DEP_PTR, align 4
  %38712 = sub i64 %38711, 1
  store i64 %38712, i64* %STACK_DEP_PTR, align 4
  %38713 = load i64, i64* %STACK_DEP_PTR, align 4
  %38714 = getelementptr i256, i256* %STACK, i64 %38713
  %38715 = load i256, i256* %38714, align 4
  %38716 = load i64, i64* %STACK_DEP_PTR, align 4
  %38717 = sub i64 %38716, 1
  store i64 %38717, i64* %STACK_DEP_PTR, align 4
  %38718 = load i64, i64* %STACK_DEP_PTR, align 4
  %38719 = getelementptr i256, i256* %STACK, i64 %38718
  %38720 = load i256, i256* %38719, align 4
  %38721 = load i64, i64* %STACK_DEP_PTR, align 4
  %38722 = sub i64 %38721, 1
  store i64 %38722, i64* %STACK_DEP_PTR, align 4
  %38723 = load i64, i64* %STACK_DEP_PTR, align 4
  %38724 = getelementptr i256, i256* %STACK, i64 %38723
  %38725 = load i256, i256* %38724, align 4
  %38726 = load i64, i64* %STACK_DEP_PTR, align 4
  %38727 = sub i64 %38726, 1
  store i64 %38727, i64* %STACK_DEP_PTR, align 4
  %38728 = load i64, i64* %STACK_DEP_PTR, align 4
  %38729 = getelementptr i256, i256* %STACK, i64 %38728
  %38730 = load i256, i256* %38729, align 4
  %38731 = load i64, i64* %STACK_DEP_PTR, align 4
  %38732 = sub i64 %38731, 1
  store i64 %38732, i64* %STACK_DEP_PTR, align 4
  %38733 = load i64, i64* %STACK_DEP_PTR, align 4
  %38734 = getelementptr i256, i256* %STACK, i64 %38733
  %38735 = load i256, i256* %38734, align 4
  %38736 = load i64, i64* %STACK_DEP_PTR, align 4
  %38737 = sub i64 %38736, 1
  store i64 %38737, i64* %STACK_DEP_PTR, align 4
  %38738 = load i64, i64* %STACK_DEP_PTR, align 4
  %38739 = getelementptr i256, i256* %STACK, i64 %38738
  %38740 = load i256, i256* %38739, align 4
  %38741 = load i64, i64* %STACK_DEP_PTR, align 4
  %38742 = sub i64 %38741, 1
  store i64 %38742, i64* %STACK_DEP_PTR, align 4
  %38743 = load i64, i64* %STACK_DEP_PTR, align 4
  %38744 = getelementptr i256, i256* %STACK, i64 %38743
  %38745 = load i256, i256* %38744, align 4
  %38746 = load i64, i64* %STACK_DEP_PTR, align 4
  %38747 = sub i64 %38746, 1
  store i64 %38747, i64* %STACK_DEP_PTR, align 4
  %38748 = load i64, i64* %STACK_DEP_PTR, align 4
  %38749 = getelementptr i256, i256* %STACK, i64 %38748
  %38750 = load i256, i256* %38749, align 4
  %38751 = load i64, i64* %STACK_DEP_PTR, align 4
  %38752 = sub i64 %38751, 1
  store i64 %38752, i64* %STACK_DEP_PTR, align 4
  %38753 = load i64, i64* %STACK_DEP_PTR, align 4
  %38754 = getelementptr i256, i256* %STACK, i64 %38753
  %38755 = load i256, i256* %38754, align 4
  %38756 = load i64, i64* %STACK_DEP_PTR, align 4
  %38757 = sub i64 %38756, 1
  store i64 %38757, i64* %STACK_DEP_PTR, align 4
  %38758 = load i64, i64* %STACK_DEP_PTR, align 4
  %38759 = getelementptr i256, i256* %STACK, i64 %38758
  %38760 = load i256, i256* %38759, align 4
  %38761 = load i64, i64* %STACK_DEP_PTR, align 4
  %38762 = sub i64 %38761, 1
  store i64 %38762, i64* %STACK_DEP_PTR, align 4
  %38763 = trunc i256 64 to i64
  %38764 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38763, i256* %38764)
  %38765 = load i256, i256* %38764, align 4
  %38766 = sub i256 %38710, %38765, !pc !579, !intsan !8
  %38767 = icmp eq i256 1, 0
  %38768 = icmp eq i1 %38767, false
  %38769 = trunc i256 12929 to i64
  %jump.check215 = icmp ne i1 %38768, false
  %38770 = load i64, i64* %STACK_DEP_PTR, align 4
  %38771 = add i64 %38770, 1
  store i64 %38771, i64* %STACK_DEP_PTR, align 4
  %38772 = load i64, i64* %STACK_DEP_PTR, align 4
  %38773 = getelementptr i256, i256* %STACK, i64 %38772
  store i256 %38760, i256* %38773, align 4
  %38774 = load i64, i64* %STACK_DEP_PTR, align 4
  %38775 = add i64 %38774, 1
  store i64 %38775, i64* %STACK_DEP_PTR, align 4
  %38776 = load i64, i64* %STACK_DEP_PTR, align 4
  %38777 = getelementptr i256, i256* %STACK, i64 %38776
  store i256 %38755, i256* %38777, align 4
  %38778 = load i64, i64* %STACK_DEP_PTR, align 4
  %38779 = add i64 %38778, 1
  store i64 %38779, i64* %STACK_DEP_PTR, align 4
  %38780 = load i64, i64* %STACK_DEP_PTR, align 4
  %38781 = getelementptr i256, i256* %STACK, i64 %38780
  store i256 %38750, i256* %38781, align 4
  %38782 = load i64, i64* %STACK_DEP_PTR, align 4
  %38783 = add i64 %38782, 1
  store i64 %38783, i64* %STACK_DEP_PTR, align 4
  %38784 = load i64, i64* %STACK_DEP_PTR, align 4
  %38785 = getelementptr i256, i256* %STACK, i64 %38784
  store i256 %38710, i256* %38785, align 4
  %38786 = load i64, i64* %STACK_DEP_PTR, align 4
  %38787 = add i64 %38786, 1
  store i64 %38787, i64* %STACK_DEP_PTR, align 4
  %38788 = load i64, i64* %STACK_DEP_PTR, align 4
  %38789 = getelementptr i256, i256* %STACK, i64 %38788
  store i256 32, i256* %38789, align 4
  %38790 = load i64, i64* %STACK_DEP_PTR, align 4
  %38791 = add i64 %38790, 1
  store i64 %38791, i64* %STACK_DEP_PTR, align 4
  %38792 = load i64, i64* %STACK_DEP_PTR, align 4
  %38793 = getelementptr i256, i256* %STACK, i64 %38792
  store i256 %38765, i256* %38793, align 4
  %38794 = load i64, i64* %STACK_DEP_PTR, align 4
  %38795 = add i64 %38794, 1
  store i64 %38795, i64* %STACK_DEP_PTR, align 4
  %38796 = load i64, i64* %STACK_DEP_PTR, align 4
  %38797 = getelementptr i256, i256* %STACK, i64 %38796
  store i256 %38766, i256* %38797, align 4
  %38798 = load i64, i64* %STACK_DEP_PTR, align 4
  %38799 = add i64 %38798, 1
  store i64 %38799, i64* %STACK_DEP_PTR, align 4
  %38800 = load i64, i64* %STACK_DEP_PTR, align 4
  %38801 = getelementptr i256, i256* %STACK, i64 %38800
  store i256 %38765, i256* %38801, align 4
  %38802 = load i64, i64* %STACK_DEP_PTR, align 4
  %38803 = add i64 %38802, 1
  store i64 %38803, i64* %STACK_DEP_PTR, align 4
  %38804 = load i64, i64* %STACK_DEP_PTR, align 4
  %38805 = getelementptr i256, i256* %STACK, i64 %38804
  store i256 %38750, i256* %38805, align 4
  %38806 = load i64, i64* %STACK_DEP_PTR, align 4
  %38807 = add i64 %38806, 1
  store i64 %38807, i64* %STACK_DEP_PTR, align 4
  %38808 = load i64, i64* %STACK_DEP_PTR, align 4
  %38809 = getelementptr i256, i256* %STACK, i64 %38808
  store i256 %38760, i256* %38809, align 4
  %38810 = load i64, i64* %STACK_DEP_PTR, align 4
  %38811 = add i64 %38810, 1
  store i64 %38811, i64* %STACK_DEP_PTR, align 4
  %38812 = zext i1 %38767 to i256
  %38813 = load i64, i64* %STACK_DEP_PTR, align 4
  %38814 = getelementptr i256, i256* %STACK, i64 %38813
  store i256 %38812, i256* %38814, align 4
  br i1 %jump.check215, label %.12929, label %.12925, !EVMBB !4

.12925:                                           ; preds = %38696
  %38815 = load i64, i64* %remaing_gas, align 4
  %38816 = icmp ugt i64 16, %38815
  br i1 %38816, label %Abort, label %38817

38817:                                            ; preds = %.12925
  %38818 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38819 = xor i32 %38818, 1901
  %38820 = urem i32 %38819, 4096
  %38821 = getelementptr i8, i8 addrspace(1)* %4, i32 %38820
  %38822 = load i8, i8 addrspace(1)* %38821, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38821, align 1, !nosanitize !3
  store i32 950, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38823 = sub i64 %38815, 16
  store i64 %38823, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12929:                                           ; preds = %38696, %JumpTable
  %38824 = load i64, i64* %remaing_gas, align 4
  %38825 = icmp ugt i64 456, %38824
  br i1 %38825, label %Abort, label %38826

38826:                                            ; preds = %.12929
  %38827 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38828 = xor i32 %38827, 3345
  %38829 = urem i32 %38828, 4096
  %38830 = getelementptr i8, i8 addrspace(1)* %4, i32 %38829
  %38831 = load i8, i8 addrspace(1)* %38830, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38830, align 1, !nosanitize !3
  store i32 1672, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38832 = sub i64 %38824, 456
  store i64 %38832, i64* %remaing_gas, align 4
  %38833 = load i64, i64* %STACK_DEP_PTR, align 4
  %38834 = getelementptr i256, i256* %STACK, i64 %38833
  %38835 = load i256, i256* %38834, align 4
  %38836 = load i64, i64* %STACK_DEP_PTR, align 4
  %38837 = sub i64 %38836, 1
  store i64 %38837, i64* %STACK_DEP_PTR, align 4
  %38838 = load i64, i64* %STACK_DEP_PTR, align 4
  %38839 = getelementptr i256, i256* %STACK, i64 %38838
  %38840 = load i256, i256* %38839, align 4
  %38841 = load i64, i64* %STACK_DEP_PTR, align 4
  %38842 = sub i64 %38841, 1
  store i64 %38842, i64* %STACK_DEP_PTR, align 4
  %38843 = load i64, i64* %STACK_DEP_PTR, align 4
  %38844 = getelementptr i256, i256* %STACK, i64 %38843
  %38845 = load i256, i256* %38844, align 4
  %38846 = load i64, i64* %STACK_DEP_PTR, align 4
  %38847 = sub i64 %38846, 1
  store i64 %38847, i64* %STACK_DEP_PTR, align 4
  %38848 = load i64, i64* %STACK_DEP_PTR, align 4
  %38849 = getelementptr i256, i256* %STACK, i64 %38848
  %38850 = load i256, i256* %38849, align 4
  %38851 = load i64, i64* %STACK_DEP_PTR, align 4
  %38852 = sub i64 %38851, 1
  store i64 %38852, i64* %STACK_DEP_PTR, align 4
  %38853 = load i64, i64* %STACK_DEP_PTR, align 4
  %38854 = getelementptr i256, i256* %STACK, i64 %38853
  %38855 = load i256, i256* %38854, align 4
  %38856 = load i64, i64* %STACK_DEP_PTR, align 4
  %38857 = sub i64 %38856, 1
  store i64 %38857, i64* %STACK_DEP_PTR, align 4
  %38858 = load i64, i64* %STACK_DEP_PTR, align 4
  %38859 = getelementptr i256, i256* %STACK, i64 %38858
  %38860 = load i256, i256* %38859, align 4
  %38861 = load i64, i64* %STACK_DEP_PTR, align 4
  %38862 = sub i64 %38861, 1
  store i64 %38862, i64* %STACK_DEP_PTR, align 4
  %38863 = load i64, i64* %STACK_DEP_PTR, align 4
  %38864 = getelementptr i256, i256* %STACK, i64 %38863
  %38865 = load i256, i256* %38864, align 4
  %38866 = load i64, i64* %STACK_DEP_PTR, align 4
  %38867 = sub i64 %38866, 1
  store i64 %38867, i64* %STACK_DEP_PTR, align 4
  %38868 = trunc i256 %38840 to i160
  %38869 = call i1 @solidity_call(), !pc !580
  %38870 = icmp eq i1 %38869, false
  %38871 = icmp eq i1 %38870, false
  %38872 = trunc i256 12949 to i64
  %jump.check216 = icmp ne i1 %38871, false
  %38873 = load i64, i64* %STACK_DEP_PTR, align 4
  %38874 = add i64 %38873, 1
  store i64 %38874, i64* %STACK_DEP_PTR, align 4
  %38875 = zext i1 %38870 to i256
  %38876 = load i64, i64* %STACK_DEP_PTR, align 4
  %38877 = getelementptr i256, i256* %STACK, i64 %38876
  store i256 %38875, i256* %38877, align 4
  br i1 %jump.check216, label %.12949, label %.12940, !EVMBB !4

.12940:                                           ; preds = %38826
  %38878 = load i64, i64* %remaing_gas, align 4
  %38879 = icmp ugt i64 16, %38878
  br i1 %38879, label %Abort, label %38880

38880:                                            ; preds = %.12940
  %38881 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38882 = xor i32 %38881, 3636
  %38883 = urem i32 %38882, 4096
  %38884 = getelementptr i8, i8 addrspace(1)* %4, i32 %38883
  %38885 = load i8, i8 addrspace(1)* %38884, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38884, align 1, !nosanitize !3
  store i32 1818, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38886 = sub i64 %38878, 16
  store i64 %38886, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12949:                                           ; preds = %38826, %JumpTable
  %38887 = load i64, i64* %remaing_gas, align 4
  %38888 = icmp ugt i64 432, %38887
  br i1 %38888, label %Abort, label %38889

38889:                                            ; preds = %.12949
  %38890 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38891 = xor i32 %38890, 3885
  %38892 = urem i32 %38891, 4096
  %38893 = getelementptr i8, i8 addrspace(1)* %4, i32 %38892
  %38894 = load i8, i8 addrspace(1)* %38893, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38893, align 1, !nosanitize !3
  store i32 1942, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38895 = sub i64 %38887, 432
  store i64 %38895, i64* %remaing_gas, align 4
  %38896 = load i64, i64* %STACK_DEP_PTR, align 4
  %38897 = getelementptr i256, i256* %STACK, i64 %38896
  %38898 = load i256, i256* %38897, align 4
  %38899 = load i64, i64* %STACK_DEP_PTR, align 4
  %38900 = sub i64 %38899, 1
  store i64 %38900, i64* %STACK_DEP_PTR, align 4
  %38901 = load i64, i64* %STACK_DEP_PTR, align 4
  %38902 = getelementptr i256, i256* %STACK, i64 %38901
  %38903 = load i256, i256* %38902, align 4
  %38904 = load i64, i64* %STACK_DEP_PTR, align 4
  %38905 = sub i64 %38904, 1
  store i64 %38905, i64* %STACK_DEP_PTR, align 4
  %38906 = load i64, i64* %STACK_DEP_PTR, align 4
  %38907 = getelementptr i256, i256* %STACK, i64 %38906
  %38908 = load i256, i256* %38907, align 4
  %38909 = load i64, i64* %STACK_DEP_PTR, align 4
  %38910 = sub i64 %38909, 1
  store i64 %38910, i64* %STACK_DEP_PTR, align 4
  %38911 = load i64, i64* %STACK_DEP_PTR, align 4
  %38912 = getelementptr i256, i256* %STACK, i64 %38911
  %38913 = load i256, i256* %38912, align 4
  %38914 = load i64, i64* %STACK_DEP_PTR, align 4
  %38915 = sub i64 %38914, 1
  store i64 %38915, i64* %STACK_DEP_PTR, align 4
  %38916 = load i64, i64* %STACK_DEP_PTR, align 4
  %38917 = getelementptr i256, i256* %STACK, i64 %38916
  %38918 = load i256, i256* %38917, align 4
  %38919 = load i64, i64* %STACK_DEP_PTR, align 4
  %38920 = sub i64 %38919, 1
  store i64 %38920, i64* %STACK_DEP_PTR, align 4
  %38921 = trunc i256 64 to i64
  %38922 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38921, i256* %38922)
  %38923 = load i256, i256* %38922, align 4
  %38924 = zext i64 0 to i256
  %38925 = icmp ult i256 %38924, 32
  %38926 = icmp eq i1 %38925, false
  %38927 = trunc i256 12972 to i64
  %jump.check217 = icmp ne i1 %38926, false
  %38928 = load i64, i64* %STACK_DEP_PTR, align 4
  %38929 = add i64 %38928, 1
  store i64 %38929, i64* %STACK_DEP_PTR, align 4
  %38930 = load i64, i64* %STACK_DEP_PTR, align 4
  %38931 = getelementptr i256, i256* %STACK, i64 %38930
  store i256 %38923, i256* %38931, align 4
  %38932 = load i64, i64* %STACK_DEP_PTR, align 4
  %38933 = add i64 %38932, 1
  store i64 %38933, i64* %STACK_DEP_PTR, align 4
  %38934 = zext i64 0 to i256
  %38935 = load i64, i64* %STACK_DEP_PTR, align 4
  %38936 = getelementptr i256, i256* %STACK, i64 %38935
  store i256 %38934, i256* %38936, align 4
  br i1 %jump.check217, label %.12972, label %.12968, !EVMBB !4

.12968:                                           ; preds = %38889
  %38937 = load i64, i64* %remaing_gas, align 4
  %38938 = icmp ugt i64 16, %38937
  br i1 %38938, label %Abort, label %38939

38939:                                            ; preds = %.12968
  %38940 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38941 = xor i32 %38940, 909
  %38942 = urem i32 %38941, 4096
  %38943 = getelementptr i8, i8 addrspace(1)* %4, i32 %38942
  %38944 = load i8, i8 addrspace(1)* %38943, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38943, align 1, !nosanitize !3
  store i32 454, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38945 = sub i64 %38937, 16
  store i64 %38945, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.12972:                                           ; preds = %38889, %JumpTable
  %38946 = load i64, i64* %STACK_DEP_PTR, align 4
  %38947 = getelementptr i256, i256* %STACK, i64 %38946
  %38948 = load i256, i256* %38947, align 4
  %38949 = load i64, i64* %STACK_DEP_PTR, align 4
  %38950 = sub i64 %38949, 1
  store i64 %38950, i64* %STACK_DEP_PTR, align 4
  %38951 = load i64, i64* %STACK_DEP_PTR, align 4
  %38952 = getelementptr i256, i256* %STACK, i64 %38951
  %38953 = load i256, i256* %38952, align 4
  %38954 = load i64, i64* %STACK_DEP_PTR, align 4
  %38955 = sub i64 %38954, 1
  store i64 %38955, i64* %STACK_DEP_PTR, align 4
  %38956 = load i64, i64* %STACK_DEP_PTR, align 4
  %38957 = getelementptr i256, i256* %STACK, i64 %38956
  %38958 = load i256, i256* %38957, align 4
  %38959 = load i64, i64* %STACK_DEP_PTR, align 4
  %38960 = sub i64 %38959, 1
  store i64 %38960, i64* %STACK_DEP_PTR, align 4
  %38961 = load i64, i64* %STACK_DEP_PTR, align 4
  %38962 = getelementptr i256, i256* %STACK, i64 %38961
  %38963 = load i256, i256* %38962, align 4
  %38964 = load i64, i64* %STACK_DEP_PTR, align 4
  %38965 = sub i64 %38964, 1
  store i64 %38965, i64* %STACK_DEP_PTR, align 4
  %38966 = add i256 %38953, %38948, !pc !581, !intsan !10
  %38967 = trunc i256 %38953 to i64
  %38968 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %38967, i256* %38968)
  %38969 = load i256, i256* %38968, align 4
  %38970 = add i256 32, %38953, !pc !582, !intsan !10
  %38971 = load i64, i64* %STACK_DEP_PTR, align 4
  %38972 = add i64 %38971, 1
  store i64 %38972, i64* %STACK_DEP_PTR, align 4
  %38973 = load i64, i64* %STACK_DEP_PTR, align 4
  %38974 = getelementptr i256, i256* %STACK, i64 %38973
  store i256 %38969, i256* %38974, align 4
  %38975 = load i64, i64* %STACK_DEP_PTR, align 4
  %38976 = add i64 %38975, 1
  store i64 %38976, i64* %STACK_DEP_PTR, align 4
  %38977 = load i64, i64* %STACK_DEP_PTR, align 4
  %38978 = getelementptr i256, i256* %STACK, i64 %38977
  store i256 %38958, i256* %38978, align 4
  br label %.12992

.12992:                                           ; preds = %.12972, %37868, %JumpTable
  %38979 = load i64, i64* %remaing_gas, align 4
  %38980 = icmp ugt i64 368, %38979
  br i1 %38980, label %Abort, label %38981

38981:                                            ; preds = %.12992
  %38982 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38983 = xor i32 %38982, 239
  %38984 = urem i32 %38983, 4096
  %38985 = getelementptr i8, i8 addrspace(1)* %4, i32 %38984
  %38986 = load i8, i8 addrspace(1)* %38985, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %38985, align 1, !nosanitize !3
  store i32 119, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %38987 = sub i64 %38979, 368
  store i64 %38987, i64* %remaing_gas, align 4
  %38988 = load i64, i64* %STACK_DEP_PTR, align 4
  %38989 = getelementptr i256, i256* %STACK, i64 %38988
  %38990 = load i256, i256* %38989, align 4
  %38991 = load i64, i64* %STACK_DEP_PTR, align 4
  %38992 = sub i64 %38991, 1
  store i64 %38992, i64* %STACK_DEP_PTR, align 4
  %38993 = load i64, i64* %STACK_DEP_PTR, align 4
  %38994 = getelementptr i256, i256* %STACK, i64 %38993
  %38995 = load i256, i256* %38994, align 4
  %38996 = load i64, i64* %STACK_DEP_PTR, align 4
  %38997 = sub i64 %38996, 1
  store i64 %38997, i64* %STACK_DEP_PTR, align 4
  %38998 = load i64, i64* %STACK_DEP_PTR, align 4
  %38999 = getelementptr i256, i256* %STACK, i64 %38998
  %39000 = load i256, i256* %38999, align 4
  %39001 = load i64, i64* %STACK_DEP_PTR, align 4
  %39002 = sub i64 %39001, 1
  store i64 %39002, i64* %STACK_DEP_PTR, align 4
  %39003 = load i64, i64* %STACK_DEP_PTR, align 4
  %39004 = getelementptr i256, i256* %STACK, i64 %39003
  %39005 = load i256, i256* %39004, align 4
  %39006 = load i64, i64* %STACK_DEP_PTR, align 4
  %39007 = sub i64 %39006, 1
  store i64 %39007, i64* %STACK_DEP_PTR, align 4
  %39008 = load i64, i64* %STACK_DEP_PTR, align 4
  %39009 = getelementptr i256, i256* %STACK, i64 %39008
  %39010 = load i256, i256* %39009, align 4
  %39011 = load i64, i64* %STACK_DEP_PTR, align 4
  %39012 = sub i64 %39011, 1
  store i64 %39012, i64* %STACK_DEP_PTR, align 4
  %39013 = load i64, i64* %STACK_DEP_PTR, align 4
  %39014 = getelementptr i256, i256* %STACK, i64 %39013
  %39015 = load i256, i256* %39014, align 4
  %39016 = load i64, i64* %STACK_DEP_PTR, align 4
  %39017 = sub i64 %39016, 1
  store i64 %39017, i64* %STACK_DEP_PTR, align 4
  %39018 = trunc i256 %39015 to i64
  store i64 %39018, i64* %JMP_TARGET_PTR, align 4
  %39019 = load i64, i64* %STACK_DEP_PTR, align 4
  %39020 = add i64 %39019, 1
  store i64 %39020, i64* %STACK_DEP_PTR, align 4
  %39021 = load i64, i64* %STACK_DEP_PTR, align 4
  %39022 = getelementptr i256, i256* %STACK, i64 %39021
  store i256 %38995, i256* %39022, align 4
  br label %JumpTable, !EVMBB !4

.13000:                                           ; preds = %35438, %23085, %14152, %6175, %JumpTable
  %39023 = load i64, i64* %remaing_gas, align 4
  %39024 = icmp ugt i64 264, %39023
  br i1 %39024, label %Abort, label %39025

39025:                                            ; preds = %.13000
  %39026 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39027 = xor i32 %39026, 2895
  %39028 = urem i32 %39027, 4096
  %39029 = getelementptr i8, i8 addrspace(1)* %4, i32 %39028
  %39030 = load i8, i8 addrspace(1)* %39029, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %39029, align 1, !nosanitize !3
  store i32 1447, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39031 = sub i64 %39023, 264
  store i64 %39031, i64* %remaing_gas, align 4
  %39032 = trunc i256 16448 to i64
  %39033 = load i64, i64* %STACK_DEP_PTR, align 4
  %39034 = add i64 %39033, 1
  store i64 %39034, i64* %STACK_DEP_PTR, align 4
  %39035 = load i64, i64* %STACK_DEP_PTR, align 4
  %39036 = getelementptr i256, i256* %STACK, i64 %39035
  store i256 0, i256* %39036, align 4
  %39037 = load i64, i64* %STACK_DEP_PTR, align 4
  %39038 = add i64 %39037, 1
  store i64 %39038, i64* %STACK_DEP_PTR, align 4
  %39039 = load i64, i64* %STACK_DEP_PTR, align 4
  %39040 = getelementptr i256, i256* %STACK, i64 %39039
  store i256 0, i256* %39040, align 4
  %39041 = load i64, i64* %STACK_DEP_PTR, align 4
  %39042 = add i64 %39041, 1
  store i64 %39042, i64* %STACK_DEP_PTR, align 4
  %39043 = load i64, i64* %STACK_DEP_PTR, align 4
  %39044 = getelementptr i256, i256* %STACK, i64 %39043
  store i256 0, i256* %39044, align 4
  %39045 = load i64, i64* %STACK_DEP_PTR, align 4
  %39046 = add i64 %39045, 1
  store i64 %39046, i64* %STACK_DEP_PTR, align 4
  %39047 = load i64, i64* %STACK_DEP_PTR, align 4
  %39048 = getelementptr i256, i256* %STACK, i64 %39047
  store i256 0, i256* %39048, align 4
  %39049 = load i64, i64* %STACK_DEP_PTR, align 4
  %39050 = add i64 %39049, 1
  store i64 %39050, i64* %STACK_DEP_PTR, align 4
  %39051 = load i64, i64* %STACK_DEP_PTR, align 4
  %39052 = getelementptr i256, i256* %STACK, i64 %39051
  store i256 13014, i256* %39052, align 4
  br label %.16448, !EVMBB !4

.13014:                                           ; preds = %JumpTable
  %39053 = load i64, i64* %remaing_gas, align 4
  %39054 = icmp ugt i64 808, %39053
  br i1 %39054, label %Abort, label %39055

39055:                                            ; preds = %.13014
  %39056 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39057 = xor i32 %39056, 137
  %39058 = urem i32 %39057, 4096
  %39059 = getelementptr i8, i8 addrspace(1)* %4, i32 %39058
  %39060 = load i8, i8 addrspace(1)* %39059, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %39059, align 1, !nosanitize !3
  store i32 68, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39061 = sub i64 %39053, 808
  store i64 %39061, i64* %remaing_gas, align 4
  %39062 = load i64, i64* %STACK_DEP_PTR, align 4
  %39063 = getelementptr i256, i256* %STACK, i64 %39062
  %39064 = load i256, i256* %39063, align 4
  %39065 = load i64, i64* %STACK_DEP_PTR, align 4
  %39066 = sub i64 %39065, 1
  store i64 %39066, i64* %STACK_DEP_PTR, align 4
  %39067 = load i64, i64* %STACK_DEP_PTR, align 4
  %39068 = getelementptr i256, i256* %STACK, i64 %39067
  %39069 = load i256, i256* %39068, align 4
  %39070 = load i64, i64* %STACK_DEP_PTR, align 4
  %39071 = sub i64 %39070, 1
  store i64 %39071, i64* %STACK_DEP_PTR, align 4
  %39072 = load i64, i64* %STACK_DEP_PTR, align 4
  %39073 = getelementptr i256, i256* %STACK, i64 %39072
  %39074 = load i256, i256* %39073, align 4
  %39075 = load i64, i64* %STACK_DEP_PTR, align 4
  %39076 = sub i64 %39075, 1
  store i64 %39076, i64* %STACK_DEP_PTR, align 4
  %39077 = load i64, i64* %STACK_DEP_PTR, align 4
  %39078 = getelementptr i256, i256* %STACK, i64 %39077
  %39079 = load i256, i256* %39078, align 4
  %39080 = load i64, i64* %STACK_DEP_PTR, align 4
  %39081 = sub i64 %39080, 1
  store i64 %39081, i64* %STACK_DEP_PTR, align 4
  %39082 = load i64, i64* %STACK_DEP_PTR, align 4
  %39083 = getelementptr i256, i256* %STACK, i64 %39082
  %39084 = load i256, i256* %39083, align 4
  %39085 = load i64, i64* %STACK_DEP_PTR, align 4
  %39086 = sub i64 %39085, 1
  store i64 %39086, i64* %STACK_DEP_PTR, align 4
  %39087 = and i256 1461501637330902918203684832716283019655932542975, %39084
  %39088 = and i256 1461501637330902918203684832716283019655932542975, %39087
  %39089 = trunc i256 0 to i64
  %39090 = alloca i256, align 8
  store i256 %39088, i256* %39090, align 4
  %39091 = bitcast i256* %39090 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39089, i8* %39091, i64 32)
  %39092 = add i256 32, 0, !pc !583, !intsan !10
  %39093 = trunc i256 %39092 to i64
  %39094 = alloca i256, align 8
  store i256 3, i256* %39094, align 4
  %39095 = bitcast i256* %39094 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39093, i8* %39095, i64 32)
  %39096 = add i256 32, %39092, !pc !584, !intsan !10
  %39097 = trunc i256 0 to i32
  %39098 = trunc i256 %39096 to i32
  %39099 = getelementptr inbounds i8, i8* %MEMORY, i32 %39097
  %39100 = alloca i256, align 8
  %39101 = bitcast i256* %39100 to i8*
  call void @__device_sha3(i8* %39099, i32 %39098, i8* %39101)
  %39102 = load i256, i256* %39100, align 4
  %39103 = alloca i256, align 8
  store i256 %39102, i256* %39103, align 4
  %39104 = alloca i256, align 8
  call void @__device_sload(i256* %39103, i256* %39104)
  %39105 = call i32 @__hashword(i256* %39103)
  %39106 = load i32, i32* %5, align 4
  %39107 = icmp eq i32 %39105, %39106
  %39108 = or i1 false, %39107
  %39109 = load i32, i32* %6, align 4
  %39110 = icmp eq i32 %39105, %39109
  %39111 = or i1 %39108, %39110
  %39112 = load i32, i32* %7, align 4
  %39113 = icmp eq i32 %39105, %39112
  %39114 = or i1 %39111, %39113
  %39115 = load i32, i32* %8, align 4
  %39116 = icmp eq i32 %39105, %39115
  %39117 = or i1 %39114, %39116
  %39118 = load i32, i32* %9, align 4
  %39119 = icmp eq i32 %39105, %39118
  %39120 = or i1 %39117, %39119
  %39121 = load i32, i32* %10, align 4
  %39122 = icmp eq i32 %39105, %39121
  %39123 = or i1 %39120, %39122
  %39124 = load i32, i32* %11, align 4
  %39125 = icmp eq i32 %39105, %39124
  %39126 = or i1 %39123, %39125
  %39127 = load i32, i32* %12, align 4
  %39128 = icmp eq i32 %39105, %39127
  %39129 = or i1 %39126, %39128
  %39130 = load i32, i32* %13, align 4
  %39131 = icmp eq i32 %39105, %39130
  %39132 = or i1 %39129, %39131
  %39133 = load i32, i32* %14, align 4
  %39134 = icmp eq i32 %39105, %39133
  %39135 = or i1 %39132, %39134
  %39136 = load i32, i32* %15, align 4
  %39137 = icmp eq i32 %39105, %39136
  %39138 = or i1 %39135, %39137
  %39139 = load i32, i32* %16, align 4
  %39140 = icmp eq i32 %39105, %39139
  %39141 = or i1 %39138, %39140
  %39142 = load i32, i32* %17, align 4
  %39143 = icmp eq i32 %39105, %39142
  %39144 = or i1 %39141, %39143
  %39145 = load i32, i32* %18, align 4
  %39146 = icmp eq i32 %39105, %39145
  %39147 = or i1 %39144, %39146
  %39148 = load i32, i32* %19, align 4
  %39149 = icmp eq i32 %39105, %39148
  %39150 = or i1 %39147, %39149
  %39151 = load i32, i32* %20, align 4
  %39152 = icmp eq i32 %39105, %39151
  %39153 = or i1 %39150, %39152
  %39154 = load i32, i32* %21, align 4
  %39155 = icmp eq i32 %39105, %39154
  %39156 = or i1 %39153, %39155
  %39157 = load i32, i32* %22, align 4
  %39158 = icmp eq i32 %39105, %39157
  %39159 = or i1 %39156, %39158
  %39160 = load i32, i32* %23, align 4
  %39161 = icmp eq i32 %39105, %39160
  %39162 = or i1 %39159, %39161
  %39163 = load i32, i32* %24, align 4
  %39164 = icmp eq i32 %39105, %39163
  %39165 = or i1 %39162, %39164
  %39166 = load i32, i32* %25, align 4
  %39167 = icmp eq i32 %39105, %39166
  %39168 = or i1 %39165, %39167
  %39169 = load i32, i32* %26, align 4
  %39170 = icmp eq i32 %39105, %39169
  %39171 = or i1 %39168, %39170
  %39172 = load i32, i32* %27, align 4
  %39173 = icmp eq i32 %39105, %39172
  %39174 = or i1 %39171, %39173
  %39175 = load i32, i32* %28, align 4
  %39176 = icmp eq i32 %39105, %39175
  %39177 = or i1 %39174, %39176
  %39178 = load i32, i32* %29, align 4
  %39179 = icmp eq i32 %39105, %39178
  %39180 = or i1 %39177, %39179
  %39181 = load i32, i32* %30, align 4
  %39182 = icmp eq i32 %39105, %39181
  %39183 = or i1 %39180, %39182
  %39184 = load i32, i32* %31, align 4
  %39185 = icmp eq i32 %39105, %39184
  %39186 = or i1 %39183, %39185
  %39187 = load i32, i32* %32, align 4
  %39188 = icmp eq i32 %39105, %39187
  %39189 = or i1 %39186, %39188
  %39190 = load i32, i32* %33, align 4
  %39191 = icmp eq i32 %39105, %39190
  %39192 = or i1 %39189, %39191
  %39193 = load i32, i32* %34, align 4
  %39194 = icmp eq i32 %39105, %39193
  %39195 = or i1 %39192, %39194
  %39196 = load i32, i32* %35, align 4
  %39197 = icmp eq i32 %39105, %39196
  %39198 = or i1 %39195, %39197
  %39199 = load i32, i32* %36, align 4
  %39200 = icmp eq i32 %39105, %39199
  %39201 = or i1 %39198, %39200
  %39202 = load i32, i32* %37, align 4
  %39203 = icmp eq i32 %39105, %39202
  %39204 = or i1 %39201, %39203
  %39205 = load i32, i32* %38, align 4
  %39206 = icmp eq i32 %39105, %39205
  %39207 = or i1 %39204, %39206
  %39208 = load i32, i32* %39, align 4
  %39209 = icmp eq i32 %39105, %39208
  %39210 = or i1 %39207, %39209
  %39211 = load i32, i32* %40, align 4
  %39212 = icmp eq i32 %39105, %39211
  %39213 = or i1 %39210, %39212
  %39214 = load i32, i32* %41, align 4
  %39215 = icmp eq i32 %39105, %39214
  %39216 = or i1 %39213, %39215
  %39217 = load i32, i32* %42, align 4
  %39218 = icmp eq i32 %39105, %39217
  %39219 = or i1 %39216, %39218
  %39220 = load i32, i32* %43, align 4
  %39221 = icmp eq i32 %39105, %39220
  %39222 = or i1 %39219, %39221
  %39223 = load i32, i32* %44, align 4
  %39224 = icmp eq i32 %39105, %39223
  %39225 = or i1 %39222, %39224
  %39226 = load i32, i32* %45, align 4
  %39227 = icmp eq i32 %39105, %39226
  %39228 = or i1 %39225, %39227
  %39229 = load i32, i32* %46, align 4
  %39230 = icmp eq i32 %39105, %39229
  %39231 = or i1 %39228, %39230
  %39232 = load i32, i32* %47, align 4
  %39233 = icmp eq i32 %39105, %39232
  %39234 = or i1 %39231, %39233
  %39235 = load i32, i32* %48, align 4
  %39236 = icmp eq i32 %39105, %39235
  %39237 = or i1 %39234, %39236
  %39238 = load i32, i32* %49, align 4
  %39239 = icmp eq i32 %39105, %39238
  %39240 = or i1 %39237, %39239
  %39241 = load i32, i32* %50, align 4
  %39242 = icmp eq i32 %39105, %39241
  %39243 = or i1 %39240, %39242
  %39244 = load i32, i32* %51, align 4
  %39245 = icmp eq i32 %39105, %39244
  %39246 = or i1 %39243, %39245
  %39247 = load i32, i32* %52, align 4
  %39248 = icmp eq i32 %39105, %39247
  %39249 = or i1 %39246, %39248
  %39250 = load i32, i32* %53, align 4
  %39251 = icmp eq i32 %39105, %39250
  %39252 = or i1 %39249, %39251
  %39253 = load i32, i32* %54, align 4
  %39254 = icmp eq i32 %39105, %39253
  %39255 = or i1 %39252, %39254
  %39256 = load i32, i32* %55, align 4
  %39257 = icmp eq i32 %39105, %39256
  %39258 = or i1 %39255, %39257
  %39259 = load i32, i32* %56, align 4
  %39260 = icmp eq i32 %39105, %39259
  %39261 = or i1 %39258, %39260
  %39262 = load i32, i32* %57, align 4
  %39263 = icmp eq i32 %39105, %39262
  %39264 = or i1 %39261, %39263
  %39265 = load i32, i32* %58, align 4
  %39266 = icmp eq i32 %39105, %39265
  %39267 = or i1 %39264, %39266
  %39268 = load i32, i32* %59, align 4
  %39269 = icmp eq i32 %39105, %39268
  %39270 = or i1 %39267, %39269
  %39271 = load i32, i32* %60, align 4
  %39272 = icmp eq i32 %39105, %39271
  %39273 = or i1 %39270, %39272
  %39274 = load i32, i32* %61, align 4
  %39275 = icmp eq i32 %39105, %39274
  %39276 = or i1 %39273, %39275
  %39277 = load i32, i32* %62, align 4
  %39278 = icmp eq i32 %39105, %39277
  %39279 = or i1 %39276, %39278
  %39280 = getelementptr i8, i8 addrspace(1)* %4, i32 139
  %39281 = zext i1 %39279 to i8
  store i8 %39281, i8 addrspace(1)* %39280, align 1, !nosanitize !3
  %39282 = load i256, i256* %39104, align 4
  %39283 = trunc i256 11418 to i64
  %39284 = load i64, i64* %STACK_DEP_PTR, align 4
  %39285 = add i64 %39284, 1
  store i64 %39285, i64* %STACK_DEP_PTR, align 4
  %39286 = load i64, i64* %STACK_DEP_PTR, align 4
  %39287 = getelementptr i256, i256* %STACK, i64 %39286
  store i256 %39084, i256* %39287, align 4
  %39288 = load i64, i64* %STACK_DEP_PTR, align 4
  %39289 = add i64 %39288, 1
  store i64 %39289, i64* %STACK_DEP_PTR, align 4
  %39290 = load i64, i64* %STACK_DEP_PTR, align 4
  %39291 = getelementptr i256, i256* %STACK, i64 %39290
  store i256 %39282, i256* %39291, align 4
  %39292 = load i64, i64* %STACK_DEP_PTR, align 4
  %39293 = add i64 %39292, 1
  store i64 %39293, i64* %STACK_DEP_PTR, align 4
  %39294 = load i64, i64* %STACK_DEP_PTR, align 4
  %39295 = getelementptr i256, i256* %STACK, i64 %39294
  store i256 %39074, i256* %39295, align 4
  %39296 = load i64, i64* %STACK_DEP_PTR, align 4
  %39297 = add i64 %39296, 1
  store i64 %39297, i64* %STACK_DEP_PTR, align 4
  %39298 = load i64, i64* %STACK_DEP_PTR, align 4
  %39299 = getelementptr i256, i256* %STACK, i64 %39298
  store i256 %39069, i256* %39299, align 4
  %39300 = load i64, i64* %STACK_DEP_PTR, align 4
  %39301 = add i64 %39300, 1
  store i64 %39301, i64* %STACK_DEP_PTR, align 4
  %39302 = load i64, i64* %STACK_DEP_PTR, align 4
  %39303 = getelementptr i256, i256* %STACK, i64 %39302
  store i256 %39064, i256* %39303, align 4
  %39304 = load i64, i64* %STACK_DEP_PTR, align 4
  %39305 = add i64 %39304, 1
  store i64 %39305, i64* %STACK_DEP_PTR, align 4
  %39306 = load i64, i64* %STACK_DEP_PTR, align 4
  %39307 = getelementptr i256, i256* %STACK, i64 %39306
  store i256 13089, i256* %39307, align 4
  %39308 = load i64, i64* %STACK_DEP_PTR, align 4
  %39309 = add i64 %39308, 1
  store i64 %39309, i64* %STACK_DEP_PTR, align 4
  %39310 = load i64, i64* %STACK_DEP_PTR, align 4
  %39311 = getelementptr i256, i256* %STACK, i64 %39310
  store i256 %39084, i256* %39311, align 4
  br label %.11418, !EVMBB !4

.13089:                                           ; preds = %JumpTable
  %39312 = load i64, i64* %remaing_gas, align 4
  %39313 = icmp ugt i64 728, %39312
  br i1 %39313, label %Abort, label %39314

39314:                                            ; preds = %.13089
  %39315 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39316 = xor i32 %39315, 1748
  %39317 = urem i32 %39316, 4096
  %39318 = getelementptr i8, i8 addrspace(1)* %4, i32 %39317
  %39319 = load i8, i8 addrspace(1)* %39318, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %39318, align 1, !nosanitize !3
  store i32 874, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39320 = sub i64 %39312, 728
  store i64 %39320, i64* %remaing_gas, align 4
  %39321 = load i64, i64* %STACK_DEP_PTR, align 4
  %39322 = getelementptr i256, i256* %STACK, i64 %39321
  %39323 = load i256, i256* %39322, align 4
  %39324 = load i64, i64* %STACK_DEP_PTR, align 4
  %39325 = sub i64 %39324, 1
  store i64 %39325, i64* %STACK_DEP_PTR, align 4
  %39326 = load i64, i64* %STACK_DEP_PTR, align 4
  %39327 = getelementptr i256, i256* %STACK, i64 %39326
  %39328 = load i256, i256* %39327, align 4
  %39329 = load i64, i64* %STACK_DEP_PTR, align 4
  %39330 = sub i64 %39329, 1
  store i64 %39330, i64* %STACK_DEP_PTR, align 4
  %39331 = load i64, i64* %STACK_DEP_PTR, align 4
  %39332 = getelementptr i256, i256* %STACK, i64 %39331
  %39333 = load i256, i256* %39332, align 4
  %39334 = load i64, i64* %STACK_DEP_PTR, align 4
  %39335 = sub i64 %39334, 1
  store i64 %39335, i64* %STACK_DEP_PTR, align 4
  %39336 = load i64, i64* %STACK_DEP_PTR, align 4
  %39337 = getelementptr i256, i256* %STACK, i64 %39336
  %39338 = load i256, i256* %39337, align 4
  %39339 = load i64, i64* %STACK_DEP_PTR, align 4
  %39340 = sub i64 %39339, 1
  store i64 %39340, i64* %STACK_DEP_PTR, align 4
  %39341 = load i64, i64* %STACK_DEP_PTR, align 4
  %39342 = getelementptr i256, i256* %STACK, i64 %39341
  %39343 = load i256, i256* %39342, align 4
  %39344 = load i64, i64* %STACK_DEP_PTR, align 4
  %39345 = sub i64 %39344, 1
  store i64 %39345, i64* %STACK_DEP_PTR, align 4
  %39346 = trunc i256 0 to i64
  %39347 = alloca i256, align 8
  store i256 %39343, i256* %39347, align 4
  %39348 = bitcast i256* %39347 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39346, i8* %39348, i64 32)
  %39349 = add i256 32, 0, !pc !585, !intsan !10
  %39350 = trunc i256 %39349 to i64
  %39351 = alloca i256, align 8
  store i256 4, i256* %39351, align 4
  %39352 = bitcast i256* %39351 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39350, i8* %39352, i64 32)
  %39353 = add i256 32, %39349, !pc !586, !intsan !10
  %39354 = trunc i256 0 to i32
  %39355 = trunc i256 %39353 to i32
  %39356 = getelementptr inbounds i8, i8* %MEMORY, i32 %39354
  %39357 = alloca i256, align 8
  %39358 = bitcast i256* %39357 to i8*
  call void @__device_sha3(i8* %39356, i32 %39355, i8* %39358)
  %39359 = load i256, i256* %39357, align 4
  %39360 = add i256 1, %39359, !pc !587, !intsan !10
  %39361 = alloca i256, align 8
  store i256 %39360, i256* %39361, align 4
  %39362 = alloca i256, align 8
  call void @__device_sload(i256* %39361, i256* %39362)
  %39363 = call i32 @__hashword(i256* %39361)
  %39364 = load i32, i32* %5, align 4
  %39365 = icmp eq i32 %39363, %39364
  %39366 = or i1 false, %39365
  %39367 = load i32, i32* %6, align 4
  %39368 = icmp eq i32 %39363, %39367
  %39369 = or i1 %39366, %39368
  %39370 = load i32, i32* %7, align 4
  %39371 = icmp eq i32 %39363, %39370
  %39372 = or i1 %39369, %39371
  %39373 = load i32, i32* %8, align 4
  %39374 = icmp eq i32 %39363, %39373
  %39375 = or i1 %39372, %39374
  %39376 = load i32, i32* %9, align 4
  %39377 = icmp eq i32 %39363, %39376
  %39378 = or i1 %39375, %39377
  %39379 = load i32, i32* %10, align 4
  %39380 = icmp eq i32 %39363, %39379
  %39381 = or i1 %39378, %39380
  %39382 = load i32, i32* %11, align 4
  %39383 = icmp eq i32 %39363, %39382
  %39384 = or i1 %39381, %39383
  %39385 = load i32, i32* %12, align 4
  %39386 = icmp eq i32 %39363, %39385
  %39387 = or i1 %39384, %39386
  %39388 = load i32, i32* %13, align 4
  %39389 = icmp eq i32 %39363, %39388
  %39390 = or i1 %39387, %39389
  %39391 = load i32, i32* %14, align 4
  %39392 = icmp eq i32 %39363, %39391
  %39393 = or i1 %39390, %39392
  %39394 = load i32, i32* %15, align 4
  %39395 = icmp eq i32 %39363, %39394
  %39396 = or i1 %39393, %39395
  %39397 = load i32, i32* %16, align 4
  %39398 = icmp eq i32 %39363, %39397
  %39399 = or i1 %39396, %39398
  %39400 = load i32, i32* %17, align 4
  %39401 = icmp eq i32 %39363, %39400
  %39402 = or i1 %39399, %39401
  %39403 = load i32, i32* %18, align 4
  %39404 = icmp eq i32 %39363, %39403
  %39405 = or i1 %39402, %39404
  %39406 = load i32, i32* %19, align 4
  %39407 = icmp eq i32 %39363, %39406
  %39408 = or i1 %39405, %39407
  %39409 = load i32, i32* %20, align 4
  %39410 = icmp eq i32 %39363, %39409
  %39411 = or i1 %39408, %39410
  %39412 = load i32, i32* %21, align 4
  %39413 = icmp eq i32 %39363, %39412
  %39414 = or i1 %39411, %39413
  %39415 = load i32, i32* %22, align 4
  %39416 = icmp eq i32 %39363, %39415
  %39417 = or i1 %39414, %39416
  %39418 = load i32, i32* %23, align 4
  %39419 = icmp eq i32 %39363, %39418
  %39420 = or i1 %39417, %39419
  %39421 = load i32, i32* %24, align 4
  %39422 = icmp eq i32 %39363, %39421
  %39423 = or i1 %39420, %39422
  %39424 = load i32, i32* %25, align 4
  %39425 = icmp eq i32 %39363, %39424
  %39426 = or i1 %39423, %39425
  %39427 = load i32, i32* %26, align 4
  %39428 = icmp eq i32 %39363, %39427
  %39429 = or i1 %39426, %39428
  %39430 = load i32, i32* %27, align 4
  %39431 = icmp eq i32 %39363, %39430
  %39432 = or i1 %39429, %39431
  %39433 = load i32, i32* %28, align 4
  %39434 = icmp eq i32 %39363, %39433
  %39435 = or i1 %39432, %39434
  %39436 = load i32, i32* %29, align 4
  %39437 = icmp eq i32 %39363, %39436
  %39438 = or i1 %39435, %39437
  %39439 = load i32, i32* %30, align 4
  %39440 = icmp eq i32 %39363, %39439
  %39441 = or i1 %39438, %39440
  %39442 = load i32, i32* %31, align 4
  %39443 = icmp eq i32 %39363, %39442
  %39444 = or i1 %39441, %39443
  %39445 = load i32, i32* %32, align 4
  %39446 = icmp eq i32 %39363, %39445
  %39447 = or i1 %39444, %39446
  %39448 = load i32, i32* %33, align 4
  %39449 = icmp eq i32 %39363, %39448
  %39450 = or i1 %39447, %39449
  %39451 = load i32, i32* %34, align 4
  %39452 = icmp eq i32 %39363, %39451
  %39453 = or i1 %39450, %39452
  %39454 = load i32, i32* %35, align 4
  %39455 = icmp eq i32 %39363, %39454
  %39456 = or i1 %39453, %39455
  %39457 = load i32, i32* %36, align 4
  %39458 = icmp eq i32 %39363, %39457
  %39459 = or i1 %39456, %39458
  %39460 = load i32, i32* %37, align 4
  %39461 = icmp eq i32 %39363, %39460
  %39462 = or i1 %39459, %39461
  %39463 = load i32, i32* %38, align 4
  %39464 = icmp eq i32 %39363, %39463
  %39465 = or i1 %39462, %39464
  %39466 = load i32, i32* %39, align 4
  %39467 = icmp eq i32 %39363, %39466
  %39468 = or i1 %39465, %39467
  %39469 = load i32, i32* %40, align 4
  %39470 = icmp eq i32 %39363, %39469
  %39471 = or i1 %39468, %39470
  %39472 = load i32, i32* %41, align 4
  %39473 = icmp eq i32 %39363, %39472
  %39474 = or i1 %39471, %39473
  %39475 = load i32, i32* %42, align 4
  %39476 = icmp eq i32 %39363, %39475
  %39477 = or i1 %39474, %39476
  %39478 = load i32, i32* %43, align 4
  %39479 = icmp eq i32 %39363, %39478
  %39480 = or i1 %39477, %39479
  %39481 = load i32, i32* %44, align 4
  %39482 = icmp eq i32 %39363, %39481
  %39483 = or i1 %39480, %39482
  %39484 = load i32, i32* %45, align 4
  %39485 = icmp eq i32 %39363, %39484
  %39486 = or i1 %39483, %39485
  %39487 = load i32, i32* %46, align 4
  %39488 = icmp eq i32 %39363, %39487
  %39489 = or i1 %39486, %39488
  %39490 = load i32, i32* %47, align 4
  %39491 = icmp eq i32 %39363, %39490
  %39492 = or i1 %39489, %39491
  %39493 = load i32, i32* %48, align 4
  %39494 = icmp eq i32 %39363, %39493
  %39495 = or i1 %39492, %39494
  %39496 = load i32, i32* %49, align 4
  %39497 = icmp eq i32 %39363, %39496
  %39498 = or i1 %39495, %39497
  %39499 = load i32, i32* %50, align 4
  %39500 = icmp eq i32 %39363, %39499
  %39501 = or i1 %39498, %39500
  %39502 = load i32, i32* %51, align 4
  %39503 = icmp eq i32 %39363, %39502
  %39504 = or i1 %39501, %39503
  %39505 = load i32, i32* %52, align 4
  %39506 = icmp eq i32 %39363, %39505
  %39507 = or i1 %39504, %39506
  %39508 = load i32, i32* %53, align 4
  %39509 = icmp eq i32 %39363, %39508
  %39510 = or i1 %39507, %39509
  %39511 = load i32, i32* %54, align 4
  %39512 = icmp eq i32 %39363, %39511
  %39513 = or i1 %39510, %39512
  %39514 = load i32, i32* %55, align 4
  %39515 = icmp eq i32 %39363, %39514
  %39516 = or i1 %39513, %39515
  %39517 = load i32, i32* %56, align 4
  %39518 = icmp eq i32 %39363, %39517
  %39519 = or i1 %39516, %39518
  %39520 = load i32, i32* %57, align 4
  %39521 = icmp eq i32 %39363, %39520
  %39522 = or i1 %39519, %39521
  %39523 = load i32, i32* %58, align 4
  %39524 = icmp eq i32 %39363, %39523
  %39525 = or i1 %39522, %39524
  %39526 = load i32, i32* %59, align 4
  %39527 = icmp eq i32 %39363, %39526
  %39528 = or i1 %39525, %39527
  %39529 = load i32, i32* %60, align 4
  %39530 = icmp eq i32 %39363, %39529
  %39531 = or i1 %39528, %39530
  %39532 = load i32, i32* %61, align 4
  %39533 = icmp eq i32 %39363, %39532
  %39534 = or i1 %39531, %39533
  %39535 = load i32, i32* %62, align 4
  %39536 = icmp eq i32 %39363, %39535
  %39537 = or i1 %39534, %39536
  %39538 = getelementptr i8, i8 addrspace(1)* %4, i32 140
  %39539 = zext i1 %39537 to i8
  store i8 %39539, i8 addrspace(1)* %39538, align 1, !nosanitize !3
  %39540 = load i256, i256* %39362, align 4
  %39541 = alloca i256, align 8
  store i256 6, i256* %39541, align 4
  %39542 = alloca i256, align 8
  call void @__device_sload(i256* %39541, i256* %39542)
  %39543 = call i32 @__hashword(i256* %39541)
  %39544 = load i32, i32* %5, align 4
  %39545 = icmp eq i32 %39543, %39544
  %39546 = or i1 false, %39545
  %39547 = load i32, i32* %6, align 4
  %39548 = icmp eq i32 %39543, %39547
  %39549 = or i1 %39546, %39548
  %39550 = load i32, i32* %7, align 4
  %39551 = icmp eq i32 %39543, %39550
  %39552 = or i1 %39549, %39551
  %39553 = load i32, i32* %8, align 4
  %39554 = icmp eq i32 %39543, %39553
  %39555 = or i1 %39552, %39554
  %39556 = load i32, i32* %9, align 4
  %39557 = icmp eq i32 %39543, %39556
  %39558 = or i1 %39555, %39557
  %39559 = load i32, i32* %10, align 4
  %39560 = icmp eq i32 %39543, %39559
  %39561 = or i1 %39558, %39560
  %39562 = load i32, i32* %11, align 4
  %39563 = icmp eq i32 %39543, %39562
  %39564 = or i1 %39561, %39563
  %39565 = load i32, i32* %12, align 4
  %39566 = icmp eq i32 %39543, %39565
  %39567 = or i1 %39564, %39566
  %39568 = load i32, i32* %13, align 4
  %39569 = icmp eq i32 %39543, %39568
  %39570 = or i1 %39567, %39569
  %39571 = load i32, i32* %14, align 4
  %39572 = icmp eq i32 %39543, %39571
  %39573 = or i1 %39570, %39572
  %39574 = load i32, i32* %15, align 4
  %39575 = icmp eq i32 %39543, %39574
  %39576 = or i1 %39573, %39575
  %39577 = load i32, i32* %16, align 4
  %39578 = icmp eq i32 %39543, %39577
  %39579 = or i1 %39576, %39578
  %39580 = load i32, i32* %17, align 4
  %39581 = icmp eq i32 %39543, %39580
  %39582 = or i1 %39579, %39581
  %39583 = load i32, i32* %18, align 4
  %39584 = icmp eq i32 %39543, %39583
  %39585 = or i1 %39582, %39584
  %39586 = load i32, i32* %19, align 4
  %39587 = icmp eq i32 %39543, %39586
  %39588 = or i1 %39585, %39587
  %39589 = load i32, i32* %20, align 4
  %39590 = icmp eq i32 %39543, %39589
  %39591 = or i1 %39588, %39590
  %39592 = load i32, i32* %21, align 4
  %39593 = icmp eq i32 %39543, %39592
  %39594 = or i1 %39591, %39593
  %39595 = load i32, i32* %22, align 4
  %39596 = icmp eq i32 %39543, %39595
  %39597 = or i1 %39594, %39596
  %39598 = load i32, i32* %23, align 4
  %39599 = icmp eq i32 %39543, %39598
  %39600 = or i1 %39597, %39599
  %39601 = load i32, i32* %24, align 4
  %39602 = icmp eq i32 %39543, %39601
  %39603 = or i1 %39600, %39602
  %39604 = load i32, i32* %25, align 4
  %39605 = icmp eq i32 %39543, %39604
  %39606 = or i1 %39603, %39605
  %39607 = load i32, i32* %26, align 4
  %39608 = icmp eq i32 %39543, %39607
  %39609 = or i1 %39606, %39608
  %39610 = load i32, i32* %27, align 4
  %39611 = icmp eq i32 %39543, %39610
  %39612 = or i1 %39609, %39611
  %39613 = load i32, i32* %28, align 4
  %39614 = icmp eq i32 %39543, %39613
  %39615 = or i1 %39612, %39614
  %39616 = load i32, i32* %29, align 4
  %39617 = icmp eq i32 %39543, %39616
  %39618 = or i1 %39615, %39617
  %39619 = load i32, i32* %30, align 4
  %39620 = icmp eq i32 %39543, %39619
  %39621 = or i1 %39618, %39620
  %39622 = load i32, i32* %31, align 4
  %39623 = icmp eq i32 %39543, %39622
  %39624 = or i1 %39621, %39623
  %39625 = load i32, i32* %32, align 4
  %39626 = icmp eq i32 %39543, %39625
  %39627 = or i1 %39624, %39626
  %39628 = load i32, i32* %33, align 4
  %39629 = icmp eq i32 %39543, %39628
  %39630 = or i1 %39627, %39629
  %39631 = load i32, i32* %34, align 4
  %39632 = icmp eq i32 %39543, %39631
  %39633 = or i1 %39630, %39632
  %39634 = load i32, i32* %35, align 4
  %39635 = icmp eq i32 %39543, %39634
  %39636 = or i1 %39633, %39635
  %39637 = load i32, i32* %36, align 4
  %39638 = icmp eq i32 %39543, %39637
  %39639 = or i1 %39636, %39638
  %39640 = load i32, i32* %37, align 4
  %39641 = icmp eq i32 %39543, %39640
  %39642 = or i1 %39639, %39641
  %39643 = load i32, i32* %38, align 4
  %39644 = icmp eq i32 %39543, %39643
  %39645 = or i1 %39642, %39644
  %39646 = load i32, i32* %39, align 4
  %39647 = icmp eq i32 %39543, %39646
  %39648 = or i1 %39645, %39647
  %39649 = load i32, i32* %40, align 4
  %39650 = icmp eq i32 %39543, %39649
  %39651 = or i1 %39648, %39650
  %39652 = load i32, i32* %41, align 4
  %39653 = icmp eq i32 %39543, %39652
  %39654 = or i1 %39651, %39653
  %39655 = load i32, i32* %42, align 4
  %39656 = icmp eq i32 %39543, %39655
  %39657 = or i1 %39654, %39656
  %39658 = load i32, i32* %43, align 4
  %39659 = icmp eq i32 %39543, %39658
  %39660 = or i1 %39657, %39659
  %39661 = load i32, i32* %44, align 4
  %39662 = icmp eq i32 %39543, %39661
  %39663 = or i1 %39660, %39662
  %39664 = load i32, i32* %45, align 4
  %39665 = icmp eq i32 %39543, %39664
  %39666 = or i1 %39663, %39665
  %39667 = load i32, i32* %46, align 4
  %39668 = icmp eq i32 %39543, %39667
  %39669 = or i1 %39666, %39668
  %39670 = load i32, i32* %47, align 4
  %39671 = icmp eq i32 %39543, %39670
  %39672 = or i1 %39669, %39671
  %39673 = load i32, i32* %48, align 4
  %39674 = icmp eq i32 %39543, %39673
  %39675 = or i1 %39672, %39674
  %39676 = load i32, i32* %49, align 4
  %39677 = icmp eq i32 %39543, %39676
  %39678 = or i1 %39675, %39677
  %39679 = load i32, i32* %50, align 4
  %39680 = icmp eq i32 %39543, %39679
  %39681 = or i1 %39678, %39680
  %39682 = load i32, i32* %51, align 4
  %39683 = icmp eq i32 %39543, %39682
  %39684 = or i1 %39681, %39683
  %39685 = load i32, i32* %52, align 4
  %39686 = icmp eq i32 %39543, %39685
  %39687 = or i1 %39684, %39686
  %39688 = load i32, i32* %53, align 4
  %39689 = icmp eq i32 %39543, %39688
  %39690 = or i1 %39687, %39689
  %39691 = load i32, i32* %54, align 4
  %39692 = icmp eq i32 %39543, %39691
  %39693 = or i1 %39690, %39692
  %39694 = load i32, i32* %55, align 4
  %39695 = icmp eq i32 %39543, %39694
  %39696 = or i1 %39693, %39695
  %39697 = load i32, i32* %56, align 4
  %39698 = icmp eq i32 %39543, %39697
  %39699 = or i1 %39696, %39698
  %39700 = load i32, i32* %57, align 4
  %39701 = icmp eq i32 %39543, %39700
  %39702 = or i1 %39699, %39701
  %39703 = load i32, i32* %58, align 4
  %39704 = icmp eq i32 %39543, %39703
  %39705 = or i1 %39702, %39704
  %39706 = load i32, i32* %59, align 4
  %39707 = icmp eq i32 %39543, %39706
  %39708 = or i1 %39705, %39707
  %39709 = load i32, i32* %60, align 4
  %39710 = icmp eq i32 %39543, %39709
  %39711 = or i1 %39708, %39710
  %39712 = load i32, i32* %61, align 4
  %39713 = icmp eq i32 %39543, %39712
  %39714 = or i1 %39711, %39713
  %39715 = load i32, i32* %62, align 4
  %39716 = icmp eq i32 %39543, %39715
  %39717 = or i1 %39714, %39716
  %39718 = getelementptr i8, i8 addrspace(1)* %4, i32 141
  %39719 = zext i1 %39717 to i8
  store i8 %39719, i8 addrspace(1)* %39718, align 1, !nosanitize !3
  %39720 = load i256, i256* %39542, align 4
  %39721 = icmp ult i256 %39720, %39540
  %39722 = icmp eq i1 %39721, false
  %39723 = icmp eq i1 %39722, false
  %39724 = trunc i256 13938 to i64
  %jump.check71 = icmp ne i1 %39723, false
  %39725 = load i64, i64* %STACK_DEP_PTR, align 4
  %39726 = add i64 %39725, 1
  store i64 %39726, i64* %STACK_DEP_PTR, align 4
  %39727 = load i64, i64* %STACK_DEP_PTR, align 4
  %39728 = getelementptr i256, i256* %STACK, i64 %39727
  store i256 %39343, i256* %39728, align 4
  %39729 = load i64, i64* %STACK_DEP_PTR, align 4
  %39730 = add i64 %39729, 1
  store i64 %39730, i64* %STACK_DEP_PTR, align 4
  %39731 = load i64, i64* %STACK_DEP_PTR, align 4
  %39732 = getelementptr i256, i256* %STACK, i64 %39731
  store i256 %39323, i256* %39732, align 4
  %39733 = load i64, i64* %STACK_DEP_PTR, align 4
  %39734 = add i64 %39733, 1
  store i64 %39734, i64* %STACK_DEP_PTR, align 4
  %39735 = load i64, i64* %STACK_DEP_PTR, align 4
  %39736 = getelementptr i256, i256* %STACK, i64 %39735
  store i256 %39333, i256* %39736, align 4
  %39737 = load i64, i64* %STACK_DEP_PTR, align 4
  %39738 = add i64 %39737, 1
  store i64 %39738, i64* %STACK_DEP_PTR, align 4
  %39739 = load i64, i64* %STACK_DEP_PTR, align 4
  %39740 = getelementptr i256, i256* %STACK, i64 %39739
  store i256 %39328, i256* %39740, align 4
  br i1 %jump.check71, label %.13938, label %.13125, !EVMBB !4

.13125:                                           ; preds = %39314
  %39741 = load i64, i64* %remaing_gas, align 4
  %39742 = icmp ugt i64 656, %39741
  br i1 %39742, label %Abort, label %39743

39743:                                            ; preds = %.13125
  %39744 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39745 = xor i32 %39744, 1974
  %39746 = urem i32 %39745, 4096
  %39747 = getelementptr i8, i8 addrspace(1)* %4, i32 %39746
  %39748 = load i8, i8 addrspace(1)* %39747, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %39747, align 1, !nosanitize !3
  store i32 987, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %39749 = sub i64 %39741, 656
  store i64 %39749, i64* %remaing_gas, align 4
  %39750 = load i64, i64* %STACK_DEP_PTR, align 4
  %39751 = sub i64 %39750, 4
  store i64 %39751, i64* %STACK_DEP_PTR, align 4
  %39752 = trunc i256 0 to i64
  %39753 = alloca i256, align 8
  store i256 %39343, i256* %39753, align 4
  %39754 = bitcast i256* %39753 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39752, i8* %39754, i64 32)
  %39755 = add i256 32, 0, !pc !588, !intsan !10
  %39756 = trunc i256 %39755 to i64
  %39757 = alloca i256, align 8
  store i256 4, i256* %39757, align 4
  %39758 = bitcast i256* %39757 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %39756, i8* %39758, i64 32)
  %39759 = add i256 32, %39755, !pc !589, !intsan !10
  %39760 = trunc i256 0 to i32
  %39761 = trunc i256 %39759 to i32
  %39762 = getelementptr inbounds i8, i8* %MEMORY, i32 %39760
  %39763 = alloca i256, align 8
  %39764 = bitcast i256* %39763 to i8*
  call void @__device_sha3(i8* %39762, i32 %39761, i8* %39764)
  %39765 = load i256, i256* %39763, align 4
  %39766 = add i256 1, %39765, !pc !590, !intsan !10
  %39767 = alloca i256, align 8
  store i256 %39766, i256* %39767, align 4
  %39768 = alloca i256, align 8
  call void @__device_sload(i256* %39767, i256* %39768)
  %39769 = call i32 @__hashword(i256* %39767)
  %39770 = load i32, i32* %5, align 4
  %39771 = icmp eq i32 %39769, %39770
  %39772 = or i1 false, %39771
  %39773 = load i32, i32* %6, align 4
  %39774 = icmp eq i32 %39769, %39773
  %39775 = or i1 %39772, %39774
  %39776 = load i32, i32* %7, align 4
  %39777 = icmp eq i32 %39769, %39776
  %39778 = or i1 %39775, %39777
  %39779 = load i32, i32* %8, align 4
  %39780 = icmp eq i32 %39769, %39779
  %39781 = or i1 %39778, %39780
  %39782 = load i32, i32* %9, align 4
  %39783 = icmp eq i32 %39769, %39782
  %39784 = or i1 %39781, %39783
  %39785 = load i32, i32* %10, align 4
  %39786 = icmp eq i32 %39769, %39785
  %39787 = or i1 %39784, %39786
  %39788 = load i32, i32* %11, align 4
  %39789 = icmp eq i32 %39769, %39788
  %39790 = or i1 %39787, %39789
  %39791 = load i32, i32* %12, align 4
  %39792 = icmp eq i32 %39769, %39791
  %39793 = or i1 %39790, %39792
  %39794 = load i32, i32* %13, align 4
  %39795 = icmp eq i32 %39769, %39794
  %39796 = or i1 %39793, %39795
  %39797 = load i32, i32* %14, align 4
  %39798 = icmp eq i32 %39769, %39797
  %39799 = or i1 %39796, %39798
  %39800 = load i32, i32* %15, align 4
  %39801 = icmp eq i32 %39769, %39800
  %39802 = or i1 %39799, %39801
  %39803 = load i32, i32* %16, align 4
  %39804 = icmp eq i32 %39769, %39803
  %39805 = or i1 %39802, %39804
  %39806 = load i32, i32* %17, align 4
  %39807 = icmp eq i32 %39769, %39806
  %39808 = or i1 %39805, %39807
  %39809 = load i32, i32* %18, align 4
  %39810 = icmp eq i32 %39769, %39809
  %39811 = or i1 %39808, %39810
  %39812 = load i32, i32* %19, align 4
  %39813 = icmp eq i32 %39769, %39812
  %39814 = or i1 %39811, %39813
  %39815 = load i32, i32* %20, align 4
  %39816 = icmp eq i32 %39769, %39815
  %39817 = or i1 %39814, %39816
  %39818 = load i32, i32* %21, align 4
  %39819 = icmp eq i32 %39769, %39818
  %39820 = or i1 %39817, %39819
  %39821 = load i32, i32* %22, align 4
  %39822 = icmp eq i32 %39769, %39821
  %39823 = or i1 %39820, %39822
  %39824 = load i32, i32* %23, align 4
  %39825 = icmp eq i32 %39769, %39824
  %39826 = or i1 %39823, %39825
  %39827 = load i32, i32* %24, align 4
  %39828 = icmp eq i32 %39769, %39827
  %39829 = or i1 %39826, %39828
  %39830 = load i32, i32* %25, align 4
  %39831 = icmp eq i32 %39769, %39830
  %39832 = or i1 %39829, %39831
  %39833 = load i32, i32* %26, align 4
  %39834 = icmp eq i32 %39769, %39833
  %39835 = or i1 %39832, %39834
  %39836 = load i32, i32* %27, align 4
  %39837 = icmp eq i32 %39769, %39836
  %39838 = or i1 %39835, %39837
  %39839 = load i32, i32* %28, align 4
  %39840 = icmp eq i32 %39769, %39839
  %39841 = or i1 %39838, %39840
  %39842 = load i32, i32* %29, align 4
  %39843 = icmp eq i32 %39769, %39842
  %39844 = or i1 %39841, %39843
  %39845 = load i32, i32* %30, align 4
  %39846 = icmp eq i32 %39769, %39845
  %39847 = or i1 %39844, %39846
  %39848 = load i32, i32* %31, align 4
  %39849 = icmp eq i32 %39769, %39848
  %39850 = or i1 %39847, %39849
  %39851 = load i32, i32* %32, align 4
  %39852 = icmp eq i32 %39769, %39851
  %39853 = or i1 %39850, %39852
  %39854 = load i32, i32* %33, align 4
  %39855 = icmp eq i32 %39769, %39854
  %39856 = or i1 %39853, %39855
  %39857 = load i32, i32* %34, align 4
  %39858 = icmp eq i32 %39769, %39857
  %39859 = or i1 %39856, %39858
  %39860 = load i32, i32* %35, align 4
  %39861 = icmp eq i32 %39769, %39860
  %39862 = or i1 %39859, %39861
  %39863 = load i32, i32* %36, align 4
  %39864 = icmp eq i32 %39769, %39863
  %39865 = or i1 %39862, %39864
  %39866 = load i32, i32* %37, align 4
  %39867 = icmp eq i32 %39769, %39866
  %39868 = or i1 %39865, %39867
  %39869 = load i32, i32* %38, align 4
  %39870 = icmp eq i32 %39769, %39869
  %39871 = or i1 %39868, %39870
  %39872 = load i32, i32* %39, align 4
  %39873 = icmp eq i32 %39769, %39872
  %39874 = or i1 %39871, %39873
  %39875 = load i32, i32* %40, align 4
  %39876 = icmp eq i32 %39769, %39875
  %39877 = or i1 %39874, %39876
  %39878 = load i32, i32* %41, align 4
  %39879 = icmp eq i32 %39769, %39878
  %39880 = or i1 %39877, %39879
  %39881 = load i32, i32* %42, align 4
  %39882 = icmp eq i32 %39769, %39881
  %39883 = or i1 %39880, %39882
  %39884 = load i32, i32* %43, align 4
  %39885 = icmp eq i32 %39769, %39884
  %39886 = or i1 %39883, %39885
  %39887 = load i32, i32* %44, align 4
  %39888 = icmp eq i32 %39769, %39887
  %39889 = or i1 %39886, %39888
  %39890 = load i32, i32* %45, align 4
  %39891 = icmp eq i32 %39769, %39890
  %39892 = or i1 %39889, %39891
  %39893 = load i32, i32* %46, align 4
  %39894 = icmp eq i32 %39769, %39893
  %39895 = or i1 %39892, %39894
  %39896 = load i32, i32* %47, align 4
  %39897 = icmp eq i32 %39769, %39896
  %39898 = or i1 %39895, %39897
  %39899 = load i32, i32* %48, align 4
  %39900 = icmp eq i32 %39769, %39899
  %39901 = or i1 %39898, %39900
  %39902 = load i32, i32* %49, align 4
  %39903 = icmp eq i32 %39769, %39902
  %39904 = or i1 %39901, %39903
  %39905 = load i32, i32* %50, align 4
  %39906 = icmp eq i32 %39769, %39905
  %39907 = or i1 %39904, %39906
  %39908 = load i32, i32* %51, align 4
  %39909 = icmp eq i32 %39769, %39908
  %39910 = or i1 %39907, %39909
  %39911 = load i32, i32* %52, align 4
  %39912 = icmp eq i32 %39769, %39911
  %39913 = or i1 %39910, %39912
  %39914 = load i32, i32* %53, align 4
  %39915 = icmp eq i32 %39769, %39914
  %39916 = or i1 %39913, %39915
  %39917 = load i32, i32* %54, align 4
  %39918 = icmp eq i32 %39769, %39917
  %39919 = or i1 %39916, %39918
  %39920 = load i32, i32* %55, align 4
  %39921 = icmp eq i32 %39769, %39920
  %39922 = or i1 %39919, %39921
  %39923 = load i32, i32* %56, align 4
  %39924 = icmp eq i32 %39769, %39923
  %39925 = or i1 %39922, %39924
  %39926 = load i32, i32* %57, align 4
  %39927 = icmp eq i32 %39769, %39926
  %39928 = or i1 %39925, %39927
  %39929 = load i32, i32* %58, align 4
  %39930 = icmp eq i32 %39769, %39929
  %39931 = or i1 %39928, %39930
  %39932 = load i32, i32* %59, align 4
  %39933 = icmp eq i32 %39769, %39932
  %39934 = or i1 %39931, %39933
  %39935 = load i32, i32* %60, align 4
  %39936 = icmp eq i32 %39769, %39935
  %39937 = or i1 %39934, %39936
  %39938 = load i32, i32* %61, align 4
  %39939 = icmp eq i32 %39769, %39938
  %39940 = or i1 %39937, %39939
  %39941 = load i32, i32* %62, align 4
  %39942 = icmp eq i32 %39769, %39941
  %39943 = or i1 %39940, %39942
  %39944 = getelementptr i8, i8 addrspace(1)* %4, i32 142
  %39945 = zext i1 %39943 to i8
  store i8 %39945, i8 addrspace(1)* %39944, align 1, !nosanitize !3
  %39946 = load i256, i256* %39768, align 4
  %39947 = alloca i256, align 8
  store i256 6, i256* %39947, align 4
  %39948 = alloca i256, align 8
  call void @__device_sload(i256* %39947, i256* %39948)
  %39949 = call i32 @__hashword(i256* %39947)
  %39950 = load i32, i32* %5, align 4
  %39951 = icmp eq i32 %39949, %39950
  %39952 = or i1 false, %39951
  %39953 = load i32, i32* %6, align 4
  %39954 = icmp eq i32 %39949, %39953
  %39955 = or i1 %39952, %39954
  %39956 = load i32, i32* %7, align 4
  %39957 = icmp eq i32 %39949, %39956
  %39958 = or i1 %39955, %39957
  %39959 = load i32, i32* %8, align 4
  %39960 = icmp eq i32 %39949, %39959
  %39961 = or i1 %39958, %39960
  %39962 = load i32, i32* %9, align 4
  %39963 = icmp eq i32 %39949, %39962
  %39964 = or i1 %39961, %39963
  %39965 = load i32, i32* %10, align 4
  %39966 = icmp eq i32 %39949, %39965
  %39967 = or i1 %39964, %39966
  %39968 = load i32, i32* %11, align 4
  %39969 = icmp eq i32 %39949, %39968
  %39970 = or i1 %39967, %39969
  %39971 = load i32, i32* %12, align 4
  %39972 = icmp eq i32 %39949, %39971
  %39973 = or i1 %39970, %39972
  %39974 = load i32, i32* %13, align 4
  %39975 = icmp eq i32 %39949, %39974
  %39976 = or i1 %39973, %39975
  %39977 = load i32, i32* %14, align 4
  %39978 = icmp eq i32 %39949, %39977
  %39979 = or i1 %39976, %39978
  %39980 = load i32, i32* %15, align 4
  %39981 = icmp eq i32 %39949, %39980
  %39982 = or i1 %39979, %39981
  %39983 = load i32, i32* %16, align 4
  %39984 = icmp eq i32 %39949, %39983
  %39985 = or i1 %39982, %39984
  %39986 = load i32, i32* %17, align 4
  %39987 = icmp eq i32 %39949, %39986
  %39988 = or i1 %39985, %39987
  %39989 = load i32, i32* %18, align 4
  %39990 = icmp eq i32 %39949, %39989
  %39991 = or i1 %39988, %39990
  %39992 = load i32, i32* %19, align 4
  %39993 = icmp eq i32 %39949, %39992
  %39994 = or i1 %39991, %39993
  %39995 = load i32, i32* %20, align 4
  %39996 = icmp eq i32 %39949, %39995
  %39997 = or i1 %39994, %39996
  %39998 = load i32, i32* %21, align 4
  %39999 = icmp eq i32 %39949, %39998
  %40000 = or i1 %39997, %39999
  %40001 = load i32, i32* %22, align 4
  %40002 = icmp eq i32 %39949, %40001
  %40003 = or i1 %40000, %40002
  %40004 = load i32, i32* %23, align 4
  %40005 = icmp eq i32 %39949, %40004
  %40006 = or i1 %40003, %40005
  %40007 = load i32, i32* %24, align 4
  %40008 = icmp eq i32 %39949, %40007
  %40009 = or i1 %40006, %40008
  %40010 = load i32, i32* %25, align 4
  %40011 = icmp eq i32 %39949, %40010
  %40012 = or i1 %40009, %40011
  %40013 = load i32, i32* %26, align 4
  %40014 = icmp eq i32 %39949, %40013
  %40015 = or i1 %40012, %40014
  %40016 = load i32, i32* %27, align 4
  %40017 = icmp eq i32 %39949, %40016
  %40018 = or i1 %40015, %40017
  %40019 = load i32, i32* %28, align 4
  %40020 = icmp eq i32 %39949, %40019
  %40021 = or i1 %40018, %40020
  %40022 = load i32, i32* %29, align 4
  %40023 = icmp eq i32 %39949, %40022
  %40024 = or i1 %40021, %40023
  %40025 = load i32, i32* %30, align 4
  %40026 = icmp eq i32 %39949, %40025
  %40027 = or i1 %40024, %40026
  %40028 = load i32, i32* %31, align 4
  %40029 = icmp eq i32 %39949, %40028
  %40030 = or i1 %40027, %40029
  %40031 = load i32, i32* %32, align 4
  %40032 = icmp eq i32 %39949, %40031
  %40033 = or i1 %40030, %40032
  %40034 = load i32, i32* %33, align 4
  %40035 = icmp eq i32 %39949, %40034
  %40036 = or i1 %40033, %40035
  %40037 = load i32, i32* %34, align 4
  %40038 = icmp eq i32 %39949, %40037
  %40039 = or i1 %40036, %40038
  %40040 = load i32, i32* %35, align 4
  %40041 = icmp eq i32 %39949, %40040
  %40042 = or i1 %40039, %40041
  %40043 = load i32, i32* %36, align 4
  %40044 = icmp eq i32 %39949, %40043
  %40045 = or i1 %40042, %40044
  %40046 = load i32, i32* %37, align 4
  %40047 = icmp eq i32 %39949, %40046
  %40048 = or i1 %40045, %40047
  %40049 = load i32, i32* %38, align 4
  %40050 = icmp eq i32 %39949, %40049
  %40051 = or i1 %40048, %40050
  %40052 = load i32, i32* %39, align 4
  %40053 = icmp eq i32 %39949, %40052
  %40054 = or i1 %40051, %40053
  %40055 = load i32, i32* %40, align 4
  %40056 = icmp eq i32 %39949, %40055
  %40057 = or i1 %40054, %40056
  %40058 = load i32, i32* %41, align 4
  %40059 = icmp eq i32 %39949, %40058
  %40060 = or i1 %40057, %40059
  %40061 = load i32, i32* %42, align 4
  %40062 = icmp eq i32 %39949, %40061
  %40063 = or i1 %40060, %40062
  %40064 = load i32, i32* %43, align 4
  %40065 = icmp eq i32 %39949, %40064
  %40066 = or i1 %40063, %40065
  %40067 = load i32, i32* %44, align 4
  %40068 = icmp eq i32 %39949, %40067
  %40069 = or i1 %40066, %40068
  %40070 = load i32, i32* %45, align 4
  %40071 = icmp eq i32 %39949, %40070
  %40072 = or i1 %40069, %40071
  %40073 = load i32, i32* %46, align 4
  %40074 = icmp eq i32 %39949, %40073
  %40075 = or i1 %40072, %40074
  %40076 = load i32, i32* %47, align 4
  %40077 = icmp eq i32 %39949, %40076
  %40078 = or i1 %40075, %40077
  %40079 = load i32, i32* %48, align 4
  %40080 = icmp eq i32 %39949, %40079
  %40081 = or i1 %40078, %40080
  %40082 = load i32, i32* %49, align 4
  %40083 = icmp eq i32 %39949, %40082
  %40084 = or i1 %40081, %40083
  %40085 = load i32, i32* %50, align 4
  %40086 = icmp eq i32 %39949, %40085
  %40087 = or i1 %40084, %40086
  %40088 = load i32, i32* %51, align 4
  %40089 = icmp eq i32 %39949, %40088
  %40090 = or i1 %40087, %40089
  %40091 = load i32, i32* %52, align 4
  %40092 = icmp eq i32 %39949, %40091
  %40093 = or i1 %40090, %40092
  %40094 = load i32, i32* %53, align 4
  %40095 = icmp eq i32 %39949, %40094
  %40096 = or i1 %40093, %40095
  %40097 = load i32, i32* %54, align 4
  %40098 = icmp eq i32 %39949, %40097
  %40099 = or i1 %40096, %40098
  %40100 = load i32, i32* %55, align 4
  %40101 = icmp eq i32 %39949, %40100
  %40102 = or i1 %40099, %40101
  %40103 = load i32, i32* %56, align 4
  %40104 = icmp eq i32 %39949, %40103
  %40105 = or i1 %40102, %40104
  %40106 = load i32, i32* %57, align 4
  %40107 = icmp eq i32 %39949, %40106
  %40108 = or i1 %40105, %40107
  %40109 = load i32, i32* %58, align 4
  %40110 = icmp eq i32 %39949, %40109
  %40111 = or i1 %40108, %40110
  %40112 = load i32, i32* %59, align 4
  %40113 = icmp eq i32 %39949, %40112
  %40114 = or i1 %40111, %40113
  %40115 = load i32, i32* %60, align 4
  %40116 = icmp eq i32 %39949, %40115
  %40117 = or i1 %40114, %40116
  %40118 = load i32, i32* %61, align 4
  %40119 = icmp eq i32 %39949, %40118
  %40120 = or i1 %40117, %40119
  %40121 = load i32, i32* %62, align 4
  %40122 = icmp eq i32 %39949, %40121
  %40123 = or i1 %40120, %40122
  %40124 = getelementptr i8, i8 addrspace(1)* %4, i32 143
  %40125 = zext i1 %40123 to i8
  store i8 %40125, i8 addrspace(1)* %40124, align 1, !nosanitize !3
  %40126 = load i256, i256* %39948, align 4
  %40127 = sub i256 %40126, %39946, !pc !591, !intsan !8
  %40128 = alloca i256, align 8
  store i256 6, i256* %40128, align 4
  %40129 = alloca i256, align 8
  store i256 %40127, i256* %40129, align 4
  call void @__device_sstore(i256* %40128, i256* %40129)
  %40130 = call i32 @__hashword(i256* %40128)
  store i32 %40130, i32* %17, align 4, !nosanitize !3
  %40131 = mul i256 %39323, 50, !pc !592, !intsan !45
  %40132 = icmp eq i256 10000, 0
  %40133 = icmp eq i1 %40132, false
  %40134 = trunc i256 13178 to i64
  %jump.check76 = icmp ne i1 %40133, false
  %40135 = load i64, i64* %STACK_DEP_PTR, align 4
  %40136 = add i64 %40135, 1
  store i64 %40136, i64* %STACK_DEP_PTR, align 4
  %40137 = load i64, i64* %STACK_DEP_PTR, align 4
  %40138 = getelementptr i256, i256* %STACK, i64 %40137
  store i256 %39343, i256* %40138, align 4
  %40139 = load i64, i64* %STACK_DEP_PTR, align 4
  %40140 = add i64 %40139, 1
  store i64 %40140, i64* %STACK_DEP_PTR, align 4
  %40141 = load i64, i64* %STACK_DEP_PTR, align 4
  %40142 = getelementptr i256, i256* %STACK, i64 %40141
  store i256 %39323, i256* %40142, align 4
  %40143 = load i64, i64* %STACK_DEP_PTR, align 4
  %40144 = add i64 %40143, 1
  store i64 %40144, i64* %STACK_DEP_PTR, align 4
  %40145 = load i64, i64* %STACK_DEP_PTR, align 4
  %40146 = getelementptr i256, i256* %STACK, i64 %40145
  store i256 %39333, i256* %40146, align 4
  %40147 = load i64, i64* %STACK_DEP_PTR, align 4
  %40148 = add i64 %40147, 1
  store i64 %40148, i64* %STACK_DEP_PTR, align 4
  %40149 = load i64, i64* %STACK_DEP_PTR, align 4
  %40150 = getelementptr i256, i256* %STACK, i64 %40149
  store i256 %39328, i256* %40150, align 4
  %40151 = load i64, i64* %STACK_DEP_PTR, align 4
  %40152 = add i64 %40151, 1
  store i64 %40152, i64* %STACK_DEP_PTR, align 4
  %40153 = load i64, i64* %STACK_DEP_PTR, align 4
  %40154 = getelementptr i256, i256* %STACK, i64 %40153
  store i256 10000, i256* %40154, align 4
  %40155 = load i64, i64* %STACK_DEP_PTR, align 4
  %40156 = add i64 %40155, 1
  store i64 %40156, i64* %STACK_DEP_PTR, align 4
  %40157 = load i64, i64* %STACK_DEP_PTR, align 4
  %40158 = getelementptr i256, i256* %STACK, i64 %40157
  store i256 %40131, i256* %40158, align 4
  br i1 %jump.check76, label %.13178, label %.13177, !EVMBB !4

.13177:                                           ; preds = %39743
  %40159 = load i64, i64* %remaing_gas, align 4
  %40160 = icmp ugt i64 16, %40159
  br i1 %40160, label %Abort, label %40161

40161:                                            ; preds = %.13177
  %40162 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %40163 = xor i32 %40162, 99
  %40164 = urem i32 %40163, 4096
  %40165 = getelementptr i8, i8 addrspace(1)* %4, i32 %40164
  %40166 = load i8, i8 addrspace(1)* %40165, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %40165, align 1, !nosanitize !3
  store i32 49, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %40167 = sub i64 %40159, 16
  store i64 %40167, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.13178:                                           ; preds = %39743, %JumpTable
  %40168 = load i64, i64* %remaing_gas, align 4
  %40169 = icmp ugt i64 1368, %40168
  br i1 %40169, label %Abort, label %40170

40170:                                            ; preds = %.13178
  %40171 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %40172 = xor i32 %40171, 309
  %40173 = urem i32 %40172, 4096
  %40174 = getelementptr i8, i8 addrspace(1)* %4, i32 %40173
  %40175 = load i8, i8 addrspace(1)* %40174, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %40174, align 1, !nosanitize !3
  store i32 154, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %40176 = sub i64 %40168, 1368
  store i64 %40176, i64* %remaing_gas, align 4
  %40177 = load i64, i64* %STACK_DEP_PTR, align 4
  %40178 = getelementptr i256, i256* %STACK, i64 %40177
  %40179 = load i256, i256* %40178, align 4
  %40180 = load i64, i64* %STACK_DEP_PTR, align 4
  %40181 = sub i64 %40180, 1
  store i64 %40181, i64* %STACK_DEP_PTR, align 4
  %40182 = load i64, i64* %STACK_DEP_PTR, align 4
  %40183 = getelementptr i256, i256* %STACK, i64 %40182
  %40184 = load i256, i256* %40183, align 4
  %40185 = load i64, i64* %STACK_DEP_PTR, align 4
  %40186 = sub i64 %40185, 1
  store i64 %40186, i64* %STACK_DEP_PTR, align 4
  %40187 = load i64, i64* %STACK_DEP_PTR, align 4
  %40188 = getelementptr i256, i256* %STACK, i64 %40187
  %40189 = load i256, i256* %40188, align 4
  %40190 = load i64, i64* %STACK_DEP_PTR, align 4
  %40191 = sub i64 %40190, 1
  store i64 %40191, i64* %STACK_DEP_PTR, align 4
  %40192 = load i64, i64* %STACK_DEP_PTR, align 4
  %40193 = getelementptr i256, i256* %STACK, i64 %40192
  %40194 = load i256, i256* %40193, align 4
  %40195 = load i64, i64* %STACK_DEP_PTR, align 4
  %40196 = sub i64 %40195, 1
  store i64 %40196, i64* %STACK_DEP_PTR, align 4
  %40197 = load i64, i64* %STACK_DEP_PTR, align 4
  %40198 = getelementptr i256, i256* %STACK, i64 %40197
  %40199 = load i256, i256* %40198, align 4
  %40200 = load i64, i64* %STACK_DEP_PTR, align 4
  %40201 = sub i64 %40200, 1
  store i64 %40201, i64* %STACK_DEP_PTR, align 4
  %40202 = load i64, i64* %STACK_DEP_PTR, align 4
  %40203 = getelementptr i256, i256* %STACK, i64 %40202
  %40204 = load i256, i256* %40203, align 4
  %40205 = load i64, i64* %STACK_DEP_PTR, align 4
  %40206 = sub i64 %40205, 1
  store i64 %40206, i64* %STACK_DEP_PTR, align 4
  %40207 = load i64, i64* %STACK_DEP_PTR, align 4
  %40208 = getelementptr i256, i256* %STACK, i64 %40207
  %40209 = load i256, i256* %40208, align 4
  %40210 = load i64, i64* %STACK_DEP_PTR, align 4
  %40211 = sub i64 %40210, 1
  store i64 %40211, i64* %STACK_DEP_PTR, align 4
  %40212 = alloca i256, align 8
  store i256 %40179, i256* %40212, align 4
  %40213 = alloca i256, align 8
  store i256 %40184, i256* %40213, align 4
  %40214 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %40212, i256* %40213, i256* %40214), !pc !593, !intsan !6
  %40215 = load i256, i256* %40214, align 4
  %40216 = sub i256 %40199, %40215, !pc !594, !intsan !8
  %40217 = trunc i256 0 to i64
  %40218 = alloca i256, align 8
  store i256 %40204, i256* %40218, align 4
  %40219 = bitcast i256* %40218 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %40217, i8* %40219, i64 32)
  %40220 = add i256 32, 0, !pc !595, !intsan !10
  %40221 = trunc i256 %40220 to i64
  %40222 = alloca i256, align 8
  store i256 4, i256* %40222, align 4
  %40223 = bitcast i256* %40222 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %40221, i8* %40223, i64 32)
  %40224 = add i256 32, %40220, !pc !596, !intsan !10
  %40225 = trunc i256 0 to i32
  %40226 = trunc i256 %40224 to i32
  %40227 = getelementptr inbounds i8, i8* %MEMORY, i32 %40225
  %40228 = alloca i256, align 8
  %40229 = bitcast i256* %40228 to i8*
  call void @__device_sha3(i8* %40227, i32 %40226, i8* %40229)
  %40230 = load i256, i256* %40228, align 4
  %40231 = add i256 %40230, 0, !pc !597, !intsan !10
  %40232 = alloca i256, align 8
  store i256 %40231, i256* %40232, align 4
  %40233 = alloca i256, align 8
  call void @__device_sload(i256* %40232, i256* %40233)
  %40234 = call i32 @__hashword(i256* %40232)
  %40235 = load i32, i32* %5, align 4
  %40236 = icmp eq i32 %40234, %40235
  %40237 = or i1 false, %40236
  %40238 = load i32, i32* %6, align 4
  %40239 = icmp eq i32 %40234, %40238
  %40240 = or i1 %40237, %40239
  %40241 = load i32, i32* %7, align 4
  %40242 = icmp eq i32 %40234, %40241
  %40243 = or i1 %40240, %40242
  %40244 = load i32, i32* %8, align 4
  %40245 = icmp eq i32 %40234, %40244
  %40246 = or i1 %40243, %40245
  %40247 = load i32, i32* %9, align 4
  %40248 = icmp eq i32 %40234, %40247
  %40249 = or i1 %40246, %40248
  %40250 = load i32, i32* %10, align 4
  %40251 = icmp eq i32 %40234, %40250
  %40252 = or i1 %40249, %40251
  %40253 = load i32, i32* %11, align 4
  %40254 = icmp eq i32 %40234, %40253
  %40255 = or i1 %40252, %40254
  %40256 = load i32, i32* %12, align 4
  %40257 = icmp eq i32 %40234, %40256
  %40258 = or i1 %40255, %40257
  %40259 = load i32, i32* %13, align 4
  %40260 = icmp eq i32 %40234, %40259
  %40261 = or i1 %40258, %40260
  %40262 = load i32, i32* %14, align 4
  %40263 = icmp eq i32 %40234, %40262
  %40264 = or i1 %40261, %40263
  %40265 = load i32, i32* %15, align 4
  %40266 = icmp eq i32 %40234, %40265
  %40267 = or i1 %40264, %40266
  %40268 = load i32, i32* %16, align 4
  %40269 = icmp eq i32 %40234, %40268
  %40270 = or i1 %40267, %40269
  %40271 = load i32, i32* %17, align 4
  %40272 = icmp eq i32 %40234, %40271
  %40273 = or i1 %40270, %40272
  %40274 = load i32, i32* %18, align 4
  %40275 = icmp eq i32 %40234, %40274
  %40276 = or i1 %40273, %40275
  %40277 = load i32, i32* %19, align 4
  %40278 = icmp eq i32 %40234, %40277
  %40279 = or i1 %40276, %40278
  %40280 = load i32, i32* %20, align 4
  %40281 = icmp eq i32 %40234, %40280
  %40282 = or i1 %40279, %40281
  %40283 = load i32, i32* %21, align 4
  %40284 = icmp eq i32 %40234, %40283
  %40285 = or i1 %40282, %40284
  %40286 = load i32, i32* %22, align 4
  %40287 = icmp eq i32 %40234, %40286
  %40288 = or i1 %40285, %40287
  %40289 = load i32, i32* %23, align 4
  %40290 = icmp eq i32 %40234, %40289
  %40291 = or i1 %40288, %40290
  %40292 = load i32, i32* %24, align 4
  %40293 = icmp eq i32 %40234, %40292
  %40294 = or i1 %40291, %40293
  %40295 = load i32, i32* %25, align 4
  %40296 = icmp eq i32 %40234, %40295
  %40297 = or i1 %40294, %40296
  %40298 = load i32, i32* %26, align 4
  %40299 = icmp eq i32 %40234, %40298
  %40300 = or i1 %40297, %40299
  %40301 = load i32, i32* %27, align 4
  %40302 = icmp eq i32 %40234, %40301
  %40303 = or i1 %40300, %40302
  %40304 = load i32, i32* %28, align 4
  %40305 = icmp eq i32 %40234, %40304
  %40306 = or i1 %40303, %40305
  %40307 = load i32, i32* %29, align 4
  %40308 = icmp eq i32 %40234, %40307
  %40309 = or i1 %40306, %40308
  %40310 = load i32, i32* %30, align 4
  %40311 = icmp eq i32 %40234, %40310
  %40312 = or i1 %40309, %40311
  %40313 = load i32, i32* %31, align 4
  %40314 = icmp eq i32 %40234, %40313
  %40315 = or i1 %40312, %40314
  %40316 = load i32, i32* %32, align 4
  %40317 = icmp eq i32 %40234, %40316
  %40318 = or i1 %40315, %40317
  %40319 = load i32, i32* %33, align 4
  %40320 = icmp eq i32 %40234, %40319
  %40321 = or i1 %40318, %40320
  %40322 = load i32, i32* %34, align 4
  %40323 = icmp eq i32 %40234, %40322
  %40324 = or i1 %40321, %40323
  %40325 = load i32, i32* %35, align 4
  %40326 = icmp eq i32 %40234, %40325
  %40327 = or i1 %40324, %40326
  %40328 = load i32, i32* %36, align 4
  %40329 = icmp eq i32 %40234, %40328
  %40330 = or i1 %40327, %40329
  %40331 = load i32, i32* %37, align 4
  %40332 = icmp eq i32 %40234, %40331
  %40333 = or i1 %40330, %40332
  %40334 = load i32, i32* %38, align 4
  %40335 = icmp eq i32 %40234, %40334
  %40336 = or i1 %40333, %40335
  %40337 = load i32, i32* %39, align 4
  %40338 = icmp eq i32 %40234, %40337
  %40339 = or i1 %40336, %40338
  %40340 = load i32, i32* %40, align 4
  %40341 = icmp eq i32 %40234, %40340
  %40342 = or i1 %40339, %40341
  %40343 = load i32, i32* %41, align 4
  %40344 = icmp eq i32 %40234, %40343
  %40345 = or i1 %40342, %40344
  %40346 = load i32, i32* %42, align 4
  %40347 = icmp eq i32 %40234, %40346
  %40348 = or i1 %40345, %40347
  %40349 = load i32, i32* %43, align 4
  %40350 = icmp eq i32 %40234, %40349
  %40351 = or i1 %40348, %40350
  %40352 = load i32, i32* %44, align 4
  %40353 = icmp eq i32 %40234, %40352
  %40354 = or i1 %40351, %40353
  %40355 = load i32, i32* %45, align 4
  %40356 = icmp eq i32 %40234, %40355
  %40357 = or i1 %40354, %40356
  %40358 = load i32, i32* %46, align 4
  %40359 = icmp eq i32 %40234, %40358
  %40360 = or i1 %40357, %40359
  %40361 = load i32, i32* %47, align 4
  %40362 = icmp eq i32 %40234, %40361
  %40363 = or i1 %40360, %40362
  %40364 = load i32, i32* %48, align 4
  %40365 = icmp eq i32 %40234, %40364
  %40366 = or i1 %40363, %40365
  %40367 = load i32, i32* %49, align 4
  %40368 = icmp eq i32 %40234, %40367
  %40369 = or i1 %40366, %40368
  %40370 = load i32, i32* %50, align 4
  %40371 = icmp eq i32 %40234, %40370
  %40372 = or i1 %40369, %40371
  %40373 = load i32, i32* %51, align 4
  %40374 = icmp eq i32 %40234, %40373
  %40375 = or i1 %40372, %40374
  %40376 = load i32, i32* %52, align 4
  %40377 = icmp eq i32 %40234, %40376
  %40378 = or i1 %40375, %40377
  %40379 = load i32, i32* %53, align 4
  %40380 = icmp eq i32 %40234, %40379
  %40381 = or i1 %40378, %40380
  %40382 = load i32, i32* %54, align 4
  %40383 = icmp eq i32 %40234, %40382
  %40384 = or i1 %40381, %40383
  %40385 = load i32, i32* %55, align 4
  %40386 = icmp eq i32 %40234, %40385
  %40387 = or i1 %40384, %40386
  %40388 = load i32, i32* %56, align 4
  %40389 = icmp eq i32 %40234, %40388
  %40390 = or i1 %40387, %40389
  %40391 = load i32, i32* %57, align 4
  %40392 = icmp eq i32 %40234, %40391
  %40393 = or i1 %40390, %40392
  %40394 = load i32, i32* %58, align 4
  %40395 = icmp eq i32 %40234, %40394
  %40396 = or i1 %40393, %40395
  %40397 = load i32, i32* %59, align 4
  %40398 = icmp eq i32 %40234, %40397
  %40399 = or i1 %40396, %40398
  %40400 = load i32, i32* %60, align 4
  %40401 = icmp eq i32 %40234, %40400
  %40402 = or i1 %40399, %40401
  %40403 = load i32, i32* %61, align 4
  %40404 = icmp eq i32 %40234, %40403
  %40405 = or i1 %40402, %40404
  %40406 = load i32, i32* %62, align 4
  %40407 = icmp eq i32 %40234, %40406
  %40408 = or i1 %40405, %40407
  %40409 = getelementptr i8, i8 addrspace(1)* %4, i32 144
  %40410 = zext i1 %40408 to i8
  store i8 %40410, i8 addrspace(1)* %40409, align 1, !nosanitize !3
  %40411 = load i256, i256* %40233, align 4
  %40412 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !598, !intsan !45
  %40413 = xor i256 %40412, -1
  %40414 = and i256 %40413, %40411
  %40415 = alloca i256, align 8
  store i256 %40231, i256* %40415, align 4
  %40416 = alloca i256, align 8
  store i256 %40414, i256* %40416, align 4
  call void @__device_sstore(i256* %40415, i256* %40416)
  %40417 = call i32 @__hashword(i256* %40415)
  store i32 %40417, i32* %19, align 4, !nosanitize !3
  %40418 = add i256 %40230, 1, !pc !599, !intsan !10
  %40419 = alloca i256, align 8
  store i256 %40418, i256* %40419, align 4
  %40420 = alloca i256, align 8
  store i256 0, i256* %40420, align 4
  call void @__device_sstore(i256* %40419, i256* %40420)
  %40421 = call i32 @__hashword(i256* %40419)
  store i32 %40421, i32* %20, align 4, !nosanitize !3
  %40422 = add i256 %40230, 2, !pc !600, !intsan !10
  %40423 = alloca i256, align 8
  store i256 %40422, i256* %40423, align 4
  %40424 = alloca i256, align 8
  call void @__device_sload(i256* %40423, i256* %40424)
  %40425 = call i32 @__hashword(i256* %40423)
  %40426 = load i32, i32* %5, align 4
  %40427 = icmp eq i32 %40425, %40426
  %40428 = or i1 false, %40427
  %40429 = load i32, i32* %6, align 4
  %40430 = icmp eq i32 %40425, %40429
  %40431 = or i1 %40428, %40430
  %40432 = load i32, i32* %7, align 4
  %40433 = icmp eq i32 %40425, %40432
  %40434 = or i1 %40431, %40433
  %40435 = load i32, i32* %8, align 4
  %40436 = icmp eq i32 %40425, %40435
  %40437 = or i1 %40434, %40436
  %40438 = load i32, i32* %9, align 4
  %40439 = icmp eq i32 %40425, %40438
  %40440 = or i1 %40437, %40439
  %40441 = load i32, i32* %10, align 4
  %40442 = icmp eq i32 %40425, %40441
  %40443 = or i1 %40440, %40442
  %40444 = load i32, i32* %11, align 4
  %40445 = icmp eq i32 %40425, %40444
  %40446 = or i1 %40443, %40445
  %40447 = load i32, i32* %12, align 4
  %40448 = icmp eq i32 %40425, %40447
  %40449 = or i1 %40446, %40448
  %40450 = load i32, i32* %13, align 4
  %40451 = icmp eq i32 %40425, %40450
  %40452 = or i1 %40449, %40451
  %40453 = load i32, i32* %14, align 4
  %40454 = icmp eq i32 %40425, %40453
  %40455 = or i1 %40452, %40454
  %40456 = load i32, i32* %15, align 4
  %40457 = icmp eq i32 %40425, %40456
  %40458 = or i1 %40455, %40457
  %40459 = load i32, i32* %16, align 4
  %40460 = icmp eq i32 %40425, %40459
  %40461 = or i1 %40458, %40460
  %40462 = load i32, i32* %17, align 4
  %40463 = icmp eq i32 %40425, %40462
  %40464 = or i1 %40461, %40463
  %40465 = load i32, i32* %18, align 4
  %40466 = icmp eq i32 %40425, %40465
  %40467 = or i1 %40464, %40466
  %40468 = load i32, i32* %19, align 4
  %40469 = icmp eq i32 %40425, %40468
  %40470 = or i1 %40467, %40469
  %40471 = load i32, i32* %20, align 4
  %40472 = icmp eq i32 %40425, %40471
  %40473 = or i1 %40470, %40472
  %40474 = load i32, i32* %21, align 4
  %40475 = icmp eq i32 %40425, %40474
  %40476 = or i1 %40473, %40475
  %40477 = load i32, i32* %22, align 4
  %40478 = icmp eq i32 %40425, %40477
  %40479 = or i1 %40476, %40478
  %40480 = load i32, i32* %23, align 4
  %40481 = icmp eq i32 %40425, %40480
  %40482 = or i1 %40479, %40481
  %40483 = load i32, i32* %24, align 4
  %40484 = icmp eq i32 %40425, %40483
  %40485 = or i1 %40482, %40484
  %40486 = load i32, i32* %25, align 4
  %40487 = icmp eq i32 %40425, %40486
  %40488 = or i1 %40485, %40487
  %40489 = load i32, i32* %26, align 4
  %40490 = icmp eq i32 %40425, %40489
  %40491 = or i1 %40488, %40490
  %40492 = load i32, i32* %27, align 4
  %40493 = icmp eq i32 %40425, %40492
  %40494 = or i1 %40491, %40493
  %40495 = load i32, i32* %28, align 4
  %40496 = icmp eq i32 %40425, %40495
  %40497 = or i1 %40494, %40496
  %40498 = load i32, i32* %29, align 4
  %40499 = icmp eq i32 %40425, %40498
  %40500 = or i1 %40497, %40499
  %40501 = load i32, i32* %30, align 4
  %40502 = icmp eq i32 %40425, %40501
  %40503 = or i1 %40500, %40502
  %40504 = load i32, i32* %31, align 4
  %40505 = icmp eq i32 %40425, %40504
  %40506 = or i1 %40503, %40505
  %40507 = load i32, i32* %32, align 4
  %40508 = icmp eq i32 %40425, %40507
  %40509 = or i1 %40506, %40508
  %40510 = load i32, i32* %33, align 4
  %40511 = icmp eq i32 %40425, %40510
  %40512 = or i1 %40509, %40511
  %40513 = load i32, i32* %34, align 4
  %40514 = icmp eq i32 %40425, %40513
  %40515 = or i1 %40512, %40514
  %40516 = load i32, i32* %35, align 4
  %40517 = icmp eq i32 %40425, %40516
  %40518 = or i1 %40515, %40517
  %40519 = load i32, i32* %36, align 4
  %40520 = icmp eq i32 %40425, %40519
  %40521 = or i1 %40518, %40520
  %40522 = load i32, i32* %37, align 4
  %40523 = icmp eq i32 %40425, %40522
  %40524 = or i1 %40521, %40523
  %40525 = load i32, i32* %38, align 4
  %40526 = icmp eq i32 %40425, %40525
  %40527 = or i1 %40524, %40526
  %40528 = load i32, i32* %39, align 4
  %40529 = icmp eq i32 %40425, %40528
  %40530 = or i1 %40527, %40529
  %40531 = load i32, i32* %40, align 4
  %40532 = icmp eq i32 %40425, %40531
  %40533 = or i1 %40530, %40532
  %40534 = load i32, i32* %41, align 4
  %40535 = icmp eq i32 %40425, %40534
  %40536 = or i1 %40533, %40535
  %40537 = load i32, i32* %42, align 4
  %40538 = icmp eq i32 %40425, %40537
  %40539 = or i1 %40536, %40538
  %40540 = load i32, i32* %43, align 4
  %40541 = icmp eq i32 %40425, %40540
  %40542 = or i1 %40539, %40541
  %40543 = load i32, i32* %44, align 4
  %40544 = icmp eq i32 %40425, %40543
  %40545 = or i1 %40542, %40544
  %40546 = load i32, i32* %45, align 4
  %40547 = icmp eq i32 %40425, %40546
  %40548 = or i1 %40545, %40547
  %40549 = load i32, i32* %46, align 4
  %40550 = icmp eq i32 %40425, %40549
  %40551 = or i1 %40548, %40550
  %40552 = load i32, i32* %47, align 4
  %40553 = icmp eq i32 %40425, %40552
  %40554 = or i1 %40551, %40553
  %40555 = load i32, i32* %48, align 4
  %40556 = icmp eq i32 %40425, %40555
  %40557 = or i1 %40554, %40556
  %40558 = load i32, i32* %49, align 4
  %40559 = icmp eq i32 %40425, %40558
  %40560 = or i1 %40557, %40559
  %40561 = load i32, i32* %50, align 4
  %40562 = icmp eq i32 %40425, %40561
  %40563 = or i1 %40560, %40562
  %40564 = load i32, i32* %51, align 4
  %40565 = icmp eq i32 %40425, %40564
  %40566 = or i1 %40563, %40565
  %40567 = load i32, i32* %52, align 4
  %40568 = icmp eq i32 %40425, %40567
  %40569 = or i1 %40566, %40568
  %40570 = load i32, i32* %53, align 4
  %40571 = icmp eq i32 %40425, %40570
  %40572 = or i1 %40569, %40571
  %40573 = load i32, i32* %54, align 4
  %40574 = icmp eq i32 %40425, %40573
  %40575 = or i1 %40572, %40574
  %40576 = load i32, i32* %55, align 4
  %40577 = icmp eq i32 %40425, %40576
  %40578 = or i1 %40575, %40577
  %40579 = load i32, i32* %56, align 4
  %40580 = icmp eq i32 %40425, %40579
  %40581 = or i1 %40578, %40580
  %40582 = load i32, i32* %57, align 4
  %40583 = icmp eq i32 %40425, %40582
  %40584 = or i1 %40581, %40583
  %40585 = load i32, i32* %58, align 4
  %40586 = icmp eq i32 %40425, %40585
  %40587 = or i1 %40584, %40586
  %40588 = load i32, i32* %59, align 4
  %40589 = icmp eq i32 %40425, %40588
  %40590 = or i1 %40587, %40589
  %40591 = load i32, i32* %60, align 4
  %40592 = icmp eq i32 %40425, %40591
  %40593 = or i1 %40590, %40592
  %40594 = load i32, i32* %61, align 4
  %40595 = icmp eq i32 %40425, %40594
  %40596 = or i1 %40593, %40595
  %40597 = load i32, i32* %62, align 4
  %40598 = icmp eq i32 %40425, %40597
  %40599 = or i1 %40596, %40598
  %40600 = getelementptr i8, i8 addrspace(1)* %4, i32 145
  %40601 = zext i1 %40599 to i8
  store i8 %40601, i8 addrspace(1)* %40600, align 1, !nosanitize !3
  %40602 = load i256, i256* %40424, align 4
  %40603 = mul i256 255, 1, !pc !601, !intsan !45
  %40604 = xor i256 %40603, -1
  %40605 = and i256 %40604, %40602
  %40606 = alloca i256, align 8
  store i256 %40422, i256* %40606, align 4
  %40607 = alloca i256, align 8
  store i256 %40605, i256* %40607, align 4
  call void @__device_sstore(i256* %40606, i256* %40607)
  %40608 = call i32 @__hashword(i256* %40606)
  store i32 %40608, i32* %21, align 4, !nosanitize !3
  %40609 = and i256 1461501637330902918203684832716283019655932542975, %40209
  %40610 = and i256 1461501637330902918203684832716283019655932542975, %40609
  %40611 = trunc i256 0 to i64
  %40612 = alloca i256, align 8
  store i256 %40610, i256* %40612, align 4
  %40613 = bitcast i256* %40612 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %40611, i8* %40613, i64 32)
  %40614 = add i256 32, 0, !pc !602, !intsan !10
  %40615 = trunc i256 %40614 to i64
  %40616 = alloca i256, align 8
  store i256 3, i256* %40616, align 4
  %40617 = bitcast i256* %40616 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %40615, i8* %40617, i64 32)
  %40618 = add i256 32, %40614, !pc !603, !intsan !10
  %40619 = trunc i256 0 to i32
  %40620 = trunc i256 %40618 to i32
  %40621 = getelementptr inbounds i8, i8* %MEMORY, i32 %40619
  %40622 = alloca i256, align 8
  %40623 = bitcast i256* %40622 to i8*
  call void @__device_sha3(i8* %40621, i32 %40620, i8* %40623)
  %40624 = load i256, i256* %40622, align 4
  %40625 = alloca i256, align 8
  store i256 %40624, i256* %40625, align 4
  %40626 = alloca i256, align 8
  store i256 0, i256* %40626, align 4
  call void @__device_sstore(i256* %40625, i256* %40626)
  %40627 = call i32 @__hashword(i256* %40625)
  store i32 %40627, i32* %22, align 4, !nosanitize !3
  %40628 = alloca i256, align 8
  store i256 5, i256* %40628, align 4
  %40629 = alloca i256, align 8
  call void @__device_sload(i256* %40628, i256* %40629)
  %40630 = call i32 @__hashword(i256* %40628)
  %40631 = load i32, i32* %5, align 4
  %40632 = icmp eq i32 %40630, %40631
  %40633 = or i1 false, %40632
  %40634 = load i32, i32* %6, align 4
  %40635 = icmp eq i32 %40630, %40634
  %40636 = or i1 %40633, %40635
  %40637 = load i32, i32* %7, align 4
  %40638 = icmp eq i32 %40630, %40637
  %40639 = or i1 %40636, %40638
  %40640 = load i32, i32* %8, align 4
  %40641 = icmp eq i32 %40630, %40640
  %40642 = or i1 %40639, %40641
  %40643 = load i32, i32* %9, align 4
  %40644 = icmp eq i32 %40630, %40643
  %40645 = or i1 %40642, %40644
  %40646 = load i32, i32* %10, align 4
  %40647 = icmp eq i32 %40630, %40646
  %40648 = or i1 %40645, %40647
  %40649 = load i32, i32* %11, align 4
  %40650 = icmp eq i32 %40630, %40649
  %40651 = or i1 %40648, %40650
  %40652 = load i32, i32* %12, align 4
  %40653 = icmp eq i32 %40630, %40652
  %40654 = or i1 %40651, %40653
  %40655 = load i32, i32* %13, align 4
  %40656 = icmp eq i32 %40630, %40655
  %40657 = or i1 %40654, %40656
  %40658 = load i32, i32* %14, align 4
  %40659 = icmp eq i32 %40630, %40658
  %40660 = or i1 %40657, %40659
  %40661 = load i32, i32* %15, align 4
  %40662 = icmp eq i32 %40630, %40661
  %40663 = or i1 %40660, %40662
  %40664 = load i32, i32* %16, align 4
  %40665 = icmp eq i32 %40630, %40664
  %40666 = or i1 %40663, %40665
  %40667 = load i32, i32* %17, align 4
  %40668 = icmp eq i32 %40630, %40667
  %40669 = or i1 %40666, %40668
  %40670 = load i32, i32* %18, align 4
  %40671 = icmp eq i32 %40630, %40670
  %40672 = or i1 %40669, %40671
  %40673 = load i32, i32* %19, align 4
  %40674 = icmp eq i32 %40630, %40673
  %40675 = or i1 %40672, %40674
  %40676 = load i32, i32* %20, align 4
  %40677 = icmp eq i32 %40630, %40676
  %40678 = or i1 %40675, %40677
  %40679 = load i32, i32* %21, align 4
  %40680 = icmp eq i32 %40630, %40679
  %40681 = or i1 %40678, %40680
  %40682 = load i32, i32* %22, align 4
  %40683 = icmp eq i32 %40630, %40682
  %40684 = or i1 %40681, %40683
  %40685 = load i32, i32* %23, align 4
  %40686 = icmp eq i32 %40630, %40685
  %40687 = or i1 %40684, %40686
  %40688 = load i32, i32* %24, align 4
  %40689 = icmp eq i32 %40630, %40688
  %40690 = or i1 %40687, %40689
  %40691 = load i32, i32* %25, align 4
  %40692 = icmp eq i32 %40630, %40691
  %40693 = or i1 %40690, %40692
  %40694 = load i32, i32* %26, align 4
  %40695 = icmp eq i32 %40630, %40694
  %40696 = or i1 %40693, %40695
  %40697 = load i32, i32* %27, align 4
  %40698 = icmp eq i32 %40630, %40697
  %40699 = or i1 %40696, %40698
  %40700 = load i32, i32* %28, align 4
  %40701 = icmp eq i32 %40630, %40700
  %40702 = or i1 %40699, %40701
  %40703 = load i32, i32* %29, align 4
  %40704 = icmp eq i32 %40630, %40703
  %40705 = or i1 %40702, %40704
  %40706 = load i32, i32* %30, align 4
  %40707 = icmp eq i32 %40630, %40706
  %40708 = or i1 %40705, %40707
  %40709 = load i32, i32* %31, align 4
  %40710 = icmp eq i32 %40630, %40709
  %40711 = or i1 %40708, %40710
  %40712 = load i32, i32* %32, align 4
  %40713 = icmp eq i32 %40630, %40712
  %40714 = or i1 %40711, %40713
  %40715 = load i32, i32* %33, align 4
  %40716 = icmp eq i32 %40630, %40715
  %40717 = or i1 %40714, %40716
  %40718 = load i32, i32* %34, align 4
  %40719 = icmp eq i32 %40630, %40718
  %40720 = or i1 %40717, %40719
  %40721 = load i32, i32* %35, align 4
  %40722 = icmp eq i32 %40630, %40721
  %40723 = or i1 %40720, %40722
  %40724 = load i32, i32* %36, align 4
  %40725 = icmp eq i32 %40630, %40724
  %40726 = or i1 %40723, %40725
  %40727 = load i32, i32* %37, align 4
  %40728 = icmp eq i32 %40630, %40727
  %40729 = or i1 %40726, %40728
  %40730 = load i32, i32* %38, align 4
  %40731 = icmp eq i32 %40630, %40730
  %40732 = or i1 %40729, %40731
  %40733 = load i32, i32* %39, align 4
  %40734 = icmp eq i32 %40630, %40733
  %40735 = or i1 %40732, %40734
  %40736 = load i32, i32* %40, align 4
  %40737 = icmp eq i32 %40630, %40736
  %40738 = or i1 %40735, %40737
  %40739 = load i32, i32* %41, align 4
  %40740 = icmp eq i32 %40630, %40739
  %40741 = or i1 %40738, %40740
  %40742 = load i32, i32* %42, align 4
  %40743 = icmp eq i32 %40630, %40742
  %40744 = or i1 %40741, %40743
  %40745 = load i32, i32* %43, align 4
  %40746 = icmp eq i32 %40630, %40745
  %40747 = or i1 %40744, %40746
  %40748 = load i32, i32* %44, align 4
  %40749 = icmp eq i32 %40630, %40748
  %40750 = or i1 %40747, %40749
  %40751 = load i32, i32* %45, align 4
  %40752 = icmp eq i32 %40630, %40751
  %40753 = or i1 %40750, %40752
  %40754 = load i32, i32* %46, align 4
  %40755 = icmp eq i32 %40630, %40754
  %40756 = or i1 %40753, %40755
  %40757 = load i32, i32* %47, align 4
  %40758 = icmp eq i32 %40630, %40757
  %40759 = or i1 %40756, %40758
  %40760 = load i32, i32* %48, align 4
  %40761 = icmp eq i32 %40630, %40760
  %40762 = or i1 %40759, %40761
  %40763 = load i32, i32* %49, align 4
  %40764 = icmp eq i32 %40630, %40763
  %40765 = or i1 %40762, %40764
  %40766 = load i32, i32* %50, align 4
  %40767 = icmp eq i32 %40630, %40766
  %40768 = or i1 %40765, %40767
  %40769 = load i32, i32* %51, align 4
  %40770 = icmp eq i32 %40630, %40769
  %40771 = or i1 %40768, %40770
  %40772 = load i32, i32* %52, align 4
  %40773 = icmp eq i32 %40630, %40772
  %40774 = or i1 %40771, %40773
  %40775 = load i32, i32* %53, align 4
  %40776 = icmp eq i32 %40630, %40775
  %40777 = or i1 %40774, %40776
  %40778 = load i32, i32* %54, align 4
  %40779 = icmp eq i32 %40630, %40778
  %40780 = or i1 %40777, %40779
  %40781 = load i32, i32* %55, align 4
  %40782 = icmp eq i32 %40630, %40781
  %40783 = or i1 %40780, %40782
  %40784 = load i32, i32* %56, align 4
  %40785 = icmp eq i32 %40630, %40784
  %40786 = or i1 %40783, %40785
  %40787 = load i32, i32* %57, align 4
  %40788 = icmp eq i32 %40630, %40787
  %40789 = or i1 %40786, %40788
  %40790 = load i32, i32* %58, align 4
  %40791 = icmp eq i32 %40630, %40790
  %40792 = or i1 %40789, %40791
  %40793 = load i32, i32* %59, align 4
  %40794 = icmp eq i32 %40630, %40793
  %40795 = or i1 %40792, %40794
  %40796 = load i32, i32* %60, align 4
  %40797 = icmp eq i32 %40630, %40796
  %40798 = or i1 %40795, %40797
  %40799 = load i32, i32* %61, align 4
  %40800 = icmp eq i32 %40630, %40799
  %40801 = or i1 %40798, %40800
  %40802 = load i32, i32* %62, align 4
  %40803 = icmp eq i32 %40630, %40802
  %40804 = or i1 %40801, %40803
  %40805 = getelementptr i8, i8 addrspace(1)* %4, i32 146
  %40806 = zext i1 %40804 to i8
  store i8 %40806, i8 addrspace(1)* %40805, align 1, !nosanitize !3
  %40807 = load i256, i256* %40629, align 4
  %40808 = icmp eq i256 %40204, %40807
  %40809 = icmp eq i1 %40808, false
  %40810 = icmp eq i1 %40809, false
  %40811 = trunc i256 13753 to i64
  %jump.check82 = icmp ne i1 %40810, false
  %40812 = load i64, i64* %STACK_DEP_PTR, align 4
  %40813 = add i64 %40812, 1
  store i64 %40813, i64* %STACK_DEP_PTR, align 4
  %40814 = load i64, i64* %STACK_DEP_PTR, align 4
  %40815 = getelementptr i256, i256* %STACK, i64 %40814
  store i256 %40209, i256* %40815, align 4
  %40816 = load i64, i64* %STACK_DEP_PTR, align 4
  %40817 = add i64 %40816, 1
  store i64 %40817, i64* %STACK_DEP_PTR, align 4
  %40818 = load i64, i64* %STACK_DEP_PTR, align 4
  %40819 = getelementptr i256, i256* %STACK, i64 %40818
  store i256 %40204, i256* %40819, align 4
  %40820 = load i64, i64* %STACK_DEP_PTR, align 4
  %40821 = add i64 %40820, 1
  store i64 %40821, i64* %STACK_DEP_PTR, align 4
  %40822 = load i64, i64* %STACK_DEP_PTR, align 4
  %40823 = getelementptr i256, i256* %STACK, i64 %40822
  store i256 %40216, i256* %40823, align 4
  %40824 = load i64, i64* %STACK_DEP_PTR, align 4
  %40825 = add i64 %40824, 1
  store i64 %40825, i64* %STACK_DEP_PTR, align 4
  %40826 = load i64, i64* %STACK_DEP_PTR, align 4
  %40827 = getelementptr i256, i256* %STACK, i64 %40826
  store i256 %40215, i256* %40827, align 4
  %40828 = load i64, i64* %STACK_DEP_PTR, align 4
  %40829 = add i64 %40828, 1
  store i64 %40829, i64* %STACK_DEP_PTR, align 4
  %40830 = load i64, i64* %STACK_DEP_PTR, align 4
  %40831 = getelementptr i256, i256* %STACK, i64 %40830
  store i256 %40189, i256* %40831, align 4
  br i1 %jump.check82, label %.13753, label %.13354, !EVMBB !4

.13354:                                           ; preds = %40170
  %40832 = load i64, i64* %STACK_DEP_PTR, align 4
  %40833 = sub i64 %40832, 4
  store i64 %40833, i64* %STACK_DEP_PTR, align 4
  %40834 = alloca i256, align 8
  store i256 5, i256* %40834, align 4
  %40835 = alloca i256, align 8
  call void @__device_sload(i256* %40834, i256* %40835)
  %40836 = call i32 @__hashword(i256* %40834)
  %40837 = load i32, i32* %5, align 4
  %40838 = icmp eq i32 %40836, %40837
  %40839 = or i1 false, %40838
  %40840 = load i32, i32* %6, align 4
  %40841 = icmp eq i32 %40836, %40840
  %40842 = or i1 %40839, %40841
  %40843 = load i32, i32* %7, align 4
  %40844 = icmp eq i32 %40836, %40843
  %40845 = or i1 %40842, %40844
  %40846 = load i32, i32* %8, align 4
  %40847 = icmp eq i32 %40836, %40846
  %40848 = or i1 %40845, %40847
  %40849 = load i32, i32* %9, align 4
  %40850 = icmp eq i32 %40836, %40849
  %40851 = or i1 %40848, %40850
  %40852 = load i32, i32* %10, align 4
  %40853 = icmp eq i32 %40836, %40852
  %40854 = or i1 %40851, %40853
  %40855 = load i32, i32* %11, align 4
  %40856 = icmp eq i32 %40836, %40855
  %40857 = or i1 %40854, %40856
  %40858 = load i32, i32* %12, align 4
  %40859 = icmp eq i32 %40836, %40858
  %40860 = or i1 %40857, %40859
  %40861 = load i32, i32* %13, align 4
  %40862 = icmp eq i32 %40836, %40861
  %40863 = or i1 %40860, %40862
  %40864 = load i32, i32* %14, align 4
  %40865 = icmp eq i32 %40836, %40864
  %40866 = or i1 %40863, %40865
  %40867 = load i32, i32* %15, align 4
  %40868 = icmp eq i32 %40836, %40867
  %40869 = or i1 %40866, %40868
  %40870 = load i32, i32* %16, align 4
  %40871 = icmp eq i32 %40836, %40870
  %40872 = or i1 %40869, %40871
  %40873 = load i32, i32* %17, align 4
  %40874 = icmp eq i32 %40836, %40873
  %40875 = or i1 %40872, %40874
  %40876 = load i32, i32* %18, align 4
  %40877 = icmp eq i32 %40836, %40876
  %40878 = or i1 %40875, %40877
  %40879 = load i32, i32* %19, align 4
  %40880 = icmp eq i32 %40836, %40879
  %40881 = or i1 %40878, %40880
  %40882 = load i32, i32* %20, align 4
  %40883 = icmp eq i32 %40836, %40882
  %40884 = or i1 %40881, %40883
  %40885 = load i32, i32* %21, align 4
  %40886 = icmp eq i32 %40836, %40885
  %40887 = or i1 %40884, %40886
  %40888 = load i32, i32* %22, align 4
  %40889 = icmp eq i32 %40836, %40888
  %40890 = or i1 %40887, %40889
  %40891 = load i32, i32* %23, align 4
  %40892 = icmp eq i32 %40836, %40891
  %40893 = or i1 %40890, %40892
  %40894 = load i32, i32* %24, align 4
  %40895 = icmp eq i32 %40836, %40894
  %40896 = or i1 %40893, %40895
  %40897 = load i32, i32* %25, align 4
  %40898 = icmp eq i32 %40836, %40897
  %40899 = or i1 %40896, %40898
  %40900 = load i32, i32* %26, align 4
  %40901 = icmp eq i32 %40836, %40900
  %40902 = or i1 %40899, %40901
  %40903 = load i32, i32* %27, align 4
  %40904 = icmp eq i32 %40836, %40903
  %40905 = or i1 %40902, %40904
  %40906 = load i32, i32* %28, align 4
  %40907 = icmp eq i32 %40836, %40906
  %40908 = or i1 %40905, %40907
  %40909 = load i32, i32* %29, align 4
  %40910 = icmp eq i32 %40836, %40909
  %40911 = or i1 %40908, %40910
  %40912 = load i32, i32* %30, align 4
  %40913 = icmp eq i32 %40836, %40912
  %40914 = or i1 %40911, %40913
  %40915 = load i32, i32* %31, align 4
  %40916 = icmp eq i32 %40836, %40915
  %40917 = or i1 %40914, %40916
  %40918 = load i32, i32* %32, align 4
  %40919 = icmp eq i32 %40836, %40918
  %40920 = or i1 %40917, %40919
  %40921 = load i32, i32* %33, align 4
  %40922 = icmp eq i32 %40836, %40921
  %40923 = or i1 %40920, %40922
  %40924 = load i32, i32* %34, align 4
  %40925 = icmp eq i32 %40836, %40924
  %40926 = or i1 %40923, %40925
  %40927 = load i32, i32* %35, align 4
  %40928 = icmp eq i32 %40836, %40927
  %40929 = or i1 %40926, %40928
  %40930 = load i32, i32* %36, align 4
  %40931 = icmp eq i32 %40836, %40930
  %40932 = or i1 %40929, %40931
  %40933 = load i32, i32* %37, align 4
  %40934 = icmp eq i32 %40836, %40933
  %40935 = or i1 %40932, %40934
  %40936 = load i32, i32* %38, align 4
  %40937 = icmp eq i32 %40836, %40936
  %40938 = or i1 %40935, %40937
  %40939 = load i32, i32* %39, align 4
  %40940 = icmp eq i32 %40836, %40939
  %40941 = or i1 %40938, %40940
  %40942 = load i32, i32* %40, align 4
  %40943 = icmp eq i32 %40836, %40942
  %40944 = or i1 %40941, %40943
  %40945 = load i32, i32* %41, align 4
  %40946 = icmp eq i32 %40836, %40945
  %40947 = or i1 %40944, %40946
  %40948 = load i32, i32* %42, align 4
  %40949 = icmp eq i32 %40836, %40948
  %40950 = or i1 %40947, %40949
  %40951 = load i32, i32* %43, align 4
  %40952 = icmp eq i32 %40836, %40951
  %40953 = or i1 %40950, %40952
  %40954 = load i32, i32* %44, align 4
  %40955 = icmp eq i32 %40836, %40954
  %40956 = or i1 %40953, %40955
  %40957 = load i32, i32* %45, align 4
  %40958 = icmp eq i32 %40836, %40957
  %40959 = or i1 %40956, %40958
  %40960 = load i32, i32* %46, align 4
  %40961 = icmp eq i32 %40836, %40960
  %40962 = or i1 %40959, %40961
  %40963 = load i32, i32* %47, align 4
  %40964 = icmp eq i32 %40836, %40963
  %40965 = or i1 %40962, %40964
  %40966 = load i32, i32* %48, align 4
  %40967 = icmp eq i32 %40836, %40966
  %40968 = or i1 %40965, %40967
  %40969 = load i32, i32* %49, align 4
  %40970 = icmp eq i32 %40836, %40969
  %40971 = or i1 %40968, %40970
  %40972 = load i32, i32* %50, align 4
  %40973 = icmp eq i32 %40836, %40972
  %40974 = or i1 %40971, %40973
  %40975 = load i32, i32* %51, align 4
  %40976 = icmp eq i32 %40836, %40975
  %40977 = or i1 %40974, %40976
  %40978 = load i32, i32* %52, align 4
  %40979 = icmp eq i32 %40836, %40978
  %40980 = or i1 %40977, %40979
  %40981 = load i32, i32* %53, align 4
  %40982 = icmp eq i32 %40836, %40981
  %40983 = or i1 %40980, %40982
  %40984 = load i32, i32* %54, align 4
  %40985 = icmp eq i32 %40836, %40984
  %40986 = or i1 %40983, %40985
  %40987 = load i32, i32* %55, align 4
  %40988 = icmp eq i32 %40836, %40987
  %40989 = or i1 %40986, %40988
  %40990 = load i32, i32* %56, align 4
  %40991 = icmp eq i32 %40836, %40990
  %40992 = or i1 %40989, %40991
  %40993 = load i32, i32* %57, align 4
  %40994 = icmp eq i32 %40836, %40993
  %40995 = or i1 %40992, %40994
  %40996 = load i32, i32* %58, align 4
  %40997 = icmp eq i32 %40836, %40996
  %40998 = or i1 %40995, %40997
  %40999 = load i32, i32* %59, align 4
  %41000 = icmp eq i32 %40836, %40999
  %41001 = or i1 %40998, %41000
  %41002 = load i32, i32* %60, align 4
  %41003 = icmp eq i32 %40836, %41002
  %41004 = or i1 %41001, %41003
  %41005 = load i32, i32* %61, align 4
  %41006 = icmp eq i32 %40836, %41005
  %41007 = or i1 %41004, %41006
  %41008 = load i32, i32* %62, align 4
  %41009 = icmp eq i32 %40836, %41008
  %41010 = or i1 %41007, %41009
  %41011 = getelementptr i8, i8 addrspace(1)* %4, i32 147
  %41012 = zext i1 %41010 to i8
  store i8 %41012, i8 addrspace(1)* %41011, align 1, !nosanitize !3
  %41013 = load i256, i256* %40835, align 4
  %41014 = trunc i256 0 to i64
  %41015 = alloca i256, align 8
  store i256 %41013, i256* %41015, align 4
  %41016 = bitcast i256* %41015 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41014, i8* %41016, i64 32)
  %41017 = add i256 32, 0, !pc !604, !intsan !10
  %41018 = trunc i256 %41017 to i64
  %41019 = alloca i256, align 8
  store i256 4, i256* %41019, align 4
  %41020 = bitcast i256* %41019 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41018, i8* %41020, i64 32)
  %41021 = add i256 32, %41017, !pc !605, !intsan !10
  %41022 = trunc i256 0 to i32
  %41023 = trunc i256 %41021 to i32
  %41024 = getelementptr inbounds i8, i8* %MEMORY, i32 %41022
  %41025 = alloca i256, align 8
  %41026 = bitcast i256* %41025 to i8*
  call void @__device_sha3(i8* %41024, i32 %41023, i8* %41026)
  %41027 = load i256, i256* %41025, align 4
  %41028 = add i256 0, %41027, !pc !606, !intsan !10
  %41029 = alloca i256, align 8
  store i256 %41028, i256* %41029, align 4
  %41030 = alloca i256, align 8
  call void @__device_sload(i256* %41029, i256* %41030)
  %41031 = call i32 @__hashword(i256* %41029)
  %41032 = load i32, i32* %5, align 4
  %41033 = icmp eq i32 %41031, %41032
  %41034 = or i1 false, %41033
  %41035 = load i32, i32* %6, align 4
  %41036 = icmp eq i32 %41031, %41035
  %41037 = or i1 %41034, %41036
  %41038 = load i32, i32* %7, align 4
  %41039 = icmp eq i32 %41031, %41038
  %41040 = or i1 %41037, %41039
  %41041 = load i32, i32* %8, align 4
  %41042 = icmp eq i32 %41031, %41041
  %41043 = or i1 %41040, %41042
  %41044 = load i32, i32* %9, align 4
  %41045 = icmp eq i32 %41031, %41044
  %41046 = or i1 %41043, %41045
  %41047 = load i32, i32* %10, align 4
  %41048 = icmp eq i32 %41031, %41047
  %41049 = or i1 %41046, %41048
  %41050 = load i32, i32* %11, align 4
  %41051 = icmp eq i32 %41031, %41050
  %41052 = or i1 %41049, %41051
  %41053 = load i32, i32* %12, align 4
  %41054 = icmp eq i32 %41031, %41053
  %41055 = or i1 %41052, %41054
  %41056 = load i32, i32* %13, align 4
  %41057 = icmp eq i32 %41031, %41056
  %41058 = or i1 %41055, %41057
  %41059 = load i32, i32* %14, align 4
  %41060 = icmp eq i32 %41031, %41059
  %41061 = or i1 %41058, %41060
  %41062 = load i32, i32* %15, align 4
  %41063 = icmp eq i32 %41031, %41062
  %41064 = or i1 %41061, %41063
  %41065 = load i32, i32* %16, align 4
  %41066 = icmp eq i32 %41031, %41065
  %41067 = or i1 %41064, %41066
  %41068 = load i32, i32* %17, align 4
  %41069 = icmp eq i32 %41031, %41068
  %41070 = or i1 %41067, %41069
  %41071 = load i32, i32* %18, align 4
  %41072 = icmp eq i32 %41031, %41071
  %41073 = or i1 %41070, %41072
  %41074 = load i32, i32* %19, align 4
  %41075 = icmp eq i32 %41031, %41074
  %41076 = or i1 %41073, %41075
  %41077 = load i32, i32* %20, align 4
  %41078 = icmp eq i32 %41031, %41077
  %41079 = or i1 %41076, %41078
  %41080 = load i32, i32* %21, align 4
  %41081 = icmp eq i32 %41031, %41080
  %41082 = or i1 %41079, %41081
  %41083 = load i32, i32* %22, align 4
  %41084 = icmp eq i32 %41031, %41083
  %41085 = or i1 %41082, %41084
  %41086 = load i32, i32* %23, align 4
  %41087 = icmp eq i32 %41031, %41086
  %41088 = or i1 %41085, %41087
  %41089 = load i32, i32* %24, align 4
  %41090 = icmp eq i32 %41031, %41089
  %41091 = or i1 %41088, %41090
  %41092 = load i32, i32* %25, align 4
  %41093 = icmp eq i32 %41031, %41092
  %41094 = or i1 %41091, %41093
  %41095 = load i32, i32* %26, align 4
  %41096 = icmp eq i32 %41031, %41095
  %41097 = or i1 %41094, %41096
  %41098 = load i32, i32* %27, align 4
  %41099 = icmp eq i32 %41031, %41098
  %41100 = or i1 %41097, %41099
  %41101 = load i32, i32* %28, align 4
  %41102 = icmp eq i32 %41031, %41101
  %41103 = or i1 %41100, %41102
  %41104 = load i32, i32* %29, align 4
  %41105 = icmp eq i32 %41031, %41104
  %41106 = or i1 %41103, %41105
  %41107 = load i32, i32* %30, align 4
  %41108 = icmp eq i32 %41031, %41107
  %41109 = or i1 %41106, %41108
  %41110 = load i32, i32* %31, align 4
  %41111 = icmp eq i32 %41031, %41110
  %41112 = or i1 %41109, %41111
  %41113 = load i32, i32* %32, align 4
  %41114 = icmp eq i32 %41031, %41113
  %41115 = or i1 %41112, %41114
  %41116 = load i32, i32* %33, align 4
  %41117 = icmp eq i32 %41031, %41116
  %41118 = or i1 %41115, %41117
  %41119 = load i32, i32* %34, align 4
  %41120 = icmp eq i32 %41031, %41119
  %41121 = or i1 %41118, %41120
  %41122 = load i32, i32* %35, align 4
  %41123 = icmp eq i32 %41031, %41122
  %41124 = or i1 %41121, %41123
  %41125 = load i32, i32* %36, align 4
  %41126 = icmp eq i32 %41031, %41125
  %41127 = or i1 %41124, %41126
  %41128 = load i32, i32* %37, align 4
  %41129 = icmp eq i32 %41031, %41128
  %41130 = or i1 %41127, %41129
  %41131 = load i32, i32* %38, align 4
  %41132 = icmp eq i32 %41031, %41131
  %41133 = or i1 %41130, %41132
  %41134 = load i32, i32* %39, align 4
  %41135 = icmp eq i32 %41031, %41134
  %41136 = or i1 %41133, %41135
  %41137 = load i32, i32* %40, align 4
  %41138 = icmp eq i32 %41031, %41137
  %41139 = or i1 %41136, %41138
  %41140 = load i32, i32* %41, align 4
  %41141 = icmp eq i32 %41031, %41140
  %41142 = or i1 %41139, %41141
  %41143 = load i32, i32* %42, align 4
  %41144 = icmp eq i32 %41031, %41143
  %41145 = or i1 %41142, %41144
  %41146 = load i32, i32* %43, align 4
  %41147 = icmp eq i32 %41031, %41146
  %41148 = or i1 %41145, %41147
  %41149 = load i32, i32* %44, align 4
  %41150 = icmp eq i32 %41031, %41149
  %41151 = or i1 %41148, %41150
  %41152 = load i32, i32* %45, align 4
  %41153 = icmp eq i32 %41031, %41152
  %41154 = or i1 %41151, %41153
  %41155 = load i32, i32* %46, align 4
  %41156 = icmp eq i32 %41031, %41155
  %41157 = or i1 %41154, %41156
  %41158 = load i32, i32* %47, align 4
  %41159 = icmp eq i32 %41031, %41158
  %41160 = or i1 %41157, %41159
  %41161 = load i32, i32* %48, align 4
  %41162 = icmp eq i32 %41031, %41161
  %41163 = or i1 %41160, %41162
  %41164 = load i32, i32* %49, align 4
  %41165 = icmp eq i32 %41031, %41164
  %41166 = or i1 %41163, %41165
  %41167 = load i32, i32* %50, align 4
  %41168 = icmp eq i32 %41031, %41167
  %41169 = or i1 %41166, %41168
  %41170 = load i32, i32* %51, align 4
  %41171 = icmp eq i32 %41031, %41170
  %41172 = or i1 %41169, %41171
  %41173 = load i32, i32* %52, align 4
  %41174 = icmp eq i32 %41031, %41173
  %41175 = or i1 %41172, %41174
  %41176 = load i32, i32* %53, align 4
  %41177 = icmp eq i32 %41031, %41176
  %41178 = or i1 %41175, %41177
  %41179 = load i32, i32* %54, align 4
  %41180 = icmp eq i32 %41031, %41179
  %41181 = or i1 %41178, %41180
  %41182 = load i32, i32* %55, align 4
  %41183 = icmp eq i32 %41031, %41182
  %41184 = or i1 %41181, %41183
  %41185 = load i32, i32* %56, align 4
  %41186 = icmp eq i32 %41031, %41185
  %41187 = or i1 %41184, %41186
  %41188 = load i32, i32* %57, align 4
  %41189 = icmp eq i32 %41031, %41188
  %41190 = or i1 %41187, %41189
  %41191 = load i32, i32* %58, align 4
  %41192 = icmp eq i32 %41031, %41191
  %41193 = or i1 %41190, %41192
  %41194 = load i32, i32* %59, align 4
  %41195 = icmp eq i32 %41031, %41194
  %41196 = or i1 %41193, %41195
  %41197 = load i32, i32* %60, align 4
  %41198 = icmp eq i32 %41031, %41197
  %41199 = or i1 %41196, %41198
  %41200 = load i32, i32* %61, align 4
  %41201 = icmp eq i32 %41031, %41200
  %41202 = or i1 %41199, %41201
  %41203 = load i32, i32* %62, align 4
  %41204 = icmp eq i32 %41031, %41203
  %41205 = or i1 %41202, %41204
  %41206 = getelementptr i8, i8 addrspace(1)* %4, i32 148
  %41207 = zext i1 %41205 to i8
  store i8 %41207, i8 addrspace(1)* %41206, align 1, !nosanitize !3
  %41208 = load i256, i256* %41030, align 4
  %41209 = alloca i256, align 8
  store i256 %41208, i256* %41209, align 4
  %41210 = alloca i256, align 8
  store i256 1, i256* %41210, align 4
  %41211 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %41209, i256* %41210, i256* %41211), !pc !607, !intsan !6
  %41212 = load i256, i256* %41211, align 4
  %41213 = and i256 1461501637330902918203684832716283019655932542975, %41212
  %41214 = and i256 1461501637330902918203684832716283019655932542975, %41213
  %41215 = and i256 1461501637330902918203684832716283019655932542975, %41214
  %41216 = trunc i256 0 to i64
  %41217 = alloca i256, align 8
  store i256 %41215, i256* %41217, align 4
  %41218 = bitcast i256* %41217 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41216, i8* %41218, i64 32)
  %41219 = add i256 32, 0, !pc !608, !intsan !10
  %41220 = trunc i256 %41219 to i64
  %41221 = alloca i256, align 8
  store i256 3, i256* %41221, align 4
  %41222 = bitcast i256* %41221 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41220, i8* %41222, i64 32)
  %41223 = add i256 32, %41219, !pc !609, !intsan !10
  %41224 = trunc i256 0 to i32
  %41225 = trunc i256 %41223 to i32
  %41226 = getelementptr inbounds i8, i8* %MEMORY, i32 %41224
  %41227 = alloca i256, align 8
  %41228 = bitcast i256* %41227 to i8*
  call void @__device_sha3(i8* %41226, i32 %41225, i8* %41228)
  %41229 = load i256, i256* %41227, align 4
  %41230 = alloca i256, align 8
  store i256 %41229, i256* %41230, align 4
  %41231 = alloca i256, align 8
  store i256 %40204, i256* %41231, align 4
  call void @__device_sstore(i256* %41230, i256* %41231)
  %41232 = call i32 @__hashword(i256* %41230)
  store i32 %41232, i32* %7, align 4, !nosanitize !3
  %41233 = trunc i256 0 to i64
  %41234 = alloca i256, align 8
  store i256 %40204, i256* %41234, align 4
  %41235 = bitcast i256* %41234 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41233, i8* %41235, i64 32)
  %41236 = add i256 32, 0, !pc !610, !intsan !10
  %41237 = trunc i256 %41236 to i64
  %41238 = alloca i256, align 8
  store i256 4, i256* %41238, align 4
  %41239 = bitcast i256* %41238 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %41237, i8* %41239, i64 32)
  %41240 = add i256 32, %41236, !pc !611, !intsan !10
  %41241 = trunc i256 0 to i32
  %41242 = trunc i256 %41240 to i32
  %41243 = getelementptr inbounds i8, i8* %MEMORY, i32 %41241
  %41244 = alloca i256, align 8
  %41245 = bitcast i256* %41244 to i8*
  call void @__device_sha3(i8* %41243, i32 %41242, i8* %41245)
  %41246 = load i256, i256* %41244, align 4
  %41247 = add i256 %41027, 0, !pc !612, !intsan !10
  %41248 = alloca i256, align 8
  store i256 %41247, i256* %41248, align 4
  %41249 = alloca i256, align 8
  call void @__device_sload(i256* %41248, i256* %41249)
  %41250 = call i32 @__hashword(i256* %41248)
  %41251 = load i32, i32* %5, align 4
  %41252 = icmp eq i32 %41250, %41251
  %41253 = or i1 false, %41252
  %41254 = load i32, i32* %6, align 4
  %41255 = icmp eq i32 %41250, %41254
  %41256 = or i1 %41253, %41255
  %41257 = load i32, i32* %7, align 4
  %41258 = icmp eq i32 %41250, %41257
  %41259 = or i1 %41256, %41258
  %41260 = load i32, i32* %8, align 4
  %41261 = icmp eq i32 %41250, %41260
  %41262 = or i1 %41259, %41261
  %41263 = load i32, i32* %9, align 4
  %41264 = icmp eq i32 %41250, %41263
  %41265 = or i1 %41262, %41264
  %41266 = load i32, i32* %10, align 4
  %41267 = icmp eq i32 %41250, %41266
  %41268 = or i1 %41265, %41267
  %41269 = load i32, i32* %11, align 4
  %41270 = icmp eq i32 %41250, %41269
  %41271 = or i1 %41268, %41270
  %41272 = load i32, i32* %12, align 4
  %41273 = icmp eq i32 %41250, %41272
  %41274 = or i1 %41271, %41273
  %41275 = load i32, i32* %13, align 4
  %41276 = icmp eq i32 %41250, %41275
  %41277 = or i1 %41274, %41276
  %41278 = load i32, i32* %14, align 4
  %41279 = icmp eq i32 %41250, %41278
  %41280 = or i1 %41277, %41279
  %41281 = load i32, i32* %15, align 4
  %41282 = icmp eq i32 %41250, %41281
  %41283 = or i1 %41280, %41282
  %41284 = load i32, i32* %16, align 4
  %41285 = icmp eq i32 %41250, %41284
  %41286 = or i1 %41283, %41285
  %41287 = load i32, i32* %17, align 4
  %41288 = icmp eq i32 %41250, %41287
  %41289 = or i1 %41286, %41288
  %41290 = load i32, i32* %18, align 4
  %41291 = icmp eq i32 %41250, %41290
  %41292 = or i1 %41289, %41291
  %41293 = load i32, i32* %19, align 4
  %41294 = icmp eq i32 %41250, %41293
  %41295 = or i1 %41292, %41294
  %41296 = load i32, i32* %20, align 4
  %41297 = icmp eq i32 %41250, %41296
  %41298 = or i1 %41295, %41297
  %41299 = load i32, i32* %21, align 4
  %41300 = icmp eq i32 %41250, %41299
  %41301 = or i1 %41298, %41300
  %41302 = load i32, i32* %22, align 4
  %41303 = icmp eq i32 %41250, %41302
  %41304 = or i1 %41301, %41303
  %41305 = load i32, i32* %23, align 4
  %41306 = icmp eq i32 %41250, %41305
  %41307 = or i1 %41304, %41306
  %41308 = load i32, i32* %24, align 4
  %41309 = icmp eq i32 %41250, %41308
  %41310 = or i1 %41307, %41309
  %41311 = load i32, i32* %25, align 4
  %41312 = icmp eq i32 %41250, %41311
  %41313 = or i1 %41310, %41312
  %41314 = load i32, i32* %26, align 4
  %41315 = icmp eq i32 %41250, %41314
  %41316 = or i1 %41313, %41315
  %41317 = load i32, i32* %27, align 4
  %41318 = icmp eq i32 %41250, %41317
  %41319 = or i1 %41316, %41318
  %41320 = load i32, i32* %28, align 4
  %41321 = icmp eq i32 %41250, %41320
  %41322 = or i1 %41319, %41321
  %41323 = load i32, i32* %29, align 4
  %41324 = icmp eq i32 %41250, %41323
  %41325 = or i1 %41322, %41324
  %41326 = load i32, i32* %30, align 4
  %41327 = icmp eq i32 %41250, %41326
  %41328 = or i1 %41325, %41327
  %41329 = load i32, i32* %31, align 4
  %41330 = icmp eq i32 %41250, %41329
  %41331 = or i1 %41328, %41330
  %41332 = load i32, i32* %32, align 4
  %41333 = icmp eq i32 %41250, %41332
  %41334 = or i1 %41331, %41333
  %41335 = load i32, i32* %33, align 4
  %41336 = icmp eq i32 %41250, %41335
  %41337 = or i1 %41334, %41336
  %41338 = load i32, i32* %34, align 4
  %41339 = icmp eq i32 %41250, %41338
  %41340 = or i1 %41337, %41339
  %41341 = load i32, i32* %35, align 4
  %41342 = icmp eq i32 %41250, %41341
  %41343 = or i1 %41340, %41342
  %41344 = load i32, i32* %36, align 4
  %41345 = icmp eq i32 %41250, %41344
  %41346 = or i1 %41343, %41345
  %41347 = load i32, i32* %37, align 4
  %41348 = icmp eq i32 %41250, %41347
  %41349 = or i1 %41346, %41348
  %41350 = load i32, i32* %38, align 4
  %41351 = icmp eq i32 %41250, %41350
  %41352 = or i1 %41349, %41351
  %41353 = load i32, i32* %39, align 4
  %41354 = icmp eq i32 %41250, %41353
  %41355 = or i1 %41352, %41354
  %41356 = load i32, i32* %40, align 4
  %41357 = icmp eq i32 %41250, %41356
  %41358 = or i1 %41355, %41357
  %41359 = load i32, i32* %41, align 4
  %41360 = icmp eq i32 %41250, %41359
  %41361 = or i1 %41358, %41360
  %41362 = load i32, i32* %42, align 4
  %41363 = icmp eq i32 %41250, %41362
  %41364 = or i1 %41361, %41363
  %41365 = load i32, i32* %43, align 4
  %41366 = icmp eq i32 %41250, %41365
  %41367 = or i1 %41364, %41366
  %41368 = load i32, i32* %44, align 4
  %41369 = icmp eq i32 %41250, %41368
  %41370 = or i1 %41367, %41369
  %41371 = load i32, i32* %45, align 4
  %41372 = icmp eq i32 %41250, %41371
  %41373 = or i1 %41370, %41372
  %41374 = load i32, i32* %46, align 4
  %41375 = icmp eq i32 %41250, %41374
  %41376 = or i1 %41373, %41375
  %41377 = load i32, i32* %47, align 4
  %41378 = icmp eq i32 %41250, %41377
  %41379 = or i1 %41376, %41378
  %41380 = load i32, i32* %48, align 4
  %41381 = icmp eq i32 %41250, %41380
  %41382 = or i1 %41379, %41381
  %41383 = load i32, i32* %49, align 4
  %41384 = icmp eq i32 %41250, %41383
  %41385 = or i1 %41382, %41384
  %41386 = load i32, i32* %50, align 4
  %41387 = icmp eq i32 %41250, %41386
  %41388 = or i1 %41385, %41387
  %41389 = load i32, i32* %51, align 4
  %41390 = icmp eq i32 %41250, %41389
  %41391 = or i1 %41388, %41390
  %41392 = load i32, i32* %52, align 4
  %41393 = icmp eq i32 %41250, %41392
  %41394 = or i1 %41391, %41393
  %41395 = load i32, i32* %53, align 4
  %41396 = icmp eq i32 %41250, %41395
  %41397 = or i1 %41394, %41396
  %41398 = load i32, i32* %54, align 4
  %41399 = icmp eq i32 %41250, %41398
  %41400 = or i1 %41397, %41399
  %41401 = load i32, i32* %55, align 4
  %41402 = icmp eq i32 %41250, %41401
  %41403 = or i1 %41400, %41402
  %41404 = load i32, i32* %56, align 4
  %41405 = icmp eq i32 %41250, %41404
  %41406 = or i1 %41403, %41405
  %41407 = load i32, i32* %57, align 4
  %41408 = icmp eq i32 %41250, %41407
  %41409 = or i1 %41406, %41408
  %41410 = load i32, i32* %58, align 4
  %41411 = icmp eq i32 %41250, %41410
  %41412 = or i1 %41409, %41411
  %41413 = load i32, i32* %59, align 4
  %41414 = icmp eq i32 %41250, %41413
  %41415 = or i1 %41412, %41414
  %41416 = load i32, i32* %60, align 4
  %41417 = icmp eq i32 %41250, %41416
  %41418 = or i1 %41415, %41417
  %41419 = load i32, i32* %61, align 4
  %41420 = icmp eq i32 %41250, %41419
  %41421 = or i1 %41418, %41420
  %41422 = load i32, i32* %62, align 4
  %41423 = icmp eq i32 %41250, %41422
  %41424 = or i1 %41421, %41423
  %41425 = getelementptr i8, i8 addrspace(1)* %4, i32 149
  %41426 = zext i1 %41424 to i8
  store i8 %41426, i8 addrspace(1)* %41425, align 1, !nosanitize !3
  %41427 = load i256, i256* %41249, align 4
  %41428 = alloca i256, align 8
  store i256 %41427, i256* %41428, align 4
  %41429 = alloca i256, align 8
  store i256 1, i256* %41429, align 4
  %41430 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %41428, i256* %41429, i256* %41430), !pc !613, !intsan !6
  %41431 = load i256, i256* %41430, align 4
  %41432 = and i256 1461501637330902918203684832716283019655932542975, %41431
  %41433 = add i256 0, %41246, !pc !614, !intsan !10
  %41434 = alloca i256, align 8
  store i256 %41433, i256* %41434, align 4
  %41435 = alloca i256, align 8
  call void @__device_sload(i256* %41434, i256* %41435)
  %41436 = call i32 @__hashword(i256* %41434)
  %41437 = load i32, i32* %5, align 4
  %41438 = icmp eq i32 %41436, %41437
  %41439 = or i1 false, %41438
  %41440 = load i32, i32* %6, align 4
  %41441 = icmp eq i32 %41436, %41440
  %41442 = or i1 %41439, %41441
  %41443 = load i32, i32* %7, align 4
  %41444 = icmp eq i32 %41436, %41443
  %41445 = or i1 %41442, %41444
  %41446 = load i32, i32* %8, align 4
  %41447 = icmp eq i32 %41436, %41446
  %41448 = or i1 %41445, %41447
  %41449 = load i32, i32* %9, align 4
  %41450 = icmp eq i32 %41436, %41449
  %41451 = or i1 %41448, %41450
  %41452 = load i32, i32* %10, align 4
  %41453 = icmp eq i32 %41436, %41452
  %41454 = or i1 %41451, %41453
  %41455 = load i32, i32* %11, align 4
  %41456 = icmp eq i32 %41436, %41455
  %41457 = or i1 %41454, %41456
  %41458 = load i32, i32* %12, align 4
  %41459 = icmp eq i32 %41436, %41458
  %41460 = or i1 %41457, %41459
  %41461 = load i32, i32* %13, align 4
  %41462 = icmp eq i32 %41436, %41461
  %41463 = or i1 %41460, %41462
  %41464 = load i32, i32* %14, align 4
  %41465 = icmp eq i32 %41436, %41464
  %41466 = or i1 %41463, %41465
  %41467 = load i32, i32* %15, align 4
  %41468 = icmp eq i32 %41436, %41467
  %41469 = or i1 %41466, %41468
  %41470 = load i32, i32* %16, align 4
  %41471 = icmp eq i32 %41436, %41470
  %41472 = or i1 %41469, %41471
  %41473 = load i32, i32* %17, align 4
  %41474 = icmp eq i32 %41436, %41473
  %41475 = or i1 %41472, %41474
  %41476 = load i32, i32* %18, align 4
  %41477 = icmp eq i32 %41436, %41476
  %41478 = or i1 %41475, %41477
  %41479 = load i32, i32* %19, align 4
  %41480 = icmp eq i32 %41436, %41479
  %41481 = or i1 %41478, %41480
  %41482 = load i32, i32* %20, align 4
  %41483 = icmp eq i32 %41436, %41482
  %41484 = or i1 %41481, %41483
  %41485 = load i32, i32* %21, align 4
  %41486 = icmp eq i32 %41436, %41485
  %41487 = or i1 %41484, %41486
  %41488 = load i32, i32* %22, align 4
  %41489 = icmp eq i32 %41436, %41488
  %41490 = or i1 %41487, %41489
  %41491 = load i32, i32* %23, align 4
  %41492 = icmp eq i32 %41436, %41491
  %41493 = or i1 %41490, %41492
  %41494 = load i32, i32* %24, align 4
  %41495 = icmp eq i32 %41436, %41494
  %41496 = or i1 %41493, %41495
  %41497 = load i32, i32* %25, align 4
  %41498 = icmp eq i32 %41436, %41497
  %41499 = or i1 %41496, %41498
  %41500 = load i32, i32* %26, align 4
  %41501 = icmp eq i32 %41436, %41500
  %41502 = or i1 %41499, %41501
  %41503 = load i32, i32* %27, align 4
  %41504 = icmp eq i32 %41436, %41503
  %41505 = or i1 %41502, %41504
  %41506 = load i32, i32* %28, align 4
  %41507 = icmp eq i32 %41436, %41506
  %41508 = or i1 %41505, %41507
  %41509 = load i32, i32* %29, align 4
  %41510 = icmp eq i32 %41436, %41509
  %41511 = or i1 %41508, %41510
  %41512 = load i32, i32* %30, align 4
  %41513 = icmp eq i32 %41436, %41512
  %41514 = or i1 %41511, %41513
  %41515 = load i32, i32* %31, align 4
  %41516 = icmp eq i32 %41436, %41515
  %41517 = or i1 %41514, %41516
  %41518 = load i32, i32* %32, align 4
  %41519 = icmp eq i32 %41436, %41518
  %41520 = or i1 %41517, %41519
  %41521 = load i32, i32* %33, align 4
  %41522 = icmp eq i32 %41436, %41521
  %41523 = or i1 %41520, %41522
  %41524 = load i32, i32* %34, align 4
  %41525 = icmp eq i32 %41436, %41524
  %41526 = or i1 %41523, %41525
  %41527 = load i32, i32* %35, align 4
  %41528 = icmp eq i32 %41436, %41527
  %41529 = or i1 %41526, %41528
  %41530 = load i32, i32* %36, align 4
  %41531 = icmp eq i32 %41436, %41530
  %41532 = or i1 %41529, %41531
  %41533 = load i32, i32* %37, align 4
  %41534 = icmp eq i32 %41436, %41533
  %41535 = or i1 %41532, %41534
  %41536 = load i32, i32* %38, align 4
  %41537 = icmp eq i32 %41436, %41536
  %41538 = or i1 %41535, %41537
  %41539 = load i32, i32* %39, align 4
  %41540 = icmp eq i32 %41436, %41539
  %41541 = or i1 %41538, %41540
  %41542 = load i32, i32* %40, align 4
  %41543 = icmp eq i32 %41436, %41542
  %41544 = or i1 %41541, %41543
  %41545 = load i32, i32* %41, align 4
  %41546 = icmp eq i32 %41436, %41545
  %41547 = or i1 %41544, %41546
  %41548 = load i32, i32* %42, align 4
  %41549 = icmp eq i32 %41436, %41548
  %41550 = or i1 %41547, %41549
  %41551 = load i32, i32* %43, align 4
  %41552 = icmp eq i32 %41436, %41551
  %41553 = or i1 %41550, %41552
  %41554 = load i32, i32* %44, align 4
  %41555 = icmp eq i32 %41436, %41554
  %41556 = or i1 %41553, %41555
  %41557 = load i32, i32* %45, align 4
  %41558 = icmp eq i32 %41436, %41557
  %41559 = or i1 %41556, %41558
  %41560 = load i32, i32* %46, align 4
  %41561 = icmp eq i32 %41436, %41560
  %41562 = or i1 %41559, %41561
  %41563 = load i32, i32* %47, align 4
  %41564 = icmp eq i32 %41436, %41563
  %41565 = or i1 %41562, %41564
  %41566 = load i32, i32* %48, align 4
  %41567 = icmp eq i32 %41436, %41566
  %41568 = or i1 %41565, %41567
  %41569 = load i32, i32* %49, align 4
  %41570 = icmp eq i32 %41436, %41569
  %41571 = or i1 %41568, %41570
  %41572 = load i32, i32* %50, align 4
  %41573 = icmp eq i32 %41436, %41572
  %41574 = or i1 %41571, %41573
  %41575 = load i32, i32* %51, align 4
  %41576 = icmp eq i32 %41436, %41575
  %41577 = or i1 %41574, %41576
  %41578 = load i32, i32* %52, align 4
  %41579 = icmp eq i32 %41436, %41578
  %41580 = or i1 %41577, %41579
  %41581 = load i32, i32* %53, align 4
  %41582 = icmp eq i32 %41436, %41581
  %41583 = or i1 %41580, %41582
  %41584 = load i32, i32* %54, align 4
  %41585 = icmp eq i32 %41436, %41584
  %41586 = or i1 %41583, %41585
  %41587 = load i32, i32* %55, align 4
  %41588 = icmp eq i32 %41436, %41587
  %41589 = or i1 %41586, %41588
  %41590 = load i32, i32* %56, align 4
  %41591 = icmp eq i32 %41436, %41590
  %41592 = or i1 %41589, %41591
  %41593 = load i32, i32* %57, align 4
  %41594 = icmp eq i32 %41436, %41593
  %41595 = or i1 %41592, %41594
  %41596 = load i32, i32* %58, align 4
  %41597 = icmp eq i32 %41436, %41596
  %41598 = or i1 %41595, %41597
  %41599 = load i32, i32* %59, align 4
  %41600 = icmp eq i32 %41436, %41599
  %41601 = or i1 %41598, %41600
  %41602 = load i32, i32* %60, align 4
  %41603 = icmp eq i32 %41436, %41602
  %41604 = or i1 %41601, %41603
  %41605 = load i32, i32* %61, align 4
  %41606 = icmp eq i32 %41436, %41605
  %41607 = or i1 %41604, %41606
  %41608 = load i32, i32* %62, align 4
  %41609 = icmp eq i32 %41436, %41608
  %41610 = or i1 %41607, %41609
  %41611 = getelementptr i8, i8 addrspace(1)* %4, i32 150
  %41612 = zext i1 %41610 to i8
  store i8 %41612, i8 addrspace(1)* %41611, align 1, !nosanitize !3
  %41613 = load i256, i256* %41435, align 4
  %41614 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !615, !intsan !45
  %41615 = xor i256 %41614, -1
  %41616 = and i256 %41615, %41613
  %41617 = and i256 1461501637330902918203684832716283019655932542975, %41432
  %41618 = mul i256 %41617, 1, !pc !616, !intsan !45
  %41619 = or i256 %41618, %41616
  %41620 = alloca i256, align 8
  store i256 %41433, i256* %41620, align 4
  %41621 = alloca i256, align 8
  store i256 %41619, i256* %41621, align 4
  call void @__device_sstore(i256* %41620, i256* %41621)
  %41622 = call i32 @__hashword(i256* %41620)
  store i32 %41622, i32* %8, align 4, !nosanitize !3
  %41623 = add i256 %41027, 1, !pc !617, !intsan !10
  %41624 = alloca i256, align 8
  store i256 %41623, i256* %41624, align 4
  %41625 = alloca i256, align 8
  call void @__device_sload(i256* %41624, i256* %41625)
  %41626 = call i32 @__hashword(i256* %41624)
  %41627 = load i32, i32* %5, align 4
  %41628 = icmp eq i32 %41626, %41627
  %41629 = or i1 false, %41628
  %41630 = load i32, i32* %6, align 4
  %41631 = icmp eq i32 %41626, %41630
  %41632 = or i1 %41629, %41631
  %41633 = load i32, i32* %7, align 4
  %41634 = icmp eq i32 %41626, %41633
  %41635 = or i1 %41632, %41634
  %41636 = load i32, i32* %8, align 4
  %41637 = icmp eq i32 %41626, %41636
  %41638 = or i1 %41635, %41637
  %41639 = load i32, i32* %9, align 4
  %41640 = icmp eq i32 %41626, %41639
  %41641 = or i1 %41638, %41640
  %41642 = load i32, i32* %10, align 4
  %41643 = icmp eq i32 %41626, %41642
  %41644 = or i1 %41641, %41643
  %41645 = load i32, i32* %11, align 4
  %41646 = icmp eq i32 %41626, %41645
  %41647 = or i1 %41644, %41646
  %41648 = load i32, i32* %12, align 4
  %41649 = icmp eq i32 %41626, %41648
  %41650 = or i1 %41647, %41649
  %41651 = load i32, i32* %13, align 4
  %41652 = icmp eq i32 %41626, %41651
  %41653 = or i1 %41650, %41652
  %41654 = load i32, i32* %14, align 4
  %41655 = icmp eq i32 %41626, %41654
  %41656 = or i1 %41653, %41655
  %41657 = load i32, i32* %15, align 4
  %41658 = icmp eq i32 %41626, %41657
  %41659 = or i1 %41656, %41658
  %41660 = load i32, i32* %16, align 4
  %41661 = icmp eq i32 %41626, %41660
  %41662 = or i1 %41659, %41661
  %41663 = load i32, i32* %17, align 4
  %41664 = icmp eq i32 %41626, %41663
  %41665 = or i1 %41662, %41664
  %41666 = load i32, i32* %18, align 4
  %41667 = icmp eq i32 %41626, %41666
  %41668 = or i1 %41665, %41667
  %41669 = load i32, i32* %19, align 4
  %41670 = icmp eq i32 %41626, %41669
  %41671 = or i1 %41668, %41670
  %41672 = load i32, i32* %20, align 4
  %41673 = icmp eq i32 %41626, %41672
  %41674 = or i1 %41671, %41673
  %41675 = load i32, i32* %21, align 4
  %41676 = icmp eq i32 %41626, %41675
  %41677 = or i1 %41674, %41676
  %41678 = load i32, i32* %22, align 4
  %41679 = icmp eq i32 %41626, %41678
  %41680 = or i1 %41677, %41679
  %41681 = load i32, i32* %23, align 4
  %41682 = icmp eq i32 %41626, %41681
  %41683 = or i1 %41680, %41682
  %41684 = load i32, i32* %24, align 4
  %41685 = icmp eq i32 %41626, %41684
  %41686 = or i1 %41683, %41685
  %41687 = load i32, i32* %25, align 4
  %41688 = icmp eq i32 %41626, %41687
  %41689 = or i1 %41686, %41688
  %41690 = load i32, i32* %26, align 4
  %41691 = icmp eq i32 %41626, %41690
  %41692 = or i1 %41689, %41691
  %41693 = load i32, i32* %27, align 4
  %41694 = icmp eq i32 %41626, %41693
  %41695 = or i1 %41692, %41694
  %41696 = load i32, i32* %28, align 4
  %41697 = icmp eq i32 %41626, %41696
  %41698 = or i1 %41695, %41697
  %41699 = load i32, i32* %29, align 4
  %41700 = icmp eq i32 %41626, %41699
  %41701 = or i1 %41698, %41700
  %41702 = load i32, i32* %30, align 4
  %41703 = icmp eq i32 %41626, %41702
  %41704 = or i1 %41701, %41703
  %41705 = load i32, i32* %31, align 4
  %41706 = icmp eq i32 %41626, %41705
  %41707 = or i1 %41704, %41706
  %41708 = load i32, i32* %32, align 4
  %41709 = icmp eq i32 %41626, %41708
  %41710 = or i1 %41707, %41709
  %41711 = load i32, i32* %33, align 4
  %41712 = icmp eq i32 %41626, %41711
  %41713 = or i1 %41710, %41712
  %41714 = load i32, i32* %34, align 4
  %41715 = icmp eq i32 %41626, %41714
  %41716 = or i1 %41713, %41715
  %41717 = load i32, i32* %35, align 4
  %41718 = icmp eq i32 %41626, %41717
  %41719 = or i1 %41716, %41718
  %41720 = load i32, i32* %36, align 4
  %41721 = icmp eq i32 %41626, %41720
  %41722 = or i1 %41719, %41721
  %41723 = load i32, i32* %37, align 4
  %41724 = icmp eq i32 %41626, %41723
  %41725 = or i1 %41722, %41724
  %41726 = load i32, i32* %38, align 4
  %41727 = icmp eq i32 %41626, %41726
  %41728 = or i1 %41725, %41727
  %41729 = load i32, i32* %39, align 4
  %41730 = icmp eq i32 %41626, %41729
  %41731 = or i1 %41728, %41730
  %41732 = load i32, i32* %40, align 4
  %41733 = icmp eq i32 %41626, %41732
  %41734 = or i1 %41731, %41733
  %41735 = load i32, i32* %41, align 4
  %41736 = icmp eq i32 %41626, %41735
  %41737 = or i1 %41734, %41736
  %41738 = load i32, i32* %42, align 4
  %41739 = icmp eq i32 %41626, %41738
  %41740 = or i1 %41737, %41739
  %41741 = load i32, i32* %43, align 4
  %41742 = icmp eq i32 %41626, %41741
  %41743 = or i1 %41740, %41742
  %41744 = load i32, i32* %44, align 4
  %41745 = icmp eq i32 %41626, %41744
  %41746 = or i1 %41743, %41745
  %41747 = load i32, i32* %45, align 4
  %41748 = icmp eq i32 %41626, %41747
  %41749 = or i1 %41746, %41748
  %41750 = load i32, i32* %46, align 4
  %41751 = icmp eq i32 %41626, %41750
  %41752 = or i1 %41749, %41751
  %41753 = load i32, i32* %47, align 4
  %41754 = icmp eq i32 %41626, %41753
  %41755 = or i1 %41752, %41754
  %41756 = load i32, i32* %48, align 4
  %41757 = icmp eq i32 %41626, %41756
  %41758 = or i1 %41755, %41757
  %41759 = load i32, i32* %49, align 4
  %41760 = icmp eq i32 %41626, %41759
  %41761 = or i1 %41758, %41760
  %41762 = load i32, i32* %50, align 4
  %41763 = icmp eq i32 %41626, %41762
  %41764 = or i1 %41761, %41763
  %41765 = load i32, i32* %51, align 4
  %41766 = icmp eq i32 %41626, %41765
  %41767 = or i1 %41764, %41766
  %41768 = load i32, i32* %52, align 4
  %41769 = icmp eq i32 %41626, %41768
  %41770 = or i1 %41767, %41769
  %41771 = load i32, i32* %53, align 4
  %41772 = icmp eq i32 %41626, %41771
  %41773 = or i1 %41770, %41772
  %41774 = load i32, i32* %54, align 4
  %41775 = icmp eq i32 %41626, %41774
  %41776 = or i1 %41773, %41775
  %41777 = load i32, i32* %55, align 4
  %41778 = icmp eq i32 %41626, %41777
  %41779 = or i1 %41776, %41778
  %41780 = load i32, i32* %56, align 4
  %41781 = icmp eq i32 %41626, %41780
  %41782 = or i1 %41779, %41781
  %41783 = load i32, i32* %57, align 4
  %41784 = icmp eq i32 %41626, %41783
  %41785 = or i1 %41782, %41784
  %41786 = load i32, i32* %58, align 4
  %41787 = icmp eq i32 %41626, %41786
  %41788 = or i1 %41785, %41787
  %41789 = load i32, i32* %59, align 4
  %41790 = icmp eq i32 %41626, %41789
  %41791 = or i1 %41788, %41790
  %41792 = load i32, i32* %60, align 4
  %41793 = icmp eq i32 %41626, %41792
  %41794 = or i1 %41791, %41793
  %41795 = load i32, i32* %61, align 4
  %41796 = icmp eq i32 %41626, %41795
  %41797 = or i1 %41794, %41796
  %41798 = load i32, i32* %62, align 4
  %41799 = icmp eq i32 %41626, %41798
  %41800 = or i1 %41797, %41799
  %41801 = getelementptr i8, i8 addrspace(1)* %4, i32 151
  %41802 = zext i1 %41800 to i8
  store i8 %41802, i8 addrspace(1)* %41801, align 1, !nosanitize !3
  %41803 = load i256, i256* %41625, align 4
  %41804 = add i256 1, %41246, !pc !618, !intsan !10
  %41805 = alloca i256, align 8
  store i256 %41804, i256* %41805, align 4
  %41806 = alloca i256, align 8
  store i256 %41803, i256* %41806, align 4
  call void @__device_sstore(i256* %41805, i256* %41806)
  %41807 = call i32 @__hashword(i256* %41805)
  store i32 %41807, i32* %9, align 4, !nosanitize !3
  %41808 = add i256 %41027, 2, !pc !619, !intsan !10
  %41809 = alloca i256, align 8
  store i256 %41808, i256* %41809, align 4
  %41810 = alloca i256, align 8
  call void @__device_sload(i256* %41809, i256* %41810)
  %41811 = call i32 @__hashword(i256* %41809)
  %41812 = load i32, i32* %5, align 4
  %41813 = icmp eq i32 %41811, %41812
  %41814 = or i1 false, %41813
  %41815 = load i32, i32* %6, align 4
  %41816 = icmp eq i32 %41811, %41815
  %41817 = or i1 %41814, %41816
  %41818 = load i32, i32* %7, align 4
  %41819 = icmp eq i32 %41811, %41818
  %41820 = or i1 %41817, %41819
  %41821 = load i32, i32* %8, align 4
  %41822 = icmp eq i32 %41811, %41821
  %41823 = or i1 %41820, %41822
  %41824 = load i32, i32* %9, align 4
  %41825 = icmp eq i32 %41811, %41824
  %41826 = or i1 %41823, %41825
  %41827 = load i32, i32* %10, align 4
  %41828 = icmp eq i32 %41811, %41827
  %41829 = or i1 %41826, %41828
  %41830 = load i32, i32* %11, align 4
  %41831 = icmp eq i32 %41811, %41830
  %41832 = or i1 %41829, %41831
  %41833 = load i32, i32* %12, align 4
  %41834 = icmp eq i32 %41811, %41833
  %41835 = or i1 %41832, %41834
  %41836 = load i32, i32* %13, align 4
  %41837 = icmp eq i32 %41811, %41836
  %41838 = or i1 %41835, %41837
  %41839 = load i32, i32* %14, align 4
  %41840 = icmp eq i32 %41811, %41839
  %41841 = or i1 %41838, %41840
  %41842 = load i32, i32* %15, align 4
  %41843 = icmp eq i32 %41811, %41842
  %41844 = or i1 %41841, %41843
  %41845 = load i32, i32* %16, align 4
  %41846 = icmp eq i32 %41811, %41845
  %41847 = or i1 %41844, %41846
  %41848 = load i32, i32* %17, align 4
  %41849 = icmp eq i32 %41811, %41848
  %41850 = or i1 %41847, %41849
  %41851 = load i32, i32* %18, align 4
  %41852 = icmp eq i32 %41811, %41851
  %41853 = or i1 %41850, %41852
  %41854 = load i32, i32* %19, align 4
  %41855 = icmp eq i32 %41811, %41854
  %41856 = or i1 %41853, %41855
  %41857 = load i32, i32* %20, align 4
  %41858 = icmp eq i32 %41811, %41857
  %41859 = or i1 %41856, %41858
  %41860 = load i32, i32* %21, align 4
  %41861 = icmp eq i32 %41811, %41860
  %41862 = or i1 %41859, %41861
  %41863 = load i32, i32* %22, align 4
  %41864 = icmp eq i32 %41811, %41863
  %41865 = or i1 %41862, %41864
  %41866 = load i32, i32* %23, align 4
  %41867 = icmp eq i32 %41811, %41866
  %41868 = or i1 %41865, %41867
  %41869 = load i32, i32* %24, align 4
  %41870 = icmp eq i32 %41811, %41869
  %41871 = or i1 %41868, %41870
  %41872 = load i32, i32* %25, align 4
  %41873 = icmp eq i32 %41811, %41872
  %41874 = or i1 %41871, %41873
  %41875 = load i32, i32* %26, align 4
  %41876 = icmp eq i32 %41811, %41875
  %41877 = or i1 %41874, %41876
  %41878 = load i32, i32* %27, align 4
  %41879 = icmp eq i32 %41811, %41878
  %41880 = or i1 %41877, %41879
  %41881 = load i32, i32* %28, align 4
  %41882 = icmp eq i32 %41811, %41881
  %41883 = or i1 %41880, %41882
  %41884 = load i32, i32* %29, align 4
  %41885 = icmp eq i32 %41811, %41884
  %41886 = or i1 %41883, %41885
  %41887 = load i32, i32* %30, align 4
  %41888 = icmp eq i32 %41811, %41887
  %41889 = or i1 %41886, %41888
  %41890 = load i32, i32* %31, align 4
  %41891 = icmp eq i32 %41811, %41890
  %41892 = or i1 %41889, %41891
  %41893 = load i32, i32* %32, align 4
  %41894 = icmp eq i32 %41811, %41893
  %41895 = or i1 %41892, %41894
  %41896 = load i32, i32* %33, align 4
  %41897 = icmp eq i32 %41811, %41896
  %41898 = or i1 %41895, %41897
  %41899 = load i32, i32* %34, align 4
  %41900 = icmp eq i32 %41811, %41899
  %41901 = or i1 %41898, %41900
  %41902 = load i32, i32* %35, align 4
  %41903 = icmp eq i32 %41811, %41902
  %41904 = or i1 %41901, %41903
  %41905 = load i32, i32* %36, align 4
  %41906 = icmp eq i32 %41811, %41905
  %41907 = or i1 %41904, %41906
  %41908 = load i32, i32* %37, align 4
  %41909 = icmp eq i32 %41811, %41908
  %41910 = or i1 %41907, %41909
  %41911 = load i32, i32* %38, align 4
  %41912 = icmp eq i32 %41811, %41911
  %41913 = or i1 %41910, %41912
  %41914 = load i32, i32* %39, align 4
  %41915 = icmp eq i32 %41811, %41914
  %41916 = or i1 %41913, %41915
  %41917 = load i32, i32* %40, align 4
  %41918 = icmp eq i32 %41811, %41917
  %41919 = or i1 %41916, %41918
  %41920 = load i32, i32* %41, align 4
  %41921 = icmp eq i32 %41811, %41920
  %41922 = or i1 %41919, %41921
  %41923 = load i32, i32* %42, align 4
  %41924 = icmp eq i32 %41811, %41923
  %41925 = or i1 %41922, %41924
  %41926 = load i32, i32* %43, align 4
  %41927 = icmp eq i32 %41811, %41926
  %41928 = or i1 %41925, %41927
  %41929 = load i32, i32* %44, align 4
  %41930 = icmp eq i32 %41811, %41929
  %41931 = or i1 %41928, %41930
  %41932 = load i32, i32* %45, align 4
  %41933 = icmp eq i32 %41811, %41932
  %41934 = or i1 %41931, %41933
  %41935 = load i32, i32* %46, align 4
  %41936 = icmp eq i32 %41811, %41935
  %41937 = or i1 %41934, %41936
  %41938 = load i32, i32* %47, align 4
  %41939 = icmp eq i32 %41811, %41938
  %41940 = or i1 %41937, %41939
  %41941 = load i32, i32* %48, align 4
  %41942 = icmp eq i32 %41811, %41941
  %41943 = or i1 %41940, %41942
  %41944 = load i32, i32* %49, align 4
  %41945 = icmp eq i32 %41811, %41944
  %41946 = or i1 %41943, %41945
  %41947 = load i32, i32* %50, align 4
  %41948 = icmp eq i32 %41811, %41947
  %41949 = or i1 %41946, %41948
  %41950 = load i32, i32* %51, align 4
  %41951 = icmp eq i32 %41811, %41950
  %41952 = or i1 %41949, %41951
  %41953 = load i32, i32* %52, align 4
  %41954 = icmp eq i32 %41811, %41953
  %41955 = or i1 %41952, %41954
  %41956 = load i32, i32* %53, align 4
  %41957 = icmp eq i32 %41811, %41956
  %41958 = or i1 %41955, %41957
  %41959 = load i32, i32* %54, align 4
  %41960 = icmp eq i32 %41811, %41959
  %41961 = or i1 %41958, %41960
  %41962 = load i32, i32* %55, align 4
  %41963 = icmp eq i32 %41811, %41962
  %41964 = or i1 %41961, %41963
  %41965 = load i32, i32* %56, align 4
  %41966 = icmp eq i32 %41811, %41965
  %41967 = or i1 %41964, %41966
  %41968 = load i32, i32* %57, align 4
  %41969 = icmp eq i32 %41811, %41968
  %41970 = or i1 %41967, %41969
  %41971 = load i32, i32* %58, align 4
  %41972 = icmp eq i32 %41811, %41971
  %41973 = or i1 %41970, %41972
  %41974 = load i32, i32* %59, align 4
  %41975 = icmp eq i32 %41811, %41974
  %41976 = or i1 %41973, %41975
  %41977 = load i32, i32* %60, align 4
  %41978 = icmp eq i32 %41811, %41977
  %41979 = or i1 %41976, %41978
  %41980 = load i32, i32* %61, align 4
  %41981 = icmp eq i32 %41811, %41980
  %41982 = or i1 %41979, %41981
  %41983 = load i32, i32* %62, align 4
  %41984 = icmp eq i32 %41811, %41983
  %41985 = or i1 %41982, %41984
  %41986 = getelementptr i8, i8 addrspace(1)* %4, i32 152
  %41987 = zext i1 %41985 to i8
  store i8 %41987, i8 addrspace(1)* %41986, align 1, !nosanitize !3
  %41988 = load i256, i256* %41810, align 4
  %41989 = alloca i256, align 8
  store i256 %41988, i256* %41989, align 4
  %41990 = alloca i256, align 8
  store i256 1, i256* %41990, align 4
  %41991 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %41989, i256* %41990, i256* %41991), !pc !620, !intsan !6
  %41992 = load i256, i256* %41991, align 4
  %41993 = and i256 255, %41992
  %41994 = add i256 2, %41246, !pc !621, !intsan !10
  %41995 = alloca i256, align 8
  store i256 %41994, i256* %41995, align 4
  %41996 = alloca i256, align 8
  call void @__device_sload(i256* %41995, i256* %41996)
  %41997 = call i32 @__hashword(i256* %41995)
  %41998 = load i32, i32* %5, align 4
  %41999 = icmp eq i32 %41997, %41998
  %42000 = or i1 false, %41999
  %42001 = load i32, i32* %6, align 4
  %42002 = icmp eq i32 %41997, %42001
  %42003 = or i1 %42000, %42002
  %42004 = load i32, i32* %7, align 4
  %42005 = icmp eq i32 %41997, %42004
  %42006 = or i1 %42003, %42005
  %42007 = load i32, i32* %8, align 4
  %42008 = icmp eq i32 %41997, %42007
  %42009 = or i1 %42006, %42008
  %42010 = load i32, i32* %9, align 4
  %42011 = icmp eq i32 %41997, %42010
  %42012 = or i1 %42009, %42011
  %42013 = load i32, i32* %10, align 4
  %42014 = icmp eq i32 %41997, %42013
  %42015 = or i1 %42012, %42014
  %42016 = load i32, i32* %11, align 4
  %42017 = icmp eq i32 %41997, %42016
  %42018 = or i1 %42015, %42017
  %42019 = load i32, i32* %12, align 4
  %42020 = icmp eq i32 %41997, %42019
  %42021 = or i1 %42018, %42020
  %42022 = load i32, i32* %13, align 4
  %42023 = icmp eq i32 %41997, %42022
  %42024 = or i1 %42021, %42023
  %42025 = load i32, i32* %14, align 4
  %42026 = icmp eq i32 %41997, %42025
  %42027 = or i1 %42024, %42026
  %42028 = load i32, i32* %15, align 4
  %42029 = icmp eq i32 %41997, %42028
  %42030 = or i1 %42027, %42029
  %42031 = load i32, i32* %16, align 4
  %42032 = icmp eq i32 %41997, %42031
  %42033 = or i1 %42030, %42032
  %42034 = load i32, i32* %17, align 4
  %42035 = icmp eq i32 %41997, %42034
  %42036 = or i1 %42033, %42035
  %42037 = load i32, i32* %18, align 4
  %42038 = icmp eq i32 %41997, %42037
  %42039 = or i1 %42036, %42038
  %42040 = load i32, i32* %19, align 4
  %42041 = icmp eq i32 %41997, %42040
  %42042 = or i1 %42039, %42041
  %42043 = load i32, i32* %20, align 4
  %42044 = icmp eq i32 %41997, %42043
  %42045 = or i1 %42042, %42044
  %42046 = load i32, i32* %21, align 4
  %42047 = icmp eq i32 %41997, %42046
  %42048 = or i1 %42045, %42047
  %42049 = load i32, i32* %22, align 4
  %42050 = icmp eq i32 %41997, %42049
  %42051 = or i1 %42048, %42050
  %42052 = load i32, i32* %23, align 4
  %42053 = icmp eq i32 %41997, %42052
  %42054 = or i1 %42051, %42053
  %42055 = load i32, i32* %24, align 4
  %42056 = icmp eq i32 %41997, %42055
  %42057 = or i1 %42054, %42056
  %42058 = load i32, i32* %25, align 4
  %42059 = icmp eq i32 %41997, %42058
  %42060 = or i1 %42057, %42059
  %42061 = load i32, i32* %26, align 4
  %42062 = icmp eq i32 %41997, %42061
  %42063 = or i1 %42060, %42062
  %42064 = load i32, i32* %27, align 4
  %42065 = icmp eq i32 %41997, %42064
  %42066 = or i1 %42063, %42065
  %42067 = load i32, i32* %28, align 4
  %42068 = icmp eq i32 %41997, %42067
  %42069 = or i1 %42066, %42068
  %42070 = load i32, i32* %29, align 4
  %42071 = icmp eq i32 %41997, %42070
  %42072 = or i1 %42069, %42071
  %42073 = load i32, i32* %30, align 4
  %42074 = icmp eq i32 %41997, %42073
  %42075 = or i1 %42072, %42074
  %42076 = load i32, i32* %31, align 4
  %42077 = icmp eq i32 %41997, %42076
  %42078 = or i1 %42075, %42077
  %42079 = load i32, i32* %32, align 4
  %42080 = icmp eq i32 %41997, %42079
  %42081 = or i1 %42078, %42080
  %42082 = load i32, i32* %33, align 4
  %42083 = icmp eq i32 %41997, %42082
  %42084 = or i1 %42081, %42083
  %42085 = load i32, i32* %34, align 4
  %42086 = icmp eq i32 %41997, %42085
  %42087 = or i1 %42084, %42086
  %42088 = load i32, i32* %35, align 4
  %42089 = icmp eq i32 %41997, %42088
  %42090 = or i1 %42087, %42089
  %42091 = load i32, i32* %36, align 4
  %42092 = icmp eq i32 %41997, %42091
  %42093 = or i1 %42090, %42092
  %42094 = load i32, i32* %37, align 4
  %42095 = icmp eq i32 %41997, %42094
  %42096 = or i1 %42093, %42095
  %42097 = load i32, i32* %38, align 4
  %42098 = icmp eq i32 %41997, %42097
  %42099 = or i1 %42096, %42098
  %42100 = load i32, i32* %39, align 4
  %42101 = icmp eq i32 %41997, %42100
  %42102 = or i1 %42099, %42101
  %42103 = load i32, i32* %40, align 4
  %42104 = icmp eq i32 %41997, %42103
  %42105 = or i1 %42102, %42104
  %42106 = load i32, i32* %41, align 4
  %42107 = icmp eq i32 %41997, %42106
  %42108 = or i1 %42105, %42107
  %42109 = load i32, i32* %42, align 4
  %42110 = icmp eq i32 %41997, %42109
  %42111 = or i1 %42108, %42110
  %42112 = load i32, i32* %43, align 4
  %42113 = icmp eq i32 %41997, %42112
  %42114 = or i1 %42111, %42113
  %42115 = load i32, i32* %44, align 4
  %42116 = icmp eq i32 %41997, %42115
  %42117 = or i1 %42114, %42116
  %42118 = load i32, i32* %45, align 4
  %42119 = icmp eq i32 %41997, %42118
  %42120 = or i1 %42117, %42119
  %42121 = load i32, i32* %46, align 4
  %42122 = icmp eq i32 %41997, %42121
  %42123 = or i1 %42120, %42122
  %42124 = load i32, i32* %47, align 4
  %42125 = icmp eq i32 %41997, %42124
  %42126 = or i1 %42123, %42125
  %42127 = load i32, i32* %48, align 4
  %42128 = icmp eq i32 %41997, %42127
  %42129 = or i1 %42126, %42128
  %42130 = load i32, i32* %49, align 4
  %42131 = icmp eq i32 %41997, %42130
  %42132 = or i1 %42129, %42131
  %42133 = load i32, i32* %50, align 4
  %42134 = icmp eq i32 %41997, %42133
  %42135 = or i1 %42132, %42134
  %42136 = load i32, i32* %51, align 4
  %42137 = icmp eq i32 %41997, %42136
  %42138 = or i1 %42135, %42137
  %42139 = load i32, i32* %52, align 4
  %42140 = icmp eq i32 %41997, %42139
  %42141 = or i1 %42138, %42140
  %42142 = load i32, i32* %53, align 4
  %42143 = icmp eq i32 %41997, %42142
  %42144 = or i1 %42141, %42143
  %42145 = load i32, i32* %54, align 4
  %42146 = icmp eq i32 %41997, %42145
  %42147 = or i1 %42144, %42146
  %42148 = load i32, i32* %55, align 4
  %42149 = icmp eq i32 %41997, %42148
  %42150 = or i1 %42147, %42149
  %42151 = load i32, i32* %56, align 4
  %42152 = icmp eq i32 %41997, %42151
  %42153 = or i1 %42150, %42152
  %42154 = load i32, i32* %57, align 4
  %42155 = icmp eq i32 %41997, %42154
  %42156 = or i1 %42153, %42155
  %42157 = load i32, i32* %58, align 4
  %42158 = icmp eq i32 %41997, %42157
  %42159 = or i1 %42156, %42158
  %42160 = load i32, i32* %59, align 4
  %42161 = icmp eq i32 %41997, %42160
  %42162 = or i1 %42159, %42161
  %42163 = load i32, i32* %60, align 4
  %42164 = icmp eq i32 %41997, %42163
  %42165 = or i1 %42162, %42164
  %42166 = load i32, i32* %61, align 4
  %42167 = icmp eq i32 %41997, %42166
  %42168 = or i1 %42165, %42167
  %42169 = load i32, i32* %62, align 4
  %42170 = icmp eq i32 %41997, %42169
  %42171 = or i1 %42168, %42170
  %42172 = getelementptr i8, i8 addrspace(1)* %4, i32 153
  %42173 = zext i1 %42171 to i8
  store i8 %42173, i8 addrspace(1)* %42172, align 1, !nosanitize !3
  %42174 = load i256, i256* %41996, align 4
  %42175 = mul i256 255, 1, !pc !622, !intsan !45
  %42176 = xor i256 %42175, -1
  %42177 = and i256 %42176, %42174
  %42178 = icmp eq i256 %41993, 0
  %42179 = icmp eq i1 %42178, false
  %42180 = zext i1 %42179 to i256
  %42181 = mul i256 %42180, 1, !pc !623, !intsan !45
  %42182 = or i256 %42181, %42177
  %42183 = alloca i256, align 8
  store i256 %41994, i256* %42183, align 4
  %42184 = alloca i256, align 8
  store i256 %42182, i256* %42184, align 4
  call void @__device_sstore(i256* %42183, i256* %42184)
  %42185 = call i32 @__hashword(i256* %42183)
  store i32 %42185, i32* %10, align 4, !nosanitize !3
  %42186 = alloca i256, align 8
  store i256 5, i256* %42186, align 4
  %42187 = alloca i256, align 8
  call void @__device_sload(i256* %42186, i256* %42187)
  %42188 = call i32 @__hashword(i256* %42186)
  %42189 = load i32, i32* %5, align 4
  %42190 = icmp eq i32 %42188, %42189
  %42191 = or i1 false, %42190
  %42192 = load i32, i32* %6, align 4
  %42193 = icmp eq i32 %42188, %42192
  %42194 = or i1 %42191, %42193
  %42195 = load i32, i32* %7, align 4
  %42196 = icmp eq i32 %42188, %42195
  %42197 = or i1 %42194, %42196
  %42198 = load i32, i32* %8, align 4
  %42199 = icmp eq i32 %42188, %42198
  %42200 = or i1 %42197, %42199
  %42201 = load i32, i32* %9, align 4
  %42202 = icmp eq i32 %42188, %42201
  %42203 = or i1 %42200, %42202
  %42204 = load i32, i32* %10, align 4
  %42205 = icmp eq i32 %42188, %42204
  %42206 = or i1 %42203, %42205
  %42207 = load i32, i32* %11, align 4
  %42208 = icmp eq i32 %42188, %42207
  %42209 = or i1 %42206, %42208
  %42210 = load i32, i32* %12, align 4
  %42211 = icmp eq i32 %42188, %42210
  %42212 = or i1 %42209, %42211
  %42213 = load i32, i32* %13, align 4
  %42214 = icmp eq i32 %42188, %42213
  %42215 = or i1 %42212, %42214
  %42216 = load i32, i32* %14, align 4
  %42217 = icmp eq i32 %42188, %42216
  %42218 = or i1 %42215, %42217
  %42219 = load i32, i32* %15, align 4
  %42220 = icmp eq i32 %42188, %42219
  %42221 = or i1 %42218, %42220
  %42222 = load i32, i32* %16, align 4
  %42223 = icmp eq i32 %42188, %42222
  %42224 = or i1 %42221, %42223
  %42225 = load i32, i32* %17, align 4
  %42226 = icmp eq i32 %42188, %42225
  %42227 = or i1 %42224, %42226
  %42228 = load i32, i32* %18, align 4
  %42229 = icmp eq i32 %42188, %42228
  %42230 = or i1 %42227, %42229
  %42231 = load i32, i32* %19, align 4
  %42232 = icmp eq i32 %42188, %42231
  %42233 = or i1 %42230, %42232
  %42234 = load i32, i32* %20, align 4
  %42235 = icmp eq i32 %42188, %42234
  %42236 = or i1 %42233, %42235
  %42237 = load i32, i32* %21, align 4
  %42238 = icmp eq i32 %42188, %42237
  %42239 = or i1 %42236, %42238
  %42240 = load i32, i32* %22, align 4
  %42241 = icmp eq i32 %42188, %42240
  %42242 = or i1 %42239, %42241
  %42243 = load i32, i32* %23, align 4
  %42244 = icmp eq i32 %42188, %42243
  %42245 = or i1 %42242, %42244
  %42246 = load i32, i32* %24, align 4
  %42247 = icmp eq i32 %42188, %42246
  %42248 = or i1 %42245, %42247
  %42249 = load i32, i32* %25, align 4
  %42250 = icmp eq i32 %42188, %42249
  %42251 = or i1 %42248, %42250
  %42252 = load i32, i32* %26, align 4
  %42253 = icmp eq i32 %42188, %42252
  %42254 = or i1 %42251, %42253
  %42255 = load i32, i32* %27, align 4
  %42256 = icmp eq i32 %42188, %42255
  %42257 = or i1 %42254, %42256
  %42258 = load i32, i32* %28, align 4
  %42259 = icmp eq i32 %42188, %42258
  %42260 = or i1 %42257, %42259
  %42261 = load i32, i32* %29, align 4
  %42262 = icmp eq i32 %42188, %42261
  %42263 = or i1 %42260, %42262
  %42264 = load i32, i32* %30, align 4
  %42265 = icmp eq i32 %42188, %42264
  %42266 = or i1 %42263, %42265
  %42267 = load i32, i32* %31, align 4
  %42268 = icmp eq i32 %42188, %42267
  %42269 = or i1 %42266, %42268
  %42270 = load i32, i32* %32, align 4
  %42271 = icmp eq i32 %42188, %42270
  %42272 = or i1 %42269, %42271
  %42273 = load i32, i32* %33, align 4
  %42274 = icmp eq i32 %42188, %42273
  %42275 = or i1 %42272, %42274
  %42276 = load i32, i32* %34, align 4
  %42277 = icmp eq i32 %42188, %42276
  %42278 = or i1 %42275, %42277
  %42279 = load i32, i32* %35, align 4
  %42280 = icmp eq i32 %42188, %42279
  %42281 = or i1 %42278, %42280
  %42282 = load i32, i32* %36, align 4
  %42283 = icmp eq i32 %42188, %42282
  %42284 = or i1 %42281, %42283
  %42285 = load i32, i32* %37, align 4
  %42286 = icmp eq i32 %42188, %42285
  %42287 = or i1 %42284, %42286
  %42288 = load i32, i32* %38, align 4
  %42289 = icmp eq i32 %42188, %42288
  %42290 = or i1 %42287, %42289
  %42291 = load i32, i32* %39, align 4
  %42292 = icmp eq i32 %42188, %42291
  %42293 = or i1 %42290, %42292
  %42294 = load i32, i32* %40, align 4
  %42295 = icmp eq i32 %42188, %42294
  %42296 = or i1 %42293, %42295
  %42297 = load i32, i32* %41, align 4
  %42298 = icmp eq i32 %42188, %42297
  %42299 = or i1 %42296, %42298
  %42300 = load i32, i32* %42, align 4
  %42301 = icmp eq i32 %42188, %42300
  %42302 = or i1 %42299, %42301
  %42303 = load i32, i32* %43, align 4
  %42304 = icmp eq i32 %42188, %42303
  %42305 = or i1 %42302, %42304
  %42306 = load i32, i32* %44, align 4
  %42307 = icmp eq i32 %42188, %42306
  %42308 = or i1 %42305, %42307
  %42309 = load i32, i32* %45, align 4
  %42310 = icmp eq i32 %42188, %42309
  %42311 = or i1 %42308, %42310
  %42312 = load i32, i32* %46, align 4
  %42313 = icmp eq i32 %42188, %42312
  %42314 = or i1 %42311, %42313
  %42315 = load i32, i32* %47, align 4
  %42316 = icmp eq i32 %42188, %42315
  %42317 = or i1 %42314, %42316
  %42318 = load i32, i32* %48, align 4
  %42319 = icmp eq i32 %42188, %42318
  %42320 = or i1 %42317, %42319
  %42321 = load i32, i32* %49, align 4
  %42322 = icmp eq i32 %42188, %42321
  %42323 = or i1 %42320, %42322
  %42324 = load i32, i32* %50, align 4
  %42325 = icmp eq i32 %42188, %42324
  %42326 = or i1 %42323, %42325
  %42327 = load i32, i32* %51, align 4
  %42328 = icmp eq i32 %42188, %42327
  %42329 = or i1 %42326, %42328
  %42330 = load i32, i32* %52, align 4
  %42331 = icmp eq i32 %42188, %42330
  %42332 = or i1 %42329, %42331
  %42333 = load i32, i32* %53, align 4
  %42334 = icmp eq i32 %42188, %42333
  %42335 = or i1 %42332, %42334
  %42336 = load i32, i32* %54, align 4
  %42337 = icmp eq i32 %42188, %42336
  %42338 = or i1 %42335, %42337
  %42339 = load i32, i32* %55, align 4
  %42340 = icmp eq i32 %42188, %42339
  %42341 = or i1 %42338, %42340
  %42342 = load i32, i32* %56, align 4
  %42343 = icmp eq i32 %42188, %42342
  %42344 = or i1 %42341, %42343
  %42345 = load i32, i32* %57, align 4
  %42346 = icmp eq i32 %42188, %42345
  %42347 = or i1 %42344, %42346
  %42348 = load i32, i32* %58, align 4
  %42349 = icmp eq i32 %42188, %42348
  %42350 = or i1 %42347, %42349
  %42351 = load i32, i32* %59, align 4
  %42352 = icmp eq i32 %42188, %42351
  %42353 = or i1 %42350, %42352
  %42354 = load i32, i32* %60, align 4
  %42355 = icmp eq i32 %42188, %42354
  %42356 = or i1 %42353, %42355
  %42357 = load i32, i32* %61, align 4
  %42358 = icmp eq i32 %42188, %42357
  %42359 = or i1 %42356, %42358
  %42360 = load i32, i32* %62, align 4
  %42361 = icmp eq i32 %42188, %42360
  %42362 = or i1 %42359, %42361
  %42363 = getelementptr i8, i8 addrspace(1)* %4, i32 154
  %42364 = zext i1 %42362 to i8
  store i8 %42364, i8 addrspace(1)* %42363, align 1, !nosanitize !3
  %42365 = load i256, i256* %42187, align 4
  %42366 = trunc i256 0 to i64
  %42367 = alloca i256, align 8
  store i256 %42365, i256* %42367, align 4
  %42368 = bitcast i256* %42367 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %42366, i8* %42368, i64 32)
  %42369 = add i256 32, 0, !pc !624, !intsan !10
  %42370 = trunc i256 %42369 to i64
  %42371 = alloca i256, align 8
  store i256 4, i256* %42371, align 4
  %42372 = bitcast i256* %42371 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %42370, i8* %42372, i64 32)
  %42373 = add i256 32, %42369, !pc !625, !intsan !10
  %42374 = trunc i256 0 to i32
  %42375 = trunc i256 %42373 to i32
  %42376 = getelementptr inbounds i8, i8* %MEMORY, i32 %42374
  %42377 = alloca i256, align 8
  %42378 = bitcast i256* %42377 to i8*
  call void @__device_sha3(i8* %42376, i32 %42375, i8* %42378)
  %42379 = load i256, i256* %42377, align 4
  %42380 = add i256 %42379, 0, !pc !626, !intsan !10
  %42381 = alloca i256, align 8
  store i256 %42380, i256* %42381, align 4
  %42382 = alloca i256, align 8
  call void @__device_sload(i256* %42381, i256* %42382)
  %42383 = call i32 @__hashword(i256* %42381)
  %42384 = load i32, i32* %5, align 4
  %42385 = icmp eq i32 %42383, %42384
  %42386 = or i1 false, %42385
  %42387 = load i32, i32* %6, align 4
  %42388 = icmp eq i32 %42383, %42387
  %42389 = or i1 %42386, %42388
  %42390 = load i32, i32* %7, align 4
  %42391 = icmp eq i32 %42383, %42390
  %42392 = or i1 %42389, %42391
  %42393 = load i32, i32* %8, align 4
  %42394 = icmp eq i32 %42383, %42393
  %42395 = or i1 %42392, %42394
  %42396 = load i32, i32* %9, align 4
  %42397 = icmp eq i32 %42383, %42396
  %42398 = or i1 %42395, %42397
  %42399 = load i32, i32* %10, align 4
  %42400 = icmp eq i32 %42383, %42399
  %42401 = or i1 %42398, %42400
  %42402 = load i32, i32* %11, align 4
  %42403 = icmp eq i32 %42383, %42402
  %42404 = or i1 %42401, %42403
  %42405 = load i32, i32* %12, align 4
  %42406 = icmp eq i32 %42383, %42405
  %42407 = or i1 %42404, %42406
  %42408 = load i32, i32* %13, align 4
  %42409 = icmp eq i32 %42383, %42408
  %42410 = or i1 %42407, %42409
  %42411 = load i32, i32* %14, align 4
  %42412 = icmp eq i32 %42383, %42411
  %42413 = or i1 %42410, %42412
  %42414 = load i32, i32* %15, align 4
  %42415 = icmp eq i32 %42383, %42414
  %42416 = or i1 %42413, %42415
  %42417 = load i32, i32* %16, align 4
  %42418 = icmp eq i32 %42383, %42417
  %42419 = or i1 %42416, %42418
  %42420 = load i32, i32* %17, align 4
  %42421 = icmp eq i32 %42383, %42420
  %42422 = or i1 %42419, %42421
  %42423 = load i32, i32* %18, align 4
  %42424 = icmp eq i32 %42383, %42423
  %42425 = or i1 %42422, %42424
  %42426 = load i32, i32* %19, align 4
  %42427 = icmp eq i32 %42383, %42426
  %42428 = or i1 %42425, %42427
  %42429 = load i32, i32* %20, align 4
  %42430 = icmp eq i32 %42383, %42429
  %42431 = or i1 %42428, %42430
  %42432 = load i32, i32* %21, align 4
  %42433 = icmp eq i32 %42383, %42432
  %42434 = or i1 %42431, %42433
  %42435 = load i32, i32* %22, align 4
  %42436 = icmp eq i32 %42383, %42435
  %42437 = or i1 %42434, %42436
  %42438 = load i32, i32* %23, align 4
  %42439 = icmp eq i32 %42383, %42438
  %42440 = or i1 %42437, %42439
  %42441 = load i32, i32* %24, align 4
  %42442 = icmp eq i32 %42383, %42441
  %42443 = or i1 %42440, %42442
  %42444 = load i32, i32* %25, align 4
  %42445 = icmp eq i32 %42383, %42444
  %42446 = or i1 %42443, %42445
  %42447 = load i32, i32* %26, align 4
  %42448 = icmp eq i32 %42383, %42447
  %42449 = or i1 %42446, %42448
  %42450 = load i32, i32* %27, align 4
  %42451 = icmp eq i32 %42383, %42450
  %42452 = or i1 %42449, %42451
  %42453 = load i32, i32* %28, align 4
  %42454 = icmp eq i32 %42383, %42453
  %42455 = or i1 %42452, %42454
  %42456 = load i32, i32* %29, align 4
  %42457 = icmp eq i32 %42383, %42456
  %42458 = or i1 %42455, %42457
  %42459 = load i32, i32* %30, align 4
  %42460 = icmp eq i32 %42383, %42459
  %42461 = or i1 %42458, %42460
  %42462 = load i32, i32* %31, align 4
  %42463 = icmp eq i32 %42383, %42462
  %42464 = or i1 %42461, %42463
  %42465 = load i32, i32* %32, align 4
  %42466 = icmp eq i32 %42383, %42465
  %42467 = or i1 %42464, %42466
  %42468 = load i32, i32* %33, align 4
  %42469 = icmp eq i32 %42383, %42468
  %42470 = or i1 %42467, %42469
  %42471 = load i32, i32* %34, align 4
  %42472 = icmp eq i32 %42383, %42471
  %42473 = or i1 %42470, %42472
  %42474 = load i32, i32* %35, align 4
  %42475 = icmp eq i32 %42383, %42474
  %42476 = or i1 %42473, %42475
  %42477 = load i32, i32* %36, align 4
  %42478 = icmp eq i32 %42383, %42477
  %42479 = or i1 %42476, %42478
  %42480 = load i32, i32* %37, align 4
  %42481 = icmp eq i32 %42383, %42480
  %42482 = or i1 %42479, %42481
  %42483 = load i32, i32* %38, align 4
  %42484 = icmp eq i32 %42383, %42483
  %42485 = or i1 %42482, %42484
  %42486 = load i32, i32* %39, align 4
  %42487 = icmp eq i32 %42383, %42486
  %42488 = or i1 %42485, %42487
  %42489 = load i32, i32* %40, align 4
  %42490 = icmp eq i32 %42383, %42489
  %42491 = or i1 %42488, %42490
  %42492 = load i32, i32* %41, align 4
  %42493 = icmp eq i32 %42383, %42492
  %42494 = or i1 %42491, %42493
  %42495 = load i32, i32* %42, align 4
  %42496 = icmp eq i32 %42383, %42495
  %42497 = or i1 %42494, %42496
  %42498 = load i32, i32* %43, align 4
  %42499 = icmp eq i32 %42383, %42498
  %42500 = or i1 %42497, %42499
  %42501 = load i32, i32* %44, align 4
  %42502 = icmp eq i32 %42383, %42501
  %42503 = or i1 %42500, %42502
  %42504 = load i32, i32* %45, align 4
  %42505 = icmp eq i32 %42383, %42504
  %42506 = or i1 %42503, %42505
  %42507 = load i32, i32* %46, align 4
  %42508 = icmp eq i32 %42383, %42507
  %42509 = or i1 %42506, %42508
  %42510 = load i32, i32* %47, align 4
  %42511 = icmp eq i32 %42383, %42510
  %42512 = or i1 %42509, %42511
  %42513 = load i32, i32* %48, align 4
  %42514 = icmp eq i32 %42383, %42513
  %42515 = or i1 %42512, %42514
  %42516 = load i32, i32* %49, align 4
  %42517 = icmp eq i32 %42383, %42516
  %42518 = or i1 %42515, %42517
  %42519 = load i32, i32* %50, align 4
  %42520 = icmp eq i32 %42383, %42519
  %42521 = or i1 %42518, %42520
  %42522 = load i32, i32* %51, align 4
  %42523 = icmp eq i32 %42383, %42522
  %42524 = or i1 %42521, %42523
  %42525 = load i32, i32* %52, align 4
  %42526 = icmp eq i32 %42383, %42525
  %42527 = or i1 %42524, %42526
  %42528 = load i32, i32* %53, align 4
  %42529 = icmp eq i32 %42383, %42528
  %42530 = or i1 %42527, %42529
  %42531 = load i32, i32* %54, align 4
  %42532 = icmp eq i32 %42383, %42531
  %42533 = or i1 %42530, %42532
  %42534 = load i32, i32* %55, align 4
  %42535 = icmp eq i32 %42383, %42534
  %42536 = or i1 %42533, %42535
  %42537 = load i32, i32* %56, align 4
  %42538 = icmp eq i32 %42383, %42537
  %42539 = or i1 %42536, %42538
  %42540 = load i32, i32* %57, align 4
  %42541 = icmp eq i32 %42383, %42540
  %42542 = or i1 %42539, %42541
  %42543 = load i32, i32* %58, align 4
  %42544 = icmp eq i32 %42383, %42543
  %42545 = or i1 %42542, %42544
  %42546 = load i32, i32* %59, align 4
  %42547 = icmp eq i32 %42383, %42546
  %42548 = or i1 %42545, %42547
  %42549 = load i32, i32* %60, align 4
  %42550 = icmp eq i32 %42383, %42549
  %42551 = or i1 %42548, %42550
  %42552 = load i32, i32* %61, align 4
  %42553 = icmp eq i32 %42383, %42552
  %42554 = or i1 %42551, %42553
  %42555 = load i32, i32* %62, align 4
  %42556 = icmp eq i32 %42383, %42555
  %42557 = or i1 %42554, %42556
  %42558 = getelementptr i8, i8 addrspace(1)* %4, i32 155
  %42559 = zext i1 %42557 to i8
  store i8 %42559, i8 addrspace(1)* %42558, align 1, !nosanitize !3
  %42560 = load i256, i256* %42382, align 4
  %42561 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !627, !intsan !45
  %42562 = xor i256 %42561, -1
  %42563 = and i256 %42562, %42560
  %42564 = alloca i256, align 8
  store i256 %42380, i256* %42564, align 4
  %42565 = alloca i256, align 8
  store i256 %42563, i256* %42565, align 4
  call void @__device_sstore(i256* %42564, i256* %42565)
  %42566 = call i32 @__hashword(i256* %42564)
  store i32 %42566, i32* %11, align 4, !nosanitize !3
  %42567 = add i256 %42379, 1, !pc !628, !intsan !10
  %42568 = alloca i256, align 8
  store i256 %42567, i256* %42568, align 4
  %42569 = alloca i256, align 8
  store i256 0, i256* %42569, align 4
  call void @__device_sstore(i256* %42568, i256* %42569)
  %42570 = call i32 @__hashword(i256* %42568)
  store i32 %42570, i32* %12, align 4, !nosanitize !3
  %42571 = add i256 %42379, 2, !pc !629, !intsan !10
  %42572 = alloca i256, align 8
  store i256 %42571, i256* %42572, align 4
  %42573 = alloca i256, align 8
  call void @__device_sload(i256* %42572, i256* %42573)
  %42574 = call i32 @__hashword(i256* %42572)
  %42575 = load i32, i32* %5, align 4
  %42576 = icmp eq i32 %42574, %42575
  %42577 = or i1 false, %42576
  %42578 = load i32, i32* %6, align 4
  %42579 = icmp eq i32 %42574, %42578
  %42580 = or i1 %42577, %42579
  %42581 = load i32, i32* %7, align 4
  %42582 = icmp eq i32 %42574, %42581
  %42583 = or i1 %42580, %42582
  %42584 = load i32, i32* %8, align 4
  %42585 = icmp eq i32 %42574, %42584
  %42586 = or i1 %42583, %42585
  %42587 = load i32, i32* %9, align 4
  %42588 = icmp eq i32 %42574, %42587
  %42589 = or i1 %42586, %42588
  %42590 = load i32, i32* %10, align 4
  %42591 = icmp eq i32 %42574, %42590
  %42592 = or i1 %42589, %42591
  %42593 = load i32, i32* %11, align 4
  %42594 = icmp eq i32 %42574, %42593
  %42595 = or i1 %42592, %42594
  %42596 = load i32, i32* %12, align 4
  %42597 = icmp eq i32 %42574, %42596
  %42598 = or i1 %42595, %42597
  %42599 = load i32, i32* %13, align 4
  %42600 = icmp eq i32 %42574, %42599
  %42601 = or i1 %42598, %42600
  %42602 = load i32, i32* %14, align 4
  %42603 = icmp eq i32 %42574, %42602
  %42604 = or i1 %42601, %42603
  %42605 = load i32, i32* %15, align 4
  %42606 = icmp eq i32 %42574, %42605
  %42607 = or i1 %42604, %42606
  %42608 = load i32, i32* %16, align 4
  %42609 = icmp eq i32 %42574, %42608
  %42610 = or i1 %42607, %42609
  %42611 = load i32, i32* %17, align 4
  %42612 = icmp eq i32 %42574, %42611
  %42613 = or i1 %42610, %42612
  %42614 = load i32, i32* %18, align 4
  %42615 = icmp eq i32 %42574, %42614
  %42616 = or i1 %42613, %42615
  %42617 = load i32, i32* %19, align 4
  %42618 = icmp eq i32 %42574, %42617
  %42619 = or i1 %42616, %42618
  %42620 = load i32, i32* %20, align 4
  %42621 = icmp eq i32 %42574, %42620
  %42622 = or i1 %42619, %42621
  %42623 = load i32, i32* %21, align 4
  %42624 = icmp eq i32 %42574, %42623
  %42625 = or i1 %42622, %42624
  %42626 = load i32, i32* %22, align 4
  %42627 = icmp eq i32 %42574, %42626
  %42628 = or i1 %42625, %42627
  %42629 = load i32, i32* %23, align 4
  %42630 = icmp eq i32 %42574, %42629
  %42631 = or i1 %42628, %42630
  %42632 = load i32, i32* %24, align 4
  %42633 = icmp eq i32 %42574, %42632
  %42634 = or i1 %42631, %42633
  %42635 = load i32, i32* %25, align 4
  %42636 = icmp eq i32 %42574, %42635
  %42637 = or i1 %42634, %42636
  %42638 = load i32, i32* %26, align 4
  %42639 = icmp eq i32 %42574, %42638
  %42640 = or i1 %42637, %42639
  %42641 = load i32, i32* %27, align 4
  %42642 = icmp eq i32 %42574, %42641
  %42643 = or i1 %42640, %42642
  %42644 = load i32, i32* %28, align 4
  %42645 = icmp eq i32 %42574, %42644
  %42646 = or i1 %42643, %42645
  %42647 = load i32, i32* %29, align 4
  %42648 = icmp eq i32 %42574, %42647
  %42649 = or i1 %42646, %42648
  %42650 = load i32, i32* %30, align 4
  %42651 = icmp eq i32 %42574, %42650
  %42652 = or i1 %42649, %42651
  %42653 = load i32, i32* %31, align 4
  %42654 = icmp eq i32 %42574, %42653
  %42655 = or i1 %42652, %42654
  %42656 = load i32, i32* %32, align 4
  %42657 = icmp eq i32 %42574, %42656
  %42658 = or i1 %42655, %42657
  %42659 = load i32, i32* %33, align 4
  %42660 = icmp eq i32 %42574, %42659
  %42661 = or i1 %42658, %42660
  %42662 = load i32, i32* %34, align 4
  %42663 = icmp eq i32 %42574, %42662
  %42664 = or i1 %42661, %42663
  %42665 = load i32, i32* %35, align 4
  %42666 = icmp eq i32 %42574, %42665
  %42667 = or i1 %42664, %42666
  %42668 = load i32, i32* %36, align 4
  %42669 = icmp eq i32 %42574, %42668
  %42670 = or i1 %42667, %42669
  %42671 = load i32, i32* %37, align 4
  %42672 = icmp eq i32 %42574, %42671
  %42673 = or i1 %42670, %42672
  %42674 = load i32, i32* %38, align 4
  %42675 = icmp eq i32 %42574, %42674
  %42676 = or i1 %42673, %42675
  %42677 = load i32, i32* %39, align 4
  %42678 = icmp eq i32 %42574, %42677
  %42679 = or i1 %42676, %42678
  %42680 = load i32, i32* %40, align 4
  %42681 = icmp eq i32 %42574, %42680
  %42682 = or i1 %42679, %42681
  %42683 = load i32, i32* %41, align 4
  %42684 = icmp eq i32 %42574, %42683
  %42685 = or i1 %42682, %42684
  %42686 = load i32, i32* %42, align 4
  %42687 = icmp eq i32 %42574, %42686
  %42688 = or i1 %42685, %42687
  %42689 = load i32, i32* %43, align 4
  %42690 = icmp eq i32 %42574, %42689
  %42691 = or i1 %42688, %42690
  %42692 = load i32, i32* %44, align 4
  %42693 = icmp eq i32 %42574, %42692
  %42694 = or i1 %42691, %42693
  %42695 = load i32, i32* %45, align 4
  %42696 = icmp eq i32 %42574, %42695
  %42697 = or i1 %42694, %42696
  %42698 = load i32, i32* %46, align 4
  %42699 = icmp eq i32 %42574, %42698
  %42700 = or i1 %42697, %42699
  %42701 = load i32, i32* %47, align 4
  %42702 = icmp eq i32 %42574, %42701
  %42703 = or i1 %42700, %42702
  %42704 = load i32, i32* %48, align 4
  %42705 = icmp eq i32 %42574, %42704
  %42706 = or i1 %42703, %42705
  %42707 = load i32, i32* %49, align 4
  %42708 = icmp eq i32 %42574, %42707
  %42709 = or i1 %42706, %42708
  %42710 = load i32, i32* %50, align 4
  %42711 = icmp eq i32 %42574, %42710
  %42712 = or i1 %42709, %42711
  %42713 = load i32, i32* %51, align 4
  %42714 = icmp eq i32 %42574, %42713
  %42715 = or i1 %42712, %42714
  %42716 = load i32, i32* %52, align 4
  %42717 = icmp eq i32 %42574, %42716
  %42718 = or i1 %42715, %42717
  %42719 = load i32, i32* %53, align 4
  %42720 = icmp eq i32 %42574, %42719
  %42721 = or i1 %42718, %42720
  %42722 = load i32, i32* %54, align 4
  %42723 = icmp eq i32 %42574, %42722
  %42724 = or i1 %42721, %42723
  %42725 = load i32, i32* %55, align 4
  %42726 = icmp eq i32 %42574, %42725
  %42727 = or i1 %42724, %42726
  %42728 = load i32, i32* %56, align 4
  %42729 = icmp eq i32 %42574, %42728
  %42730 = or i1 %42727, %42729
  %42731 = load i32, i32* %57, align 4
  %42732 = icmp eq i32 %42574, %42731
  %42733 = or i1 %42730, %42732
  %42734 = load i32, i32* %58, align 4
  %42735 = icmp eq i32 %42574, %42734
  %42736 = or i1 %42733, %42735
  %42737 = load i32, i32* %59, align 4
  %42738 = icmp eq i32 %42574, %42737
  %42739 = or i1 %42736, %42738
  %42740 = load i32, i32* %60, align 4
  %42741 = icmp eq i32 %42574, %42740
  %42742 = or i1 %42739, %42741
  %42743 = load i32, i32* %61, align 4
  %42744 = icmp eq i32 %42574, %42743
  %42745 = or i1 %42742, %42744
  %42746 = load i32, i32* %62, align 4
  %42747 = icmp eq i32 %42574, %42746
  %42748 = or i1 %42745, %42747
  %42749 = getelementptr i8, i8 addrspace(1)* %4, i32 156
  %42750 = zext i1 %42748 to i8
  store i8 %42750, i8 addrspace(1)* %42749, align 1, !nosanitize !3
  %42751 = load i256, i256* %42573, align 4
  %42752 = mul i256 255, 1, !pc !630, !intsan !45
  %42753 = xor i256 %42752, -1
  %42754 = and i256 %42753, %42751
  %42755 = alloca i256, align 8
  store i256 %42571, i256* %42755, align 4
  %42756 = alloca i256, align 8
  store i256 %42754, i256* %42756, align 4
  call void @__device_sstore(i256* %42755, i256* %42756)
  %42757 = call i32 @__hashword(i256* %42755)
  store i32 %42757, i32* %13, align 4, !nosanitize !3
  %42758 = load i64, i64* %STACK_DEP_PTR, align 4
  %42759 = add i64 %42758, 1
  store i64 %42759, i64* %STACK_DEP_PTR, align 4
  %42760 = load i64, i64* %STACK_DEP_PTR, align 4
  %42761 = getelementptr i256, i256* %STACK, i64 %42760
  store i256 %40204, i256* %42761, align 4
  %42762 = load i64, i64* %STACK_DEP_PTR, align 4
  %42763 = add i64 %42762, 1
  store i64 %42763, i64* %STACK_DEP_PTR, align 4
  %42764 = load i64, i64* %STACK_DEP_PTR, align 4
  %42765 = getelementptr i256, i256* %STACK, i64 %42764
  store i256 %40216, i256* %42765, align 4
  %42766 = load i64, i64* %STACK_DEP_PTR, align 4
  %42767 = add i64 %42766, 1
  store i64 %42767, i64* %STACK_DEP_PTR, align 4
  %42768 = load i64, i64* %STACK_DEP_PTR, align 4
  %42769 = getelementptr i256, i256* %STACK, i64 %42768
  store i256 %40215, i256* %42769, align 4
  %42770 = load i64, i64* %STACK_DEP_PTR, align 4
  %42771 = add i64 %42770, 1
  store i64 %42771, i64* %STACK_DEP_PTR, align 4
  %42772 = load i64, i64* %STACK_DEP_PTR, align 4
  %42773 = getelementptr i256, i256* %STACK, i64 %42772
  store i256 %41027, i256* %42773, align 4
  br label %.13753

.13753:                                           ; preds = %.13354, %40170, %JumpTable
  %42774 = load i64, i64* %remaing_gas, align 4
  %42775 = icmp ugt i64 736, %42774
  br i1 %42775, label %Abort, label %42776

42776:                                            ; preds = %.13753
  %42777 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %42778 = xor i32 %42777, 961
  %42779 = urem i32 %42778, 4096
  %42780 = getelementptr i8, i8 addrspace(1)* %4, i32 %42779
  %42781 = load i8, i8 addrspace(1)* %42780, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %42780, align 1, !nosanitize !3
  store i32 480, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %42782 = sub i64 %42774, 736
  store i64 %42782, i64* %remaing_gas, align 4
  %42783 = load i64, i64* %STACK_DEP_PTR, align 4
  %42784 = getelementptr i256, i256* %STACK, i64 %42783
  %42785 = load i256, i256* %42784, align 4
  %42786 = load i64, i64* %STACK_DEP_PTR, align 4
  %42787 = sub i64 %42786, 1
  store i64 %42787, i64* %STACK_DEP_PTR, align 4
  %42788 = load i64, i64* %STACK_DEP_PTR, align 4
  %42789 = getelementptr i256, i256* %STACK, i64 %42788
  %42790 = load i256, i256* %42789, align 4
  %42791 = load i64, i64* %STACK_DEP_PTR, align 4
  %42792 = sub i64 %42791, 1
  store i64 %42792, i64* %STACK_DEP_PTR, align 4
  %42793 = load i64, i64* %STACK_DEP_PTR, align 4
  %42794 = getelementptr i256, i256* %STACK, i64 %42793
  %42795 = load i256, i256* %42794, align 4
  %42796 = load i64, i64* %STACK_DEP_PTR, align 4
  %42797 = sub i64 %42796, 1
  store i64 %42797, i64* %STACK_DEP_PTR, align 4
  %42798 = load i64, i64* %STACK_DEP_PTR, align 4
  %42799 = getelementptr i256, i256* %STACK, i64 %42798
  %42800 = load i256, i256* %42799, align 4
  %42801 = load i64, i64* %STACK_DEP_PTR, align 4
  %42802 = sub i64 %42801, 1
  store i64 %42802, i64* %STACK_DEP_PTR, align 4
  %42803 = load i64, i64* %STACK_DEP_PTR, align 4
  %42804 = getelementptr i256, i256* %STACK, i64 %42803
  %42805 = load i256, i256* %42804, align 4
  %42806 = load i64, i64* %STACK_DEP_PTR, align 4
  %42807 = sub i64 %42806, 1
  store i64 %42807, i64* %STACK_DEP_PTR, align 4
  %42808 = alloca i256, align 8
  store i256 5, i256* %42808, align 4
  %42809 = alloca i256, align 8
  call void @__device_sload(i256* %42808, i256* %42809)
  %42810 = call i32 @__hashword(i256* %42808)
  %42811 = load i32, i32* %5, align 4
  %42812 = icmp eq i32 %42810, %42811
  %42813 = or i1 false, %42812
  %42814 = load i32, i32* %6, align 4
  %42815 = icmp eq i32 %42810, %42814
  %42816 = or i1 %42813, %42815
  %42817 = load i32, i32* %7, align 4
  %42818 = icmp eq i32 %42810, %42817
  %42819 = or i1 %42816, %42818
  %42820 = load i32, i32* %8, align 4
  %42821 = icmp eq i32 %42810, %42820
  %42822 = or i1 %42819, %42821
  %42823 = load i32, i32* %9, align 4
  %42824 = icmp eq i32 %42810, %42823
  %42825 = or i1 %42822, %42824
  %42826 = load i32, i32* %10, align 4
  %42827 = icmp eq i32 %42810, %42826
  %42828 = or i1 %42825, %42827
  %42829 = load i32, i32* %11, align 4
  %42830 = icmp eq i32 %42810, %42829
  %42831 = or i1 %42828, %42830
  %42832 = load i32, i32* %12, align 4
  %42833 = icmp eq i32 %42810, %42832
  %42834 = or i1 %42831, %42833
  %42835 = load i32, i32* %13, align 4
  %42836 = icmp eq i32 %42810, %42835
  %42837 = or i1 %42834, %42836
  %42838 = load i32, i32* %14, align 4
  %42839 = icmp eq i32 %42810, %42838
  %42840 = or i1 %42837, %42839
  %42841 = load i32, i32* %15, align 4
  %42842 = icmp eq i32 %42810, %42841
  %42843 = or i1 %42840, %42842
  %42844 = load i32, i32* %16, align 4
  %42845 = icmp eq i32 %42810, %42844
  %42846 = or i1 %42843, %42845
  %42847 = load i32, i32* %17, align 4
  %42848 = icmp eq i32 %42810, %42847
  %42849 = or i1 %42846, %42848
  %42850 = load i32, i32* %18, align 4
  %42851 = icmp eq i32 %42810, %42850
  %42852 = or i1 %42849, %42851
  %42853 = load i32, i32* %19, align 4
  %42854 = icmp eq i32 %42810, %42853
  %42855 = or i1 %42852, %42854
  %42856 = load i32, i32* %20, align 4
  %42857 = icmp eq i32 %42810, %42856
  %42858 = or i1 %42855, %42857
  %42859 = load i32, i32* %21, align 4
  %42860 = icmp eq i32 %42810, %42859
  %42861 = or i1 %42858, %42860
  %42862 = load i32, i32* %22, align 4
  %42863 = icmp eq i32 %42810, %42862
  %42864 = or i1 %42861, %42863
  %42865 = load i32, i32* %23, align 4
  %42866 = icmp eq i32 %42810, %42865
  %42867 = or i1 %42864, %42866
  %42868 = load i32, i32* %24, align 4
  %42869 = icmp eq i32 %42810, %42868
  %42870 = or i1 %42867, %42869
  %42871 = load i32, i32* %25, align 4
  %42872 = icmp eq i32 %42810, %42871
  %42873 = or i1 %42870, %42872
  %42874 = load i32, i32* %26, align 4
  %42875 = icmp eq i32 %42810, %42874
  %42876 = or i1 %42873, %42875
  %42877 = load i32, i32* %27, align 4
  %42878 = icmp eq i32 %42810, %42877
  %42879 = or i1 %42876, %42878
  %42880 = load i32, i32* %28, align 4
  %42881 = icmp eq i32 %42810, %42880
  %42882 = or i1 %42879, %42881
  %42883 = load i32, i32* %29, align 4
  %42884 = icmp eq i32 %42810, %42883
  %42885 = or i1 %42882, %42884
  %42886 = load i32, i32* %30, align 4
  %42887 = icmp eq i32 %42810, %42886
  %42888 = or i1 %42885, %42887
  %42889 = load i32, i32* %31, align 4
  %42890 = icmp eq i32 %42810, %42889
  %42891 = or i1 %42888, %42890
  %42892 = load i32, i32* %32, align 4
  %42893 = icmp eq i32 %42810, %42892
  %42894 = or i1 %42891, %42893
  %42895 = load i32, i32* %33, align 4
  %42896 = icmp eq i32 %42810, %42895
  %42897 = or i1 %42894, %42896
  %42898 = load i32, i32* %34, align 4
  %42899 = icmp eq i32 %42810, %42898
  %42900 = or i1 %42897, %42899
  %42901 = load i32, i32* %35, align 4
  %42902 = icmp eq i32 %42810, %42901
  %42903 = or i1 %42900, %42902
  %42904 = load i32, i32* %36, align 4
  %42905 = icmp eq i32 %42810, %42904
  %42906 = or i1 %42903, %42905
  %42907 = load i32, i32* %37, align 4
  %42908 = icmp eq i32 %42810, %42907
  %42909 = or i1 %42906, %42908
  %42910 = load i32, i32* %38, align 4
  %42911 = icmp eq i32 %42810, %42910
  %42912 = or i1 %42909, %42911
  %42913 = load i32, i32* %39, align 4
  %42914 = icmp eq i32 %42810, %42913
  %42915 = or i1 %42912, %42914
  %42916 = load i32, i32* %40, align 4
  %42917 = icmp eq i32 %42810, %42916
  %42918 = or i1 %42915, %42917
  %42919 = load i32, i32* %41, align 4
  %42920 = icmp eq i32 %42810, %42919
  %42921 = or i1 %42918, %42920
  %42922 = load i32, i32* %42, align 4
  %42923 = icmp eq i32 %42810, %42922
  %42924 = or i1 %42921, %42923
  %42925 = load i32, i32* %43, align 4
  %42926 = icmp eq i32 %42810, %42925
  %42927 = or i1 %42924, %42926
  %42928 = load i32, i32* %44, align 4
  %42929 = icmp eq i32 %42810, %42928
  %42930 = or i1 %42927, %42929
  %42931 = load i32, i32* %45, align 4
  %42932 = icmp eq i32 %42810, %42931
  %42933 = or i1 %42930, %42932
  %42934 = load i32, i32* %46, align 4
  %42935 = icmp eq i32 %42810, %42934
  %42936 = or i1 %42933, %42935
  %42937 = load i32, i32* %47, align 4
  %42938 = icmp eq i32 %42810, %42937
  %42939 = or i1 %42936, %42938
  %42940 = load i32, i32* %48, align 4
  %42941 = icmp eq i32 %42810, %42940
  %42942 = or i1 %42939, %42941
  %42943 = load i32, i32* %49, align 4
  %42944 = icmp eq i32 %42810, %42943
  %42945 = or i1 %42942, %42944
  %42946 = load i32, i32* %50, align 4
  %42947 = icmp eq i32 %42810, %42946
  %42948 = or i1 %42945, %42947
  %42949 = load i32, i32* %51, align 4
  %42950 = icmp eq i32 %42810, %42949
  %42951 = or i1 %42948, %42950
  %42952 = load i32, i32* %52, align 4
  %42953 = icmp eq i32 %42810, %42952
  %42954 = or i1 %42951, %42953
  %42955 = load i32, i32* %53, align 4
  %42956 = icmp eq i32 %42810, %42955
  %42957 = or i1 %42954, %42956
  %42958 = load i32, i32* %54, align 4
  %42959 = icmp eq i32 %42810, %42958
  %42960 = or i1 %42957, %42959
  %42961 = load i32, i32* %55, align 4
  %42962 = icmp eq i32 %42810, %42961
  %42963 = or i1 %42960, %42962
  %42964 = load i32, i32* %56, align 4
  %42965 = icmp eq i32 %42810, %42964
  %42966 = or i1 %42963, %42965
  %42967 = load i32, i32* %57, align 4
  %42968 = icmp eq i32 %42810, %42967
  %42969 = or i1 %42966, %42968
  %42970 = load i32, i32* %58, align 4
  %42971 = icmp eq i32 %42810, %42970
  %42972 = or i1 %42969, %42971
  %42973 = load i32, i32* %59, align 4
  %42974 = icmp eq i32 %42810, %42973
  %42975 = or i1 %42972, %42974
  %42976 = load i32, i32* %60, align 4
  %42977 = icmp eq i32 %42810, %42976
  %42978 = or i1 %42975, %42977
  %42979 = load i32, i32* %61, align 4
  %42980 = icmp eq i32 %42810, %42979
  %42981 = or i1 %42978, %42980
  %42982 = load i32, i32* %62, align 4
  %42983 = icmp eq i32 %42810, %42982
  %42984 = or i1 %42981, %42983
  %42985 = getelementptr i8, i8 addrspace(1)* %4, i32 157
  %42986 = zext i1 %42984 to i8
  store i8 %42986, i8 addrspace(1)* %42985, align 1, !nosanitize !3
  %42987 = load i256, i256* %42809, align 4
  %42988 = sub i256 %42987, 1, !pc !631, !intsan !8
  %42989 = alloca i256, align 8
  store i256 5, i256* %42989, align 4
  %42990 = alloca i256, align 8
  store i256 %42988, i256* %42990, align 4
  call void @__device_sstore(i256* %42989, i256* %42990)
  %42991 = call i32 @__hashword(i256* %42989)
  store i32 %42991, i32* %14, align 4, !nosanitize !3
  %42992 = trunc i256 14584 to i64
  %42993 = load i64, i64* %STACK_DEP_PTR, align 4
  %42994 = add i64 %42993, 1
  store i64 %42994, i64* %STACK_DEP_PTR, align 4
  %42995 = load i64, i64* %STACK_DEP_PTR, align 4
  %42996 = getelementptr i256, i256* %STACK, i64 %42995
  store i256 %42805, i256* %42996, align 4
  %42997 = load i64, i64* %STACK_DEP_PTR, align 4
  %42998 = add i64 %42997, 1
  store i64 %42998, i64* %STACK_DEP_PTR, align 4
  %42999 = load i64, i64* %STACK_DEP_PTR, align 4
  %43000 = getelementptr i256, i256* %STACK, i64 %42999
  store i256 %42800, i256* %43000, align 4
  %43001 = load i64, i64* %STACK_DEP_PTR, align 4
  %43002 = add i64 %43001, 1
  store i64 %43002, i64* %STACK_DEP_PTR, align 4
  %43003 = load i64, i64* %STACK_DEP_PTR, align 4
  %43004 = getelementptr i256, i256* %STACK, i64 %43003
  store i256 %42795, i256* %43004, align 4
  %43005 = load i64, i64* %STACK_DEP_PTR, align 4
  %43006 = add i64 %43005, 1
  store i64 %43006, i64* %STACK_DEP_PTR, align 4
  %43007 = load i64, i64* %STACK_DEP_PTR, align 4
  %43008 = getelementptr i256, i256* %STACK, i64 %43007
  store i256 %42790, i256* %43008, align 4
  %43009 = load i64, i64* %STACK_DEP_PTR, align 4
  %43010 = add i64 %43009, 1
  store i64 %43010, i64* %STACK_DEP_PTR, align 4
  %43011 = load i64, i64* %STACK_DEP_PTR, align 4
  %43012 = getelementptr i256, i256* %STACK, i64 %43011
  store i256 %42785, i256* %43012, align 4
  %43013 = load i64, i64* %STACK_DEP_PTR, align 4
  %43014 = add i64 %43013, 1
  store i64 %43014, i64* %STACK_DEP_PTR, align 4
  %43015 = load i64, i64* %STACK_DEP_PTR, align 4
  %43016 = getelementptr i256, i256* %STACK, i64 %43015
  store i256 13782, i256* %43016, align 4
  %43017 = load i64, i64* %STACK_DEP_PTR, align 4
  %43018 = add i64 %43017, 1
  store i64 %43018, i64* %STACK_DEP_PTR, align 4
  %43019 = load i64, i64* %STACK_DEP_PTR, align 4
  %43020 = getelementptr i256, i256* %STACK, i64 %43019
  store i256 %42805, i256* %43020, align 4
  %43021 = load i64, i64* %STACK_DEP_PTR, align 4
  %43022 = add i64 %43021, 1
  store i64 %43022, i64* %STACK_DEP_PTR, align 4
  %43023 = load i64, i64* %STACK_DEP_PTR, align 4
  %43024 = getelementptr i256, i256* %STACK, i64 %43023
  store i256 %42795, i256* %43024, align 4
  br label %.14584, !EVMBB !4

.13782:                                           ; preds = %JumpTable
  %43025 = load i64, i64* %remaing_gas, align 4
  %43026 = icmp ugt i64 464, %43025
  br i1 %43026, label %Abort, label %43027

43027:                                            ; preds = %.13782
  %43028 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43029 = xor i32 %43028, 199
  %43030 = urem i32 %43029, 4096
  %43031 = getelementptr i8, i8 addrspace(1)* %4, i32 %43030
  %43032 = load i8, i8 addrspace(1)* %43031, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43031, align 1, !nosanitize !3
  store i32 99, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43033 = sub i64 %43025, 464
  store i64 %43033, i64* %remaing_gas, align 4
  %43034 = load i64, i64* %STACK_DEP_PTR, align 4
  %43035 = getelementptr i256, i256* %STACK, i64 %43034
  %43036 = load i256, i256* %43035, align 4
  %43037 = load i64, i64* %STACK_DEP_PTR, align 4
  %43038 = sub i64 %43037, 1
  store i64 %43038, i64* %STACK_DEP_PTR, align 4
  %43039 = load i64, i64* %STACK_DEP_PTR, align 4
  %43040 = getelementptr i256, i256* %STACK, i64 %43039
  %43041 = load i256, i256* %43040, align 4
  %43042 = load i64, i64* %STACK_DEP_PTR, align 4
  %43043 = sub i64 %43042, 1
  store i64 %43043, i64* %STACK_DEP_PTR, align 4
  %43044 = alloca i256, align 8
  store i256 8, i256* %43044, align 4
  %43045 = alloca i256, align 8
  call void @__device_sload(i256* %43044, i256* %43045)
  %43046 = call i32 @__hashword(i256* %43044)
  %43047 = load i32, i32* %5, align 4
  %43048 = icmp eq i32 %43046, %43047
  %43049 = or i1 false, %43048
  %43050 = load i32, i32* %6, align 4
  %43051 = icmp eq i32 %43046, %43050
  %43052 = or i1 %43049, %43051
  %43053 = load i32, i32* %7, align 4
  %43054 = icmp eq i32 %43046, %43053
  %43055 = or i1 %43052, %43054
  %43056 = load i32, i32* %8, align 4
  %43057 = icmp eq i32 %43046, %43056
  %43058 = or i1 %43055, %43057
  %43059 = load i32, i32* %9, align 4
  %43060 = icmp eq i32 %43046, %43059
  %43061 = or i1 %43058, %43060
  %43062 = load i32, i32* %10, align 4
  %43063 = icmp eq i32 %43046, %43062
  %43064 = or i1 %43061, %43063
  %43065 = load i32, i32* %11, align 4
  %43066 = icmp eq i32 %43046, %43065
  %43067 = or i1 %43064, %43066
  %43068 = load i32, i32* %12, align 4
  %43069 = icmp eq i32 %43046, %43068
  %43070 = or i1 %43067, %43069
  %43071 = load i32, i32* %13, align 4
  %43072 = icmp eq i32 %43046, %43071
  %43073 = or i1 %43070, %43072
  %43074 = load i32, i32* %14, align 4
  %43075 = icmp eq i32 %43046, %43074
  %43076 = or i1 %43073, %43075
  %43077 = load i32, i32* %15, align 4
  %43078 = icmp eq i32 %43046, %43077
  %43079 = or i1 %43076, %43078
  %43080 = load i32, i32* %16, align 4
  %43081 = icmp eq i32 %43046, %43080
  %43082 = or i1 %43079, %43081
  %43083 = load i32, i32* %17, align 4
  %43084 = icmp eq i32 %43046, %43083
  %43085 = or i1 %43082, %43084
  %43086 = load i32, i32* %18, align 4
  %43087 = icmp eq i32 %43046, %43086
  %43088 = or i1 %43085, %43087
  %43089 = load i32, i32* %19, align 4
  %43090 = icmp eq i32 %43046, %43089
  %43091 = or i1 %43088, %43090
  %43092 = load i32, i32* %20, align 4
  %43093 = icmp eq i32 %43046, %43092
  %43094 = or i1 %43091, %43093
  %43095 = load i32, i32* %21, align 4
  %43096 = icmp eq i32 %43046, %43095
  %43097 = or i1 %43094, %43096
  %43098 = load i32, i32* %22, align 4
  %43099 = icmp eq i32 %43046, %43098
  %43100 = or i1 %43097, %43099
  %43101 = load i32, i32* %23, align 4
  %43102 = icmp eq i32 %43046, %43101
  %43103 = or i1 %43100, %43102
  %43104 = load i32, i32* %24, align 4
  %43105 = icmp eq i32 %43046, %43104
  %43106 = or i1 %43103, %43105
  %43107 = load i32, i32* %25, align 4
  %43108 = icmp eq i32 %43046, %43107
  %43109 = or i1 %43106, %43108
  %43110 = load i32, i32* %26, align 4
  %43111 = icmp eq i32 %43046, %43110
  %43112 = or i1 %43109, %43111
  %43113 = load i32, i32* %27, align 4
  %43114 = icmp eq i32 %43046, %43113
  %43115 = or i1 %43112, %43114
  %43116 = load i32, i32* %28, align 4
  %43117 = icmp eq i32 %43046, %43116
  %43118 = or i1 %43115, %43117
  %43119 = load i32, i32* %29, align 4
  %43120 = icmp eq i32 %43046, %43119
  %43121 = or i1 %43118, %43120
  %43122 = load i32, i32* %30, align 4
  %43123 = icmp eq i32 %43046, %43122
  %43124 = or i1 %43121, %43123
  %43125 = load i32, i32* %31, align 4
  %43126 = icmp eq i32 %43046, %43125
  %43127 = or i1 %43124, %43126
  %43128 = load i32, i32* %32, align 4
  %43129 = icmp eq i32 %43046, %43128
  %43130 = or i1 %43127, %43129
  %43131 = load i32, i32* %33, align 4
  %43132 = icmp eq i32 %43046, %43131
  %43133 = or i1 %43130, %43132
  %43134 = load i32, i32* %34, align 4
  %43135 = icmp eq i32 %43046, %43134
  %43136 = or i1 %43133, %43135
  %43137 = load i32, i32* %35, align 4
  %43138 = icmp eq i32 %43046, %43137
  %43139 = or i1 %43136, %43138
  %43140 = load i32, i32* %36, align 4
  %43141 = icmp eq i32 %43046, %43140
  %43142 = or i1 %43139, %43141
  %43143 = load i32, i32* %37, align 4
  %43144 = icmp eq i32 %43046, %43143
  %43145 = or i1 %43142, %43144
  %43146 = load i32, i32* %38, align 4
  %43147 = icmp eq i32 %43046, %43146
  %43148 = or i1 %43145, %43147
  %43149 = load i32, i32* %39, align 4
  %43150 = icmp eq i32 %43046, %43149
  %43151 = or i1 %43148, %43150
  %43152 = load i32, i32* %40, align 4
  %43153 = icmp eq i32 %43046, %43152
  %43154 = or i1 %43151, %43153
  %43155 = load i32, i32* %41, align 4
  %43156 = icmp eq i32 %43046, %43155
  %43157 = or i1 %43154, %43156
  %43158 = load i32, i32* %42, align 4
  %43159 = icmp eq i32 %43046, %43158
  %43160 = or i1 %43157, %43159
  %43161 = load i32, i32* %43, align 4
  %43162 = icmp eq i32 %43046, %43161
  %43163 = or i1 %43160, %43162
  %43164 = load i32, i32* %44, align 4
  %43165 = icmp eq i32 %43046, %43164
  %43166 = or i1 %43163, %43165
  %43167 = load i32, i32* %45, align 4
  %43168 = icmp eq i32 %43046, %43167
  %43169 = or i1 %43166, %43168
  %43170 = load i32, i32* %46, align 4
  %43171 = icmp eq i32 %43046, %43170
  %43172 = or i1 %43169, %43171
  %43173 = load i32, i32* %47, align 4
  %43174 = icmp eq i32 %43046, %43173
  %43175 = or i1 %43172, %43174
  %43176 = load i32, i32* %48, align 4
  %43177 = icmp eq i32 %43046, %43176
  %43178 = or i1 %43175, %43177
  %43179 = load i32, i32* %49, align 4
  %43180 = icmp eq i32 %43046, %43179
  %43181 = or i1 %43178, %43180
  %43182 = load i32, i32* %50, align 4
  %43183 = icmp eq i32 %43046, %43182
  %43184 = or i1 %43181, %43183
  %43185 = load i32, i32* %51, align 4
  %43186 = icmp eq i32 %43046, %43185
  %43187 = or i1 %43184, %43186
  %43188 = load i32, i32* %52, align 4
  %43189 = icmp eq i32 %43046, %43188
  %43190 = or i1 %43187, %43189
  %43191 = load i32, i32* %53, align 4
  %43192 = icmp eq i32 %43046, %43191
  %43193 = or i1 %43190, %43192
  %43194 = load i32, i32* %54, align 4
  %43195 = icmp eq i32 %43046, %43194
  %43196 = or i1 %43193, %43195
  %43197 = load i32, i32* %55, align 4
  %43198 = icmp eq i32 %43046, %43197
  %43199 = or i1 %43196, %43198
  %43200 = load i32, i32* %56, align 4
  %43201 = icmp eq i32 %43046, %43200
  %43202 = or i1 %43199, %43201
  %43203 = load i32, i32* %57, align 4
  %43204 = icmp eq i32 %43046, %43203
  %43205 = or i1 %43202, %43204
  %43206 = load i32, i32* %58, align 4
  %43207 = icmp eq i32 %43046, %43206
  %43208 = or i1 %43205, %43207
  %43209 = load i32, i32* %59, align 4
  %43210 = icmp eq i32 %43046, %43209
  %43211 = or i1 %43208, %43210
  %43212 = load i32, i32* %60, align 4
  %43213 = icmp eq i32 %43046, %43212
  %43214 = or i1 %43211, %43213
  %43215 = load i32, i32* %61, align 4
  %43216 = icmp eq i32 %43046, %43215
  %43217 = or i1 %43214, %43216
  %43218 = load i32, i32* %62, align 4
  %43219 = icmp eq i32 %43046, %43218
  %43220 = or i1 %43217, %43219
  %43221 = getelementptr i8, i8 addrspace(1)* %4, i32 158
  %43222 = zext i1 %43220 to i8
  store i8 %43222, i8 addrspace(1)* %43221, align 1, !nosanitize !3
  %43223 = load i256, i256* %43045, align 4
  %43224 = alloca i256, align 8
  store i256 %43223, i256* %43224, align 4
  %43225 = alloca i256, align 8
  store i256 1, i256* %43225, align 4
  %43226 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %43224, i256* %43225, i256* %43226), !pc !632, !intsan !6
  %43227 = load i256, i256* %43226, align 4
  %43228 = and i256 1461501637330902918203684832716283019655932542975, %43227
  %43229 = trunc i256 14584 to i64
  %43230 = load i64, i64* %STACK_DEP_PTR, align 4
  %43231 = add i64 %43230, 1
  store i64 %43231, i64* %STACK_DEP_PTR, align 4
  %43232 = load i64, i64* %STACK_DEP_PTR, align 4
  %43233 = getelementptr i256, i256* %STACK, i64 %43232
  store i256 %43041, i256* %43233, align 4
  %43234 = load i64, i64* %STACK_DEP_PTR, align 4
  %43235 = add i64 %43234, 1
  store i64 %43235, i64* %STACK_DEP_PTR, align 4
  %43236 = load i64, i64* %STACK_DEP_PTR, align 4
  %43237 = getelementptr i256, i256* %STACK, i64 %43236
  store i256 %43036, i256* %43237, align 4
  %43238 = load i64, i64* %STACK_DEP_PTR, align 4
  %43239 = add i64 %43238, 1
  store i64 %43239, i64* %STACK_DEP_PTR, align 4
  %43240 = load i64, i64* %STACK_DEP_PTR, align 4
  %43241 = getelementptr i256, i256* %STACK, i64 %43240
  store i256 13826, i256* %43241, align 4
  %43242 = load i64, i64* %STACK_DEP_PTR, align 4
  %43243 = add i64 %43242, 1
  store i64 %43243, i64* %STACK_DEP_PTR, align 4
  %43244 = load i64, i64* %STACK_DEP_PTR, align 4
  %43245 = getelementptr i256, i256* %STACK, i64 %43244
  store i256 %43228, i256* %43245, align 4
  %43246 = load i64, i64* %STACK_DEP_PTR, align 4
  %43247 = add i64 %43246, 1
  store i64 %43247, i64* %STACK_DEP_PTR, align 4
  %43248 = load i64, i64* %STACK_DEP_PTR, align 4
  %43249 = getelementptr i256, i256* %STACK, i64 %43248
  store i256 %43041, i256* %43249, align 4
  br label %.14584, !EVMBB !4

.13826:                                           ; preds = %JumpTable
  %43250 = load i64, i64* %remaing_gas, align 4
  %43251 = icmp ugt i64 704, %43250
  br i1 %43251, label %Abort, label %43252

43252:                                            ; preds = %.13826
  %43253 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43254 = xor i32 %43253, 740
  %43255 = urem i32 %43254, 4096
  %43256 = getelementptr i8, i8 addrspace(1)* %4, i32 %43255
  %43257 = load i8, i8 addrspace(1)* %43256, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43256, align 1, !nosanitize !3
  store i32 370, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43258 = sub i64 %43250, 704
  store i64 %43258, i64* %remaing_gas, align 4
  %43259 = load i64, i64* %STACK_DEP_PTR, align 4
  %43260 = getelementptr i256, i256* %STACK, i64 %43259
  %43261 = load i256, i256* %43260, align 4
  %43262 = load i64, i64* %STACK_DEP_PTR, align 4
  %43263 = sub i64 %43262, 1
  store i64 %43263, i64* %STACK_DEP_PTR, align 4
  %43264 = load i64, i64* %STACK_DEP_PTR, align 4
  %43265 = getelementptr i256, i256* %STACK, i64 %43264
  %43266 = load i256, i256* %43265, align 4
  %43267 = load i64, i64* %STACK_DEP_PTR, align 4
  %43268 = sub i64 %43267, 1
  store i64 %43268, i64* %STACK_DEP_PTR, align 4
  %43269 = load i64, i64* %STACK_DEP_PTR, align 4
  %43270 = getelementptr i256, i256* %STACK, i64 %43269
  %43271 = load i256, i256* %43270, align 4
  %43272 = load i64, i64* %STACK_DEP_PTR, align 4
  %43273 = sub i64 %43272, 1
  store i64 %43273, i64* %STACK_DEP_PTR, align 4
  %43274 = load i64, i64* %STACK_DEP_PTR, align 4
  %43275 = getelementptr i256, i256* %STACK, i64 %43274
  %43276 = load i256, i256* %43275, align 4
  %43277 = load i64, i64* %STACK_DEP_PTR, align 4
  %43278 = sub i64 %43277, 1
  store i64 %43278, i64* %STACK_DEP_PTR, align 4
  %43279 = load i64, i64* %STACK_DEP_PTR, align 4
  %43280 = getelementptr i256, i256* %STACK, i64 %43279
  %43281 = load i256, i256* %43280, align 4
  %43282 = load i64, i64* %STACK_DEP_PTR, align 4
  %43283 = sub i64 %43282, 1
  store i64 %43283, i64* %STACK_DEP_PTR, align 4
  %43284 = trunc i256 64 to i64
  %43285 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %43284, i256* %43285)
  %43286 = load i256, i256* %43285, align 4
  %43287 = and i256 1461501637330902918203684832716283019655932542975, %43281
  %43288 = and i256 1461501637330902918203684832716283019655932542975, %43287
  %43289 = trunc i256 %43286 to i64
  %43290 = alloca i256, align 8
  store i256 %43288, i256* %43290, align 4
  %43291 = bitcast i256* %43290 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %43289, i8* %43291, i64 32)
  %43292 = add i256 32, %43286, !pc !633, !intsan !10
  %43293 = trunc i256 %43292 to i64
  %43294 = alloca i256, align 8
  store i256 %43271, i256* %43294, align 4
  %43295 = bitcast i256* %43294 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %43293, i8* %43295, i64 32)
  %43296 = add i256 32, %43292, !pc !634, !intsan !10
  %43297 = trunc i256 64 to i64
  %43298 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %43297, i256* %43298)
  %43299 = load i256, i256* %43298, align 4
  %43300 = sub i256 %43296, %43299, !pc !635, !intsan !8
  %43301 = trunc i256 21779269187102215415525935841880160856169780320566889044378441848627263180596 to i64
  call void @addBugSet(i64 %43301)
  %43302 = trunc i256 14010 to i64
  %43303 = load i64, i64* %STACK_DEP_PTR, align 4
  %43304 = add i64 %43303, 1
  store i64 %43304, i64* %STACK_DEP_PTR, align 4
  %43305 = load i64, i64* %STACK_DEP_PTR, align 4
  %43306 = getelementptr i256, i256* %STACK, i64 %43305
  store i256 %43281, i256* %43306, align 4
  %43307 = load i64, i64* %STACK_DEP_PTR, align 4
  %43308 = add i64 %43307, 1
  store i64 %43308, i64* %STACK_DEP_PTR, align 4
  %43309 = load i64, i64* %STACK_DEP_PTR, align 4
  %43310 = getelementptr i256, i256* %STACK, i64 %43309
  store i256 %43276, i256* %43310, align 4
  %43311 = load i64, i64* %STACK_DEP_PTR, align 4
  %43312 = add i64 %43311, 1
  store i64 %43312, i64* %STACK_DEP_PTR, align 4
  %43313 = load i64, i64* %STACK_DEP_PTR, align 4
  %43314 = getelementptr i256, i256* %STACK, i64 %43313
  store i256 %43271, i256* %43314, align 4
  %43315 = load i64, i64* %STACK_DEP_PTR, align 4
  %43316 = add i64 %43315, 1
  store i64 %43316, i64* %STACK_DEP_PTR, align 4
  %43317 = load i64, i64* %STACK_DEP_PTR, align 4
  %43318 = getelementptr i256, i256* %STACK, i64 %43317
  store i256 %43266, i256* %43318, align 4
  %43319 = load i64, i64* %STACK_DEP_PTR, align 4
  %43320 = add i64 %43319, 1
  store i64 %43320, i64* %STACK_DEP_PTR, align 4
  %43321 = load i64, i64* %STACK_DEP_PTR, align 4
  %43322 = getelementptr i256, i256* %STACK, i64 %43321
  store i256 %43261, i256* %43322, align 4
  br label %.14010, !EVMBB !4

.13938:                                           ; preds = %39314, %JumpTable
  %43323 = alloca i256, align 8
  store i256 8, i256* %43323, align 4
  %43324 = alloca i256, align 8
  call void @__device_sload(i256* %43323, i256* %43324)
  %43325 = call i32 @__hashword(i256* %43323)
  %43326 = load i32, i32* %5, align 4
  %43327 = icmp eq i32 %43325, %43326
  %43328 = or i1 false, %43327
  %43329 = load i32, i32* %6, align 4
  %43330 = icmp eq i32 %43325, %43329
  %43331 = or i1 %43328, %43330
  %43332 = load i32, i32* %7, align 4
  %43333 = icmp eq i32 %43325, %43332
  %43334 = or i1 %43331, %43333
  %43335 = load i32, i32* %8, align 4
  %43336 = icmp eq i32 %43325, %43335
  %43337 = or i1 %43334, %43336
  %43338 = load i32, i32* %9, align 4
  %43339 = icmp eq i32 %43325, %43338
  %43340 = or i1 %43337, %43339
  %43341 = load i32, i32* %10, align 4
  %43342 = icmp eq i32 %43325, %43341
  %43343 = or i1 %43340, %43342
  %43344 = load i32, i32* %11, align 4
  %43345 = icmp eq i32 %43325, %43344
  %43346 = or i1 %43343, %43345
  %43347 = load i32, i32* %12, align 4
  %43348 = icmp eq i32 %43325, %43347
  %43349 = or i1 %43346, %43348
  %43350 = load i32, i32* %13, align 4
  %43351 = icmp eq i32 %43325, %43350
  %43352 = or i1 %43349, %43351
  %43353 = load i32, i32* %14, align 4
  %43354 = icmp eq i32 %43325, %43353
  %43355 = or i1 %43352, %43354
  %43356 = load i32, i32* %15, align 4
  %43357 = icmp eq i32 %43325, %43356
  %43358 = or i1 %43355, %43357
  %43359 = load i32, i32* %16, align 4
  %43360 = icmp eq i32 %43325, %43359
  %43361 = or i1 %43358, %43360
  %43362 = load i32, i32* %17, align 4
  %43363 = icmp eq i32 %43325, %43362
  %43364 = or i1 %43361, %43363
  %43365 = load i32, i32* %18, align 4
  %43366 = icmp eq i32 %43325, %43365
  %43367 = or i1 %43364, %43366
  %43368 = load i32, i32* %19, align 4
  %43369 = icmp eq i32 %43325, %43368
  %43370 = or i1 %43367, %43369
  %43371 = load i32, i32* %20, align 4
  %43372 = icmp eq i32 %43325, %43371
  %43373 = or i1 %43370, %43372
  %43374 = load i32, i32* %21, align 4
  %43375 = icmp eq i32 %43325, %43374
  %43376 = or i1 %43373, %43375
  %43377 = load i32, i32* %22, align 4
  %43378 = icmp eq i32 %43325, %43377
  %43379 = or i1 %43376, %43378
  %43380 = load i32, i32* %23, align 4
  %43381 = icmp eq i32 %43325, %43380
  %43382 = or i1 %43379, %43381
  %43383 = load i32, i32* %24, align 4
  %43384 = icmp eq i32 %43325, %43383
  %43385 = or i1 %43382, %43384
  %43386 = load i32, i32* %25, align 4
  %43387 = icmp eq i32 %43325, %43386
  %43388 = or i1 %43385, %43387
  %43389 = load i32, i32* %26, align 4
  %43390 = icmp eq i32 %43325, %43389
  %43391 = or i1 %43388, %43390
  %43392 = load i32, i32* %27, align 4
  %43393 = icmp eq i32 %43325, %43392
  %43394 = or i1 %43391, %43393
  %43395 = load i32, i32* %28, align 4
  %43396 = icmp eq i32 %43325, %43395
  %43397 = or i1 %43394, %43396
  %43398 = load i32, i32* %29, align 4
  %43399 = icmp eq i32 %43325, %43398
  %43400 = or i1 %43397, %43399
  %43401 = load i32, i32* %30, align 4
  %43402 = icmp eq i32 %43325, %43401
  %43403 = or i1 %43400, %43402
  %43404 = load i32, i32* %31, align 4
  %43405 = icmp eq i32 %43325, %43404
  %43406 = or i1 %43403, %43405
  %43407 = load i32, i32* %32, align 4
  %43408 = icmp eq i32 %43325, %43407
  %43409 = or i1 %43406, %43408
  %43410 = load i32, i32* %33, align 4
  %43411 = icmp eq i32 %43325, %43410
  %43412 = or i1 %43409, %43411
  %43413 = load i32, i32* %34, align 4
  %43414 = icmp eq i32 %43325, %43413
  %43415 = or i1 %43412, %43414
  %43416 = load i32, i32* %35, align 4
  %43417 = icmp eq i32 %43325, %43416
  %43418 = or i1 %43415, %43417
  %43419 = load i32, i32* %36, align 4
  %43420 = icmp eq i32 %43325, %43419
  %43421 = or i1 %43418, %43420
  %43422 = load i32, i32* %37, align 4
  %43423 = icmp eq i32 %43325, %43422
  %43424 = or i1 %43421, %43423
  %43425 = load i32, i32* %38, align 4
  %43426 = icmp eq i32 %43325, %43425
  %43427 = or i1 %43424, %43426
  %43428 = load i32, i32* %39, align 4
  %43429 = icmp eq i32 %43325, %43428
  %43430 = or i1 %43427, %43429
  %43431 = load i32, i32* %40, align 4
  %43432 = icmp eq i32 %43325, %43431
  %43433 = or i1 %43430, %43432
  %43434 = load i32, i32* %41, align 4
  %43435 = icmp eq i32 %43325, %43434
  %43436 = or i1 %43433, %43435
  %43437 = load i32, i32* %42, align 4
  %43438 = icmp eq i32 %43325, %43437
  %43439 = or i1 %43436, %43438
  %43440 = load i32, i32* %43, align 4
  %43441 = icmp eq i32 %43325, %43440
  %43442 = or i1 %43439, %43441
  %43443 = load i32, i32* %44, align 4
  %43444 = icmp eq i32 %43325, %43443
  %43445 = or i1 %43442, %43444
  %43446 = load i32, i32* %45, align 4
  %43447 = icmp eq i32 %43325, %43446
  %43448 = or i1 %43445, %43447
  %43449 = load i32, i32* %46, align 4
  %43450 = icmp eq i32 %43325, %43449
  %43451 = or i1 %43448, %43450
  %43452 = load i32, i32* %47, align 4
  %43453 = icmp eq i32 %43325, %43452
  %43454 = or i1 %43451, %43453
  %43455 = load i32, i32* %48, align 4
  %43456 = icmp eq i32 %43325, %43455
  %43457 = or i1 %43454, %43456
  %43458 = load i32, i32* %49, align 4
  %43459 = icmp eq i32 %43325, %43458
  %43460 = or i1 %43457, %43459
  %43461 = load i32, i32* %50, align 4
  %43462 = icmp eq i32 %43325, %43461
  %43463 = or i1 %43460, %43462
  %43464 = load i32, i32* %51, align 4
  %43465 = icmp eq i32 %43325, %43464
  %43466 = or i1 %43463, %43465
  %43467 = load i32, i32* %52, align 4
  %43468 = icmp eq i32 %43325, %43467
  %43469 = or i1 %43466, %43468
  %43470 = load i32, i32* %53, align 4
  %43471 = icmp eq i32 %43325, %43470
  %43472 = or i1 %43469, %43471
  %43473 = load i32, i32* %54, align 4
  %43474 = icmp eq i32 %43325, %43473
  %43475 = or i1 %43472, %43474
  %43476 = load i32, i32* %55, align 4
  %43477 = icmp eq i32 %43325, %43476
  %43478 = or i1 %43475, %43477
  %43479 = load i32, i32* %56, align 4
  %43480 = icmp eq i32 %43325, %43479
  %43481 = or i1 %43478, %43480
  %43482 = load i32, i32* %57, align 4
  %43483 = icmp eq i32 %43325, %43482
  %43484 = or i1 %43481, %43483
  %43485 = load i32, i32* %58, align 4
  %43486 = icmp eq i32 %43325, %43485
  %43487 = or i1 %43484, %43486
  %43488 = load i32, i32* %59, align 4
  %43489 = icmp eq i32 %43325, %43488
  %43490 = or i1 %43487, %43489
  %43491 = load i32, i32* %60, align 4
  %43492 = icmp eq i32 %43325, %43491
  %43493 = or i1 %43490, %43492
  %43494 = load i32, i32* %61, align 4
  %43495 = icmp eq i32 %43325, %43494
  %43496 = or i1 %43493, %43495
  %43497 = load i32, i32* %62, align 4
  %43498 = icmp eq i32 %43325, %43497
  %43499 = or i1 %43496, %43498
  %43500 = getelementptr i8, i8 addrspace(1)* %4, i32 159
  %43501 = zext i1 %43499 to i8
  store i8 %43501, i8 addrspace(1)* %43500, align 1, !nosanitize !3
  %43502 = load i256, i256* %43324, align 4
  %43503 = mul i256 255, 1461501637330902918203684832716283019655932542976, !pc !636, !intsan !45
  %43504 = xor i256 %43503, -1
  %43505 = and i256 %43504, %43502
  %43506 = icmp eq i256 1, 0
  %43507 = icmp eq i1 %43506, false
  %43508 = zext i1 %43507 to i256
  %43509 = mul i256 %43508, 1461501637330902918203684832716283019655932542976, !pc !637, !intsan !45
  %43510 = or i256 %43509, %43505
  %43511 = alloca i256, align 8
  store i256 8, i256* %43511, align 4
  %43512 = alloca i256, align 8
  store i256 %43510, i256* %43512, align 4
  call void @__device_sstore(i256* %43511, i256* %43512)
  %43513 = call i32 @__hashword(i256* %43511)
  store i32 %43513, i32* %18, align 4, !nosanitize !3
  %43514 = trunc i256 64 to i64
  %43515 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %43514, i256* %43515)
  %43516 = load i256, i256* %43515, align 4
  %43517 = trunc i256 64 to i64
  %43518 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %43517, i256* %43518)
  %43519 = load i256, i256* %43518, align 4
  %43520 = sub i256 %43516, %43519, !pc !638, !intsan !8
  %43521 = trunc i256 37495094437807398806302164849837153474977970768503765070072680779894391288602 to i64
  call void @addBugSet(i64 %43521)
  br label %.14010

.14010:                                           ; preds = %.13938, %43252, %JumpTable
  %43522 = load i64, i64* %remaing_gas, align 4
  %43523 = icmp ugt i64 88, %43522
  br i1 %43523, label %Abort, label %43524

43524:                                            ; preds = %.14010
  %43525 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43526 = xor i32 %43525, 2596
  %43527 = urem i32 %43526, 4096
  %43528 = getelementptr i8, i8 addrspace(1)* %4, i32 %43527
  %43529 = load i8, i8 addrspace(1)* %43528, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43528, align 1, !nosanitize !3
  store i32 1298, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43530 = sub i64 %43522, 88
  store i64 %43530, i64* %remaing_gas, align 4
  %43531 = alloca i256, align 8
  store i256 5, i256* %43531, align 4
  %43532 = alloca i256, align 8
  call void @__device_sload(i256* %43531, i256* %43532)
  %43533 = call i32 @__hashword(i256* %43531)
  %43534 = load i32, i32* %5, align 4
  %43535 = icmp eq i32 %43533, %43534
  %43536 = or i1 false, %43535
  %43537 = load i32, i32* %6, align 4
  %43538 = icmp eq i32 %43533, %43537
  %43539 = or i1 %43536, %43538
  %43540 = load i32, i32* %7, align 4
  %43541 = icmp eq i32 %43533, %43540
  %43542 = or i1 %43539, %43541
  %43543 = load i32, i32* %8, align 4
  %43544 = icmp eq i32 %43533, %43543
  %43545 = or i1 %43542, %43544
  %43546 = load i32, i32* %9, align 4
  %43547 = icmp eq i32 %43533, %43546
  %43548 = or i1 %43545, %43547
  %43549 = load i32, i32* %10, align 4
  %43550 = icmp eq i32 %43533, %43549
  %43551 = or i1 %43548, %43550
  %43552 = load i32, i32* %11, align 4
  %43553 = icmp eq i32 %43533, %43552
  %43554 = or i1 %43551, %43553
  %43555 = load i32, i32* %12, align 4
  %43556 = icmp eq i32 %43533, %43555
  %43557 = or i1 %43554, %43556
  %43558 = load i32, i32* %13, align 4
  %43559 = icmp eq i32 %43533, %43558
  %43560 = or i1 %43557, %43559
  %43561 = load i32, i32* %14, align 4
  %43562 = icmp eq i32 %43533, %43561
  %43563 = or i1 %43560, %43562
  %43564 = load i32, i32* %15, align 4
  %43565 = icmp eq i32 %43533, %43564
  %43566 = or i1 %43563, %43565
  %43567 = load i32, i32* %16, align 4
  %43568 = icmp eq i32 %43533, %43567
  %43569 = or i1 %43566, %43568
  %43570 = load i32, i32* %17, align 4
  %43571 = icmp eq i32 %43533, %43570
  %43572 = or i1 %43569, %43571
  %43573 = load i32, i32* %18, align 4
  %43574 = icmp eq i32 %43533, %43573
  %43575 = or i1 %43572, %43574
  %43576 = load i32, i32* %19, align 4
  %43577 = icmp eq i32 %43533, %43576
  %43578 = or i1 %43575, %43577
  %43579 = load i32, i32* %20, align 4
  %43580 = icmp eq i32 %43533, %43579
  %43581 = or i1 %43578, %43580
  %43582 = load i32, i32* %21, align 4
  %43583 = icmp eq i32 %43533, %43582
  %43584 = or i1 %43581, %43583
  %43585 = load i32, i32* %22, align 4
  %43586 = icmp eq i32 %43533, %43585
  %43587 = or i1 %43584, %43586
  %43588 = load i32, i32* %23, align 4
  %43589 = icmp eq i32 %43533, %43588
  %43590 = or i1 %43587, %43589
  %43591 = load i32, i32* %24, align 4
  %43592 = icmp eq i32 %43533, %43591
  %43593 = or i1 %43590, %43592
  %43594 = load i32, i32* %25, align 4
  %43595 = icmp eq i32 %43533, %43594
  %43596 = or i1 %43593, %43595
  %43597 = load i32, i32* %26, align 4
  %43598 = icmp eq i32 %43533, %43597
  %43599 = or i1 %43596, %43598
  %43600 = load i32, i32* %27, align 4
  %43601 = icmp eq i32 %43533, %43600
  %43602 = or i1 %43599, %43601
  %43603 = load i32, i32* %28, align 4
  %43604 = icmp eq i32 %43533, %43603
  %43605 = or i1 %43602, %43604
  %43606 = load i32, i32* %29, align 4
  %43607 = icmp eq i32 %43533, %43606
  %43608 = or i1 %43605, %43607
  %43609 = load i32, i32* %30, align 4
  %43610 = icmp eq i32 %43533, %43609
  %43611 = or i1 %43608, %43610
  %43612 = load i32, i32* %31, align 4
  %43613 = icmp eq i32 %43533, %43612
  %43614 = or i1 %43611, %43613
  %43615 = load i32, i32* %32, align 4
  %43616 = icmp eq i32 %43533, %43615
  %43617 = or i1 %43614, %43616
  %43618 = load i32, i32* %33, align 4
  %43619 = icmp eq i32 %43533, %43618
  %43620 = or i1 %43617, %43619
  %43621 = load i32, i32* %34, align 4
  %43622 = icmp eq i32 %43533, %43621
  %43623 = or i1 %43620, %43622
  %43624 = load i32, i32* %35, align 4
  %43625 = icmp eq i32 %43533, %43624
  %43626 = or i1 %43623, %43625
  %43627 = load i32, i32* %36, align 4
  %43628 = icmp eq i32 %43533, %43627
  %43629 = or i1 %43626, %43628
  %43630 = load i32, i32* %37, align 4
  %43631 = icmp eq i32 %43533, %43630
  %43632 = or i1 %43629, %43631
  %43633 = load i32, i32* %38, align 4
  %43634 = icmp eq i32 %43533, %43633
  %43635 = or i1 %43632, %43634
  %43636 = load i32, i32* %39, align 4
  %43637 = icmp eq i32 %43533, %43636
  %43638 = or i1 %43635, %43637
  %43639 = load i32, i32* %40, align 4
  %43640 = icmp eq i32 %43533, %43639
  %43641 = or i1 %43638, %43640
  %43642 = load i32, i32* %41, align 4
  %43643 = icmp eq i32 %43533, %43642
  %43644 = or i1 %43641, %43643
  %43645 = load i32, i32* %42, align 4
  %43646 = icmp eq i32 %43533, %43645
  %43647 = or i1 %43644, %43646
  %43648 = load i32, i32* %43, align 4
  %43649 = icmp eq i32 %43533, %43648
  %43650 = or i1 %43647, %43649
  %43651 = load i32, i32* %44, align 4
  %43652 = icmp eq i32 %43533, %43651
  %43653 = or i1 %43650, %43652
  %43654 = load i32, i32* %45, align 4
  %43655 = icmp eq i32 %43533, %43654
  %43656 = or i1 %43653, %43655
  %43657 = load i32, i32* %46, align 4
  %43658 = icmp eq i32 %43533, %43657
  %43659 = or i1 %43656, %43658
  %43660 = load i32, i32* %47, align 4
  %43661 = icmp eq i32 %43533, %43660
  %43662 = or i1 %43659, %43661
  %43663 = load i32, i32* %48, align 4
  %43664 = icmp eq i32 %43533, %43663
  %43665 = or i1 %43662, %43664
  %43666 = load i32, i32* %49, align 4
  %43667 = icmp eq i32 %43533, %43666
  %43668 = or i1 %43665, %43667
  %43669 = load i32, i32* %50, align 4
  %43670 = icmp eq i32 %43533, %43669
  %43671 = or i1 %43668, %43670
  %43672 = load i32, i32* %51, align 4
  %43673 = icmp eq i32 %43533, %43672
  %43674 = or i1 %43671, %43673
  %43675 = load i32, i32* %52, align 4
  %43676 = icmp eq i32 %43533, %43675
  %43677 = or i1 %43674, %43676
  %43678 = load i32, i32* %53, align 4
  %43679 = icmp eq i32 %43533, %43678
  %43680 = or i1 %43677, %43679
  %43681 = load i32, i32* %54, align 4
  %43682 = icmp eq i32 %43533, %43681
  %43683 = or i1 %43680, %43682
  %43684 = load i32, i32* %55, align 4
  %43685 = icmp eq i32 %43533, %43684
  %43686 = or i1 %43683, %43685
  %43687 = load i32, i32* %56, align 4
  %43688 = icmp eq i32 %43533, %43687
  %43689 = or i1 %43686, %43688
  %43690 = load i32, i32* %57, align 4
  %43691 = icmp eq i32 %43533, %43690
  %43692 = or i1 %43689, %43691
  %43693 = load i32, i32* %58, align 4
  %43694 = icmp eq i32 %43533, %43693
  %43695 = or i1 %43692, %43694
  %43696 = load i32, i32* %59, align 4
  %43697 = icmp eq i32 %43533, %43696
  %43698 = or i1 %43695, %43697
  %43699 = load i32, i32* %60, align 4
  %43700 = icmp eq i32 %43533, %43699
  %43701 = or i1 %43698, %43700
  %43702 = load i32, i32* %61, align 4
  %43703 = icmp eq i32 %43533, %43702
  %43704 = or i1 %43701, %43703
  %43705 = load i32, i32* %62, align 4
  %43706 = icmp eq i32 %43533, %43705
  %43707 = or i1 %43704, %43706
  %43708 = getelementptr i8, i8 addrspace(1)* %4, i32 160
  %43709 = zext i1 %43707 to i8
  store i8 %43709, i8 addrspace(1)* %43708, align 1, !nosanitize !3
  %43710 = load i256, i256* %43532, align 4
  %43711 = icmp ugt i256 %43710, 10
  %43712 = icmp eq i1 %43711, false
  %43713 = trunc i256 14026 to i64
  %jump.check218 = icmp ne i1 %43712, false
  br i1 %jump.check218, label %.14026, label %.14022, !EVMBB !4

.14022:                                           ; preds = %43524
  %43714 = load i64, i64* %remaing_gas, align 4
  %43715 = icmp ugt i64 16, %43714
  br i1 %43715, label %Abort, label %43716

43716:                                            ; preds = %.14022
  %43717 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43718 = xor i32 %43717, 3715
  %43719 = urem i32 %43718, 4096
  %43720 = getelementptr i8, i8 addrspace(1)* %4, i32 %43719
  %43721 = load i8, i8 addrspace(1)* %43720, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43720, align 1, !nosanitize !3
  store i32 1857, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43722 = sub i64 %43714, 16
  store i64 %43722, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.14026:                                           ; preds = %43524, %JumpTable
  %43723 = load i64, i64* %remaing_gas, align 4
  %43724 = icmp ugt i64 320, %43723
  br i1 %43724, label %Abort, label %43725

43725:                                            ; preds = %.14026
  %43726 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43727 = xor i32 %43726, 2663
  %43728 = urem i32 %43727, 4096
  %43729 = getelementptr i8, i8 addrspace(1)* %4, i32 %43728
  %43730 = load i8, i8 addrspace(1)* %43729, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43729, align 1, !nosanitize !3
  store i32 1331, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43731 = sub i64 %43723, 320
  store i64 %43731, i64* %remaing_gas, align 4
  %43732 = load i64, i64* %STACK_DEP_PTR, align 4
  %43733 = getelementptr i256, i256* %STACK, i64 %43732
  %43734 = load i256, i256* %43733, align 4
  %43735 = load i64, i64* %STACK_DEP_PTR, align 4
  %43736 = sub i64 %43735, 1
  store i64 %43736, i64* %STACK_DEP_PTR, align 4
  %43737 = load i64, i64* %STACK_DEP_PTR, align 4
  %43738 = getelementptr i256, i256* %STACK, i64 %43737
  %43739 = load i256, i256* %43738, align 4
  %43740 = load i64, i64* %STACK_DEP_PTR, align 4
  %43741 = sub i64 %43740, 1
  store i64 %43741, i64* %STACK_DEP_PTR, align 4
  %43742 = load i64, i64* %STACK_DEP_PTR, align 4
  %43743 = getelementptr i256, i256* %STACK, i64 %43742
  %43744 = load i256, i256* %43743, align 4
  %43745 = load i64, i64* %STACK_DEP_PTR, align 4
  %43746 = sub i64 %43745, 1
  store i64 %43746, i64* %STACK_DEP_PTR, align 4
  %43747 = load i64, i64* %STACK_DEP_PTR, align 4
  %43748 = getelementptr i256, i256* %STACK, i64 %43747
  %43749 = load i256, i256* %43748, align 4
  %43750 = load i64, i64* %STACK_DEP_PTR, align 4
  %43751 = sub i64 %43750, 1
  store i64 %43751, i64* %STACK_DEP_PTR, align 4
  %43752 = load i64, i64* %STACK_DEP_PTR, align 4
  %43753 = getelementptr i256, i256* %STACK, i64 %43752
  %43754 = load i256, i256* %43753, align 4
  %43755 = load i64, i64* %STACK_DEP_PTR, align 4
  %43756 = sub i64 %43755, 1
  store i64 %43756, i64* %STACK_DEP_PTR, align 4
  %43757 = load i64, i64* %STACK_DEP_PTR, align 4
  %43758 = getelementptr i256, i256* %STACK, i64 %43757
  %43759 = load i256, i256* %43758, align 4
  %43760 = load i64, i64* %STACK_DEP_PTR, align 4
  %43761 = sub i64 %43760, 1
  store i64 %43761, i64* %STACK_DEP_PTR, align 4
  %43762 = trunc i256 %43759 to i64
  store i64 %43762, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.14033:                                           ; preds = %14546, %JumpTable
  %43763 = load i64, i64* %remaing_gas, align 4
  %43764 = icmp ugt i64 208, %43763
  br i1 %43764, label %Abort, label %43765

43765:                                            ; preds = %.14033
  %43766 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43767 = xor i32 %43766, 216
  %43768 = urem i32 %43767, 4096
  %43769 = getelementptr i8, i8 addrspace(1)* %4, i32 %43768
  %43770 = load i8, i8 addrspace(1)* %43769, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43769, align 1, !nosanitize !3
  store i32 108, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43771 = sub i64 %43763, 208
  store i64 %43771, i64* %remaing_gas, align 4
  %43772 = alloca i256, align 8
  store i256 0, i256* %43772, align 4
  %43773 = alloca i256, align 8
  call void @__device_sload(i256* %43772, i256* %43773)
  %43774 = call i32 @__hashword(i256* %43772)
  %43775 = load i32, i32* %5, align 4
  %43776 = icmp eq i32 %43774, %43775
  %43777 = or i1 false, %43776
  %43778 = load i32, i32* %6, align 4
  %43779 = icmp eq i32 %43774, %43778
  %43780 = or i1 %43777, %43779
  %43781 = load i32, i32* %7, align 4
  %43782 = icmp eq i32 %43774, %43781
  %43783 = or i1 %43780, %43782
  %43784 = load i32, i32* %8, align 4
  %43785 = icmp eq i32 %43774, %43784
  %43786 = or i1 %43783, %43785
  %43787 = load i32, i32* %9, align 4
  %43788 = icmp eq i32 %43774, %43787
  %43789 = or i1 %43786, %43788
  %43790 = load i32, i32* %10, align 4
  %43791 = icmp eq i32 %43774, %43790
  %43792 = or i1 %43789, %43791
  %43793 = load i32, i32* %11, align 4
  %43794 = icmp eq i32 %43774, %43793
  %43795 = or i1 %43792, %43794
  %43796 = load i32, i32* %12, align 4
  %43797 = icmp eq i32 %43774, %43796
  %43798 = or i1 %43795, %43797
  %43799 = load i32, i32* %13, align 4
  %43800 = icmp eq i32 %43774, %43799
  %43801 = or i1 %43798, %43800
  %43802 = load i32, i32* %14, align 4
  %43803 = icmp eq i32 %43774, %43802
  %43804 = or i1 %43801, %43803
  %43805 = load i32, i32* %15, align 4
  %43806 = icmp eq i32 %43774, %43805
  %43807 = or i1 %43804, %43806
  %43808 = load i32, i32* %16, align 4
  %43809 = icmp eq i32 %43774, %43808
  %43810 = or i1 %43807, %43809
  %43811 = load i32, i32* %17, align 4
  %43812 = icmp eq i32 %43774, %43811
  %43813 = or i1 %43810, %43812
  %43814 = load i32, i32* %18, align 4
  %43815 = icmp eq i32 %43774, %43814
  %43816 = or i1 %43813, %43815
  %43817 = load i32, i32* %19, align 4
  %43818 = icmp eq i32 %43774, %43817
  %43819 = or i1 %43816, %43818
  %43820 = load i32, i32* %20, align 4
  %43821 = icmp eq i32 %43774, %43820
  %43822 = or i1 %43819, %43821
  %43823 = load i32, i32* %21, align 4
  %43824 = icmp eq i32 %43774, %43823
  %43825 = or i1 %43822, %43824
  %43826 = load i32, i32* %22, align 4
  %43827 = icmp eq i32 %43774, %43826
  %43828 = or i1 %43825, %43827
  %43829 = load i32, i32* %23, align 4
  %43830 = icmp eq i32 %43774, %43829
  %43831 = or i1 %43828, %43830
  %43832 = load i32, i32* %24, align 4
  %43833 = icmp eq i32 %43774, %43832
  %43834 = or i1 %43831, %43833
  %43835 = load i32, i32* %25, align 4
  %43836 = icmp eq i32 %43774, %43835
  %43837 = or i1 %43834, %43836
  %43838 = load i32, i32* %26, align 4
  %43839 = icmp eq i32 %43774, %43838
  %43840 = or i1 %43837, %43839
  %43841 = load i32, i32* %27, align 4
  %43842 = icmp eq i32 %43774, %43841
  %43843 = or i1 %43840, %43842
  %43844 = load i32, i32* %28, align 4
  %43845 = icmp eq i32 %43774, %43844
  %43846 = or i1 %43843, %43845
  %43847 = load i32, i32* %29, align 4
  %43848 = icmp eq i32 %43774, %43847
  %43849 = or i1 %43846, %43848
  %43850 = load i32, i32* %30, align 4
  %43851 = icmp eq i32 %43774, %43850
  %43852 = or i1 %43849, %43851
  %43853 = load i32, i32* %31, align 4
  %43854 = icmp eq i32 %43774, %43853
  %43855 = or i1 %43852, %43854
  %43856 = load i32, i32* %32, align 4
  %43857 = icmp eq i32 %43774, %43856
  %43858 = or i1 %43855, %43857
  %43859 = load i32, i32* %33, align 4
  %43860 = icmp eq i32 %43774, %43859
  %43861 = or i1 %43858, %43860
  %43862 = load i32, i32* %34, align 4
  %43863 = icmp eq i32 %43774, %43862
  %43864 = or i1 %43861, %43863
  %43865 = load i32, i32* %35, align 4
  %43866 = icmp eq i32 %43774, %43865
  %43867 = or i1 %43864, %43866
  %43868 = load i32, i32* %36, align 4
  %43869 = icmp eq i32 %43774, %43868
  %43870 = or i1 %43867, %43869
  %43871 = load i32, i32* %37, align 4
  %43872 = icmp eq i32 %43774, %43871
  %43873 = or i1 %43870, %43872
  %43874 = load i32, i32* %38, align 4
  %43875 = icmp eq i32 %43774, %43874
  %43876 = or i1 %43873, %43875
  %43877 = load i32, i32* %39, align 4
  %43878 = icmp eq i32 %43774, %43877
  %43879 = or i1 %43876, %43878
  %43880 = load i32, i32* %40, align 4
  %43881 = icmp eq i32 %43774, %43880
  %43882 = or i1 %43879, %43881
  %43883 = load i32, i32* %41, align 4
  %43884 = icmp eq i32 %43774, %43883
  %43885 = or i1 %43882, %43884
  %43886 = load i32, i32* %42, align 4
  %43887 = icmp eq i32 %43774, %43886
  %43888 = or i1 %43885, %43887
  %43889 = load i32, i32* %43, align 4
  %43890 = icmp eq i32 %43774, %43889
  %43891 = or i1 %43888, %43890
  %43892 = load i32, i32* %44, align 4
  %43893 = icmp eq i32 %43774, %43892
  %43894 = or i1 %43891, %43893
  %43895 = load i32, i32* %45, align 4
  %43896 = icmp eq i32 %43774, %43895
  %43897 = or i1 %43894, %43896
  %43898 = load i32, i32* %46, align 4
  %43899 = icmp eq i32 %43774, %43898
  %43900 = or i1 %43897, %43899
  %43901 = load i32, i32* %47, align 4
  %43902 = icmp eq i32 %43774, %43901
  %43903 = or i1 %43900, %43902
  %43904 = load i32, i32* %48, align 4
  %43905 = icmp eq i32 %43774, %43904
  %43906 = or i1 %43903, %43905
  %43907 = load i32, i32* %49, align 4
  %43908 = icmp eq i32 %43774, %43907
  %43909 = or i1 %43906, %43908
  %43910 = load i32, i32* %50, align 4
  %43911 = icmp eq i32 %43774, %43910
  %43912 = or i1 %43909, %43911
  %43913 = load i32, i32* %51, align 4
  %43914 = icmp eq i32 %43774, %43913
  %43915 = or i1 %43912, %43914
  %43916 = load i32, i32* %52, align 4
  %43917 = icmp eq i32 %43774, %43916
  %43918 = or i1 %43915, %43917
  %43919 = load i32, i32* %53, align 4
  %43920 = icmp eq i32 %43774, %43919
  %43921 = or i1 %43918, %43920
  %43922 = load i32, i32* %54, align 4
  %43923 = icmp eq i32 %43774, %43922
  %43924 = or i1 %43921, %43923
  %43925 = load i32, i32* %55, align 4
  %43926 = icmp eq i32 %43774, %43925
  %43927 = or i1 %43924, %43926
  %43928 = load i32, i32* %56, align 4
  %43929 = icmp eq i32 %43774, %43928
  %43930 = or i1 %43927, %43929
  %43931 = load i32, i32* %57, align 4
  %43932 = icmp eq i32 %43774, %43931
  %43933 = or i1 %43930, %43932
  %43934 = load i32, i32* %58, align 4
  %43935 = icmp eq i32 %43774, %43934
  %43936 = or i1 %43933, %43935
  %43937 = load i32, i32* %59, align 4
  %43938 = icmp eq i32 %43774, %43937
  %43939 = or i1 %43936, %43938
  %43940 = load i32, i32* %60, align 4
  %43941 = icmp eq i32 %43774, %43940
  %43942 = or i1 %43939, %43941
  %43943 = load i32, i32* %61, align 4
  %43944 = icmp eq i32 %43774, %43943
  %43945 = or i1 %43942, %43944
  %43946 = load i32, i32* %62, align 4
  %43947 = icmp eq i32 %43774, %43946
  %43948 = or i1 %43945, %43947
  %43949 = getelementptr i8, i8 addrspace(1)* %4, i32 161
  %43950 = zext i1 %43948 to i8
  store i8 %43950, i8 addrspace(1)* %43949, align 1, !nosanitize !3
  %43951 = load i256, i256* %43773, align 4
  %43952 = alloca i256, align 8
  store i256 %43951, i256* %43952, align 4
  %43953 = alloca i256, align 8
  store i256 1, i256* %43953, align 4
  %43954 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %43952, i256* %43953, i256* %43954), !pc !639, !intsan !6
  %43955 = load i256, i256* %43954, align 4
  %43956 = and i256 1461501637330902918203684832716283019655932542975, %43955
  %43957 = and i256 1461501637330902918203684832716283019655932542975, %43956
  %43958 = icmp eq i256 %43957, 0
  %43959 = icmp eq i1 %43958, false
  %43960 = trunc i256 14110 to i64
  %jump.check66 = icmp ne i1 %43959, false
  %43961 = load i64, i64* %STACK_DEP_PTR, align 4
  %43962 = add i64 %43961, 1
  store i64 %43962, i64* %STACK_DEP_PTR, align 4
  %43963 = load i64, i64* %STACK_DEP_PTR, align 4
  %43964 = getelementptr i256, i256* %STACK, i64 %43963
  store i256 0, i256* %43964, align 4
  br i1 %jump.check66, label %.14110, label %.14099, !EVMBB !4

.14099:                                           ; preds = %43765
  %43965 = load i64, i64* %remaing_gas, align 4
  %43966 = icmp ugt i64 144, %43965
  br i1 %43966, label %Abort, label %43967

43967:                                            ; preds = %.14099
  %43968 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43969 = xor i32 %43968, 2541
  %43970 = urem i32 %43969, 4096
  %43971 = getelementptr i8, i8 addrspace(1)* %4, i32 %43970
  %43972 = load i8, i8 addrspace(1)* %43971, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43971, align 1, !nosanitize !3
  store i32 1270, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43973 = sub i64 %43965, 144
  store i64 %43973, i64* %remaing_gas, align 4
  %43974 = load i64, i64* %STACK_DEP_PTR, align 4
  %43975 = sub i64 %43974, 0
  store i64 %43975, i64* %STACK_DEP_PTR, align 4
  %43976 = trunc i256 17834 to i64
  %43977 = load i64, i64* %STACK_DEP_PTR, align 4
  %43978 = add i64 %43977, 1
  store i64 %43978, i64* %STACK_DEP_PTR, align 4
  %43979 = load i64, i64* %STACK_DEP_PTR, align 4
  %43980 = getelementptr i256, i256* %STACK, i64 %43979
  store i256 14108, i256* %43980, align 4
  %43981 = load i64, i64* %STACK_DEP_PTR, align 4
  %43982 = add i64 %43981, 1
  store i64 %43982, i64* %STACK_DEP_PTR, align 4
  %43983 = load i64, i64* %STACK_DEP_PTR, align 4
  %43984 = getelementptr i256, i256* %STACK, i64 %43983
  store i256 0, i256* %43984, align 4
  br label %.17834, !EVMBB !4

.14108:                                           ; preds = %JumpTable
  %43985 = load i64, i64* %STACK_DEP_PTR, align 4
  %43986 = getelementptr i256, i256* %STACK, i64 %43985
  %43987 = load i256, i256* %43986, align 4
  %43988 = load i64, i64* %STACK_DEP_PTR, align 4
  %43989 = sub i64 %43988, 1
  store i64 %43989, i64* %STACK_DEP_PTR, align 4
  br label %.14110

.14110:                                           ; preds = %.14108, %43765, %JumpTable
  %43990 = load i64, i64* %remaing_gas, align 4
  %43991 = icmp ugt i64 784, %43990
  br i1 %43991, label %Abort, label %43992

43992:                                            ; preds = %.14110
  %43993 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43994 = xor i32 %43993, 406
  %43995 = urem i32 %43994, 4096
  %43996 = getelementptr i8, i8 addrspace(1)* %4, i32 %43995
  %43997 = load i8, i8 addrspace(1)* %43996, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %43996, align 1, !nosanitize !3
  store i32 203, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %43998 = sub i64 %43990, 784
  store i64 %43998, i64* %remaing_gas, align 4
  %43999 = alloca i256, align 8
  store i256 0, i256* %43999, align 4
  %44000 = alloca i256, align 8
  call void @__device_sload(i256* %43999, i256* %44000)
  %44001 = call i32 @__hashword(i256* %43999)
  %44002 = load i32, i32* %5, align 4
  %44003 = icmp eq i32 %44001, %44002
  %44004 = or i1 false, %44003
  %44005 = load i32, i32* %6, align 4
  %44006 = icmp eq i32 %44001, %44005
  %44007 = or i1 %44004, %44006
  %44008 = load i32, i32* %7, align 4
  %44009 = icmp eq i32 %44001, %44008
  %44010 = or i1 %44007, %44009
  %44011 = load i32, i32* %8, align 4
  %44012 = icmp eq i32 %44001, %44011
  %44013 = or i1 %44010, %44012
  %44014 = load i32, i32* %9, align 4
  %44015 = icmp eq i32 %44001, %44014
  %44016 = or i1 %44013, %44015
  %44017 = load i32, i32* %10, align 4
  %44018 = icmp eq i32 %44001, %44017
  %44019 = or i1 %44016, %44018
  %44020 = load i32, i32* %11, align 4
  %44021 = icmp eq i32 %44001, %44020
  %44022 = or i1 %44019, %44021
  %44023 = load i32, i32* %12, align 4
  %44024 = icmp eq i32 %44001, %44023
  %44025 = or i1 %44022, %44024
  %44026 = load i32, i32* %13, align 4
  %44027 = icmp eq i32 %44001, %44026
  %44028 = or i1 %44025, %44027
  %44029 = load i32, i32* %14, align 4
  %44030 = icmp eq i32 %44001, %44029
  %44031 = or i1 %44028, %44030
  %44032 = load i32, i32* %15, align 4
  %44033 = icmp eq i32 %44001, %44032
  %44034 = or i1 %44031, %44033
  %44035 = load i32, i32* %16, align 4
  %44036 = icmp eq i32 %44001, %44035
  %44037 = or i1 %44034, %44036
  %44038 = load i32, i32* %17, align 4
  %44039 = icmp eq i32 %44001, %44038
  %44040 = or i1 %44037, %44039
  %44041 = load i32, i32* %18, align 4
  %44042 = icmp eq i32 %44001, %44041
  %44043 = or i1 %44040, %44042
  %44044 = load i32, i32* %19, align 4
  %44045 = icmp eq i32 %44001, %44044
  %44046 = or i1 %44043, %44045
  %44047 = load i32, i32* %20, align 4
  %44048 = icmp eq i32 %44001, %44047
  %44049 = or i1 %44046, %44048
  %44050 = load i32, i32* %21, align 4
  %44051 = icmp eq i32 %44001, %44050
  %44052 = or i1 %44049, %44051
  %44053 = load i32, i32* %22, align 4
  %44054 = icmp eq i32 %44001, %44053
  %44055 = or i1 %44052, %44054
  %44056 = load i32, i32* %23, align 4
  %44057 = icmp eq i32 %44001, %44056
  %44058 = or i1 %44055, %44057
  %44059 = load i32, i32* %24, align 4
  %44060 = icmp eq i32 %44001, %44059
  %44061 = or i1 %44058, %44060
  %44062 = load i32, i32* %25, align 4
  %44063 = icmp eq i32 %44001, %44062
  %44064 = or i1 %44061, %44063
  %44065 = load i32, i32* %26, align 4
  %44066 = icmp eq i32 %44001, %44065
  %44067 = or i1 %44064, %44066
  %44068 = load i32, i32* %27, align 4
  %44069 = icmp eq i32 %44001, %44068
  %44070 = or i1 %44067, %44069
  %44071 = load i32, i32* %28, align 4
  %44072 = icmp eq i32 %44001, %44071
  %44073 = or i1 %44070, %44072
  %44074 = load i32, i32* %29, align 4
  %44075 = icmp eq i32 %44001, %44074
  %44076 = or i1 %44073, %44075
  %44077 = load i32, i32* %30, align 4
  %44078 = icmp eq i32 %44001, %44077
  %44079 = or i1 %44076, %44078
  %44080 = load i32, i32* %31, align 4
  %44081 = icmp eq i32 %44001, %44080
  %44082 = or i1 %44079, %44081
  %44083 = load i32, i32* %32, align 4
  %44084 = icmp eq i32 %44001, %44083
  %44085 = or i1 %44082, %44084
  %44086 = load i32, i32* %33, align 4
  %44087 = icmp eq i32 %44001, %44086
  %44088 = or i1 %44085, %44087
  %44089 = load i32, i32* %34, align 4
  %44090 = icmp eq i32 %44001, %44089
  %44091 = or i1 %44088, %44090
  %44092 = load i32, i32* %35, align 4
  %44093 = icmp eq i32 %44001, %44092
  %44094 = or i1 %44091, %44093
  %44095 = load i32, i32* %36, align 4
  %44096 = icmp eq i32 %44001, %44095
  %44097 = or i1 %44094, %44096
  %44098 = load i32, i32* %37, align 4
  %44099 = icmp eq i32 %44001, %44098
  %44100 = or i1 %44097, %44099
  %44101 = load i32, i32* %38, align 4
  %44102 = icmp eq i32 %44001, %44101
  %44103 = or i1 %44100, %44102
  %44104 = load i32, i32* %39, align 4
  %44105 = icmp eq i32 %44001, %44104
  %44106 = or i1 %44103, %44105
  %44107 = load i32, i32* %40, align 4
  %44108 = icmp eq i32 %44001, %44107
  %44109 = or i1 %44106, %44108
  %44110 = load i32, i32* %41, align 4
  %44111 = icmp eq i32 %44001, %44110
  %44112 = or i1 %44109, %44111
  %44113 = load i32, i32* %42, align 4
  %44114 = icmp eq i32 %44001, %44113
  %44115 = or i1 %44112, %44114
  %44116 = load i32, i32* %43, align 4
  %44117 = icmp eq i32 %44001, %44116
  %44118 = or i1 %44115, %44117
  %44119 = load i32, i32* %44, align 4
  %44120 = icmp eq i32 %44001, %44119
  %44121 = or i1 %44118, %44120
  %44122 = load i32, i32* %45, align 4
  %44123 = icmp eq i32 %44001, %44122
  %44124 = or i1 %44121, %44123
  %44125 = load i32, i32* %46, align 4
  %44126 = icmp eq i32 %44001, %44125
  %44127 = or i1 %44124, %44126
  %44128 = load i32, i32* %47, align 4
  %44129 = icmp eq i32 %44001, %44128
  %44130 = or i1 %44127, %44129
  %44131 = load i32, i32* %48, align 4
  %44132 = icmp eq i32 %44001, %44131
  %44133 = or i1 %44130, %44132
  %44134 = load i32, i32* %49, align 4
  %44135 = icmp eq i32 %44001, %44134
  %44136 = or i1 %44133, %44135
  %44137 = load i32, i32* %50, align 4
  %44138 = icmp eq i32 %44001, %44137
  %44139 = or i1 %44136, %44138
  %44140 = load i32, i32* %51, align 4
  %44141 = icmp eq i32 %44001, %44140
  %44142 = or i1 %44139, %44141
  %44143 = load i32, i32* %52, align 4
  %44144 = icmp eq i32 %44001, %44143
  %44145 = or i1 %44142, %44144
  %44146 = load i32, i32* %53, align 4
  %44147 = icmp eq i32 %44001, %44146
  %44148 = or i1 %44145, %44147
  %44149 = load i32, i32* %54, align 4
  %44150 = icmp eq i32 %44001, %44149
  %44151 = or i1 %44148, %44150
  %44152 = load i32, i32* %55, align 4
  %44153 = icmp eq i32 %44001, %44152
  %44154 = or i1 %44151, %44153
  %44155 = load i32, i32* %56, align 4
  %44156 = icmp eq i32 %44001, %44155
  %44157 = or i1 %44154, %44156
  %44158 = load i32, i32* %57, align 4
  %44159 = icmp eq i32 %44001, %44158
  %44160 = or i1 %44157, %44159
  %44161 = load i32, i32* %58, align 4
  %44162 = icmp eq i32 %44001, %44161
  %44163 = or i1 %44160, %44162
  %44164 = load i32, i32* %59, align 4
  %44165 = icmp eq i32 %44001, %44164
  %44166 = or i1 %44163, %44165
  %44167 = load i32, i32* %60, align 4
  %44168 = icmp eq i32 %44001, %44167
  %44169 = or i1 %44166, %44168
  %44170 = load i32, i32* %61, align 4
  %44171 = icmp eq i32 %44001, %44170
  %44172 = or i1 %44169, %44171
  %44173 = load i32, i32* %62, align 4
  %44174 = icmp eq i32 %44001, %44173
  %44175 = or i1 %44172, %44174
  %44176 = getelementptr i8, i8 addrspace(1)* %4, i32 162
  %44177 = zext i1 %44175 to i8
  store i8 %44177, i8 addrspace(1)* %44176, align 1, !nosanitize !3
  %44178 = load i256, i256* %44000, align 4
  %44179 = alloca i256, align 8
  store i256 %44178, i256* %44179, align 4
  %44180 = alloca i256, align 8
  store i256 1, i256* %44180, align 4
  %44181 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %44179, i256* %44180, i256* %44181), !pc !640, !intsan !6
  %44182 = load i256, i256* %44181, align 4
  %44183 = and i256 1461501637330902918203684832716283019655932542975, %44182
  %44184 = and i256 1461501637330902918203684832716283019655932542975, %44183
  %44185 = trunc i256 64 to i64
  %44186 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44185, i256* %44186)
  %44187 = load i256, i256* %44186, align 4
  %44188 = and i256 4294967295, 952911921
  %44189 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %44188, !pc !641, !intsan !45
  %44190 = trunc i256 %44187 to i64
  %44191 = alloca i256, align 8
  store i256 %44189, i256* %44191, align 4
  %44192 = bitcast i256* %44191 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %44190, i8* %44192, i64 32)
  %44193 = add i256 4, %44187, !pc !642, !intsan !10
  %44194 = trunc i256 64 to i64
  %44195 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44194, i256* %44195)
  %44196 = load i256, i256* %44195, align 4
  %44197 = sub i256 %44193, %44196, !pc !643, !intsan !8
  %44198 = icmp eq i256 1, 0
  %44199 = icmp eq i1 %44198, false
  %44200 = trunc i256 14243 to i64
  %jump.check70 = icmp ne i1 %44199, false
  %44201 = load i64, i64* %STACK_DEP_PTR, align 4
  %44202 = add i64 %44201, 1
  store i64 %44202, i64* %STACK_DEP_PTR, align 4
  %44203 = load i64, i64* %STACK_DEP_PTR, align 4
  %44204 = getelementptr i256, i256* %STACK, i64 %44203
  store i256 %44184, i256* %44204, align 4
  %44205 = load i64, i64* %STACK_DEP_PTR, align 4
  %44206 = add i64 %44205, 1
  store i64 %44206, i64* %STACK_DEP_PTR, align 4
  %44207 = load i64, i64* %STACK_DEP_PTR, align 4
  %44208 = getelementptr i256, i256* %STACK, i64 %44207
  store i256 952911921, i256* %44208, align 4
  %44209 = load i64, i64* %STACK_DEP_PTR, align 4
  %44210 = add i64 %44209, 1
  store i64 %44210, i64* %STACK_DEP_PTR, align 4
  %44211 = load i64, i64* %STACK_DEP_PTR, align 4
  %44212 = getelementptr i256, i256* %STACK, i64 %44211
  store i256 %44193, i256* %44212, align 4
  %44213 = load i64, i64* %STACK_DEP_PTR, align 4
  %44214 = add i64 %44213, 1
  store i64 %44214, i64* %STACK_DEP_PTR, align 4
  %44215 = load i64, i64* %STACK_DEP_PTR, align 4
  %44216 = getelementptr i256, i256* %STACK, i64 %44215
  store i256 32, i256* %44216, align 4
  %44217 = load i64, i64* %STACK_DEP_PTR, align 4
  %44218 = add i64 %44217, 1
  store i64 %44218, i64* %STACK_DEP_PTR, align 4
  %44219 = load i64, i64* %STACK_DEP_PTR, align 4
  %44220 = getelementptr i256, i256* %STACK, i64 %44219
  store i256 %44196, i256* %44220, align 4
  %44221 = load i64, i64* %STACK_DEP_PTR, align 4
  %44222 = add i64 %44221, 1
  store i64 %44222, i64* %STACK_DEP_PTR, align 4
  %44223 = load i64, i64* %STACK_DEP_PTR, align 4
  %44224 = getelementptr i256, i256* %STACK, i64 %44223
  store i256 %44197, i256* %44224, align 4
  %44225 = load i64, i64* %STACK_DEP_PTR, align 4
  %44226 = add i64 %44225, 1
  store i64 %44226, i64* %STACK_DEP_PTR, align 4
  %44227 = load i64, i64* %STACK_DEP_PTR, align 4
  %44228 = getelementptr i256, i256* %STACK, i64 %44227
  store i256 %44196, i256* %44228, align 4
  %44229 = load i64, i64* %STACK_DEP_PTR, align 4
  %44230 = add i64 %44229, 1
  store i64 %44230, i64* %STACK_DEP_PTR, align 4
  %44231 = load i64, i64* %STACK_DEP_PTR, align 4
  %44232 = getelementptr i256, i256* %STACK, i64 %44231
  store i256 0, i256* %44232, align 4
  %44233 = load i64, i64* %STACK_DEP_PTR, align 4
  %44234 = add i64 %44233, 1
  store i64 %44234, i64* %STACK_DEP_PTR, align 4
  %44235 = load i64, i64* %STACK_DEP_PTR, align 4
  %44236 = getelementptr i256, i256* %STACK, i64 %44235
  store i256 %44184, i256* %44236, align 4
  %44237 = load i64, i64* %STACK_DEP_PTR, align 4
  %44238 = add i64 %44237, 1
  store i64 %44238, i64* %STACK_DEP_PTR, align 4
  %44239 = zext i1 %44198 to i256
  %44240 = load i64, i64* %STACK_DEP_PTR, align 4
  %44241 = getelementptr i256, i256* %STACK, i64 %44240
  store i256 %44239, i256* %44241, align 4
  br i1 %jump.check70, label %.14243, label %.14239, !EVMBB !4

.14239:                                           ; preds = %43992
  %44242 = load i64, i64* %remaing_gas, align 4
  %44243 = icmp ugt i64 40, %44242
  br i1 %44243, label %Abort, label %44244

44244:                                            ; preds = %.14239
  %44245 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44246 = xor i32 %44245, 3858
  %44247 = urem i32 %44246, 4096
  %44248 = getelementptr i8, i8 addrspace(1)* %4, i32 %44247
  %44249 = load i8, i8 addrspace(1)* %44248, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44248, align 1, !nosanitize !3
  store i32 1929, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44250 = sub i64 %44242, 40
  store i64 %44250, i64* %remaing_gas, align 4
  %44251 = load i64, i64* %STACK_DEP_PTR, align 4
  %44252 = sub i64 %44251, 0
  store i64 %44252, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14243:                                           ; preds = %43992, %JumpTable
  %44253 = load i64, i64* %remaing_gas, align 4
  %44254 = icmp ugt i64 456, %44253
  br i1 %44254, label %Abort, label %44255

44255:                                            ; preds = %.14243
  %44256 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44257 = xor i32 %44256, 2028
  %44258 = urem i32 %44257, 4096
  %44259 = getelementptr i8, i8 addrspace(1)* %4, i32 %44258
  %44260 = load i8, i8 addrspace(1)* %44259, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44259, align 1, !nosanitize !3
  store i32 1014, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44261 = sub i64 %44253, 456
  store i64 %44261, i64* %remaing_gas, align 4
  %44262 = load i64, i64* %STACK_DEP_PTR, align 4
  %44263 = getelementptr i256, i256* %STACK, i64 %44262
  %44264 = load i256, i256* %44263, align 4
  %44265 = load i64, i64* %STACK_DEP_PTR, align 4
  %44266 = sub i64 %44265, 1
  store i64 %44266, i64* %STACK_DEP_PTR, align 4
  %44267 = load i64, i64* %STACK_DEP_PTR, align 4
  %44268 = getelementptr i256, i256* %STACK, i64 %44267
  %44269 = load i256, i256* %44268, align 4
  %44270 = load i64, i64* %STACK_DEP_PTR, align 4
  %44271 = sub i64 %44270, 1
  store i64 %44271, i64* %STACK_DEP_PTR, align 4
  %44272 = load i64, i64* %STACK_DEP_PTR, align 4
  %44273 = getelementptr i256, i256* %STACK, i64 %44272
  %44274 = load i256, i256* %44273, align 4
  %44275 = load i64, i64* %STACK_DEP_PTR, align 4
  %44276 = sub i64 %44275, 1
  store i64 %44276, i64* %STACK_DEP_PTR, align 4
  %44277 = load i64, i64* %STACK_DEP_PTR, align 4
  %44278 = getelementptr i256, i256* %STACK, i64 %44277
  %44279 = load i256, i256* %44278, align 4
  %44280 = load i64, i64* %STACK_DEP_PTR, align 4
  %44281 = sub i64 %44280, 1
  store i64 %44281, i64* %STACK_DEP_PTR, align 4
  %44282 = load i64, i64* %STACK_DEP_PTR, align 4
  %44283 = getelementptr i256, i256* %STACK, i64 %44282
  %44284 = load i256, i256* %44283, align 4
  %44285 = load i64, i64* %STACK_DEP_PTR, align 4
  %44286 = sub i64 %44285, 1
  store i64 %44286, i64* %STACK_DEP_PTR, align 4
  %44287 = load i64, i64* %STACK_DEP_PTR, align 4
  %44288 = getelementptr i256, i256* %STACK, i64 %44287
  %44289 = load i256, i256* %44288, align 4
  %44290 = load i64, i64* %STACK_DEP_PTR, align 4
  %44291 = sub i64 %44290, 1
  store i64 %44291, i64* %STACK_DEP_PTR, align 4
  %44292 = load i64, i64* %STACK_DEP_PTR, align 4
  %44293 = getelementptr i256, i256* %STACK, i64 %44292
  %44294 = load i256, i256* %44293, align 4
  %44295 = load i64, i64* %STACK_DEP_PTR, align 4
  %44296 = sub i64 %44295, 1
  store i64 %44296, i64* %STACK_DEP_PTR, align 4
  %44297 = trunc i256 %44269 to i160
  %44298 = call i1 @solidity_call(), !pc !644
  %44299 = icmp eq i1 %44298, false
  %44300 = icmp eq i1 %44299, false
  %44301 = trunc i256 14263 to i64
  %jump.check75 = icmp ne i1 %44300, false
  %44302 = load i64, i64* %STACK_DEP_PTR, align 4
  %44303 = add i64 %44302, 1
  store i64 %44303, i64* %STACK_DEP_PTR, align 4
  %44304 = zext i1 %44299 to i256
  %44305 = load i64, i64* %STACK_DEP_PTR, align 4
  %44306 = getelementptr i256, i256* %STACK, i64 %44305
  store i256 %44304, i256* %44306, align 4
  br i1 %jump.check75, label %.14263, label %.14254, !EVMBB !4

.14254:                                           ; preds = %44255
  %44307 = load i64, i64* %remaing_gas, align 4
  %44308 = icmp ugt i64 40, %44307
  br i1 %44308, label %Abort, label %44309

44309:                                            ; preds = %.14254
  %44310 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44311 = xor i32 %44310, 1349
  %44312 = urem i32 %44311, 4096
  %44313 = getelementptr i8, i8 addrspace(1)* %4, i32 %44312
  %44314 = load i8, i8 addrspace(1)* %44313, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44313, align 1, !nosanitize !3
  store i32 674, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44315 = sub i64 %44307, 40
  store i64 %44315, i64* %remaing_gas, align 4
  %44316 = load i64, i64* %STACK_DEP_PTR, align 4
  %44317 = sub i64 %44316, 0
  store i64 %44317, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14263:                                           ; preds = %44255, %JumpTable
  %44318 = load i64, i64* %remaing_gas, align 4
  %44319 = icmp ugt i64 384, %44318
  br i1 %44319, label %Abort, label %44320

44320:                                            ; preds = %.14263
  %44321 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44322 = xor i32 %44321, 1593
  %44323 = urem i32 %44322, 4096
  %44324 = getelementptr i8, i8 addrspace(1)* %4, i32 %44323
  %44325 = load i8, i8 addrspace(1)* %44324, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44324, align 1, !nosanitize !3
  store i32 796, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44326 = sub i64 %44318, 384
  store i64 %44326, i64* %remaing_gas, align 4
  %44327 = load i64, i64* %STACK_DEP_PTR, align 4
  %44328 = getelementptr i256, i256* %STACK, i64 %44327
  %44329 = load i256, i256* %44328, align 4
  %44330 = load i64, i64* %STACK_DEP_PTR, align 4
  %44331 = sub i64 %44330, 1
  store i64 %44331, i64* %STACK_DEP_PTR, align 4
  %44332 = load i64, i64* %STACK_DEP_PTR, align 4
  %44333 = getelementptr i256, i256* %STACK, i64 %44332
  %44334 = load i256, i256* %44333, align 4
  %44335 = load i64, i64* %STACK_DEP_PTR, align 4
  %44336 = sub i64 %44335, 1
  store i64 %44336, i64* %STACK_DEP_PTR, align 4
  %44337 = load i64, i64* %STACK_DEP_PTR, align 4
  %44338 = getelementptr i256, i256* %STACK, i64 %44337
  %44339 = load i256, i256* %44338, align 4
  %44340 = load i64, i64* %STACK_DEP_PTR, align 4
  %44341 = sub i64 %44340, 1
  store i64 %44341, i64* %STACK_DEP_PTR, align 4
  %44342 = load i64, i64* %STACK_DEP_PTR, align 4
  %44343 = getelementptr i256, i256* %STACK, i64 %44342
  %44344 = load i256, i256* %44343, align 4
  %44345 = load i64, i64* %STACK_DEP_PTR, align 4
  %44346 = sub i64 %44345, 1
  store i64 %44346, i64* %STACK_DEP_PTR, align 4
  %44347 = trunc i256 64 to i64
  %44348 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44347, i256* %44348)
  %44349 = load i256, i256* %44348, align 4
  %44350 = zext i64 0 to i256
  %44351 = icmp ult i256 %44350, 32
  %44352 = icmp eq i1 %44351, false
  %44353 = trunc i256 14285 to i64
  %jump.check81 = icmp ne i1 %44352, false
  %44354 = load i64, i64* %STACK_DEP_PTR, align 4
  %44355 = add i64 %44354, 1
  store i64 %44355, i64* %STACK_DEP_PTR, align 4
  %44356 = load i64, i64* %STACK_DEP_PTR, align 4
  %44357 = getelementptr i256, i256* %STACK, i64 %44356
  store i256 %44349, i256* %44357, align 4
  %44358 = load i64, i64* %STACK_DEP_PTR, align 4
  %44359 = add i64 %44358, 1
  store i64 %44359, i64* %STACK_DEP_PTR, align 4
  %44360 = zext i64 0 to i256
  %44361 = load i64, i64* %STACK_DEP_PTR, align 4
  %44362 = getelementptr i256, i256* %STACK, i64 %44361
  store i256 %44360, i256* %44362, align 4
  br i1 %jump.check81, label %.14285, label %.14281, !EVMBB !4

.14281:                                           ; preds = %44320
  %44363 = load i64, i64* %remaing_gas, align 4
  %44364 = icmp ugt i64 40, %44363
  br i1 %44364, label %Abort, label %44365

44365:                                            ; preds = %.14281
  %44366 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44367 = xor i32 %44366, 770
  %44368 = urem i32 %44367, 4096
  %44369 = getelementptr i8, i8 addrspace(1)* %4, i32 %44368
  %44370 = load i8, i8 addrspace(1)* %44369, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44369, align 1, !nosanitize !3
  store i32 385, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44371 = sub i64 %44363, 40
  store i64 %44371, i64* %remaing_gas, align 4
  %44372 = load i64, i64* %STACK_DEP_PTR, align 4
  %44373 = sub i64 %44372, 0
  store i64 %44373, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14285:                                           ; preds = %44320, %JumpTable
  %44374 = load i64, i64* %remaing_gas, align 4
  %44375 = icmp ugt i64 1056, %44374
  br i1 %44375, label %Abort, label %44376

44376:                                            ; preds = %.14285
  %44377 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44378 = xor i32 %44377, 2264
  %44379 = urem i32 %44378, 4096
  %44380 = getelementptr i8, i8 addrspace(1)* %4, i32 %44379
  %44381 = load i8, i8 addrspace(1)* %44380, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44380, align 1, !nosanitize !3
  store i32 1132, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44382 = sub i64 %44374, 1056
  store i64 %44382, i64* %remaing_gas, align 4
  %44383 = load i64, i64* %STACK_DEP_PTR, align 4
  %44384 = getelementptr i256, i256* %STACK, i64 %44383
  %44385 = load i256, i256* %44384, align 4
  %44386 = load i64, i64* %STACK_DEP_PTR, align 4
  %44387 = sub i64 %44386, 1
  store i64 %44387, i64* %STACK_DEP_PTR, align 4
  %44388 = load i64, i64* %STACK_DEP_PTR, align 4
  %44389 = getelementptr i256, i256* %STACK, i64 %44388
  %44390 = load i256, i256* %44389, align 4
  %44391 = load i64, i64* %STACK_DEP_PTR, align 4
  %44392 = sub i64 %44391, 1
  store i64 %44392, i64* %STACK_DEP_PTR, align 4
  %44393 = add i256 %44390, %44385, !pc !645, !intsan !10
  %44394 = trunc i256 %44390 to i64
  %44395 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44394, i256* %44395)
  %44396 = load i256, i256* %44395, align 4
  %44397 = add i256 32, %44390, !pc !646, !intsan !10
  %44398 = alloca i256, align 8
  store i256 1, i256* %44398, align 4
  %44399 = alloca i256, align 8
  call void @__device_sload(i256* %44398, i256* %44399)
  %44400 = call i32 @__hashword(i256* %44398)
  %44401 = load i32, i32* %5, align 4
  %44402 = icmp eq i32 %44400, %44401
  %44403 = or i1 false, %44402
  %44404 = load i32, i32* %6, align 4
  %44405 = icmp eq i32 %44400, %44404
  %44406 = or i1 %44403, %44405
  %44407 = load i32, i32* %7, align 4
  %44408 = icmp eq i32 %44400, %44407
  %44409 = or i1 %44406, %44408
  %44410 = load i32, i32* %8, align 4
  %44411 = icmp eq i32 %44400, %44410
  %44412 = or i1 %44409, %44411
  %44413 = load i32, i32* %9, align 4
  %44414 = icmp eq i32 %44400, %44413
  %44415 = or i1 %44412, %44414
  %44416 = load i32, i32* %10, align 4
  %44417 = icmp eq i32 %44400, %44416
  %44418 = or i1 %44415, %44417
  %44419 = load i32, i32* %11, align 4
  %44420 = icmp eq i32 %44400, %44419
  %44421 = or i1 %44418, %44420
  %44422 = load i32, i32* %12, align 4
  %44423 = icmp eq i32 %44400, %44422
  %44424 = or i1 %44421, %44423
  %44425 = load i32, i32* %13, align 4
  %44426 = icmp eq i32 %44400, %44425
  %44427 = or i1 %44424, %44426
  %44428 = load i32, i32* %14, align 4
  %44429 = icmp eq i32 %44400, %44428
  %44430 = or i1 %44427, %44429
  %44431 = load i32, i32* %15, align 4
  %44432 = icmp eq i32 %44400, %44431
  %44433 = or i1 %44430, %44432
  %44434 = load i32, i32* %16, align 4
  %44435 = icmp eq i32 %44400, %44434
  %44436 = or i1 %44433, %44435
  %44437 = load i32, i32* %17, align 4
  %44438 = icmp eq i32 %44400, %44437
  %44439 = or i1 %44436, %44438
  %44440 = load i32, i32* %18, align 4
  %44441 = icmp eq i32 %44400, %44440
  %44442 = or i1 %44439, %44441
  %44443 = load i32, i32* %19, align 4
  %44444 = icmp eq i32 %44400, %44443
  %44445 = or i1 %44442, %44444
  %44446 = load i32, i32* %20, align 4
  %44447 = icmp eq i32 %44400, %44446
  %44448 = or i1 %44445, %44447
  %44449 = load i32, i32* %21, align 4
  %44450 = icmp eq i32 %44400, %44449
  %44451 = or i1 %44448, %44450
  %44452 = load i32, i32* %22, align 4
  %44453 = icmp eq i32 %44400, %44452
  %44454 = or i1 %44451, %44453
  %44455 = load i32, i32* %23, align 4
  %44456 = icmp eq i32 %44400, %44455
  %44457 = or i1 %44454, %44456
  %44458 = load i32, i32* %24, align 4
  %44459 = icmp eq i32 %44400, %44458
  %44460 = or i1 %44457, %44459
  %44461 = load i32, i32* %25, align 4
  %44462 = icmp eq i32 %44400, %44461
  %44463 = or i1 %44460, %44462
  %44464 = load i32, i32* %26, align 4
  %44465 = icmp eq i32 %44400, %44464
  %44466 = or i1 %44463, %44465
  %44467 = load i32, i32* %27, align 4
  %44468 = icmp eq i32 %44400, %44467
  %44469 = or i1 %44466, %44468
  %44470 = load i32, i32* %28, align 4
  %44471 = icmp eq i32 %44400, %44470
  %44472 = or i1 %44469, %44471
  %44473 = load i32, i32* %29, align 4
  %44474 = icmp eq i32 %44400, %44473
  %44475 = or i1 %44472, %44474
  %44476 = load i32, i32* %30, align 4
  %44477 = icmp eq i32 %44400, %44476
  %44478 = or i1 %44475, %44477
  %44479 = load i32, i32* %31, align 4
  %44480 = icmp eq i32 %44400, %44479
  %44481 = or i1 %44478, %44480
  %44482 = load i32, i32* %32, align 4
  %44483 = icmp eq i32 %44400, %44482
  %44484 = or i1 %44481, %44483
  %44485 = load i32, i32* %33, align 4
  %44486 = icmp eq i32 %44400, %44485
  %44487 = or i1 %44484, %44486
  %44488 = load i32, i32* %34, align 4
  %44489 = icmp eq i32 %44400, %44488
  %44490 = or i1 %44487, %44489
  %44491 = load i32, i32* %35, align 4
  %44492 = icmp eq i32 %44400, %44491
  %44493 = or i1 %44490, %44492
  %44494 = load i32, i32* %36, align 4
  %44495 = icmp eq i32 %44400, %44494
  %44496 = or i1 %44493, %44495
  %44497 = load i32, i32* %37, align 4
  %44498 = icmp eq i32 %44400, %44497
  %44499 = or i1 %44496, %44498
  %44500 = load i32, i32* %38, align 4
  %44501 = icmp eq i32 %44400, %44500
  %44502 = or i1 %44499, %44501
  %44503 = load i32, i32* %39, align 4
  %44504 = icmp eq i32 %44400, %44503
  %44505 = or i1 %44502, %44504
  %44506 = load i32, i32* %40, align 4
  %44507 = icmp eq i32 %44400, %44506
  %44508 = or i1 %44505, %44507
  %44509 = load i32, i32* %41, align 4
  %44510 = icmp eq i32 %44400, %44509
  %44511 = or i1 %44508, %44510
  %44512 = load i32, i32* %42, align 4
  %44513 = icmp eq i32 %44400, %44512
  %44514 = or i1 %44511, %44513
  %44515 = load i32, i32* %43, align 4
  %44516 = icmp eq i32 %44400, %44515
  %44517 = or i1 %44514, %44516
  %44518 = load i32, i32* %44, align 4
  %44519 = icmp eq i32 %44400, %44518
  %44520 = or i1 %44517, %44519
  %44521 = load i32, i32* %45, align 4
  %44522 = icmp eq i32 %44400, %44521
  %44523 = or i1 %44520, %44522
  %44524 = load i32, i32* %46, align 4
  %44525 = icmp eq i32 %44400, %44524
  %44526 = or i1 %44523, %44525
  %44527 = load i32, i32* %47, align 4
  %44528 = icmp eq i32 %44400, %44527
  %44529 = or i1 %44526, %44528
  %44530 = load i32, i32* %48, align 4
  %44531 = icmp eq i32 %44400, %44530
  %44532 = or i1 %44529, %44531
  %44533 = load i32, i32* %49, align 4
  %44534 = icmp eq i32 %44400, %44533
  %44535 = or i1 %44532, %44534
  %44536 = load i32, i32* %50, align 4
  %44537 = icmp eq i32 %44400, %44536
  %44538 = or i1 %44535, %44537
  %44539 = load i32, i32* %51, align 4
  %44540 = icmp eq i32 %44400, %44539
  %44541 = or i1 %44538, %44540
  %44542 = load i32, i32* %52, align 4
  %44543 = icmp eq i32 %44400, %44542
  %44544 = or i1 %44541, %44543
  %44545 = load i32, i32* %53, align 4
  %44546 = icmp eq i32 %44400, %44545
  %44547 = or i1 %44544, %44546
  %44548 = load i32, i32* %54, align 4
  %44549 = icmp eq i32 %44400, %44548
  %44550 = or i1 %44547, %44549
  %44551 = load i32, i32* %55, align 4
  %44552 = icmp eq i32 %44400, %44551
  %44553 = or i1 %44550, %44552
  %44554 = load i32, i32* %56, align 4
  %44555 = icmp eq i32 %44400, %44554
  %44556 = or i1 %44553, %44555
  %44557 = load i32, i32* %57, align 4
  %44558 = icmp eq i32 %44400, %44557
  %44559 = or i1 %44556, %44558
  %44560 = load i32, i32* %58, align 4
  %44561 = icmp eq i32 %44400, %44560
  %44562 = or i1 %44559, %44561
  %44563 = load i32, i32* %59, align 4
  %44564 = icmp eq i32 %44400, %44563
  %44565 = or i1 %44562, %44564
  %44566 = load i32, i32* %60, align 4
  %44567 = icmp eq i32 %44400, %44566
  %44568 = or i1 %44565, %44567
  %44569 = load i32, i32* %61, align 4
  %44570 = icmp eq i32 %44400, %44569
  %44571 = or i1 %44568, %44570
  %44572 = load i32, i32* %62, align 4
  %44573 = icmp eq i32 %44400, %44572
  %44574 = or i1 %44571, %44573
  %44575 = getelementptr i8, i8 addrspace(1)* %4, i32 163
  %44576 = zext i1 %44574 to i8
  store i8 %44576, i8 addrspace(1)* %44575, align 1, !nosanitize !3
  %44577 = load i256, i256* %44399, align 4
  %44578 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !647, !intsan !45
  %44579 = xor i256 %44578, -1
  %44580 = and i256 %44579, %44577
  %44581 = and i256 1461501637330902918203684832716283019655932542975, %44396
  %44582 = mul i256 %44581, 1, !pc !648, !intsan !45
  %44583 = or i256 %44582, %44580
  %44584 = alloca i256, align 8
  store i256 1, i256* %44584, align 4
  %44585 = alloca i256, align 8
  store i256 %44583, i256* %44585, align 4
  call void @__device_sstore(i256* %44584, i256* %44585)
  %44586 = call i32 @__hashword(i256* %44584)
  store i32 %44586, i32* %6, align 4, !nosanitize !3
  %44587 = alloca i256, align 8
  store i256 1, i256* %44587, align 4
  %44588 = alloca i256, align 8
  call void @__device_sload(i256* %44587, i256* %44588)
  %44589 = call i32 @__hashword(i256* %44587)
  %44590 = load i32, i32* %5, align 4
  %44591 = icmp eq i32 %44589, %44590
  %44592 = or i1 false, %44591
  %44593 = load i32, i32* %6, align 4
  %44594 = icmp eq i32 %44589, %44593
  %44595 = or i1 %44592, %44594
  %44596 = load i32, i32* %7, align 4
  %44597 = icmp eq i32 %44589, %44596
  %44598 = or i1 %44595, %44597
  %44599 = load i32, i32* %8, align 4
  %44600 = icmp eq i32 %44589, %44599
  %44601 = or i1 %44598, %44600
  %44602 = load i32, i32* %9, align 4
  %44603 = icmp eq i32 %44589, %44602
  %44604 = or i1 %44601, %44603
  %44605 = load i32, i32* %10, align 4
  %44606 = icmp eq i32 %44589, %44605
  %44607 = or i1 %44604, %44606
  %44608 = load i32, i32* %11, align 4
  %44609 = icmp eq i32 %44589, %44608
  %44610 = or i1 %44607, %44609
  %44611 = load i32, i32* %12, align 4
  %44612 = icmp eq i32 %44589, %44611
  %44613 = or i1 %44610, %44612
  %44614 = load i32, i32* %13, align 4
  %44615 = icmp eq i32 %44589, %44614
  %44616 = or i1 %44613, %44615
  %44617 = load i32, i32* %14, align 4
  %44618 = icmp eq i32 %44589, %44617
  %44619 = or i1 %44616, %44618
  %44620 = load i32, i32* %15, align 4
  %44621 = icmp eq i32 %44589, %44620
  %44622 = or i1 %44619, %44621
  %44623 = load i32, i32* %16, align 4
  %44624 = icmp eq i32 %44589, %44623
  %44625 = or i1 %44622, %44624
  %44626 = load i32, i32* %17, align 4
  %44627 = icmp eq i32 %44589, %44626
  %44628 = or i1 %44625, %44627
  %44629 = load i32, i32* %18, align 4
  %44630 = icmp eq i32 %44589, %44629
  %44631 = or i1 %44628, %44630
  %44632 = load i32, i32* %19, align 4
  %44633 = icmp eq i32 %44589, %44632
  %44634 = or i1 %44631, %44633
  %44635 = load i32, i32* %20, align 4
  %44636 = icmp eq i32 %44589, %44635
  %44637 = or i1 %44634, %44636
  %44638 = load i32, i32* %21, align 4
  %44639 = icmp eq i32 %44589, %44638
  %44640 = or i1 %44637, %44639
  %44641 = load i32, i32* %22, align 4
  %44642 = icmp eq i32 %44589, %44641
  %44643 = or i1 %44640, %44642
  %44644 = load i32, i32* %23, align 4
  %44645 = icmp eq i32 %44589, %44644
  %44646 = or i1 %44643, %44645
  %44647 = load i32, i32* %24, align 4
  %44648 = icmp eq i32 %44589, %44647
  %44649 = or i1 %44646, %44648
  %44650 = load i32, i32* %25, align 4
  %44651 = icmp eq i32 %44589, %44650
  %44652 = or i1 %44649, %44651
  %44653 = load i32, i32* %26, align 4
  %44654 = icmp eq i32 %44589, %44653
  %44655 = or i1 %44652, %44654
  %44656 = load i32, i32* %27, align 4
  %44657 = icmp eq i32 %44589, %44656
  %44658 = or i1 %44655, %44657
  %44659 = load i32, i32* %28, align 4
  %44660 = icmp eq i32 %44589, %44659
  %44661 = or i1 %44658, %44660
  %44662 = load i32, i32* %29, align 4
  %44663 = icmp eq i32 %44589, %44662
  %44664 = or i1 %44661, %44663
  %44665 = load i32, i32* %30, align 4
  %44666 = icmp eq i32 %44589, %44665
  %44667 = or i1 %44664, %44666
  %44668 = load i32, i32* %31, align 4
  %44669 = icmp eq i32 %44589, %44668
  %44670 = or i1 %44667, %44669
  %44671 = load i32, i32* %32, align 4
  %44672 = icmp eq i32 %44589, %44671
  %44673 = or i1 %44670, %44672
  %44674 = load i32, i32* %33, align 4
  %44675 = icmp eq i32 %44589, %44674
  %44676 = or i1 %44673, %44675
  %44677 = load i32, i32* %34, align 4
  %44678 = icmp eq i32 %44589, %44677
  %44679 = or i1 %44676, %44678
  %44680 = load i32, i32* %35, align 4
  %44681 = icmp eq i32 %44589, %44680
  %44682 = or i1 %44679, %44681
  %44683 = load i32, i32* %36, align 4
  %44684 = icmp eq i32 %44589, %44683
  %44685 = or i1 %44682, %44684
  %44686 = load i32, i32* %37, align 4
  %44687 = icmp eq i32 %44589, %44686
  %44688 = or i1 %44685, %44687
  %44689 = load i32, i32* %38, align 4
  %44690 = icmp eq i32 %44589, %44689
  %44691 = or i1 %44688, %44690
  %44692 = load i32, i32* %39, align 4
  %44693 = icmp eq i32 %44589, %44692
  %44694 = or i1 %44691, %44693
  %44695 = load i32, i32* %40, align 4
  %44696 = icmp eq i32 %44589, %44695
  %44697 = or i1 %44694, %44696
  %44698 = load i32, i32* %41, align 4
  %44699 = icmp eq i32 %44589, %44698
  %44700 = or i1 %44697, %44699
  %44701 = load i32, i32* %42, align 4
  %44702 = icmp eq i32 %44589, %44701
  %44703 = or i1 %44700, %44702
  %44704 = load i32, i32* %43, align 4
  %44705 = icmp eq i32 %44589, %44704
  %44706 = or i1 %44703, %44705
  %44707 = load i32, i32* %44, align 4
  %44708 = icmp eq i32 %44589, %44707
  %44709 = or i1 %44706, %44708
  %44710 = load i32, i32* %45, align 4
  %44711 = icmp eq i32 %44589, %44710
  %44712 = or i1 %44709, %44711
  %44713 = load i32, i32* %46, align 4
  %44714 = icmp eq i32 %44589, %44713
  %44715 = or i1 %44712, %44714
  %44716 = load i32, i32* %47, align 4
  %44717 = icmp eq i32 %44589, %44716
  %44718 = or i1 %44715, %44717
  %44719 = load i32, i32* %48, align 4
  %44720 = icmp eq i32 %44589, %44719
  %44721 = or i1 %44718, %44720
  %44722 = load i32, i32* %49, align 4
  %44723 = icmp eq i32 %44589, %44722
  %44724 = or i1 %44721, %44723
  %44725 = load i32, i32* %50, align 4
  %44726 = icmp eq i32 %44589, %44725
  %44727 = or i1 %44724, %44726
  %44728 = load i32, i32* %51, align 4
  %44729 = icmp eq i32 %44589, %44728
  %44730 = or i1 %44727, %44729
  %44731 = load i32, i32* %52, align 4
  %44732 = icmp eq i32 %44589, %44731
  %44733 = or i1 %44730, %44732
  %44734 = load i32, i32* %53, align 4
  %44735 = icmp eq i32 %44589, %44734
  %44736 = or i1 %44733, %44735
  %44737 = load i32, i32* %54, align 4
  %44738 = icmp eq i32 %44589, %44737
  %44739 = or i1 %44736, %44738
  %44740 = load i32, i32* %55, align 4
  %44741 = icmp eq i32 %44589, %44740
  %44742 = or i1 %44739, %44741
  %44743 = load i32, i32* %56, align 4
  %44744 = icmp eq i32 %44589, %44743
  %44745 = or i1 %44742, %44744
  %44746 = load i32, i32* %57, align 4
  %44747 = icmp eq i32 %44589, %44746
  %44748 = or i1 %44745, %44747
  %44749 = load i32, i32* %58, align 4
  %44750 = icmp eq i32 %44589, %44749
  %44751 = or i1 %44748, %44750
  %44752 = load i32, i32* %59, align 4
  %44753 = icmp eq i32 %44589, %44752
  %44754 = or i1 %44751, %44753
  %44755 = load i32, i32* %60, align 4
  %44756 = icmp eq i32 %44589, %44755
  %44757 = or i1 %44754, %44756
  %44758 = load i32, i32* %61, align 4
  %44759 = icmp eq i32 %44589, %44758
  %44760 = or i1 %44757, %44759
  %44761 = load i32, i32* %62, align 4
  %44762 = icmp eq i32 %44589, %44761
  %44763 = or i1 %44760, %44762
  %44764 = getelementptr i8, i8 addrspace(1)* %4, i32 164
  %44765 = zext i1 %44763 to i8
  store i8 %44765, i8 addrspace(1)* %44764, align 1, !nosanitize !3
  %44766 = load i256, i256* %44588, align 4
  %44767 = alloca i256, align 8
  store i256 %44766, i256* %44767, align 4
  %44768 = alloca i256, align 8
  store i256 1, i256* %44768, align 4
  %44769 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %44767, i256* %44768, i256* %44769), !pc !649, !intsan !6
  %44770 = load i256, i256* %44769, align 4
  %44771 = and i256 1461501637330902918203684832716283019655932542975, %44770
  %44772 = and i256 1461501637330902918203684832716283019655932542975, %44771
  %44773 = trunc i256 64 to i64
  %44774 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44773, i256* %44774)
  %44775 = load i256, i256* %44774, align 4
  %44776 = and i256 4294967295, 3263287710
  %44777 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %44776, !pc !650, !intsan !45
  %44778 = trunc i256 %44775 to i64
  %44779 = alloca i256, align 8
  store i256 %44777, i256* %44779, align 4
  %44780 = bitcast i256* %44779 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %44778, i8* %44780, i64 32)
  %44781 = add i256 4, %44775, !pc !651, !intsan !10
  %44782 = trunc i256 64 to i64
  %44783 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44782, i256* %44783)
  %44784 = load i256, i256* %44783, align 4
  %44785 = sub i256 %44781, %44784, !pc !652, !intsan !8
  %44786 = icmp eq i256 1, 0
  %44787 = icmp eq i1 %44786, false
  %44788 = trunc i256 14500 to i64
  %jump.check87 = icmp ne i1 %44787, false
  %44789 = load i64, i64* %STACK_DEP_PTR, align 4
  %44790 = add i64 %44789, 1
  store i64 %44790, i64* %STACK_DEP_PTR, align 4
  %44791 = load i64, i64* %STACK_DEP_PTR, align 4
  %44792 = getelementptr i256, i256* %STACK, i64 %44791
  store i256 %44772, i256* %44792, align 4
  %44793 = load i64, i64* %STACK_DEP_PTR, align 4
  %44794 = add i64 %44793, 1
  store i64 %44794, i64* %STACK_DEP_PTR, align 4
  %44795 = load i64, i64* %STACK_DEP_PTR, align 4
  %44796 = getelementptr i256, i256* %STACK, i64 %44795
  store i256 3263287710, i256* %44796, align 4
  %44797 = load i64, i64* %STACK_DEP_PTR, align 4
  %44798 = add i64 %44797, 1
  store i64 %44798, i64* %STACK_DEP_PTR, align 4
  %44799 = load i64, i64* %STACK_DEP_PTR, align 4
  %44800 = getelementptr i256, i256* %STACK, i64 %44799
  store i256 %44781, i256* %44800, align 4
  %44801 = load i64, i64* %STACK_DEP_PTR, align 4
  %44802 = add i64 %44801, 1
  store i64 %44802, i64* %STACK_DEP_PTR, align 4
  %44803 = load i64, i64* %STACK_DEP_PTR, align 4
  %44804 = getelementptr i256, i256* %STACK, i64 %44803
  store i256 32, i256* %44804, align 4
  %44805 = load i64, i64* %STACK_DEP_PTR, align 4
  %44806 = add i64 %44805, 1
  store i64 %44806, i64* %STACK_DEP_PTR, align 4
  %44807 = load i64, i64* %STACK_DEP_PTR, align 4
  %44808 = getelementptr i256, i256* %STACK, i64 %44807
  store i256 %44784, i256* %44808, align 4
  %44809 = load i64, i64* %STACK_DEP_PTR, align 4
  %44810 = add i64 %44809, 1
  store i64 %44810, i64* %STACK_DEP_PTR, align 4
  %44811 = load i64, i64* %STACK_DEP_PTR, align 4
  %44812 = getelementptr i256, i256* %STACK, i64 %44811
  store i256 %44785, i256* %44812, align 4
  %44813 = load i64, i64* %STACK_DEP_PTR, align 4
  %44814 = add i64 %44813, 1
  store i64 %44814, i64* %STACK_DEP_PTR, align 4
  %44815 = load i64, i64* %STACK_DEP_PTR, align 4
  %44816 = getelementptr i256, i256* %STACK, i64 %44815
  store i256 %44784, i256* %44816, align 4
  %44817 = load i64, i64* %STACK_DEP_PTR, align 4
  %44818 = add i64 %44817, 1
  store i64 %44818, i64* %STACK_DEP_PTR, align 4
  %44819 = load i64, i64* %STACK_DEP_PTR, align 4
  %44820 = getelementptr i256, i256* %STACK, i64 %44819
  store i256 0, i256* %44820, align 4
  %44821 = load i64, i64* %STACK_DEP_PTR, align 4
  %44822 = add i64 %44821, 1
  store i64 %44822, i64* %STACK_DEP_PTR, align 4
  %44823 = load i64, i64* %STACK_DEP_PTR, align 4
  %44824 = getelementptr i256, i256* %STACK, i64 %44823
  store i256 %44772, i256* %44824, align 4
  %44825 = load i64, i64* %STACK_DEP_PTR, align 4
  %44826 = add i64 %44825, 1
  store i64 %44826, i64* %STACK_DEP_PTR, align 4
  %44827 = zext i1 %44786 to i256
  %44828 = load i64, i64* %STACK_DEP_PTR, align 4
  %44829 = getelementptr i256, i256* %STACK, i64 %44828
  store i256 %44827, i256* %44829, align 4
  br i1 %jump.check87, label %.14500, label %.14496, !EVMBB !4

.14496:                                           ; preds = %44376
  %44830 = load i64, i64* %remaing_gas, align 4
  %44831 = icmp ugt i64 40, %44830
  br i1 %44831, label %Abort, label %44832

44832:                                            ; preds = %.14496
  %44833 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44834 = xor i32 %44833, 1509
  %44835 = urem i32 %44834, 4096
  %44836 = getelementptr i8, i8 addrspace(1)* %4, i32 %44835
  %44837 = load i8, i8 addrspace(1)* %44836, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44836, align 1, !nosanitize !3
  store i32 754, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44838 = sub i64 %44830, 40
  store i64 %44838, i64* %remaing_gas, align 4
  %44839 = load i64, i64* %STACK_DEP_PTR, align 4
  %44840 = sub i64 %44839, 0
  store i64 %44840, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14500:                                           ; preds = %44376, %JumpTable
  %44841 = load i64, i64* %remaing_gas, align 4
  %44842 = icmp ugt i64 456, %44841
  br i1 %44842, label %Abort, label %44843

44843:                                            ; preds = %.14500
  %44844 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44845 = xor i32 %44844, 1290
  %44846 = urem i32 %44845, 4096
  %44847 = getelementptr i8, i8 addrspace(1)* %4, i32 %44846
  %44848 = load i8, i8 addrspace(1)* %44847, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44847, align 1, !nosanitize !3
  store i32 645, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44849 = sub i64 %44841, 456
  store i64 %44849, i64* %remaing_gas, align 4
  %44850 = load i64, i64* %STACK_DEP_PTR, align 4
  %44851 = getelementptr i256, i256* %STACK, i64 %44850
  %44852 = load i256, i256* %44851, align 4
  %44853 = load i64, i64* %STACK_DEP_PTR, align 4
  %44854 = sub i64 %44853, 1
  store i64 %44854, i64* %STACK_DEP_PTR, align 4
  %44855 = load i64, i64* %STACK_DEP_PTR, align 4
  %44856 = getelementptr i256, i256* %STACK, i64 %44855
  %44857 = load i256, i256* %44856, align 4
  %44858 = load i64, i64* %STACK_DEP_PTR, align 4
  %44859 = sub i64 %44858, 1
  store i64 %44859, i64* %STACK_DEP_PTR, align 4
  %44860 = load i64, i64* %STACK_DEP_PTR, align 4
  %44861 = getelementptr i256, i256* %STACK, i64 %44860
  %44862 = load i256, i256* %44861, align 4
  %44863 = load i64, i64* %STACK_DEP_PTR, align 4
  %44864 = sub i64 %44863, 1
  store i64 %44864, i64* %STACK_DEP_PTR, align 4
  %44865 = load i64, i64* %STACK_DEP_PTR, align 4
  %44866 = getelementptr i256, i256* %STACK, i64 %44865
  %44867 = load i256, i256* %44866, align 4
  %44868 = load i64, i64* %STACK_DEP_PTR, align 4
  %44869 = sub i64 %44868, 1
  store i64 %44869, i64* %STACK_DEP_PTR, align 4
  %44870 = load i64, i64* %STACK_DEP_PTR, align 4
  %44871 = getelementptr i256, i256* %STACK, i64 %44870
  %44872 = load i256, i256* %44871, align 4
  %44873 = load i64, i64* %STACK_DEP_PTR, align 4
  %44874 = sub i64 %44873, 1
  store i64 %44874, i64* %STACK_DEP_PTR, align 4
  %44875 = load i64, i64* %STACK_DEP_PTR, align 4
  %44876 = getelementptr i256, i256* %STACK, i64 %44875
  %44877 = load i256, i256* %44876, align 4
  %44878 = load i64, i64* %STACK_DEP_PTR, align 4
  %44879 = sub i64 %44878, 1
  store i64 %44879, i64* %STACK_DEP_PTR, align 4
  %44880 = load i64, i64* %STACK_DEP_PTR, align 4
  %44881 = getelementptr i256, i256* %STACK, i64 %44880
  %44882 = load i256, i256* %44881, align 4
  %44883 = load i64, i64* %STACK_DEP_PTR, align 4
  %44884 = sub i64 %44883, 1
  store i64 %44884, i64* %STACK_DEP_PTR, align 4
  %44885 = trunc i256 %44857 to i160
  %44886 = call i1 @solidity_call(), !pc !653
  %44887 = icmp eq i1 %44886, false
  %44888 = icmp eq i1 %44887, false
  %44889 = trunc i256 14520 to i64
  %jump.check91 = icmp ne i1 %44888, false
  %44890 = load i64, i64* %STACK_DEP_PTR, align 4
  %44891 = add i64 %44890, 1
  store i64 %44891, i64* %STACK_DEP_PTR, align 4
  %44892 = zext i1 %44887 to i256
  %44893 = load i64, i64* %STACK_DEP_PTR, align 4
  %44894 = getelementptr i256, i256* %STACK, i64 %44893
  store i256 %44892, i256* %44894, align 4
  br i1 %jump.check91, label %.14520, label %.14511, !EVMBB !4

.14511:                                           ; preds = %44843
  %44895 = load i64, i64* %remaing_gas, align 4
  %44896 = icmp ugt i64 40, %44895
  br i1 %44896, label %Abort, label %44897

44897:                                            ; preds = %.14511
  %44898 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44899 = xor i32 %44898, 2040
  %44900 = urem i32 %44899, 4096
  %44901 = getelementptr i8, i8 addrspace(1)* %4, i32 %44900
  %44902 = load i8, i8 addrspace(1)* %44901, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44901, align 1, !nosanitize !3
  store i32 1020, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44903 = sub i64 %44895, 40
  store i64 %44903, i64* %remaing_gas, align 4
  %44904 = load i64, i64* %STACK_DEP_PTR, align 4
  %44905 = sub i64 %44904, 0
  store i64 %44905, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14520:                                           ; preds = %44843, %JumpTable
  %44906 = load i64, i64* %remaing_gas, align 4
  %44907 = icmp ugt i64 384, %44906
  br i1 %44907, label %Abort, label %44908

44908:                                            ; preds = %.14520
  %44909 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44910 = xor i32 %44909, 2205
  %44911 = urem i32 %44910, 4096
  %44912 = getelementptr i8, i8 addrspace(1)* %4, i32 %44911
  %44913 = load i8, i8 addrspace(1)* %44912, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44912, align 1, !nosanitize !3
  store i32 1102, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44914 = sub i64 %44906, 384
  store i64 %44914, i64* %remaing_gas, align 4
  %44915 = load i64, i64* %STACK_DEP_PTR, align 4
  %44916 = getelementptr i256, i256* %STACK, i64 %44915
  %44917 = load i256, i256* %44916, align 4
  %44918 = load i64, i64* %STACK_DEP_PTR, align 4
  %44919 = sub i64 %44918, 1
  store i64 %44919, i64* %STACK_DEP_PTR, align 4
  %44920 = load i64, i64* %STACK_DEP_PTR, align 4
  %44921 = getelementptr i256, i256* %STACK, i64 %44920
  %44922 = load i256, i256* %44921, align 4
  %44923 = load i64, i64* %STACK_DEP_PTR, align 4
  %44924 = sub i64 %44923, 1
  store i64 %44924, i64* %STACK_DEP_PTR, align 4
  %44925 = load i64, i64* %STACK_DEP_PTR, align 4
  %44926 = getelementptr i256, i256* %STACK, i64 %44925
  %44927 = load i256, i256* %44926, align 4
  %44928 = load i64, i64* %STACK_DEP_PTR, align 4
  %44929 = sub i64 %44928, 1
  store i64 %44929, i64* %STACK_DEP_PTR, align 4
  %44930 = load i64, i64* %STACK_DEP_PTR, align 4
  %44931 = getelementptr i256, i256* %STACK, i64 %44930
  %44932 = load i256, i256* %44931, align 4
  %44933 = load i64, i64* %STACK_DEP_PTR, align 4
  %44934 = sub i64 %44933, 1
  store i64 %44934, i64* %STACK_DEP_PTR, align 4
  %44935 = trunc i256 64 to i64
  %44936 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44935, i256* %44936)
  %44937 = load i256, i256* %44936, align 4
  %44938 = zext i64 0 to i256
  %44939 = icmp ult i256 %44938, 32
  %44940 = icmp eq i1 %44939, false
  %44941 = trunc i256 14542 to i64
  %jump.check97 = icmp ne i1 %44940, false
  %44942 = load i64, i64* %STACK_DEP_PTR, align 4
  %44943 = add i64 %44942, 1
  store i64 %44943, i64* %STACK_DEP_PTR, align 4
  %44944 = load i64, i64* %STACK_DEP_PTR, align 4
  %44945 = getelementptr i256, i256* %STACK, i64 %44944
  store i256 %44937, i256* %44945, align 4
  %44946 = load i64, i64* %STACK_DEP_PTR, align 4
  %44947 = add i64 %44946, 1
  store i64 %44947, i64* %STACK_DEP_PTR, align 4
  %44948 = zext i64 0 to i256
  %44949 = load i64, i64* %STACK_DEP_PTR, align 4
  %44950 = getelementptr i256, i256* %STACK, i64 %44949
  store i256 %44948, i256* %44950, align 4
  br i1 %jump.check97, label %.14542, label %.14538, !EVMBB !4

.14538:                                           ; preds = %44908
  %44951 = load i64, i64* %remaing_gas, align 4
  %44952 = icmp ugt i64 40, %44951
  br i1 %44952, label %Abort, label %44953

44953:                                            ; preds = %.14538
  %44954 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44955 = xor i32 %44954, 3191
  %44956 = urem i32 %44955, 4096
  %44957 = getelementptr i8, i8 addrspace(1)* %4, i32 %44956
  %44958 = load i8, i8 addrspace(1)* %44957, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44957, align 1, !nosanitize !3
  store i32 1595, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44959 = sub i64 %44951, 40
  store i64 %44959, i64* %remaing_gas, align 4
  %44960 = load i64, i64* %STACK_DEP_PTR, align 4
  %44961 = sub i64 %44960, 0
  store i64 %44961, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.14542:                                           ; preds = %44908, %JumpTable
  %44962 = load i64, i64* %remaing_gas, align 4
  %44963 = icmp ugt i64 320, %44962
  br i1 %44963, label %Abort, label %44964

44964:                                            ; preds = %.14542
  %44965 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44966 = xor i32 %44965, 1289
  %44967 = urem i32 %44966, 4096
  %44968 = getelementptr i8, i8 addrspace(1)* %4, i32 %44967
  %44969 = load i8, i8 addrspace(1)* %44968, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %44968, align 1, !nosanitize !3
  store i32 644, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %44970 = sub i64 %44962, 320
  store i64 %44970, i64* %remaing_gas, align 4
  %44971 = load i64, i64* %STACK_DEP_PTR, align 4
  %44972 = getelementptr i256, i256* %STACK, i64 %44971
  %44973 = load i256, i256* %44972, align 4
  %44974 = load i64, i64* %STACK_DEP_PTR, align 4
  %44975 = sub i64 %44974, 1
  store i64 %44975, i64* %STACK_DEP_PTR, align 4
  %44976 = load i64, i64* %STACK_DEP_PTR, align 4
  %44977 = getelementptr i256, i256* %STACK, i64 %44976
  %44978 = load i256, i256* %44977, align 4
  %44979 = load i64, i64* %STACK_DEP_PTR, align 4
  %44980 = sub i64 %44979, 1
  store i64 %44980, i64* %STACK_DEP_PTR, align 4
  %44981 = load i64, i64* %STACK_DEP_PTR, align 4
  %44982 = getelementptr i256, i256* %STACK, i64 %44981
  %44983 = load i256, i256* %44982, align 4
  %44984 = load i64, i64* %STACK_DEP_PTR, align 4
  %44985 = sub i64 %44984, 1
  store i64 %44985, i64* %STACK_DEP_PTR, align 4
  %44986 = load i64, i64* %STACK_DEP_PTR, align 4
  %44987 = getelementptr i256, i256* %STACK, i64 %44986
  %44988 = load i256, i256* %44987, align 4
  %44989 = load i64, i64* %STACK_DEP_PTR, align 4
  %44990 = sub i64 %44989, 1
  store i64 %44990, i64* %STACK_DEP_PTR, align 4
  %44991 = add i256 %44978, %44973, !pc !654, !intsan !10
  %44992 = trunc i256 %44978 to i64
  %44993 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %44992, i256* %44993)
  %44994 = load i256, i256* %44993, align 4
  %44995 = add i256 32, %44978, !pc !655, !intsan !10
  %44996 = trunc i256 %44988 to i64
  store i64 %44996, i64* %JMP_TARGET_PTR, align 4
  %44997 = load i64, i64* %STACK_DEP_PTR, align 4
  %44998 = add i64 %44997, 1
  store i64 %44998, i64* %STACK_DEP_PTR, align 4
  %44999 = load i64, i64* %STACK_DEP_PTR, align 4
  %45000 = getelementptr i256, i256* %STACK, i64 %44999
  store i256 %44994, i256* %45000, align 4
  br label %JumpTable, !EVMBB !4

.14564:                                           ; preds = %16699, %15134, %JumpTable
  %45001 = load i64, i64* %remaing_gas, align 4
  %45002 = icmp ugt i64 312, %45001
  br i1 %45002, label %Abort, label %45003

45003:                                            ; preds = %.14564
  %45004 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45005 = xor i32 %45004, 1745
  %45006 = urem i32 %45005, 4096
  %45007 = getelementptr i8, i8 addrspace(1)* %4, i32 %45006
  %45008 = load i8, i8 addrspace(1)* %45007, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45007, align 1, !nosanitize !3
  store i32 872, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45009 = sub i64 %45001, 312
  store i64 %45009, i64* %remaing_gas, align 4
  %45010 = load i64, i64* %STACK_DEP_PTR, align 4
  %45011 = getelementptr i256, i256* %STACK, i64 %45010
  %45012 = load i256, i256* %45011, align 4
  %45013 = load i64, i64* %STACK_DEP_PTR, align 4
  %45014 = sub i64 %45013, 1
  store i64 %45014, i64* %STACK_DEP_PTR, align 4
  %45015 = trunc i256 18235 to i64
  %45016 = load i64, i64* %STACK_DEP_PTR, align 4
  %45017 = add i64 %45016, 1
  store i64 %45017, i64* %STACK_DEP_PTR, align 4
  %45018 = load i64, i64* %STACK_DEP_PTR, align 4
  %45019 = getelementptr i256, i256* %STACK, i64 %45018
  store i256 %45012, i256* %45019, align 4
  %45020 = load i64, i64* %STACK_DEP_PTR, align 4
  %45021 = add i64 %45020, 1
  store i64 %45021, i64* %STACK_DEP_PTR, align 4
  %45022 = load i64, i64* %STACK_DEP_PTR, align 4
  %45023 = getelementptr i256, i256* %STACK, i64 %45022
  store i256 0, i256* %45023, align 4
  %45024 = load i64, i64* %STACK_DEP_PTR, align 4
  %45025 = add i64 %45024, 1
  store i64 %45025, i64* %STACK_DEP_PTR, align 4
  %45026 = load i64, i64* %STACK_DEP_PTR, align 4
  %45027 = getelementptr i256, i256* %STACK, i64 %45026
  store i256 14577, i256* %45027, align 4
  %45028 = load i64, i64* %STACK_DEP_PTR, align 4
  %45029 = add i64 %45028, 1
  store i64 %45029, i64* %STACK_DEP_PTR, align 4
  %45030 = load i64, i64* %STACK_DEP_PTR, align 4
  %45031 = getelementptr i256, i256* %STACK, i64 %45030
  store i256 %45012, i256* %45031, align 4
  %45032 = load i64, i64* %STACK_DEP_PTR, align 4
  %45033 = add i64 %45032, 1
  store i64 %45033, i64* %STACK_DEP_PTR, align 4
  %45034 = load i64, i64* %STACK_DEP_PTR, align 4
  %45035 = getelementptr i256, i256* %STACK, i64 %45034
  store i256 0, i256* %45035, align 4
  br label %.18235, !EVMBB !4

.14577:                                           ; preds = %JumpTable
  %45036 = load i64, i64* %remaing_gas, align 4
  %45037 = icmp ugt i64 272, %45036
  br i1 %45037, label %Abort, label %45038

45038:                                            ; preds = %.14577
  %45039 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45040 = xor i32 %45039, 2981
  %45041 = urem i32 %45040, 4096
  %45042 = getelementptr i8, i8 addrspace(1)* %4, i32 %45041
  %45043 = load i8, i8 addrspace(1)* %45042, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45042, align 1, !nosanitize !3
  store i32 1490, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45044 = sub i64 %45036, 272
  store i64 %45044, i64* %remaing_gas, align 4
  %45045 = load i64, i64* %STACK_DEP_PTR, align 4
  %45046 = getelementptr i256, i256* %STACK, i64 %45045
  %45047 = load i256, i256* %45046, align 4
  %45048 = load i64, i64* %STACK_DEP_PTR, align 4
  %45049 = sub i64 %45048, 1
  store i64 %45049, i64* %STACK_DEP_PTR, align 4
  %45050 = load i64, i64* %STACK_DEP_PTR, align 4
  %45051 = getelementptr i256, i256* %STACK, i64 %45050
  %45052 = load i256, i256* %45051, align 4
  %45053 = load i64, i64* %STACK_DEP_PTR, align 4
  %45054 = sub i64 %45053, 1
  store i64 %45054, i64* %STACK_DEP_PTR, align 4
  %45055 = load i64, i64* %STACK_DEP_PTR, align 4
  %45056 = getelementptr i256, i256* %STACK, i64 %45055
  %45057 = load i256, i256* %45056, align 4
  %45058 = load i64, i64* %STACK_DEP_PTR, align 4
  %45059 = sub i64 %45058, 1
  store i64 %45059, i64* %STACK_DEP_PTR, align 4
  %45060 = load i64, i64* %STACK_DEP_PTR, align 4
  %45061 = getelementptr i256, i256* %STACK, i64 %45060
  %45062 = load i256, i256* %45061, align 4
  %45063 = load i64, i64* %STACK_DEP_PTR, align 4
  %45064 = sub i64 %45063, 1
  store i64 %45064, i64* %STACK_DEP_PTR, align 4
  %45065 = trunc i256 %45062 to i64
  store i64 %45065, i64* %JMP_TARGET_PTR, align 4
  %45066 = load i64, i64* %STACK_DEP_PTR, align 4
  %45067 = add i64 %45066, 1
  store i64 %45067, i64* %STACK_DEP_PTR, align 4
  %45068 = load i64, i64* %STACK_DEP_PTR, align 4
  %45069 = getelementptr i256, i256* %STACK, i64 %45068
  store i256 %45047, i256* %45069, align 4
  br label %JumpTable, !EVMBB !4

.14584:                                           ; preds = %48555, %47420, %46371, %43027, %42776, %18417, %15541, %JumpTable
  %45070 = load i64, i64* %remaing_gas, align 4
  %45071 = icmp ugt i64 144, %45070
  br i1 %45071, label %Abort, label %45072

45072:                                            ; preds = %.14584
  %45073 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45074 = xor i32 %45073, 2198
  %45075 = urem i32 %45074, 4096
  %45076 = getelementptr i8, i8 addrspace(1)* %4, i32 %45075
  %45077 = load i8, i8 addrspace(1)* %45076, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45076, align 1, !nosanitize !3
  store i32 1099, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45078 = sub i64 %45070, 144
  store i64 %45078, i64* %remaing_gas, align 4
  %45079 = load i64, i64* %STACK_DEP_PTR, align 4
  %45080 = getelementptr i256, i256* %STACK, i64 %45079
  %45081 = load i256, i256* %45080, align 4
  %45082 = load i64, i64* %STACK_DEP_PTR, align 4
  %45083 = sub i64 %45082, 1
  store i64 %45083, i64* %STACK_DEP_PTR, align 4
  %45084 = icmp eq i256 %45081, 0
  %45085 = icmp eq i1 %45084, false
  %45086 = trunc i256 14642 to i64
  %jump.check92 = icmp ne i1 %45085, false
  %45087 = load i64, i64* %STACK_DEP_PTR, align 4
  %45088 = add i64 %45087, 1
  store i64 %45088, i64* %STACK_DEP_PTR, align 4
  %45089 = load i64, i64* %STACK_DEP_PTR, align 4
  %45090 = getelementptr i256, i256* %STACK, i64 %45089
  store i256 %45081, i256* %45090, align 4
  br i1 %jump.check92, label %.14642, label %.14594, !EVMBB !4

.14594:                                           ; preds = %45072
  %45091 = load i64, i64* %remaing_gas, align 4
  %45092 = icmp ugt i64 136, %45091
  br i1 %45092, label %Abort, label %45093

45093:                                            ; preds = %.14594
  %45094 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45095 = xor i32 %45094, 1985
  %45096 = urem i32 %45095, 4096
  %45097 = getelementptr i8, i8 addrspace(1)* %4, i32 %45096
  %45098 = load i8, i8 addrspace(1)* %45097, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45097, align 1, !nosanitize !3
  store i32 992, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45099 = sub i64 %45091, 136
  store i64 %45099, i64* %remaing_gas, align 4
  %45100 = load i64, i64* %STACK_DEP_PTR, align 4
  %45101 = sub i64 %45100, 0
  store i64 %45101, i64* %STACK_DEP_PTR, align 4
  %45102 = trunc i256 64 to i64
  %45103 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45102, i256* %45103)
  %45104 = load i256, i256* %45103, align 4
  %45105 = trunc i256 64 to i64
  %45106 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45105, i256* %45106)
  %45107 = load i256, i256* %45106, align 4
  %45108 = sub i256 %45104, %45107, !pc !656, !intsan !8
  %45109 = trunc i256 32290703678274732461283295522977572438593946056557637987311955853663119353375 to i64
  call void @addBugSet(i64 %45109)
  %45110 = trunc i256 15310 to i64
  br label %.15310, !EVMBB !4

.14642:                                           ; preds = %45072, %JumpTable
  %45111 = load i64, i64* %remaing_gas, align 4
  %45112 = icmp ugt i64 168, %45111
  br i1 %45112, label %Abort, label %45113

45113:                                            ; preds = %.14642
  %45114 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45115 = xor i32 %45114, 1780
  %45116 = urem i32 %45115, 4096
  %45117 = getelementptr i8, i8 addrspace(1)* %4, i32 %45116
  %45118 = load i8, i8 addrspace(1)* %45117, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45117, align 1, !nosanitize !3
  store i32 890, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45119 = sub i64 %45111, 168
  store i64 %45119, i64* %remaing_gas, align 4
  %45120 = load i64, i64* %STACK_DEP_PTR, align 4
  %45121 = getelementptr i256, i256* %STACK, i64 %45120
  %45122 = load i256, i256* %45121, align 4
  %45123 = load i64, i64* %STACK_DEP_PTR, align 4
  %45124 = sub i64 %45123, 1
  store i64 %45124, i64* %STACK_DEP_PTR, align 4
  %45125 = load i160, i160 addrspace(4)* @SELFADDRESS, align 4
  %45126 = zext i160 %45125 to i256
  %45127 = and i256 1461501637330902918203684832716283019655932542975, %45126
  %45128 = icmp ult i256 -57896044618658097711785492504343953926634992332820282019728792003956564819968, %45122
  %45129 = icmp eq i1 %45128, false
  %45130 = trunc i256 14722 to i64
  %jump.check98 = icmp ne i1 %45129, false
  %45131 = load i64, i64* %STACK_DEP_PTR, align 4
  %45132 = add i64 %45131, 1
  store i64 %45132, i64* %STACK_DEP_PTR, align 4
  %45133 = load i64, i64* %STACK_DEP_PTR, align 4
  %45134 = getelementptr i256, i256* %STACK, i64 %45133
  store i256 %45122, i256* %45134, align 4
  br i1 %jump.check98, label %.14722, label %.14674, !EVMBB !4

.14674:                                           ; preds = %45113
  %45135 = load i64, i64* %remaing_gas, align 4
  %45136 = icmp ugt i64 136, %45135
  br i1 %45136, label %Abort, label %45137

45137:                                            ; preds = %.14674
  %45138 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45139 = xor i32 %45138, 2335
  %45140 = urem i32 %45139, 4096
  %45141 = getelementptr i8, i8 addrspace(1)* %4, i32 %45140
  %45142 = load i8, i8 addrspace(1)* %45141, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45141, align 1, !nosanitize !3
  store i32 1167, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45143 = sub i64 %45135, 136
  store i64 %45143, i64* %remaing_gas, align 4
  %45144 = load i64, i64* %STACK_DEP_PTR, align 4
  %45145 = sub i64 %45144, 0
  store i64 %45145, i64* %STACK_DEP_PTR, align 4
  %45146 = trunc i256 64 to i64
  %45147 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45146, i256* %45147)
  %45148 = load i256, i256* %45147, align 4
  %45149 = trunc i256 64 to i64
  %45150 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45149, i256* %45150)
  %45151 = load i256, i256* %45150, align 4
  %45152 = sub i256 %45148, %45151, !pc !657, !intsan !8
  %45153 = trunc i256 36317616705075676977067010585790982874253992057692628935680078120376618220199 to i64
  call void @addBugSet(i64 %45153)
  %45154 = trunc i256 15310 to i64
  br label %.15310, !EVMBB !4

.14722:                                           ; preds = %45113, %JumpTable
  %45155 = load i64, i64* %remaing_gas, align 4
  %45156 = icmp ugt i64 384, %45155
  br i1 %45156, label %Abort, label %45157

45157:                                            ; preds = %.14722
  %45158 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45159 = xor i32 %45158, 3733
  %45160 = urem i32 %45159, 4096
  %45161 = getelementptr i8, i8 addrspace(1)* %4, i32 %45160
  %45162 = load i8, i8 addrspace(1)* %45161, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45161, align 1, !nosanitize !3
  store i32 1866, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45163 = sub i64 %45155, 384
  store i64 %45163, i64* %remaing_gas, align 4
  %45164 = load i64, i64* %STACK_DEP_PTR, align 4
  %45165 = getelementptr i256, i256* %STACK, i64 %45164
  %45166 = load i256, i256* %45165, align 4
  %45167 = load i64, i64* %STACK_DEP_PTR, align 4
  %45168 = sub i64 %45167, 1
  store i64 %45168, i64* %STACK_DEP_PTR, align 4
  %45169 = load i64, i64* %STACK_DEP_PTR, align 4
  %45170 = getelementptr i256, i256* %STACK, i64 %45169
  %45171 = load i256, i256* %45170, align 4
  %45172 = load i64, i64* %STACK_DEP_PTR, align 4
  %45173 = sub i64 %45172, 1
  store i64 %45173, i64* %STACK_DEP_PTR, align 4
  %45174 = and i256 1461501637330902918203684832716283019655932542975, %45171
  %45175 = alloca i256, align 8
  store i256 2, i256* %45175, align 4
  %45176 = alloca i256, align 8
  call void @__device_sload(i256* %45175, i256* %45176)
  %45177 = call i32 @__hashword(i256* %45175)
  %45178 = load i32, i32* %5, align 4
  %45179 = icmp eq i32 %45177, %45178
  %45180 = or i1 false, %45179
  %45181 = load i32, i32* %6, align 4
  %45182 = icmp eq i32 %45177, %45181
  %45183 = or i1 %45180, %45182
  %45184 = load i32, i32* %7, align 4
  %45185 = icmp eq i32 %45177, %45184
  %45186 = or i1 %45183, %45185
  %45187 = load i32, i32* %8, align 4
  %45188 = icmp eq i32 %45177, %45187
  %45189 = or i1 %45186, %45188
  %45190 = load i32, i32* %9, align 4
  %45191 = icmp eq i32 %45177, %45190
  %45192 = or i1 %45189, %45191
  %45193 = load i32, i32* %10, align 4
  %45194 = icmp eq i32 %45177, %45193
  %45195 = or i1 %45192, %45194
  %45196 = load i32, i32* %11, align 4
  %45197 = icmp eq i32 %45177, %45196
  %45198 = or i1 %45195, %45197
  %45199 = load i32, i32* %12, align 4
  %45200 = icmp eq i32 %45177, %45199
  %45201 = or i1 %45198, %45200
  %45202 = load i32, i32* %13, align 4
  %45203 = icmp eq i32 %45177, %45202
  %45204 = or i1 %45201, %45203
  %45205 = load i32, i32* %14, align 4
  %45206 = icmp eq i32 %45177, %45205
  %45207 = or i1 %45204, %45206
  %45208 = load i32, i32* %15, align 4
  %45209 = icmp eq i32 %45177, %45208
  %45210 = or i1 %45207, %45209
  %45211 = load i32, i32* %16, align 4
  %45212 = icmp eq i32 %45177, %45211
  %45213 = or i1 %45210, %45212
  %45214 = load i32, i32* %17, align 4
  %45215 = icmp eq i32 %45177, %45214
  %45216 = or i1 %45213, %45215
  %45217 = load i32, i32* %18, align 4
  %45218 = icmp eq i32 %45177, %45217
  %45219 = or i1 %45216, %45218
  %45220 = load i32, i32* %19, align 4
  %45221 = icmp eq i32 %45177, %45220
  %45222 = or i1 %45219, %45221
  %45223 = load i32, i32* %20, align 4
  %45224 = icmp eq i32 %45177, %45223
  %45225 = or i1 %45222, %45224
  %45226 = load i32, i32* %21, align 4
  %45227 = icmp eq i32 %45177, %45226
  %45228 = or i1 %45225, %45227
  %45229 = load i32, i32* %22, align 4
  %45230 = icmp eq i32 %45177, %45229
  %45231 = or i1 %45228, %45230
  %45232 = load i32, i32* %23, align 4
  %45233 = icmp eq i32 %45177, %45232
  %45234 = or i1 %45231, %45233
  %45235 = load i32, i32* %24, align 4
  %45236 = icmp eq i32 %45177, %45235
  %45237 = or i1 %45234, %45236
  %45238 = load i32, i32* %25, align 4
  %45239 = icmp eq i32 %45177, %45238
  %45240 = or i1 %45237, %45239
  %45241 = load i32, i32* %26, align 4
  %45242 = icmp eq i32 %45177, %45241
  %45243 = or i1 %45240, %45242
  %45244 = load i32, i32* %27, align 4
  %45245 = icmp eq i32 %45177, %45244
  %45246 = or i1 %45243, %45245
  %45247 = load i32, i32* %28, align 4
  %45248 = icmp eq i32 %45177, %45247
  %45249 = or i1 %45246, %45248
  %45250 = load i32, i32* %29, align 4
  %45251 = icmp eq i32 %45177, %45250
  %45252 = or i1 %45249, %45251
  %45253 = load i32, i32* %30, align 4
  %45254 = icmp eq i32 %45177, %45253
  %45255 = or i1 %45252, %45254
  %45256 = load i32, i32* %31, align 4
  %45257 = icmp eq i32 %45177, %45256
  %45258 = or i1 %45255, %45257
  %45259 = load i32, i32* %32, align 4
  %45260 = icmp eq i32 %45177, %45259
  %45261 = or i1 %45258, %45260
  %45262 = load i32, i32* %33, align 4
  %45263 = icmp eq i32 %45177, %45262
  %45264 = or i1 %45261, %45263
  %45265 = load i32, i32* %34, align 4
  %45266 = icmp eq i32 %45177, %45265
  %45267 = or i1 %45264, %45266
  %45268 = load i32, i32* %35, align 4
  %45269 = icmp eq i32 %45177, %45268
  %45270 = or i1 %45267, %45269
  %45271 = load i32, i32* %36, align 4
  %45272 = icmp eq i32 %45177, %45271
  %45273 = or i1 %45270, %45272
  %45274 = load i32, i32* %37, align 4
  %45275 = icmp eq i32 %45177, %45274
  %45276 = or i1 %45273, %45275
  %45277 = load i32, i32* %38, align 4
  %45278 = icmp eq i32 %45177, %45277
  %45279 = or i1 %45276, %45278
  %45280 = load i32, i32* %39, align 4
  %45281 = icmp eq i32 %45177, %45280
  %45282 = or i1 %45279, %45281
  %45283 = load i32, i32* %40, align 4
  %45284 = icmp eq i32 %45177, %45283
  %45285 = or i1 %45282, %45284
  %45286 = load i32, i32* %41, align 4
  %45287 = icmp eq i32 %45177, %45286
  %45288 = or i1 %45285, %45287
  %45289 = load i32, i32* %42, align 4
  %45290 = icmp eq i32 %45177, %45289
  %45291 = or i1 %45288, %45290
  %45292 = load i32, i32* %43, align 4
  %45293 = icmp eq i32 %45177, %45292
  %45294 = or i1 %45291, %45293
  %45295 = load i32, i32* %44, align 4
  %45296 = icmp eq i32 %45177, %45295
  %45297 = or i1 %45294, %45296
  %45298 = load i32, i32* %45, align 4
  %45299 = icmp eq i32 %45177, %45298
  %45300 = or i1 %45297, %45299
  %45301 = load i32, i32* %46, align 4
  %45302 = icmp eq i32 %45177, %45301
  %45303 = or i1 %45300, %45302
  %45304 = load i32, i32* %47, align 4
  %45305 = icmp eq i32 %45177, %45304
  %45306 = or i1 %45303, %45305
  %45307 = load i32, i32* %48, align 4
  %45308 = icmp eq i32 %45177, %45307
  %45309 = or i1 %45306, %45308
  %45310 = load i32, i32* %49, align 4
  %45311 = icmp eq i32 %45177, %45310
  %45312 = or i1 %45309, %45311
  %45313 = load i32, i32* %50, align 4
  %45314 = icmp eq i32 %45177, %45313
  %45315 = or i1 %45312, %45314
  %45316 = load i32, i32* %51, align 4
  %45317 = icmp eq i32 %45177, %45316
  %45318 = or i1 %45315, %45317
  %45319 = load i32, i32* %52, align 4
  %45320 = icmp eq i32 %45177, %45319
  %45321 = or i1 %45318, %45320
  %45322 = load i32, i32* %53, align 4
  %45323 = icmp eq i32 %45177, %45322
  %45324 = or i1 %45321, %45323
  %45325 = load i32, i32* %54, align 4
  %45326 = icmp eq i32 %45177, %45325
  %45327 = or i1 %45324, %45326
  %45328 = load i32, i32* %55, align 4
  %45329 = icmp eq i32 %45177, %45328
  %45330 = or i1 %45327, %45329
  %45331 = load i32, i32* %56, align 4
  %45332 = icmp eq i32 %45177, %45331
  %45333 = or i1 %45330, %45332
  %45334 = load i32, i32* %57, align 4
  %45335 = icmp eq i32 %45177, %45334
  %45336 = or i1 %45333, %45335
  %45337 = load i32, i32* %58, align 4
  %45338 = icmp eq i32 %45177, %45337
  %45339 = or i1 %45336, %45338
  %45340 = load i32, i32* %59, align 4
  %45341 = icmp eq i32 %45177, %45340
  %45342 = or i1 %45339, %45341
  %45343 = load i32, i32* %60, align 4
  %45344 = icmp eq i32 %45177, %45343
  %45345 = or i1 %45342, %45344
  %45346 = load i32, i32* %61, align 4
  %45347 = icmp eq i32 %45177, %45346
  %45348 = or i1 %45345, %45347
  %45349 = load i32, i32* %62, align 4
  %45350 = icmp eq i32 %45177, %45349
  %45351 = or i1 %45348, %45350
  %45352 = getelementptr i8, i8 addrspace(1)* %4, i32 165
  %45353 = zext i1 %45351 to i8
  store i8 %45353, i8 addrspace(1)* %45352, align 1, !nosanitize !3
  %45354 = load i256, i256* %45176, align 4
  %45355 = trunc i256 64 to i64
  %45356 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45355, i256* %45356)
  %45357 = load i256, i256* %45356, align 4
  %45358 = trunc i256 64 to i64
  %45359 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45358, i256* %45359)
  %45360 = load i256, i256* %45359, align 4
  %45361 = sub i256 %45357, %45360, !pc !658, !intsan !8
  %45362 = trunc i256 %45354 to i64
  %45363 = trunc i256 %45174 to i160
  %45364 = call i1 @solidity_call(), !pc !659
  %45365 = icmp eq i1 %45364, false
  %45366 = icmp eq i1 %45365, false
  %45367 = trunc i256 15202 to i64
  %jump.check102 = icmp ne i1 %45366, false
  %45368 = load i64, i64* %STACK_DEP_PTR, align 4
  %45369 = add i64 %45368, 1
  store i64 %45369, i64* %STACK_DEP_PTR, align 4
  %45370 = load i64, i64* %STACK_DEP_PTR, align 4
  %45371 = getelementptr i256, i256* %STACK, i64 %45370
  store i256 %45171, i256* %45371, align 4
  %45372 = load i64, i64* %STACK_DEP_PTR, align 4
  %45373 = add i64 %45372, 1
  store i64 %45373, i64* %STACK_DEP_PTR, align 4
  %45374 = load i64, i64* %STACK_DEP_PTR, align 4
  %45375 = getelementptr i256, i256* %STACK, i64 %45374
  store i256 %45166, i256* %45375, align 4
  br i1 %jump.check102, label %.15202, label %.14777, !EVMBB !4

.14777:                                           ; preds = %45157
  %45376 = load i64, i64* %remaing_gas, align 4
  %45377 = icmp ugt i64 496, %45376
  br i1 %45377, label %Abort, label %45378

45378:                                            ; preds = %.14777
  %45379 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45380 = xor i32 %45379, 3754
  %45381 = urem i32 %45380, 4096
  %45382 = getelementptr i8, i8 addrspace(1)* %4, i32 %45381
  %45383 = load i8, i8 addrspace(1)* %45382, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45382, align 1, !nosanitize !3
  store i32 1877, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45384 = sub i64 %45376, 496
  store i64 %45384, i64* %remaing_gas, align 4
  %45385 = load i64, i64* %STACK_DEP_PTR, align 4
  %45386 = sub i64 %45385, 2
  store i64 %45386, i64* %STACK_DEP_PTR, align 4
  %45387 = trunc i256 64 to i64
  %45388 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45387, i256* %45388)
  %45389 = load i256, i256* %45388, align 4
  %45390 = and i256 1461501637330902918203684832716283019655932542975, %45171
  %45391 = and i256 1461501637330902918203684832716283019655932542975, %45390
  %45392 = trunc i256 %45389 to i64
  %45393 = alloca i256, align 8
  store i256 %45391, i256* %45393, align 4
  %45394 = bitcast i256* %45393 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %45392, i8* %45394, i64 32)
  %45395 = add i256 32, %45389, !pc !660, !intsan !10
  %45396 = trunc i256 %45395 to i64
  %45397 = alloca i256, align 8
  store i256 %45166, i256* %45397, align 4
  %45398 = bitcast i256* %45397 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %45396, i8* %45398, i64 32)
  %45399 = add i256 32, %45395, !pc !661, !intsan !10
  %45400 = trunc i256 64 to i64
  %45401 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45400, i256* %45401)
  %45402 = load i256, i256* %45401, align 4
  %45403 = sub i256 %45399, %45402, !pc !662, !intsan !8
  %45404 = trunc i256 -48591815262623346795851600524949351873237659767009746238783547601244776008699 to i64
  call void @addBugSet(i64 %45404)
  %45405 = alloca i256, align 8
  store i256 8, i256* %45405, align 4
  %45406 = alloca i256, align 8
  call void @__device_sload(i256* %45405, i256* %45406)
  %45407 = call i32 @__hashword(i256* %45405)
  %45408 = load i32, i32* %5, align 4
  %45409 = icmp eq i32 %45407, %45408
  %45410 = or i1 false, %45409
  %45411 = load i32, i32* %6, align 4
  %45412 = icmp eq i32 %45407, %45411
  %45413 = or i1 %45410, %45412
  %45414 = load i32, i32* %7, align 4
  %45415 = icmp eq i32 %45407, %45414
  %45416 = or i1 %45413, %45415
  %45417 = load i32, i32* %8, align 4
  %45418 = icmp eq i32 %45407, %45417
  %45419 = or i1 %45416, %45418
  %45420 = load i32, i32* %9, align 4
  %45421 = icmp eq i32 %45407, %45420
  %45422 = or i1 %45419, %45421
  %45423 = load i32, i32* %10, align 4
  %45424 = icmp eq i32 %45407, %45423
  %45425 = or i1 %45422, %45424
  %45426 = load i32, i32* %11, align 4
  %45427 = icmp eq i32 %45407, %45426
  %45428 = or i1 %45425, %45427
  %45429 = load i32, i32* %12, align 4
  %45430 = icmp eq i32 %45407, %45429
  %45431 = or i1 %45428, %45430
  %45432 = load i32, i32* %13, align 4
  %45433 = icmp eq i32 %45407, %45432
  %45434 = or i1 %45431, %45433
  %45435 = load i32, i32* %14, align 4
  %45436 = icmp eq i32 %45407, %45435
  %45437 = or i1 %45434, %45436
  %45438 = load i32, i32* %15, align 4
  %45439 = icmp eq i32 %45407, %45438
  %45440 = or i1 %45437, %45439
  %45441 = load i32, i32* %16, align 4
  %45442 = icmp eq i32 %45407, %45441
  %45443 = or i1 %45440, %45442
  %45444 = load i32, i32* %17, align 4
  %45445 = icmp eq i32 %45407, %45444
  %45446 = or i1 %45443, %45445
  %45447 = load i32, i32* %18, align 4
  %45448 = icmp eq i32 %45407, %45447
  %45449 = or i1 %45446, %45448
  %45450 = load i32, i32* %19, align 4
  %45451 = icmp eq i32 %45407, %45450
  %45452 = or i1 %45449, %45451
  %45453 = load i32, i32* %20, align 4
  %45454 = icmp eq i32 %45407, %45453
  %45455 = or i1 %45452, %45454
  %45456 = load i32, i32* %21, align 4
  %45457 = icmp eq i32 %45407, %45456
  %45458 = or i1 %45455, %45457
  %45459 = load i32, i32* %22, align 4
  %45460 = icmp eq i32 %45407, %45459
  %45461 = or i1 %45458, %45460
  %45462 = load i32, i32* %23, align 4
  %45463 = icmp eq i32 %45407, %45462
  %45464 = or i1 %45461, %45463
  %45465 = load i32, i32* %24, align 4
  %45466 = icmp eq i32 %45407, %45465
  %45467 = or i1 %45464, %45466
  %45468 = load i32, i32* %25, align 4
  %45469 = icmp eq i32 %45407, %45468
  %45470 = or i1 %45467, %45469
  %45471 = load i32, i32* %26, align 4
  %45472 = icmp eq i32 %45407, %45471
  %45473 = or i1 %45470, %45472
  %45474 = load i32, i32* %27, align 4
  %45475 = icmp eq i32 %45407, %45474
  %45476 = or i1 %45473, %45475
  %45477 = load i32, i32* %28, align 4
  %45478 = icmp eq i32 %45407, %45477
  %45479 = or i1 %45476, %45478
  %45480 = load i32, i32* %29, align 4
  %45481 = icmp eq i32 %45407, %45480
  %45482 = or i1 %45479, %45481
  %45483 = load i32, i32* %30, align 4
  %45484 = icmp eq i32 %45407, %45483
  %45485 = or i1 %45482, %45484
  %45486 = load i32, i32* %31, align 4
  %45487 = icmp eq i32 %45407, %45486
  %45488 = or i1 %45485, %45487
  %45489 = load i32, i32* %32, align 4
  %45490 = icmp eq i32 %45407, %45489
  %45491 = or i1 %45488, %45490
  %45492 = load i32, i32* %33, align 4
  %45493 = icmp eq i32 %45407, %45492
  %45494 = or i1 %45491, %45493
  %45495 = load i32, i32* %34, align 4
  %45496 = icmp eq i32 %45407, %45495
  %45497 = or i1 %45494, %45496
  %45498 = load i32, i32* %35, align 4
  %45499 = icmp eq i32 %45407, %45498
  %45500 = or i1 %45497, %45499
  %45501 = load i32, i32* %36, align 4
  %45502 = icmp eq i32 %45407, %45501
  %45503 = or i1 %45500, %45502
  %45504 = load i32, i32* %37, align 4
  %45505 = icmp eq i32 %45407, %45504
  %45506 = or i1 %45503, %45505
  %45507 = load i32, i32* %38, align 4
  %45508 = icmp eq i32 %45407, %45507
  %45509 = or i1 %45506, %45508
  %45510 = load i32, i32* %39, align 4
  %45511 = icmp eq i32 %45407, %45510
  %45512 = or i1 %45509, %45511
  %45513 = load i32, i32* %40, align 4
  %45514 = icmp eq i32 %45407, %45513
  %45515 = or i1 %45512, %45514
  %45516 = load i32, i32* %41, align 4
  %45517 = icmp eq i32 %45407, %45516
  %45518 = or i1 %45515, %45517
  %45519 = load i32, i32* %42, align 4
  %45520 = icmp eq i32 %45407, %45519
  %45521 = or i1 %45518, %45520
  %45522 = load i32, i32* %43, align 4
  %45523 = icmp eq i32 %45407, %45522
  %45524 = or i1 %45521, %45523
  %45525 = load i32, i32* %44, align 4
  %45526 = icmp eq i32 %45407, %45525
  %45527 = or i1 %45524, %45526
  %45528 = load i32, i32* %45, align 4
  %45529 = icmp eq i32 %45407, %45528
  %45530 = or i1 %45527, %45529
  %45531 = load i32, i32* %46, align 4
  %45532 = icmp eq i32 %45407, %45531
  %45533 = or i1 %45530, %45532
  %45534 = load i32, i32* %47, align 4
  %45535 = icmp eq i32 %45407, %45534
  %45536 = or i1 %45533, %45535
  %45537 = load i32, i32* %48, align 4
  %45538 = icmp eq i32 %45407, %45537
  %45539 = or i1 %45536, %45538
  %45540 = load i32, i32* %49, align 4
  %45541 = icmp eq i32 %45407, %45540
  %45542 = or i1 %45539, %45541
  %45543 = load i32, i32* %50, align 4
  %45544 = icmp eq i32 %45407, %45543
  %45545 = or i1 %45542, %45544
  %45546 = load i32, i32* %51, align 4
  %45547 = icmp eq i32 %45407, %45546
  %45548 = or i1 %45545, %45547
  %45549 = load i32, i32* %52, align 4
  %45550 = icmp eq i32 %45407, %45549
  %45551 = or i1 %45548, %45550
  %45552 = load i32, i32* %53, align 4
  %45553 = icmp eq i32 %45407, %45552
  %45554 = or i1 %45551, %45553
  %45555 = load i32, i32* %54, align 4
  %45556 = icmp eq i32 %45407, %45555
  %45557 = or i1 %45554, %45556
  %45558 = load i32, i32* %55, align 4
  %45559 = icmp eq i32 %45407, %45558
  %45560 = or i1 %45557, %45559
  %45561 = load i32, i32* %56, align 4
  %45562 = icmp eq i32 %45407, %45561
  %45563 = or i1 %45560, %45562
  %45564 = load i32, i32* %57, align 4
  %45565 = icmp eq i32 %45407, %45564
  %45566 = or i1 %45563, %45565
  %45567 = load i32, i32* %58, align 4
  %45568 = icmp eq i32 %45407, %45567
  %45569 = or i1 %45566, %45568
  %45570 = load i32, i32* %59, align 4
  %45571 = icmp eq i32 %45407, %45570
  %45572 = or i1 %45569, %45571
  %45573 = load i32, i32* %60, align 4
  %45574 = icmp eq i32 %45407, %45573
  %45575 = or i1 %45572, %45574
  %45576 = load i32, i32* %61, align 4
  %45577 = icmp eq i32 %45407, %45576
  %45578 = or i1 %45575, %45577
  %45579 = load i32, i32* %62, align 4
  %45580 = icmp eq i32 %45407, %45579
  %45581 = or i1 %45578, %45580
  %45582 = getelementptr i8, i8 addrspace(1)* %4, i32 166
  %45583 = zext i1 %45581 to i8
  store i8 %45583, i8 addrspace(1)* %45582, align 1, !nosanitize !3
  %45584 = load i256, i256* %45406, align 4
  %45585 = alloca i256, align 8
  store i256 %45584, i256* %45585, align 4
  %45586 = alloca i256, align 8
  store i256 1, i256* %45586, align 4
  %45587 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %45585, i256* %45586, i256* %45587), !pc !663, !intsan !6
  %45588 = load i256, i256* %45587, align 4
  %45589 = and i256 1461501637330902918203684832716283019655932542975, %45588
  %45590 = and i256 1461501637330902918203684832716283019655932542975, %45589
  %45591 = and i256 1461501637330902918203684832716283019655932542975, %45171
  %45592 = icmp eq i256 %45591, %45590
  %45593 = icmp eq i1 %45592, false
  %45594 = icmp eq i1 %45593, false
  %45595 = trunc i256 15201 to i64
  %jump.check108 = icmp ne i1 %45594, false
  %45596 = load i64, i64* %STACK_DEP_PTR, align 4
  %45597 = add i64 %45596, 1
  store i64 %45597, i64* %STACK_DEP_PTR, align 4
  %45598 = load i64, i64* %STACK_DEP_PTR, align 4
  %45599 = getelementptr i256, i256* %STACK, i64 %45598
  store i256 %45171, i256* %45599, align 4
  %45600 = load i64, i64* %STACK_DEP_PTR, align 4
  %45601 = add i64 %45600, 1
  store i64 %45601, i64* %STACK_DEP_PTR, align 4
  %45602 = load i64, i64* %STACK_DEP_PTR, align 4
  %45603 = getelementptr i256, i256* %STACK, i64 %45602
  store i256 %45166, i256* %45603, align 4
  br i1 %jump.check108, label %.15201, label %.14971, !EVMBB !4

.14971:                                           ; preds = %45378
  %45604 = load i64, i64* %remaing_gas, align 4
  %45605 = icmp ugt i64 368, %45604
  br i1 %45605, label %Abort, label %45606

45606:                                            ; preds = %.14971
  %45607 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45608 = xor i32 %45607, 2434
  %45609 = urem i32 %45608, 4096
  %45610 = getelementptr i8, i8 addrspace(1)* %4, i32 %45609
  %45611 = load i8, i8 addrspace(1)* %45610, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %45610, align 1, !nosanitize !3
  store i32 1217, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %45612 = sub i64 %45604, 368
  store i64 %45612, i64* %remaing_gas, align 4
  %45613 = load i64, i64* %STACK_DEP_PTR, align 4
  %45614 = sub i64 %45613, 1
  store i64 %45614, i64* %STACK_DEP_PTR, align 4
  %45615 = alloca i256, align 8
  store i256 8, i256* %45615, align 4
  %45616 = alloca i256, align 8
  call void @__device_sload(i256* %45615, i256* %45616)
  %45617 = call i32 @__hashword(i256* %45615)
  %45618 = load i32, i32* %5, align 4
  %45619 = icmp eq i32 %45617, %45618
  %45620 = or i1 false, %45619
  %45621 = load i32, i32* %6, align 4
  %45622 = icmp eq i32 %45617, %45621
  %45623 = or i1 %45620, %45622
  %45624 = load i32, i32* %7, align 4
  %45625 = icmp eq i32 %45617, %45624
  %45626 = or i1 %45623, %45625
  %45627 = load i32, i32* %8, align 4
  %45628 = icmp eq i32 %45617, %45627
  %45629 = or i1 %45626, %45628
  %45630 = load i32, i32* %9, align 4
  %45631 = icmp eq i32 %45617, %45630
  %45632 = or i1 %45629, %45631
  %45633 = load i32, i32* %10, align 4
  %45634 = icmp eq i32 %45617, %45633
  %45635 = or i1 %45632, %45634
  %45636 = load i32, i32* %11, align 4
  %45637 = icmp eq i32 %45617, %45636
  %45638 = or i1 %45635, %45637
  %45639 = load i32, i32* %12, align 4
  %45640 = icmp eq i32 %45617, %45639
  %45641 = or i1 %45638, %45640
  %45642 = load i32, i32* %13, align 4
  %45643 = icmp eq i32 %45617, %45642
  %45644 = or i1 %45641, %45643
  %45645 = load i32, i32* %14, align 4
  %45646 = icmp eq i32 %45617, %45645
  %45647 = or i1 %45644, %45646
  %45648 = load i32, i32* %15, align 4
  %45649 = icmp eq i32 %45617, %45648
  %45650 = or i1 %45647, %45649
  %45651 = load i32, i32* %16, align 4
  %45652 = icmp eq i32 %45617, %45651
  %45653 = or i1 %45650, %45652
  %45654 = load i32, i32* %17, align 4
  %45655 = icmp eq i32 %45617, %45654
  %45656 = or i1 %45653, %45655
  %45657 = load i32, i32* %18, align 4
  %45658 = icmp eq i32 %45617, %45657
  %45659 = or i1 %45656, %45658
  %45660 = load i32, i32* %19, align 4
  %45661 = icmp eq i32 %45617, %45660
  %45662 = or i1 %45659, %45661
  %45663 = load i32, i32* %20, align 4
  %45664 = icmp eq i32 %45617, %45663
  %45665 = or i1 %45662, %45664
  %45666 = load i32, i32* %21, align 4
  %45667 = icmp eq i32 %45617, %45666
  %45668 = or i1 %45665, %45667
  %45669 = load i32, i32* %22, align 4
  %45670 = icmp eq i32 %45617, %45669
  %45671 = or i1 %45668, %45670
  %45672 = load i32, i32* %23, align 4
  %45673 = icmp eq i32 %45617, %45672
  %45674 = or i1 %45671, %45673
  %45675 = load i32, i32* %24, align 4
  %45676 = icmp eq i32 %45617, %45675
  %45677 = or i1 %45674, %45676
  %45678 = load i32, i32* %25, align 4
  %45679 = icmp eq i32 %45617, %45678
  %45680 = or i1 %45677, %45679
  %45681 = load i32, i32* %26, align 4
  %45682 = icmp eq i32 %45617, %45681
  %45683 = or i1 %45680, %45682
  %45684 = load i32, i32* %27, align 4
  %45685 = icmp eq i32 %45617, %45684
  %45686 = or i1 %45683, %45685
  %45687 = load i32, i32* %28, align 4
  %45688 = icmp eq i32 %45617, %45687
  %45689 = or i1 %45686, %45688
  %45690 = load i32, i32* %29, align 4
  %45691 = icmp eq i32 %45617, %45690
  %45692 = or i1 %45689, %45691
  %45693 = load i32, i32* %30, align 4
  %45694 = icmp eq i32 %45617, %45693
  %45695 = or i1 %45692, %45694
  %45696 = load i32, i32* %31, align 4
  %45697 = icmp eq i32 %45617, %45696
  %45698 = or i1 %45695, %45697
  %45699 = load i32, i32* %32, align 4
  %45700 = icmp eq i32 %45617, %45699
  %45701 = or i1 %45698, %45700
  %45702 = load i32, i32* %33, align 4
  %45703 = icmp eq i32 %45617, %45702
  %45704 = or i1 %45701, %45703
  %45705 = load i32, i32* %34, align 4
  %45706 = icmp eq i32 %45617, %45705
  %45707 = or i1 %45704, %45706
  %45708 = load i32, i32* %35, align 4
  %45709 = icmp eq i32 %45617, %45708
  %45710 = or i1 %45707, %45709
  %45711 = load i32, i32* %36, align 4
  %45712 = icmp eq i32 %45617, %45711
  %45713 = or i1 %45710, %45712
  %45714 = load i32, i32* %37, align 4
  %45715 = icmp eq i32 %45617, %45714
  %45716 = or i1 %45713, %45715
  %45717 = load i32, i32* %38, align 4
  %45718 = icmp eq i32 %45617, %45717
  %45719 = or i1 %45716, %45718
  %45720 = load i32, i32* %39, align 4
  %45721 = icmp eq i32 %45617, %45720
  %45722 = or i1 %45719, %45721
  %45723 = load i32, i32* %40, align 4
  %45724 = icmp eq i32 %45617, %45723
  %45725 = or i1 %45722, %45724
  %45726 = load i32, i32* %41, align 4
  %45727 = icmp eq i32 %45617, %45726
  %45728 = or i1 %45725, %45727
  %45729 = load i32, i32* %42, align 4
  %45730 = icmp eq i32 %45617, %45729
  %45731 = or i1 %45728, %45730
  %45732 = load i32, i32* %43, align 4
  %45733 = icmp eq i32 %45617, %45732
  %45734 = or i1 %45731, %45733
  %45735 = load i32, i32* %44, align 4
  %45736 = icmp eq i32 %45617, %45735
  %45737 = or i1 %45734, %45736
  %45738 = load i32, i32* %45, align 4
  %45739 = icmp eq i32 %45617, %45738
  %45740 = or i1 %45737, %45739
  %45741 = load i32, i32* %46, align 4
  %45742 = icmp eq i32 %45617, %45741
  %45743 = or i1 %45740, %45742
  %45744 = load i32, i32* %47, align 4
  %45745 = icmp eq i32 %45617, %45744
  %45746 = or i1 %45743, %45745
  %45747 = load i32, i32* %48, align 4
  %45748 = icmp eq i32 %45617, %45747
  %45749 = or i1 %45746, %45748
  %45750 = load i32, i32* %49, align 4
  %45751 = icmp eq i32 %45617, %45750
  %45752 = or i1 %45749, %45751
  %45753 = load i32, i32* %50, align 4
  %45754 = icmp eq i32 %45617, %45753
  %45755 = or i1 %45752, %45754
  %45756 = load i32, i32* %51, align 4
  %45757 = icmp eq i32 %45617, %45756
  %45758 = or i1 %45755, %45757
  %45759 = load i32, i32* %52, align 4
  %45760 = icmp eq i32 %45617, %45759
  %45761 = or i1 %45758, %45760
  %45762 = load i32, i32* %53, align 4
  %45763 = icmp eq i32 %45617, %45762
  %45764 = or i1 %45761, %45763
  %45765 = load i32, i32* %54, align 4
  %45766 = icmp eq i32 %45617, %45765
  %45767 = or i1 %45764, %45766
  %45768 = load i32, i32* %55, align 4
  %45769 = icmp eq i32 %45617, %45768
  %45770 = or i1 %45767, %45769
  %45771 = load i32, i32* %56, align 4
  %45772 = icmp eq i32 %45617, %45771
  %45773 = or i1 %45770, %45772
  %45774 = load i32, i32* %57, align 4
  %45775 = icmp eq i32 %45617, %45774
  %45776 = or i1 %45773, %45775
  %45777 = load i32, i32* %58, align 4
  %45778 = icmp eq i32 %45617, %45777
  %45779 = or i1 %45776, %45778
  %45780 = load i32, i32* %59, align 4
  %45781 = icmp eq i32 %45617, %45780
  %45782 = or i1 %45779, %45781
  %45783 = load i32, i32* %60, align 4
  %45784 = icmp eq i32 %45617, %45783
  %45785 = or i1 %45782, %45784
  %45786 = load i32, i32* %61, align 4
  %45787 = icmp eq i32 %45617, %45786
  %45788 = or i1 %45785, %45787
  %45789 = load i32, i32* %62, align 4
  %45790 = icmp eq i32 %45617, %45789
  %45791 = or i1 %45788, %45790
  %45792 = getelementptr i8, i8 addrspace(1)* %4, i32 167
  %45793 = zext i1 %45791 to i8
  store i8 %45793, i8 addrspace(1)* %45792, align 1, !nosanitize !3
  %45794 = load i256, i256* %45616, align 4
  %45795 = alloca i256, align 8
  store i256 %45794, i256* %45795, align 4
  %45796 = alloca i256, align 8
  store i256 1, i256* %45796, align 4
  %45797 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %45795, i256* %45796, i256* %45797), !pc !664, !intsan !6
  %45798 = load i256, i256* %45797, align 4
  %45799 = and i256 1461501637330902918203684832716283019655932542975, %45798
  %45800 = and i256 1461501637330902918203684832716283019655932542975, %45799
  %45801 = alloca i256, align 8
  store i256 2, i256* %45801, align 4
  %45802 = alloca i256, align 8
  call void @__device_sload(i256* %45801, i256* %45802)
  %45803 = call i32 @__hashword(i256* %45801)
  %45804 = load i32, i32* %5, align 4
  %45805 = icmp eq i32 %45803, %45804
  %45806 = or i1 false, %45805
  %45807 = load i32, i32* %6, align 4
  %45808 = icmp eq i32 %45803, %45807
  %45809 = or i1 %45806, %45808
  %45810 = load i32, i32* %7, align 4
  %45811 = icmp eq i32 %45803, %45810
  %45812 = or i1 %45809, %45811
  %45813 = load i32, i32* %8, align 4
  %45814 = icmp eq i32 %45803, %45813
  %45815 = or i1 %45812, %45814
  %45816 = load i32, i32* %9, align 4
  %45817 = icmp eq i32 %45803, %45816
  %45818 = or i1 %45815, %45817
  %45819 = load i32, i32* %10, align 4
  %45820 = icmp eq i32 %45803, %45819
  %45821 = or i1 %45818, %45820
  %45822 = load i32, i32* %11, align 4
  %45823 = icmp eq i32 %45803, %45822
  %45824 = or i1 %45821, %45823
  %45825 = load i32, i32* %12, align 4
  %45826 = icmp eq i32 %45803, %45825
  %45827 = or i1 %45824, %45826
  %45828 = load i32, i32* %13, align 4
  %45829 = icmp eq i32 %45803, %45828
  %45830 = or i1 %45827, %45829
  %45831 = load i32, i32* %14, align 4
  %45832 = icmp eq i32 %45803, %45831
  %45833 = or i1 %45830, %45832
  %45834 = load i32, i32* %15, align 4
  %45835 = icmp eq i32 %45803, %45834
  %45836 = or i1 %45833, %45835
  %45837 = load i32, i32* %16, align 4
  %45838 = icmp eq i32 %45803, %45837
  %45839 = or i1 %45836, %45838
  %45840 = load i32, i32* %17, align 4
  %45841 = icmp eq i32 %45803, %45840
  %45842 = or i1 %45839, %45841
  %45843 = load i32, i32* %18, align 4
  %45844 = icmp eq i32 %45803, %45843
  %45845 = or i1 %45842, %45844
  %45846 = load i32, i32* %19, align 4
  %45847 = icmp eq i32 %45803, %45846
  %45848 = or i1 %45845, %45847
  %45849 = load i32, i32* %20, align 4
  %45850 = icmp eq i32 %45803, %45849
  %45851 = or i1 %45848, %45850
  %45852 = load i32, i32* %21, align 4
  %45853 = icmp eq i32 %45803, %45852
  %45854 = or i1 %45851, %45853
  %45855 = load i32, i32* %22, align 4
  %45856 = icmp eq i32 %45803, %45855
  %45857 = or i1 %45854, %45856
  %45858 = load i32, i32* %23, align 4
  %45859 = icmp eq i32 %45803, %45858
  %45860 = or i1 %45857, %45859
  %45861 = load i32, i32* %24, align 4
  %45862 = icmp eq i32 %45803, %45861
  %45863 = or i1 %45860, %45862
  %45864 = load i32, i32* %25, align 4
  %45865 = icmp eq i32 %45803, %45864
  %45866 = or i1 %45863, %45865
  %45867 = load i32, i32* %26, align 4
  %45868 = icmp eq i32 %45803, %45867
  %45869 = or i1 %45866, %45868
  %45870 = load i32, i32* %27, align 4
  %45871 = icmp eq i32 %45803, %45870
  %45872 = or i1 %45869, %45871
  %45873 = load i32, i32* %28, align 4
  %45874 = icmp eq i32 %45803, %45873
  %45875 = or i1 %45872, %45874
  %45876 = load i32, i32* %29, align 4
  %45877 = icmp eq i32 %45803, %45876
  %45878 = or i1 %45875, %45877
  %45879 = load i32, i32* %30, align 4
  %45880 = icmp eq i32 %45803, %45879
  %45881 = or i1 %45878, %45880
  %45882 = load i32, i32* %31, align 4
  %45883 = icmp eq i32 %45803, %45882
  %45884 = or i1 %45881, %45883
  %45885 = load i32, i32* %32, align 4
  %45886 = icmp eq i32 %45803, %45885
  %45887 = or i1 %45884, %45886
  %45888 = load i32, i32* %33, align 4
  %45889 = icmp eq i32 %45803, %45888
  %45890 = or i1 %45887, %45889
  %45891 = load i32, i32* %34, align 4
  %45892 = icmp eq i32 %45803, %45891
  %45893 = or i1 %45890, %45892
  %45894 = load i32, i32* %35, align 4
  %45895 = icmp eq i32 %45803, %45894
  %45896 = or i1 %45893, %45895
  %45897 = load i32, i32* %36, align 4
  %45898 = icmp eq i32 %45803, %45897
  %45899 = or i1 %45896, %45898
  %45900 = load i32, i32* %37, align 4
  %45901 = icmp eq i32 %45803, %45900
  %45902 = or i1 %45899, %45901
  %45903 = load i32, i32* %38, align 4
  %45904 = icmp eq i32 %45803, %45903
  %45905 = or i1 %45902, %45904
  %45906 = load i32, i32* %39, align 4
  %45907 = icmp eq i32 %45803, %45906
  %45908 = or i1 %45905, %45907
  %45909 = load i32, i32* %40, align 4
  %45910 = icmp eq i32 %45803, %45909
  %45911 = or i1 %45908, %45910
  %45912 = load i32, i32* %41, align 4
  %45913 = icmp eq i32 %45803, %45912
  %45914 = or i1 %45911, %45913
  %45915 = load i32, i32* %42, align 4
  %45916 = icmp eq i32 %45803, %45915
  %45917 = or i1 %45914, %45916
  %45918 = load i32, i32* %43, align 4
  %45919 = icmp eq i32 %45803, %45918
  %45920 = or i1 %45917, %45919
  %45921 = load i32, i32* %44, align 4
  %45922 = icmp eq i32 %45803, %45921
  %45923 = or i1 %45920, %45922
  %45924 = load i32, i32* %45, align 4
  %45925 = icmp eq i32 %45803, %45924
  %45926 = or i1 %45923, %45925
  %45927 = load i32, i32* %46, align 4
  %45928 = icmp eq i32 %45803, %45927
  %45929 = or i1 %45926, %45928
  %45930 = load i32, i32* %47, align 4
  %45931 = icmp eq i32 %45803, %45930
  %45932 = or i1 %45929, %45931
  %45933 = load i32, i32* %48, align 4
  %45934 = icmp eq i32 %45803, %45933
  %45935 = or i1 %45932, %45934
  %45936 = load i32, i32* %49, align 4
  %45937 = icmp eq i32 %45803, %45936
  %45938 = or i1 %45935, %45937
  %45939 = load i32, i32* %50, align 4
  %45940 = icmp eq i32 %45803, %45939
  %45941 = or i1 %45938, %45940
  %45942 = load i32, i32* %51, align 4
  %45943 = icmp eq i32 %45803, %45942
  %45944 = or i1 %45941, %45943
  %45945 = load i32, i32* %52, align 4
  %45946 = icmp eq i32 %45803, %45945
  %45947 = or i1 %45944, %45946
  %45948 = load i32, i32* %53, align 4
  %45949 = icmp eq i32 %45803, %45948
  %45950 = or i1 %45947, %45949
  %45951 = load i32, i32* %54, align 4
  %45952 = icmp eq i32 %45803, %45951
  %45953 = or i1 %45950, %45952
  %45954 = load i32, i32* %55, align 4
  %45955 = icmp eq i32 %45803, %45954
  %45956 = or i1 %45953, %45955
  %45957 = load i32, i32* %56, align 4
  %45958 = icmp eq i32 %45803, %45957
  %45959 = or i1 %45956, %45958
  %45960 = load i32, i32* %57, align 4
  %45961 = icmp eq i32 %45803, %45960
  %45962 = or i1 %45959, %45961
  %45963 = load i32, i32* %58, align 4
  %45964 = icmp eq i32 %45803, %45963
  %45965 = or i1 %45962, %45964
  %45966 = load i32, i32* %59, align 4
  %45967 = icmp eq i32 %45803, %45966
  %45968 = or i1 %45965, %45967
  %45969 = load i32, i32* %60, align 4
  %45970 = icmp eq i32 %45803, %45969
  %45971 = or i1 %45968, %45970
  %45972 = load i32, i32* %61, align 4
  %45973 = icmp eq i32 %45803, %45972
  %45974 = or i1 %45971, %45973
  %45975 = load i32, i32* %62, align 4
  %45976 = icmp eq i32 %45803, %45975
  %45977 = or i1 %45974, %45976
  %45978 = getelementptr i8, i8 addrspace(1)* %4, i32 168
  %45979 = zext i1 %45977 to i8
  store i8 %45979, i8 addrspace(1)* %45978, align 1, !nosanitize !3
  %45980 = load i256, i256* %45802, align 4
  %45981 = trunc i256 64 to i64
  %45982 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45981, i256* %45982)
  %45983 = load i256, i256* %45982, align 4
  %45984 = trunc i256 64 to i64
  %45985 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %45984, i256* %45985)
  %45986 = load i256, i256* %45985, align 4
  %45987 = sub i256 %45983, %45986, !pc !665, !intsan !8
  %45988 = trunc i256 %45980 to i64
  %45989 = trunc i256 %45800 to i160
  %45990 = call i1 @solidity_call(), !pc !666
  %45991 = icmp eq i1 %45990, false
  %45992 = icmp eq i1 %45991, false
  %45993 = trunc i256 15200 to i64
  %jump.check114 = icmp ne i1 %45992, false
  %45994 = load i64, i64* %STACK_DEP_PTR, align 4
  %45995 = add i64 %45994, 1
  store i64 %45995, i64* %STACK_DEP_PTR, align 4
  %45996 = load i64, i64* %STACK_DEP_PTR, align 4
  %45997 = getelementptr i256, i256* %STACK, i64 %45996
  store i256 %45166, i256* %45997, align 4
  br i1 %jump.check114, label %.15200, label %.15059, !EVMBB !4

.15059:                                           ; preds = %45606
  %45998 = load i64, i64* %STACK_DEP_PTR, align 4
  %45999 = sub i64 %45998, 1
  store i64 %45999, i64* %STACK_DEP_PTR, align 4
  %46000 = alloca i256, align 8
  store i256 8, i256* %46000, align 4
  %46001 = alloca i256, align 8
  call void @__device_sload(i256* %46000, i256* %46001)
  %46002 = call i32 @__hashword(i256* %46000)
  %46003 = load i32, i32* %5, align 4
  %46004 = icmp eq i32 %46002, %46003
  %46005 = or i1 false, %46004
  %46006 = load i32, i32* %6, align 4
  %46007 = icmp eq i32 %46002, %46006
  %46008 = or i1 %46005, %46007
  %46009 = load i32, i32* %7, align 4
  %46010 = icmp eq i32 %46002, %46009
  %46011 = or i1 %46008, %46010
  %46012 = load i32, i32* %8, align 4
  %46013 = icmp eq i32 %46002, %46012
  %46014 = or i1 %46011, %46013
  %46015 = load i32, i32* %9, align 4
  %46016 = icmp eq i32 %46002, %46015
  %46017 = or i1 %46014, %46016
  %46018 = load i32, i32* %10, align 4
  %46019 = icmp eq i32 %46002, %46018
  %46020 = or i1 %46017, %46019
  %46021 = load i32, i32* %11, align 4
  %46022 = icmp eq i32 %46002, %46021
  %46023 = or i1 %46020, %46022
  %46024 = load i32, i32* %12, align 4
  %46025 = icmp eq i32 %46002, %46024
  %46026 = or i1 %46023, %46025
  %46027 = load i32, i32* %13, align 4
  %46028 = icmp eq i32 %46002, %46027
  %46029 = or i1 %46026, %46028
  %46030 = load i32, i32* %14, align 4
  %46031 = icmp eq i32 %46002, %46030
  %46032 = or i1 %46029, %46031
  %46033 = load i32, i32* %15, align 4
  %46034 = icmp eq i32 %46002, %46033
  %46035 = or i1 %46032, %46034
  %46036 = load i32, i32* %16, align 4
  %46037 = icmp eq i32 %46002, %46036
  %46038 = or i1 %46035, %46037
  %46039 = load i32, i32* %17, align 4
  %46040 = icmp eq i32 %46002, %46039
  %46041 = or i1 %46038, %46040
  %46042 = load i32, i32* %18, align 4
  %46043 = icmp eq i32 %46002, %46042
  %46044 = or i1 %46041, %46043
  %46045 = load i32, i32* %19, align 4
  %46046 = icmp eq i32 %46002, %46045
  %46047 = or i1 %46044, %46046
  %46048 = load i32, i32* %20, align 4
  %46049 = icmp eq i32 %46002, %46048
  %46050 = or i1 %46047, %46049
  %46051 = load i32, i32* %21, align 4
  %46052 = icmp eq i32 %46002, %46051
  %46053 = or i1 %46050, %46052
  %46054 = load i32, i32* %22, align 4
  %46055 = icmp eq i32 %46002, %46054
  %46056 = or i1 %46053, %46055
  %46057 = load i32, i32* %23, align 4
  %46058 = icmp eq i32 %46002, %46057
  %46059 = or i1 %46056, %46058
  %46060 = load i32, i32* %24, align 4
  %46061 = icmp eq i32 %46002, %46060
  %46062 = or i1 %46059, %46061
  %46063 = load i32, i32* %25, align 4
  %46064 = icmp eq i32 %46002, %46063
  %46065 = or i1 %46062, %46064
  %46066 = load i32, i32* %26, align 4
  %46067 = icmp eq i32 %46002, %46066
  %46068 = or i1 %46065, %46067
  %46069 = load i32, i32* %27, align 4
  %46070 = icmp eq i32 %46002, %46069
  %46071 = or i1 %46068, %46070
  %46072 = load i32, i32* %28, align 4
  %46073 = icmp eq i32 %46002, %46072
  %46074 = or i1 %46071, %46073
  %46075 = load i32, i32* %29, align 4
  %46076 = icmp eq i32 %46002, %46075
  %46077 = or i1 %46074, %46076
  %46078 = load i32, i32* %30, align 4
  %46079 = icmp eq i32 %46002, %46078
  %46080 = or i1 %46077, %46079
  %46081 = load i32, i32* %31, align 4
  %46082 = icmp eq i32 %46002, %46081
  %46083 = or i1 %46080, %46082
  %46084 = load i32, i32* %32, align 4
  %46085 = icmp eq i32 %46002, %46084
  %46086 = or i1 %46083, %46085
  %46087 = load i32, i32* %33, align 4
  %46088 = icmp eq i32 %46002, %46087
  %46089 = or i1 %46086, %46088
  %46090 = load i32, i32* %34, align 4
  %46091 = icmp eq i32 %46002, %46090
  %46092 = or i1 %46089, %46091
  %46093 = load i32, i32* %35, align 4
  %46094 = icmp eq i32 %46002, %46093
  %46095 = or i1 %46092, %46094
  %46096 = load i32, i32* %36, align 4
  %46097 = icmp eq i32 %46002, %46096
  %46098 = or i1 %46095, %46097
  %46099 = load i32, i32* %37, align 4
  %46100 = icmp eq i32 %46002, %46099
  %46101 = or i1 %46098, %46100
  %46102 = load i32, i32* %38, align 4
  %46103 = icmp eq i32 %46002, %46102
  %46104 = or i1 %46101, %46103
  %46105 = load i32, i32* %39, align 4
  %46106 = icmp eq i32 %46002, %46105
  %46107 = or i1 %46104, %46106
  %46108 = load i32, i32* %40, align 4
  %46109 = icmp eq i32 %46002, %46108
  %46110 = or i1 %46107, %46109
  %46111 = load i32, i32* %41, align 4
  %46112 = icmp eq i32 %46002, %46111
  %46113 = or i1 %46110, %46112
  %46114 = load i32, i32* %42, align 4
  %46115 = icmp eq i32 %46002, %46114
  %46116 = or i1 %46113, %46115
  %46117 = load i32, i32* %43, align 4
  %46118 = icmp eq i32 %46002, %46117
  %46119 = or i1 %46116, %46118
  %46120 = load i32, i32* %44, align 4
  %46121 = icmp eq i32 %46002, %46120
  %46122 = or i1 %46119, %46121
  %46123 = load i32, i32* %45, align 4
  %46124 = icmp eq i32 %46002, %46123
  %46125 = or i1 %46122, %46124
  %46126 = load i32, i32* %46, align 4
  %46127 = icmp eq i32 %46002, %46126
  %46128 = or i1 %46125, %46127
  %46129 = load i32, i32* %47, align 4
  %46130 = icmp eq i32 %46002, %46129
  %46131 = or i1 %46128, %46130
  %46132 = load i32, i32* %48, align 4
  %46133 = icmp eq i32 %46002, %46132
  %46134 = or i1 %46131, %46133
  %46135 = load i32, i32* %49, align 4
  %46136 = icmp eq i32 %46002, %46135
  %46137 = or i1 %46134, %46136
  %46138 = load i32, i32* %50, align 4
  %46139 = icmp eq i32 %46002, %46138
  %46140 = or i1 %46137, %46139
  %46141 = load i32, i32* %51, align 4
  %46142 = icmp eq i32 %46002, %46141
  %46143 = or i1 %46140, %46142
  %46144 = load i32, i32* %52, align 4
  %46145 = icmp eq i32 %46002, %46144
  %46146 = or i1 %46143, %46145
  %46147 = load i32, i32* %53, align 4
  %46148 = icmp eq i32 %46002, %46147
  %46149 = or i1 %46146, %46148
  %46150 = load i32, i32* %54, align 4
  %46151 = icmp eq i32 %46002, %46150
  %46152 = or i1 %46149, %46151
  %46153 = load i32, i32* %55, align 4
  %46154 = icmp eq i32 %46002, %46153
  %46155 = or i1 %46152, %46154
  %46156 = load i32, i32* %56, align 4
  %46157 = icmp eq i32 %46002, %46156
  %46158 = or i1 %46155, %46157
  %46159 = load i32, i32* %57, align 4
  %46160 = icmp eq i32 %46002, %46159
  %46161 = or i1 %46158, %46160
  %46162 = load i32, i32* %58, align 4
  %46163 = icmp eq i32 %46002, %46162
  %46164 = or i1 %46161, %46163
  %46165 = load i32, i32* %59, align 4
  %46166 = icmp eq i32 %46002, %46165
  %46167 = or i1 %46164, %46166
  %46168 = load i32, i32* %60, align 4
  %46169 = icmp eq i32 %46002, %46168
  %46170 = or i1 %46167, %46169
  %46171 = load i32, i32* %61, align 4
  %46172 = icmp eq i32 %46002, %46171
  %46173 = or i1 %46170, %46172
  %46174 = load i32, i32* %62, align 4
  %46175 = icmp eq i32 %46002, %46174
  %46176 = or i1 %46173, %46175
  %46177 = getelementptr i8, i8 addrspace(1)* %4, i32 169
  %46178 = zext i1 %46176 to i8
  store i8 %46178, i8 addrspace(1)* %46177, align 1, !nosanitize !3
  %46179 = load i256, i256* %46001, align 4
  %46180 = alloca i256, align 8
  store i256 %46179, i256* %46180, align 4
  %46181 = alloca i256, align 8
  store i256 1, i256* %46181, align 4
  %46182 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %46180, i256* %46181, i256* %46182), !pc !667, !intsan !6
  %46183 = load i256, i256* %46182, align 4
  %46184 = and i256 1461501637330902918203684832716283019655932542975, %46183
  %46185 = trunc i256 64 to i64
  %46186 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46185, i256* %46186)
  %46187 = load i256, i256* %46186, align 4
  %46188 = and i256 1461501637330902918203684832716283019655932542975, %46184
  %46189 = and i256 1461501637330902918203684832716283019655932542975, %46188
  %46190 = trunc i256 %46187 to i64
  %46191 = alloca i256, align 8
  store i256 %46189, i256* %46191, align 4
  %46192 = bitcast i256* %46191 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46190, i8* %46192, i64 32)
  %46193 = add i256 32, %46187, !pc !668, !intsan !10
  %46194 = trunc i256 %46193 to i64
  %46195 = alloca i256, align 8
  store i256 %45166, i256* %46195, align 4
  %46196 = bitcast i256* %46195 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46194, i8* %46196, i64 32)
  %46197 = add i256 32, %46193, !pc !669, !intsan !10
  %46198 = trunc i256 64 to i64
  %46199 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46198, i256* %46199)
  %46200 = load i256, i256* %46199, align 4
  %46201 = sub i256 %46197, %46200, !pc !670, !intsan !8
  %46202 = trunc i256 -48591815262623346795851600524949351873237659767009746238783547601244776008699 to i64
  call void @addBugSet(i64 %46202)
  %46203 = load i64, i64* %STACK_DEP_PTR, align 4
  %46204 = add i64 %46203, 1
  store i64 %46204, i64* %STACK_DEP_PTR, align 4
  %46205 = load i64, i64* %STACK_DEP_PTR, align 4
  %46206 = getelementptr i256, i256* %STACK, i64 %46205
  store i256 %45166, i256* %46206, align 4
  br label %.15200

.15200:                                           ; preds = %.15059, %45606, %JumpTable
  br label %.15201

.15201:                                           ; preds = %.15200, %45378, %JumpTable
  br label %.15202

.15202:                                           ; preds = %.15201, %45157, %JumpTable
  %46207 = load i64, i64* %STACK_DEP_PTR, align 4
  %46208 = getelementptr i256, i256* %STACK, i64 %46207
  %46209 = load i256, i256* %46208, align 4
  %46210 = load i64, i64* %STACK_DEP_PTR, align 4
  %46211 = sub i64 %46210, 1
  store i64 %46211, i64* %STACK_DEP_PTR, align 4
  %46212 = load i64, i64* %STACK_DEP_PTR, align 4
  %46213 = getelementptr i256, i256* %STACK, i64 %46212
  %46214 = load i256, i256* %46213, align 4
  %46215 = load i64, i64* %STACK_DEP_PTR, align 4
  %46216 = sub i64 %46215, 1
  store i64 %46216, i64* %STACK_DEP_PTR, align 4
  %46217 = trunc i256 64 to i64
  %46218 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46217, i256* %46218)
  %46219 = load i256, i256* %46218, align 4
  %46220 = and i256 1461501637330902918203684832716283019655932542975, %46214
  %46221 = and i256 1461501637330902918203684832716283019655932542975, %46220
  %46222 = trunc i256 %46219 to i64
  %46223 = alloca i256, align 8
  store i256 %46221, i256* %46223, align 4
  %46224 = bitcast i256* %46223 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46222, i8* %46224, i64 32)
  %46225 = add i256 32, %46219, !pc !671, !intsan !10
  %46226 = trunc i256 %46225 to i64
  %46227 = alloca i256, align 8
  store i256 %46209, i256* %46227, align 4
  %46228 = bitcast i256* %46227 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46226, i8* %46228, i64 32)
  %46229 = add i256 32, %46225, !pc !672, !intsan !10
  %46230 = trunc i256 64 to i64
  %46231 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46230, i256* %46231)
  %46232 = load i256, i256* %46231, align 4
  %46233 = sub i256 %46229, %46232, !pc !673, !intsan !8
  %46234 = trunc i256 -25378834077956632512645652705008565836124427910572214841713460167610402954384 to i64
  call void @addBugSet(i64 %46234)
  %46235 = load i64, i64* %STACK_DEP_PTR, align 4
  %46236 = add i64 %46235, 1
  store i64 %46236, i64* %STACK_DEP_PTR, align 4
  %46237 = load i64, i64* %STACK_DEP_PTR, align 4
  %46238 = getelementptr i256, i256* %STACK, i64 %46237
  store i256 %46214, i256* %46238, align 4
  %46239 = load i64, i64* %STACK_DEP_PTR, align 4
  %46240 = add i64 %46239, 1
  store i64 %46240, i64* %STACK_DEP_PTR, align 4
  %46241 = load i64, i64* %STACK_DEP_PTR, align 4
  %46242 = getelementptr i256, i256* %STACK, i64 %46241
  store i256 %46209, i256* %46242, align 4
  br label %.15310

.15310:                                           ; preds = %.15202, %45137, %45093, %JumpTable
  %46243 = load i64, i64* %remaing_gas, align 4
  %46244 = icmp ugt i64 176, %46243
  br i1 %46244, label %Abort, label %46245

46245:                                            ; preds = %.15310
  %46246 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46247 = xor i32 %46246, 4042
  %46248 = urem i32 %46247, 4096
  %46249 = getelementptr i8, i8 addrspace(1)* %4, i32 %46248
  %46250 = load i8, i8 addrspace(1)* %46249, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46249, align 1, !nosanitize !3
  store i32 2021, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46251 = sub i64 %46243, 176
  store i64 %46251, i64* %remaing_gas, align 4
  %46252 = load i64, i64* %STACK_DEP_PTR, align 4
  %46253 = getelementptr i256, i256* %STACK, i64 %46252
  %46254 = load i256, i256* %46253, align 4
  %46255 = load i64, i64* %STACK_DEP_PTR, align 4
  %46256 = sub i64 %46255, 1
  store i64 %46256, i64* %STACK_DEP_PTR, align 4
  %46257 = load i64, i64* %STACK_DEP_PTR, align 4
  %46258 = getelementptr i256, i256* %STACK, i64 %46257
  %46259 = load i256, i256* %46258, align 4
  %46260 = load i64, i64* %STACK_DEP_PTR, align 4
  %46261 = sub i64 %46260, 1
  store i64 %46261, i64* %STACK_DEP_PTR, align 4
  %46262 = load i64, i64* %STACK_DEP_PTR, align 4
  %46263 = getelementptr i256, i256* %STACK, i64 %46262
  %46264 = load i256, i256* %46263, align 4
  %46265 = load i64, i64* %STACK_DEP_PTR, align 4
  %46266 = sub i64 %46265, 1
  store i64 %46266, i64* %STACK_DEP_PTR, align 4
  %46267 = trunc i256 %46264 to i64
  store i64 %46267, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.15314:                                           ; preds = %16798, %JumpTable
  %46268 = load i64, i64* %remaing_gas, align 4
  %46269 = icmp ugt i64 248, %46268
  br i1 %46269, label %Abort, label %46270

46270:                                            ; preds = %.15314
  %46271 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46272 = xor i32 %46271, 620
  %46273 = urem i32 %46272, 4096
  %46274 = getelementptr i8, i8 addrspace(1)* %4, i32 %46273
  %46275 = load i8, i8 addrspace(1)* %46274, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46274, align 1, !nosanitize !3
  store i32 310, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46276 = sub i64 %46268, 248
  store i64 %46276, i64* %remaing_gas, align 4
  %46277 = load i64, i64* %STACK_DEP_PTR, align 4
  %46278 = getelementptr i256, i256* %STACK, i64 %46277
  %46279 = load i256, i256* %46278, align 4
  %46280 = load i64, i64* %STACK_DEP_PTR, align 4
  %46281 = sub i64 %46280, 1
  store i64 %46281, i64* %STACK_DEP_PTR, align 4
  %46282 = sub i256 %46279, 1, !pc !674, !intsan !8
  %46283 = icmp ult i256 %46282, 7500
  %46284 = icmp eq i1 %46283, false
  %46285 = trunc i256 15550 to i64
  %jump.check219 = icmp ne i1 %46284, false
  %46286 = load i64, i64* %STACK_DEP_PTR, align 4
  %46287 = add i64 %46286, 1
  store i64 %46287, i64* %STACK_DEP_PTR, align 4
  %46288 = load i64, i64* %STACK_DEP_PTR, align 4
  %46289 = getelementptr i256, i256* %STACK, i64 %46288
  store i256 %46279, i256* %46289, align 4
  %46290 = load i64, i64* %STACK_DEP_PTR, align 4
  %46291 = add i64 %46290, 1
  store i64 %46291, i64* %STACK_DEP_PTR, align 4
  %46292 = load i64, i64* %STACK_DEP_PTR, align 4
  %46293 = getelementptr i256, i256* %STACK, i64 %46292
  store i256 0, i256* %46293, align 4
  %46294 = load i64, i64* %STACK_DEP_PTR, align 4
  %46295 = add i64 %46294, 1
  store i64 %46295, i64* %STACK_DEP_PTR, align 4
  %46296 = load i64, i64* %STACK_DEP_PTR, align 4
  %46297 = getelementptr i256, i256* %STACK, i64 %46296
  store i256 %46279, i256* %46297, align 4
  br i1 %jump.check219, label %.15550, label %.15331, !EVMBB !4

.15331:                                           ; preds = %46270
  %46298 = load i64, i64* %remaing_gas, align 4
  %46299 = icmp ugt i64 584, %46298
  br i1 %46299, label %Abort, label %46300

46300:                                            ; preds = %.15331
  %46301 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46302 = xor i32 %46301, 2633
  %46303 = urem i32 %46302, 4096
  %46304 = getelementptr i8, i8 addrspace(1)* %4, i32 %46303
  %46305 = load i8, i8 addrspace(1)* %46304, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46304, align 1, !nosanitize !3
  store i32 1316, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46306 = sub i64 %46298, 584
  store i64 %46306, i64* %remaing_gas, align 4
  %46307 = load i64, i64* %STACK_DEP_PTR, align 4
  %46308 = getelementptr i256, i256* %STACK, i64 %46307
  %46309 = load i256, i256* %46308, align 4
  %46310 = load i64, i64* %STACK_DEP_PTR, align 4
  %46311 = sub i64 %46310, 1
  store i64 %46311, i64* %STACK_DEP_PTR, align 4
  %46312 = load i64, i64* %STACK_DEP_PTR, align 4
  %46313 = getelementptr i256, i256* %STACK, i64 %46312
  %46314 = load i256, i256* %46313, align 4
  %46315 = load i64, i64* %STACK_DEP_PTR, align 4
  %46316 = sub i64 %46315, 1
  store i64 %46316, i64* %STACK_DEP_PTR, align 4
  %46317 = load i64, i64* %STACK_DEP_PTR, align 4
  %46318 = getelementptr i256, i256* %STACK, i64 %46317
  %46319 = load i256, i256* %46318, align 4
  %46320 = load i64, i64* %STACK_DEP_PTR, align 4
  %46321 = sub i64 %46320, 1
  store i64 %46321, i64* %STACK_DEP_PTR, align 4
  %46322 = load i64, i64* %STACK_DEP_PTR, align 4
  %46323 = getelementptr i256, i256* %STACK, i64 %46322
  %46324 = load i256, i256* %46323, align 4
  %46325 = load i64, i64* %STACK_DEP_PTR, align 4
  %46326 = sub i64 %46325, 1
  store i64 %46326, i64* %STACK_DEP_PTR, align 4
  %46327 = sub i256 10000, 190, !pc !675, !intsan !8
  %46328 = add i256 32, %46324, !pc !676, !intsan !10
  %46329 = trunc i256 %46328 to i64
  %46330 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46329, i256* %46330)
  %46331 = load i256, i256* %46330, align 4
  %46332 = mul i256 %46331, %46327, !pc !677, !intsan !45
  %46333 = icmp eq i256 7500, 0
  %46334 = icmp eq i1 %46333, false
  %46335 = trunc i256 15354 to i64
  %jump.check220 = icmp ne i1 %46334, false
  %46336 = load i64, i64* %STACK_DEP_PTR, align 4
  %46337 = add i64 %46336, 1
  store i64 %46337, i64* %STACK_DEP_PTR, align 4
  %46338 = load i64, i64* %STACK_DEP_PTR, align 4
  %46339 = getelementptr i256, i256* %STACK, i64 %46338
  store i256 %46324, i256* %46339, align 4
  %46340 = load i64, i64* %STACK_DEP_PTR, align 4
  %46341 = add i64 %46340, 1
  store i64 %46341, i64* %STACK_DEP_PTR, align 4
  %46342 = load i64, i64* %STACK_DEP_PTR, align 4
  %46343 = getelementptr i256, i256* %STACK, i64 %46342
  store i256 %46319, i256* %46343, align 4
  %46344 = load i64, i64* %STACK_DEP_PTR, align 4
  %46345 = add i64 %46344, 1
  store i64 %46345, i64* %STACK_DEP_PTR, align 4
  %46346 = load i64, i64* %STACK_DEP_PTR, align 4
  %46347 = getelementptr i256, i256* %STACK, i64 %46346
  store i256 %46314, i256* %46347, align 4
  %46348 = load i64, i64* %STACK_DEP_PTR, align 4
  %46349 = add i64 %46348, 1
  store i64 %46349, i64* %STACK_DEP_PTR, align 4
  %46350 = load i64, i64* %STACK_DEP_PTR, align 4
  %46351 = getelementptr i256, i256* %STACK, i64 %46350
  store i256 %46309, i256* %46351, align 4
  %46352 = load i64, i64* %STACK_DEP_PTR, align 4
  %46353 = add i64 %46352, 1
  store i64 %46353, i64* %STACK_DEP_PTR, align 4
  %46354 = load i64, i64* %STACK_DEP_PTR, align 4
  %46355 = getelementptr i256, i256* %STACK, i64 %46354
  store i256 7500, i256* %46355, align 4
  %46356 = load i64, i64* %STACK_DEP_PTR, align 4
  %46357 = add i64 %46356, 1
  store i64 %46357, i64* %STACK_DEP_PTR, align 4
  %46358 = load i64, i64* %STACK_DEP_PTR, align 4
  %46359 = getelementptr i256, i256* %STACK, i64 %46358
  store i256 %46332, i256* %46359, align 4
  br i1 %jump.check220, label %.15354, label %.15353, !EVMBB !4

.15353:                                           ; preds = %46300
  %46360 = load i64, i64* %remaing_gas, align 4
  %46361 = icmp ugt i64 16, %46360
  br i1 %46361, label %Abort, label %46362

46362:                                            ; preds = %.15353
  %46363 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46364 = xor i32 %46363, 686
  %46365 = urem i32 %46364, 4096
  %46366 = getelementptr i8, i8 addrspace(1)* %4, i32 %46365
  %46367 = load i8, i8 addrspace(1)* %46366, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46366, align 1, !nosanitize !3
  store i32 343, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46368 = sub i64 %46360, 16
  store i64 %46368, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.15354:                                           ; preds = %46300, %JumpTable
  %46369 = load i64, i64* %remaing_gas, align 4
  %46370 = icmp ugt i64 1032, %46369
  br i1 %46370, label %Abort, label %46371

46371:                                            ; preds = %.15354
  %46372 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46373 = xor i32 %46372, 3216
  %46374 = urem i32 %46373, 4096
  %46375 = getelementptr i8, i8 addrspace(1)* %4, i32 %46374
  %46376 = load i8, i8 addrspace(1)* %46375, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46375, align 1, !nosanitize !3
  store i32 1608, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46377 = sub i64 %46369, 1032
  store i64 %46377, i64* %remaing_gas, align 4
  %46378 = load i64, i64* %STACK_DEP_PTR, align 4
  %46379 = getelementptr i256, i256* %STACK, i64 %46378
  %46380 = load i256, i256* %46379, align 4
  %46381 = load i64, i64* %STACK_DEP_PTR, align 4
  %46382 = sub i64 %46381, 1
  store i64 %46382, i64* %STACK_DEP_PTR, align 4
  %46383 = load i64, i64* %STACK_DEP_PTR, align 4
  %46384 = getelementptr i256, i256* %STACK, i64 %46383
  %46385 = load i256, i256* %46384, align 4
  %46386 = load i64, i64* %STACK_DEP_PTR, align 4
  %46387 = sub i64 %46386, 1
  store i64 %46387, i64* %STACK_DEP_PTR, align 4
  %46388 = load i64, i64* %STACK_DEP_PTR, align 4
  %46389 = getelementptr i256, i256* %STACK, i64 %46388
  %46390 = load i256, i256* %46389, align 4
  %46391 = load i64, i64* %STACK_DEP_PTR, align 4
  %46392 = sub i64 %46391, 1
  store i64 %46392, i64* %STACK_DEP_PTR, align 4
  %46393 = load i64, i64* %STACK_DEP_PTR, align 4
  %46394 = getelementptr i256, i256* %STACK, i64 %46393
  %46395 = load i256, i256* %46394, align 4
  %46396 = load i64, i64* %STACK_DEP_PTR, align 4
  %46397 = sub i64 %46396, 1
  store i64 %46397, i64* %STACK_DEP_PTR, align 4
  %46398 = load i64, i64* %STACK_DEP_PTR, align 4
  %46399 = getelementptr i256, i256* %STACK, i64 %46398
  %46400 = load i256, i256* %46399, align 4
  %46401 = load i64, i64* %STACK_DEP_PTR, align 4
  %46402 = sub i64 %46401, 1
  store i64 %46402, i64* %STACK_DEP_PTR, align 4
  %46403 = load i64, i64* %STACK_DEP_PTR, align 4
  %46404 = getelementptr i256, i256* %STACK, i64 %46403
  %46405 = load i256, i256* %46404, align 4
  %46406 = load i64, i64* %STACK_DEP_PTR, align 4
  %46407 = sub i64 %46406, 1
  store i64 %46407, i64* %STACK_DEP_PTR, align 4
  %46408 = alloca i256, align 8
  store i256 %46380, i256* %46408, align 4
  %46409 = alloca i256, align 8
  store i256 %46385, i256* %46409, align 4
  %46410 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %46408, i256* %46409, i256* %46410), !pc !678, !intsan !6
  %46411 = load i256, i256* %46410, align 4
  %46412 = add i256 0, %46405, !pc !679, !intsan !10
  %46413 = trunc i256 %46412 to i64
  %46414 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46413, i256* %46414)
  %46415 = load i256, i256* %46414, align 4
  %46416 = trunc i256 64 to i64
  %46417 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46416, i256* %46417)
  %46418 = load i256, i256* %46417, align 4
  %46419 = and i256 1461501637330902918203684832716283019655932542975, %46415
  %46420 = and i256 1461501637330902918203684832716283019655932542975, %46419
  %46421 = trunc i256 %46418 to i64
  %46422 = alloca i256, align 8
  store i256 %46420, i256* %46422, align 4
  %46423 = bitcast i256* %46422 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46421, i8* %46423, i64 32)
  %46424 = add i256 32, %46418, !pc !680, !intsan !10
  %46425 = trunc i256 %46424 to i64
  %46426 = alloca i256, align 8
  store i256 %46400, i256* %46426, align 4
  %46427 = bitcast i256* %46426 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46425, i8* %46427, i64 32)
  %46428 = add i256 32, %46424, !pc !681, !intsan !10
  %46429 = trunc i256 %46428 to i64
  %46430 = alloca i256, align 8
  store i256 %46411, i256* %46430, align 4
  %46431 = bitcast i256* %46430 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %46429, i8* %46431, i64 32)
  %46432 = add i256 32, %46428, !pc !682, !intsan !10
  %46433 = trunc i256 64 to i64
  %46434 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46433, i256* %46434)
  %46435 = load i256, i256* %46434, align 4
  %46436 = sub i256 %46432, %46435, !pc !683, !intsan !8
  %46437 = trunc i256 -40855355889889451841004623863176994874972114171816916407198566795874576108843 to i64
  call void @addBugSet(i64 %46437)
  %46438 = add i256 0, %46405, !pc !684, !intsan !10
  %46439 = trunc i256 %46438 to i64
  %46440 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46439, i256* %46440)
  %46441 = load i256, i256* %46440, align 4
  %46442 = trunc i256 14584 to i64
  %46443 = load i64, i64* %STACK_DEP_PTR, align 4
  %46444 = add i64 %46443, 1
  store i64 %46444, i64* %STACK_DEP_PTR, align 4
  %46445 = load i64, i64* %STACK_DEP_PTR, align 4
  %46446 = getelementptr i256, i256* %STACK, i64 %46445
  store i256 %46405, i256* %46446, align 4
  %46447 = load i64, i64* %STACK_DEP_PTR, align 4
  %46448 = add i64 %46447, 1
  store i64 %46448, i64* %STACK_DEP_PTR, align 4
  %46449 = load i64, i64* %STACK_DEP_PTR, align 4
  %46450 = getelementptr i256, i256* %STACK, i64 %46449
  store i256 %46400, i256* %46450, align 4
  %46451 = load i64, i64* %STACK_DEP_PTR, align 4
  %46452 = add i64 %46451, 1
  store i64 %46452, i64* %STACK_DEP_PTR, align 4
  %46453 = load i64, i64* %STACK_DEP_PTR, align 4
  %46454 = getelementptr i256, i256* %STACK, i64 %46453
  store i256 %46411, i256* %46454, align 4
  %46455 = load i64, i64* %STACK_DEP_PTR, align 4
  %46456 = add i64 %46455, 1
  store i64 %46456, i64* %STACK_DEP_PTR, align 4
  %46457 = load i64, i64* %STACK_DEP_PTR, align 4
  %46458 = getelementptr i256, i256* %STACK, i64 %46457
  store i256 %46390, i256* %46458, align 4
  %46459 = load i64, i64* %STACK_DEP_PTR, align 4
  %46460 = add i64 %46459, 1
  store i64 %46460, i64* %STACK_DEP_PTR, align 4
  %46461 = load i64, i64* %STACK_DEP_PTR, align 4
  %46462 = getelementptr i256, i256* %STACK, i64 %46461
  store i256 15490, i256* %46462, align 4
  %46463 = load i64, i64* %STACK_DEP_PTR, align 4
  %46464 = add i64 %46463, 1
  store i64 %46464, i64* %STACK_DEP_PTR, align 4
  %46465 = load i64, i64* %STACK_DEP_PTR, align 4
  %46466 = getelementptr i256, i256* %STACK, i64 %46465
  store i256 %46441, i256* %46466, align 4
  %46467 = load i64, i64* %STACK_DEP_PTR, align 4
  %46468 = add i64 %46467, 1
  store i64 %46468, i64* %STACK_DEP_PTR, align 4
  %46469 = load i64, i64* %STACK_DEP_PTR, align 4
  %46470 = getelementptr i256, i256* %STACK, i64 %46469
  store i256 %46411, i256* %46470, align 4
  br label %.14584, !EVMBB !4

.15490:                                           ; preds = %JumpTable
  %46471 = load i64, i64* %remaing_gas, align 4
  %46472 = icmp ugt i64 376, %46471
  br i1 %46472, label %Abort, label %46473

46473:                                            ; preds = %.15490
  %46474 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46475 = xor i32 %46474, 2253
  %46476 = urem i32 %46475, 4096
  %46477 = getelementptr i8, i8 addrspace(1)* %4, i32 %46476
  %46478 = load i8, i8 addrspace(1)* %46477, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %46477, align 1, !nosanitize !3
  store i32 1126, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %46479 = sub i64 %46471, 376
  store i64 %46479, i64* %remaing_gas, align 4
  %46480 = load i64, i64* %STACK_DEP_PTR, align 4
  %46481 = getelementptr i256, i256* %STACK, i64 %46480
  %46482 = load i256, i256* %46481, align 4
  %46483 = load i64, i64* %STACK_DEP_PTR, align 4
  %46484 = sub i64 %46483, 1
  store i64 %46484, i64* %STACK_DEP_PTR, align 4
  %46485 = load i64, i64* %STACK_DEP_PTR, align 4
  %46486 = getelementptr i256, i256* %STACK, i64 %46485
  %46487 = load i256, i256* %46486, align 4
  %46488 = load i64, i64* %STACK_DEP_PTR, align 4
  %46489 = sub i64 %46488, 1
  store i64 %46489, i64* %STACK_DEP_PTR, align 4
  %46490 = alloca i256, align 8
  store i256 14, i256* %46490, align 4
  %46491 = alloca i256, align 8
  call void @__device_sload(i256* %46490, i256* %46491)
  %46492 = call i32 @__hashword(i256* %46490)
  %46493 = load i32, i32* %5, align 4
  %46494 = icmp eq i32 %46492, %46493
  %46495 = or i1 false, %46494
  %46496 = load i32, i32* %6, align 4
  %46497 = icmp eq i32 %46492, %46496
  %46498 = or i1 %46495, %46497
  %46499 = load i32, i32* %7, align 4
  %46500 = icmp eq i32 %46492, %46499
  %46501 = or i1 %46498, %46500
  %46502 = load i32, i32* %8, align 4
  %46503 = icmp eq i32 %46492, %46502
  %46504 = or i1 %46501, %46503
  %46505 = load i32, i32* %9, align 4
  %46506 = icmp eq i32 %46492, %46505
  %46507 = or i1 %46504, %46506
  %46508 = load i32, i32* %10, align 4
  %46509 = icmp eq i32 %46492, %46508
  %46510 = or i1 %46507, %46509
  %46511 = load i32, i32* %11, align 4
  %46512 = icmp eq i32 %46492, %46511
  %46513 = or i1 %46510, %46512
  %46514 = load i32, i32* %12, align 4
  %46515 = icmp eq i32 %46492, %46514
  %46516 = or i1 %46513, %46515
  %46517 = load i32, i32* %13, align 4
  %46518 = icmp eq i32 %46492, %46517
  %46519 = or i1 %46516, %46518
  %46520 = load i32, i32* %14, align 4
  %46521 = icmp eq i32 %46492, %46520
  %46522 = or i1 %46519, %46521
  %46523 = load i32, i32* %15, align 4
  %46524 = icmp eq i32 %46492, %46523
  %46525 = or i1 %46522, %46524
  %46526 = load i32, i32* %16, align 4
  %46527 = icmp eq i32 %46492, %46526
  %46528 = or i1 %46525, %46527
  %46529 = load i32, i32* %17, align 4
  %46530 = icmp eq i32 %46492, %46529
  %46531 = or i1 %46528, %46530
  %46532 = load i32, i32* %18, align 4
  %46533 = icmp eq i32 %46492, %46532
  %46534 = or i1 %46531, %46533
  %46535 = load i32, i32* %19, align 4
  %46536 = icmp eq i32 %46492, %46535
  %46537 = or i1 %46534, %46536
  %46538 = load i32, i32* %20, align 4
  %46539 = icmp eq i32 %46492, %46538
  %46540 = or i1 %46537, %46539
  %46541 = load i32, i32* %21, align 4
  %46542 = icmp eq i32 %46492, %46541
  %46543 = or i1 %46540, %46542
  %46544 = load i32, i32* %22, align 4
  %46545 = icmp eq i32 %46492, %46544
  %46546 = or i1 %46543, %46545
  %46547 = load i32, i32* %23, align 4
  %46548 = icmp eq i32 %46492, %46547
  %46549 = or i1 %46546, %46548
  %46550 = load i32, i32* %24, align 4
  %46551 = icmp eq i32 %46492, %46550
  %46552 = or i1 %46549, %46551
  %46553 = load i32, i32* %25, align 4
  %46554 = icmp eq i32 %46492, %46553
  %46555 = or i1 %46552, %46554
  %46556 = load i32, i32* %26, align 4
  %46557 = icmp eq i32 %46492, %46556
  %46558 = or i1 %46555, %46557
  %46559 = load i32, i32* %27, align 4
  %46560 = icmp eq i32 %46492, %46559
  %46561 = or i1 %46558, %46560
  %46562 = load i32, i32* %28, align 4
  %46563 = icmp eq i32 %46492, %46562
  %46564 = or i1 %46561, %46563
  %46565 = load i32, i32* %29, align 4
  %46566 = icmp eq i32 %46492, %46565
  %46567 = or i1 %46564, %46566
  %46568 = load i32, i32* %30, align 4
  %46569 = icmp eq i32 %46492, %46568
  %46570 = or i1 %46567, %46569
  %46571 = load i32, i32* %31, align 4
  %46572 = icmp eq i32 %46492, %46571
  %46573 = or i1 %46570, %46572
  %46574 = load i32, i32* %32, align 4
  %46575 = icmp eq i32 %46492, %46574
  %46576 = or i1 %46573, %46575
  %46577 = load i32, i32* %33, align 4
  %46578 = icmp eq i32 %46492, %46577
  %46579 = or i1 %46576, %46578
  %46580 = load i32, i32* %34, align 4
  %46581 = icmp eq i32 %46492, %46580
  %46582 = or i1 %46579, %46581
  %46583 = load i32, i32* %35, align 4
  %46584 = icmp eq i32 %46492, %46583
  %46585 = or i1 %46582, %46584
  %46586 = load i32, i32* %36, align 4
  %46587 = icmp eq i32 %46492, %46586
  %46588 = or i1 %46585, %46587
  %46589 = load i32, i32* %37, align 4
  %46590 = icmp eq i32 %46492, %46589
  %46591 = or i1 %46588, %46590
  %46592 = load i32, i32* %38, align 4
  %46593 = icmp eq i32 %46492, %46592
  %46594 = or i1 %46591, %46593
  %46595 = load i32, i32* %39, align 4
  %46596 = icmp eq i32 %46492, %46595
  %46597 = or i1 %46594, %46596
  %46598 = load i32, i32* %40, align 4
  %46599 = icmp eq i32 %46492, %46598
  %46600 = or i1 %46597, %46599
  %46601 = load i32, i32* %41, align 4
  %46602 = icmp eq i32 %46492, %46601
  %46603 = or i1 %46600, %46602
  %46604 = load i32, i32* %42, align 4
  %46605 = icmp eq i32 %46492, %46604
  %46606 = or i1 %46603, %46605
  %46607 = load i32, i32* %43, align 4
  %46608 = icmp eq i32 %46492, %46607
  %46609 = or i1 %46606, %46608
  %46610 = load i32, i32* %44, align 4
  %46611 = icmp eq i32 %46492, %46610
  %46612 = or i1 %46609, %46611
  %46613 = load i32, i32* %45, align 4
  %46614 = icmp eq i32 %46492, %46613
  %46615 = or i1 %46612, %46614
  %46616 = load i32, i32* %46, align 4
  %46617 = icmp eq i32 %46492, %46616
  %46618 = or i1 %46615, %46617
  %46619 = load i32, i32* %47, align 4
  %46620 = icmp eq i32 %46492, %46619
  %46621 = or i1 %46618, %46620
  %46622 = load i32, i32* %48, align 4
  %46623 = icmp eq i32 %46492, %46622
  %46624 = or i1 %46621, %46623
  %46625 = load i32, i32* %49, align 4
  %46626 = icmp eq i32 %46492, %46625
  %46627 = or i1 %46624, %46626
  %46628 = load i32, i32* %50, align 4
  %46629 = icmp eq i32 %46492, %46628
  %46630 = or i1 %46627, %46629
  %46631 = load i32, i32* %51, align 4
  %46632 = icmp eq i32 %46492, %46631
  %46633 = or i1 %46630, %46632
  %46634 = load i32, i32* %52, align 4
  %46635 = icmp eq i32 %46492, %46634
  %46636 = or i1 %46633, %46635
  %46637 = load i32, i32* %53, align 4
  %46638 = icmp eq i32 %46492, %46637
  %46639 = or i1 %46636, %46638
  %46640 = load i32, i32* %54, align 4
  %46641 = icmp eq i32 %46492, %46640
  %46642 = or i1 %46639, %46641
  %46643 = load i32, i32* %55, align 4
  %46644 = icmp eq i32 %46492, %46643
  %46645 = or i1 %46642, %46644
  %46646 = load i32, i32* %56, align 4
  %46647 = icmp eq i32 %46492, %46646
  %46648 = or i1 %46645, %46647
  %46649 = load i32, i32* %57, align 4
  %46650 = icmp eq i32 %46492, %46649
  %46651 = or i1 %46648, %46650
  %46652 = load i32, i32* %58, align 4
  %46653 = icmp eq i32 %46492, %46652
  %46654 = or i1 %46651, %46653
  %46655 = load i32, i32* %59, align 4
  %46656 = icmp eq i32 %46492, %46655
  %46657 = or i1 %46654, %46656
  %46658 = load i32, i32* %60, align 4
  %46659 = icmp eq i32 %46492, %46658
  %46660 = or i1 %46657, %46659
  %46661 = load i32, i32* %61, align 4
  %46662 = icmp eq i32 %46492, %46661
  %46663 = or i1 %46660, %46662
  %46664 = load i32, i32* %62, align 4
  %46665 = icmp eq i32 %46492, %46664
  %46666 = or i1 %46663, %46665
  %46667 = getelementptr i8, i8 addrspace(1)* %4, i32 170
  %46668 = zext i1 %46666 to i8
  store i8 %46668, i8 addrspace(1)* %46667, align 1, !nosanitize !3
  %46669 = load i256, i256* %46491, align 4
  %46670 = alloca i256, align 8
  store i256 14, i256* %46670, align 4
  %46671 = alloca i256, align 8
  call void @__device_sload(i256* %46670, i256* %46671)
  %46672 = call i32 @__hashword(i256* %46670)
  %46673 = load i32, i32* %5, align 4
  %46674 = icmp eq i32 %46672, %46673
  %46675 = or i1 false, %46674
  %46676 = load i32, i32* %6, align 4
  %46677 = icmp eq i32 %46672, %46676
  %46678 = or i1 %46675, %46677
  %46679 = load i32, i32* %7, align 4
  %46680 = icmp eq i32 %46672, %46679
  %46681 = or i1 %46678, %46680
  %46682 = load i32, i32* %8, align 4
  %46683 = icmp eq i32 %46672, %46682
  %46684 = or i1 %46681, %46683
  %46685 = load i32, i32* %9, align 4
  %46686 = icmp eq i32 %46672, %46685
  %46687 = or i1 %46684, %46686
  %46688 = load i32, i32* %10, align 4
  %46689 = icmp eq i32 %46672, %46688
  %46690 = or i1 %46687, %46689
  %46691 = load i32, i32* %11, align 4
  %46692 = icmp eq i32 %46672, %46691
  %46693 = or i1 %46690, %46692
  %46694 = load i32, i32* %12, align 4
  %46695 = icmp eq i32 %46672, %46694
  %46696 = or i1 %46693, %46695
  %46697 = load i32, i32* %13, align 4
  %46698 = icmp eq i32 %46672, %46697
  %46699 = or i1 %46696, %46698
  %46700 = load i32, i32* %14, align 4
  %46701 = icmp eq i32 %46672, %46700
  %46702 = or i1 %46699, %46701
  %46703 = load i32, i32* %15, align 4
  %46704 = icmp eq i32 %46672, %46703
  %46705 = or i1 %46702, %46704
  %46706 = load i32, i32* %16, align 4
  %46707 = icmp eq i32 %46672, %46706
  %46708 = or i1 %46705, %46707
  %46709 = load i32, i32* %17, align 4
  %46710 = icmp eq i32 %46672, %46709
  %46711 = or i1 %46708, %46710
  %46712 = load i32, i32* %18, align 4
  %46713 = icmp eq i32 %46672, %46712
  %46714 = or i1 %46711, %46713
  %46715 = load i32, i32* %19, align 4
  %46716 = icmp eq i32 %46672, %46715
  %46717 = or i1 %46714, %46716
  %46718 = load i32, i32* %20, align 4
  %46719 = icmp eq i32 %46672, %46718
  %46720 = or i1 %46717, %46719
  %46721 = load i32, i32* %21, align 4
  %46722 = icmp eq i32 %46672, %46721
  %46723 = or i1 %46720, %46722
  %46724 = load i32, i32* %22, align 4
  %46725 = icmp eq i32 %46672, %46724
  %46726 = or i1 %46723, %46725
  %46727 = load i32, i32* %23, align 4
  %46728 = icmp eq i32 %46672, %46727
  %46729 = or i1 %46726, %46728
  %46730 = load i32, i32* %24, align 4
  %46731 = icmp eq i32 %46672, %46730
  %46732 = or i1 %46729, %46731
  %46733 = load i32, i32* %25, align 4
  %46734 = icmp eq i32 %46672, %46733
  %46735 = or i1 %46732, %46734
  %46736 = load i32, i32* %26, align 4
  %46737 = icmp eq i32 %46672, %46736
  %46738 = or i1 %46735, %46737
  %46739 = load i32, i32* %27, align 4
  %46740 = icmp eq i32 %46672, %46739
  %46741 = or i1 %46738, %46740
  %46742 = load i32, i32* %28, align 4
  %46743 = icmp eq i32 %46672, %46742
  %46744 = or i1 %46741, %46743
  %46745 = load i32, i32* %29, align 4
  %46746 = icmp eq i32 %46672, %46745
  %46747 = or i1 %46744, %46746
  %46748 = load i32, i32* %30, align 4
  %46749 = icmp eq i32 %46672, %46748
  %46750 = or i1 %46747, %46749
  %46751 = load i32, i32* %31, align 4
  %46752 = icmp eq i32 %46672, %46751
  %46753 = or i1 %46750, %46752
  %46754 = load i32, i32* %32, align 4
  %46755 = icmp eq i32 %46672, %46754
  %46756 = or i1 %46753, %46755
  %46757 = load i32, i32* %33, align 4
  %46758 = icmp eq i32 %46672, %46757
  %46759 = or i1 %46756, %46758
  %46760 = load i32, i32* %34, align 4
  %46761 = icmp eq i32 %46672, %46760
  %46762 = or i1 %46759, %46761
  %46763 = load i32, i32* %35, align 4
  %46764 = icmp eq i32 %46672, %46763
  %46765 = or i1 %46762, %46764
  %46766 = load i32, i32* %36, align 4
  %46767 = icmp eq i32 %46672, %46766
  %46768 = or i1 %46765, %46767
  %46769 = load i32, i32* %37, align 4
  %46770 = icmp eq i32 %46672, %46769
  %46771 = or i1 %46768, %46770
  %46772 = load i32, i32* %38, align 4
  %46773 = icmp eq i32 %46672, %46772
  %46774 = or i1 %46771, %46773
  %46775 = load i32, i32* %39, align 4
  %46776 = icmp eq i32 %46672, %46775
  %46777 = or i1 %46774, %46776
  %46778 = load i32, i32* %40, align 4
  %46779 = icmp eq i32 %46672, %46778
  %46780 = or i1 %46777, %46779
  %46781 = load i32, i32* %41, align 4
  %46782 = icmp eq i32 %46672, %46781
  %46783 = or i1 %46780, %46782
  %46784 = load i32, i32* %42, align 4
  %46785 = icmp eq i32 %46672, %46784
  %46786 = or i1 %46783, %46785
  %46787 = load i32, i32* %43, align 4
  %46788 = icmp eq i32 %46672, %46787
  %46789 = or i1 %46786, %46788
  %46790 = load i32, i32* %44, align 4
  %46791 = icmp eq i32 %46672, %46790
  %46792 = or i1 %46789, %46791
  %46793 = load i32, i32* %45, align 4
  %46794 = icmp eq i32 %46672, %46793
  %46795 = or i1 %46792, %46794
  %46796 = load i32, i32* %46, align 4
  %46797 = icmp eq i32 %46672, %46796
  %46798 = or i1 %46795, %46797
  %46799 = load i32, i32* %47, align 4
  %46800 = icmp eq i32 %46672, %46799
  %46801 = or i1 %46798, %46800
  %46802 = load i32, i32* %48, align 4
  %46803 = icmp eq i32 %46672, %46802
  %46804 = or i1 %46801, %46803
  %46805 = load i32, i32* %49, align 4
  %46806 = icmp eq i32 %46672, %46805
  %46807 = or i1 %46804, %46806
  %46808 = load i32, i32* %50, align 4
  %46809 = icmp eq i32 %46672, %46808
  %46810 = or i1 %46807, %46809
  %46811 = load i32, i32* %51, align 4
  %46812 = icmp eq i32 %46672, %46811
  %46813 = or i1 %46810, %46812
  %46814 = load i32, i32* %52, align 4
  %46815 = icmp eq i32 %46672, %46814
  %46816 = or i1 %46813, %46815
  %46817 = load i32, i32* %53, align 4
  %46818 = icmp eq i32 %46672, %46817
  %46819 = or i1 %46816, %46818
  %46820 = load i32, i32* %54, align 4
  %46821 = icmp eq i32 %46672, %46820
  %46822 = or i1 %46819, %46821
  %46823 = load i32, i32* %55, align 4
  %46824 = icmp eq i32 %46672, %46823
  %46825 = or i1 %46822, %46824
  %46826 = load i32, i32* %56, align 4
  %46827 = icmp eq i32 %46672, %46826
  %46828 = or i1 %46825, %46827
  %46829 = load i32, i32* %57, align 4
  %46830 = icmp eq i32 %46672, %46829
  %46831 = or i1 %46828, %46830
  %46832 = load i32, i32* %58, align 4
  %46833 = icmp eq i32 %46672, %46832
  %46834 = or i1 %46831, %46833
  %46835 = load i32, i32* %59, align 4
  %46836 = icmp eq i32 %46672, %46835
  %46837 = or i1 %46834, %46836
  %46838 = load i32, i32* %60, align 4
  %46839 = icmp eq i32 %46672, %46838
  %46840 = or i1 %46837, %46839
  %46841 = load i32, i32* %61, align 4
  %46842 = icmp eq i32 %46672, %46841
  %46843 = or i1 %46840, %46842
  %46844 = load i32, i32* %62, align 4
  %46845 = icmp eq i32 %46672, %46844
  %46846 = or i1 %46843, %46845
  %46847 = getelementptr i8, i8 addrspace(1)* %4, i32 171
  %46848 = zext i1 %46846 to i8
  store i8 %46848, i8 addrspace(1)* %46847, align 1, !nosanitize !3
  %46849 = load i256, i256* %46671, align 4
  %46850 = add i256 %46849, %46487, !pc !685, !intsan !10
  %46851 = icmp ult i256 %46850, %46669
  %46852 = trunc i256 15517 to i64
  %jump.check221 = icmp ne i1 %46851, false
  %46853 = load i64, i64* %STACK_DEP_PTR, align 4
  %46854 = add i64 %46853, 1
  store i64 %46854, i64* %STACK_DEP_PTR, align 4
  %46855 = load i64, i64* %STACK_DEP_PTR, align 4
  %46856 = getelementptr i256, i256* %STACK, i64 %46855
  store i256 %46487, i256* %46856, align 4
  %46857 = load i64, i64* %STACK_DEP_PTR, align 4
  %46858 = add i64 %46857, 1
  store i64 %46858, i64* %STACK_DEP_PTR, align 4
  %46859 = load i64, i64* %STACK_DEP_PTR, align 4
  %46860 = getelementptr i256, i256* %STACK, i64 %46859
  store i256 %46482, i256* %46860, align 4
  %46861 = load i64, i64* %STACK_DEP_PTR, align 4
  %46862 = add i64 %46861, 1
  store i64 %46862, i64* %STACK_DEP_PTR, align 4
  %46863 = zext i1 %46851 to i256
  %46864 = load i64, i64* %STACK_DEP_PTR, align 4
  %46865 = getelementptr i256, i256* %STACK, i64 %46864
  store i256 %46863, i256* %46865, align 4
  br i1 %jump.check221, label %.15517, label %.15505, !EVMBB !4

.15505:                                           ; preds = %46473
  %46866 = load i64, i64* %STACK_DEP_PTR, align 4
  %46867 = getelementptr i256, i256* %STACK, i64 %46866
  %46868 = load i256, i256* %46867, align 4
  %46869 = load i64, i64* %STACK_DEP_PTR, align 4
  %46870 = sub i64 %46869, 1
  store i64 %46870, i64* %STACK_DEP_PTR, align 4
  %46871 = load i64, i64* %STACK_DEP_PTR, align 4
  %46872 = getelementptr i256, i256* %STACK, i64 %46871
  %46873 = load i256, i256* %46872, align 4
  %46874 = load i64, i64* %STACK_DEP_PTR, align 4
  %46875 = sub i64 %46874, 1
  store i64 %46875, i64* %STACK_DEP_PTR, align 4
  %46876 = load i64, i64* %STACK_DEP_PTR, align 4
  %46877 = getelementptr i256, i256* %STACK, i64 %46876
  %46878 = load i256, i256* %46877, align 4
  %46879 = load i64, i64* %STACK_DEP_PTR, align 4
  %46880 = sub i64 %46879, 1
  store i64 %46880, i64* %STACK_DEP_PTR, align 4
  %46881 = load i64, i64* %STACK_DEP_PTR, align 4
  %46882 = getelementptr i256, i256* %STACK, i64 %46881
  %46883 = load i256, i256* %46882, align 4
  %46884 = load i64, i64* %STACK_DEP_PTR, align 4
  %46885 = sub i64 %46884, 1
  store i64 %46885, i64* %STACK_DEP_PTR, align 4
  %46886 = load i64, i64* %STACK_DEP_PTR, align 4
  %46887 = getelementptr i256, i256* %STACK, i64 %46886
  %46888 = load i256, i256* %46887, align 4
  %46889 = load i64, i64* %STACK_DEP_PTR, align 4
  %46890 = sub i64 %46889, 1
  store i64 %46890, i64* %STACK_DEP_PTR, align 4
  %46891 = add i256 32, %46888, !pc !686, !intsan !10
  %46892 = trunc i256 %46891 to i64
  %46893 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %46892, i256* %46893)
  %46894 = load i256, i256* %46893, align 4
  %46895 = alloca i256, align 8
  store i256 14, i256* %46895, align 4
  %46896 = alloca i256, align 8
  call void @__device_sload(i256* %46895, i256* %46896)
  %46897 = call i32 @__hashword(i256* %46895)
  %46898 = load i32, i32* %5, align 4
  %46899 = icmp eq i32 %46897, %46898
  %46900 = or i1 false, %46899
  %46901 = load i32, i32* %6, align 4
  %46902 = icmp eq i32 %46897, %46901
  %46903 = or i1 %46900, %46902
  %46904 = load i32, i32* %7, align 4
  %46905 = icmp eq i32 %46897, %46904
  %46906 = or i1 %46903, %46905
  %46907 = load i32, i32* %8, align 4
  %46908 = icmp eq i32 %46897, %46907
  %46909 = or i1 %46906, %46908
  %46910 = load i32, i32* %9, align 4
  %46911 = icmp eq i32 %46897, %46910
  %46912 = or i1 %46909, %46911
  %46913 = load i32, i32* %10, align 4
  %46914 = icmp eq i32 %46897, %46913
  %46915 = or i1 %46912, %46914
  %46916 = load i32, i32* %11, align 4
  %46917 = icmp eq i32 %46897, %46916
  %46918 = or i1 %46915, %46917
  %46919 = load i32, i32* %12, align 4
  %46920 = icmp eq i32 %46897, %46919
  %46921 = or i1 %46918, %46920
  %46922 = load i32, i32* %13, align 4
  %46923 = icmp eq i32 %46897, %46922
  %46924 = or i1 %46921, %46923
  %46925 = load i32, i32* %14, align 4
  %46926 = icmp eq i32 %46897, %46925
  %46927 = or i1 %46924, %46926
  %46928 = load i32, i32* %15, align 4
  %46929 = icmp eq i32 %46897, %46928
  %46930 = or i1 %46927, %46929
  %46931 = load i32, i32* %16, align 4
  %46932 = icmp eq i32 %46897, %46931
  %46933 = or i1 %46930, %46932
  %46934 = load i32, i32* %17, align 4
  %46935 = icmp eq i32 %46897, %46934
  %46936 = or i1 %46933, %46935
  %46937 = load i32, i32* %18, align 4
  %46938 = icmp eq i32 %46897, %46937
  %46939 = or i1 %46936, %46938
  %46940 = load i32, i32* %19, align 4
  %46941 = icmp eq i32 %46897, %46940
  %46942 = or i1 %46939, %46941
  %46943 = load i32, i32* %20, align 4
  %46944 = icmp eq i32 %46897, %46943
  %46945 = or i1 %46942, %46944
  %46946 = load i32, i32* %21, align 4
  %46947 = icmp eq i32 %46897, %46946
  %46948 = or i1 %46945, %46947
  %46949 = load i32, i32* %22, align 4
  %46950 = icmp eq i32 %46897, %46949
  %46951 = or i1 %46948, %46950
  %46952 = load i32, i32* %23, align 4
  %46953 = icmp eq i32 %46897, %46952
  %46954 = or i1 %46951, %46953
  %46955 = load i32, i32* %24, align 4
  %46956 = icmp eq i32 %46897, %46955
  %46957 = or i1 %46954, %46956
  %46958 = load i32, i32* %25, align 4
  %46959 = icmp eq i32 %46897, %46958
  %46960 = or i1 %46957, %46959
  %46961 = load i32, i32* %26, align 4
  %46962 = icmp eq i32 %46897, %46961
  %46963 = or i1 %46960, %46962
  %46964 = load i32, i32* %27, align 4
  %46965 = icmp eq i32 %46897, %46964
  %46966 = or i1 %46963, %46965
  %46967 = load i32, i32* %28, align 4
  %46968 = icmp eq i32 %46897, %46967
  %46969 = or i1 %46966, %46968
  %46970 = load i32, i32* %29, align 4
  %46971 = icmp eq i32 %46897, %46970
  %46972 = or i1 %46969, %46971
  %46973 = load i32, i32* %30, align 4
  %46974 = icmp eq i32 %46897, %46973
  %46975 = or i1 %46972, %46974
  %46976 = load i32, i32* %31, align 4
  %46977 = icmp eq i32 %46897, %46976
  %46978 = or i1 %46975, %46977
  %46979 = load i32, i32* %32, align 4
  %46980 = icmp eq i32 %46897, %46979
  %46981 = or i1 %46978, %46980
  %46982 = load i32, i32* %33, align 4
  %46983 = icmp eq i32 %46897, %46982
  %46984 = or i1 %46981, %46983
  %46985 = load i32, i32* %34, align 4
  %46986 = icmp eq i32 %46897, %46985
  %46987 = or i1 %46984, %46986
  %46988 = load i32, i32* %35, align 4
  %46989 = icmp eq i32 %46897, %46988
  %46990 = or i1 %46987, %46989
  %46991 = load i32, i32* %36, align 4
  %46992 = icmp eq i32 %46897, %46991
  %46993 = or i1 %46990, %46992
  %46994 = load i32, i32* %37, align 4
  %46995 = icmp eq i32 %46897, %46994
  %46996 = or i1 %46993, %46995
  %46997 = load i32, i32* %38, align 4
  %46998 = icmp eq i32 %46897, %46997
  %46999 = or i1 %46996, %46998
  %47000 = load i32, i32* %39, align 4
  %47001 = icmp eq i32 %46897, %47000
  %47002 = or i1 %46999, %47001
  %47003 = load i32, i32* %40, align 4
  %47004 = icmp eq i32 %46897, %47003
  %47005 = or i1 %47002, %47004
  %47006 = load i32, i32* %41, align 4
  %47007 = icmp eq i32 %46897, %47006
  %47008 = or i1 %47005, %47007
  %47009 = load i32, i32* %42, align 4
  %47010 = icmp eq i32 %46897, %47009
  %47011 = or i1 %47008, %47010
  %47012 = load i32, i32* %43, align 4
  %47013 = icmp eq i32 %46897, %47012
  %47014 = or i1 %47011, %47013
  %47015 = load i32, i32* %44, align 4
  %47016 = icmp eq i32 %46897, %47015
  %47017 = or i1 %47014, %47016
  %47018 = load i32, i32* %45, align 4
  %47019 = icmp eq i32 %46897, %47018
  %47020 = or i1 %47017, %47019
  %47021 = load i32, i32* %46, align 4
  %47022 = icmp eq i32 %46897, %47021
  %47023 = or i1 %47020, %47022
  %47024 = load i32, i32* %47, align 4
  %47025 = icmp eq i32 %46897, %47024
  %47026 = or i1 %47023, %47025
  %47027 = load i32, i32* %48, align 4
  %47028 = icmp eq i32 %46897, %47027
  %47029 = or i1 %47026, %47028
  %47030 = load i32, i32* %49, align 4
  %47031 = icmp eq i32 %46897, %47030
  %47032 = or i1 %47029, %47031
  %47033 = load i32, i32* %50, align 4
  %47034 = icmp eq i32 %46897, %47033
  %47035 = or i1 %47032, %47034
  %47036 = load i32, i32* %51, align 4
  %47037 = icmp eq i32 %46897, %47036
  %47038 = or i1 %47035, %47037
  %47039 = load i32, i32* %52, align 4
  %47040 = icmp eq i32 %46897, %47039
  %47041 = or i1 %47038, %47040
  %47042 = load i32, i32* %53, align 4
  %47043 = icmp eq i32 %46897, %47042
  %47044 = or i1 %47041, %47043
  %47045 = load i32, i32* %54, align 4
  %47046 = icmp eq i32 %46897, %47045
  %47047 = or i1 %47044, %47046
  %47048 = load i32, i32* %55, align 4
  %47049 = icmp eq i32 %46897, %47048
  %47050 = or i1 %47047, %47049
  %47051 = load i32, i32* %56, align 4
  %47052 = icmp eq i32 %46897, %47051
  %47053 = or i1 %47050, %47052
  %47054 = load i32, i32* %57, align 4
  %47055 = icmp eq i32 %46897, %47054
  %47056 = or i1 %47053, %47055
  %47057 = load i32, i32* %58, align 4
  %47058 = icmp eq i32 %46897, %47057
  %47059 = or i1 %47056, %47058
  %47060 = load i32, i32* %59, align 4
  %47061 = icmp eq i32 %46897, %47060
  %47062 = or i1 %47059, %47061
  %47063 = load i32, i32* %60, align 4
  %47064 = icmp eq i32 %46897, %47063
  %47065 = or i1 %47062, %47064
  %47066 = load i32, i32* %61, align 4
  %47067 = icmp eq i32 %46897, %47066
  %47068 = or i1 %47065, %47067
  %47069 = load i32, i32* %62, align 4
  %47070 = icmp eq i32 %46897, %47069
  %47071 = or i1 %47068, %47070
  %47072 = getelementptr i8, i8 addrspace(1)* %4, i32 172
  %47073 = zext i1 %47071 to i8
  store i8 %47073, i8 addrspace(1)* %47072, align 1, !nosanitize !3
  %47074 = load i256, i256* %46896, align 4
  %47075 = add i256 %47074, %46878, !pc !687, !intsan !10
  %47076 = icmp ult i256 %47075, %46894
  %47077 = load i64, i64* %STACK_DEP_PTR, align 4
  %47078 = add i64 %47077, 1
  store i64 %47078, i64* %STACK_DEP_PTR, align 4
  %47079 = load i64, i64* %STACK_DEP_PTR, align 4
  %47080 = getelementptr i256, i256* %STACK, i64 %47079
  store i256 %46888, i256* %47080, align 4
  %47081 = load i64, i64* %STACK_DEP_PTR, align 4
  %47082 = add i64 %47081, 1
  store i64 %47082, i64* %STACK_DEP_PTR, align 4
  %47083 = load i64, i64* %STACK_DEP_PTR, align 4
  %47084 = getelementptr i256, i256* %STACK, i64 %47083
  store i256 %46883, i256* %47084, align 4
  %47085 = load i64, i64* %STACK_DEP_PTR, align 4
  %47086 = add i64 %47085, 1
  store i64 %47086, i64* %STACK_DEP_PTR, align 4
  %47087 = load i64, i64* %STACK_DEP_PTR, align 4
  %47088 = getelementptr i256, i256* %STACK, i64 %47087
  store i256 %46878, i256* %47088, align 4
  %47089 = load i64, i64* %STACK_DEP_PTR, align 4
  %47090 = add i64 %47089, 1
  store i64 %47090, i64* %STACK_DEP_PTR, align 4
  %47091 = load i64, i64* %STACK_DEP_PTR, align 4
  %47092 = getelementptr i256, i256* %STACK, i64 %47091
  store i256 %46873, i256* %47092, align 4
  %47093 = load i64, i64* %STACK_DEP_PTR, align 4
  %47094 = add i64 %47093, 1
  store i64 %47094, i64* %STACK_DEP_PTR, align 4
  %47095 = zext i1 %47076 to i256
  %47096 = load i64, i64* %STACK_DEP_PTR, align 4
  %47097 = getelementptr i256, i256* %STACK, i64 %47096
  store i256 %47095, i256* %47097, align 4
  br label %.15517

.15517:                                           ; preds = %.15505, %46473, %JumpTable
  %47098 = load i64, i64* %remaing_gas, align 4
  %47099 = icmp ugt i64 88, %47098
  br i1 %47099, label %Abort, label %47100

47100:                                            ; preds = %.15517
  %47101 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47102 = xor i32 %47101, 3350
  %47103 = urem i32 %47102, 4096
  %47104 = getelementptr i8, i8 addrspace(1)* %4, i32 %47103
  %47105 = load i8, i8 addrspace(1)* %47104, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47104, align 1, !nosanitize !3
  store i32 1675, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47106 = sub i64 %47098, 88
  store i64 %47106, i64* %remaing_gas, align 4
  %47107 = load i64, i64* %STACK_DEP_PTR, align 4
  %47108 = getelementptr i256, i256* %STACK, i64 %47107
  %47109 = load i256, i256* %47108, align 4
  %47110 = load i64, i64* %STACK_DEP_PTR, align 4
  %47111 = sub i64 %47110, 1
  store i64 %47111, i64* %STACK_DEP_PTR, align 4
  %47112 = icmp eq i256 %47109, 0
  %47113 = trunc i256 15527 to i64
  %jump.check222 = icmp ne i1 %47112, false
  br i1 %jump.check222, label %.15527, label %.15523, !EVMBB !4

.15523:                                           ; preds = %47100
  %47114 = load i64, i64* %remaing_gas, align 4
  %47115 = icmp ugt i64 16, %47114
  br i1 %47115, label %Abort, label %47116

47116:                                            ; preds = %.15523
  %47117 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47118 = xor i32 %47117, 3432
  %47119 = urem i32 %47118, 4096
  %47120 = getelementptr i8, i8 addrspace(1)* %4, i32 %47119
  %47121 = load i8, i8 addrspace(1)* %47120, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47120, align 1, !nosanitize !3
  store i32 1716, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47122 = sub i64 %47114, 16
  store i64 %47122, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.15527:                                           ; preds = %47100, %JumpTable
  %47123 = load i64, i64* %STACK_DEP_PTR, align 4
  %47124 = getelementptr i256, i256* %STACK, i64 %47123
  %47125 = load i256, i256* %47124, align 4
  %47126 = load i64, i64* %STACK_DEP_PTR, align 4
  %47127 = sub i64 %47126, 1
  store i64 %47127, i64* %STACK_DEP_PTR, align 4
  %47128 = load i64, i64* %STACK_DEP_PTR, align 4
  %47129 = getelementptr i256, i256* %STACK, i64 %47128
  %47130 = load i256, i256* %47129, align 4
  %47131 = load i64, i64* %STACK_DEP_PTR, align 4
  %47132 = sub i64 %47131, 1
  store i64 %47132, i64* %STACK_DEP_PTR, align 4
  %47133 = load i64, i64* %STACK_DEP_PTR, align 4
  %47134 = getelementptr i256, i256* %STACK, i64 %47133
  %47135 = load i256, i256* %47134, align 4
  %47136 = load i64, i64* %STACK_DEP_PTR, align 4
  %47137 = sub i64 %47136, 1
  store i64 %47137, i64* %STACK_DEP_PTR, align 4
  %47138 = load i64, i64* %STACK_DEP_PTR, align 4
  %47139 = getelementptr i256, i256* %STACK, i64 %47138
  %47140 = load i256, i256* %47139, align 4
  %47141 = load i64, i64* %STACK_DEP_PTR, align 4
  %47142 = sub i64 %47141, 1
  store i64 %47142, i64* %STACK_DEP_PTR, align 4
  %47143 = add i256 32, %47140, !pc !688, !intsan !10
  %47144 = trunc i256 %47143 to i64
  %47145 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47144, i256* %47145)
  %47146 = load i256, i256* %47145, align 4
  %47147 = sub i256 %47130, %47146, !pc !689, !intsan !8
  %47148 = alloca i256, align 8
  store i256 14, i256* %47148, align 4
  %47149 = alloca i256, align 8
  call void @__device_sload(i256* %47148, i256* %47149)
  %47150 = call i32 @__hashword(i256* %47148)
  %47151 = load i32, i32* %5, align 4
  %47152 = icmp eq i32 %47150, %47151
  %47153 = or i1 false, %47152
  %47154 = load i32, i32* %6, align 4
  %47155 = icmp eq i32 %47150, %47154
  %47156 = or i1 %47153, %47155
  %47157 = load i32, i32* %7, align 4
  %47158 = icmp eq i32 %47150, %47157
  %47159 = or i1 %47156, %47158
  %47160 = load i32, i32* %8, align 4
  %47161 = icmp eq i32 %47150, %47160
  %47162 = or i1 %47159, %47161
  %47163 = load i32, i32* %9, align 4
  %47164 = icmp eq i32 %47150, %47163
  %47165 = or i1 %47162, %47164
  %47166 = load i32, i32* %10, align 4
  %47167 = icmp eq i32 %47150, %47166
  %47168 = or i1 %47165, %47167
  %47169 = load i32, i32* %11, align 4
  %47170 = icmp eq i32 %47150, %47169
  %47171 = or i1 %47168, %47170
  %47172 = load i32, i32* %12, align 4
  %47173 = icmp eq i32 %47150, %47172
  %47174 = or i1 %47171, %47173
  %47175 = load i32, i32* %13, align 4
  %47176 = icmp eq i32 %47150, %47175
  %47177 = or i1 %47174, %47176
  %47178 = load i32, i32* %14, align 4
  %47179 = icmp eq i32 %47150, %47178
  %47180 = or i1 %47177, %47179
  %47181 = load i32, i32* %15, align 4
  %47182 = icmp eq i32 %47150, %47181
  %47183 = or i1 %47180, %47182
  %47184 = load i32, i32* %16, align 4
  %47185 = icmp eq i32 %47150, %47184
  %47186 = or i1 %47183, %47185
  %47187 = load i32, i32* %17, align 4
  %47188 = icmp eq i32 %47150, %47187
  %47189 = or i1 %47186, %47188
  %47190 = load i32, i32* %18, align 4
  %47191 = icmp eq i32 %47150, %47190
  %47192 = or i1 %47189, %47191
  %47193 = load i32, i32* %19, align 4
  %47194 = icmp eq i32 %47150, %47193
  %47195 = or i1 %47192, %47194
  %47196 = load i32, i32* %20, align 4
  %47197 = icmp eq i32 %47150, %47196
  %47198 = or i1 %47195, %47197
  %47199 = load i32, i32* %21, align 4
  %47200 = icmp eq i32 %47150, %47199
  %47201 = or i1 %47198, %47200
  %47202 = load i32, i32* %22, align 4
  %47203 = icmp eq i32 %47150, %47202
  %47204 = or i1 %47201, %47203
  %47205 = load i32, i32* %23, align 4
  %47206 = icmp eq i32 %47150, %47205
  %47207 = or i1 %47204, %47206
  %47208 = load i32, i32* %24, align 4
  %47209 = icmp eq i32 %47150, %47208
  %47210 = or i1 %47207, %47209
  %47211 = load i32, i32* %25, align 4
  %47212 = icmp eq i32 %47150, %47211
  %47213 = or i1 %47210, %47212
  %47214 = load i32, i32* %26, align 4
  %47215 = icmp eq i32 %47150, %47214
  %47216 = or i1 %47213, %47215
  %47217 = load i32, i32* %27, align 4
  %47218 = icmp eq i32 %47150, %47217
  %47219 = or i1 %47216, %47218
  %47220 = load i32, i32* %28, align 4
  %47221 = icmp eq i32 %47150, %47220
  %47222 = or i1 %47219, %47221
  %47223 = load i32, i32* %29, align 4
  %47224 = icmp eq i32 %47150, %47223
  %47225 = or i1 %47222, %47224
  %47226 = load i32, i32* %30, align 4
  %47227 = icmp eq i32 %47150, %47226
  %47228 = or i1 %47225, %47227
  %47229 = load i32, i32* %31, align 4
  %47230 = icmp eq i32 %47150, %47229
  %47231 = or i1 %47228, %47230
  %47232 = load i32, i32* %32, align 4
  %47233 = icmp eq i32 %47150, %47232
  %47234 = or i1 %47231, %47233
  %47235 = load i32, i32* %33, align 4
  %47236 = icmp eq i32 %47150, %47235
  %47237 = or i1 %47234, %47236
  %47238 = load i32, i32* %34, align 4
  %47239 = icmp eq i32 %47150, %47238
  %47240 = or i1 %47237, %47239
  %47241 = load i32, i32* %35, align 4
  %47242 = icmp eq i32 %47150, %47241
  %47243 = or i1 %47240, %47242
  %47244 = load i32, i32* %36, align 4
  %47245 = icmp eq i32 %47150, %47244
  %47246 = or i1 %47243, %47245
  %47247 = load i32, i32* %37, align 4
  %47248 = icmp eq i32 %47150, %47247
  %47249 = or i1 %47246, %47248
  %47250 = load i32, i32* %38, align 4
  %47251 = icmp eq i32 %47150, %47250
  %47252 = or i1 %47249, %47251
  %47253 = load i32, i32* %39, align 4
  %47254 = icmp eq i32 %47150, %47253
  %47255 = or i1 %47252, %47254
  %47256 = load i32, i32* %40, align 4
  %47257 = icmp eq i32 %47150, %47256
  %47258 = or i1 %47255, %47257
  %47259 = load i32, i32* %41, align 4
  %47260 = icmp eq i32 %47150, %47259
  %47261 = or i1 %47258, %47260
  %47262 = load i32, i32* %42, align 4
  %47263 = icmp eq i32 %47150, %47262
  %47264 = or i1 %47261, %47263
  %47265 = load i32, i32* %43, align 4
  %47266 = icmp eq i32 %47150, %47265
  %47267 = or i1 %47264, %47266
  %47268 = load i32, i32* %44, align 4
  %47269 = icmp eq i32 %47150, %47268
  %47270 = or i1 %47267, %47269
  %47271 = load i32, i32* %45, align 4
  %47272 = icmp eq i32 %47150, %47271
  %47273 = or i1 %47270, %47272
  %47274 = load i32, i32* %46, align 4
  %47275 = icmp eq i32 %47150, %47274
  %47276 = or i1 %47273, %47275
  %47277 = load i32, i32* %47, align 4
  %47278 = icmp eq i32 %47150, %47277
  %47279 = or i1 %47276, %47278
  %47280 = load i32, i32* %48, align 4
  %47281 = icmp eq i32 %47150, %47280
  %47282 = or i1 %47279, %47281
  %47283 = load i32, i32* %49, align 4
  %47284 = icmp eq i32 %47150, %47283
  %47285 = or i1 %47282, %47284
  %47286 = load i32, i32* %50, align 4
  %47287 = icmp eq i32 %47150, %47286
  %47288 = or i1 %47285, %47287
  %47289 = load i32, i32* %51, align 4
  %47290 = icmp eq i32 %47150, %47289
  %47291 = or i1 %47288, %47290
  %47292 = load i32, i32* %52, align 4
  %47293 = icmp eq i32 %47150, %47292
  %47294 = or i1 %47291, %47293
  %47295 = load i32, i32* %53, align 4
  %47296 = icmp eq i32 %47150, %47295
  %47297 = or i1 %47294, %47296
  %47298 = load i32, i32* %54, align 4
  %47299 = icmp eq i32 %47150, %47298
  %47300 = or i1 %47297, %47299
  %47301 = load i32, i32* %55, align 4
  %47302 = icmp eq i32 %47150, %47301
  %47303 = or i1 %47300, %47302
  %47304 = load i32, i32* %56, align 4
  %47305 = icmp eq i32 %47150, %47304
  %47306 = or i1 %47303, %47305
  %47307 = load i32, i32* %57, align 4
  %47308 = icmp eq i32 %47150, %47307
  %47309 = or i1 %47306, %47308
  %47310 = load i32, i32* %58, align 4
  %47311 = icmp eq i32 %47150, %47310
  %47312 = or i1 %47309, %47311
  %47313 = load i32, i32* %59, align 4
  %47314 = icmp eq i32 %47150, %47313
  %47315 = or i1 %47312, %47314
  %47316 = load i32, i32* %60, align 4
  %47317 = icmp eq i32 %47150, %47316
  %47318 = or i1 %47315, %47317
  %47319 = load i32, i32* %61, align 4
  %47320 = icmp eq i32 %47150, %47319
  %47321 = or i1 %47318, %47320
  %47322 = load i32, i32* %62, align 4
  %47323 = icmp eq i32 %47150, %47322
  %47324 = or i1 %47321, %47323
  %47325 = getelementptr i8, i8 addrspace(1)* %4, i32 173
  %47326 = zext i1 %47324 to i8
  store i8 %47326, i8 addrspace(1)* %47325, align 1, !nosanitize !3
  %47327 = load i256, i256* %47149, align 4
  %47328 = add i256 %47327, %47147, !pc !690, !intsan !10
  %47329 = alloca i256, align 8
  store i256 14, i256* %47329, align 4
  %47330 = alloca i256, align 8
  store i256 %47328, i256* %47330, align 4
  call void @__device_sstore(i256* %47329, i256* %47330)
  %47331 = call i32 @__hashword(i256* %47329)
  store i32 %47331, i32* %48, align 4, !nosanitize !3
  %47332 = load i64, i64* %STACK_DEP_PTR, align 4
  %47333 = add i64 %47332, 1
  store i64 %47333, i64* %STACK_DEP_PTR, align 4
  %47334 = load i64, i64* %STACK_DEP_PTR, align 4
  %47335 = getelementptr i256, i256* %STACK, i64 %47334
  store i256 %47140, i256* %47335, align 4
  %47336 = load i64, i64* %STACK_DEP_PTR, align 4
  %47337 = add i64 %47336, 1
  store i64 %47337, i64* %STACK_DEP_PTR, align 4
  %47338 = load i64, i64* %STACK_DEP_PTR, align 4
  %47339 = getelementptr i256, i256* %STACK, i64 %47338
  store i256 %47135, i256* %47339, align 4
  %47340 = load i64, i64* %STACK_DEP_PTR, align 4
  %47341 = add i64 %47340, 1
  store i64 %47341, i64* %STACK_DEP_PTR, align 4
  %47342 = load i64, i64* %STACK_DEP_PTR, align 4
  %47343 = getelementptr i256, i256* %STACK, i64 %47342
  store i256 %47130, i256* %47343, align 4
  %47344 = load i64, i64* %STACK_DEP_PTR, align 4
  %47345 = add i64 %47344, 1
  store i64 %47345, i64* %STACK_DEP_PTR, align 4
  %47346 = load i64, i64* %STACK_DEP_PTR, align 4
  %47347 = getelementptr i256, i256* %STACK, i64 %47346
  store i256 %47125, i256* %47347, align 4
  br label %.15550

.15550:                                           ; preds = %.15527, %46270, %JumpTable
  %47348 = load i64, i64* %remaing_gas, align 4
  %47349 = icmp ugt i64 272, %47348
  br i1 %47349, label %Abort, label %47350

47350:                                            ; preds = %.15550
  %47351 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47352 = xor i32 %47351, 698
  %47353 = urem i32 %47352, 4096
  %47354 = getelementptr i8, i8 addrspace(1)* %4, i32 %47353
  %47355 = load i8, i8 addrspace(1)* %47354, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47354, align 1, !nosanitize !3
  store i32 349, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47356 = sub i64 %47348, 272
  store i64 %47356, i64* %remaing_gas, align 4
  %47357 = load i64, i64* %STACK_DEP_PTR, align 4
  %47358 = getelementptr i256, i256* %STACK, i64 %47357
  %47359 = load i256, i256* %47358, align 4
  %47360 = load i64, i64* %STACK_DEP_PTR, align 4
  %47361 = sub i64 %47360, 1
  store i64 %47361, i64* %STACK_DEP_PTR, align 4
  %47362 = load i64, i64* %STACK_DEP_PTR, align 4
  %47363 = getelementptr i256, i256* %STACK, i64 %47362
  %47364 = load i256, i256* %47363, align 4
  %47365 = load i64, i64* %STACK_DEP_PTR, align 4
  %47366 = sub i64 %47365, 1
  store i64 %47366, i64* %STACK_DEP_PTR, align 4
  %47367 = load i64, i64* %STACK_DEP_PTR, align 4
  %47368 = getelementptr i256, i256* %STACK, i64 %47367
  %47369 = load i256, i256* %47368, align 4
  %47370 = load i64, i64* %STACK_DEP_PTR, align 4
  %47371 = sub i64 %47370, 1
  store i64 %47371, i64* %STACK_DEP_PTR, align 4
  %47372 = load i64, i64* %STACK_DEP_PTR, align 4
  %47373 = getelementptr i256, i256* %STACK, i64 %47372
  %47374 = load i256, i256* %47373, align 4
  %47375 = load i64, i64* %STACK_DEP_PTR, align 4
  %47376 = sub i64 %47375, 1
  store i64 %47376, i64* %STACK_DEP_PTR, align 4
  %47377 = load i64, i64* %STACK_DEP_PTR, align 4
  %47378 = getelementptr i256, i256* %STACK, i64 %47377
  %47379 = load i256, i256* %47378, align 4
  %47380 = load i64, i64* %STACK_DEP_PTR, align 4
  %47381 = sub i64 %47380, 1
  store i64 %47381, i64* %STACK_DEP_PTR, align 4
  %47382 = trunc i256 %47379 to i64
  store i64 %47382, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.15556:                                           ; preds = %17523, %JumpTable
  %47383 = load i64, i64* %remaing_gas, align 4
  %47384 = icmp ugt i64 304, %47383
  br i1 %47384, label %Abort, label %47385

47385:                                            ; preds = %.15556
  %47386 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47387 = xor i32 %47386, 3756
  %47388 = urem i32 %47387, 4096
  %47389 = getelementptr i8, i8 addrspace(1)* %4, i32 %47388
  %47390 = load i8, i8 addrspace(1)* %47389, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47389, align 1, !nosanitize !3
  store i32 1878, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47391 = sub i64 %47383, 304
  store i64 %47391, i64* %remaing_gas, align 4
  %47392 = load i64, i64* %STACK_DEP_PTR, align 4
  %47393 = getelementptr i256, i256* %STACK, i64 %47392
  %47394 = load i256, i256* %47393, align 4
  %47395 = load i64, i64* %STACK_DEP_PTR, align 4
  %47396 = sub i64 %47395, 1
  store i64 %47396, i64* %STACK_DEP_PTR, align 4
  %47397 = sub i256 %47394, 1, !pc !691, !intsan !8
  %47398 = icmp ult i256 %47397, 7500
  %47399 = icmp eq i1 %47398, false
  %47400 = icmp eq i1 %47399, false
  %47401 = trunc i256 15869 to i64
  %jump.check223 = icmp ne i1 %47400, false
  %47402 = load i64, i64* %STACK_DEP_PTR, align 4
  %47403 = add i64 %47402, 1
  store i64 %47403, i64* %STACK_DEP_PTR, align 4
  %47404 = load i64, i64* %STACK_DEP_PTR, align 4
  %47405 = getelementptr i256, i256* %STACK, i64 %47404
  store i256 %47394, i256* %47405, align 4
  %47406 = load i64, i64* %STACK_DEP_PTR, align 4
  %47407 = add i64 %47406, 1
  store i64 %47407, i64* %STACK_DEP_PTR, align 4
  %47408 = load i64, i64* %STACK_DEP_PTR, align 4
  %47409 = getelementptr i256, i256* %STACK, i64 %47408
  store i256 0, i256* %47409, align 4
  %47410 = load i64, i64* %STACK_DEP_PTR, align 4
  %47411 = add i64 %47410, 1
  store i64 %47411, i64* %STACK_DEP_PTR, align 4
  %47412 = load i64, i64* %STACK_DEP_PTR, align 4
  %47413 = getelementptr i256, i256* %STACK, i64 %47412
  store i256 0, i256* %47413, align 4
  %47414 = load i64, i64* %STACK_DEP_PTR, align 4
  %47415 = add i64 %47414, 1
  store i64 %47415, i64* %STACK_DEP_PTR, align 4
  %47416 = load i64, i64* %STACK_DEP_PTR, align 4
  %47417 = getelementptr i256, i256* %STACK, i64 %47416
  store i256 %47394, i256* %47417, align 4
  br i1 %jump.check223, label %.15869, label %.15575, !EVMBB !4

.15575:                                           ; preds = %47385
  %47418 = load i64, i64* %remaing_gas, align 4
  %47419 = icmp ugt i64 928, %47418
  br i1 %47419, label %Abort, label %47420

47420:                                            ; preds = %.15575
  %47421 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47422 = xor i32 %47421, 3194
  %47423 = urem i32 %47422, 4096
  %47424 = getelementptr i8, i8 addrspace(1)* %4, i32 %47423
  %47425 = load i8, i8 addrspace(1)* %47424, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47424, align 1, !nosanitize !3
  store i32 1597, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47426 = sub i64 %47418, 928
  store i64 %47426, i64* %remaing_gas, align 4
  %47427 = load i64, i64* %STACK_DEP_PTR, align 4
  %47428 = getelementptr i256, i256* %STACK, i64 %47427
  %47429 = load i256, i256* %47428, align 4
  %47430 = load i64, i64* %STACK_DEP_PTR, align 4
  %47431 = sub i64 %47430, 1
  store i64 %47431, i64* %STACK_DEP_PTR, align 4
  %47432 = load i64, i64* %STACK_DEP_PTR, align 4
  %47433 = getelementptr i256, i256* %STACK, i64 %47432
  %47434 = load i256, i256* %47433, align 4
  %47435 = load i64, i64* %STACK_DEP_PTR, align 4
  %47436 = sub i64 %47435, 1
  store i64 %47436, i64* %STACK_DEP_PTR, align 4
  %47437 = load i64, i64* %STACK_DEP_PTR, align 4
  %47438 = getelementptr i256, i256* %STACK, i64 %47437
  %47439 = load i256, i256* %47438, align 4
  %47440 = load i64, i64* %STACK_DEP_PTR, align 4
  %47441 = sub i64 %47440, 1
  store i64 %47441, i64* %STACK_DEP_PTR, align 4
  %47442 = load i64, i64* %STACK_DEP_PTR, align 4
  %47443 = getelementptr i256, i256* %STACK, i64 %47442
  %47444 = load i256, i256* %47443, align 4
  %47445 = load i64, i64* %STACK_DEP_PTR, align 4
  %47446 = sub i64 %47445, 1
  store i64 %47446, i64* %STACK_DEP_PTR, align 4
  %47447 = load i64, i64* %STACK_DEP_PTR, align 4
  %47448 = getelementptr i256, i256* %STACK, i64 %47447
  %47449 = load i256, i256* %47448, align 4
  %47450 = load i64, i64* %STACK_DEP_PTR, align 4
  %47451 = sub i64 %47450, 1
  store i64 %47451, i64* %STACK_DEP_PTR, align 4
  %47452 = add i256 0, %47449, !pc !692, !intsan !10
  %47453 = trunc i256 %47452 to i64
  %47454 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47453, i256* %47454)
  %47455 = load i256, i256* %47454, align 4
  %47456 = trunc i256 64 to i64
  %47457 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47456, i256* %47457)
  %47458 = load i256, i256* %47457, align 4
  %47459 = and i256 1461501637330902918203684832716283019655932542975, %47455
  %47460 = and i256 1461501637330902918203684832716283019655932542975, %47459
  %47461 = trunc i256 %47458 to i64
  %47462 = alloca i256, align 8
  store i256 %47460, i256* %47462, align 4
  %47463 = bitcast i256* %47462 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %47461, i8* %47463, i64 32)
  %47464 = add i256 32, %47458, !pc !693, !intsan !10
  %47465 = trunc i256 %47464 to i64
  %47466 = alloca i256, align 8
  store i256 %47444, i256* %47466, align 4
  %47467 = bitcast i256* %47466 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %47465, i8* %47467, i64 32)
  %47468 = add i256 32, %47464, !pc !694, !intsan !10
  %47469 = trunc i256 64 to i64
  %47470 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47469, i256* %47470)
  %47471 = load i256, i256* %47470, align 4
  %47472 = sub i256 %47468, %47471, !pc !695, !intsan !8
  %47473 = trunc i256 -4135887542360290124705128266002866539021900757171529042443963002133710001969 to i64
  call void @addBugSet(i64 %47473)
  %47474 = add i256 0, %47449, !pc !696, !intsan !10
  %47475 = trunc i256 %47474 to i64
  %47476 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47475, i256* %47476)
  %47477 = load i256, i256* %47476, align 4
  %47478 = trunc i256 14584 to i64
  %47479 = load i64, i64* %STACK_DEP_PTR, align 4
  %47480 = add i64 %47479, 1
  store i64 %47480, i64* %STACK_DEP_PTR, align 4
  %47481 = load i64, i64* %STACK_DEP_PTR, align 4
  %47482 = getelementptr i256, i256* %STACK, i64 %47481
  store i256 %47449, i256* %47482, align 4
  %47483 = load i64, i64* %STACK_DEP_PTR, align 4
  %47484 = add i64 %47483, 1
  store i64 %47484, i64* %STACK_DEP_PTR, align 4
  %47485 = load i64, i64* %STACK_DEP_PTR, align 4
  %47486 = getelementptr i256, i256* %STACK, i64 %47485
  store i256 %47444, i256* %47486, align 4
  %47487 = load i64, i64* %STACK_DEP_PTR, align 4
  %47488 = add i64 %47487, 1
  store i64 %47488, i64* %STACK_DEP_PTR, align 4
  %47489 = load i64, i64* %STACK_DEP_PTR, align 4
  %47490 = getelementptr i256, i256* %STACK, i64 %47489
  store i256 %47439, i256* %47490, align 4
  %47491 = load i64, i64* %STACK_DEP_PTR, align 4
  %47492 = add i64 %47491, 1
  store i64 %47492, i64* %STACK_DEP_PTR, align 4
  %47493 = load i64, i64* %STACK_DEP_PTR, align 4
  %47494 = getelementptr i256, i256* %STACK, i64 %47493
  store i256 %47434, i256* %47494, align 4
  %47495 = load i64, i64* %STACK_DEP_PTR, align 4
  %47496 = add i64 %47495, 1
  store i64 %47496, i64* %STACK_DEP_PTR, align 4
  %47497 = load i64, i64* %STACK_DEP_PTR, align 4
  %47498 = getelementptr i256, i256* %STACK, i64 %47497
  store i256 %47429, i256* %47498, align 4
  %47499 = load i64, i64* %STACK_DEP_PTR, align 4
  %47500 = add i64 %47499, 1
  store i64 %47500, i64* %STACK_DEP_PTR, align 4
  %47501 = load i64, i64* %STACK_DEP_PTR, align 4
  %47502 = getelementptr i256, i256* %STACK, i64 %47501
  store i256 15700, i256* %47502, align 4
  %47503 = load i64, i64* %STACK_DEP_PTR, align 4
  %47504 = add i64 %47503, 1
  store i64 %47504, i64* %STACK_DEP_PTR, align 4
  %47505 = load i64, i64* %STACK_DEP_PTR, align 4
  %47506 = getelementptr i256, i256* %STACK, i64 %47505
  store i256 %47477, i256* %47506, align 4
  %47507 = load i64, i64* %STACK_DEP_PTR, align 4
  %47508 = add i64 %47507, 1
  store i64 %47508, i64* %STACK_DEP_PTR, align 4
  %47509 = load i64, i64* %STACK_DEP_PTR, align 4
  %47510 = getelementptr i256, i256* %STACK, i64 %47509
  store i256 1, i256* %47510, align 4
  br label %.14584, !EVMBB !4

.15700:                                           ; preds = %JumpTable
  %47511 = load i64, i64* %remaing_gas, align 4
  %47512 = icmp ugt i64 704, %47511
  br i1 %47512, label %Abort, label %47513

47513:                                            ; preds = %.15700
  %47514 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47515 = xor i32 %47514, 2726
  %47516 = urem i32 %47515, 4096
  %47517 = getelementptr i8, i8 addrspace(1)* %4, i32 %47516
  %47518 = load i8, i8 addrspace(1)* %47517, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %47517, align 1, !nosanitize !3
  store i32 1363, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %47519 = sub i64 %47511, 704
  store i64 %47519, i64* %remaing_gas, align 4
  %47520 = load i64, i64* %STACK_DEP_PTR, align 4
  %47521 = getelementptr i256, i256* %STACK, i64 %47520
  %47522 = load i256, i256* %47521, align 4
  %47523 = load i64, i64* %STACK_DEP_PTR, align 4
  %47524 = sub i64 %47523, 1
  store i64 %47524, i64* %STACK_DEP_PTR, align 4
  %47525 = load i64, i64* %STACK_DEP_PTR, align 4
  %47526 = getelementptr i256, i256* %STACK, i64 %47525
  %47527 = load i256, i256* %47526, align 4
  %47528 = load i64, i64* %STACK_DEP_PTR, align 4
  %47529 = sub i64 %47528, 1
  store i64 %47529, i64* %STACK_DEP_PTR, align 4
  %47530 = load i64, i64* %STACK_DEP_PTR, align 4
  %47531 = getelementptr i256, i256* %STACK, i64 %47530
  %47532 = load i256, i256* %47531, align 4
  %47533 = load i64, i64* %STACK_DEP_PTR, align 4
  %47534 = sub i64 %47533, 1
  store i64 %47534, i64* %STACK_DEP_PTR, align 4
  %47535 = load i64, i64* %STACK_DEP_PTR, align 4
  %47536 = getelementptr i256, i256* %STACK, i64 %47535
  %47537 = load i256, i256* %47536, align 4
  %47538 = load i64, i64* %STACK_DEP_PTR, align 4
  %47539 = sub i64 %47538, 1
  store i64 %47539, i64* %STACK_DEP_PTR, align 4
  %47540 = load i64, i64* %STACK_DEP_PTR, align 4
  %47541 = getelementptr i256, i256* %STACK, i64 %47540
  %47542 = load i256, i256* %47541, align 4
  %47543 = load i64, i64* %STACK_DEP_PTR, align 4
  %47544 = sub i64 %47543, 1
  store i64 %47544, i64* %STACK_DEP_PTR, align 4
  %47545 = alloca i256, align 8
  store i256 13, i256* %47545, align 4
  %47546 = alloca i256, align 8
  call void @__device_sload(i256* %47545, i256* %47546)
  %47547 = call i32 @__hashword(i256* %47545)
  %47548 = load i32, i32* %5, align 4
  %47549 = icmp eq i32 %47547, %47548
  %47550 = or i1 false, %47549
  %47551 = load i32, i32* %6, align 4
  %47552 = icmp eq i32 %47547, %47551
  %47553 = or i1 %47550, %47552
  %47554 = load i32, i32* %7, align 4
  %47555 = icmp eq i32 %47547, %47554
  %47556 = or i1 %47553, %47555
  %47557 = load i32, i32* %8, align 4
  %47558 = icmp eq i32 %47547, %47557
  %47559 = or i1 %47556, %47558
  %47560 = load i32, i32* %9, align 4
  %47561 = icmp eq i32 %47547, %47560
  %47562 = or i1 %47559, %47561
  %47563 = load i32, i32* %10, align 4
  %47564 = icmp eq i32 %47547, %47563
  %47565 = or i1 %47562, %47564
  %47566 = load i32, i32* %11, align 4
  %47567 = icmp eq i32 %47547, %47566
  %47568 = or i1 %47565, %47567
  %47569 = load i32, i32* %12, align 4
  %47570 = icmp eq i32 %47547, %47569
  %47571 = or i1 %47568, %47570
  %47572 = load i32, i32* %13, align 4
  %47573 = icmp eq i32 %47547, %47572
  %47574 = or i1 %47571, %47573
  %47575 = load i32, i32* %14, align 4
  %47576 = icmp eq i32 %47547, %47575
  %47577 = or i1 %47574, %47576
  %47578 = load i32, i32* %15, align 4
  %47579 = icmp eq i32 %47547, %47578
  %47580 = or i1 %47577, %47579
  %47581 = load i32, i32* %16, align 4
  %47582 = icmp eq i32 %47547, %47581
  %47583 = or i1 %47580, %47582
  %47584 = load i32, i32* %17, align 4
  %47585 = icmp eq i32 %47547, %47584
  %47586 = or i1 %47583, %47585
  %47587 = load i32, i32* %18, align 4
  %47588 = icmp eq i32 %47547, %47587
  %47589 = or i1 %47586, %47588
  %47590 = load i32, i32* %19, align 4
  %47591 = icmp eq i32 %47547, %47590
  %47592 = or i1 %47589, %47591
  %47593 = load i32, i32* %20, align 4
  %47594 = icmp eq i32 %47547, %47593
  %47595 = or i1 %47592, %47594
  %47596 = load i32, i32* %21, align 4
  %47597 = icmp eq i32 %47547, %47596
  %47598 = or i1 %47595, %47597
  %47599 = load i32, i32* %22, align 4
  %47600 = icmp eq i32 %47547, %47599
  %47601 = or i1 %47598, %47600
  %47602 = load i32, i32* %23, align 4
  %47603 = icmp eq i32 %47547, %47602
  %47604 = or i1 %47601, %47603
  %47605 = load i32, i32* %24, align 4
  %47606 = icmp eq i32 %47547, %47605
  %47607 = or i1 %47604, %47606
  %47608 = load i32, i32* %25, align 4
  %47609 = icmp eq i32 %47547, %47608
  %47610 = or i1 %47607, %47609
  %47611 = load i32, i32* %26, align 4
  %47612 = icmp eq i32 %47547, %47611
  %47613 = or i1 %47610, %47612
  %47614 = load i32, i32* %27, align 4
  %47615 = icmp eq i32 %47547, %47614
  %47616 = or i1 %47613, %47615
  %47617 = load i32, i32* %28, align 4
  %47618 = icmp eq i32 %47547, %47617
  %47619 = or i1 %47616, %47618
  %47620 = load i32, i32* %29, align 4
  %47621 = icmp eq i32 %47547, %47620
  %47622 = or i1 %47619, %47621
  %47623 = load i32, i32* %30, align 4
  %47624 = icmp eq i32 %47547, %47623
  %47625 = or i1 %47622, %47624
  %47626 = load i32, i32* %31, align 4
  %47627 = icmp eq i32 %47547, %47626
  %47628 = or i1 %47625, %47627
  %47629 = load i32, i32* %32, align 4
  %47630 = icmp eq i32 %47547, %47629
  %47631 = or i1 %47628, %47630
  %47632 = load i32, i32* %33, align 4
  %47633 = icmp eq i32 %47547, %47632
  %47634 = or i1 %47631, %47633
  %47635 = load i32, i32* %34, align 4
  %47636 = icmp eq i32 %47547, %47635
  %47637 = or i1 %47634, %47636
  %47638 = load i32, i32* %35, align 4
  %47639 = icmp eq i32 %47547, %47638
  %47640 = or i1 %47637, %47639
  %47641 = load i32, i32* %36, align 4
  %47642 = icmp eq i32 %47547, %47641
  %47643 = or i1 %47640, %47642
  %47644 = load i32, i32* %37, align 4
  %47645 = icmp eq i32 %47547, %47644
  %47646 = or i1 %47643, %47645
  %47647 = load i32, i32* %38, align 4
  %47648 = icmp eq i32 %47547, %47647
  %47649 = or i1 %47646, %47648
  %47650 = load i32, i32* %39, align 4
  %47651 = icmp eq i32 %47547, %47650
  %47652 = or i1 %47649, %47651
  %47653 = load i32, i32* %40, align 4
  %47654 = icmp eq i32 %47547, %47653
  %47655 = or i1 %47652, %47654
  %47656 = load i32, i32* %41, align 4
  %47657 = icmp eq i32 %47547, %47656
  %47658 = or i1 %47655, %47657
  %47659 = load i32, i32* %42, align 4
  %47660 = icmp eq i32 %47547, %47659
  %47661 = or i1 %47658, %47660
  %47662 = load i32, i32* %43, align 4
  %47663 = icmp eq i32 %47547, %47662
  %47664 = or i1 %47661, %47663
  %47665 = load i32, i32* %44, align 4
  %47666 = icmp eq i32 %47547, %47665
  %47667 = or i1 %47664, %47666
  %47668 = load i32, i32* %45, align 4
  %47669 = icmp eq i32 %47547, %47668
  %47670 = or i1 %47667, %47669
  %47671 = load i32, i32* %46, align 4
  %47672 = icmp eq i32 %47547, %47671
  %47673 = or i1 %47670, %47672
  %47674 = load i32, i32* %47, align 4
  %47675 = icmp eq i32 %47547, %47674
  %47676 = or i1 %47673, %47675
  %47677 = load i32, i32* %48, align 4
  %47678 = icmp eq i32 %47547, %47677
  %47679 = or i1 %47676, %47678
  %47680 = load i32, i32* %49, align 4
  %47681 = icmp eq i32 %47547, %47680
  %47682 = or i1 %47679, %47681
  %47683 = load i32, i32* %50, align 4
  %47684 = icmp eq i32 %47547, %47683
  %47685 = or i1 %47682, %47684
  %47686 = load i32, i32* %51, align 4
  %47687 = icmp eq i32 %47547, %47686
  %47688 = or i1 %47685, %47687
  %47689 = load i32, i32* %52, align 4
  %47690 = icmp eq i32 %47547, %47689
  %47691 = or i1 %47688, %47690
  %47692 = load i32, i32* %53, align 4
  %47693 = icmp eq i32 %47547, %47692
  %47694 = or i1 %47691, %47693
  %47695 = load i32, i32* %54, align 4
  %47696 = icmp eq i32 %47547, %47695
  %47697 = or i1 %47694, %47696
  %47698 = load i32, i32* %55, align 4
  %47699 = icmp eq i32 %47547, %47698
  %47700 = or i1 %47697, %47699
  %47701 = load i32, i32* %56, align 4
  %47702 = icmp eq i32 %47547, %47701
  %47703 = or i1 %47700, %47702
  %47704 = load i32, i32* %57, align 4
  %47705 = icmp eq i32 %47547, %47704
  %47706 = or i1 %47703, %47705
  %47707 = load i32, i32* %58, align 4
  %47708 = icmp eq i32 %47547, %47707
  %47709 = or i1 %47706, %47708
  %47710 = load i32, i32* %59, align 4
  %47711 = icmp eq i32 %47547, %47710
  %47712 = or i1 %47709, %47711
  %47713 = load i32, i32* %60, align 4
  %47714 = icmp eq i32 %47547, %47713
  %47715 = or i1 %47712, %47714
  %47716 = load i32, i32* %61, align 4
  %47717 = icmp eq i32 %47547, %47716
  %47718 = or i1 %47715, %47717
  %47719 = load i32, i32* %62, align 4
  %47720 = icmp eq i32 %47547, %47719
  %47721 = or i1 %47718, %47720
  %47722 = getelementptr i8, i8 addrspace(1)* %4, i32 174
  %47723 = zext i1 %47721 to i8
  store i8 %47723, i8 addrspace(1)* %47722, align 1, !nosanitize !3
  %47724 = load i256, i256* %47546, align 4
  %47725 = add i256 32, %47542, !pc !697, !intsan !10
  %47726 = trunc i256 %47725 to i64
  %47727 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47726, i256* %47727)
  %47728 = load i256, i256* %47727, align 4
  %47729 = alloca i256, align 8
  store i256 13, i256* %47729, align 4
  %47730 = alloca i256, align 8
  call void @__device_sload(i256* %47729, i256* %47730)
  %47731 = call i32 @__hashword(i256* %47729)
  %47732 = load i32, i32* %5, align 4
  %47733 = icmp eq i32 %47731, %47732
  %47734 = or i1 false, %47733
  %47735 = load i32, i32* %6, align 4
  %47736 = icmp eq i32 %47731, %47735
  %47737 = or i1 %47734, %47736
  %47738 = load i32, i32* %7, align 4
  %47739 = icmp eq i32 %47731, %47738
  %47740 = or i1 %47737, %47739
  %47741 = load i32, i32* %8, align 4
  %47742 = icmp eq i32 %47731, %47741
  %47743 = or i1 %47740, %47742
  %47744 = load i32, i32* %9, align 4
  %47745 = icmp eq i32 %47731, %47744
  %47746 = or i1 %47743, %47745
  %47747 = load i32, i32* %10, align 4
  %47748 = icmp eq i32 %47731, %47747
  %47749 = or i1 %47746, %47748
  %47750 = load i32, i32* %11, align 4
  %47751 = icmp eq i32 %47731, %47750
  %47752 = or i1 %47749, %47751
  %47753 = load i32, i32* %12, align 4
  %47754 = icmp eq i32 %47731, %47753
  %47755 = or i1 %47752, %47754
  %47756 = load i32, i32* %13, align 4
  %47757 = icmp eq i32 %47731, %47756
  %47758 = or i1 %47755, %47757
  %47759 = load i32, i32* %14, align 4
  %47760 = icmp eq i32 %47731, %47759
  %47761 = or i1 %47758, %47760
  %47762 = load i32, i32* %15, align 4
  %47763 = icmp eq i32 %47731, %47762
  %47764 = or i1 %47761, %47763
  %47765 = load i32, i32* %16, align 4
  %47766 = icmp eq i32 %47731, %47765
  %47767 = or i1 %47764, %47766
  %47768 = load i32, i32* %17, align 4
  %47769 = icmp eq i32 %47731, %47768
  %47770 = or i1 %47767, %47769
  %47771 = load i32, i32* %18, align 4
  %47772 = icmp eq i32 %47731, %47771
  %47773 = or i1 %47770, %47772
  %47774 = load i32, i32* %19, align 4
  %47775 = icmp eq i32 %47731, %47774
  %47776 = or i1 %47773, %47775
  %47777 = load i32, i32* %20, align 4
  %47778 = icmp eq i32 %47731, %47777
  %47779 = or i1 %47776, %47778
  %47780 = load i32, i32* %21, align 4
  %47781 = icmp eq i32 %47731, %47780
  %47782 = or i1 %47779, %47781
  %47783 = load i32, i32* %22, align 4
  %47784 = icmp eq i32 %47731, %47783
  %47785 = or i1 %47782, %47784
  %47786 = load i32, i32* %23, align 4
  %47787 = icmp eq i32 %47731, %47786
  %47788 = or i1 %47785, %47787
  %47789 = load i32, i32* %24, align 4
  %47790 = icmp eq i32 %47731, %47789
  %47791 = or i1 %47788, %47790
  %47792 = load i32, i32* %25, align 4
  %47793 = icmp eq i32 %47731, %47792
  %47794 = or i1 %47791, %47793
  %47795 = load i32, i32* %26, align 4
  %47796 = icmp eq i32 %47731, %47795
  %47797 = or i1 %47794, %47796
  %47798 = load i32, i32* %27, align 4
  %47799 = icmp eq i32 %47731, %47798
  %47800 = or i1 %47797, %47799
  %47801 = load i32, i32* %28, align 4
  %47802 = icmp eq i32 %47731, %47801
  %47803 = or i1 %47800, %47802
  %47804 = load i32, i32* %29, align 4
  %47805 = icmp eq i32 %47731, %47804
  %47806 = or i1 %47803, %47805
  %47807 = load i32, i32* %30, align 4
  %47808 = icmp eq i32 %47731, %47807
  %47809 = or i1 %47806, %47808
  %47810 = load i32, i32* %31, align 4
  %47811 = icmp eq i32 %47731, %47810
  %47812 = or i1 %47809, %47811
  %47813 = load i32, i32* %32, align 4
  %47814 = icmp eq i32 %47731, %47813
  %47815 = or i1 %47812, %47814
  %47816 = load i32, i32* %33, align 4
  %47817 = icmp eq i32 %47731, %47816
  %47818 = or i1 %47815, %47817
  %47819 = load i32, i32* %34, align 4
  %47820 = icmp eq i32 %47731, %47819
  %47821 = or i1 %47818, %47820
  %47822 = load i32, i32* %35, align 4
  %47823 = icmp eq i32 %47731, %47822
  %47824 = or i1 %47821, %47823
  %47825 = load i32, i32* %36, align 4
  %47826 = icmp eq i32 %47731, %47825
  %47827 = or i1 %47824, %47826
  %47828 = load i32, i32* %37, align 4
  %47829 = icmp eq i32 %47731, %47828
  %47830 = or i1 %47827, %47829
  %47831 = load i32, i32* %38, align 4
  %47832 = icmp eq i32 %47731, %47831
  %47833 = or i1 %47830, %47832
  %47834 = load i32, i32* %39, align 4
  %47835 = icmp eq i32 %47731, %47834
  %47836 = or i1 %47833, %47835
  %47837 = load i32, i32* %40, align 4
  %47838 = icmp eq i32 %47731, %47837
  %47839 = or i1 %47836, %47838
  %47840 = load i32, i32* %41, align 4
  %47841 = icmp eq i32 %47731, %47840
  %47842 = or i1 %47839, %47841
  %47843 = load i32, i32* %42, align 4
  %47844 = icmp eq i32 %47731, %47843
  %47845 = or i1 %47842, %47844
  %47846 = load i32, i32* %43, align 4
  %47847 = icmp eq i32 %47731, %47846
  %47848 = or i1 %47845, %47847
  %47849 = load i32, i32* %44, align 4
  %47850 = icmp eq i32 %47731, %47849
  %47851 = or i1 %47848, %47850
  %47852 = load i32, i32* %45, align 4
  %47853 = icmp eq i32 %47731, %47852
  %47854 = or i1 %47851, %47853
  %47855 = load i32, i32* %46, align 4
  %47856 = icmp eq i32 %47731, %47855
  %47857 = or i1 %47854, %47856
  %47858 = load i32, i32* %47, align 4
  %47859 = icmp eq i32 %47731, %47858
  %47860 = or i1 %47857, %47859
  %47861 = load i32, i32* %48, align 4
  %47862 = icmp eq i32 %47731, %47861
  %47863 = or i1 %47860, %47862
  %47864 = load i32, i32* %49, align 4
  %47865 = icmp eq i32 %47731, %47864
  %47866 = or i1 %47863, %47865
  %47867 = load i32, i32* %50, align 4
  %47868 = icmp eq i32 %47731, %47867
  %47869 = or i1 %47866, %47868
  %47870 = load i32, i32* %51, align 4
  %47871 = icmp eq i32 %47731, %47870
  %47872 = or i1 %47869, %47871
  %47873 = load i32, i32* %52, align 4
  %47874 = icmp eq i32 %47731, %47873
  %47875 = or i1 %47872, %47874
  %47876 = load i32, i32* %53, align 4
  %47877 = icmp eq i32 %47731, %47876
  %47878 = or i1 %47875, %47877
  %47879 = load i32, i32* %54, align 4
  %47880 = icmp eq i32 %47731, %47879
  %47881 = or i1 %47878, %47880
  %47882 = load i32, i32* %55, align 4
  %47883 = icmp eq i32 %47731, %47882
  %47884 = or i1 %47881, %47883
  %47885 = load i32, i32* %56, align 4
  %47886 = icmp eq i32 %47731, %47885
  %47887 = or i1 %47884, %47886
  %47888 = load i32, i32* %57, align 4
  %47889 = icmp eq i32 %47731, %47888
  %47890 = or i1 %47887, %47889
  %47891 = load i32, i32* %58, align 4
  %47892 = icmp eq i32 %47731, %47891
  %47893 = or i1 %47890, %47892
  %47894 = load i32, i32* %59, align 4
  %47895 = icmp eq i32 %47731, %47894
  %47896 = or i1 %47893, %47895
  %47897 = load i32, i32* %60, align 4
  %47898 = icmp eq i32 %47731, %47897
  %47899 = or i1 %47896, %47898
  %47900 = load i32, i32* %61, align 4
  %47901 = icmp eq i32 %47731, %47900
  %47902 = or i1 %47899, %47901
  %47903 = load i32, i32* %62, align 4
  %47904 = icmp eq i32 %47731, %47903
  %47905 = or i1 %47902, %47904
  %47906 = getelementptr i8, i8 addrspace(1)* %4, i32 175
  %47907 = zext i1 %47905 to i8
  store i8 %47907, i8 addrspace(1)* %47906, align 1, !nosanitize !3
  %47908 = load i256, i256* %47730, align 4
  %47909 = add i256 %47908, %47728, !pc !698, !intsan !10
  %47910 = icmp ult i256 %47909, %47724
  %47911 = trunc i256 15735 to i64
  %jump.check224 = icmp ne i1 %47910, false
  %47912 = load i64, i64* %STACK_DEP_PTR, align 4
  %47913 = add i64 %47912, 1
  store i64 %47913, i64* %STACK_DEP_PTR, align 4
  %47914 = load i64, i64* %STACK_DEP_PTR, align 4
  %47915 = getelementptr i256, i256* %STACK, i64 %47914
  store i256 %47542, i256* %47915, align 4
  %47916 = load i64, i64* %STACK_DEP_PTR, align 4
  %47917 = add i64 %47916, 1
  store i64 %47917, i64* %STACK_DEP_PTR, align 4
  %47918 = load i64, i64* %STACK_DEP_PTR, align 4
  %47919 = getelementptr i256, i256* %STACK, i64 %47918
  store i256 %47537, i256* %47919, align 4
  %47920 = load i64, i64* %STACK_DEP_PTR, align 4
  %47921 = add i64 %47920, 1
  store i64 %47921, i64* %STACK_DEP_PTR, align 4
  %47922 = load i64, i64* %STACK_DEP_PTR, align 4
  %47923 = getelementptr i256, i256* %STACK, i64 %47922
  store i256 %47532, i256* %47923, align 4
  %47924 = load i64, i64* %STACK_DEP_PTR, align 4
  %47925 = add i64 %47924, 1
  store i64 %47925, i64* %STACK_DEP_PTR, align 4
  %47926 = load i64, i64* %STACK_DEP_PTR, align 4
  %47927 = getelementptr i256, i256* %STACK, i64 %47926
  store i256 %47527, i256* %47927, align 4
  %47928 = load i64, i64* %STACK_DEP_PTR, align 4
  %47929 = add i64 %47928, 1
  store i64 %47929, i64* %STACK_DEP_PTR, align 4
  %47930 = load i64, i64* %STACK_DEP_PTR, align 4
  %47931 = getelementptr i256, i256* %STACK, i64 %47930
  store i256 %47522, i256* %47931, align 4
  %47932 = load i64, i64* %STACK_DEP_PTR, align 4
  %47933 = add i64 %47932, 1
  store i64 %47933, i64* %STACK_DEP_PTR, align 4
  %47934 = zext i1 %47910 to i256
  %47935 = load i64, i64* %STACK_DEP_PTR, align 4
  %47936 = getelementptr i256, i256* %STACK, i64 %47935
  store i256 %47934, i256* %47936, align 4
  br i1 %jump.check224, label %.15735, label %.15719, !EVMBB !4

.15719:                                           ; preds = %47513
  %47937 = load i64, i64* %STACK_DEP_PTR, align 4
  %47938 = getelementptr i256, i256* %STACK, i64 %47937
  %47939 = load i256, i256* %47938, align 4
  %47940 = load i64, i64* %STACK_DEP_PTR, align 4
  %47941 = sub i64 %47940, 1
  store i64 %47941, i64* %STACK_DEP_PTR, align 4
  %47942 = load i64, i64* %STACK_DEP_PTR, align 4
  %47943 = getelementptr i256, i256* %STACK, i64 %47942
  %47944 = load i256, i256* %47943, align 4
  %47945 = load i64, i64* %STACK_DEP_PTR, align 4
  %47946 = sub i64 %47945, 1
  store i64 %47946, i64* %STACK_DEP_PTR, align 4
  %47947 = load i64, i64* %STACK_DEP_PTR, align 4
  %47948 = getelementptr i256, i256* %STACK, i64 %47947
  %47949 = load i256, i256* %47948, align 4
  %47950 = load i64, i64* %STACK_DEP_PTR, align 4
  %47951 = sub i64 %47950, 1
  store i64 %47951, i64* %STACK_DEP_PTR, align 4
  %47952 = load i64, i64* %STACK_DEP_PTR, align 4
  %47953 = getelementptr i256, i256* %STACK, i64 %47952
  %47954 = load i256, i256* %47953, align 4
  %47955 = load i64, i64* %STACK_DEP_PTR, align 4
  %47956 = sub i64 %47955, 1
  store i64 %47956, i64* %STACK_DEP_PTR, align 4
  %47957 = load i64, i64* %STACK_DEP_PTR, align 4
  %47958 = getelementptr i256, i256* %STACK, i64 %47957
  %47959 = load i256, i256* %47958, align 4
  %47960 = load i64, i64* %STACK_DEP_PTR, align 4
  %47961 = sub i64 %47960, 1
  store i64 %47961, i64* %STACK_DEP_PTR, align 4
  %47962 = load i64, i64* %STACK_DEP_PTR, align 4
  %47963 = getelementptr i256, i256* %STACK, i64 %47962
  %47964 = load i256, i256* %47963, align 4
  %47965 = load i64, i64* %STACK_DEP_PTR, align 4
  %47966 = sub i64 %47965, 1
  store i64 %47966, i64* %STACK_DEP_PTR, align 4
  %47967 = add i256 32, %47964, !pc !699, !intsan !10
  %47968 = trunc i256 %47967 to i64
  %47969 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47968, i256* %47969)
  %47970 = load i256, i256* %47969, align 4
  %47971 = add i256 32, %47964, !pc !700, !intsan !10
  %47972 = trunc i256 %47971 to i64
  %47973 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %47972, i256* %47973)
  %47974 = load i256, i256* %47973, align 4
  %47975 = alloca i256, align 8
  store i256 13, i256* %47975, align 4
  %47976 = alloca i256, align 8
  call void @__device_sload(i256* %47975, i256* %47976)
  %47977 = call i32 @__hashword(i256* %47975)
  %47978 = load i32, i32* %5, align 4
  %47979 = icmp eq i32 %47977, %47978
  %47980 = or i1 false, %47979
  %47981 = load i32, i32* %6, align 4
  %47982 = icmp eq i32 %47977, %47981
  %47983 = or i1 %47980, %47982
  %47984 = load i32, i32* %7, align 4
  %47985 = icmp eq i32 %47977, %47984
  %47986 = or i1 %47983, %47985
  %47987 = load i32, i32* %8, align 4
  %47988 = icmp eq i32 %47977, %47987
  %47989 = or i1 %47986, %47988
  %47990 = load i32, i32* %9, align 4
  %47991 = icmp eq i32 %47977, %47990
  %47992 = or i1 %47989, %47991
  %47993 = load i32, i32* %10, align 4
  %47994 = icmp eq i32 %47977, %47993
  %47995 = or i1 %47992, %47994
  %47996 = load i32, i32* %11, align 4
  %47997 = icmp eq i32 %47977, %47996
  %47998 = or i1 %47995, %47997
  %47999 = load i32, i32* %12, align 4
  %48000 = icmp eq i32 %47977, %47999
  %48001 = or i1 %47998, %48000
  %48002 = load i32, i32* %13, align 4
  %48003 = icmp eq i32 %47977, %48002
  %48004 = or i1 %48001, %48003
  %48005 = load i32, i32* %14, align 4
  %48006 = icmp eq i32 %47977, %48005
  %48007 = or i1 %48004, %48006
  %48008 = load i32, i32* %15, align 4
  %48009 = icmp eq i32 %47977, %48008
  %48010 = or i1 %48007, %48009
  %48011 = load i32, i32* %16, align 4
  %48012 = icmp eq i32 %47977, %48011
  %48013 = or i1 %48010, %48012
  %48014 = load i32, i32* %17, align 4
  %48015 = icmp eq i32 %47977, %48014
  %48016 = or i1 %48013, %48015
  %48017 = load i32, i32* %18, align 4
  %48018 = icmp eq i32 %47977, %48017
  %48019 = or i1 %48016, %48018
  %48020 = load i32, i32* %19, align 4
  %48021 = icmp eq i32 %47977, %48020
  %48022 = or i1 %48019, %48021
  %48023 = load i32, i32* %20, align 4
  %48024 = icmp eq i32 %47977, %48023
  %48025 = or i1 %48022, %48024
  %48026 = load i32, i32* %21, align 4
  %48027 = icmp eq i32 %47977, %48026
  %48028 = or i1 %48025, %48027
  %48029 = load i32, i32* %22, align 4
  %48030 = icmp eq i32 %47977, %48029
  %48031 = or i1 %48028, %48030
  %48032 = load i32, i32* %23, align 4
  %48033 = icmp eq i32 %47977, %48032
  %48034 = or i1 %48031, %48033
  %48035 = load i32, i32* %24, align 4
  %48036 = icmp eq i32 %47977, %48035
  %48037 = or i1 %48034, %48036
  %48038 = load i32, i32* %25, align 4
  %48039 = icmp eq i32 %47977, %48038
  %48040 = or i1 %48037, %48039
  %48041 = load i32, i32* %26, align 4
  %48042 = icmp eq i32 %47977, %48041
  %48043 = or i1 %48040, %48042
  %48044 = load i32, i32* %27, align 4
  %48045 = icmp eq i32 %47977, %48044
  %48046 = or i1 %48043, %48045
  %48047 = load i32, i32* %28, align 4
  %48048 = icmp eq i32 %47977, %48047
  %48049 = or i1 %48046, %48048
  %48050 = load i32, i32* %29, align 4
  %48051 = icmp eq i32 %47977, %48050
  %48052 = or i1 %48049, %48051
  %48053 = load i32, i32* %30, align 4
  %48054 = icmp eq i32 %47977, %48053
  %48055 = or i1 %48052, %48054
  %48056 = load i32, i32* %31, align 4
  %48057 = icmp eq i32 %47977, %48056
  %48058 = or i1 %48055, %48057
  %48059 = load i32, i32* %32, align 4
  %48060 = icmp eq i32 %47977, %48059
  %48061 = or i1 %48058, %48060
  %48062 = load i32, i32* %33, align 4
  %48063 = icmp eq i32 %47977, %48062
  %48064 = or i1 %48061, %48063
  %48065 = load i32, i32* %34, align 4
  %48066 = icmp eq i32 %47977, %48065
  %48067 = or i1 %48064, %48066
  %48068 = load i32, i32* %35, align 4
  %48069 = icmp eq i32 %47977, %48068
  %48070 = or i1 %48067, %48069
  %48071 = load i32, i32* %36, align 4
  %48072 = icmp eq i32 %47977, %48071
  %48073 = or i1 %48070, %48072
  %48074 = load i32, i32* %37, align 4
  %48075 = icmp eq i32 %47977, %48074
  %48076 = or i1 %48073, %48075
  %48077 = load i32, i32* %38, align 4
  %48078 = icmp eq i32 %47977, %48077
  %48079 = or i1 %48076, %48078
  %48080 = load i32, i32* %39, align 4
  %48081 = icmp eq i32 %47977, %48080
  %48082 = or i1 %48079, %48081
  %48083 = load i32, i32* %40, align 4
  %48084 = icmp eq i32 %47977, %48083
  %48085 = or i1 %48082, %48084
  %48086 = load i32, i32* %41, align 4
  %48087 = icmp eq i32 %47977, %48086
  %48088 = or i1 %48085, %48087
  %48089 = load i32, i32* %42, align 4
  %48090 = icmp eq i32 %47977, %48089
  %48091 = or i1 %48088, %48090
  %48092 = load i32, i32* %43, align 4
  %48093 = icmp eq i32 %47977, %48092
  %48094 = or i1 %48091, %48093
  %48095 = load i32, i32* %44, align 4
  %48096 = icmp eq i32 %47977, %48095
  %48097 = or i1 %48094, %48096
  %48098 = load i32, i32* %45, align 4
  %48099 = icmp eq i32 %47977, %48098
  %48100 = or i1 %48097, %48099
  %48101 = load i32, i32* %46, align 4
  %48102 = icmp eq i32 %47977, %48101
  %48103 = or i1 %48100, %48102
  %48104 = load i32, i32* %47, align 4
  %48105 = icmp eq i32 %47977, %48104
  %48106 = or i1 %48103, %48105
  %48107 = load i32, i32* %48, align 4
  %48108 = icmp eq i32 %47977, %48107
  %48109 = or i1 %48106, %48108
  %48110 = load i32, i32* %49, align 4
  %48111 = icmp eq i32 %47977, %48110
  %48112 = or i1 %48109, %48111
  %48113 = load i32, i32* %50, align 4
  %48114 = icmp eq i32 %47977, %48113
  %48115 = or i1 %48112, %48114
  %48116 = load i32, i32* %51, align 4
  %48117 = icmp eq i32 %47977, %48116
  %48118 = or i1 %48115, %48117
  %48119 = load i32, i32* %52, align 4
  %48120 = icmp eq i32 %47977, %48119
  %48121 = or i1 %48118, %48120
  %48122 = load i32, i32* %53, align 4
  %48123 = icmp eq i32 %47977, %48122
  %48124 = or i1 %48121, %48123
  %48125 = load i32, i32* %54, align 4
  %48126 = icmp eq i32 %47977, %48125
  %48127 = or i1 %48124, %48126
  %48128 = load i32, i32* %55, align 4
  %48129 = icmp eq i32 %47977, %48128
  %48130 = or i1 %48127, %48129
  %48131 = load i32, i32* %56, align 4
  %48132 = icmp eq i32 %47977, %48131
  %48133 = or i1 %48130, %48132
  %48134 = load i32, i32* %57, align 4
  %48135 = icmp eq i32 %47977, %48134
  %48136 = or i1 %48133, %48135
  %48137 = load i32, i32* %58, align 4
  %48138 = icmp eq i32 %47977, %48137
  %48139 = or i1 %48136, %48138
  %48140 = load i32, i32* %59, align 4
  %48141 = icmp eq i32 %47977, %48140
  %48142 = or i1 %48139, %48141
  %48143 = load i32, i32* %60, align 4
  %48144 = icmp eq i32 %47977, %48143
  %48145 = or i1 %48142, %48144
  %48146 = load i32, i32* %61, align 4
  %48147 = icmp eq i32 %47977, %48146
  %48148 = or i1 %48145, %48147
  %48149 = load i32, i32* %62, align 4
  %48150 = icmp eq i32 %47977, %48149
  %48151 = or i1 %48148, %48150
  %48152 = getelementptr i8, i8 addrspace(1)* %4, i32 176
  %48153 = zext i1 %48151 to i8
  store i8 %48153, i8 addrspace(1)* %48152, align 1, !nosanitize !3
  %48154 = load i256, i256* %47976, align 4
  %48155 = add i256 %48154, %47974, !pc !701, !intsan !10
  %48156 = icmp ult i256 %48155, %47970
  %48157 = load i64, i64* %STACK_DEP_PTR, align 4
  %48158 = add i64 %48157, 1
  store i64 %48158, i64* %STACK_DEP_PTR, align 4
  %48159 = load i64, i64* %STACK_DEP_PTR, align 4
  %48160 = getelementptr i256, i256* %STACK, i64 %48159
  store i256 %47964, i256* %48160, align 4
  %48161 = load i64, i64* %STACK_DEP_PTR, align 4
  %48162 = add i64 %48161, 1
  store i64 %48162, i64* %STACK_DEP_PTR, align 4
  %48163 = load i64, i64* %STACK_DEP_PTR, align 4
  %48164 = getelementptr i256, i256* %STACK, i64 %48163
  store i256 %47959, i256* %48164, align 4
  %48165 = load i64, i64* %STACK_DEP_PTR, align 4
  %48166 = add i64 %48165, 1
  store i64 %48166, i64* %STACK_DEP_PTR, align 4
  %48167 = load i64, i64* %STACK_DEP_PTR, align 4
  %48168 = getelementptr i256, i256* %STACK, i64 %48167
  store i256 %47954, i256* %48168, align 4
  %48169 = load i64, i64* %STACK_DEP_PTR, align 4
  %48170 = add i64 %48169, 1
  store i64 %48170, i64* %STACK_DEP_PTR, align 4
  %48171 = load i64, i64* %STACK_DEP_PTR, align 4
  %48172 = getelementptr i256, i256* %STACK, i64 %48171
  store i256 %47949, i256* %48172, align 4
  %48173 = load i64, i64* %STACK_DEP_PTR, align 4
  %48174 = add i64 %48173, 1
  store i64 %48174, i64* %STACK_DEP_PTR, align 4
  %48175 = load i64, i64* %STACK_DEP_PTR, align 4
  %48176 = getelementptr i256, i256* %STACK, i64 %48175
  store i256 %47944, i256* %48176, align 4
  %48177 = load i64, i64* %STACK_DEP_PTR, align 4
  %48178 = add i64 %48177, 1
  store i64 %48178, i64* %STACK_DEP_PTR, align 4
  %48179 = zext i1 %48156 to i256
  %48180 = load i64, i64* %STACK_DEP_PTR, align 4
  %48181 = getelementptr i256, i256* %STACK, i64 %48180
  store i256 %48179, i256* %48181, align 4
  br label %.15735

.15735:                                           ; preds = %.15719, %47513, %JumpTable
  %48182 = load i64, i64* %remaing_gas, align 4
  %48183 = icmp ugt i64 128, %48182
  br i1 %48183, label %Abort, label %48184

48184:                                            ; preds = %.15735
  %48185 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48186 = xor i32 %48185, 1010
  %48187 = urem i32 %48186, 4096
  %48188 = getelementptr i8, i8 addrspace(1)* %4, i32 %48187
  %48189 = load i8, i8 addrspace(1)* %48188, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48188, align 1, !nosanitize !3
  store i32 505, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48190 = sub i64 %48182, 128
  store i64 %48190, i64* %remaing_gas, align 4
  %48191 = load i64, i64* %STACK_DEP_PTR, align 4
  %48192 = getelementptr i256, i256* %STACK, i64 %48191
  %48193 = load i256, i256* %48192, align 4
  %48194 = load i64, i64* %STACK_DEP_PTR, align 4
  %48195 = sub i64 %48194, 1
  store i64 %48195, i64* %STACK_DEP_PTR, align 4
  %48196 = trunc i256 15750 to i64
  %jump.check225 = icmp ne i256 %48193, 0
  %48197 = load i64, i64* %STACK_DEP_PTR, align 4
  %48198 = add i64 %48197, 1
  store i64 %48198, i64* %STACK_DEP_PTR, align 4
  %48199 = load i64, i64* %STACK_DEP_PTR, align 4
  %48200 = getelementptr i256, i256* %STACK, i64 %48199
  store i256 %48193, i256* %48200, align 4
  br i1 %jump.check225, label %.15750, label %.15741, !EVMBB !4

.15741:                                           ; preds = %48184
  %48201 = load i64, i64* %STACK_DEP_PTR, align 4
  %48202 = getelementptr i256, i256* %STACK, i64 %48201
  %48203 = load i256, i256* %48202, align 4
  %48204 = load i64, i64* %STACK_DEP_PTR, align 4
  %48205 = sub i64 %48204, 1
  store i64 %48205, i64* %STACK_DEP_PTR, align 4
  %48206 = load i64, i64* %STACK_DEP_PTR, align 4
  %48207 = getelementptr i256, i256* %STACK, i64 %48206
  %48208 = load i256, i256* %48207, align 4
  %48209 = load i64, i64* %STACK_DEP_PTR, align 4
  %48210 = sub i64 %48209, 1
  store i64 %48210, i64* %STACK_DEP_PTR, align 4
  %48211 = load i64, i64* %STACK_DEP_PTR, align 4
  %48212 = getelementptr i256, i256* %STACK, i64 %48211
  %48213 = load i256, i256* %48212, align 4
  %48214 = load i64, i64* %STACK_DEP_PTR, align 4
  %48215 = sub i64 %48214, 1
  store i64 %48215, i64* %STACK_DEP_PTR, align 4
  %48216 = load i64, i64* %STACK_DEP_PTR, align 4
  %48217 = getelementptr i256, i256* %STACK, i64 %48216
  %48218 = load i256, i256* %48217, align 4
  %48219 = load i64, i64* %STACK_DEP_PTR, align 4
  %48220 = sub i64 %48219, 1
  store i64 %48220, i64* %STACK_DEP_PTR, align 4
  %48221 = load i64, i64* %STACK_DEP_PTR, align 4
  %48222 = getelementptr i256, i256* %STACK, i64 %48221
  %48223 = load i256, i256* %48222, align 4
  %48224 = load i64, i64* %STACK_DEP_PTR, align 4
  %48225 = sub i64 %48224, 1
  store i64 %48225, i64* %STACK_DEP_PTR, align 4
  %48226 = load i64, i64* %STACK_DEP_PTR, align 4
  %48227 = getelementptr i256, i256* %STACK, i64 %48226
  %48228 = load i256, i256* %48227, align 4
  %48229 = load i64, i64* %STACK_DEP_PTR, align 4
  %48230 = sub i64 %48229, 1
  store i64 %48230, i64* %STACK_DEP_PTR, align 4
  %48231 = add i256 32, %48228, !pc !702, !intsan !10
  %48232 = trunc i256 %48231 to i64
  %48233 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %48232, i256* %48233)
  %48234 = load i256, i256* %48233, align 4
  %48235 = icmp eq i256 %48234, 1
  %48236 = load i64, i64* %STACK_DEP_PTR, align 4
  %48237 = add i64 %48236, 1
  store i64 %48237, i64* %STACK_DEP_PTR, align 4
  %48238 = load i64, i64* %STACK_DEP_PTR, align 4
  %48239 = getelementptr i256, i256* %STACK, i64 %48238
  store i256 %48228, i256* %48239, align 4
  %48240 = load i64, i64* %STACK_DEP_PTR, align 4
  %48241 = add i64 %48240, 1
  store i64 %48241, i64* %STACK_DEP_PTR, align 4
  %48242 = load i64, i64* %STACK_DEP_PTR, align 4
  %48243 = getelementptr i256, i256* %STACK, i64 %48242
  store i256 %48223, i256* %48243, align 4
  %48244 = load i64, i64* %STACK_DEP_PTR, align 4
  %48245 = add i64 %48244, 1
  store i64 %48245, i64* %STACK_DEP_PTR, align 4
  %48246 = load i64, i64* %STACK_DEP_PTR, align 4
  %48247 = getelementptr i256, i256* %STACK, i64 %48246
  store i256 %48218, i256* %48247, align 4
  %48248 = load i64, i64* %STACK_DEP_PTR, align 4
  %48249 = add i64 %48248, 1
  store i64 %48249, i64* %STACK_DEP_PTR, align 4
  %48250 = load i64, i64* %STACK_DEP_PTR, align 4
  %48251 = getelementptr i256, i256* %STACK, i64 %48250
  store i256 %48213, i256* %48251, align 4
  %48252 = load i64, i64* %STACK_DEP_PTR, align 4
  %48253 = add i64 %48252, 1
  store i64 %48253, i64* %STACK_DEP_PTR, align 4
  %48254 = load i64, i64* %STACK_DEP_PTR, align 4
  %48255 = getelementptr i256, i256* %STACK, i64 %48254
  store i256 %48208, i256* %48255, align 4
  %48256 = load i64, i64* %STACK_DEP_PTR, align 4
  %48257 = add i64 %48256, 1
  store i64 %48257, i64* %STACK_DEP_PTR, align 4
  %48258 = zext i1 %48235 to i256
  %48259 = load i64, i64* %STACK_DEP_PTR, align 4
  %48260 = getelementptr i256, i256* %STACK, i64 %48259
  store i256 %48258, i256* %48260, align 4
  br label %.15750

.15750:                                           ; preds = %.15741, %48184, %JumpTable
  %48261 = load i64, i64* %remaing_gas, align 4
  %48262 = icmp ugt i64 88, %48261
  br i1 %48262, label %Abort, label %48263

48263:                                            ; preds = %.15750
  %48264 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48265 = xor i32 %48264, 692
  %48266 = urem i32 %48265, 4096
  %48267 = getelementptr i8, i8 addrspace(1)* %4, i32 %48266
  %48268 = load i8, i8 addrspace(1)* %48267, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48267, align 1, !nosanitize !3
  store i32 346, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48269 = sub i64 %48261, 88
  store i64 %48269, i64* %remaing_gas, align 4
  %48270 = load i64, i64* %STACK_DEP_PTR, align 4
  %48271 = getelementptr i256, i256* %STACK, i64 %48270
  %48272 = load i256, i256* %48271, align 4
  %48273 = load i64, i64* %STACK_DEP_PTR, align 4
  %48274 = sub i64 %48273, 1
  store i64 %48274, i64* %STACK_DEP_PTR, align 4
  %48275 = icmp eq i256 %48272, 0
  %48276 = trunc i256 15760 to i64
  %jump.check226 = icmp ne i1 %48275, false
  br i1 %jump.check226, label %.15760, label %.15756, !EVMBB !4

.15756:                                           ; preds = %48263
  %48277 = load i64, i64* %remaing_gas, align 4
  %48278 = icmp ugt i64 16, %48277
  br i1 %48278, label %Abort, label %48279

48279:                                            ; preds = %.15756
  %48280 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48281 = xor i32 %48280, 3496
  %48282 = urem i32 %48281, 4096
  %48283 = getelementptr i8, i8 addrspace(1)* %4, i32 %48282
  %48284 = load i8, i8 addrspace(1)* %48283, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48283, align 1, !nosanitize !3
  store i32 1748, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48285 = sub i64 %48277, 16
  store i64 %48285, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.15760:                                           ; preds = %48263, %JumpTable
  %48286 = load i64, i64* %remaing_gas, align 4
  %48287 = icmp ugt i64 784, %48286
  br i1 %48287, label %Abort, label %48288

48288:                                            ; preds = %.15760
  %48289 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48290 = xor i32 %48289, 3274
  %48291 = urem i32 %48290, 4096
  %48292 = getelementptr i8, i8 addrspace(1)* %4, i32 %48291
  %48293 = load i8, i8 addrspace(1)* %48292, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48292, align 1, !nosanitize !3
  store i32 1637, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48294 = sub i64 %48286, 784
  store i64 %48294, i64* %remaing_gas, align 4
  %48295 = load i64, i64* %STACK_DEP_PTR, align 4
  %48296 = getelementptr i256, i256* %STACK, i64 %48295
  %48297 = load i256, i256* %48296, align 4
  %48298 = load i64, i64* %STACK_DEP_PTR, align 4
  %48299 = sub i64 %48298, 1
  store i64 %48299, i64* %STACK_DEP_PTR, align 4
  %48300 = load i64, i64* %STACK_DEP_PTR, align 4
  %48301 = getelementptr i256, i256* %STACK, i64 %48300
  %48302 = load i256, i256* %48301, align 4
  %48303 = load i64, i64* %STACK_DEP_PTR, align 4
  %48304 = sub i64 %48303, 1
  store i64 %48304, i64* %STACK_DEP_PTR, align 4
  %48305 = load i64, i64* %STACK_DEP_PTR, align 4
  %48306 = getelementptr i256, i256* %STACK, i64 %48305
  %48307 = load i256, i256* %48306, align 4
  %48308 = load i64, i64* %STACK_DEP_PTR, align 4
  %48309 = sub i64 %48308, 1
  store i64 %48309, i64* %STACK_DEP_PTR, align 4
  %48310 = load i64, i64* %STACK_DEP_PTR, align 4
  %48311 = getelementptr i256, i256* %STACK, i64 %48310
  %48312 = load i256, i256* %48311, align 4
  %48313 = load i64, i64* %STACK_DEP_PTR, align 4
  %48314 = sub i64 %48313, 1
  store i64 %48314, i64* %STACK_DEP_PTR, align 4
  %48315 = load i64, i64* %STACK_DEP_PTR, align 4
  %48316 = getelementptr i256, i256* %STACK, i64 %48315
  %48317 = load i256, i256* %48316, align 4
  %48318 = load i64, i64* %STACK_DEP_PTR, align 4
  %48319 = sub i64 %48318, 1
  store i64 %48319, i64* %STACK_DEP_PTR, align 4
  %48320 = add i256 32, %48317, !pc !703, !intsan !10
  %48321 = trunc i256 %48320 to i64
  %48322 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %48321, i256* %48322)
  %48323 = load i256, i256* %48322, align 4
  %48324 = sub i256 %48323, 1, !pc !704, !intsan !8
  %48325 = alloca i256, align 8
  store i256 13, i256* %48325, align 4
  %48326 = alloca i256, align 8
  call void @__device_sload(i256* %48325, i256* %48326)
  %48327 = call i32 @__hashword(i256* %48325)
  %48328 = load i32, i32* %5, align 4
  %48329 = icmp eq i32 %48327, %48328
  %48330 = or i1 false, %48329
  %48331 = load i32, i32* %6, align 4
  %48332 = icmp eq i32 %48327, %48331
  %48333 = or i1 %48330, %48332
  %48334 = load i32, i32* %7, align 4
  %48335 = icmp eq i32 %48327, %48334
  %48336 = or i1 %48333, %48335
  %48337 = load i32, i32* %8, align 4
  %48338 = icmp eq i32 %48327, %48337
  %48339 = or i1 %48336, %48338
  %48340 = load i32, i32* %9, align 4
  %48341 = icmp eq i32 %48327, %48340
  %48342 = or i1 %48339, %48341
  %48343 = load i32, i32* %10, align 4
  %48344 = icmp eq i32 %48327, %48343
  %48345 = or i1 %48342, %48344
  %48346 = load i32, i32* %11, align 4
  %48347 = icmp eq i32 %48327, %48346
  %48348 = or i1 %48345, %48347
  %48349 = load i32, i32* %12, align 4
  %48350 = icmp eq i32 %48327, %48349
  %48351 = or i1 %48348, %48350
  %48352 = load i32, i32* %13, align 4
  %48353 = icmp eq i32 %48327, %48352
  %48354 = or i1 %48351, %48353
  %48355 = load i32, i32* %14, align 4
  %48356 = icmp eq i32 %48327, %48355
  %48357 = or i1 %48354, %48356
  %48358 = load i32, i32* %15, align 4
  %48359 = icmp eq i32 %48327, %48358
  %48360 = or i1 %48357, %48359
  %48361 = load i32, i32* %16, align 4
  %48362 = icmp eq i32 %48327, %48361
  %48363 = or i1 %48360, %48362
  %48364 = load i32, i32* %17, align 4
  %48365 = icmp eq i32 %48327, %48364
  %48366 = or i1 %48363, %48365
  %48367 = load i32, i32* %18, align 4
  %48368 = icmp eq i32 %48327, %48367
  %48369 = or i1 %48366, %48368
  %48370 = load i32, i32* %19, align 4
  %48371 = icmp eq i32 %48327, %48370
  %48372 = or i1 %48369, %48371
  %48373 = load i32, i32* %20, align 4
  %48374 = icmp eq i32 %48327, %48373
  %48375 = or i1 %48372, %48374
  %48376 = load i32, i32* %21, align 4
  %48377 = icmp eq i32 %48327, %48376
  %48378 = or i1 %48375, %48377
  %48379 = load i32, i32* %22, align 4
  %48380 = icmp eq i32 %48327, %48379
  %48381 = or i1 %48378, %48380
  %48382 = load i32, i32* %23, align 4
  %48383 = icmp eq i32 %48327, %48382
  %48384 = or i1 %48381, %48383
  %48385 = load i32, i32* %24, align 4
  %48386 = icmp eq i32 %48327, %48385
  %48387 = or i1 %48384, %48386
  %48388 = load i32, i32* %25, align 4
  %48389 = icmp eq i32 %48327, %48388
  %48390 = or i1 %48387, %48389
  %48391 = load i32, i32* %26, align 4
  %48392 = icmp eq i32 %48327, %48391
  %48393 = or i1 %48390, %48392
  %48394 = load i32, i32* %27, align 4
  %48395 = icmp eq i32 %48327, %48394
  %48396 = or i1 %48393, %48395
  %48397 = load i32, i32* %28, align 4
  %48398 = icmp eq i32 %48327, %48397
  %48399 = or i1 %48396, %48398
  %48400 = load i32, i32* %29, align 4
  %48401 = icmp eq i32 %48327, %48400
  %48402 = or i1 %48399, %48401
  %48403 = load i32, i32* %30, align 4
  %48404 = icmp eq i32 %48327, %48403
  %48405 = or i1 %48402, %48404
  %48406 = load i32, i32* %31, align 4
  %48407 = icmp eq i32 %48327, %48406
  %48408 = or i1 %48405, %48407
  %48409 = load i32, i32* %32, align 4
  %48410 = icmp eq i32 %48327, %48409
  %48411 = or i1 %48408, %48410
  %48412 = load i32, i32* %33, align 4
  %48413 = icmp eq i32 %48327, %48412
  %48414 = or i1 %48411, %48413
  %48415 = load i32, i32* %34, align 4
  %48416 = icmp eq i32 %48327, %48415
  %48417 = or i1 %48414, %48416
  %48418 = load i32, i32* %35, align 4
  %48419 = icmp eq i32 %48327, %48418
  %48420 = or i1 %48417, %48419
  %48421 = load i32, i32* %36, align 4
  %48422 = icmp eq i32 %48327, %48421
  %48423 = or i1 %48420, %48422
  %48424 = load i32, i32* %37, align 4
  %48425 = icmp eq i32 %48327, %48424
  %48426 = or i1 %48423, %48425
  %48427 = load i32, i32* %38, align 4
  %48428 = icmp eq i32 %48327, %48427
  %48429 = or i1 %48426, %48428
  %48430 = load i32, i32* %39, align 4
  %48431 = icmp eq i32 %48327, %48430
  %48432 = or i1 %48429, %48431
  %48433 = load i32, i32* %40, align 4
  %48434 = icmp eq i32 %48327, %48433
  %48435 = or i1 %48432, %48434
  %48436 = load i32, i32* %41, align 4
  %48437 = icmp eq i32 %48327, %48436
  %48438 = or i1 %48435, %48437
  %48439 = load i32, i32* %42, align 4
  %48440 = icmp eq i32 %48327, %48439
  %48441 = or i1 %48438, %48440
  %48442 = load i32, i32* %43, align 4
  %48443 = icmp eq i32 %48327, %48442
  %48444 = or i1 %48441, %48443
  %48445 = load i32, i32* %44, align 4
  %48446 = icmp eq i32 %48327, %48445
  %48447 = or i1 %48444, %48446
  %48448 = load i32, i32* %45, align 4
  %48449 = icmp eq i32 %48327, %48448
  %48450 = or i1 %48447, %48449
  %48451 = load i32, i32* %46, align 4
  %48452 = icmp eq i32 %48327, %48451
  %48453 = or i1 %48450, %48452
  %48454 = load i32, i32* %47, align 4
  %48455 = icmp eq i32 %48327, %48454
  %48456 = or i1 %48453, %48455
  %48457 = load i32, i32* %48, align 4
  %48458 = icmp eq i32 %48327, %48457
  %48459 = or i1 %48456, %48458
  %48460 = load i32, i32* %49, align 4
  %48461 = icmp eq i32 %48327, %48460
  %48462 = or i1 %48459, %48461
  %48463 = load i32, i32* %50, align 4
  %48464 = icmp eq i32 %48327, %48463
  %48465 = or i1 %48462, %48464
  %48466 = load i32, i32* %51, align 4
  %48467 = icmp eq i32 %48327, %48466
  %48468 = or i1 %48465, %48467
  %48469 = load i32, i32* %52, align 4
  %48470 = icmp eq i32 %48327, %48469
  %48471 = or i1 %48468, %48470
  %48472 = load i32, i32* %53, align 4
  %48473 = icmp eq i32 %48327, %48472
  %48474 = or i1 %48471, %48473
  %48475 = load i32, i32* %54, align 4
  %48476 = icmp eq i32 %48327, %48475
  %48477 = or i1 %48474, %48476
  %48478 = load i32, i32* %55, align 4
  %48479 = icmp eq i32 %48327, %48478
  %48480 = or i1 %48477, %48479
  %48481 = load i32, i32* %56, align 4
  %48482 = icmp eq i32 %48327, %48481
  %48483 = or i1 %48480, %48482
  %48484 = load i32, i32* %57, align 4
  %48485 = icmp eq i32 %48327, %48484
  %48486 = or i1 %48483, %48485
  %48487 = load i32, i32* %58, align 4
  %48488 = icmp eq i32 %48327, %48487
  %48489 = or i1 %48486, %48488
  %48490 = load i32, i32* %59, align 4
  %48491 = icmp eq i32 %48327, %48490
  %48492 = or i1 %48489, %48491
  %48493 = load i32, i32* %60, align 4
  %48494 = icmp eq i32 %48327, %48493
  %48495 = or i1 %48492, %48494
  %48496 = load i32, i32* %61, align 4
  %48497 = icmp eq i32 %48327, %48496
  %48498 = or i1 %48495, %48497
  %48499 = load i32, i32* %62, align 4
  %48500 = icmp eq i32 %48327, %48499
  %48501 = or i1 %48498, %48500
  %48502 = getelementptr i8, i8 addrspace(1)* %4, i32 177
  %48503 = zext i1 %48501 to i8
  store i8 %48503, i8 addrspace(1)* %48502, align 1, !nosanitize !3
  %48504 = load i256, i256* %48326, align 4
  %48505 = add i256 %48504, %48324, !pc !705, !intsan !10
  %48506 = sub i256 10000, 90, !pc !706, !intsan !8
  %48507 = add i256 32, %48317, !pc !707, !intsan !10
  %48508 = trunc i256 %48507 to i64
  %48509 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %48508, i256* %48509)
  %48510 = load i256, i256* %48509, align 4
  %48511 = sub i256 %48510, 1, !pc !708, !intsan !8
  %48512 = mul i256 %48511, %48506, !pc !709, !intsan !45
  %48513 = icmp eq i256 10000, 0
  %48514 = icmp eq i1 %48513, false
  %48515 = trunc i256 15801 to i64
  %jump.check227 = icmp ne i1 %48514, false
  %48516 = load i64, i64* %STACK_DEP_PTR, align 4
  %48517 = add i64 %48516, 1
  store i64 %48517, i64* %STACK_DEP_PTR, align 4
  %48518 = load i64, i64* %STACK_DEP_PTR, align 4
  %48519 = getelementptr i256, i256* %STACK, i64 %48518
  store i256 %48317, i256* %48519, align 4
  %48520 = load i64, i64* %STACK_DEP_PTR, align 4
  %48521 = add i64 %48520, 1
  store i64 %48521, i64* %STACK_DEP_PTR, align 4
  %48522 = load i64, i64* %STACK_DEP_PTR, align 4
  %48523 = getelementptr i256, i256* %STACK, i64 %48522
  store i256 %48312, i256* %48523, align 4
  %48524 = load i64, i64* %STACK_DEP_PTR, align 4
  %48525 = add i64 %48524, 1
  store i64 %48525, i64* %STACK_DEP_PTR, align 4
  %48526 = load i64, i64* %STACK_DEP_PTR, align 4
  %48527 = getelementptr i256, i256* %STACK, i64 %48526
  store i256 %48505, i256* %48527, align 4
  %48528 = load i64, i64* %STACK_DEP_PTR, align 4
  %48529 = add i64 %48528, 1
  store i64 %48529, i64* %STACK_DEP_PTR, align 4
  %48530 = load i64, i64* %STACK_DEP_PTR, align 4
  %48531 = getelementptr i256, i256* %STACK, i64 %48530
  store i256 %48302, i256* %48531, align 4
  %48532 = load i64, i64* %STACK_DEP_PTR, align 4
  %48533 = add i64 %48532, 1
  store i64 %48533, i64* %STACK_DEP_PTR, align 4
  %48534 = load i64, i64* %STACK_DEP_PTR, align 4
  %48535 = getelementptr i256, i256* %STACK, i64 %48534
  store i256 %48297, i256* %48535, align 4
  %48536 = load i64, i64* %STACK_DEP_PTR, align 4
  %48537 = add i64 %48536, 1
  store i64 %48537, i64* %STACK_DEP_PTR, align 4
  %48538 = load i64, i64* %STACK_DEP_PTR, align 4
  %48539 = getelementptr i256, i256* %STACK, i64 %48538
  store i256 10000, i256* %48539, align 4
  %48540 = load i64, i64* %STACK_DEP_PTR, align 4
  %48541 = add i64 %48540, 1
  store i64 %48541, i64* %STACK_DEP_PTR, align 4
  %48542 = load i64, i64* %STACK_DEP_PTR, align 4
  %48543 = getelementptr i256, i256* %STACK, i64 %48542
  store i256 %48512, i256* %48543, align 4
  br i1 %jump.check227, label %.15801, label %.15800, !EVMBB !4

.15800:                                           ; preds = %48288
  %48544 = load i64, i64* %remaing_gas, align 4
  %48545 = icmp ugt i64 16, %48544
  br i1 %48545, label %Abort, label %48546

48546:                                            ; preds = %.15800
  %48547 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48548 = xor i32 %48547, 2201
  %48549 = urem i32 %48548, 4096
  %48550 = getelementptr i8, i8 addrspace(1)* %4, i32 %48549
  %48551 = load i8, i8 addrspace(1)* %48550, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48550, align 1, !nosanitize !3
  store i32 1100, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48552 = sub i64 %48544, 16
  store i64 %48552, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.15801:                                           ; preds = %48288, %JumpTable
  %48553 = load i64, i64* %remaing_gas, align 4
  %48554 = icmp ugt i64 848, %48553
  br i1 %48554, label %Abort, label %48555

48555:                                            ; preds = %.15801
  %48556 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48557 = xor i32 %48556, 690
  %48558 = urem i32 %48557, 4096
  %48559 = getelementptr i8, i8 addrspace(1)* %4, i32 %48558
  %48560 = load i8, i8 addrspace(1)* %48559, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %48559, align 1, !nosanitize !3
  store i32 345, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %48561 = sub i64 %48553, 848
  store i64 %48561, i64* %remaing_gas, align 4
  %48562 = load i64, i64* %STACK_DEP_PTR, align 4
  %48563 = getelementptr i256, i256* %STACK, i64 %48562
  %48564 = load i256, i256* %48563, align 4
  %48565 = load i64, i64* %STACK_DEP_PTR, align 4
  %48566 = sub i64 %48565, 1
  store i64 %48566, i64* %STACK_DEP_PTR, align 4
  %48567 = load i64, i64* %STACK_DEP_PTR, align 4
  %48568 = getelementptr i256, i256* %STACK, i64 %48567
  %48569 = load i256, i256* %48568, align 4
  %48570 = load i64, i64* %STACK_DEP_PTR, align 4
  %48571 = sub i64 %48570, 1
  store i64 %48571, i64* %STACK_DEP_PTR, align 4
  %48572 = load i64, i64* %STACK_DEP_PTR, align 4
  %48573 = getelementptr i256, i256* %STACK, i64 %48572
  %48574 = load i256, i256* %48573, align 4
  %48575 = load i64, i64* %STACK_DEP_PTR, align 4
  %48576 = sub i64 %48575, 1
  store i64 %48576, i64* %STACK_DEP_PTR, align 4
  %48577 = load i64, i64* %STACK_DEP_PTR, align 4
  %48578 = getelementptr i256, i256* %STACK, i64 %48577
  %48579 = load i256, i256* %48578, align 4
  %48580 = load i64, i64* %STACK_DEP_PTR, align 4
  %48581 = sub i64 %48580, 1
  store i64 %48581, i64* %STACK_DEP_PTR, align 4
  %48582 = load i64, i64* %STACK_DEP_PTR, align 4
  %48583 = getelementptr i256, i256* %STACK, i64 %48582
  %48584 = load i256, i256* %48583, align 4
  %48585 = load i64, i64* %STACK_DEP_PTR, align 4
  %48586 = sub i64 %48585, 1
  store i64 %48586, i64* %STACK_DEP_PTR, align 4
  %48587 = alloca i256, align 8
  store i256 %48564, i256* %48587, align 4
  %48588 = alloca i256, align 8
  store i256 %48569, i256* %48588, align 4
  %48589 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %48587, i256* %48588, i256* %48589), !pc !710, !intsan !6
  %48590 = load i256, i256* %48589, align 4
  %48591 = alloca i256, align 8
  store i256 13, i256* %48591, align 4
  %48592 = alloca i256, align 8
  call void @__device_sload(i256* %48591, i256* %48592)
  %48593 = call i32 @__hashword(i256* %48591)
  %48594 = load i32, i32* %5, align 4
  %48595 = icmp eq i32 %48593, %48594
  %48596 = or i1 false, %48595
  %48597 = load i32, i32* %6, align 4
  %48598 = icmp eq i32 %48593, %48597
  %48599 = or i1 %48596, %48598
  %48600 = load i32, i32* %7, align 4
  %48601 = icmp eq i32 %48593, %48600
  %48602 = or i1 %48599, %48601
  %48603 = load i32, i32* %8, align 4
  %48604 = icmp eq i32 %48593, %48603
  %48605 = or i1 %48602, %48604
  %48606 = load i32, i32* %9, align 4
  %48607 = icmp eq i32 %48593, %48606
  %48608 = or i1 %48605, %48607
  %48609 = load i32, i32* %10, align 4
  %48610 = icmp eq i32 %48593, %48609
  %48611 = or i1 %48608, %48610
  %48612 = load i32, i32* %11, align 4
  %48613 = icmp eq i32 %48593, %48612
  %48614 = or i1 %48611, %48613
  %48615 = load i32, i32* %12, align 4
  %48616 = icmp eq i32 %48593, %48615
  %48617 = or i1 %48614, %48616
  %48618 = load i32, i32* %13, align 4
  %48619 = icmp eq i32 %48593, %48618
  %48620 = or i1 %48617, %48619
  %48621 = load i32, i32* %14, align 4
  %48622 = icmp eq i32 %48593, %48621
  %48623 = or i1 %48620, %48622
  %48624 = load i32, i32* %15, align 4
  %48625 = icmp eq i32 %48593, %48624
  %48626 = or i1 %48623, %48625
  %48627 = load i32, i32* %16, align 4
  %48628 = icmp eq i32 %48593, %48627
  %48629 = or i1 %48626, %48628
  %48630 = load i32, i32* %17, align 4
  %48631 = icmp eq i32 %48593, %48630
  %48632 = or i1 %48629, %48631
  %48633 = load i32, i32* %18, align 4
  %48634 = icmp eq i32 %48593, %48633
  %48635 = or i1 %48632, %48634
  %48636 = load i32, i32* %19, align 4
  %48637 = icmp eq i32 %48593, %48636
  %48638 = or i1 %48635, %48637
  %48639 = load i32, i32* %20, align 4
  %48640 = icmp eq i32 %48593, %48639
  %48641 = or i1 %48638, %48640
  %48642 = load i32, i32* %21, align 4
  %48643 = icmp eq i32 %48593, %48642
  %48644 = or i1 %48641, %48643
  %48645 = load i32, i32* %22, align 4
  %48646 = icmp eq i32 %48593, %48645
  %48647 = or i1 %48644, %48646
  %48648 = load i32, i32* %23, align 4
  %48649 = icmp eq i32 %48593, %48648
  %48650 = or i1 %48647, %48649
  %48651 = load i32, i32* %24, align 4
  %48652 = icmp eq i32 %48593, %48651
  %48653 = or i1 %48650, %48652
  %48654 = load i32, i32* %25, align 4
  %48655 = icmp eq i32 %48593, %48654
  %48656 = or i1 %48653, %48655
  %48657 = load i32, i32* %26, align 4
  %48658 = icmp eq i32 %48593, %48657
  %48659 = or i1 %48656, %48658
  %48660 = load i32, i32* %27, align 4
  %48661 = icmp eq i32 %48593, %48660
  %48662 = or i1 %48659, %48661
  %48663 = load i32, i32* %28, align 4
  %48664 = icmp eq i32 %48593, %48663
  %48665 = or i1 %48662, %48664
  %48666 = load i32, i32* %29, align 4
  %48667 = icmp eq i32 %48593, %48666
  %48668 = or i1 %48665, %48667
  %48669 = load i32, i32* %30, align 4
  %48670 = icmp eq i32 %48593, %48669
  %48671 = or i1 %48668, %48670
  %48672 = load i32, i32* %31, align 4
  %48673 = icmp eq i32 %48593, %48672
  %48674 = or i1 %48671, %48673
  %48675 = load i32, i32* %32, align 4
  %48676 = icmp eq i32 %48593, %48675
  %48677 = or i1 %48674, %48676
  %48678 = load i32, i32* %33, align 4
  %48679 = icmp eq i32 %48593, %48678
  %48680 = or i1 %48677, %48679
  %48681 = load i32, i32* %34, align 4
  %48682 = icmp eq i32 %48593, %48681
  %48683 = or i1 %48680, %48682
  %48684 = load i32, i32* %35, align 4
  %48685 = icmp eq i32 %48593, %48684
  %48686 = or i1 %48683, %48685
  %48687 = load i32, i32* %36, align 4
  %48688 = icmp eq i32 %48593, %48687
  %48689 = or i1 %48686, %48688
  %48690 = load i32, i32* %37, align 4
  %48691 = icmp eq i32 %48593, %48690
  %48692 = or i1 %48689, %48691
  %48693 = load i32, i32* %38, align 4
  %48694 = icmp eq i32 %48593, %48693
  %48695 = or i1 %48692, %48694
  %48696 = load i32, i32* %39, align 4
  %48697 = icmp eq i32 %48593, %48696
  %48698 = or i1 %48695, %48697
  %48699 = load i32, i32* %40, align 4
  %48700 = icmp eq i32 %48593, %48699
  %48701 = or i1 %48698, %48700
  %48702 = load i32, i32* %41, align 4
  %48703 = icmp eq i32 %48593, %48702
  %48704 = or i1 %48701, %48703
  %48705 = load i32, i32* %42, align 4
  %48706 = icmp eq i32 %48593, %48705
  %48707 = or i1 %48704, %48706
  %48708 = load i32, i32* %43, align 4
  %48709 = icmp eq i32 %48593, %48708
  %48710 = or i1 %48707, %48709
  %48711 = load i32, i32* %44, align 4
  %48712 = icmp eq i32 %48593, %48711
  %48713 = or i1 %48710, %48712
  %48714 = load i32, i32* %45, align 4
  %48715 = icmp eq i32 %48593, %48714
  %48716 = or i1 %48713, %48715
  %48717 = load i32, i32* %46, align 4
  %48718 = icmp eq i32 %48593, %48717
  %48719 = or i1 %48716, %48718
  %48720 = load i32, i32* %47, align 4
  %48721 = icmp eq i32 %48593, %48720
  %48722 = or i1 %48719, %48721
  %48723 = load i32, i32* %48, align 4
  %48724 = icmp eq i32 %48593, %48723
  %48725 = or i1 %48722, %48724
  %48726 = load i32, i32* %49, align 4
  %48727 = icmp eq i32 %48593, %48726
  %48728 = or i1 %48725, %48727
  %48729 = load i32, i32* %50, align 4
  %48730 = icmp eq i32 %48593, %48729
  %48731 = or i1 %48728, %48730
  %48732 = load i32, i32* %51, align 4
  %48733 = icmp eq i32 %48593, %48732
  %48734 = or i1 %48731, %48733
  %48735 = load i32, i32* %52, align 4
  %48736 = icmp eq i32 %48593, %48735
  %48737 = or i1 %48734, %48736
  %48738 = load i32, i32* %53, align 4
  %48739 = icmp eq i32 %48593, %48738
  %48740 = or i1 %48737, %48739
  %48741 = load i32, i32* %54, align 4
  %48742 = icmp eq i32 %48593, %48741
  %48743 = or i1 %48740, %48742
  %48744 = load i32, i32* %55, align 4
  %48745 = icmp eq i32 %48593, %48744
  %48746 = or i1 %48743, %48745
  %48747 = load i32, i32* %56, align 4
  %48748 = icmp eq i32 %48593, %48747
  %48749 = or i1 %48746, %48748
  %48750 = load i32, i32* %57, align 4
  %48751 = icmp eq i32 %48593, %48750
  %48752 = or i1 %48749, %48751
  %48753 = load i32, i32* %58, align 4
  %48754 = icmp eq i32 %48593, %48753
  %48755 = or i1 %48752, %48754
  %48756 = load i32, i32* %59, align 4
  %48757 = icmp eq i32 %48593, %48756
  %48758 = or i1 %48755, %48757
  %48759 = load i32, i32* %60, align 4
  %48760 = icmp eq i32 %48593, %48759
  %48761 = or i1 %48758, %48760
  %48762 = load i32, i32* %61, align 4
  %48763 = icmp eq i32 %48593, %48762
  %48764 = or i1 %48761, %48763
  %48765 = load i32, i32* %62, align 4
  %48766 = icmp eq i32 %48593, %48765
  %48767 = or i1 %48764, %48766
  %48768 = getelementptr i8, i8 addrspace(1)* %4, i32 178
  %48769 = zext i1 %48767 to i8
  store i8 %48769, i8 addrspace(1)* %48768, align 1, !nosanitize !3
  %48770 = load i256, i256* %48592, align 4
  %48771 = add i256 %48770, %48590, !pc !711, !intsan !10
  %48772 = alloca i256, align 8
  store i256 13, i256* %48772, align 4
  %48773 = alloca i256, align 8
  store i256 %48771, i256* %48773, align 4
  call void @__device_sstore(i256* %48772, i256* %48773)
  %48774 = call i32 @__hashword(i256* %48772)
  store i32 %48774, i32* %49, align 4, !nosanitize !3
  %48775 = alloca i256, align 8
  store i256 13, i256* %48775, align 4
  %48776 = alloca i256, align 8
  call void @__device_sload(i256* %48775, i256* %48776)
  %48777 = call i32 @__hashword(i256* %48775)
  %48778 = load i32, i32* %5, align 4
  %48779 = icmp eq i32 %48777, %48778
  %48780 = or i1 false, %48779
  %48781 = load i32, i32* %6, align 4
  %48782 = icmp eq i32 %48777, %48781
  %48783 = or i1 %48780, %48782
  %48784 = load i32, i32* %7, align 4
  %48785 = icmp eq i32 %48777, %48784
  %48786 = or i1 %48783, %48785
  %48787 = load i32, i32* %8, align 4
  %48788 = icmp eq i32 %48777, %48787
  %48789 = or i1 %48786, %48788
  %48790 = load i32, i32* %9, align 4
  %48791 = icmp eq i32 %48777, %48790
  %48792 = or i1 %48789, %48791
  %48793 = load i32, i32* %10, align 4
  %48794 = icmp eq i32 %48777, %48793
  %48795 = or i1 %48792, %48794
  %48796 = load i32, i32* %11, align 4
  %48797 = icmp eq i32 %48777, %48796
  %48798 = or i1 %48795, %48797
  %48799 = load i32, i32* %12, align 4
  %48800 = icmp eq i32 %48777, %48799
  %48801 = or i1 %48798, %48800
  %48802 = load i32, i32* %13, align 4
  %48803 = icmp eq i32 %48777, %48802
  %48804 = or i1 %48801, %48803
  %48805 = load i32, i32* %14, align 4
  %48806 = icmp eq i32 %48777, %48805
  %48807 = or i1 %48804, %48806
  %48808 = load i32, i32* %15, align 4
  %48809 = icmp eq i32 %48777, %48808
  %48810 = or i1 %48807, %48809
  %48811 = load i32, i32* %16, align 4
  %48812 = icmp eq i32 %48777, %48811
  %48813 = or i1 %48810, %48812
  %48814 = load i32, i32* %17, align 4
  %48815 = icmp eq i32 %48777, %48814
  %48816 = or i1 %48813, %48815
  %48817 = load i32, i32* %18, align 4
  %48818 = icmp eq i32 %48777, %48817
  %48819 = or i1 %48816, %48818
  %48820 = load i32, i32* %19, align 4
  %48821 = icmp eq i32 %48777, %48820
  %48822 = or i1 %48819, %48821
  %48823 = load i32, i32* %20, align 4
  %48824 = icmp eq i32 %48777, %48823
  %48825 = or i1 %48822, %48824
  %48826 = load i32, i32* %21, align 4
  %48827 = icmp eq i32 %48777, %48826
  %48828 = or i1 %48825, %48827
  %48829 = load i32, i32* %22, align 4
  %48830 = icmp eq i32 %48777, %48829
  %48831 = or i1 %48828, %48830
  %48832 = load i32, i32* %23, align 4
  %48833 = icmp eq i32 %48777, %48832
  %48834 = or i1 %48831, %48833
  %48835 = load i32, i32* %24, align 4
  %48836 = icmp eq i32 %48777, %48835
  %48837 = or i1 %48834, %48836
  %48838 = load i32, i32* %25, align 4
  %48839 = icmp eq i32 %48777, %48838
  %48840 = or i1 %48837, %48839
  %48841 = load i32, i32* %26, align 4
  %48842 = icmp eq i32 %48777, %48841
  %48843 = or i1 %48840, %48842
  %48844 = load i32, i32* %27, align 4
  %48845 = icmp eq i32 %48777, %48844
  %48846 = or i1 %48843, %48845
  %48847 = load i32, i32* %28, align 4
  %48848 = icmp eq i32 %48777, %48847
  %48849 = or i1 %48846, %48848
  %48850 = load i32, i32* %29, align 4
  %48851 = icmp eq i32 %48777, %48850
  %48852 = or i1 %48849, %48851
  %48853 = load i32, i32* %30, align 4
  %48854 = icmp eq i32 %48777, %48853
  %48855 = or i1 %48852, %48854
  %48856 = load i32, i32* %31, align 4
  %48857 = icmp eq i32 %48777, %48856
  %48858 = or i1 %48855, %48857
  %48859 = load i32, i32* %32, align 4
  %48860 = icmp eq i32 %48777, %48859
  %48861 = or i1 %48858, %48860
  %48862 = load i32, i32* %33, align 4
  %48863 = icmp eq i32 %48777, %48862
  %48864 = or i1 %48861, %48863
  %48865 = load i32, i32* %34, align 4
  %48866 = icmp eq i32 %48777, %48865
  %48867 = or i1 %48864, %48866
  %48868 = load i32, i32* %35, align 4
  %48869 = icmp eq i32 %48777, %48868
  %48870 = or i1 %48867, %48869
  %48871 = load i32, i32* %36, align 4
  %48872 = icmp eq i32 %48777, %48871
  %48873 = or i1 %48870, %48872
  %48874 = load i32, i32* %37, align 4
  %48875 = icmp eq i32 %48777, %48874
  %48876 = or i1 %48873, %48875
  %48877 = load i32, i32* %38, align 4
  %48878 = icmp eq i32 %48777, %48877
  %48879 = or i1 %48876, %48878
  %48880 = load i32, i32* %39, align 4
  %48881 = icmp eq i32 %48777, %48880
  %48882 = or i1 %48879, %48881
  %48883 = load i32, i32* %40, align 4
  %48884 = icmp eq i32 %48777, %48883
  %48885 = or i1 %48882, %48884
  %48886 = load i32, i32* %41, align 4
  %48887 = icmp eq i32 %48777, %48886
  %48888 = or i1 %48885, %48887
  %48889 = load i32, i32* %42, align 4
  %48890 = icmp eq i32 %48777, %48889
  %48891 = or i1 %48888, %48890
  %48892 = load i32, i32* %43, align 4
  %48893 = icmp eq i32 %48777, %48892
  %48894 = or i1 %48891, %48893
  %48895 = load i32, i32* %44, align 4
  %48896 = icmp eq i32 %48777, %48895
  %48897 = or i1 %48894, %48896
  %48898 = load i32, i32* %45, align 4
  %48899 = icmp eq i32 %48777, %48898
  %48900 = or i1 %48897, %48899
  %48901 = load i32, i32* %46, align 4
  %48902 = icmp eq i32 %48777, %48901
  %48903 = or i1 %48900, %48902
  %48904 = load i32, i32* %47, align 4
  %48905 = icmp eq i32 %48777, %48904
  %48906 = or i1 %48903, %48905
  %48907 = load i32, i32* %48, align 4
  %48908 = icmp eq i32 %48777, %48907
  %48909 = or i1 %48906, %48908
  %48910 = load i32, i32* %49, align 4
  %48911 = icmp eq i32 %48777, %48910
  %48912 = or i1 %48909, %48911
  %48913 = load i32, i32* %50, align 4
  %48914 = icmp eq i32 %48777, %48913
  %48915 = or i1 %48912, %48914
  %48916 = load i32, i32* %51, align 4
  %48917 = icmp eq i32 %48777, %48916
  %48918 = or i1 %48915, %48917
  %48919 = load i32, i32* %52, align 4
  %48920 = icmp eq i32 %48777, %48919
  %48921 = or i1 %48918, %48920
  %48922 = load i32, i32* %53, align 4
  %48923 = icmp eq i32 %48777, %48922
  %48924 = or i1 %48921, %48923
  %48925 = load i32, i32* %54, align 4
  %48926 = icmp eq i32 %48777, %48925
  %48927 = or i1 %48924, %48926
  %48928 = load i32, i32* %55, align 4
  %48929 = icmp eq i32 %48777, %48928
  %48930 = or i1 %48927, %48929
  %48931 = load i32, i32* %56, align 4
  %48932 = icmp eq i32 %48777, %48931
  %48933 = or i1 %48930, %48932
  %48934 = load i32, i32* %57, align 4
  %48935 = icmp eq i32 %48777, %48934
  %48936 = or i1 %48933, %48935
  %48937 = load i32, i32* %58, align 4
  %48938 = icmp eq i32 %48777, %48937
  %48939 = or i1 %48936, %48938
  %48940 = load i32, i32* %59, align 4
  %48941 = icmp eq i32 %48777, %48940
  %48942 = or i1 %48939, %48941
  %48943 = load i32, i32* %60, align 4
  %48944 = icmp eq i32 %48777, %48943
  %48945 = or i1 %48942, %48944
  %48946 = load i32, i32* %61, align 4
  %48947 = icmp eq i32 %48777, %48946
  %48948 = or i1 %48945, %48947
  %48949 = load i32, i32* %62, align 4
  %48950 = icmp eq i32 %48777, %48949
  %48951 = or i1 %48948, %48950
  %48952 = getelementptr i8, i8 addrspace(1)* %4, i32 179
  %48953 = zext i1 %48951 to i8
  store i8 %48953, i8 addrspace(1)* %48952, align 1, !nosanitize !3
  %48954 = load i256, i256* %48776, align 4
  %48955 = sub i256 %48584, %48954, !pc !712, !intsan !8
  %48956 = alloca i256, align 8
  store i256 8, i256* %48956, align 4
  %48957 = alloca i256, align 8
  call void @__device_sload(i256* %48956, i256* %48957)
  %48958 = call i32 @__hashword(i256* %48956)
  %48959 = load i32, i32* %5, align 4
  %48960 = icmp eq i32 %48958, %48959
  %48961 = or i1 false, %48960
  %48962 = load i32, i32* %6, align 4
  %48963 = icmp eq i32 %48958, %48962
  %48964 = or i1 %48961, %48963
  %48965 = load i32, i32* %7, align 4
  %48966 = icmp eq i32 %48958, %48965
  %48967 = or i1 %48964, %48966
  %48968 = load i32, i32* %8, align 4
  %48969 = icmp eq i32 %48958, %48968
  %48970 = or i1 %48967, %48969
  %48971 = load i32, i32* %9, align 4
  %48972 = icmp eq i32 %48958, %48971
  %48973 = or i1 %48970, %48972
  %48974 = load i32, i32* %10, align 4
  %48975 = icmp eq i32 %48958, %48974
  %48976 = or i1 %48973, %48975
  %48977 = load i32, i32* %11, align 4
  %48978 = icmp eq i32 %48958, %48977
  %48979 = or i1 %48976, %48978
  %48980 = load i32, i32* %12, align 4
  %48981 = icmp eq i32 %48958, %48980
  %48982 = or i1 %48979, %48981
  %48983 = load i32, i32* %13, align 4
  %48984 = icmp eq i32 %48958, %48983
  %48985 = or i1 %48982, %48984
  %48986 = load i32, i32* %14, align 4
  %48987 = icmp eq i32 %48958, %48986
  %48988 = or i1 %48985, %48987
  %48989 = load i32, i32* %15, align 4
  %48990 = icmp eq i32 %48958, %48989
  %48991 = or i1 %48988, %48990
  %48992 = load i32, i32* %16, align 4
  %48993 = icmp eq i32 %48958, %48992
  %48994 = or i1 %48991, %48993
  %48995 = load i32, i32* %17, align 4
  %48996 = icmp eq i32 %48958, %48995
  %48997 = or i1 %48994, %48996
  %48998 = load i32, i32* %18, align 4
  %48999 = icmp eq i32 %48958, %48998
  %49000 = or i1 %48997, %48999
  %49001 = load i32, i32* %19, align 4
  %49002 = icmp eq i32 %48958, %49001
  %49003 = or i1 %49000, %49002
  %49004 = load i32, i32* %20, align 4
  %49005 = icmp eq i32 %48958, %49004
  %49006 = or i1 %49003, %49005
  %49007 = load i32, i32* %21, align 4
  %49008 = icmp eq i32 %48958, %49007
  %49009 = or i1 %49006, %49008
  %49010 = load i32, i32* %22, align 4
  %49011 = icmp eq i32 %48958, %49010
  %49012 = or i1 %49009, %49011
  %49013 = load i32, i32* %23, align 4
  %49014 = icmp eq i32 %48958, %49013
  %49015 = or i1 %49012, %49014
  %49016 = load i32, i32* %24, align 4
  %49017 = icmp eq i32 %48958, %49016
  %49018 = or i1 %49015, %49017
  %49019 = load i32, i32* %25, align 4
  %49020 = icmp eq i32 %48958, %49019
  %49021 = or i1 %49018, %49020
  %49022 = load i32, i32* %26, align 4
  %49023 = icmp eq i32 %48958, %49022
  %49024 = or i1 %49021, %49023
  %49025 = load i32, i32* %27, align 4
  %49026 = icmp eq i32 %48958, %49025
  %49027 = or i1 %49024, %49026
  %49028 = load i32, i32* %28, align 4
  %49029 = icmp eq i32 %48958, %49028
  %49030 = or i1 %49027, %49029
  %49031 = load i32, i32* %29, align 4
  %49032 = icmp eq i32 %48958, %49031
  %49033 = or i1 %49030, %49032
  %49034 = load i32, i32* %30, align 4
  %49035 = icmp eq i32 %48958, %49034
  %49036 = or i1 %49033, %49035
  %49037 = load i32, i32* %31, align 4
  %49038 = icmp eq i32 %48958, %49037
  %49039 = or i1 %49036, %49038
  %49040 = load i32, i32* %32, align 4
  %49041 = icmp eq i32 %48958, %49040
  %49042 = or i1 %49039, %49041
  %49043 = load i32, i32* %33, align 4
  %49044 = icmp eq i32 %48958, %49043
  %49045 = or i1 %49042, %49044
  %49046 = load i32, i32* %34, align 4
  %49047 = icmp eq i32 %48958, %49046
  %49048 = or i1 %49045, %49047
  %49049 = load i32, i32* %35, align 4
  %49050 = icmp eq i32 %48958, %49049
  %49051 = or i1 %49048, %49050
  %49052 = load i32, i32* %36, align 4
  %49053 = icmp eq i32 %48958, %49052
  %49054 = or i1 %49051, %49053
  %49055 = load i32, i32* %37, align 4
  %49056 = icmp eq i32 %48958, %49055
  %49057 = or i1 %49054, %49056
  %49058 = load i32, i32* %38, align 4
  %49059 = icmp eq i32 %48958, %49058
  %49060 = or i1 %49057, %49059
  %49061 = load i32, i32* %39, align 4
  %49062 = icmp eq i32 %48958, %49061
  %49063 = or i1 %49060, %49062
  %49064 = load i32, i32* %40, align 4
  %49065 = icmp eq i32 %48958, %49064
  %49066 = or i1 %49063, %49065
  %49067 = load i32, i32* %41, align 4
  %49068 = icmp eq i32 %48958, %49067
  %49069 = or i1 %49066, %49068
  %49070 = load i32, i32* %42, align 4
  %49071 = icmp eq i32 %48958, %49070
  %49072 = or i1 %49069, %49071
  %49073 = load i32, i32* %43, align 4
  %49074 = icmp eq i32 %48958, %49073
  %49075 = or i1 %49072, %49074
  %49076 = load i32, i32* %44, align 4
  %49077 = icmp eq i32 %48958, %49076
  %49078 = or i1 %49075, %49077
  %49079 = load i32, i32* %45, align 4
  %49080 = icmp eq i32 %48958, %49079
  %49081 = or i1 %49078, %49080
  %49082 = load i32, i32* %46, align 4
  %49083 = icmp eq i32 %48958, %49082
  %49084 = or i1 %49081, %49083
  %49085 = load i32, i32* %47, align 4
  %49086 = icmp eq i32 %48958, %49085
  %49087 = or i1 %49084, %49086
  %49088 = load i32, i32* %48, align 4
  %49089 = icmp eq i32 %48958, %49088
  %49090 = or i1 %49087, %49089
  %49091 = load i32, i32* %49, align 4
  %49092 = icmp eq i32 %48958, %49091
  %49093 = or i1 %49090, %49092
  %49094 = load i32, i32* %50, align 4
  %49095 = icmp eq i32 %48958, %49094
  %49096 = or i1 %49093, %49095
  %49097 = load i32, i32* %51, align 4
  %49098 = icmp eq i32 %48958, %49097
  %49099 = or i1 %49096, %49098
  %49100 = load i32, i32* %52, align 4
  %49101 = icmp eq i32 %48958, %49100
  %49102 = or i1 %49099, %49101
  %49103 = load i32, i32* %53, align 4
  %49104 = icmp eq i32 %48958, %49103
  %49105 = or i1 %49102, %49104
  %49106 = load i32, i32* %54, align 4
  %49107 = icmp eq i32 %48958, %49106
  %49108 = or i1 %49105, %49107
  %49109 = load i32, i32* %55, align 4
  %49110 = icmp eq i32 %48958, %49109
  %49111 = or i1 %49108, %49110
  %49112 = load i32, i32* %56, align 4
  %49113 = icmp eq i32 %48958, %49112
  %49114 = or i1 %49111, %49113
  %49115 = load i32, i32* %57, align 4
  %49116 = icmp eq i32 %48958, %49115
  %49117 = or i1 %49114, %49116
  %49118 = load i32, i32* %58, align 4
  %49119 = icmp eq i32 %48958, %49118
  %49120 = or i1 %49117, %49119
  %49121 = load i32, i32* %59, align 4
  %49122 = icmp eq i32 %48958, %49121
  %49123 = or i1 %49120, %49122
  %49124 = load i32, i32* %60, align 4
  %49125 = icmp eq i32 %48958, %49124
  %49126 = or i1 %49123, %49125
  %49127 = load i32, i32* %61, align 4
  %49128 = icmp eq i32 %48958, %49127
  %49129 = or i1 %49126, %49128
  %49130 = load i32, i32* %62, align 4
  %49131 = icmp eq i32 %48958, %49130
  %49132 = or i1 %49129, %49131
  %49133 = getelementptr i8, i8 addrspace(1)* %4, i32 180
  %49134 = zext i1 %49132 to i8
  store i8 %49134, i8 addrspace(1)* %49133, align 1, !nosanitize !3
  %49135 = load i256, i256* %48957, align 4
  %49136 = alloca i256, align 8
  store i256 %49135, i256* %49136, align 4
  %49137 = alloca i256, align 8
  store i256 1, i256* %49137, align 4
  %49138 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %49136, i256* %49137, i256* %49138), !pc !713, !intsan !6
  %49139 = load i256, i256* %49138, align 4
  %49140 = and i256 1461501637330902918203684832716283019655932542975, %49139
  %49141 = trunc i256 14584 to i64
  %49142 = load i64, i64* %STACK_DEP_PTR, align 4
  %49143 = add i64 %49142, 1
  store i64 %49143, i64* %STACK_DEP_PTR, align 4
  %49144 = load i64, i64* %STACK_DEP_PTR, align 4
  %49145 = getelementptr i256, i256* %STACK, i64 %49144
  store i256 %48584, i256* %49145, align 4
  %49146 = load i64, i64* %STACK_DEP_PTR, align 4
  %49147 = add i64 %49146, 1
  store i64 %49147, i64* %STACK_DEP_PTR, align 4
  %49148 = load i64, i64* %STACK_DEP_PTR, align 4
  %49149 = getelementptr i256, i256* %STACK, i64 %49148
  store i256 %48955, i256* %49149, align 4
  %49150 = load i64, i64* %STACK_DEP_PTR, align 4
  %49151 = add i64 %49150, 1
  store i64 %49151, i64* %STACK_DEP_PTR, align 4
  %49152 = load i64, i64* %STACK_DEP_PTR, align 4
  %49153 = getelementptr i256, i256* %STACK, i64 %49152
  store i256 %48574, i256* %49153, align 4
  %49154 = load i64, i64* %STACK_DEP_PTR, align 4
  %49155 = add i64 %49154, 1
  store i64 %49155, i64* %STACK_DEP_PTR, align 4
  %49156 = load i64, i64* %STACK_DEP_PTR, align 4
  %49157 = getelementptr i256, i256* %STACK, i64 %49156
  store i256 15868, i256* %49157, align 4
  %49158 = load i64, i64* %STACK_DEP_PTR, align 4
  %49159 = add i64 %49158, 1
  store i64 %49159, i64* %STACK_DEP_PTR, align 4
  %49160 = load i64, i64* %STACK_DEP_PTR, align 4
  %49161 = getelementptr i256, i256* %STACK, i64 %49160
  store i256 %49140, i256* %49161, align 4
  %49162 = load i64, i64* %STACK_DEP_PTR, align 4
  %49163 = add i64 %49162, 1
  store i64 %49163, i64* %STACK_DEP_PTR, align 4
  %49164 = load i64, i64* %STACK_DEP_PTR, align 4
  %49165 = getelementptr i256, i256* %STACK, i64 %49164
  store i256 %48955, i256* %49165, align 4
  br label %.14584, !EVMBB !4

.15868:                                           ; preds = %JumpTable
  br label %.15869

.15869:                                           ; preds = %.15868, %47385, %JumpTable
  %49166 = load i64, i64* %remaing_gas, align 4
  %49167 = icmp ugt i64 320, %49166
  br i1 %49167, label %Abort, label %49168

49168:                                            ; preds = %.15869
  %49169 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49170 = xor i32 %49169, 1218
  %49171 = urem i32 %49170, 4096
  %49172 = getelementptr i8, i8 addrspace(1)* %4, i32 %49171
  %49173 = load i8, i8 addrspace(1)* %49172, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49172, align 1, !nosanitize !3
  store i32 609, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49174 = sub i64 %49166, 320
  store i64 %49174, i64* %remaing_gas, align 4
  %49175 = load i64, i64* %STACK_DEP_PTR, align 4
  %49176 = getelementptr i256, i256* %STACK, i64 %49175
  %49177 = load i256, i256* %49176, align 4
  %49178 = load i64, i64* %STACK_DEP_PTR, align 4
  %49179 = sub i64 %49178, 1
  store i64 %49179, i64* %STACK_DEP_PTR, align 4
  %49180 = load i64, i64* %STACK_DEP_PTR, align 4
  %49181 = getelementptr i256, i256* %STACK, i64 %49180
  %49182 = load i256, i256* %49181, align 4
  %49183 = load i64, i64* %STACK_DEP_PTR, align 4
  %49184 = sub i64 %49183, 1
  store i64 %49184, i64* %STACK_DEP_PTR, align 4
  %49185 = load i64, i64* %STACK_DEP_PTR, align 4
  %49186 = getelementptr i256, i256* %STACK, i64 %49185
  %49187 = load i256, i256* %49186, align 4
  %49188 = load i64, i64* %STACK_DEP_PTR, align 4
  %49189 = sub i64 %49188, 1
  store i64 %49189, i64* %STACK_DEP_PTR, align 4
  %49190 = load i64, i64* %STACK_DEP_PTR, align 4
  %49191 = getelementptr i256, i256* %STACK, i64 %49190
  %49192 = load i256, i256* %49191, align 4
  %49193 = load i64, i64* %STACK_DEP_PTR, align 4
  %49194 = sub i64 %49193, 1
  store i64 %49194, i64* %STACK_DEP_PTR, align 4
  %49195 = load i64, i64* %STACK_DEP_PTR, align 4
  %49196 = getelementptr i256, i256* %STACK, i64 %49195
  %49197 = load i256, i256* %49196, align 4
  %49198 = load i64, i64* %STACK_DEP_PTR, align 4
  %49199 = sub i64 %49198, 1
  store i64 %49199, i64* %STACK_DEP_PTR, align 4
  %49200 = load i64, i64* %STACK_DEP_PTR, align 4
  %49201 = getelementptr i256, i256* %STACK, i64 %49200
  %49202 = load i256, i256* %49201, align 4
  %49203 = load i64, i64* %STACK_DEP_PTR, align 4
  %49204 = sub i64 %49203, 1
  store i64 %49204, i64* %STACK_DEP_PTR, align 4
  %49205 = trunc i256 %49202 to i64
  store i64 %49205, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.15876:                                           ; preds = %22620, %JumpTable
  %49206 = load i64, i64* %remaing_gas, align 4
  %49207 = icmp ugt i64 160, %49206
  br i1 %49207, label %Abort, label %49208

49208:                                            ; preds = %.15876
  %49209 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49210 = xor i32 %49209, 311
  %49211 = urem i32 %49210, 4096
  %49212 = getelementptr i8, i8 addrspace(1)* %4, i32 %49211
  %49213 = load i8, i8 addrspace(1)* %49212, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49212, align 1, !nosanitize !3
  store i32 155, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49214 = sub i64 %49206, 160
  store i64 %49214, i64* %remaing_gas, align 4
  %49215 = alloca i256, align 8
  store i256 0, i256* %49215, align 4
  %49216 = alloca i256, align 8
  call void @__device_sload(i256* %49215, i256* %49216)
  %49217 = call i32 @__hashword(i256* %49215)
  %49218 = load i32, i32* %5, align 4
  %49219 = icmp eq i32 %49217, %49218
  %49220 = or i1 false, %49219
  %49221 = load i32, i32* %6, align 4
  %49222 = icmp eq i32 %49217, %49221
  %49223 = or i1 %49220, %49222
  %49224 = load i32, i32* %7, align 4
  %49225 = icmp eq i32 %49217, %49224
  %49226 = or i1 %49223, %49225
  %49227 = load i32, i32* %8, align 4
  %49228 = icmp eq i32 %49217, %49227
  %49229 = or i1 %49226, %49228
  %49230 = load i32, i32* %9, align 4
  %49231 = icmp eq i32 %49217, %49230
  %49232 = or i1 %49229, %49231
  %49233 = load i32, i32* %10, align 4
  %49234 = icmp eq i32 %49217, %49233
  %49235 = or i1 %49232, %49234
  %49236 = load i32, i32* %11, align 4
  %49237 = icmp eq i32 %49217, %49236
  %49238 = or i1 %49235, %49237
  %49239 = load i32, i32* %12, align 4
  %49240 = icmp eq i32 %49217, %49239
  %49241 = or i1 %49238, %49240
  %49242 = load i32, i32* %13, align 4
  %49243 = icmp eq i32 %49217, %49242
  %49244 = or i1 %49241, %49243
  %49245 = load i32, i32* %14, align 4
  %49246 = icmp eq i32 %49217, %49245
  %49247 = or i1 %49244, %49246
  %49248 = load i32, i32* %15, align 4
  %49249 = icmp eq i32 %49217, %49248
  %49250 = or i1 %49247, %49249
  %49251 = load i32, i32* %16, align 4
  %49252 = icmp eq i32 %49217, %49251
  %49253 = or i1 %49250, %49252
  %49254 = load i32, i32* %17, align 4
  %49255 = icmp eq i32 %49217, %49254
  %49256 = or i1 %49253, %49255
  %49257 = load i32, i32* %18, align 4
  %49258 = icmp eq i32 %49217, %49257
  %49259 = or i1 %49256, %49258
  %49260 = load i32, i32* %19, align 4
  %49261 = icmp eq i32 %49217, %49260
  %49262 = or i1 %49259, %49261
  %49263 = load i32, i32* %20, align 4
  %49264 = icmp eq i32 %49217, %49263
  %49265 = or i1 %49262, %49264
  %49266 = load i32, i32* %21, align 4
  %49267 = icmp eq i32 %49217, %49266
  %49268 = or i1 %49265, %49267
  %49269 = load i32, i32* %22, align 4
  %49270 = icmp eq i32 %49217, %49269
  %49271 = or i1 %49268, %49270
  %49272 = load i32, i32* %23, align 4
  %49273 = icmp eq i32 %49217, %49272
  %49274 = or i1 %49271, %49273
  %49275 = load i32, i32* %24, align 4
  %49276 = icmp eq i32 %49217, %49275
  %49277 = or i1 %49274, %49276
  %49278 = load i32, i32* %25, align 4
  %49279 = icmp eq i32 %49217, %49278
  %49280 = or i1 %49277, %49279
  %49281 = load i32, i32* %26, align 4
  %49282 = icmp eq i32 %49217, %49281
  %49283 = or i1 %49280, %49282
  %49284 = load i32, i32* %27, align 4
  %49285 = icmp eq i32 %49217, %49284
  %49286 = or i1 %49283, %49285
  %49287 = load i32, i32* %28, align 4
  %49288 = icmp eq i32 %49217, %49287
  %49289 = or i1 %49286, %49288
  %49290 = load i32, i32* %29, align 4
  %49291 = icmp eq i32 %49217, %49290
  %49292 = or i1 %49289, %49291
  %49293 = load i32, i32* %30, align 4
  %49294 = icmp eq i32 %49217, %49293
  %49295 = or i1 %49292, %49294
  %49296 = load i32, i32* %31, align 4
  %49297 = icmp eq i32 %49217, %49296
  %49298 = or i1 %49295, %49297
  %49299 = load i32, i32* %32, align 4
  %49300 = icmp eq i32 %49217, %49299
  %49301 = or i1 %49298, %49300
  %49302 = load i32, i32* %33, align 4
  %49303 = icmp eq i32 %49217, %49302
  %49304 = or i1 %49301, %49303
  %49305 = load i32, i32* %34, align 4
  %49306 = icmp eq i32 %49217, %49305
  %49307 = or i1 %49304, %49306
  %49308 = load i32, i32* %35, align 4
  %49309 = icmp eq i32 %49217, %49308
  %49310 = or i1 %49307, %49309
  %49311 = load i32, i32* %36, align 4
  %49312 = icmp eq i32 %49217, %49311
  %49313 = or i1 %49310, %49312
  %49314 = load i32, i32* %37, align 4
  %49315 = icmp eq i32 %49217, %49314
  %49316 = or i1 %49313, %49315
  %49317 = load i32, i32* %38, align 4
  %49318 = icmp eq i32 %49217, %49317
  %49319 = or i1 %49316, %49318
  %49320 = load i32, i32* %39, align 4
  %49321 = icmp eq i32 %49217, %49320
  %49322 = or i1 %49319, %49321
  %49323 = load i32, i32* %40, align 4
  %49324 = icmp eq i32 %49217, %49323
  %49325 = or i1 %49322, %49324
  %49326 = load i32, i32* %41, align 4
  %49327 = icmp eq i32 %49217, %49326
  %49328 = or i1 %49325, %49327
  %49329 = load i32, i32* %42, align 4
  %49330 = icmp eq i32 %49217, %49329
  %49331 = or i1 %49328, %49330
  %49332 = load i32, i32* %43, align 4
  %49333 = icmp eq i32 %49217, %49332
  %49334 = or i1 %49331, %49333
  %49335 = load i32, i32* %44, align 4
  %49336 = icmp eq i32 %49217, %49335
  %49337 = or i1 %49334, %49336
  %49338 = load i32, i32* %45, align 4
  %49339 = icmp eq i32 %49217, %49338
  %49340 = or i1 %49337, %49339
  %49341 = load i32, i32* %46, align 4
  %49342 = icmp eq i32 %49217, %49341
  %49343 = or i1 %49340, %49342
  %49344 = load i32, i32* %47, align 4
  %49345 = icmp eq i32 %49217, %49344
  %49346 = or i1 %49343, %49345
  %49347 = load i32, i32* %48, align 4
  %49348 = icmp eq i32 %49217, %49347
  %49349 = or i1 %49346, %49348
  %49350 = load i32, i32* %49, align 4
  %49351 = icmp eq i32 %49217, %49350
  %49352 = or i1 %49349, %49351
  %49353 = load i32, i32* %50, align 4
  %49354 = icmp eq i32 %49217, %49353
  %49355 = or i1 %49352, %49354
  %49356 = load i32, i32* %51, align 4
  %49357 = icmp eq i32 %49217, %49356
  %49358 = or i1 %49355, %49357
  %49359 = load i32, i32* %52, align 4
  %49360 = icmp eq i32 %49217, %49359
  %49361 = or i1 %49358, %49360
  %49362 = load i32, i32* %53, align 4
  %49363 = icmp eq i32 %49217, %49362
  %49364 = or i1 %49361, %49363
  %49365 = load i32, i32* %54, align 4
  %49366 = icmp eq i32 %49217, %49365
  %49367 = or i1 %49364, %49366
  %49368 = load i32, i32* %55, align 4
  %49369 = icmp eq i32 %49217, %49368
  %49370 = or i1 %49367, %49369
  %49371 = load i32, i32* %56, align 4
  %49372 = icmp eq i32 %49217, %49371
  %49373 = or i1 %49370, %49372
  %49374 = load i32, i32* %57, align 4
  %49375 = icmp eq i32 %49217, %49374
  %49376 = or i1 %49373, %49375
  %49377 = load i32, i32* %58, align 4
  %49378 = icmp eq i32 %49217, %49377
  %49379 = or i1 %49376, %49378
  %49380 = load i32, i32* %59, align 4
  %49381 = icmp eq i32 %49217, %49380
  %49382 = or i1 %49379, %49381
  %49383 = load i32, i32* %60, align 4
  %49384 = icmp eq i32 %49217, %49383
  %49385 = or i1 %49382, %49384
  %49386 = load i32, i32* %61, align 4
  %49387 = icmp eq i32 %49217, %49386
  %49388 = or i1 %49385, %49387
  %49389 = load i32, i32* %62, align 4
  %49390 = icmp eq i32 %49217, %49389
  %49391 = or i1 %49388, %49390
  %49392 = getelementptr i8, i8 addrspace(1)* %4, i32 181
  %49393 = zext i1 %49391 to i8
  store i8 %49393, i8 addrspace(1)* %49392, align 1, !nosanitize !3
  %49394 = load i256, i256* %49216, align 4
  %49395 = alloca i256, align 8
  store i256 %49394, i256* %49395, align 4
  %49396 = alloca i256, align 8
  store i256 1, i256* %49396, align 4
  %49397 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %49395, i256* %49396, i256* %49397), !pc !714, !intsan !6
  %49398 = load i256, i256* %49397, align 4
  %49399 = and i256 1461501637330902918203684832716283019655932542975, %49398
  %49400 = and i256 1461501637330902918203684832716283019655932542975, %49399
  %49401 = icmp eq i256 %49400, 0
  %49402 = icmp eq i1 %49401, false
  %49403 = trunc i256 15952 to i64
  %jump.check106 = icmp ne i1 %49402, false
  br i1 %jump.check106, label %.15952, label %.15941, !EVMBB !4

.15941:                                           ; preds = %49208
  %49404 = load i64, i64* %remaing_gas, align 4
  %49405 = icmp ugt i64 120, %49404
  br i1 %49405, label %Abort, label %49406

49406:                                            ; preds = %.15941
  %49407 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49408 = xor i32 %49407, 3882
  %49409 = urem i32 %49408, 4096
  %49410 = getelementptr i8, i8 addrspace(1)* %4, i32 %49409
  %49411 = load i8, i8 addrspace(1)* %49410, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49410, align 1, !nosanitize !3
  store i32 1941, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49412 = sub i64 %49404, 120
  store i64 %49412, i64* %remaing_gas, align 4
  %49413 = trunc i256 17834 to i64
  %49414 = load i64, i64* %STACK_DEP_PTR, align 4
  %49415 = add i64 %49414, 1
  store i64 %49415, i64* %STACK_DEP_PTR, align 4
  %49416 = load i64, i64* %STACK_DEP_PTR, align 4
  %49417 = getelementptr i256, i256* %STACK, i64 %49416
  store i256 15950, i256* %49417, align 4
  %49418 = load i64, i64* %STACK_DEP_PTR, align 4
  %49419 = add i64 %49418, 1
  store i64 %49419, i64* %STACK_DEP_PTR, align 4
  %49420 = load i64, i64* %STACK_DEP_PTR, align 4
  %49421 = getelementptr i256, i256* %STACK, i64 %49420
  store i256 0, i256* %49421, align 4
  br label %.17834, !EVMBB !4

.15950:                                           ; preds = %JumpTable
  %49422 = load i64, i64* %STACK_DEP_PTR, align 4
  %49423 = getelementptr i256, i256* %STACK, i64 %49422
  %49424 = load i256, i256* %49423, align 4
  %49425 = load i64, i64* %STACK_DEP_PTR, align 4
  %49426 = sub i64 %49425, 1
  store i64 %49426, i64* %STACK_DEP_PTR, align 4
  br label %.15952

.15952:                                           ; preds = %.15950, %49208, %JumpTable
  %49427 = load i64, i64* %remaing_gas, align 4
  %49428 = icmp ugt i64 784, %49427
  br i1 %49428, label %Abort, label %49429

49429:                                            ; preds = %.15952
  %49430 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49431 = xor i32 %49430, 2507
  %49432 = urem i32 %49431, 4096
  %49433 = getelementptr i8, i8 addrspace(1)* %4, i32 %49432
  %49434 = load i8, i8 addrspace(1)* %49433, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49433, align 1, !nosanitize !3
  store i32 1253, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49435 = sub i64 %49427, 784
  store i64 %49435, i64* %remaing_gas, align 4
  %49436 = alloca i256, align 8
  store i256 0, i256* %49436, align 4
  %49437 = alloca i256, align 8
  call void @__device_sload(i256* %49436, i256* %49437)
  %49438 = call i32 @__hashword(i256* %49436)
  %49439 = load i32, i32* %5, align 4
  %49440 = icmp eq i32 %49438, %49439
  %49441 = or i1 false, %49440
  %49442 = load i32, i32* %6, align 4
  %49443 = icmp eq i32 %49438, %49442
  %49444 = or i1 %49441, %49443
  %49445 = load i32, i32* %7, align 4
  %49446 = icmp eq i32 %49438, %49445
  %49447 = or i1 %49444, %49446
  %49448 = load i32, i32* %8, align 4
  %49449 = icmp eq i32 %49438, %49448
  %49450 = or i1 %49447, %49449
  %49451 = load i32, i32* %9, align 4
  %49452 = icmp eq i32 %49438, %49451
  %49453 = or i1 %49450, %49452
  %49454 = load i32, i32* %10, align 4
  %49455 = icmp eq i32 %49438, %49454
  %49456 = or i1 %49453, %49455
  %49457 = load i32, i32* %11, align 4
  %49458 = icmp eq i32 %49438, %49457
  %49459 = or i1 %49456, %49458
  %49460 = load i32, i32* %12, align 4
  %49461 = icmp eq i32 %49438, %49460
  %49462 = or i1 %49459, %49461
  %49463 = load i32, i32* %13, align 4
  %49464 = icmp eq i32 %49438, %49463
  %49465 = or i1 %49462, %49464
  %49466 = load i32, i32* %14, align 4
  %49467 = icmp eq i32 %49438, %49466
  %49468 = or i1 %49465, %49467
  %49469 = load i32, i32* %15, align 4
  %49470 = icmp eq i32 %49438, %49469
  %49471 = or i1 %49468, %49470
  %49472 = load i32, i32* %16, align 4
  %49473 = icmp eq i32 %49438, %49472
  %49474 = or i1 %49471, %49473
  %49475 = load i32, i32* %17, align 4
  %49476 = icmp eq i32 %49438, %49475
  %49477 = or i1 %49474, %49476
  %49478 = load i32, i32* %18, align 4
  %49479 = icmp eq i32 %49438, %49478
  %49480 = or i1 %49477, %49479
  %49481 = load i32, i32* %19, align 4
  %49482 = icmp eq i32 %49438, %49481
  %49483 = or i1 %49480, %49482
  %49484 = load i32, i32* %20, align 4
  %49485 = icmp eq i32 %49438, %49484
  %49486 = or i1 %49483, %49485
  %49487 = load i32, i32* %21, align 4
  %49488 = icmp eq i32 %49438, %49487
  %49489 = or i1 %49486, %49488
  %49490 = load i32, i32* %22, align 4
  %49491 = icmp eq i32 %49438, %49490
  %49492 = or i1 %49489, %49491
  %49493 = load i32, i32* %23, align 4
  %49494 = icmp eq i32 %49438, %49493
  %49495 = or i1 %49492, %49494
  %49496 = load i32, i32* %24, align 4
  %49497 = icmp eq i32 %49438, %49496
  %49498 = or i1 %49495, %49497
  %49499 = load i32, i32* %25, align 4
  %49500 = icmp eq i32 %49438, %49499
  %49501 = or i1 %49498, %49500
  %49502 = load i32, i32* %26, align 4
  %49503 = icmp eq i32 %49438, %49502
  %49504 = or i1 %49501, %49503
  %49505 = load i32, i32* %27, align 4
  %49506 = icmp eq i32 %49438, %49505
  %49507 = or i1 %49504, %49506
  %49508 = load i32, i32* %28, align 4
  %49509 = icmp eq i32 %49438, %49508
  %49510 = or i1 %49507, %49509
  %49511 = load i32, i32* %29, align 4
  %49512 = icmp eq i32 %49438, %49511
  %49513 = or i1 %49510, %49512
  %49514 = load i32, i32* %30, align 4
  %49515 = icmp eq i32 %49438, %49514
  %49516 = or i1 %49513, %49515
  %49517 = load i32, i32* %31, align 4
  %49518 = icmp eq i32 %49438, %49517
  %49519 = or i1 %49516, %49518
  %49520 = load i32, i32* %32, align 4
  %49521 = icmp eq i32 %49438, %49520
  %49522 = or i1 %49519, %49521
  %49523 = load i32, i32* %33, align 4
  %49524 = icmp eq i32 %49438, %49523
  %49525 = or i1 %49522, %49524
  %49526 = load i32, i32* %34, align 4
  %49527 = icmp eq i32 %49438, %49526
  %49528 = or i1 %49525, %49527
  %49529 = load i32, i32* %35, align 4
  %49530 = icmp eq i32 %49438, %49529
  %49531 = or i1 %49528, %49530
  %49532 = load i32, i32* %36, align 4
  %49533 = icmp eq i32 %49438, %49532
  %49534 = or i1 %49531, %49533
  %49535 = load i32, i32* %37, align 4
  %49536 = icmp eq i32 %49438, %49535
  %49537 = or i1 %49534, %49536
  %49538 = load i32, i32* %38, align 4
  %49539 = icmp eq i32 %49438, %49538
  %49540 = or i1 %49537, %49539
  %49541 = load i32, i32* %39, align 4
  %49542 = icmp eq i32 %49438, %49541
  %49543 = or i1 %49540, %49542
  %49544 = load i32, i32* %40, align 4
  %49545 = icmp eq i32 %49438, %49544
  %49546 = or i1 %49543, %49545
  %49547 = load i32, i32* %41, align 4
  %49548 = icmp eq i32 %49438, %49547
  %49549 = or i1 %49546, %49548
  %49550 = load i32, i32* %42, align 4
  %49551 = icmp eq i32 %49438, %49550
  %49552 = or i1 %49549, %49551
  %49553 = load i32, i32* %43, align 4
  %49554 = icmp eq i32 %49438, %49553
  %49555 = or i1 %49552, %49554
  %49556 = load i32, i32* %44, align 4
  %49557 = icmp eq i32 %49438, %49556
  %49558 = or i1 %49555, %49557
  %49559 = load i32, i32* %45, align 4
  %49560 = icmp eq i32 %49438, %49559
  %49561 = or i1 %49558, %49560
  %49562 = load i32, i32* %46, align 4
  %49563 = icmp eq i32 %49438, %49562
  %49564 = or i1 %49561, %49563
  %49565 = load i32, i32* %47, align 4
  %49566 = icmp eq i32 %49438, %49565
  %49567 = or i1 %49564, %49566
  %49568 = load i32, i32* %48, align 4
  %49569 = icmp eq i32 %49438, %49568
  %49570 = or i1 %49567, %49569
  %49571 = load i32, i32* %49, align 4
  %49572 = icmp eq i32 %49438, %49571
  %49573 = or i1 %49570, %49572
  %49574 = load i32, i32* %50, align 4
  %49575 = icmp eq i32 %49438, %49574
  %49576 = or i1 %49573, %49575
  %49577 = load i32, i32* %51, align 4
  %49578 = icmp eq i32 %49438, %49577
  %49579 = or i1 %49576, %49578
  %49580 = load i32, i32* %52, align 4
  %49581 = icmp eq i32 %49438, %49580
  %49582 = or i1 %49579, %49581
  %49583 = load i32, i32* %53, align 4
  %49584 = icmp eq i32 %49438, %49583
  %49585 = or i1 %49582, %49584
  %49586 = load i32, i32* %54, align 4
  %49587 = icmp eq i32 %49438, %49586
  %49588 = or i1 %49585, %49587
  %49589 = load i32, i32* %55, align 4
  %49590 = icmp eq i32 %49438, %49589
  %49591 = or i1 %49588, %49590
  %49592 = load i32, i32* %56, align 4
  %49593 = icmp eq i32 %49438, %49592
  %49594 = or i1 %49591, %49593
  %49595 = load i32, i32* %57, align 4
  %49596 = icmp eq i32 %49438, %49595
  %49597 = or i1 %49594, %49596
  %49598 = load i32, i32* %58, align 4
  %49599 = icmp eq i32 %49438, %49598
  %49600 = or i1 %49597, %49599
  %49601 = load i32, i32* %59, align 4
  %49602 = icmp eq i32 %49438, %49601
  %49603 = or i1 %49600, %49602
  %49604 = load i32, i32* %60, align 4
  %49605 = icmp eq i32 %49438, %49604
  %49606 = or i1 %49603, %49605
  %49607 = load i32, i32* %61, align 4
  %49608 = icmp eq i32 %49438, %49607
  %49609 = or i1 %49606, %49608
  %49610 = load i32, i32* %62, align 4
  %49611 = icmp eq i32 %49438, %49610
  %49612 = or i1 %49609, %49611
  %49613 = getelementptr i8, i8 addrspace(1)* %4, i32 182
  %49614 = zext i1 %49612 to i8
  store i8 %49614, i8 addrspace(1)* %49613, align 1, !nosanitize !3
  %49615 = load i256, i256* %49437, align 4
  %49616 = alloca i256, align 8
  store i256 %49615, i256* %49616, align 4
  %49617 = alloca i256, align 8
  store i256 1, i256* %49617, align 4
  %49618 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %49616, i256* %49617, i256* %49618), !pc !715, !intsan !6
  %49619 = load i256, i256* %49618, align 4
  %49620 = and i256 1461501637330902918203684832716283019655932542975, %49619
  %49621 = and i256 1461501637330902918203684832716283019655932542975, %49620
  %49622 = trunc i256 64 to i64
  %49623 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %49622, i256* %49623)
  %49624 = load i256, i256* %49623, align 4
  %49625 = and i256 4294967295, 952911921
  %49626 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %49625, !pc !716, !intsan !45
  %49627 = trunc i256 %49624 to i64
  %49628 = alloca i256, align 8
  store i256 %49626, i256* %49628, align 4
  %49629 = bitcast i256* %49628 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %49627, i8* %49629, i64 32)
  %49630 = add i256 4, %49624, !pc !717, !intsan !10
  %49631 = trunc i256 64 to i64
  %49632 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %49631, i256* %49632)
  %49633 = load i256, i256* %49632, align 4
  %49634 = sub i256 %49630, %49633, !pc !718, !intsan !8
  %49635 = icmp eq i256 1, 0
  %49636 = icmp eq i1 %49635, false
  %49637 = trunc i256 16085 to i64
  %jump.check112 = icmp ne i1 %49636, false
  %49638 = load i64, i64* %STACK_DEP_PTR, align 4
  %49639 = add i64 %49638, 1
  store i64 %49639, i64* %STACK_DEP_PTR, align 4
  %49640 = load i64, i64* %STACK_DEP_PTR, align 4
  %49641 = getelementptr i256, i256* %STACK, i64 %49640
  store i256 %49621, i256* %49641, align 4
  %49642 = load i64, i64* %STACK_DEP_PTR, align 4
  %49643 = add i64 %49642, 1
  store i64 %49643, i64* %STACK_DEP_PTR, align 4
  %49644 = load i64, i64* %STACK_DEP_PTR, align 4
  %49645 = getelementptr i256, i256* %STACK, i64 %49644
  store i256 952911921, i256* %49645, align 4
  %49646 = load i64, i64* %STACK_DEP_PTR, align 4
  %49647 = add i64 %49646, 1
  store i64 %49647, i64* %STACK_DEP_PTR, align 4
  %49648 = load i64, i64* %STACK_DEP_PTR, align 4
  %49649 = getelementptr i256, i256* %STACK, i64 %49648
  store i256 %49630, i256* %49649, align 4
  %49650 = load i64, i64* %STACK_DEP_PTR, align 4
  %49651 = add i64 %49650, 1
  store i64 %49651, i64* %STACK_DEP_PTR, align 4
  %49652 = load i64, i64* %STACK_DEP_PTR, align 4
  %49653 = getelementptr i256, i256* %STACK, i64 %49652
  store i256 32, i256* %49653, align 4
  %49654 = load i64, i64* %STACK_DEP_PTR, align 4
  %49655 = add i64 %49654, 1
  store i64 %49655, i64* %STACK_DEP_PTR, align 4
  %49656 = load i64, i64* %STACK_DEP_PTR, align 4
  %49657 = getelementptr i256, i256* %STACK, i64 %49656
  store i256 %49633, i256* %49657, align 4
  %49658 = load i64, i64* %STACK_DEP_PTR, align 4
  %49659 = add i64 %49658, 1
  store i64 %49659, i64* %STACK_DEP_PTR, align 4
  %49660 = load i64, i64* %STACK_DEP_PTR, align 4
  %49661 = getelementptr i256, i256* %STACK, i64 %49660
  store i256 %49634, i256* %49661, align 4
  %49662 = load i64, i64* %STACK_DEP_PTR, align 4
  %49663 = add i64 %49662, 1
  store i64 %49663, i64* %STACK_DEP_PTR, align 4
  %49664 = load i64, i64* %STACK_DEP_PTR, align 4
  %49665 = getelementptr i256, i256* %STACK, i64 %49664
  store i256 %49633, i256* %49665, align 4
  %49666 = load i64, i64* %STACK_DEP_PTR, align 4
  %49667 = add i64 %49666, 1
  store i64 %49667, i64* %STACK_DEP_PTR, align 4
  %49668 = load i64, i64* %STACK_DEP_PTR, align 4
  %49669 = getelementptr i256, i256* %STACK, i64 %49668
  store i256 0, i256* %49669, align 4
  %49670 = load i64, i64* %STACK_DEP_PTR, align 4
  %49671 = add i64 %49670, 1
  store i64 %49671, i64* %STACK_DEP_PTR, align 4
  %49672 = load i64, i64* %STACK_DEP_PTR, align 4
  %49673 = getelementptr i256, i256* %STACK, i64 %49672
  store i256 %49621, i256* %49673, align 4
  %49674 = load i64, i64* %STACK_DEP_PTR, align 4
  %49675 = add i64 %49674, 1
  store i64 %49675, i64* %STACK_DEP_PTR, align 4
  %49676 = zext i1 %49635 to i256
  %49677 = load i64, i64* %STACK_DEP_PTR, align 4
  %49678 = getelementptr i256, i256* %STACK, i64 %49677
  store i256 %49676, i256* %49678, align 4
  br i1 %jump.check112, label %.16085, label %.16081, !EVMBB !4

.16081:                                           ; preds = %49429
  %49679 = load i64, i64* %remaing_gas, align 4
  %49680 = icmp ugt i64 40, %49679
  br i1 %49680, label %Abort, label %49681

49681:                                            ; preds = %.16081
  %49682 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49683 = xor i32 %49682, 2056
  %49684 = urem i32 %49683, 4096
  %49685 = getelementptr i8, i8 addrspace(1)* %4, i32 %49684
  %49686 = load i8, i8 addrspace(1)* %49685, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49685, align 1, !nosanitize !3
  store i32 1028, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49687 = sub i64 %49679, 40
  store i64 %49687, i64* %remaing_gas, align 4
  %49688 = load i64, i64* %STACK_DEP_PTR, align 4
  %49689 = sub i64 %49688, 0
  store i64 %49689, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.16085:                                           ; preds = %49429, %JumpTable
  %49690 = load i64, i64* %remaing_gas, align 4
  %49691 = icmp ugt i64 456, %49690
  br i1 %49691, label %Abort, label %49692

49692:                                            ; preds = %.16085
  %49693 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49694 = xor i32 %49693, 2767
  %49695 = urem i32 %49694, 4096
  %49696 = getelementptr i8, i8 addrspace(1)* %4, i32 %49695
  %49697 = load i8, i8 addrspace(1)* %49696, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49696, align 1, !nosanitize !3
  store i32 1383, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49698 = sub i64 %49690, 456
  store i64 %49698, i64* %remaing_gas, align 4
  %49699 = load i64, i64* %STACK_DEP_PTR, align 4
  %49700 = getelementptr i256, i256* %STACK, i64 %49699
  %49701 = load i256, i256* %49700, align 4
  %49702 = load i64, i64* %STACK_DEP_PTR, align 4
  %49703 = sub i64 %49702, 1
  store i64 %49703, i64* %STACK_DEP_PTR, align 4
  %49704 = load i64, i64* %STACK_DEP_PTR, align 4
  %49705 = getelementptr i256, i256* %STACK, i64 %49704
  %49706 = load i256, i256* %49705, align 4
  %49707 = load i64, i64* %STACK_DEP_PTR, align 4
  %49708 = sub i64 %49707, 1
  store i64 %49708, i64* %STACK_DEP_PTR, align 4
  %49709 = load i64, i64* %STACK_DEP_PTR, align 4
  %49710 = getelementptr i256, i256* %STACK, i64 %49709
  %49711 = load i256, i256* %49710, align 4
  %49712 = load i64, i64* %STACK_DEP_PTR, align 4
  %49713 = sub i64 %49712, 1
  store i64 %49713, i64* %STACK_DEP_PTR, align 4
  %49714 = load i64, i64* %STACK_DEP_PTR, align 4
  %49715 = getelementptr i256, i256* %STACK, i64 %49714
  %49716 = load i256, i256* %49715, align 4
  %49717 = load i64, i64* %STACK_DEP_PTR, align 4
  %49718 = sub i64 %49717, 1
  store i64 %49718, i64* %STACK_DEP_PTR, align 4
  %49719 = load i64, i64* %STACK_DEP_PTR, align 4
  %49720 = getelementptr i256, i256* %STACK, i64 %49719
  %49721 = load i256, i256* %49720, align 4
  %49722 = load i64, i64* %STACK_DEP_PTR, align 4
  %49723 = sub i64 %49722, 1
  store i64 %49723, i64* %STACK_DEP_PTR, align 4
  %49724 = load i64, i64* %STACK_DEP_PTR, align 4
  %49725 = getelementptr i256, i256* %STACK, i64 %49724
  %49726 = load i256, i256* %49725, align 4
  %49727 = load i64, i64* %STACK_DEP_PTR, align 4
  %49728 = sub i64 %49727, 1
  store i64 %49728, i64* %STACK_DEP_PTR, align 4
  %49729 = load i64, i64* %STACK_DEP_PTR, align 4
  %49730 = getelementptr i256, i256* %STACK, i64 %49729
  %49731 = load i256, i256* %49730, align 4
  %49732 = load i64, i64* %STACK_DEP_PTR, align 4
  %49733 = sub i64 %49732, 1
  store i64 %49733, i64* %STACK_DEP_PTR, align 4
  %49734 = trunc i256 %49706 to i160
  %49735 = call i1 @solidity_call(), !pc !719
  %49736 = icmp eq i1 %49735, false
  %49737 = icmp eq i1 %49736, false
  %49738 = trunc i256 16105 to i64
  %jump.check118 = icmp ne i1 %49737, false
  %49739 = load i64, i64* %STACK_DEP_PTR, align 4
  %49740 = add i64 %49739, 1
  store i64 %49740, i64* %STACK_DEP_PTR, align 4
  %49741 = zext i1 %49736 to i256
  %49742 = load i64, i64* %STACK_DEP_PTR, align 4
  %49743 = getelementptr i256, i256* %STACK, i64 %49742
  store i256 %49741, i256* %49743, align 4
  br i1 %jump.check118, label %.16105, label %.16096, !EVMBB !4

.16096:                                           ; preds = %49692
  %49744 = load i64, i64* %remaing_gas, align 4
  %49745 = icmp ugt i64 40, %49744
  br i1 %49745, label %Abort, label %49746

49746:                                            ; preds = %.16096
  %49747 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49748 = xor i32 %49747, 609
  %49749 = urem i32 %49748, 4096
  %49750 = getelementptr i8, i8 addrspace(1)* %4, i32 %49749
  %49751 = load i8, i8 addrspace(1)* %49750, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49750, align 1, !nosanitize !3
  store i32 304, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49752 = sub i64 %49744, 40
  store i64 %49752, i64* %remaing_gas, align 4
  %49753 = load i64, i64* %STACK_DEP_PTR, align 4
  %49754 = sub i64 %49753, 0
  store i64 %49754, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.16105:                                           ; preds = %49692, %JumpTable
  %49755 = load i64, i64* %remaing_gas, align 4
  %49756 = icmp ugt i64 384, %49755
  br i1 %49756, label %Abort, label %49757

49757:                                            ; preds = %.16105
  %49758 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49759 = xor i32 %49758, 4041
  %49760 = urem i32 %49759, 4096
  %49761 = getelementptr i8, i8 addrspace(1)* %4, i32 %49760
  %49762 = load i8, i8 addrspace(1)* %49761, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49761, align 1, !nosanitize !3
  store i32 2020, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49763 = sub i64 %49755, 384
  store i64 %49763, i64* %remaing_gas, align 4
  %49764 = load i64, i64* %STACK_DEP_PTR, align 4
  %49765 = getelementptr i256, i256* %STACK, i64 %49764
  %49766 = load i256, i256* %49765, align 4
  %49767 = load i64, i64* %STACK_DEP_PTR, align 4
  %49768 = sub i64 %49767, 1
  store i64 %49768, i64* %STACK_DEP_PTR, align 4
  %49769 = load i64, i64* %STACK_DEP_PTR, align 4
  %49770 = getelementptr i256, i256* %STACK, i64 %49769
  %49771 = load i256, i256* %49770, align 4
  %49772 = load i64, i64* %STACK_DEP_PTR, align 4
  %49773 = sub i64 %49772, 1
  store i64 %49773, i64* %STACK_DEP_PTR, align 4
  %49774 = load i64, i64* %STACK_DEP_PTR, align 4
  %49775 = getelementptr i256, i256* %STACK, i64 %49774
  %49776 = load i256, i256* %49775, align 4
  %49777 = load i64, i64* %STACK_DEP_PTR, align 4
  %49778 = sub i64 %49777, 1
  store i64 %49778, i64* %STACK_DEP_PTR, align 4
  %49779 = load i64, i64* %STACK_DEP_PTR, align 4
  %49780 = getelementptr i256, i256* %STACK, i64 %49779
  %49781 = load i256, i256* %49780, align 4
  %49782 = load i64, i64* %STACK_DEP_PTR, align 4
  %49783 = sub i64 %49782, 1
  store i64 %49783, i64* %STACK_DEP_PTR, align 4
  %49784 = trunc i256 64 to i64
  %49785 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %49784, i256* %49785)
  %49786 = load i256, i256* %49785, align 4
  %49787 = zext i64 0 to i256
  %49788 = icmp ult i256 %49787, 32
  %49789 = icmp eq i1 %49788, false
  %49790 = trunc i256 16127 to i64
  %jump.check123 = icmp ne i1 %49789, false
  %49791 = load i64, i64* %STACK_DEP_PTR, align 4
  %49792 = add i64 %49791, 1
  store i64 %49792, i64* %STACK_DEP_PTR, align 4
  %49793 = load i64, i64* %STACK_DEP_PTR, align 4
  %49794 = getelementptr i256, i256* %STACK, i64 %49793
  store i256 %49786, i256* %49794, align 4
  %49795 = load i64, i64* %STACK_DEP_PTR, align 4
  %49796 = add i64 %49795, 1
  store i64 %49796, i64* %STACK_DEP_PTR, align 4
  %49797 = zext i64 0 to i256
  %49798 = load i64, i64* %STACK_DEP_PTR, align 4
  %49799 = getelementptr i256, i256* %STACK, i64 %49798
  store i256 %49797, i256* %49799, align 4
  br i1 %jump.check123, label %.16127, label %.16123, !EVMBB !4

.16123:                                           ; preds = %49757
  %49800 = load i64, i64* %remaing_gas, align 4
  %49801 = icmp ugt i64 40, %49800
  br i1 %49801, label %Abort, label %49802

49802:                                            ; preds = %.16123
  %49803 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49804 = xor i32 %49803, 451
  %49805 = urem i32 %49804, 4096
  %49806 = getelementptr i8, i8 addrspace(1)* %4, i32 %49805
  %49807 = load i8, i8 addrspace(1)* %49806, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49806, align 1, !nosanitize !3
  store i32 225, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49808 = sub i64 %49800, 40
  store i64 %49808, i64* %remaing_gas, align 4
  %49809 = load i64, i64* %STACK_DEP_PTR, align 4
  %49810 = sub i64 %49809, 0
  store i64 %49810, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.16127:                                           ; preds = %49757, %JumpTable
  %49811 = load i64, i64* %remaing_gas, align 4
  %49812 = icmp ugt i64 1232, %49811
  br i1 %49812, label %Abort, label %49813

49813:                                            ; preds = %.16127
  %49814 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49815 = xor i32 %49814, 2944
  %49816 = urem i32 %49815, 4096
  %49817 = getelementptr i8, i8 addrspace(1)* %4, i32 %49816
  %49818 = load i8, i8 addrspace(1)* %49817, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %49817, align 1, !nosanitize !3
  store i32 1472, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %49819 = sub i64 %49811, 1232
  store i64 %49819, i64* %remaing_gas, align 4
  %49820 = load i64, i64* %STACK_DEP_PTR, align 4
  %49821 = getelementptr i256, i256* %STACK, i64 %49820
  %49822 = load i256, i256* %49821, align 4
  %49823 = load i64, i64* %STACK_DEP_PTR, align 4
  %49824 = sub i64 %49823, 1
  store i64 %49824, i64* %STACK_DEP_PTR, align 4
  %49825 = load i64, i64* %STACK_DEP_PTR, align 4
  %49826 = getelementptr i256, i256* %STACK, i64 %49825
  %49827 = load i256, i256* %49826, align 4
  %49828 = load i64, i64* %STACK_DEP_PTR, align 4
  %49829 = sub i64 %49828, 1
  store i64 %49829, i64* %STACK_DEP_PTR, align 4
  %49830 = load i64, i64* %STACK_DEP_PTR, align 4
  %49831 = getelementptr i256, i256* %STACK, i64 %49830
  %49832 = load i256, i256* %49831, align 4
  %49833 = load i64, i64* %STACK_DEP_PTR, align 4
  %49834 = sub i64 %49833, 1
  store i64 %49834, i64* %STACK_DEP_PTR, align 4
  %49835 = add i256 %49827, %49822, !pc !720, !intsan !10
  %49836 = trunc i256 %49827 to i64
  %49837 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %49836, i256* %49837)
  %49838 = load i256, i256* %49837, align 4
  %49839 = add i256 32, %49827, !pc !721, !intsan !10
  %49840 = alloca i256, align 8
  store i256 1, i256* %49840, align 4
  %49841 = alloca i256, align 8
  call void @__device_sload(i256* %49840, i256* %49841)
  %49842 = call i32 @__hashword(i256* %49840)
  %49843 = load i32, i32* %5, align 4
  %49844 = icmp eq i32 %49842, %49843
  %49845 = or i1 false, %49844
  %49846 = load i32, i32* %6, align 4
  %49847 = icmp eq i32 %49842, %49846
  %49848 = or i1 %49845, %49847
  %49849 = load i32, i32* %7, align 4
  %49850 = icmp eq i32 %49842, %49849
  %49851 = or i1 %49848, %49850
  %49852 = load i32, i32* %8, align 4
  %49853 = icmp eq i32 %49842, %49852
  %49854 = or i1 %49851, %49853
  %49855 = load i32, i32* %9, align 4
  %49856 = icmp eq i32 %49842, %49855
  %49857 = or i1 %49854, %49856
  %49858 = load i32, i32* %10, align 4
  %49859 = icmp eq i32 %49842, %49858
  %49860 = or i1 %49857, %49859
  %49861 = load i32, i32* %11, align 4
  %49862 = icmp eq i32 %49842, %49861
  %49863 = or i1 %49860, %49862
  %49864 = load i32, i32* %12, align 4
  %49865 = icmp eq i32 %49842, %49864
  %49866 = or i1 %49863, %49865
  %49867 = load i32, i32* %13, align 4
  %49868 = icmp eq i32 %49842, %49867
  %49869 = or i1 %49866, %49868
  %49870 = load i32, i32* %14, align 4
  %49871 = icmp eq i32 %49842, %49870
  %49872 = or i1 %49869, %49871
  %49873 = load i32, i32* %15, align 4
  %49874 = icmp eq i32 %49842, %49873
  %49875 = or i1 %49872, %49874
  %49876 = load i32, i32* %16, align 4
  %49877 = icmp eq i32 %49842, %49876
  %49878 = or i1 %49875, %49877
  %49879 = load i32, i32* %17, align 4
  %49880 = icmp eq i32 %49842, %49879
  %49881 = or i1 %49878, %49880
  %49882 = load i32, i32* %18, align 4
  %49883 = icmp eq i32 %49842, %49882
  %49884 = or i1 %49881, %49883
  %49885 = load i32, i32* %19, align 4
  %49886 = icmp eq i32 %49842, %49885
  %49887 = or i1 %49884, %49886
  %49888 = load i32, i32* %20, align 4
  %49889 = icmp eq i32 %49842, %49888
  %49890 = or i1 %49887, %49889
  %49891 = load i32, i32* %21, align 4
  %49892 = icmp eq i32 %49842, %49891
  %49893 = or i1 %49890, %49892
  %49894 = load i32, i32* %22, align 4
  %49895 = icmp eq i32 %49842, %49894
  %49896 = or i1 %49893, %49895
  %49897 = load i32, i32* %23, align 4
  %49898 = icmp eq i32 %49842, %49897
  %49899 = or i1 %49896, %49898
  %49900 = load i32, i32* %24, align 4
  %49901 = icmp eq i32 %49842, %49900
  %49902 = or i1 %49899, %49901
  %49903 = load i32, i32* %25, align 4
  %49904 = icmp eq i32 %49842, %49903
  %49905 = or i1 %49902, %49904
  %49906 = load i32, i32* %26, align 4
  %49907 = icmp eq i32 %49842, %49906
  %49908 = or i1 %49905, %49907
  %49909 = load i32, i32* %27, align 4
  %49910 = icmp eq i32 %49842, %49909
  %49911 = or i1 %49908, %49910
  %49912 = load i32, i32* %28, align 4
  %49913 = icmp eq i32 %49842, %49912
  %49914 = or i1 %49911, %49913
  %49915 = load i32, i32* %29, align 4
  %49916 = icmp eq i32 %49842, %49915
  %49917 = or i1 %49914, %49916
  %49918 = load i32, i32* %30, align 4
  %49919 = icmp eq i32 %49842, %49918
  %49920 = or i1 %49917, %49919
  %49921 = load i32, i32* %31, align 4
  %49922 = icmp eq i32 %49842, %49921
  %49923 = or i1 %49920, %49922
  %49924 = load i32, i32* %32, align 4
  %49925 = icmp eq i32 %49842, %49924
  %49926 = or i1 %49923, %49925
  %49927 = load i32, i32* %33, align 4
  %49928 = icmp eq i32 %49842, %49927
  %49929 = or i1 %49926, %49928
  %49930 = load i32, i32* %34, align 4
  %49931 = icmp eq i32 %49842, %49930
  %49932 = or i1 %49929, %49931
  %49933 = load i32, i32* %35, align 4
  %49934 = icmp eq i32 %49842, %49933
  %49935 = or i1 %49932, %49934
  %49936 = load i32, i32* %36, align 4
  %49937 = icmp eq i32 %49842, %49936
  %49938 = or i1 %49935, %49937
  %49939 = load i32, i32* %37, align 4
  %49940 = icmp eq i32 %49842, %49939
  %49941 = or i1 %49938, %49940
  %49942 = load i32, i32* %38, align 4
  %49943 = icmp eq i32 %49842, %49942
  %49944 = or i1 %49941, %49943
  %49945 = load i32, i32* %39, align 4
  %49946 = icmp eq i32 %49842, %49945
  %49947 = or i1 %49944, %49946
  %49948 = load i32, i32* %40, align 4
  %49949 = icmp eq i32 %49842, %49948
  %49950 = or i1 %49947, %49949
  %49951 = load i32, i32* %41, align 4
  %49952 = icmp eq i32 %49842, %49951
  %49953 = or i1 %49950, %49952
  %49954 = load i32, i32* %42, align 4
  %49955 = icmp eq i32 %49842, %49954
  %49956 = or i1 %49953, %49955
  %49957 = load i32, i32* %43, align 4
  %49958 = icmp eq i32 %49842, %49957
  %49959 = or i1 %49956, %49958
  %49960 = load i32, i32* %44, align 4
  %49961 = icmp eq i32 %49842, %49960
  %49962 = or i1 %49959, %49961
  %49963 = load i32, i32* %45, align 4
  %49964 = icmp eq i32 %49842, %49963
  %49965 = or i1 %49962, %49964
  %49966 = load i32, i32* %46, align 4
  %49967 = icmp eq i32 %49842, %49966
  %49968 = or i1 %49965, %49967
  %49969 = load i32, i32* %47, align 4
  %49970 = icmp eq i32 %49842, %49969
  %49971 = or i1 %49968, %49970
  %49972 = load i32, i32* %48, align 4
  %49973 = icmp eq i32 %49842, %49972
  %49974 = or i1 %49971, %49973
  %49975 = load i32, i32* %49, align 4
  %49976 = icmp eq i32 %49842, %49975
  %49977 = or i1 %49974, %49976
  %49978 = load i32, i32* %50, align 4
  %49979 = icmp eq i32 %49842, %49978
  %49980 = or i1 %49977, %49979
  %49981 = load i32, i32* %51, align 4
  %49982 = icmp eq i32 %49842, %49981
  %49983 = or i1 %49980, %49982
  %49984 = load i32, i32* %52, align 4
  %49985 = icmp eq i32 %49842, %49984
  %49986 = or i1 %49983, %49985
  %49987 = load i32, i32* %53, align 4
  %49988 = icmp eq i32 %49842, %49987
  %49989 = or i1 %49986, %49988
  %49990 = load i32, i32* %54, align 4
  %49991 = icmp eq i32 %49842, %49990
  %49992 = or i1 %49989, %49991
  %49993 = load i32, i32* %55, align 4
  %49994 = icmp eq i32 %49842, %49993
  %49995 = or i1 %49992, %49994
  %49996 = load i32, i32* %56, align 4
  %49997 = icmp eq i32 %49842, %49996
  %49998 = or i1 %49995, %49997
  %49999 = load i32, i32* %57, align 4
  %50000 = icmp eq i32 %49842, %49999
  %50001 = or i1 %49998, %50000
  %50002 = load i32, i32* %58, align 4
  %50003 = icmp eq i32 %49842, %50002
  %50004 = or i1 %50001, %50003
  %50005 = load i32, i32* %59, align 4
  %50006 = icmp eq i32 %49842, %50005
  %50007 = or i1 %50004, %50006
  %50008 = load i32, i32* %60, align 4
  %50009 = icmp eq i32 %49842, %50008
  %50010 = or i1 %50007, %50009
  %50011 = load i32, i32* %61, align 4
  %50012 = icmp eq i32 %49842, %50011
  %50013 = or i1 %50010, %50012
  %50014 = load i32, i32* %62, align 4
  %50015 = icmp eq i32 %49842, %50014
  %50016 = or i1 %50013, %50015
  %50017 = getelementptr i8, i8 addrspace(1)* %4, i32 183
  %50018 = zext i1 %50016 to i8
  store i8 %50018, i8 addrspace(1)* %50017, align 1, !nosanitize !3
  %50019 = load i256, i256* %49841, align 4
  %50020 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !722, !intsan !45
  %50021 = xor i256 %50020, -1
  %50022 = and i256 %50021, %50019
  %50023 = and i256 1461501637330902918203684832716283019655932542975, %49838
  %50024 = mul i256 %50023, 1, !pc !723, !intsan !45
  %50025 = or i256 %50024, %50022
  %50026 = alloca i256, align 8
  store i256 1, i256* %50026, align 4
  %50027 = alloca i256, align 8
  store i256 %50025, i256* %50027, align 4
  call void @__device_sstore(i256* %50026, i256* %50027)
  %50028 = call i32 @__hashword(i256* %50026)
  store i32 %50028, i32* %26, align 4, !nosanitize !3
  %50029 = alloca i256, align 8
  store i256 1, i256* %50029, align 4
  %50030 = alloca i256, align 8
  call void @__device_sload(i256* %50029, i256* %50030)
  %50031 = call i32 @__hashword(i256* %50029)
  %50032 = load i32, i32* %5, align 4
  %50033 = icmp eq i32 %50031, %50032
  %50034 = or i1 false, %50033
  %50035 = load i32, i32* %6, align 4
  %50036 = icmp eq i32 %50031, %50035
  %50037 = or i1 %50034, %50036
  %50038 = load i32, i32* %7, align 4
  %50039 = icmp eq i32 %50031, %50038
  %50040 = or i1 %50037, %50039
  %50041 = load i32, i32* %8, align 4
  %50042 = icmp eq i32 %50031, %50041
  %50043 = or i1 %50040, %50042
  %50044 = load i32, i32* %9, align 4
  %50045 = icmp eq i32 %50031, %50044
  %50046 = or i1 %50043, %50045
  %50047 = load i32, i32* %10, align 4
  %50048 = icmp eq i32 %50031, %50047
  %50049 = or i1 %50046, %50048
  %50050 = load i32, i32* %11, align 4
  %50051 = icmp eq i32 %50031, %50050
  %50052 = or i1 %50049, %50051
  %50053 = load i32, i32* %12, align 4
  %50054 = icmp eq i32 %50031, %50053
  %50055 = or i1 %50052, %50054
  %50056 = load i32, i32* %13, align 4
  %50057 = icmp eq i32 %50031, %50056
  %50058 = or i1 %50055, %50057
  %50059 = load i32, i32* %14, align 4
  %50060 = icmp eq i32 %50031, %50059
  %50061 = or i1 %50058, %50060
  %50062 = load i32, i32* %15, align 4
  %50063 = icmp eq i32 %50031, %50062
  %50064 = or i1 %50061, %50063
  %50065 = load i32, i32* %16, align 4
  %50066 = icmp eq i32 %50031, %50065
  %50067 = or i1 %50064, %50066
  %50068 = load i32, i32* %17, align 4
  %50069 = icmp eq i32 %50031, %50068
  %50070 = or i1 %50067, %50069
  %50071 = load i32, i32* %18, align 4
  %50072 = icmp eq i32 %50031, %50071
  %50073 = or i1 %50070, %50072
  %50074 = load i32, i32* %19, align 4
  %50075 = icmp eq i32 %50031, %50074
  %50076 = or i1 %50073, %50075
  %50077 = load i32, i32* %20, align 4
  %50078 = icmp eq i32 %50031, %50077
  %50079 = or i1 %50076, %50078
  %50080 = load i32, i32* %21, align 4
  %50081 = icmp eq i32 %50031, %50080
  %50082 = or i1 %50079, %50081
  %50083 = load i32, i32* %22, align 4
  %50084 = icmp eq i32 %50031, %50083
  %50085 = or i1 %50082, %50084
  %50086 = load i32, i32* %23, align 4
  %50087 = icmp eq i32 %50031, %50086
  %50088 = or i1 %50085, %50087
  %50089 = load i32, i32* %24, align 4
  %50090 = icmp eq i32 %50031, %50089
  %50091 = or i1 %50088, %50090
  %50092 = load i32, i32* %25, align 4
  %50093 = icmp eq i32 %50031, %50092
  %50094 = or i1 %50091, %50093
  %50095 = load i32, i32* %26, align 4
  %50096 = icmp eq i32 %50031, %50095
  %50097 = or i1 %50094, %50096
  %50098 = load i32, i32* %27, align 4
  %50099 = icmp eq i32 %50031, %50098
  %50100 = or i1 %50097, %50099
  %50101 = load i32, i32* %28, align 4
  %50102 = icmp eq i32 %50031, %50101
  %50103 = or i1 %50100, %50102
  %50104 = load i32, i32* %29, align 4
  %50105 = icmp eq i32 %50031, %50104
  %50106 = or i1 %50103, %50105
  %50107 = load i32, i32* %30, align 4
  %50108 = icmp eq i32 %50031, %50107
  %50109 = or i1 %50106, %50108
  %50110 = load i32, i32* %31, align 4
  %50111 = icmp eq i32 %50031, %50110
  %50112 = or i1 %50109, %50111
  %50113 = load i32, i32* %32, align 4
  %50114 = icmp eq i32 %50031, %50113
  %50115 = or i1 %50112, %50114
  %50116 = load i32, i32* %33, align 4
  %50117 = icmp eq i32 %50031, %50116
  %50118 = or i1 %50115, %50117
  %50119 = load i32, i32* %34, align 4
  %50120 = icmp eq i32 %50031, %50119
  %50121 = or i1 %50118, %50120
  %50122 = load i32, i32* %35, align 4
  %50123 = icmp eq i32 %50031, %50122
  %50124 = or i1 %50121, %50123
  %50125 = load i32, i32* %36, align 4
  %50126 = icmp eq i32 %50031, %50125
  %50127 = or i1 %50124, %50126
  %50128 = load i32, i32* %37, align 4
  %50129 = icmp eq i32 %50031, %50128
  %50130 = or i1 %50127, %50129
  %50131 = load i32, i32* %38, align 4
  %50132 = icmp eq i32 %50031, %50131
  %50133 = or i1 %50130, %50132
  %50134 = load i32, i32* %39, align 4
  %50135 = icmp eq i32 %50031, %50134
  %50136 = or i1 %50133, %50135
  %50137 = load i32, i32* %40, align 4
  %50138 = icmp eq i32 %50031, %50137
  %50139 = or i1 %50136, %50138
  %50140 = load i32, i32* %41, align 4
  %50141 = icmp eq i32 %50031, %50140
  %50142 = or i1 %50139, %50141
  %50143 = load i32, i32* %42, align 4
  %50144 = icmp eq i32 %50031, %50143
  %50145 = or i1 %50142, %50144
  %50146 = load i32, i32* %43, align 4
  %50147 = icmp eq i32 %50031, %50146
  %50148 = or i1 %50145, %50147
  %50149 = load i32, i32* %44, align 4
  %50150 = icmp eq i32 %50031, %50149
  %50151 = or i1 %50148, %50150
  %50152 = load i32, i32* %45, align 4
  %50153 = icmp eq i32 %50031, %50152
  %50154 = or i1 %50151, %50153
  %50155 = load i32, i32* %46, align 4
  %50156 = icmp eq i32 %50031, %50155
  %50157 = or i1 %50154, %50156
  %50158 = load i32, i32* %47, align 4
  %50159 = icmp eq i32 %50031, %50158
  %50160 = or i1 %50157, %50159
  %50161 = load i32, i32* %48, align 4
  %50162 = icmp eq i32 %50031, %50161
  %50163 = or i1 %50160, %50162
  %50164 = load i32, i32* %49, align 4
  %50165 = icmp eq i32 %50031, %50164
  %50166 = or i1 %50163, %50165
  %50167 = load i32, i32* %50, align 4
  %50168 = icmp eq i32 %50031, %50167
  %50169 = or i1 %50166, %50168
  %50170 = load i32, i32* %51, align 4
  %50171 = icmp eq i32 %50031, %50170
  %50172 = or i1 %50169, %50171
  %50173 = load i32, i32* %52, align 4
  %50174 = icmp eq i32 %50031, %50173
  %50175 = or i1 %50172, %50174
  %50176 = load i32, i32* %53, align 4
  %50177 = icmp eq i32 %50031, %50176
  %50178 = or i1 %50175, %50177
  %50179 = load i32, i32* %54, align 4
  %50180 = icmp eq i32 %50031, %50179
  %50181 = or i1 %50178, %50180
  %50182 = load i32, i32* %55, align 4
  %50183 = icmp eq i32 %50031, %50182
  %50184 = or i1 %50181, %50183
  %50185 = load i32, i32* %56, align 4
  %50186 = icmp eq i32 %50031, %50185
  %50187 = or i1 %50184, %50186
  %50188 = load i32, i32* %57, align 4
  %50189 = icmp eq i32 %50031, %50188
  %50190 = or i1 %50187, %50189
  %50191 = load i32, i32* %58, align 4
  %50192 = icmp eq i32 %50031, %50191
  %50193 = or i1 %50190, %50192
  %50194 = load i32, i32* %59, align 4
  %50195 = icmp eq i32 %50031, %50194
  %50196 = or i1 %50193, %50195
  %50197 = load i32, i32* %60, align 4
  %50198 = icmp eq i32 %50031, %50197
  %50199 = or i1 %50196, %50198
  %50200 = load i32, i32* %61, align 4
  %50201 = icmp eq i32 %50031, %50200
  %50202 = or i1 %50199, %50201
  %50203 = load i32, i32* %62, align 4
  %50204 = icmp eq i32 %50031, %50203
  %50205 = or i1 %50202, %50204
  %50206 = getelementptr i8, i8 addrspace(1)* %4, i32 184
  %50207 = zext i1 %50205 to i8
  store i8 %50207, i8 addrspace(1)* %50206, align 1, !nosanitize !3
  %50208 = load i256, i256* %50030, align 4
  %50209 = alloca i256, align 8
  store i256 %50208, i256* %50209, align 4
  %50210 = alloca i256, align 8
  store i256 1, i256* %50210, align 4
  %50211 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %50209, i256* %50210, i256* %50211), !pc !724, !intsan !6
  %50212 = load i256, i256* %50211, align 4
  %50213 = and i256 1461501637330902918203684832716283019655932542975, %50212
  %50214 = and i256 1461501637330902918203684832716283019655932542975, %50213
  %50215 = trunc i256 64 to i64
  %50216 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %50215, i256* %50216)
  %50217 = load i256, i256* %50216, align 4
  %50218 = and i256 4294967295, 1754124247
  %50219 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %50218, !pc !725, !intsan !45
  %50220 = trunc i256 %50217 to i64
  %50221 = alloca i256, align 8
  store i256 %50219, i256* %50221, align 4
  %50222 = bitcast i256* %50221 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %50220, i8* %50222, i64 32)
  %50223 = add i256 4, %50217, !pc !726, !intsan !10
  %50224 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %50225 = and i256 %50224, %49832
  %50226 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %50227 = and i256 %50226, %50225
  %50228 = trunc i256 %50223 to i64
  %50229 = alloca i256, align 8
  store i256 %50227, i256* %50229, align 4
  %50230 = bitcast i256* %50229 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %50228, i8* %50230, i64 32)
  %50231 = add i256 32, %50223, !pc !727, !intsan !10
  %50232 = trunc i256 64 to i64
  %50233 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %50232, i256* %50233)
  %50234 = load i256, i256* %50233, align 4
  %50235 = sub i256 %50231, %50234, !pc !728, !intsan !8
  %50236 = icmp eq i256 1, 0
  %50237 = icmp eq i1 %50236, false
  %50238 = trunc i256 16421 to i64
  %jump.check128 = icmp ne i1 %50237, false
  %50239 = load i64, i64* %STACK_DEP_PTR, align 4
  %50240 = add i64 %50239, 1
  store i64 %50240, i64* %STACK_DEP_PTR, align 4
  %50241 = load i64, i64* %STACK_DEP_PTR, align 4
  %50242 = getelementptr i256, i256* %STACK, i64 %50241
  store i256 %49832, i256* %50242, align 4
  %50243 = load i64, i64* %STACK_DEP_PTR, align 4
  %50244 = add i64 %50243, 1
  store i64 %50244, i64* %STACK_DEP_PTR, align 4
  %50245 = load i64, i64* %STACK_DEP_PTR, align 4
  %50246 = getelementptr i256, i256* %STACK, i64 %50245
  store i256 %50214, i256* %50246, align 4
  %50247 = load i64, i64* %STACK_DEP_PTR, align 4
  %50248 = add i64 %50247, 1
  store i64 %50248, i64* %STACK_DEP_PTR, align 4
  %50249 = load i64, i64* %STACK_DEP_PTR, align 4
  %50250 = getelementptr i256, i256* %STACK, i64 %50249
  store i256 1754124247, i256* %50250, align 4
  %50251 = load i64, i64* %STACK_DEP_PTR, align 4
  %50252 = add i64 %50251, 1
  store i64 %50252, i64* %STACK_DEP_PTR, align 4
  %50253 = load i64, i64* %STACK_DEP_PTR, align 4
  %50254 = getelementptr i256, i256* %STACK, i64 %50253
  store i256 %50231, i256* %50254, align 4
  %50255 = load i64, i64* %STACK_DEP_PTR, align 4
  %50256 = add i64 %50255, 1
  store i64 %50256, i64* %STACK_DEP_PTR, align 4
  %50257 = load i64, i64* %STACK_DEP_PTR, align 4
  %50258 = getelementptr i256, i256* %STACK, i64 %50257
  store i256 0, i256* %50258, align 4
  %50259 = load i64, i64* %STACK_DEP_PTR, align 4
  %50260 = add i64 %50259, 1
  store i64 %50260, i64* %STACK_DEP_PTR, align 4
  %50261 = load i64, i64* %STACK_DEP_PTR, align 4
  %50262 = getelementptr i256, i256* %STACK, i64 %50261
  store i256 %50234, i256* %50262, align 4
  %50263 = load i64, i64* %STACK_DEP_PTR, align 4
  %50264 = add i64 %50263, 1
  store i64 %50264, i64* %STACK_DEP_PTR, align 4
  %50265 = load i64, i64* %STACK_DEP_PTR, align 4
  %50266 = getelementptr i256, i256* %STACK, i64 %50265
  store i256 %50235, i256* %50266, align 4
  %50267 = load i64, i64* %STACK_DEP_PTR, align 4
  %50268 = add i64 %50267, 1
  store i64 %50268, i64* %STACK_DEP_PTR, align 4
  %50269 = load i64, i64* %STACK_DEP_PTR, align 4
  %50270 = getelementptr i256, i256* %STACK, i64 %50269
  store i256 %50234, i256* %50270, align 4
  %50271 = load i64, i64* %STACK_DEP_PTR, align 4
  %50272 = add i64 %50271, 1
  store i64 %50272, i64* %STACK_DEP_PTR, align 4
  %50273 = load i64, i64* %STACK_DEP_PTR, align 4
  %50274 = getelementptr i256, i256* %STACK, i64 %50273
  store i256 0, i256* %50274, align 4
  %50275 = load i64, i64* %STACK_DEP_PTR, align 4
  %50276 = add i64 %50275, 1
  store i64 %50276, i64* %STACK_DEP_PTR, align 4
  %50277 = load i64, i64* %STACK_DEP_PTR, align 4
  %50278 = getelementptr i256, i256* %STACK, i64 %50277
  store i256 %50214, i256* %50278, align 4
  %50279 = load i64, i64* %STACK_DEP_PTR, align 4
  %50280 = add i64 %50279, 1
  store i64 %50280, i64* %STACK_DEP_PTR, align 4
  %50281 = zext i1 %50236 to i256
  %50282 = load i64, i64* %STACK_DEP_PTR, align 4
  %50283 = getelementptr i256, i256* %STACK, i64 %50282
  store i256 %50281, i256* %50283, align 4
  br i1 %jump.check128, label %.16421, label %.16417, !EVMBB !4

.16417:                                           ; preds = %49813
  %50284 = load i64, i64* %remaing_gas, align 4
  %50285 = icmp ugt i64 40, %50284
  br i1 %50285, label %Abort, label %50286

50286:                                            ; preds = %.16417
  %50287 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50288 = xor i32 %50287, 3678
  %50289 = urem i32 %50288, 4096
  %50290 = getelementptr i8, i8 addrspace(1)* %4, i32 %50289
  %50291 = load i8, i8 addrspace(1)* %50290, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50290, align 1, !nosanitize !3
  store i32 1839, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50292 = sub i64 %50284, 40
  store i64 %50292, i64* %remaing_gas, align 4
  %50293 = load i64, i64* %STACK_DEP_PTR, align 4
  %50294 = sub i64 %50293, 0
  store i64 %50294, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.16421:                                           ; preds = %49813, %JumpTable
  %50295 = load i64, i64* %remaing_gas, align 4
  %50296 = icmp ugt i64 456, %50295
  br i1 %50296, label %Abort, label %50297

50297:                                            ; preds = %.16421
  %50298 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50299 = xor i32 %50298, 110
  %50300 = urem i32 %50299, 4096
  %50301 = getelementptr i8, i8 addrspace(1)* %4, i32 %50300
  %50302 = load i8, i8 addrspace(1)* %50301, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50301, align 1, !nosanitize !3
  store i32 55, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50303 = sub i64 %50295, 456
  store i64 %50303, i64* %remaing_gas, align 4
  %50304 = load i64, i64* %STACK_DEP_PTR, align 4
  %50305 = getelementptr i256, i256* %STACK, i64 %50304
  %50306 = load i256, i256* %50305, align 4
  %50307 = load i64, i64* %STACK_DEP_PTR, align 4
  %50308 = sub i64 %50307, 1
  store i64 %50308, i64* %STACK_DEP_PTR, align 4
  %50309 = load i64, i64* %STACK_DEP_PTR, align 4
  %50310 = getelementptr i256, i256* %STACK, i64 %50309
  %50311 = load i256, i256* %50310, align 4
  %50312 = load i64, i64* %STACK_DEP_PTR, align 4
  %50313 = sub i64 %50312, 1
  store i64 %50313, i64* %STACK_DEP_PTR, align 4
  %50314 = load i64, i64* %STACK_DEP_PTR, align 4
  %50315 = getelementptr i256, i256* %STACK, i64 %50314
  %50316 = load i256, i256* %50315, align 4
  %50317 = load i64, i64* %STACK_DEP_PTR, align 4
  %50318 = sub i64 %50317, 1
  store i64 %50318, i64* %STACK_DEP_PTR, align 4
  %50319 = load i64, i64* %STACK_DEP_PTR, align 4
  %50320 = getelementptr i256, i256* %STACK, i64 %50319
  %50321 = load i256, i256* %50320, align 4
  %50322 = load i64, i64* %STACK_DEP_PTR, align 4
  %50323 = sub i64 %50322, 1
  store i64 %50323, i64* %STACK_DEP_PTR, align 4
  %50324 = load i64, i64* %STACK_DEP_PTR, align 4
  %50325 = getelementptr i256, i256* %STACK, i64 %50324
  %50326 = load i256, i256* %50325, align 4
  %50327 = load i64, i64* %STACK_DEP_PTR, align 4
  %50328 = sub i64 %50327, 1
  store i64 %50328, i64* %STACK_DEP_PTR, align 4
  %50329 = load i64, i64* %STACK_DEP_PTR, align 4
  %50330 = getelementptr i256, i256* %STACK, i64 %50329
  %50331 = load i256, i256* %50330, align 4
  %50332 = load i64, i64* %STACK_DEP_PTR, align 4
  %50333 = sub i64 %50332, 1
  store i64 %50333, i64* %STACK_DEP_PTR, align 4
  %50334 = load i64, i64* %STACK_DEP_PTR, align 4
  %50335 = getelementptr i256, i256* %STACK, i64 %50334
  %50336 = load i256, i256* %50335, align 4
  %50337 = load i64, i64* %STACK_DEP_PTR, align 4
  %50338 = sub i64 %50337, 1
  store i64 %50338, i64* %STACK_DEP_PTR, align 4
  %50339 = trunc i256 %50311 to i160
  %50340 = call i1 @solidity_call(), !pc !729
  %50341 = icmp eq i1 %50340, false
  %50342 = icmp eq i1 %50341, false
  %50343 = trunc i256 16441 to i64
  %jump.check133 = icmp ne i1 %50342, false
  %50344 = load i64, i64* %STACK_DEP_PTR, align 4
  %50345 = add i64 %50344, 1
  store i64 %50345, i64* %STACK_DEP_PTR, align 4
  %50346 = zext i1 %50341 to i256
  %50347 = load i64, i64* %STACK_DEP_PTR, align 4
  %50348 = getelementptr i256, i256* %STACK, i64 %50347
  store i256 %50346, i256* %50348, align 4
  br i1 %jump.check133, label %.16441, label %.16432, !EVMBB !4

.16432:                                           ; preds = %50297
  %50349 = load i64, i64* %remaing_gas, align 4
  %50350 = icmp ugt i64 40, %50349
  br i1 %50350, label %Abort, label %50351

50351:                                            ; preds = %.16432
  %50352 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50353 = xor i32 %50352, 1283
  %50354 = urem i32 %50353, 4096
  %50355 = getelementptr i8, i8 addrspace(1)* %4, i32 %50354
  %50356 = load i8, i8 addrspace(1)* %50355, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50355, align 1, !nosanitize !3
  store i32 641, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50357 = sub i64 %50349, 40
  store i64 %50357, i64* %remaing_gas, align 4
  %50358 = load i64, i64* %STACK_DEP_PTR, align 4
  %50359 = sub i64 %50358, 0
  store i64 %50359, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.16441:                                           ; preds = %50297, %JumpTable
  %50360 = load i64, i64* %remaing_gas, align 4
  %50361 = icmp ugt i64 320, %50360
  br i1 %50361, label %Abort, label %50362

50362:                                            ; preds = %.16441
  %50363 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50364 = xor i32 %50363, 3624
  %50365 = urem i32 %50364, 4096
  %50366 = getelementptr i8, i8 addrspace(1)* %4, i32 %50365
  %50367 = load i8, i8 addrspace(1)* %50366, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50366, align 1, !nosanitize !3
  store i32 1812, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50368 = sub i64 %50360, 320
  store i64 %50368, i64* %remaing_gas, align 4
  %50369 = load i64, i64* %STACK_DEP_PTR, align 4
  %50370 = getelementptr i256, i256* %STACK, i64 %50369
  %50371 = load i256, i256* %50370, align 4
  %50372 = load i64, i64* %STACK_DEP_PTR, align 4
  %50373 = sub i64 %50372, 1
  store i64 %50373, i64* %STACK_DEP_PTR, align 4
  %50374 = load i64, i64* %STACK_DEP_PTR, align 4
  %50375 = getelementptr i256, i256* %STACK, i64 %50374
  %50376 = load i256, i256* %50375, align 4
  %50377 = load i64, i64* %STACK_DEP_PTR, align 4
  %50378 = sub i64 %50377, 1
  store i64 %50378, i64* %STACK_DEP_PTR, align 4
  %50379 = load i64, i64* %STACK_DEP_PTR, align 4
  %50380 = getelementptr i256, i256* %STACK, i64 %50379
  %50381 = load i256, i256* %50380, align 4
  %50382 = load i64, i64* %STACK_DEP_PTR, align 4
  %50383 = sub i64 %50382, 1
  store i64 %50383, i64* %STACK_DEP_PTR, align 4
  %50384 = load i64, i64* %STACK_DEP_PTR, align 4
  %50385 = getelementptr i256, i256* %STACK, i64 %50384
  %50386 = load i256, i256* %50385, align 4
  %50387 = load i64, i64* %STACK_DEP_PTR, align 4
  %50388 = sub i64 %50387, 1
  store i64 %50388, i64* %STACK_DEP_PTR, align 4
  %50389 = load i64, i64* %STACK_DEP_PTR, align 4
  %50390 = getelementptr i256, i256* %STACK, i64 %50389
  %50391 = load i256, i256* %50390, align 4
  %50392 = load i64, i64* %STACK_DEP_PTR, align 4
  %50393 = sub i64 %50392, 1
  store i64 %50393, i64* %STACK_DEP_PTR, align 4
  %50394 = load i64, i64* %STACK_DEP_PTR, align 4
  %50395 = getelementptr i256, i256* %STACK, i64 %50394
  %50396 = load i256, i256* %50395, align 4
  %50397 = load i64, i64* %STACK_DEP_PTR, align 4
  %50398 = sub i64 %50397, 1
  store i64 %50398, i64* %STACK_DEP_PTR, align 4
  %50399 = trunc i256 %50396 to i64
  store i64 %50399, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.16448:                                           ; preds = %39025, %35218, %28439, %JumpTable
  %50400 = load i64, i64* %remaing_gas, align 4
  %50401 = icmp ugt i64 392, %50400
  br i1 %50401, label %Abort, label %50402

50402:                                            ; preds = %.16448
  %50403 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50404 = xor i32 %50403, 730
  %50405 = urem i32 %50404, 4096
  %50406 = getelementptr i8, i8 addrspace(1)* %4, i32 %50405
  %50407 = load i8, i8 addrspace(1)* %50406, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50406, align 1, !nosanitize !3
  store i32 365, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50408 = sub i64 %50400, 392
  store i64 %50408, i64* %remaing_gas, align 4
  %50409 = alloca i256, align 8
  store i256 15, i256* %50409, align 4
  %50410 = alloca i256, align 8
  call void @__device_sload(i256* %50409, i256* %50410)
  %50411 = call i32 @__hashword(i256* %50409)
  %50412 = load i32, i32* %5, align 4
  %50413 = icmp eq i32 %50411, %50412
  %50414 = or i1 false, %50413
  %50415 = load i32, i32* %6, align 4
  %50416 = icmp eq i32 %50411, %50415
  %50417 = or i1 %50414, %50416
  %50418 = load i32, i32* %7, align 4
  %50419 = icmp eq i32 %50411, %50418
  %50420 = or i1 %50417, %50419
  %50421 = load i32, i32* %8, align 4
  %50422 = icmp eq i32 %50411, %50421
  %50423 = or i1 %50420, %50422
  %50424 = load i32, i32* %9, align 4
  %50425 = icmp eq i32 %50411, %50424
  %50426 = or i1 %50423, %50425
  %50427 = load i32, i32* %10, align 4
  %50428 = icmp eq i32 %50411, %50427
  %50429 = or i1 %50426, %50428
  %50430 = load i32, i32* %11, align 4
  %50431 = icmp eq i32 %50411, %50430
  %50432 = or i1 %50429, %50431
  %50433 = load i32, i32* %12, align 4
  %50434 = icmp eq i32 %50411, %50433
  %50435 = or i1 %50432, %50434
  %50436 = load i32, i32* %13, align 4
  %50437 = icmp eq i32 %50411, %50436
  %50438 = or i1 %50435, %50437
  %50439 = load i32, i32* %14, align 4
  %50440 = icmp eq i32 %50411, %50439
  %50441 = or i1 %50438, %50440
  %50442 = load i32, i32* %15, align 4
  %50443 = icmp eq i32 %50411, %50442
  %50444 = or i1 %50441, %50443
  %50445 = load i32, i32* %16, align 4
  %50446 = icmp eq i32 %50411, %50445
  %50447 = or i1 %50444, %50446
  %50448 = load i32, i32* %17, align 4
  %50449 = icmp eq i32 %50411, %50448
  %50450 = or i1 %50447, %50449
  %50451 = load i32, i32* %18, align 4
  %50452 = icmp eq i32 %50411, %50451
  %50453 = or i1 %50450, %50452
  %50454 = load i32, i32* %19, align 4
  %50455 = icmp eq i32 %50411, %50454
  %50456 = or i1 %50453, %50455
  %50457 = load i32, i32* %20, align 4
  %50458 = icmp eq i32 %50411, %50457
  %50459 = or i1 %50456, %50458
  %50460 = load i32, i32* %21, align 4
  %50461 = icmp eq i32 %50411, %50460
  %50462 = or i1 %50459, %50461
  %50463 = load i32, i32* %22, align 4
  %50464 = icmp eq i32 %50411, %50463
  %50465 = or i1 %50462, %50464
  %50466 = load i32, i32* %23, align 4
  %50467 = icmp eq i32 %50411, %50466
  %50468 = or i1 %50465, %50467
  %50469 = load i32, i32* %24, align 4
  %50470 = icmp eq i32 %50411, %50469
  %50471 = or i1 %50468, %50470
  %50472 = load i32, i32* %25, align 4
  %50473 = icmp eq i32 %50411, %50472
  %50474 = or i1 %50471, %50473
  %50475 = load i32, i32* %26, align 4
  %50476 = icmp eq i32 %50411, %50475
  %50477 = or i1 %50474, %50476
  %50478 = load i32, i32* %27, align 4
  %50479 = icmp eq i32 %50411, %50478
  %50480 = or i1 %50477, %50479
  %50481 = load i32, i32* %28, align 4
  %50482 = icmp eq i32 %50411, %50481
  %50483 = or i1 %50480, %50482
  %50484 = load i32, i32* %29, align 4
  %50485 = icmp eq i32 %50411, %50484
  %50486 = or i1 %50483, %50485
  %50487 = load i32, i32* %30, align 4
  %50488 = icmp eq i32 %50411, %50487
  %50489 = or i1 %50486, %50488
  %50490 = load i32, i32* %31, align 4
  %50491 = icmp eq i32 %50411, %50490
  %50492 = or i1 %50489, %50491
  %50493 = load i32, i32* %32, align 4
  %50494 = icmp eq i32 %50411, %50493
  %50495 = or i1 %50492, %50494
  %50496 = load i32, i32* %33, align 4
  %50497 = icmp eq i32 %50411, %50496
  %50498 = or i1 %50495, %50497
  %50499 = load i32, i32* %34, align 4
  %50500 = icmp eq i32 %50411, %50499
  %50501 = or i1 %50498, %50500
  %50502 = load i32, i32* %35, align 4
  %50503 = icmp eq i32 %50411, %50502
  %50504 = or i1 %50501, %50503
  %50505 = load i32, i32* %36, align 4
  %50506 = icmp eq i32 %50411, %50505
  %50507 = or i1 %50504, %50506
  %50508 = load i32, i32* %37, align 4
  %50509 = icmp eq i32 %50411, %50508
  %50510 = or i1 %50507, %50509
  %50511 = load i32, i32* %38, align 4
  %50512 = icmp eq i32 %50411, %50511
  %50513 = or i1 %50510, %50512
  %50514 = load i32, i32* %39, align 4
  %50515 = icmp eq i32 %50411, %50514
  %50516 = or i1 %50513, %50515
  %50517 = load i32, i32* %40, align 4
  %50518 = icmp eq i32 %50411, %50517
  %50519 = or i1 %50516, %50518
  %50520 = load i32, i32* %41, align 4
  %50521 = icmp eq i32 %50411, %50520
  %50522 = or i1 %50519, %50521
  %50523 = load i32, i32* %42, align 4
  %50524 = icmp eq i32 %50411, %50523
  %50525 = or i1 %50522, %50524
  %50526 = load i32, i32* %43, align 4
  %50527 = icmp eq i32 %50411, %50526
  %50528 = or i1 %50525, %50527
  %50529 = load i32, i32* %44, align 4
  %50530 = icmp eq i32 %50411, %50529
  %50531 = or i1 %50528, %50530
  %50532 = load i32, i32* %45, align 4
  %50533 = icmp eq i32 %50411, %50532
  %50534 = or i1 %50531, %50533
  %50535 = load i32, i32* %46, align 4
  %50536 = icmp eq i32 %50411, %50535
  %50537 = or i1 %50534, %50536
  %50538 = load i32, i32* %47, align 4
  %50539 = icmp eq i32 %50411, %50538
  %50540 = or i1 %50537, %50539
  %50541 = load i32, i32* %48, align 4
  %50542 = icmp eq i32 %50411, %50541
  %50543 = or i1 %50540, %50542
  %50544 = load i32, i32* %49, align 4
  %50545 = icmp eq i32 %50411, %50544
  %50546 = or i1 %50543, %50545
  %50547 = load i32, i32* %50, align 4
  %50548 = icmp eq i32 %50411, %50547
  %50549 = or i1 %50546, %50548
  %50550 = load i32, i32* %51, align 4
  %50551 = icmp eq i32 %50411, %50550
  %50552 = or i1 %50549, %50551
  %50553 = load i32, i32* %52, align 4
  %50554 = icmp eq i32 %50411, %50553
  %50555 = or i1 %50552, %50554
  %50556 = load i32, i32* %53, align 4
  %50557 = icmp eq i32 %50411, %50556
  %50558 = or i1 %50555, %50557
  %50559 = load i32, i32* %54, align 4
  %50560 = icmp eq i32 %50411, %50559
  %50561 = or i1 %50558, %50560
  %50562 = load i32, i32* %55, align 4
  %50563 = icmp eq i32 %50411, %50562
  %50564 = or i1 %50561, %50563
  %50565 = load i32, i32* %56, align 4
  %50566 = icmp eq i32 %50411, %50565
  %50567 = or i1 %50564, %50566
  %50568 = load i32, i32* %57, align 4
  %50569 = icmp eq i32 %50411, %50568
  %50570 = or i1 %50567, %50569
  %50571 = load i32, i32* %58, align 4
  %50572 = icmp eq i32 %50411, %50571
  %50573 = or i1 %50570, %50572
  %50574 = load i32, i32* %59, align 4
  %50575 = icmp eq i32 %50411, %50574
  %50576 = or i1 %50573, %50575
  %50577 = load i32, i32* %60, align 4
  %50578 = icmp eq i32 %50411, %50577
  %50579 = or i1 %50576, %50578
  %50580 = load i32, i32* %61, align 4
  %50581 = icmp eq i32 %50411, %50580
  %50582 = or i1 %50579, %50581
  %50583 = load i32, i32* %62, align 4
  %50584 = icmp eq i32 %50411, %50583
  %50585 = or i1 %50582, %50584
  %50586 = getelementptr i8, i8 addrspace(1)* %4, i32 185
  %50587 = zext i1 %50585 to i8
  store i8 %50587, i8 addrspace(1)* %50586, align 1, !nosanitize !3
  %50588 = load i256, i256* %50410, align 4
  %50589 = alloca i256, align 8
  store i256 %50588, i256* %50589, align 4
  %50590 = alloca i256, align 8
  store i256 1, i256* %50590, align 4
  %50591 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %50589, i256* %50590, i256* %50591), !pc !730, !intsan !6
  %50592 = load i256, i256* %50591, align 4
  %50593 = and i256 255, %50592
  %50594 = icmp eq i256 %50593, 0
  %50595 = icmp eq i1 %50594, false
  %50596 = trunc i256 17009 to i64
  %jump.check23 = icmp ne i1 %50595, false
  %50597 = load i64, i64* %STACK_DEP_PTR, align 4
  %50598 = add i64 %50597, 1
  store i64 %50598, i64* %STACK_DEP_PTR, align 4
  %50599 = load i64, i64* %STACK_DEP_PTR, align 4
  %50600 = getelementptr i256, i256* %STACK, i64 %50599
  store i256 0, i256* %50600, align 4
  %50601 = load i64, i64* %STACK_DEP_PTR, align 4
  %50602 = add i64 %50601, 1
  store i64 %50602, i64* %STACK_DEP_PTR, align 4
  %50603 = load i64, i64* %STACK_DEP_PTR, align 4
  %50604 = getelementptr i256, i256* %STACK, i64 %50603
  store i256 0, i256* %50604, align 4
  %50605 = load i64, i64* %STACK_DEP_PTR, align 4
  %50606 = add i64 %50605, 1
  store i64 %50606, i64* %STACK_DEP_PTR, align 4
  %50607 = load i64, i64* %STACK_DEP_PTR, align 4
  %50608 = getelementptr i256, i256* %STACK, i64 %50607
  store i256 0, i256* %50608, align 4
  %50609 = load i64, i64* %STACK_DEP_PTR, align 4
  %50610 = add i64 %50609, 1
  store i64 %50610, i64* %STACK_DEP_PTR, align 4
  %50611 = load i64, i64* %STACK_DEP_PTR, align 4
  %50612 = getelementptr i256, i256* %STACK, i64 %50611
  store i256 0, i256* %50612, align 4
  %50613 = load i64, i64* %STACK_DEP_PTR, align 4
  %50614 = add i64 %50613, 1
  store i64 %50614, i64* %STACK_DEP_PTR, align 4
  %50615 = load i64, i64* %STACK_DEP_PTR, align 4
  %50616 = getelementptr i256, i256* %STACK, i64 %50615
  store i256 0, i256* %50616, align 4
  br i1 %jump.check23, label %.17009, label %.16479, !EVMBB !4

.16479:                                           ; preds = %50402
  %50617 = load i64, i64* %STACK_DEP_PTR, align 4
  %50618 = sub i64 %50617, 4
  store i64 %50618, i64* %STACK_DEP_PTR, align 4
  %50619 = load i64, i64* %STACK_DEP_PTR, align 4
  %50620 = add i64 %50619, 1
  store i64 %50620, i64* %STACK_DEP_PTR, align 4
  %50621 = load i64, i64* %STACK_DEP_PTR, align 4
  %50622 = getelementptr i256, i256* %STACK, i64 %50621
  store i256 1, i256* %50622, align 4
  %50623 = load i64, i64* %STACK_DEP_PTR, align 4
  %50624 = add i64 %50623, 1
  store i64 %50624, i64* %STACK_DEP_PTR, align 4
  %50625 = load i64, i64* %STACK_DEP_PTR, align 4
  %50626 = getelementptr i256, i256* %STACK, i64 %50625
  store i256 0, i256* %50626, align 4
  %50627 = load i64, i64* %STACK_DEP_PTR, align 4
  %50628 = add i64 %50627, 1
  store i64 %50628, i64* %STACK_DEP_PTR, align 4
  %50629 = load i64, i64* %STACK_DEP_PTR, align 4
  %50630 = getelementptr i256, i256* %STACK, i64 %50629
  store i256 0, i256* %50630, align 4
  %50631 = load i64, i64* %STACK_DEP_PTR, align 4
  %50632 = add i64 %50631, 1
  store i64 %50632, i64* %STACK_DEP_PTR, align 4
  %50633 = load i64, i64* %STACK_DEP_PTR, align 4
  %50634 = getelementptr i256, i256* %STACK, i64 %50633
  store i256 0, i256* %50634, align 4
  br label %.16483

.16483:                                           ; preds = %52839, %.16479, %JumpTable
  %50635 = load i64, i64* %remaing_gas, align 4
  %50636 = icmp ugt i64 480, %50635
  br i1 %50636, label %Abort, label %50637

50637:                                            ; preds = %.16483
  %50638 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50639 = xor i32 %50638, 3916
  %50640 = urem i32 %50639, 4096
  %50641 = getelementptr i8, i8 addrspace(1)* %4, i32 %50640
  %50642 = load i8, i8 addrspace(1)* %50641, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50641, align 1, !nosanitize !3
  store i32 1958, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50643 = sub i64 %50635, 480
  store i64 %50643, i64* %remaing_gas, align 4
  %50644 = load i64, i64* %STACK_DEP_PTR, align 4
  %50645 = getelementptr i256, i256* %STACK, i64 %50644
  %50646 = load i256, i256* %50645, align 4
  %50647 = load i64, i64* %STACK_DEP_PTR, align 4
  %50648 = sub i64 %50647, 1
  store i64 %50648, i64* %STACK_DEP_PTR, align 4
  %50649 = load i64, i64* %STACK_DEP_PTR, align 4
  %50650 = getelementptr i256, i256* %STACK, i64 %50649
  %50651 = load i256, i256* %50650, align 4
  %50652 = load i64, i64* %STACK_DEP_PTR, align 4
  %50653 = sub i64 %50652, 1
  store i64 %50653, i64* %STACK_DEP_PTR, align 4
  %50654 = load i64, i64* %STACK_DEP_PTR, align 4
  %50655 = getelementptr i256, i256* %STACK, i64 %50654
  %50656 = load i256, i256* %50655, align 4
  %50657 = load i64, i64* %STACK_DEP_PTR, align 4
  %50658 = sub i64 %50657, 1
  store i64 %50658, i64* %STACK_DEP_PTR, align 4
  %50659 = load i64, i64* %STACK_DEP_PTR, align 4
  %50660 = getelementptr i256, i256* %STACK, i64 %50659
  %50661 = load i256, i256* %50660, align 4
  %50662 = load i64, i64* %STACK_DEP_PTR, align 4
  %50663 = sub i64 %50662, 1
  store i64 %50663, i64* %STACK_DEP_PTR, align 4
  %50664 = alloca i256, align 8
  store i256 5, i256* %50664, align 4
  %50665 = alloca i256, align 8
  call void @__device_sload(i256* %50664, i256* %50665)
  %50666 = call i32 @__hashword(i256* %50664)
  %50667 = load i32, i32* %5, align 4
  %50668 = icmp eq i32 %50666, %50667
  %50669 = or i1 false, %50668
  %50670 = load i32, i32* %6, align 4
  %50671 = icmp eq i32 %50666, %50670
  %50672 = or i1 %50669, %50671
  %50673 = load i32, i32* %7, align 4
  %50674 = icmp eq i32 %50666, %50673
  %50675 = or i1 %50672, %50674
  %50676 = load i32, i32* %8, align 4
  %50677 = icmp eq i32 %50666, %50676
  %50678 = or i1 %50675, %50677
  %50679 = load i32, i32* %9, align 4
  %50680 = icmp eq i32 %50666, %50679
  %50681 = or i1 %50678, %50680
  %50682 = load i32, i32* %10, align 4
  %50683 = icmp eq i32 %50666, %50682
  %50684 = or i1 %50681, %50683
  %50685 = load i32, i32* %11, align 4
  %50686 = icmp eq i32 %50666, %50685
  %50687 = or i1 %50684, %50686
  %50688 = load i32, i32* %12, align 4
  %50689 = icmp eq i32 %50666, %50688
  %50690 = or i1 %50687, %50689
  %50691 = load i32, i32* %13, align 4
  %50692 = icmp eq i32 %50666, %50691
  %50693 = or i1 %50690, %50692
  %50694 = load i32, i32* %14, align 4
  %50695 = icmp eq i32 %50666, %50694
  %50696 = or i1 %50693, %50695
  %50697 = load i32, i32* %15, align 4
  %50698 = icmp eq i32 %50666, %50697
  %50699 = or i1 %50696, %50698
  %50700 = load i32, i32* %16, align 4
  %50701 = icmp eq i32 %50666, %50700
  %50702 = or i1 %50699, %50701
  %50703 = load i32, i32* %17, align 4
  %50704 = icmp eq i32 %50666, %50703
  %50705 = or i1 %50702, %50704
  %50706 = load i32, i32* %18, align 4
  %50707 = icmp eq i32 %50666, %50706
  %50708 = or i1 %50705, %50707
  %50709 = load i32, i32* %19, align 4
  %50710 = icmp eq i32 %50666, %50709
  %50711 = or i1 %50708, %50710
  %50712 = load i32, i32* %20, align 4
  %50713 = icmp eq i32 %50666, %50712
  %50714 = or i1 %50711, %50713
  %50715 = load i32, i32* %21, align 4
  %50716 = icmp eq i32 %50666, %50715
  %50717 = or i1 %50714, %50716
  %50718 = load i32, i32* %22, align 4
  %50719 = icmp eq i32 %50666, %50718
  %50720 = or i1 %50717, %50719
  %50721 = load i32, i32* %23, align 4
  %50722 = icmp eq i32 %50666, %50721
  %50723 = or i1 %50720, %50722
  %50724 = load i32, i32* %24, align 4
  %50725 = icmp eq i32 %50666, %50724
  %50726 = or i1 %50723, %50725
  %50727 = load i32, i32* %25, align 4
  %50728 = icmp eq i32 %50666, %50727
  %50729 = or i1 %50726, %50728
  %50730 = load i32, i32* %26, align 4
  %50731 = icmp eq i32 %50666, %50730
  %50732 = or i1 %50729, %50731
  %50733 = load i32, i32* %27, align 4
  %50734 = icmp eq i32 %50666, %50733
  %50735 = or i1 %50732, %50734
  %50736 = load i32, i32* %28, align 4
  %50737 = icmp eq i32 %50666, %50736
  %50738 = or i1 %50735, %50737
  %50739 = load i32, i32* %29, align 4
  %50740 = icmp eq i32 %50666, %50739
  %50741 = or i1 %50738, %50740
  %50742 = load i32, i32* %30, align 4
  %50743 = icmp eq i32 %50666, %50742
  %50744 = or i1 %50741, %50743
  %50745 = load i32, i32* %31, align 4
  %50746 = icmp eq i32 %50666, %50745
  %50747 = or i1 %50744, %50746
  %50748 = load i32, i32* %32, align 4
  %50749 = icmp eq i32 %50666, %50748
  %50750 = or i1 %50747, %50749
  %50751 = load i32, i32* %33, align 4
  %50752 = icmp eq i32 %50666, %50751
  %50753 = or i1 %50750, %50752
  %50754 = load i32, i32* %34, align 4
  %50755 = icmp eq i32 %50666, %50754
  %50756 = or i1 %50753, %50755
  %50757 = load i32, i32* %35, align 4
  %50758 = icmp eq i32 %50666, %50757
  %50759 = or i1 %50756, %50758
  %50760 = load i32, i32* %36, align 4
  %50761 = icmp eq i32 %50666, %50760
  %50762 = or i1 %50759, %50761
  %50763 = load i32, i32* %37, align 4
  %50764 = icmp eq i32 %50666, %50763
  %50765 = or i1 %50762, %50764
  %50766 = load i32, i32* %38, align 4
  %50767 = icmp eq i32 %50666, %50766
  %50768 = or i1 %50765, %50767
  %50769 = load i32, i32* %39, align 4
  %50770 = icmp eq i32 %50666, %50769
  %50771 = or i1 %50768, %50770
  %50772 = load i32, i32* %40, align 4
  %50773 = icmp eq i32 %50666, %50772
  %50774 = or i1 %50771, %50773
  %50775 = load i32, i32* %41, align 4
  %50776 = icmp eq i32 %50666, %50775
  %50777 = or i1 %50774, %50776
  %50778 = load i32, i32* %42, align 4
  %50779 = icmp eq i32 %50666, %50778
  %50780 = or i1 %50777, %50779
  %50781 = load i32, i32* %43, align 4
  %50782 = icmp eq i32 %50666, %50781
  %50783 = or i1 %50780, %50782
  %50784 = load i32, i32* %44, align 4
  %50785 = icmp eq i32 %50666, %50784
  %50786 = or i1 %50783, %50785
  %50787 = load i32, i32* %45, align 4
  %50788 = icmp eq i32 %50666, %50787
  %50789 = or i1 %50786, %50788
  %50790 = load i32, i32* %46, align 4
  %50791 = icmp eq i32 %50666, %50790
  %50792 = or i1 %50789, %50791
  %50793 = load i32, i32* %47, align 4
  %50794 = icmp eq i32 %50666, %50793
  %50795 = or i1 %50792, %50794
  %50796 = load i32, i32* %48, align 4
  %50797 = icmp eq i32 %50666, %50796
  %50798 = or i1 %50795, %50797
  %50799 = load i32, i32* %49, align 4
  %50800 = icmp eq i32 %50666, %50799
  %50801 = or i1 %50798, %50800
  %50802 = load i32, i32* %50, align 4
  %50803 = icmp eq i32 %50666, %50802
  %50804 = or i1 %50801, %50803
  %50805 = load i32, i32* %51, align 4
  %50806 = icmp eq i32 %50666, %50805
  %50807 = or i1 %50804, %50806
  %50808 = load i32, i32* %52, align 4
  %50809 = icmp eq i32 %50666, %50808
  %50810 = or i1 %50807, %50809
  %50811 = load i32, i32* %53, align 4
  %50812 = icmp eq i32 %50666, %50811
  %50813 = or i1 %50810, %50812
  %50814 = load i32, i32* %54, align 4
  %50815 = icmp eq i32 %50666, %50814
  %50816 = or i1 %50813, %50815
  %50817 = load i32, i32* %55, align 4
  %50818 = icmp eq i32 %50666, %50817
  %50819 = or i1 %50816, %50818
  %50820 = load i32, i32* %56, align 4
  %50821 = icmp eq i32 %50666, %50820
  %50822 = or i1 %50819, %50821
  %50823 = load i32, i32* %57, align 4
  %50824 = icmp eq i32 %50666, %50823
  %50825 = or i1 %50822, %50824
  %50826 = load i32, i32* %58, align 4
  %50827 = icmp eq i32 %50666, %50826
  %50828 = or i1 %50825, %50827
  %50829 = load i32, i32* %59, align 4
  %50830 = icmp eq i32 %50666, %50829
  %50831 = or i1 %50828, %50830
  %50832 = load i32, i32* %60, align 4
  %50833 = icmp eq i32 %50666, %50832
  %50834 = or i1 %50831, %50833
  %50835 = load i32, i32* %61, align 4
  %50836 = icmp eq i32 %50666, %50835
  %50837 = or i1 %50834, %50836
  %50838 = load i32, i32* %62, align 4
  %50839 = icmp eq i32 %50666, %50838
  %50840 = or i1 %50837, %50839
  %50841 = getelementptr i8, i8 addrspace(1)* %4, i32 186
  %50842 = zext i1 %50840 to i8
  store i8 %50842, i8 addrspace(1)* %50841, align 1, !nosanitize !3
  %50843 = load i256, i256* %50665, align 4
  %50844 = icmp ugt i256 %50661, %50843
  %50845 = icmp eq i1 %50844, false
  %50846 = icmp eq i1 %50845, false
  %50847 = trunc i256 16962 to i64
  %jump.check228 = icmp ne i1 %50846, false
  %50848 = load i64, i64* %STACK_DEP_PTR, align 4
  %50849 = add i64 %50848, 1
  store i64 %50849, i64* %STACK_DEP_PTR, align 4
  %50850 = load i64, i64* %STACK_DEP_PTR, align 4
  %50851 = getelementptr i256, i256* %STACK, i64 %50850
  store i256 %50661, i256* %50851, align 4
  %50852 = load i64, i64* %STACK_DEP_PTR, align 4
  %50853 = add i64 %50852, 1
  store i64 %50853, i64* %STACK_DEP_PTR, align 4
  %50854 = load i64, i64* %STACK_DEP_PTR, align 4
  %50855 = getelementptr i256, i256* %STACK, i64 %50854
  store i256 %50656, i256* %50855, align 4
  %50856 = load i64, i64* %STACK_DEP_PTR, align 4
  %50857 = add i64 %50856, 1
  store i64 %50857, i64* %STACK_DEP_PTR, align 4
  %50858 = load i64, i64* %STACK_DEP_PTR, align 4
  %50859 = getelementptr i256, i256* %STACK, i64 %50858
  store i256 %50651, i256* %50859, align 4
  %50860 = load i64, i64* %STACK_DEP_PTR, align 4
  %50861 = add i64 %50860, 1
  store i64 %50861, i64* %STACK_DEP_PTR, align 4
  %50862 = load i64, i64* %STACK_DEP_PTR, align 4
  %50863 = getelementptr i256, i256* %STACK, i64 %50862
  store i256 %50646, i256* %50863, align 4
  br i1 %jump.check228, label %.16962, label %.16495, !EVMBB !4

.16495:                                           ; preds = %50637
  %50864 = load i64, i64* %remaing_gas, align 4
  %50865 = icmp ugt i64 768, %50864
  br i1 %50865, label %Abort, label %50866

50866:                                            ; preds = %.16495
  %50867 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50868 = xor i32 %50867, 215
  %50869 = urem i32 %50868, 4096
  %50870 = getelementptr i8, i8 addrspace(1)* %4, i32 %50869
  %50871 = load i8, i8 addrspace(1)* %50870, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %50870, align 1, !nosanitize !3
  store i32 107, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %50872 = sub i64 %50864, 768
  store i64 %50872, i64* %remaing_gas, align 4
  %50873 = load i64, i64* %STACK_DEP_PTR, align 4
  %50874 = getelementptr i256, i256* %STACK, i64 %50873
  %50875 = load i256, i256* %50874, align 4
  %50876 = load i64, i64* %STACK_DEP_PTR, align 4
  %50877 = sub i64 %50876, 1
  store i64 %50877, i64* %STACK_DEP_PTR, align 4
  %50878 = load i64, i64* %STACK_DEP_PTR, align 4
  %50879 = getelementptr i256, i256* %STACK, i64 %50878
  %50880 = load i256, i256* %50879, align 4
  %50881 = load i64, i64* %STACK_DEP_PTR, align 4
  %50882 = sub i64 %50881, 1
  store i64 %50882, i64* %STACK_DEP_PTR, align 4
  %50883 = load i64, i64* %STACK_DEP_PTR, align 4
  %50884 = getelementptr i256, i256* %STACK, i64 %50883
  %50885 = load i256, i256* %50884, align 4
  %50886 = load i64, i64* %STACK_DEP_PTR, align 4
  %50887 = sub i64 %50886, 1
  store i64 %50887, i64* %STACK_DEP_PTR, align 4
  %50888 = load i64, i64* %STACK_DEP_PTR, align 4
  %50889 = getelementptr i256, i256* %STACK, i64 %50888
  %50890 = load i256, i256* %50889, align 4
  %50891 = load i64, i64* %STACK_DEP_PTR, align 4
  %50892 = sub i64 %50891, 1
  store i64 %50892, i64* %STACK_DEP_PTR, align 4
  %50893 = trunc i256 0 to i64
  %50894 = alloca i256, align 8
  store i256 %50890, i256* %50894, align 4
  %50895 = bitcast i256* %50894 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %50893, i8* %50895, i64 32)
  %50896 = add i256 32, 0, !pc !731, !intsan !10
  %50897 = trunc i256 %50896 to i64
  %50898 = alloca i256, align 8
  store i256 4, i256* %50898, align 4
  %50899 = bitcast i256* %50898 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %50897, i8* %50899, i64 32)
  %50900 = add i256 32, %50896, !pc !732, !intsan !10
  %50901 = trunc i256 0 to i32
  %50902 = trunc i256 %50900 to i32
  %50903 = getelementptr inbounds i8, i8* %MEMORY, i32 %50901
  %50904 = alloca i256, align 8
  %50905 = bitcast i256* %50904 to i8*
  call void @__device_sha3(i8* %50903, i32 %50902, i8* %50905)
  %50906 = load i256, i256* %50904, align 4
  %50907 = add i256 0, %50906, !pc !733, !intsan !10
  %50908 = alloca i256, align 8
  store i256 %50907, i256* %50908, align 4
  %50909 = alloca i256, align 8
  call void @__device_sload(i256* %50908, i256* %50909)
  %50910 = call i32 @__hashword(i256* %50908)
  %50911 = load i32, i32* %5, align 4
  %50912 = icmp eq i32 %50910, %50911
  %50913 = or i1 false, %50912
  %50914 = load i32, i32* %6, align 4
  %50915 = icmp eq i32 %50910, %50914
  %50916 = or i1 %50913, %50915
  %50917 = load i32, i32* %7, align 4
  %50918 = icmp eq i32 %50910, %50917
  %50919 = or i1 %50916, %50918
  %50920 = load i32, i32* %8, align 4
  %50921 = icmp eq i32 %50910, %50920
  %50922 = or i1 %50919, %50921
  %50923 = load i32, i32* %9, align 4
  %50924 = icmp eq i32 %50910, %50923
  %50925 = or i1 %50922, %50924
  %50926 = load i32, i32* %10, align 4
  %50927 = icmp eq i32 %50910, %50926
  %50928 = or i1 %50925, %50927
  %50929 = load i32, i32* %11, align 4
  %50930 = icmp eq i32 %50910, %50929
  %50931 = or i1 %50928, %50930
  %50932 = load i32, i32* %12, align 4
  %50933 = icmp eq i32 %50910, %50932
  %50934 = or i1 %50931, %50933
  %50935 = load i32, i32* %13, align 4
  %50936 = icmp eq i32 %50910, %50935
  %50937 = or i1 %50934, %50936
  %50938 = load i32, i32* %14, align 4
  %50939 = icmp eq i32 %50910, %50938
  %50940 = or i1 %50937, %50939
  %50941 = load i32, i32* %15, align 4
  %50942 = icmp eq i32 %50910, %50941
  %50943 = or i1 %50940, %50942
  %50944 = load i32, i32* %16, align 4
  %50945 = icmp eq i32 %50910, %50944
  %50946 = or i1 %50943, %50945
  %50947 = load i32, i32* %17, align 4
  %50948 = icmp eq i32 %50910, %50947
  %50949 = or i1 %50946, %50948
  %50950 = load i32, i32* %18, align 4
  %50951 = icmp eq i32 %50910, %50950
  %50952 = or i1 %50949, %50951
  %50953 = load i32, i32* %19, align 4
  %50954 = icmp eq i32 %50910, %50953
  %50955 = or i1 %50952, %50954
  %50956 = load i32, i32* %20, align 4
  %50957 = icmp eq i32 %50910, %50956
  %50958 = or i1 %50955, %50957
  %50959 = load i32, i32* %21, align 4
  %50960 = icmp eq i32 %50910, %50959
  %50961 = or i1 %50958, %50960
  %50962 = load i32, i32* %22, align 4
  %50963 = icmp eq i32 %50910, %50962
  %50964 = or i1 %50961, %50963
  %50965 = load i32, i32* %23, align 4
  %50966 = icmp eq i32 %50910, %50965
  %50967 = or i1 %50964, %50966
  %50968 = load i32, i32* %24, align 4
  %50969 = icmp eq i32 %50910, %50968
  %50970 = or i1 %50967, %50969
  %50971 = load i32, i32* %25, align 4
  %50972 = icmp eq i32 %50910, %50971
  %50973 = or i1 %50970, %50972
  %50974 = load i32, i32* %26, align 4
  %50975 = icmp eq i32 %50910, %50974
  %50976 = or i1 %50973, %50975
  %50977 = load i32, i32* %27, align 4
  %50978 = icmp eq i32 %50910, %50977
  %50979 = or i1 %50976, %50978
  %50980 = load i32, i32* %28, align 4
  %50981 = icmp eq i32 %50910, %50980
  %50982 = or i1 %50979, %50981
  %50983 = load i32, i32* %29, align 4
  %50984 = icmp eq i32 %50910, %50983
  %50985 = or i1 %50982, %50984
  %50986 = load i32, i32* %30, align 4
  %50987 = icmp eq i32 %50910, %50986
  %50988 = or i1 %50985, %50987
  %50989 = load i32, i32* %31, align 4
  %50990 = icmp eq i32 %50910, %50989
  %50991 = or i1 %50988, %50990
  %50992 = load i32, i32* %32, align 4
  %50993 = icmp eq i32 %50910, %50992
  %50994 = or i1 %50991, %50993
  %50995 = load i32, i32* %33, align 4
  %50996 = icmp eq i32 %50910, %50995
  %50997 = or i1 %50994, %50996
  %50998 = load i32, i32* %34, align 4
  %50999 = icmp eq i32 %50910, %50998
  %51000 = or i1 %50997, %50999
  %51001 = load i32, i32* %35, align 4
  %51002 = icmp eq i32 %50910, %51001
  %51003 = or i1 %51000, %51002
  %51004 = load i32, i32* %36, align 4
  %51005 = icmp eq i32 %50910, %51004
  %51006 = or i1 %51003, %51005
  %51007 = load i32, i32* %37, align 4
  %51008 = icmp eq i32 %50910, %51007
  %51009 = or i1 %51006, %51008
  %51010 = load i32, i32* %38, align 4
  %51011 = icmp eq i32 %50910, %51010
  %51012 = or i1 %51009, %51011
  %51013 = load i32, i32* %39, align 4
  %51014 = icmp eq i32 %50910, %51013
  %51015 = or i1 %51012, %51014
  %51016 = load i32, i32* %40, align 4
  %51017 = icmp eq i32 %50910, %51016
  %51018 = or i1 %51015, %51017
  %51019 = load i32, i32* %41, align 4
  %51020 = icmp eq i32 %50910, %51019
  %51021 = or i1 %51018, %51020
  %51022 = load i32, i32* %42, align 4
  %51023 = icmp eq i32 %50910, %51022
  %51024 = or i1 %51021, %51023
  %51025 = load i32, i32* %43, align 4
  %51026 = icmp eq i32 %50910, %51025
  %51027 = or i1 %51024, %51026
  %51028 = load i32, i32* %44, align 4
  %51029 = icmp eq i32 %50910, %51028
  %51030 = or i1 %51027, %51029
  %51031 = load i32, i32* %45, align 4
  %51032 = icmp eq i32 %50910, %51031
  %51033 = or i1 %51030, %51032
  %51034 = load i32, i32* %46, align 4
  %51035 = icmp eq i32 %50910, %51034
  %51036 = or i1 %51033, %51035
  %51037 = load i32, i32* %47, align 4
  %51038 = icmp eq i32 %50910, %51037
  %51039 = or i1 %51036, %51038
  %51040 = load i32, i32* %48, align 4
  %51041 = icmp eq i32 %50910, %51040
  %51042 = or i1 %51039, %51041
  %51043 = load i32, i32* %49, align 4
  %51044 = icmp eq i32 %50910, %51043
  %51045 = or i1 %51042, %51044
  %51046 = load i32, i32* %50, align 4
  %51047 = icmp eq i32 %50910, %51046
  %51048 = or i1 %51045, %51047
  %51049 = load i32, i32* %51, align 4
  %51050 = icmp eq i32 %50910, %51049
  %51051 = or i1 %51048, %51050
  %51052 = load i32, i32* %52, align 4
  %51053 = icmp eq i32 %50910, %51052
  %51054 = or i1 %51051, %51053
  %51055 = load i32, i32* %53, align 4
  %51056 = icmp eq i32 %50910, %51055
  %51057 = or i1 %51054, %51056
  %51058 = load i32, i32* %54, align 4
  %51059 = icmp eq i32 %50910, %51058
  %51060 = or i1 %51057, %51059
  %51061 = load i32, i32* %55, align 4
  %51062 = icmp eq i32 %50910, %51061
  %51063 = or i1 %51060, %51062
  %51064 = load i32, i32* %56, align 4
  %51065 = icmp eq i32 %50910, %51064
  %51066 = or i1 %51063, %51065
  %51067 = load i32, i32* %57, align 4
  %51068 = icmp eq i32 %50910, %51067
  %51069 = or i1 %51066, %51068
  %51070 = load i32, i32* %58, align 4
  %51071 = icmp eq i32 %50910, %51070
  %51072 = or i1 %51069, %51071
  %51073 = load i32, i32* %59, align 4
  %51074 = icmp eq i32 %50910, %51073
  %51075 = or i1 %51072, %51074
  %51076 = load i32, i32* %60, align 4
  %51077 = icmp eq i32 %50910, %51076
  %51078 = or i1 %51075, %51077
  %51079 = load i32, i32* %61, align 4
  %51080 = icmp eq i32 %50910, %51079
  %51081 = or i1 %51078, %51080
  %51082 = load i32, i32* %62, align 4
  %51083 = icmp eq i32 %50910, %51082
  %51084 = or i1 %51081, %51083
  %51085 = getelementptr i8, i8 addrspace(1)* %4, i32 187
  %51086 = zext i1 %51084 to i8
  store i8 %51086, i8 addrspace(1)* %51085, align 1, !nosanitize !3
  %51087 = load i256, i256* %50909, align 4
  %51088 = alloca i256, align 8
  store i256 %51087, i256* %51088, align 4
  %51089 = alloca i256, align 8
  store i256 1, i256* %51089, align 4
  %51090 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %51088, i256* %51089, i256* %51090), !pc !734, !intsan !6
  %51091 = load i256, i256* %51090, align 4
  %51092 = and i256 1461501637330902918203684832716283019655932542975, %51091
  %51093 = trunc i256 4443 to i64
  %51094 = load i64, i64* %STACK_DEP_PTR, align 4
  %51095 = add i64 %51094, 1
  store i64 %51095, i64* %STACK_DEP_PTR, align 4
  %51096 = load i64, i64* %STACK_DEP_PTR, align 4
  %51097 = getelementptr i256, i256* %STACK, i64 %51096
  store i256 %50890, i256* %51097, align 4
  %51098 = load i64, i64* %STACK_DEP_PTR, align 4
  %51099 = add i64 %51098, 1
  store i64 %51099, i64* %STACK_DEP_PTR, align 4
  %51100 = load i64, i64* %STACK_DEP_PTR, align 4
  %51101 = getelementptr i256, i256* %STACK, i64 %51100
  store i256 %51092, i256* %51101, align 4
  %51102 = load i64, i64* %STACK_DEP_PTR, align 4
  %51103 = add i64 %51102, 1
  store i64 %51103, i64* %STACK_DEP_PTR, align 4
  %51104 = load i64, i64* %STACK_DEP_PTR, align 4
  %51105 = getelementptr i256, i256* %STACK, i64 %51104
  store i256 %50880, i256* %51105, align 4
  %51106 = load i64, i64* %STACK_DEP_PTR, align 4
  %51107 = add i64 %51106, 1
  store i64 %51107, i64* %STACK_DEP_PTR, align 4
  %51108 = load i64, i64* %STACK_DEP_PTR, align 4
  %51109 = getelementptr i256, i256* %STACK, i64 %51108
  store i256 %50875, i256* %51109, align 4
  %51110 = load i64, i64* %STACK_DEP_PTR, align 4
  %51111 = add i64 %51110, 1
  store i64 %51111, i64* %STACK_DEP_PTR, align 4
  %51112 = load i64, i64* %STACK_DEP_PTR, align 4
  %51113 = getelementptr i256, i256* %STACK, i64 %51112
  store i256 16560, i256* %51113, align 4
  %51114 = load i64, i64* %STACK_DEP_PTR, align 4
  %51115 = add i64 %51114, 1
  store i64 %51115, i64* %STACK_DEP_PTR, align 4
  %51116 = load i64, i64* %STACK_DEP_PTR, align 4
  %51117 = getelementptr i256, i256* %STACK, i64 %51116
  store i256 %51092, i256* %51117, align 4
  br label %.4443, !EVMBB !4

.16560:                                           ; preds = %JumpTable
  %51118 = load i64, i64* %remaing_gas, align 4
  %51119 = icmp ugt i64 456, %51118
  br i1 %51119, label %Abort, label %51120

51120:                                            ; preds = %.16560
  %51121 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51122 = xor i32 %51121, 3946
  %51123 = urem i32 %51122, 4096
  %51124 = getelementptr i8, i8 addrspace(1)* %4, i32 %51123
  %51125 = load i8, i8 addrspace(1)* %51124, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %51124, align 1, !nosanitize !3
  store i32 1973, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51126 = sub i64 %51118, 456
  store i64 %51126, i64* %remaing_gas, align 4
  %51127 = load i64, i64* %STACK_DEP_PTR, align 4
  %51128 = getelementptr i256, i256* %STACK, i64 %51127
  %51129 = load i256, i256* %51128, align 4
  %51130 = load i64, i64* %STACK_DEP_PTR, align 4
  %51131 = sub i64 %51130, 1
  store i64 %51131, i64* %STACK_DEP_PTR, align 4
  %51132 = load i64, i64* %STACK_DEP_PTR, align 4
  %51133 = getelementptr i256, i256* %STACK, i64 %51132
  %51134 = load i256, i256* %51133, align 4
  %51135 = load i64, i64* %STACK_DEP_PTR, align 4
  %51136 = sub i64 %51135, 1
  store i64 %51136, i64* %STACK_DEP_PTR, align 4
  %51137 = load i64, i64* %STACK_DEP_PTR, align 4
  %51138 = getelementptr i256, i256* %STACK, i64 %51137
  %51139 = load i256, i256* %51138, align 4
  %51140 = load i64, i64* %STACK_DEP_PTR, align 4
  %51141 = sub i64 %51140, 1
  store i64 %51141, i64* %STACK_DEP_PTR, align 4
  %51142 = load i64, i64* %STACK_DEP_PTR, align 4
  %51143 = getelementptr i256, i256* %STACK, i64 %51142
  %51144 = load i256, i256* %51143, align 4
  %51145 = load i64, i64* %STACK_DEP_PTR, align 4
  %51146 = sub i64 %51145, 1
  store i64 %51146, i64* %STACK_DEP_PTR, align 4
  %51147 = trunc i256 4726 to i64
  %51148 = load i64, i64* %STACK_DEP_PTR, align 4
  %51149 = add i64 %51148, 1
  store i64 %51149, i64* %STACK_DEP_PTR, align 4
  %51150 = load i64, i64* %STACK_DEP_PTR, align 4
  %51151 = getelementptr i256, i256* %STACK, i64 %51150
  store i256 %51144, i256* %51151, align 4
  %51152 = load i64, i64* %STACK_DEP_PTR, align 4
  %51153 = add i64 %51152, 1
  store i64 %51153, i64* %STACK_DEP_PTR, align 4
  %51154 = load i64, i64* %STACK_DEP_PTR, align 4
  %51155 = getelementptr i256, i256* %STACK, i64 %51154
  store i256 %51129, i256* %51155, align 4
  %51156 = load i64, i64* %STACK_DEP_PTR, align 4
  %51157 = add i64 %51156, 1
  store i64 %51157, i64* %STACK_DEP_PTR, align 4
  %51158 = load i64, i64* %STACK_DEP_PTR, align 4
  %51159 = getelementptr i256, i256* %STACK, i64 %51158
  store i256 %51134, i256* %51159, align 4
  %51160 = load i64, i64* %STACK_DEP_PTR, align 4
  %51161 = add i64 %51160, 1
  store i64 %51161, i64* %STACK_DEP_PTR, align 4
  %51162 = load i64, i64* %STACK_DEP_PTR, align 4
  %51163 = getelementptr i256, i256* %STACK, i64 %51162
  store i256 16571, i256* %51163, align 4
  %51164 = load i64, i64* %STACK_DEP_PTR, align 4
  %51165 = add i64 %51164, 1
  store i64 %51165, i64* %STACK_DEP_PTR, align 4
  %51166 = load i64, i64* %STACK_DEP_PTR, align 4
  %51167 = getelementptr i256, i256* %STACK, i64 %51166
  store i256 %51144, i256* %51167, align 4
  br label %.4726, !EVMBB !4

.16571:                                           ; preds = %JumpTable
  %51168 = load i64, i64* %remaing_gas, align 4
  %51169 = icmp ugt i64 952, %51168
  br i1 %51169, label %Abort, label %51170

51170:                                            ; preds = %.16571
  %51171 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51172 = xor i32 %51171, 2073
  %51173 = urem i32 %51172, 4096
  %51174 = getelementptr i8, i8 addrspace(1)* %4, i32 %51173
  %51175 = load i8, i8 addrspace(1)* %51174, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %51174, align 1, !nosanitize !3
  store i32 1036, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51176 = sub i64 %51168, 952
  store i64 %51176, i64* %remaing_gas, align 4
  %51177 = load i64, i64* %STACK_DEP_PTR, align 4
  %51178 = getelementptr i256, i256* %STACK, i64 %51177
  %51179 = load i256, i256* %51178, align 4
  %51180 = load i64, i64* %STACK_DEP_PTR, align 4
  %51181 = sub i64 %51180, 1
  store i64 %51181, i64* %STACK_DEP_PTR, align 4
  %51182 = load i64, i64* %STACK_DEP_PTR, align 4
  %51183 = getelementptr i256, i256* %STACK, i64 %51182
  %51184 = load i256, i256* %51183, align 4
  %51185 = load i64, i64* %STACK_DEP_PTR, align 4
  %51186 = sub i64 %51185, 1
  store i64 %51186, i64* %STACK_DEP_PTR, align 4
  %51187 = load i64, i64* %STACK_DEP_PTR, align 4
  %51188 = getelementptr i256, i256* %STACK, i64 %51187
  %51189 = load i256, i256* %51188, align 4
  %51190 = load i64, i64* %STACK_DEP_PTR, align 4
  %51191 = sub i64 %51190, 1
  store i64 %51191, i64* %STACK_DEP_PTR, align 4
  %51192 = load i64, i64* %STACK_DEP_PTR, align 4
  %51193 = getelementptr i256, i256* %STACK, i64 %51192
  %51194 = load i256, i256* %51193, align 4
  %51195 = load i64, i64* %STACK_DEP_PTR, align 4
  %51196 = sub i64 %51195, 1
  store i64 %51196, i64* %STACK_DEP_PTR, align 4
  %51197 = load i64, i64* %STACK_DEP_PTR, align 4
  %51198 = getelementptr i256, i256* %STACK, i64 %51197
  %51199 = load i256, i256* %51198, align 4
  %51200 = load i64, i64* %STACK_DEP_PTR, align 4
  %51201 = sub i64 %51200, 1
  store i64 %51201, i64* %STACK_DEP_PTR, align 4
  %51202 = trunc i256 0 to i64
  %51203 = alloca i256, align 8
  store i256 %51199, i256* %51203, align 4
  %51204 = bitcast i256* %51203 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51202, i8* %51204, i64 32)
  %51205 = add i256 32, 0, !pc !735, !intsan !10
  %51206 = trunc i256 %51205 to i64
  %51207 = alloca i256, align 8
  store i256 4, i256* %51207, align 4
  %51208 = bitcast i256* %51207 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51206, i8* %51208, i64 32)
  %51209 = add i256 32, %51205, !pc !736, !intsan !10
  %51210 = trunc i256 0 to i32
  %51211 = trunc i256 %51209 to i32
  %51212 = getelementptr inbounds i8, i8* %MEMORY, i32 %51210
  %51213 = alloca i256, align 8
  %51214 = bitcast i256* %51213 to i8*
  call void @__device_sha3(i8* %51212, i32 %51211, i8* %51214)
  %51215 = load i256, i256* %51213, align 4
  %51216 = add i256 1, %51215, !pc !737, !intsan !10
  %51217 = alloca i256, align 8
  store i256 %51216, i256* %51217, align 4
  %51218 = alloca i256, align 8
  call void @__device_sload(i256* %51217, i256* %51218)
  %51219 = call i32 @__hashword(i256* %51217)
  %51220 = load i32, i32* %5, align 4
  %51221 = icmp eq i32 %51219, %51220
  %51222 = or i1 false, %51221
  %51223 = load i32, i32* %6, align 4
  %51224 = icmp eq i32 %51219, %51223
  %51225 = or i1 %51222, %51224
  %51226 = load i32, i32* %7, align 4
  %51227 = icmp eq i32 %51219, %51226
  %51228 = or i1 %51225, %51227
  %51229 = load i32, i32* %8, align 4
  %51230 = icmp eq i32 %51219, %51229
  %51231 = or i1 %51228, %51230
  %51232 = load i32, i32* %9, align 4
  %51233 = icmp eq i32 %51219, %51232
  %51234 = or i1 %51231, %51233
  %51235 = load i32, i32* %10, align 4
  %51236 = icmp eq i32 %51219, %51235
  %51237 = or i1 %51234, %51236
  %51238 = load i32, i32* %11, align 4
  %51239 = icmp eq i32 %51219, %51238
  %51240 = or i1 %51237, %51239
  %51241 = load i32, i32* %12, align 4
  %51242 = icmp eq i32 %51219, %51241
  %51243 = or i1 %51240, %51242
  %51244 = load i32, i32* %13, align 4
  %51245 = icmp eq i32 %51219, %51244
  %51246 = or i1 %51243, %51245
  %51247 = load i32, i32* %14, align 4
  %51248 = icmp eq i32 %51219, %51247
  %51249 = or i1 %51246, %51248
  %51250 = load i32, i32* %15, align 4
  %51251 = icmp eq i32 %51219, %51250
  %51252 = or i1 %51249, %51251
  %51253 = load i32, i32* %16, align 4
  %51254 = icmp eq i32 %51219, %51253
  %51255 = or i1 %51252, %51254
  %51256 = load i32, i32* %17, align 4
  %51257 = icmp eq i32 %51219, %51256
  %51258 = or i1 %51255, %51257
  %51259 = load i32, i32* %18, align 4
  %51260 = icmp eq i32 %51219, %51259
  %51261 = or i1 %51258, %51260
  %51262 = load i32, i32* %19, align 4
  %51263 = icmp eq i32 %51219, %51262
  %51264 = or i1 %51261, %51263
  %51265 = load i32, i32* %20, align 4
  %51266 = icmp eq i32 %51219, %51265
  %51267 = or i1 %51264, %51266
  %51268 = load i32, i32* %21, align 4
  %51269 = icmp eq i32 %51219, %51268
  %51270 = or i1 %51267, %51269
  %51271 = load i32, i32* %22, align 4
  %51272 = icmp eq i32 %51219, %51271
  %51273 = or i1 %51270, %51272
  %51274 = load i32, i32* %23, align 4
  %51275 = icmp eq i32 %51219, %51274
  %51276 = or i1 %51273, %51275
  %51277 = load i32, i32* %24, align 4
  %51278 = icmp eq i32 %51219, %51277
  %51279 = or i1 %51276, %51278
  %51280 = load i32, i32* %25, align 4
  %51281 = icmp eq i32 %51219, %51280
  %51282 = or i1 %51279, %51281
  %51283 = load i32, i32* %26, align 4
  %51284 = icmp eq i32 %51219, %51283
  %51285 = or i1 %51282, %51284
  %51286 = load i32, i32* %27, align 4
  %51287 = icmp eq i32 %51219, %51286
  %51288 = or i1 %51285, %51287
  %51289 = load i32, i32* %28, align 4
  %51290 = icmp eq i32 %51219, %51289
  %51291 = or i1 %51288, %51290
  %51292 = load i32, i32* %29, align 4
  %51293 = icmp eq i32 %51219, %51292
  %51294 = or i1 %51291, %51293
  %51295 = load i32, i32* %30, align 4
  %51296 = icmp eq i32 %51219, %51295
  %51297 = or i1 %51294, %51296
  %51298 = load i32, i32* %31, align 4
  %51299 = icmp eq i32 %51219, %51298
  %51300 = or i1 %51297, %51299
  %51301 = load i32, i32* %32, align 4
  %51302 = icmp eq i32 %51219, %51301
  %51303 = or i1 %51300, %51302
  %51304 = load i32, i32* %33, align 4
  %51305 = icmp eq i32 %51219, %51304
  %51306 = or i1 %51303, %51305
  %51307 = load i32, i32* %34, align 4
  %51308 = icmp eq i32 %51219, %51307
  %51309 = or i1 %51306, %51308
  %51310 = load i32, i32* %35, align 4
  %51311 = icmp eq i32 %51219, %51310
  %51312 = or i1 %51309, %51311
  %51313 = load i32, i32* %36, align 4
  %51314 = icmp eq i32 %51219, %51313
  %51315 = or i1 %51312, %51314
  %51316 = load i32, i32* %37, align 4
  %51317 = icmp eq i32 %51219, %51316
  %51318 = or i1 %51315, %51317
  %51319 = load i32, i32* %38, align 4
  %51320 = icmp eq i32 %51219, %51319
  %51321 = or i1 %51318, %51320
  %51322 = load i32, i32* %39, align 4
  %51323 = icmp eq i32 %51219, %51322
  %51324 = or i1 %51321, %51323
  %51325 = load i32, i32* %40, align 4
  %51326 = icmp eq i32 %51219, %51325
  %51327 = or i1 %51324, %51326
  %51328 = load i32, i32* %41, align 4
  %51329 = icmp eq i32 %51219, %51328
  %51330 = or i1 %51327, %51329
  %51331 = load i32, i32* %42, align 4
  %51332 = icmp eq i32 %51219, %51331
  %51333 = or i1 %51330, %51332
  %51334 = load i32, i32* %43, align 4
  %51335 = icmp eq i32 %51219, %51334
  %51336 = or i1 %51333, %51335
  %51337 = load i32, i32* %44, align 4
  %51338 = icmp eq i32 %51219, %51337
  %51339 = or i1 %51336, %51338
  %51340 = load i32, i32* %45, align 4
  %51341 = icmp eq i32 %51219, %51340
  %51342 = or i1 %51339, %51341
  %51343 = load i32, i32* %46, align 4
  %51344 = icmp eq i32 %51219, %51343
  %51345 = or i1 %51342, %51344
  %51346 = load i32, i32* %47, align 4
  %51347 = icmp eq i32 %51219, %51346
  %51348 = or i1 %51345, %51347
  %51349 = load i32, i32* %48, align 4
  %51350 = icmp eq i32 %51219, %51349
  %51351 = or i1 %51348, %51350
  %51352 = load i32, i32* %49, align 4
  %51353 = icmp eq i32 %51219, %51352
  %51354 = or i1 %51351, %51353
  %51355 = load i32, i32* %50, align 4
  %51356 = icmp eq i32 %51219, %51355
  %51357 = or i1 %51354, %51356
  %51358 = load i32, i32* %51, align 4
  %51359 = icmp eq i32 %51219, %51358
  %51360 = or i1 %51357, %51359
  %51361 = load i32, i32* %52, align 4
  %51362 = icmp eq i32 %51219, %51361
  %51363 = or i1 %51360, %51362
  %51364 = load i32, i32* %53, align 4
  %51365 = icmp eq i32 %51219, %51364
  %51366 = or i1 %51363, %51365
  %51367 = load i32, i32* %54, align 4
  %51368 = icmp eq i32 %51219, %51367
  %51369 = or i1 %51366, %51368
  %51370 = load i32, i32* %55, align 4
  %51371 = icmp eq i32 %51219, %51370
  %51372 = or i1 %51369, %51371
  %51373 = load i32, i32* %56, align 4
  %51374 = icmp eq i32 %51219, %51373
  %51375 = or i1 %51372, %51374
  %51376 = load i32, i32* %57, align 4
  %51377 = icmp eq i32 %51219, %51376
  %51378 = or i1 %51375, %51377
  %51379 = load i32, i32* %58, align 4
  %51380 = icmp eq i32 %51219, %51379
  %51381 = or i1 %51378, %51380
  %51382 = load i32, i32* %59, align 4
  %51383 = icmp eq i32 %51219, %51382
  %51384 = or i1 %51381, %51383
  %51385 = load i32, i32* %60, align 4
  %51386 = icmp eq i32 %51219, %51385
  %51387 = or i1 %51384, %51386
  %51388 = load i32, i32* %61, align 4
  %51389 = icmp eq i32 %51219, %51388
  %51390 = or i1 %51387, %51389
  %51391 = load i32, i32* %62, align 4
  %51392 = icmp eq i32 %51219, %51391
  %51393 = or i1 %51390, %51392
  %51394 = getelementptr i8, i8 addrspace(1)* %4, i32 188
  %51395 = zext i1 %51393 to i8
  store i8 %51395, i8 addrspace(1)* %51394, align 1, !nosanitize !3
  %51396 = load i256, i256* %51218, align 4
  %51397 = trunc i256 0 to i64
  %51398 = alloca i256, align 8
  store i256 %51199, i256* %51398, align 4
  %51399 = bitcast i256* %51398 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51397, i8* %51399, i64 32)
  %51400 = add i256 32, 0, !pc !738, !intsan !10
  %51401 = trunc i256 %51400 to i64
  %51402 = alloca i256, align 8
  store i256 4, i256* %51402, align 4
  %51403 = bitcast i256* %51402 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51401, i8* %51403, i64 32)
  %51404 = add i256 32, %51400, !pc !739, !intsan !10
  %51405 = trunc i256 0 to i32
  %51406 = trunc i256 %51404 to i32
  %51407 = getelementptr inbounds i8, i8* %MEMORY, i32 %51405
  %51408 = alloca i256, align 8
  %51409 = bitcast i256* %51408 to i8*
  call void @__device_sha3(i8* %51407, i32 %51406, i8* %51409)
  %51410 = load i256, i256* %51408, align 4
  %51411 = add i256 1, %51410, !pc !740, !intsan !10
  %51412 = alloca i256, align 8
  store i256 %51411, i256* %51412, align 4
  %51413 = alloca i256, align 8
  call void @__device_sload(i256* %51412, i256* %51413)
  %51414 = call i32 @__hashword(i256* %51412)
  %51415 = load i32, i32* %5, align 4
  %51416 = icmp eq i32 %51414, %51415
  %51417 = or i1 false, %51416
  %51418 = load i32, i32* %6, align 4
  %51419 = icmp eq i32 %51414, %51418
  %51420 = or i1 %51417, %51419
  %51421 = load i32, i32* %7, align 4
  %51422 = icmp eq i32 %51414, %51421
  %51423 = or i1 %51420, %51422
  %51424 = load i32, i32* %8, align 4
  %51425 = icmp eq i32 %51414, %51424
  %51426 = or i1 %51423, %51425
  %51427 = load i32, i32* %9, align 4
  %51428 = icmp eq i32 %51414, %51427
  %51429 = or i1 %51426, %51428
  %51430 = load i32, i32* %10, align 4
  %51431 = icmp eq i32 %51414, %51430
  %51432 = or i1 %51429, %51431
  %51433 = load i32, i32* %11, align 4
  %51434 = icmp eq i32 %51414, %51433
  %51435 = or i1 %51432, %51434
  %51436 = load i32, i32* %12, align 4
  %51437 = icmp eq i32 %51414, %51436
  %51438 = or i1 %51435, %51437
  %51439 = load i32, i32* %13, align 4
  %51440 = icmp eq i32 %51414, %51439
  %51441 = or i1 %51438, %51440
  %51442 = load i32, i32* %14, align 4
  %51443 = icmp eq i32 %51414, %51442
  %51444 = or i1 %51441, %51443
  %51445 = load i32, i32* %15, align 4
  %51446 = icmp eq i32 %51414, %51445
  %51447 = or i1 %51444, %51446
  %51448 = load i32, i32* %16, align 4
  %51449 = icmp eq i32 %51414, %51448
  %51450 = or i1 %51447, %51449
  %51451 = load i32, i32* %17, align 4
  %51452 = icmp eq i32 %51414, %51451
  %51453 = or i1 %51450, %51452
  %51454 = load i32, i32* %18, align 4
  %51455 = icmp eq i32 %51414, %51454
  %51456 = or i1 %51453, %51455
  %51457 = load i32, i32* %19, align 4
  %51458 = icmp eq i32 %51414, %51457
  %51459 = or i1 %51456, %51458
  %51460 = load i32, i32* %20, align 4
  %51461 = icmp eq i32 %51414, %51460
  %51462 = or i1 %51459, %51461
  %51463 = load i32, i32* %21, align 4
  %51464 = icmp eq i32 %51414, %51463
  %51465 = or i1 %51462, %51464
  %51466 = load i32, i32* %22, align 4
  %51467 = icmp eq i32 %51414, %51466
  %51468 = or i1 %51465, %51467
  %51469 = load i32, i32* %23, align 4
  %51470 = icmp eq i32 %51414, %51469
  %51471 = or i1 %51468, %51470
  %51472 = load i32, i32* %24, align 4
  %51473 = icmp eq i32 %51414, %51472
  %51474 = or i1 %51471, %51473
  %51475 = load i32, i32* %25, align 4
  %51476 = icmp eq i32 %51414, %51475
  %51477 = or i1 %51474, %51476
  %51478 = load i32, i32* %26, align 4
  %51479 = icmp eq i32 %51414, %51478
  %51480 = or i1 %51477, %51479
  %51481 = load i32, i32* %27, align 4
  %51482 = icmp eq i32 %51414, %51481
  %51483 = or i1 %51480, %51482
  %51484 = load i32, i32* %28, align 4
  %51485 = icmp eq i32 %51414, %51484
  %51486 = or i1 %51483, %51485
  %51487 = load i32, i32* %29, align 4
  %51488 = icmp eq i32 %51414, %51487
  %51489 = or i1 %51486, %51488
  %51490 = load i32, i32* %30, align 4
  %51491 = icmp eq i32 %51414, %51490
  %51492 = or i1 %51489, %51491
  %51493 = load i32, i32* %31, align 4
  %51494 = icmp eq i32 %51414, %51493
  %51495 = or i1 %51492, %51494
  %51496 = load i32, i32* %32, align 4
  %51497 = icmp eq i32 %51414, %51496
  %51498 = or i1 %51495, %51497
  %51499 = load i32, i32* %33, align 4
  %51500 = icmp eq i32 %51414, %51499
  %51501 = or i1 %51498, %51500
  %51502 = load i32, i32* %34, align 4
  %51503 = icmp eq i32 %51414, %51502
  %51504 = or i1 %51501, %51503
  %51505 = load i32, i32* %35, align 4
  %51506 = icmp eq i32 %51414, %51505
  %51507 = or i1 %51504, %51506
  %51508 = load i32, i32* %36, align 4
  %51509 = icmp eq i32 %51414, %51508
  %51510 = or i1 %51507, %51509
  %51511 = load i32, i32* %37, align 4
  %51512 = icmp eq i32 %51414, %51511
  %51513 = or i1 %51510, %51512
  %51514 = load i32, i32* %38, align 4
  %51515 = icmp eq i32 %51414, %51514
  %51516 = or i1 %51513, %51515
  %51517 = load i32, i32* %39, align 4
  %51518 = icmp eq i32 %51414, %51517
  %51519 = or i1 %51516, %51518
  %51520 = load i32, i32* %40, align 4
  %51521 = icmp eq i32 %51414, %51520
  %51522 = or i1 %51519, %51521
  %51523 = load i32, i32* %41, align 4
  %51524 = icmp eq i32 %51414, %51523
  %51525 = or i1 %51522, %51524
  %51526 = load i32, i32* %42, align 4
  %51527 = icmp eq i32 %51414, %51526
  %51528 = or i1 %51525, %51527
  %51529 = load i32, i32* %43, align 4
  %51530 = icmp eq i32 %51414, %51529
  %51531 = or i1 %51528, %51530
  %51532 = load i32, i32* %44, align 4
  %51533 = icmp eq i32 %51414, %51532
  %51534 = or i1 %51531, %51533
  %51535 = load i32, i32* %45, align 4
  %51536 = icmp eq i32 %51414, %51535
  %51537 = or i1 %51534, %51536
  %51538 = load i32, i32* %46, align 4
  %51539 = icmp eq i32 %51414, %51538
  %51540 = or i1 %51537, %51539
  %51541 = load i32, i32* %47, align 4
  %51542 = icmp eq i32 %51414, %51541
  %51543 = or i1 %51540, %51542
  %51544 = load i32, i32* %48, align 4
  %51545 = icmp eq i32 %51414, %51544
  %51546 = or i1 %51543, %51545
  %51547 = load i32, i32* %49, align 4
  %51548 = icmp eq i32 %51414, %51547
  %51549 = or i1 %51546, %51548
  %51550 = load i32, i32* %50, align 4
  %51551 = icmp eq i32 %51414, %51550
  %51552 = or i1 %51549, %51551
  %51553 = load i32, i32* %51, align 4
  %51554 = icmp eq i32 %51414, %51553
  %51555 = or i1 %51552, %51554
  %51556 = load i32, i32* %52, align 4
  %51557 = icmp eq i32 %51414, %51556
  %51558 = or i1 %51555, %51557
  %51559 = load i32, i32* %53, align 4
  %51560 = icmp eq i32 %51414, %51559
  %51561 = or i1 %51558, %51560
  %51562 = load i32, i32* %54, align 4
  %51563 = icmp eq i32 %51414, %51562
  %51564 = or i1 %51561, %51563
  %51565 = load i32, i32* %55, align 4
  %51566 = icmp eq i32 %51414, %51565
  %51567 = or i1 %51564, %51566
  %51568 = load i32, i32* %56, align 4
  %51569 = icmp eq i32 %51414, %51568
  %51570 = or i1 %51567, %51569
  %51571 = load i32, i32* %57, align 4
  %51572 = icmp eq i32 %51414, %51571
  %51573 = or i1 %51570, %51572
  %51574 = load i32, i32* %58, align 4
  %51575 = icmp eq i32 %51414, %51574
  %51576 = or i1 %51573, %51575
  %51577 = load i32, i32* %59, align 4
  %51578 = icmp eq i32 %51414, %51577
  %51579 = or i1 %51576, %51578
  %51580 = load i32, i32* %60, align 4
  %51581 = icmp eq i32 %51414, %51580
  %51582 = or i1 %51579, %51581
  %51583 = load i32, i32* %61, align 4
  %51584 = icmp eq i32 %51414, %51583
  %51585 = or i1 %51582, %51584
  %51586 = load i32, i32* %62, align 4
  %51587 = icmp eq i32 %51414, %51586
  %51588 = or i1 %51585, %51587
  %51589 = getelementptr i8, i8 addrspace(1)* %4, i32 189
  %51590 = zext i1 %51588 to i8
  store i8 %51590, i8 addrspace(1)* %51589, align 1, !nosanitize !3
  %51591 = load i256, i256* %51413, align 4
  %51592 = add i256 %51591, %51189, !pc !741, !intsan !10
  %51593 = icmp ult i256 %51592, %51396
  %51594 = icmp eq i1 %51593, false
  %51595 = icmp eq i1 %51594, false
  %51596 = trunc i256 16659 to i64
  %jump.check229 = icmp ne i1 %51595, false
  %51597 = load i64, i64* %STACK_DEP_PTR, align 4
  %51598 = add i64 %51597, 1
  store i64 %51598, i64* %STACK_DEP_PTR, align 4
  %51599 = load i64, i64* %STACK_DEP_PTR, align 4
  %51600 = getelementptr i256, i256* %STACK, i64 %51599
  store i256 %51199, i256* %51600, align 4
  %51601 = load i64, i64* %STACK_DEP_PTR, align 4
  %51602 = add i64 %51601, 1
  store i64 %51602, i64* %STACK_DEP_PTR, align 4
  %51603 = load i64, i64* %STACK_DEP_PTR, align 4
  %51604 = getelementptr i256, i256* %STACK, i64 %51603
  store i256 %51194, i256* %51604, align 4
  %51605 = load i64, i64* %STACK_DEP_PTR, align 4
  %51606 = add i64 %51605, 1
  store i64 %51606, i64* %STACK_DEP_PTR, align 4
  %51607 = load i64, i64* %STACK_DEP_PTR, align 4
  %51608 = getelementptr i256, i256* %STACK, i64 %51607
  store i256 %51189, i256* %51608, align 4
  %51609 = load i64, i64* %STACK_DEP_PTR, align 4
  %51610 = add i64 %51609, 1
  store i64 %51610, i64* %STACK_DEP_PTR, align 4
  %51611 = load i64, i64* %STACK_DEP_PTR, align 4
  %51612 = getelementptr i256, i256* %STACK, i64 %51611
  store i256 %51179, i256* %51612, align 4
  %51613 = load i64, i64* %STACK_DEP_PTR, align 4
  %51614 = add i64 %51613, 1
  store i64 %51614, i64* %STACK_DEP_PTR, align 4
  %51615 = zext i1 %51594 to i256
  %51616 = load i64, i64* %STACK_DEP_PTR, align 4
  %51617 = getelementptr i256, i256* %STACK, i64 %51616
  store i256 %51615, i256* %51617, align 4
  br i1 %jump.check229, label %.16659, label %.16630, !EVMBB !4

.16630:                                           ; preds = %51170
  %51618 = load i64, i64* %STACK_DEP_PTR, align 4
  %51619 = getelementptr i256, i256* %STACK, i64 %51618
  %51620 = load i256, i256* %51619, align 4
  %51621 = load i64, i64* %STACK_DEP_PTR, align 4
  %51622 = sub i64 %51621, 1
  store i64 %51622, i64* %STACK_DEP_PTR, align 4
  %51623 = load i64, i64* %STACK_DEP_PTR, align 4
  %51624 = getelementptr i256, i256* %STACK, i64 %51623
  %51625 = load i256, i256* %51624, align 4
  %51626 = load i64, i64* %STACK_DEP_PTR, align 4
  %51627 = sub i64 %51626, 1
  store i64 %51627, i64* %STACK_DEP_PTR, align 4
  %51628 = load i64, i64* %STACK_DEP_PTR, align 4
  %51629 = getelementptr i256, i256* %STACK, i64 %51628
  %51630 = load i256, i256* %51629, align 4
  %51631 = load i64, i64* %STACK_DEP_PTR, align 4
  %51632 = sub i64 %51631, 1
  store i64 %51632, i64* %STACK_DEP_PTR, align 4
  %51633 = load i64, i64* %STACK_DEP_PTR, align 4
  %51634 = getelementptr i256, i256* %STACK, i64 %51633
  %51635 = load i256, i256* %51634, align 4
  %51636 = load i64, i64* %STACK_DEP_PTR, align 4
  %51637 = sub i64 %51636, 1
  store i64 %51637, i64* %STACK_DEP_PTR, align 4
  %51638 = load i64, i64* %STACK_DEP_PTR, align 4
  %51639 = getelementptr i256, i256* %STACK, i64 %51638
  %51640 = load i256, i256* %51639, align 4
  %51641 = load i64, i64* %STACK_DEP_PTR, align 4
  %51642 = sub i64 %51641, 1
  store i64 %51642, i64* %STACK_DEP_PTR, align 4
  %51643 = trunc i256 0 to i64
  %51644 = alloca i256, align 8
  store i256 %51640, i256* %51644, align 4
  %51645 = bitcast i256* %51644 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51643, i8* %51645, i64 32)
  %51646 = add i256 32, 0, !pc !742, !intsan !10
  %51647 = trunc i256 %51646 to i64
  %51648 = alloca i256, align 8
  store i256 4, i256* %51648, align 4
  %51649 = bitcast i256* %51648 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51647, i8* %51649, i64 32)
  %51650 = add i256 32, %51646, !pc !743, !intsan !10
  %51651 = trunc i256 0 to i32
  %51652 = trunc i256 %51650 to i32
  %51653 = getelementptr inbounds i8, i8* %MEMORY, i32 %51651
  %51654 = alloca i256, align 8
  %51655 = bitcast i256* %51654 to i8*
  call void @__device_sha3(i8* %51653, i32 %51652, i8* %51655)
  %51656 = load i256, i256* %51654, align 4
  %51657 = add i256 1, %51656, !pc !744, !intsan !10
  %51658 = alloca i256, align 8
  store i256 %51657, i256* %51658, align 4
  %51659 = alloca i256, align 8
  call void @__device_sload(i256* %51658, i256* %51659)
  %51660 = call i32 @__hashword(i256* %51658)
  %51661 = load i32, i32* %5, align 4
  %51662 = icmp eq i32 %51660, %51661
  %51663 = or i1 false, %51662
  %51664 = load i32, i32* %6, align 4
  %51665 = icmp eq i32 %51660, %51664
  %51666 = or i1 %51663, %51665
  %51667 = load i32, i32* %7, align 4
  %51668 = icmp eq i32 %51660, %51667
  %51669 = or i1 %51666, %51668
  %51670 = load i32, i32* %8, align 4
  %51671 = icmp eq i32 %51660, %51670
  %51672 = or i1 %51669, %51671
  %51673 = load i32, i32* %9, align 4
  %51674 = icmp eq i32 %51660, %51673
  %51675 = or i1 %51672, %51674
  %51676 = load i32, i32* %10, align 4
  %51677 = icmp eq i32 %51660, %51676
  %51678 = or i1 %51675, %51677
  %51679 = load i32, i32* %11, align 4
  %51680 = icmp eq i32 %51660, %51679
  %51681 = or i1 %51678, %51680
  %51682 = load i32, i32* %12, align 4
  %51683 = icmp eq i32 %51660, %51682
  %51684 = or i1 %51681, %51683
  %51685 = load i32, i32* %13, align 4
  %51686 = icmp eq i32 %51660, %51685
  %51687 = or i1 %51684, %51686
  %51688 = load i32, i32* %14, align 4
  %51689 = icmp eq i32 %51660, %51688
  %51690 = or i1 %51687, %51689
  %51691 = load i32, i32* %15, align 4
  %51692 = icmp eq i32 %51660, %51691
  %51693 = or i1 %51690, %51692
  %51694 = load i32, i32* %16, align 4
  %51695 = icmp eq i32 %51660, %51694
  %51696 = or i1 %51693, %51695
  %51697 = load i32, i32* %17, align 4
  %51698 = icmp eq i32 %51660, %51697
  %51699 = or i1 %51696, %51698
  %51700 = load i32, i32* %18, align 4
  %51701 = icmp eq i32 %51660, %51700
  %51702 = or i1 %51699, %51701
  %51703 = load i32, i32* %19, align 4
  %51704 = icmp eq i32 %51660, %51703
  %51705 = or i1 %51702, %51704
  %51706 = load i32, i32* %20, align 4
  %51707 = icmp eq i32 %51660, %51706
  %51708 = or i1 %51705, %51707
  %51709 = load i32, i32* %21, align 4
  %51710 = icmp eq i32 %51660, %51709
  %51711 = or i1 %51708, %51710
  %51712 = load i32, i32* %22, align 4
  %51713 = icmp eq i32 %51660, %51712
  %51714 = or i1 %51711, %51713
  %51715 = load i32, i32* %23, align 4
  %51716 = icmp eq i32 %51660, %51715
  %51717 = or i1 %51714, %51716
  %51718 = load i32, i32* %24, align 4
  %51719 = icmp eq i32 %51660, %51718
  %51720 = or i1 %51717, %51719
  %51721 = load i32, i32* %25, align 4
  %51722 = icmp eq i32 %51660, %51721
  %51723 = or i1 %51720, %51722
  %51724 = load i32, i32* %26, align 4
  %51725 = icmp eq i32 %51660, %51724
  %51726 = or i1 %51723, %51725
  %51727 = load i32, i32* %27, align 4
  %51728 = icmp eq i32 %51660, %51727
  %51729 = or i1 %51726, %51728
  %51730 = load i32, i32* %28, align 4
  %51731 = icmp eq i32 %51660, %51730
  %51732 = or i1 %51729, %51731
  %51733 = load i32, i32* %29, align 4
  %51734 = icmp eq i32 %51660, %51733
  %51735 = or i1 %51732, %51734
  %51736 = load i32, i32* %30, align 4
  %51737 = icmp eq i32 %51660, %51736
  %51738 = or i1 %51735, %51737
  %51739 = load i32, i32* %31, align 4
  %51740 = icmp eq i32 %51660, %51739
  %51741 = or i1 %51738, %51740
  %51742 = load i32, i32* %32, align 4
  %51743 = icmp eq i32 %51660, %51742
  %51744 = or i1 %51741, %51743
  %51745 = load i32, i32* %33, align 4
  %51746 = icmp eq i32 %51660, %51745
  %51747 = or i1 %51744, %51746
  %51748 = load i32, i32* %34, align 4
  %51749 = icmp eq i32 %51660, %51748
  %51750 = or i1 %51747, %51749
  %51751 = load i32, i32* %35, align 4
  %51752 = icmp eq i32 %51660, %51751
  %51753 = or i1 %51750, %51752
  %51754 = load i32, i32* %36, align 4
  %51755 = icmp eq i32 %51660, %51754
  %51756 = or i1 %51753, %51755
  %51757 = load i32, i32* %37, align 4
  %51758 = icmp eq i32 %51660, %51757
  %51759 = or i1 %51756, %51758
  %51760 = load i32, i32* %38, align 4
  %51761 = icmp eq i32 %51660, %51760
  %51762 = or i1 %51759, %51761
  %51763 = load i32, i32* %39, align 4
  %51764 = icmp eq i32 %51660, %51763
  %51765 = or i1 %51762, %51764
  %51766 = load i32, i32* %40, align 4
  %51767 = icmp eq i32 %51660, %51766
  %51768 = or i1 %51765, %51767
  %51769 = load i32, i32* %41, align 4
  %51770 = icmp eq i32 %51660, %51769
  %51771 = or i1 %51768, %51770
  %51772 = load i32, i32* %42, align 4
  %51773 = icmp eq i32 %51660, %51772
  %51774 = or i1 %51771, %51773
  %51775 = load i32, i32* %43, align 4
  %51776 = icmp eq i32 %51660, %51775
  %51777 = or i1 %51774, %51776
  %51778 = load i32, i32* %44, align 4
  %51779 = icmp eq i32 %51660, %51778
  %51780 = or i1 %51777, %51779
  %51781 = load i32, i32* %45, align 4
  %51782 = icmp eq i32 %51660, %51781
  %51783 = or i1 %51780, %51782
  %51784 = load i32, i32* %46, align 4
  %51785 = icmp eq i32 %51660, %51784
  %51786 = or i1 %51783, %51785
  %51787 = load i32, i32* %47, align 4
  %51788 = icmp eq i32 %51660, %51787
  %51789 = or i1 %51786, %51788
  %51790 = load i32, i32* %48, align 4
  %51791 = icmp eq i32 %51660, %51790
  %51792 = or i1 %51789, %51791
  %51793 = load i32, i32* %49, align 4
  %51794 = icmp eq i32 %51660, %51793
  %51795 = or i1 %51792, %51794
  %51796 = load i32, i32* %50, align 4
  %51797 = icmp eq i32 %51660, %51796
  %51798 = or i1 %51795, %51797
  %51799 = load i32, i32* %51, align 4
  %51800 = icmp eq i32 %51660, %51799
  %51801 = or i1 %51798, %51800
  %51802 = load i32, i32* %52, align 4
  %51803 = icmp eq i32 %51660, %51802
  %51804 = or i1 %51801, %51803
  %51805 = load i32, i32* %53, align 4
  %51806 = icmp eq i32 %51660, %51805
  %51807 = or i1 %51804, %51806
  %51808 = load i32, i32* %54, align 4
  %51809 = icmp eq i32 %51660, %51808
  %51810 = or i1 %51807, %51809
  %51811 = load i32, i32* %55, align 4
  %51812 = icmp eq i32 %51660, %51811
  %51813 = or i1 %51810, %51812
  %51814 = load i32, i32* %56, align 4
  %51815 = icmp eq i32 %51660, %51814
  %51816 = or i1 %51813, %51815
  %51817 = load i32, i32* %57, align 4
  %51818 = icmp eq i32 %51660, %51817
  %51819 = or i1 %51816, %51818
  %51820 = load i32, i32* %58, align 4
  %51821 = icmp eq i32 %51660, %51820
  %51822 = or i1 %51819, %51821
  %51823 = load i32, i32* %59, align 4
  %51824 = icmp eq i32 %51660, %51823
  %51825 = or i1 %51822, %51824
  %51826 = load i32, i32* %60, align 4
  %51827 = icmp eq i32 %51660, %51826
  %51828 = or i1 %51825, %51827
  %51829 = load i32, i32* %61, align 4
  %51830 = icmp eq i32 %51660, %51829
  %51831 = or i1 %51828, %51830
  %51832 = load i32, i32* %62, align 4
  %51833 = icmp eq i32 %51660, %51832
  %51834 = or i1 %51831, %51833
  %51835 = getelementptr i8, i8 addrspace(1)* %4, i32 190
  %51836 = zext i1 %51834 to i8
  store i8 %51836, i8 addrspace(1)* %51835, align 1, !nosanitize !3
  %51837 = load i256, i256* %51659, align 4
  %51838 = add i256 %51837, %51630, !pc !745, !intsan !10
  %51839 = icmp ult i256 %51838, %51625
  %51840 = icmp eq i1 %51839, false
  %51841 = load i64, i64* %STACK_DEP_PTR, align 4
  %51842 = add i64 %51841, 1
  store i64 %51842, i64* %STACK_DEP_PTR, align 4
  %51843 = load i64, i64* %STACK_DEP_PTR, align 4
  %51844 = getelementptr i256, i256* %STACK, i64 %51843
  store i256 %51640, i256* %51844, align 4
  %51845 = load i64, i64* %STACK_DEP_PTR, align 4
  %51846 = add i64 %51845, 1
  store i64 %51846, i64* %STACK_DEP_PTR, align 4
  %51847 = load i64, i64* %STACK_DEP_PTR, align 4
  %51848 = getelementptr i256, i256* %STACK, i64 %51847
  store i256 %51635, i256* %51848, align 4
  %51849 = load i64, i64* %STACK_DEP_PTR, align 4
  %51850 = add i64 %51849, 1
  store i64 %51850, i64* %STACK_DEP_PTR, align 4
  %51851 = load i64, i64* %STACK_DEP_PTR, align 4
  %51852 = getelementptr i256, i256* %STACK, i64 %51851
  store i256 %51630, i256* %51852, align 4
  %51853 = load i64, i64* %STACK_DEP_PTR, align 4
  %51854 = add i64 %51853, 1
  store i64 %51854, i64* %STACK_DEP_PTR, align 4
  %51855 = load i64, i64* %STACK_DEP_PTR, align 4
  %51856 = getelementptr i256, i256* %STACK, i64 %51855
  store i256 %51625, i256* %51856, align 4
  %51857 = load i64, i64* %STACK_DEP_PTR, align 4
  %51858 = add i64 %51857, 1
  store i64 %51858, i64* %STACK_DEP_PTR, align 4
  %51859 = zext i1 %51840 to i256
  %51860 = load i64, i64* %STACK_DEP_PTR, align 4
  %51861 = getelementptr i256, i256* %STACK, i64 %51860
  store i256 %51859, i256* %51861, align 4
  br label %.16659

.16659:                                           ; preds = %.16630, %51170, %JumpTable
  %51862 = load i64, i64* %remaing_gas, align 4
  %51863 = icmp ugt i64 88, %51862
  br i1 %51863, label %Abort, label %51864

51864:                                            ; preds = %.16659
  %51865 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51866 = xor i32 %51865, 3565
  %51867 = urem i32 %51866, 4096
  %51868 = getelementptr i8, i8 addrspace(1)* %4, i32 %51867
  %51869 = load i8, i8 addrspace(1)* %51868, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %51868, align 1, !nosanitize !3
  store i32 1782, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51870 = sub i64 %51862, 88
  store i64 %51870, i64* %remaing_gas, align 4
  %51871 = load i64, i64* %STACK_DEP_PTR, align 4
  %51872 = getelementptr i256, i256* %STACK, i64 %51871
  %51873 = load i256, i256* %51872, align 4
  %51874 = load i64, i64* %STACK_DEP_PTR, align 4
  %51875 = sub i64 %51874, 1
  store i64 %51875, i64* %STACK_DEP_PTR, align 4
  %51876 = icmp eq i256 %51873, 0
  %51877 = trunc i256 16816 to i64
  %jump.check230 = icmp ne i1 %51876, false
  br i1 %jump.check230, label %.16816, label %.16665, !EVMBB !4

.16665:                                           ; preds = %51864
  %51878 = load i64, i64* %remaing_gas, align 4
  %51879 = icmp ugt i64 872, %51878
  br i1 %51879, label %Abort, label %51880

51880:                                            ; preds = %.16665
  %51881 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51882 = xor i32 %51881, 3282
  %51883 = urem i32 %51882, 4096
  %51884 = getelementptr i8, i8 addrspace(1)* %4, i32 %51883
  %51885 = load i8, i8 addrspace(1)* %51884, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %51884, align 1, !nosanitize !3
  store i32 1641, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %51886 = sub i64 %51878, 872
  store i64 %51886, i64* %remaing_gas, align 4
  %51887 = load i64, i64* %STACK_DEP_PTR, align 4
  %51888 = getelementptr i256, i256* %STACK, i64 %51887
  %51889 = load i256, i256* %51888, align 4
  %51890 = load i64, i64* %STACK_DEP_PTR, align 4
  %51891 = sub i64 %51890, 1
  store i64 %51891, i64* %STACK_DEP_PTR, align 4
  %51892 = load i64, i64* %STACK_DEP_PTR, align 4
  %51893 = getelementptr i256, i256* %STACK, i64 %51892
  %51894 = load i256, i256* %51893, align 4
  %51895 = load i64, i64* %STACK_DEP_PTR, align 4
  %51896 = sub i64 %51895, 1
  store i64 %51896, i64* %STACK_DEP_PTR, align 4
  %51897 = load i64, i64* %STACK_DEP_PTR, align 4
  %51898 = getelementptr i256, i256* %STACK, i64 %51897
  %51899 = load i256, i256* %51898, align 4
  %51900 = load i64, i64* %STACK_DEP_PTR, align 4
  %51901 = sub i64 %51900, 1
  store i64 %51901, i64* %STACK_DEP_PTR, align 4
  %51902 = load i64, i64* %STACK_DEP_PTR, align 4
  %51903 = getelementptr i256, i256* %STACK, i64 %51902
  %51904 = load i256, i256* %51903, align 4
  %51905 = load i64, i64* %STACK_DEP_PTR, align 4
  %51906 = sub i64 %51905, 1
  store i64 %51906, i64* %STACK_DEP_PTR, align 4
  %51907 = sub i256 %51894, %51889, !pc !746, !intsan !8
  %51908 = trunc i256 0 to i64
  %51909 = alloca i256, align 8
  store i256 %51904, i256* %51909, align 4
  %51910 = bitcast i256* %51909 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51908, i8* %51910, i64 32)
  %51911 = add i256 32, 0, !pc !747, !intsan !10
  %51912 = trunc i256 %51911 to i64
  %51913 = alloca i256, align 8
  store i256 4, i256* %51913, align 4
  %51914 = bitcast i256* %51913 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %51912, i8* %51914, i64 32)
  %51915 = add i256 32, %51911, !pc !748, !intsan !10
  %51916 = trunc i256 0 to i32
  %51917 = trunc i256 %51915 to i32
  %51918 = getelementptr inbounds i8, i8* %MEMORY, i32 %51916
  %51919 = alloca i256, align 8
  %51920 = bitcast i256* %51919 to i8*
  call void @__device_sha3(i8* %51918, i32 %51917, i8* %51920)
  %51921 = load i256, i256* %51919, align 4
  %51922 = add i256 1, %51921, !pc !749, !intsan !10
  %51923 = alloca i256, align 8
  store i256 %51922, i256* %51923, align 4
  %51924 = alloca i256, align 8
  call void @__device_sload(i256* %51923, i256* %51924)
  %51925 = call i32 @__hashword(i256* %51923)
  %51926 = load i32, i32* %5, align 4
  %51927 = icmp eq i32 %51925, %51926
  %51928 = or i1 false, %51927
  %51929 = load i32, i32* %6, align 4
  %51930 = icmp eq i32 %51925, %51929
  %51931 = or i1 %51928, %51930
  %51932 = load i32, i32* %7, align 4
  %51933 = icmp eq i32 %51925, %51932
  %51934 = or i1 %51931, %51933
  %51935 = load i32, i32* %8, align 4
  %51936 = icmp eq i32 %51925, %51935
  %51937 = or i1 %51934, %51936
  %51938 = load i32, i32* %9, align 4
  %51939 = icmp eq i32 %51925, %51938
  %51940 = or i1 %51937, %51939
  %51941 = load i32, i32* %10, align 4
  %51942 = icmp eq i32 %51925, %51941
  %51943 = or i1 %51940, %51942
  %51944 = load i32, i32* %11, align 4
  %51945 = icmp eq i32 %51925, %51944
  %51946 = or i1 %51943, %51945
  %51947 = load i32, i32* %12, align 4
  %51948 = icmp eq i32 %51925, %51947
  %51949 = or i1 %51946, %51948
  %51950 = load i32, i32* %13, align 4
  %51951 = icmp eq i32 %51925, %51950
  %51952 = or i1 %51949, %51951
  %51953 = load i32, i32* %14, align 4
  %51954 = icmp eq i32 %51925, %51953
  %51955 = or i1 %51952, %51954
  %51956 = load i32, i32* %15, align 4
  %51957 = icmp eq i32 %51925, %51956
  %51958 = or i1 %51955, %51957
  %51959 = load i32, i32* %16, align 4
  %51960 = icmp eq i32 %51925, %51959
  %51961 = or i1 %51958, %51960
  %51962 = load i32, i32* %17, align 4
  %51963 = icmp eq i32 %51925, %51962
  %51964 = or i1 %51961, %51963
  %51965 = load i32, i32* %18, align 4
  %51966 = icmp eq i32 %51925, %51965
  %51967 = or i1 %51964, %51966
  %51968 = load i32, i32* %19, align 4
  %51969 = icmp eq i32 %51925, %51968
  %51970 = or i1 %51967, %51969
  %51971 = load i32, i32* %20, align 4
  %51972 = icmp eq i32 %51925, %51971
  %51973 = or i1 %51970, %51972
  %51974 = load i32, i32* %21, align 4
  %51975 = icmp eq i32 %51925, %51974
  %51976 = or i1 %51973, %51975
  %51977 = load i32, i32* %22, align 4
  %51978 = icmp eq i32 %51925, %51977
  %51979 = or i1 %51976, %51978
  %51980 = load i32, i32* %23, align 4
  %51981 = icmp eq i32 %51925, %51980
  %51982 = or i1 %51979, %51981
  %51983 = load i32, i32* %24, align 4
  %51984 = icmp eq i32 %51925, %51983
  %51985 = or i1 %51982, %51984
  %51986 = load i32, i32* %25, align 4
  %51987 = icmp eq i32 %51925, %51986
  %51988 = or i1 %51985, %51987
  %51989 = load i32, i32* %26, align 4
  %51990 = icmp eq i32 %51925, %51989
  %51991 = or i1 %51988, %51990
  %51992 = load i32, i32* %27, align 4
  %51993 = icmp eq i32 %51925, %51992
  %51994 = or i1 %51991, %51993
  %51995 = load i32, i32* %28, align 4
  %51996 = icmp eq i32 %51925, %51995
  %51997 = or i1 %51994, %51996
  %51998 = load i32, i32* %29, align 4
  %51999 = icmp eq i32 %51925, %51998
  %52000 = or i1 %51997, %51999
  %52001 = load i32, i32* %30, align 4
  %52002 = icmp eq i32 %51925, %52001
  %52003 = or i1 %52000, %52002
  %52004 = load i32, i32* %31, align 4
  %52005 = icmp eq i32 %51925, %52004
  %52006 = or i1 %52003, %52005
  %52007 = load i32, i32* %32, align 4
  %52008 = icmp eq i32 %51925, %52007
  %52009 = or i1 %52006, %52008
  %52010 = load i32, i32* %33, align 4
  %52011 = icmp eq i32 %51925, %52010
  %52012 = or i1 %52009, %52011
  %52013 = load i32, i32* %34, align 4
  %52014 = icmp eq i32 %51925, %52013
  %52015 = or i1 %52012, %52014
  %52016 = load i32, i32* %35, align 4
  %52017 = icmp eq i32 %51925, %52016
  %52018 = or i1 %52015, %52017
  %52019 = load i32, i32* %36, align 4
  %52020 = icmp eq i32 %51925, %52019
  %52021 = or i1 %52018, %52020
  %52022 = load i32, i32* %37, align 4
  %52023 = icmp eq i32 %51925, %52022
  %52024 = or i1 %52021, %52023
  %52025 = load i32, i32* %38, align 4
  %52026 = icmp eq i32 %51925, %52025
  %52027 = or i1 %52024, %52026
  %52028 = load i32, i32* %39, align 4
  %52029 = icmp eq i32 %51925, %52028
  %52030 = or i1 %52027, %52029
  %52031 = load i32, i32* %40, align 4
  %52032 = icmp eq i32 %51925, %52031
  %52033 = or i1 %52030, %52032
  %52034 = load i32, i32* %41, align 4
  %52035 = icmp eq i32 %51925, %52034
  %52036 = or i1 %52033, %52035
  %52037 = load i32, i32* %42, align 4
  %52038 = icmp eq i32 %51925, %52037
  %52039 = or i1 %52036, %52038
  %52040 = load i32, i32* %43, align 4
  %52041 = icmp eq i32 %51925, %52040
  %52042 = or i1 %52039, %52041
  %52043 = load i32, i32* %44, align 4
  %52044 = icmp eq i32 %51925, %52043
  %52045 = or i1 %52042, %52044
  %52046 = load i32, i32* %45, align 4
  %52047 = icmp eq i32 %51925, %52046
  %52048 = or i1 %52045, %52047
  %52049 = load i32, i32* %46, align 4
  %52050 = icmp eq i32 %51925, %52049
  %52051 = or i1 %52048, %52050
  %52052 = load i32, i32* %47, align 4
  %52053 = icmp eq i32 %51925, %52052
  %52054 = or i1 %52051, %52053
  %52055 = load i32, i32* %48, align 4
  %52056 = icmp eq i32 %51925, %52055
  %52057 = or i1 %52054, %52056
  %52058 = load i32, i32* %49, align 4
  %52059 = icmp eq i32 %51925, %52058
  %52060 = or i1 %52057, %52059
  %52061 = load i32, i32* %50, align 4
  %52062 = icmp eq i32 %51925, %52061
  %52063 = or i1 %52060, %52062
  %52064 = load i32, i32* %51, align 4
  %52065 = icmp eq i32 %51925, %52064
  %52066 = or i1 %52063, %52065
  %52067 = load i32, i32* %52, align 4
  %52068 = icmp eq i32 %51925, %52067
  %52069 = or i1 %52066, %52068
  %52070 = load i32, i32* %53, align 4
  %52071 = icmp eq i32 %51925, %52070
  %52072 = or i1 %52069, %52071
  %52073 = load i32, i32* %54, align 4
  %52074 = icmp eq i32 %51925, %52073
  %52075 = or i1 %52072, %52074
  %52076 = load i32, i32* %55, align 4
  %52077 = icmp eq i32 %51925, %52076
  %52078 = or i1 %52075, %52077
  %52079 = load i32, i32* %56, align 4
  %52080 = icmp eq i32 %51925, %52079
  %52081 = or i1 %52078, %52080
  %52082 = load i32, i32* %57, align 4
  %52083 = icmp eq i32 %51925, %52082
  %52084 = or i1 %52081, %52083
  %52085 = load i32, i32* %58, align 4
  %52086 = icmp eq i32 %51925, %52085
  %52087 = or i1 %52084, %52086
  %52088 = load i32, i32* %59, align 4
  %52089 = icmp eq i32 %51925, %52088
  %52090 = or i1 %52087, %52089
  %52091 = load i32, i32* %60, align 4
  %52092 = icmp eq i32 %51925, %52091
  %52093 = or i1 %52090, %52092
  %52094 = load i32, i32* %61, align 4
  %52095 = icmp eq i32 %51925, %52094
  %52096 = or i1 %52093, %52095
  %52097 = load i32, i32* %62, align 4
  %52098 = icmp eq i32 %51925, %52097
  %52099 = or i1 %52096, %52098
  %52100 = getelementptr i8, i8 addrspace(1)* %4, i32 191
  %52101 = zext i1 %52099 to i8
  store i8 %52101, i8 addrspace(1)* %52100, align 1, !nosanitize !3
  %52102 = load i256, i256* %51924, align 4
  %52103 = add i256 %52102, %51907, !pc !750, !intsan !10
  %52104 = alloca i256, align 8
  store i256 %51922, i256* %52104, align 4
  %52105 = alloca i256, align 8
  store i256 %52103, i256* %52105, align 4
  call void @__device_sstore(i256* %52104, i256* %52105)
  %52106 = call i32 @__hashword(i256* %52104)
  store i32 %52106, i32* %50, align 4, !nosanitize !3
  %52107 = sub i256 %51894, %51889, !pc !751, !intsan !8
  %52108 = trunc i256 64 to i64
  %52109 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %52108, i256* %52109)
  %52110 = load i256, i256* %52109, align 4
  %52111 = and i256 1461501637330902918203684832716283019655932542975, %51899
  %52112 = and i256 1461501637330902918203684832716283019655932542975, %52111
  %52113 = trunc i256 %52110 to i64
  %52114 = alloca i256, align 8
  store i256 %52112, i256* %52114, align 4
  %52115 = bitcast i256* %52114 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52113, i8* %52115, i64 32)
  %52116 = add i256 32, %52110, !pc !752, !intsan !10
  %52117 = trunc i256 %52116 to i64
  %52118 = alloca i256, align 8
  store i256 %52107, i256* %52118, align 4
  %52119 = bitcast i256* %52118 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52117, i8* %52119, i64 32)
  %52120 = add i256 32, %52116, !pc !753, !intsan !10
  %52121 = trunc i256 64 to i64
  %52122 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %52121, i256* %52122)
  %52123 = load i256, i256* %52122, align 4
  %52124 = sub i256 %52120, %52123, !pc !754, !intsan !8
  %52125 = trunc i256 -50679224712216582149058229388367755404202492714372704071740798585972116367411 to i64
  call void @addBugSet(i64 %52125)
  %52126 = trunc i256 16888 to i64
  %52127 = load i64, i64* %STACK_DEP_PTR, align 4
  %52128 = add i64 %52127, 1
  store i64 %52128, i64* %STACK_DEP_PTR, align 4
  %52129 = load i64, i64* %STACK_DEP_PTR, align 4
  %52130 = getelementptr i256, i256* %STACK, i64 %52129
  store i256 %51904, i256* %52130, align 4
  %52131 = load i64, i64* %STACK_DEP_PTR, align 4
  %52132 = add i64 %52131, 1
  store i64 %52132, i64* %STACK_DEP_PTR, align 4
  %52133 = load i64, i64* %STACK_DEP_PTR, align 4
  %52134 = getelementptr i256, i256* %STACK, i64 %52133
  store i256 %51899, i256* %52134, align 4
  %52135 = load i64, i64* %STACK_DEP_PTR, align 4
  %52136 = add i64 %52135, 1
  store i64 %52136, i64* %STACK_DEP_PTR, align 4
  %52137 = load i64, i64* %STACK_DEP_PTR, align 4
  %52138 = getelementptr i256, i256* %STACK, i64 %52137
  store i256 %51894, i256* %52138, align 4
  %52139 = load i64, i64* %STACK_DEP_PTR, align 4
  %52140 = add i64 %52139, 1
  store i64 %52140, i64* %STACK_DEP_PTR, align 4
  %52141 = load i64, i64* %STACK_DEP_PTR, align 4
  %52142 = getelementptr i256, i256* %STACK, i64 %52141
  store i256 %51889, i256* %52142, align 4
  br label %.16888, !EVMBB !4

.16816:                                           ; preds = %51864, %JumpTable
  %52143 = alloca i256, align 8
  store i256 8, i256* %52143, align 4
  %52144 = alloca i256, align 8
  call void @__device_sload(i256* %52143, i256* %52144)
  %52145 = call i32 @__hashword(i256* %52143)
  %52146 = load i32, i32* %5, align 4
  %52147 = icmp eq i32 %52145, %52146
  %52148 = or i1 false, %52147
  %52149 = load i32, i32* %6, align 4
  %52150 = icmp eq i32 %52145, %52149
  %52151 = or i1 %52148, %52150
  %52152 = load i32, i32* %7, align 4
  %52153 = icmp eq i32 %52145, %52152
  %52154 = or i1 %52151, %52153
  %52155 = load i32, i32* %8, align 4
  %52156 = icmp eq i32 %52145, %52155
  %52157 = or i1 %52154, %52156
  %52158 = load i32, i32* %9, align 4
  %52159 = icmp eq i32 %52145, %52158
  %52160 = or i1 %52157, %52159
  %52161 = load i32, i32* %10, align 4
  %52162 = icmp eq i32 %52145, %52161
  %52163 = or i1 %52160, %52162
  %52164 = load i32, i32* %11, align 4
  %52165 = icmp eq i32 %52145, %52164
  %52166 = or i1 %52163, %52165
  %52167 = load i32, i32* %12, align 4
  %52168 = icmp eq i32 %52145, %52167
  %52169 = or i1 %52166, %52168
  %52170 = load i32, i32* %13, align 4
  %52171 = icmp eq i32 %52145, %52170
  %52172 = or i1 %52169, %52171
  %52173 = load i32, i32* %14, align 4
  %52174 = icmp eq i32 %52145, %52173
  %52175 = or i1 %52172, %52174
  %52176 = load i32, i32* %15, align 4
  %52177 = icmp eq i32 %52145, %52176
  %52178 = or i1 %52175, %52177
  %52179 = load i32, i32* %16, align 4
  %52180 = icmp eq i32 %52145, %52179
  %52181 = or i1 %52178, %52180
  %52182 = load i32, i32* %17, align 4
  %52183 = icmp eq i32 %52145, %52182
  %52184 = or i1 %52181, %52183
  %52185 = load i32, i32* %18, align 4
  %52186 = icmp eq i32 %52145, %52185
  %52187 = or i1 %52184, %52186
  %52188 = load i32, i32* %19, align 4
  %52189 = icmp eq i32 %52145, %52188
  %52190 = or i1 %52187, %52189
  %52191 = load i32, i32* %20, align 4
  %52192 = icmp eq i32 %52145, %52191
  %52193 = or i1 %52190, %52192
  %52194 = load i32, i32* %21, align 4
  %52195 = icmp eq i32 %52145, %52194
  %52196 = or i1 %52193, %52195
  %52197 = load i32, i32* %22, align 4
  %52198 = icmp eq i32 %52145, %52197
  %52199 = or i1 %52196, %52198
  %52200 = load i32, i32* %23, align 4
  %52201 = icmp eq i32 %52145, %52200
  %52202 = or i1 %52199, %52201
  %52203 = load i32, i32* %24, align 4
  %52204 = icmp eq i32 %52145, %52203
  %52205 = or i1 %52202, %52204
  %52206 = load i32, i32* %25, align 4
  %52207 = icmp eq i32 %52145, %52206
  %52208 = or i1 %52205, %52207
  %52209 = load i32, i32* %26, align 4
  %52210 = icmp eq i32 %52145, %52209
  %52211 = or i1 %52208, %52210
  %52212 = load i32, i32* %27, align 4
  %52213 = icmp eq i32 %52145, %52212
  %52214 = or i1 %52211, %52213
  %52215 = load i32, i32* %28, align 4
  %52216 = icmp eq i32 %52145, %52215
  %52217 = or i1 %52214, %52216
  %52218 = load i32, i32* %29, align 4
  %52219 = icmp eq i32 %52145, %52218
  %52220 = or i1 %52217, %52219
  %52221 = load i32, i32* %30, align 4
  %52222 = icmp eq i32 %52145, %52221
  %52223 = or i1 %52220, %52222
  %52224 = load i32, i32* %31, align 4
  %52225 = icmp eq i32 %52145, %52224
  %52226 = or i1 %52223, %52225
  %52227 = load i32, i32* %32, align 4
  %52228 = icmp eq i32 %52145, %52227
  %52229 = or i1 %52226, %52228
  %52230 = load i32, i32* %33, align 4
  %52231 = icmp eq i32 %52145, %52230
  %52232 = or i1 %52229, %52231
  %52233 = load i32, i32* %34, align 4
  %52234 = icmp eq i32 %52145, %52233
  %52235 = or i1 %52232, %52234
  %52236 = load i32, i32* %35, align 4
  %52237 = icmp eq i32 %52145, %52236
  %52238 = or i1 %52235, %52237
  %52239 = load i32, i32* %36, align 4
  %52240 = icmp eq i32 %52145, %52239
  %52241 = or i1 %52238, %52240
  %52242 = load i32, i32* %37, align 4
  %52243 = icmp eq i32 %52145, %52242
  %52244 = or i1 %52241, %52243
  %52245 = load i32, i32* %38, align 4
  %52246 = icmp eq i32 %52145, %52245
  %52247 = or i1 %52244, %52246
  %52248 = load i32, i32* %39, align 4
  %52249 = icmp eq i32 %52145, %52248
  %52250 = or i1 %52247, %52249
  %52251 = load i32, i32* %40, align 4
  %52252 = icmp eq i32 %52145, %52251
  %52253 = or i1 %52250, %52252
  %52254 = load i32, i32* %41, align 4
  %52255 = icmp eq i32 %52145, %52254
  %52256 = or i1 %52253, %52255
  %52257 = load i32, i32* %42, align 4
  %52258 = icmp eq i32 %52145, %52257
  %52259 = or i1 %52256, %52258
  %52260 = load i32, i32* %43, align 4
  %52261 = icmp eq i32 %52145, %52260
  %52262 = or i1 %52259, %52261
  %52263 = load i32, i32* %44, align 4
  %52264 = icmp eq i32 %52145, %52263
  %52265 = or i1 %52262, %52264
  %52266 = load i32, i32* %45, align 4
  %52267 = icmp eq i32 %52145, %52266
  %52268 = or i1 %52265, %52267
  %52269 = load i32, i32* %46, align 4
  %52270 = icmp eq i32 %52145, %52269
  %52271 = or i1 %52268, %52270
  %52272 = load i32, i32* %47, align 4
  %52273 = icmp eq i32 %52145, %52272
  %52274 = or i1 %52271, %52273
  %52275 = load i32, i32* %48, align 4
  %52276 = icmp eq i32 %52145, %52275
  %52277 = or i1 %52274, %52276
  %52278 = load i32, i32* %49, align 4
  %52279 = icmp eq i32 %52145, %52278
  %52280 = or i1 %52277, %52279
  %52281 = load i32, i32* %50, align 4
  %52282 = icmp eq i32 %52145, %52281
  %52283 = or i1 %52280, %52282
  %52284 = load i32, i32* %51, align 4
  %52285 = icmp eq i32 %52145, %52284
  %52286 = or i1 %52283, %52285
  %52287 = load i32, i32* %52, align 4
  %52288 = icmp eq i32 %52145, %52287
  %52289 = or i1 %52286, %52288
  %52290 = load i32, i32* %53, align 4
  %52291 = icmp eq i32 %52145, %52290
  %52292 = or i1 %52289, %52291
  %52293 = load i32, i32* %54, align 4
  %52294 = icmp eq i32 %52145, %52293
  %52295 = or i1 %52292, %52294
  %52296 = load i32, i32* %55, align 4
  %52297 = icmp eq i32 %52145, %52296
  %52298 = or i1 %52295, %52297
  %52299 = load i32, i32* %56, align 4
  %52300 = icmp eq i32 %52145, %52299
  %52301 = or i1 %52298, %52300
  %52302 = load i32, i32* %57, align 4
  %52303 = icmp eq i32 %52145, %52302
  %52304 = or i1 %52301, %52303
  %52305 = load i32, i32* %58, align 4
  %52306 = icmp eq i32 %52145, %52305
  %52307 = or i1 %52304, %52306
  %52308 = load i32, i32* %59, align 4
  %52309 = icmp eq i32 %52145, %52308
  %52310 = or i1 %52307, %52309
  %52311 = load i32, i32* %60, align 4
  %52312 = icmp eq i32 %52145, %52311
  %52313 = or i1 %52310, %52312
  %52314 = load i32, i32* %61, align 4
  %52315 = icmp eq i32 %52145, %52314
  %52316 = or i1 %52313, %52315
  %52317 = load i32, i32* %62, align 4
  %52318 = icmp eq i32 %52145, %52317
  %52319 = or i1 %52316, %52318
  %52320 = getelementptr i8, i8 addrspace(1)* %4, i32 192
  %52321 = zext i1 %52319 to i8
  store i8 %52321, i8 addrspace(1)* %52320, align 1, !nosanitize !3
  %52322 = load i256, i256* %52144, align 4
  %52323 = mul i256 255, 1461501637330902918203684832716283019655932542976, !pc !755, !intsan !45
  %52324 = xor i256 %52323, -1
  %52325 = and i256 %52324, %52322
  %52326 = icmp eq i256 1, 0
  %52327 = icmp eq i1 %52326, false
  %52328 = zext i1 %52327 to i256
  %52329 = mul i256 %52328, 1461501637330902918203684832716283019655932542976, !pc !756, !intsan !45
  %52330 = or i256 %52329, %52325
  %52331 = alloca i256, align 8
  store i256 8, i256* %52331, align 4
  %52332 = alloca i256, align 8
  store i256 %52330, i256* %52332, align 4
  call void @__device_sstore(i256* %52331, i256* %52332)
  %52333 = call i32 @__hashword(i256* %52331)
  store i32 %52333, i32* %51, align 4, !nosanitize !3
  %52334 = trunc i256 64 to i64
  %52335 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %52334, i256* %52335)
  %52336 = load i256, i256* %52335, align 4
  %52337 = trunc i256 64 to i64
  %52338 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %52337, i256* %52338)
  %52339 = load i256, i256* %52338, align 4
  %52340 = sub i256 %52336, %52339, !pc !757, !intsan !8
  %52341 = trunc i256 37495094437807398806302164849837153474977970768503765070072680779894391288602 to i64
  call void @addBugSet(i64 %52341)
  br label %.16888

.16888:                                           ; preds = %.16816, %51880, %JumpTable
  %52342 = load i64, i64* %remaing_gas, align 4
  %52343 = icmp ugt i64 744, %52342
  br i1 %52343, label %Abort, label %52344

52344:                                            ; preds = %.16888
  %52345 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %52346 = xor i32 %52345, 2771
  %52347 = urem i32 %52346, 4096
  %52348 = getelementptr i8, i8 addrspace(1)* %4, i32 %52347
  %52349 = load i8, i8 addrspace(1)* %52348, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %52348, align 1, !nosanitize !3
  store i32 1385, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %52350 = sub i64 %52342, 744
  store i64 %52350, i64* %remaing_gas, align 4
  %52351 = load i64, i64* %STACK_DEP_PTR, align 4
  %52352 = getelementptr i256, i256* %STACK, i64 %52351
  %52353 = load i256, i256* %52352, align 4
  %52354 = load i64, i64* %STACK_DEP_PTR, align 4
  %52355 = sub i64 %52354, 1
  store i64 %52355, i64* %STACK_DEP_PTR, align 4
  %52356 = load i64, i64* %STACK_DEP_PTR, align 4
  %52357 = getelementptr i256, i256* %STACK, i64 %52356
  %52358 = load i256, i256* %52357, align 4
  %52359 = load i64, i64* %STACK_DEP_PTR, align 4
  %52360 = sub i64 %52359, 1
  store i64 %52360, i64* %STACK_DEP_PTR, align 4
  %52361 = load i64, i64* %STACK_DEP_PTR, align 4
  %52362 = getelementptr i256, i256* %STACK, i64 %52361
  %52363 = load i256, i256* %52362, align 4
  %52364 = load i64, i64* %STACK_DEP_PTR, align 4
  %52365 = sub i64 %52364, 1
  store i64 %52365, i64* %STACK_DEP_PTR, align 4
  %52366 = load i64, i64* %STACK_DEP_PTR, align 4
  %52367 = getelementptr i256, i256* %STACK, i64 %52366
  %52368 = load i256, i256* %52367, align 4
  %52369 = load i64, i64* %STACK_DEP_PTR, align 4
  %52370 = sub i64 %52369, 1
  store i64 %52370, i64* %STACK_DEP_PTR, align 4
  %52371 = load i64, i64* %STACK_DEP_PTR, align 4
  %52372 = getelementptr i256, i256* %STACK, i64 %52371
  %52373 = load i256, i256* %52372, align 4
  %52374 = load i64, i64* %STACK_DEP_PTR, align 4
  %52375 = sub i64 %52374, 1
  store i64 %52375, i64* %STACK_DEP_PTR, align 4
  %52376 = trunc i256 0 to i64
  %52377 = alloca i256, align 8
  store i256 %52368, i256* %52377, align 4
  %52378 = bitcast i256* %52377 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52376, i8* %52378, i64 32)
  %52379 = add i256 32, 0, !pc !758, !intsan !10
  %52380 = trunc i256 %52379 to i64
  %52381 = alloca i256, align 8
  store i256 4, i256* %52381, align 4
  %52382 = bitcast i256* %52381 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52380, i8* %52382, i64 32)
  %52383 = add i256 32, %52379, !pc !759, !intsan !10
  %52384 = trunc i256 0 to i32
  %52385 = trunc i256 %52383 to i32
  %52386 = getelementptr inbounds i8, i8* %MEMORY, i32 %52384
  %52387 = alloca i256, align 8
  %52388 = bitcast i256* %52387 to i8*
  call void @__device_sha3(i8* %52386, i32 %52385, i8* %52388)
  %52389 = load i256, i256* %52387, align 4
  %52390 = add i256 1, %52389, !pc !760, !intsan !10
  %52391 = alloca i256, align 8
  store i256 %52390, i256* %52391, align 4
  %52392 = alloca i256, align 8
  call void @__device_sload(i256* %52391, i256* %52392)
  %52393 = call i32 @__hashword(i256* %52391)
  %52394 = load i32, i32* %5, align 4
  %52395 = icmp eq i32 %52393, %52394
  %52396 = or i1 false, %52395
  %52397 = load i32, i32* %6, align 4
  %52398 = icmp eq i32 %52393, %52397
  %52399 = or i1 %52396, %52398
  %52400 = load i32, i32* %7, align 4
  %52401 = icmp eq i32 %52393, %52400
  %52402 = or i1 %52399, %52401
  %52403 = load i32, i32* %8, align 4
  %52404 = icmp eq i32 %52393, %52403
  %52405 = or i1 %52402, %52404
  %52406 = load i32, i32* %9, align 4
  %52407 = icmp eq i32 %52393, %52406
  %52408 = or i1 %52405, %52407
  %52409 = load i32, i32* %10, align 4
  %52410 = icmp eq i32 %52393, %52409
  %52411 = or i1 %52408, %52410
  %52412 = load i32, i32* %11, align 4
  %52413 = icmp eq i32 %52393, %52412
  %52414 = or i1 %52411, %52413
  %52415 = load i32, i32* %12, align 4
  %52416 = icmp eq i32 %52393, %52415
  %52417 = or i1 %52414, %52416
  %52418 = load i32, i32* %13, align 4
  %52419 = icmp eq i32 %52393, %52418
  %52420 = or i1 %52417, %52419
  %52421 = load i32, i32* %14, align 4
  %52422 = icmp eq i32 %52393, %52421
  %52423 = or i1 %52420, %52422
  %52424 = load i32, i32* %15, align 4
  %52425 = icmp eq i32 %52393, %52424
  %52426 = or i1 %52423, %52425
  %52427 = load i32, i32* %16, align 4
  %52428 = icmp eq i32 %52393, %52427
  %52429 = or i1 %52426, %52428
  %52430 = load i32, i32* %17, align 4
  %52431 = icmp eq i32 %52393, %52430
  %52432 = or i1 %52429, %52431
  %52433 = load i32, i32* %18, align 4
  %52434 = icmp eq i32 %52393, %52433
  %52435 = or i1 %52432, %52434
  %52436 = load i32, i32* %19, align 4
  %52437 = icmp eq i32 %52393, %52436
  %52438 = or i1 %52435, %52437
  %52439 = load i32, i32* %20, align 4
  %52440 = icmp eq i32 %52393, %52439
  %52441 = or i1 %52438, %52440
  %52442 = load i32, i32* %21, align 4
  %52443 = icmp eq i32 %52393, %52442
  %52444 = or i1 %52441, %52443
  %52445 = load i32, i32* %22, align 4
  %52446 = icmp eq i32 %52393, %52445
  %52447 = or i1 %52444, %52446
  %52448 = load i32, i32* %23, align 4
  %52449 = icmp eq i32 %52393, %52448
  %52450 = or i1 %52447, %52449
  %52451 = load i32, i32* %24, align 4
  %52452 = icmp eq i32 %52393, %52451
  %52453 = or i1 %52450, %52452
  %52454 = load i32, i32* %25, align 4
  %52455 = icmp eq i32 %52393, %52454
  %52456 = or i1 %52453, %52455
  %52457 = load i32, i32* %26, align 4
  %52458 = icmp eq i32 %52393, %52457
  %52459 = or i1 %52456, %52458
  %52460 = load i32, i32* %27, align 4
  %52461 = icmp eq i32 %52393, %52460
  %52462 = or i1 %52459, %52461
  %52463 = load i32, i32* %28, align 4
  %52464 = icmp eq i32 %52393, %52463
  %52465 = or i1 %52462, %52464
  %52466 = load i32, i32* %29, align 4
  %52467 = icmp eq i32 %52393, %52466
  %52468 = or i1 %52465, %52467
  %52469 = load i32, i32* %30, align 4
  %52470 = icmp eq i32 %52393, %52469
  %52471 = or i1 %52468, %52470
  %52472 = load i32, i32* %31, align 4
  %52473 = icmp eq i32 %52393, %52472
  %52474 = or i1 %52471, %52473
  %52475 = load i32, i32* %32, align 4
  %52476 = icmp eq i32 %52393, %52475
  %52477 = or i1 %52474, %52476
  %52478 = load i32, i32* %33, align 4
  %52479 = icmp eq i32 %52393, %52478
  %52480 = or i1 %52477, %52479
  %52481 = load i32, i32* %34, align 4
  %52482 = icmp eq i32 %52393, %52481
  %52483 = or i1 %52480, %52482
  %52484 = load i32, i32* %35, align 4
  %52485 = icmp eq i32 %52393, %52484
  %52486 = or i1 %52483, %52485
  %52487 = load i32, i32* %36, align 4
  %52488 = icmp eq i32 %52393, %52487
  %52489 = or i1 %52486, %52488
  %52490 = load i32, i32* %37, align 4
  %52491 = icmp eq i32 %52393, %52490
  %52492 = or i1 %52489, %52491
  %52493 = load i32, i32* %38, align 4
  %52494 = icmp eq i32 %52393, %52493
  %52495 = or i1 %52492, %52494
  %52496 = load i32, i32* %39, align 4
  %52497 = icmp eq i32 %52393, %52496
  %52498 = or i1 %52495, %52497
  %52499 = load i32, i32* %40, align 4
  %52500 = icmp eq i32 %52393, %52499
  %52501 = or i1 %52498, %52500
  %52502 = load i32, i32* %41, align 4
  %52503 = icmp eq i32 %52393, %52502
  %52504 = or i1 %52501, %52503
  %52505 = load i32, i32* %42, align 4
  %52506 = icmp eq i32 %52393, %52505
  %52507 = or i1 %52504, %52506
  %52508 = load i32, i32* %43, align 4
  %52509 = icmp eq i32 %52393, %52508
  %52510 = or i1 %52507, %52509
  %52511 = load i32, i32* %44, align 4
  %52512 = icmp eq i32 %52393, %52511
  %52513 = or i1 %52510, %52512
  %52514 = load i32, i32* %45, align 4
  %52515 = icmp eq i32 %52393, %52514
  %52516 = or i1 %52513, %52515
  %52517 = load i32, i32* %46, align 4
  %52518 = icmp eq i32 %52393, %52517
  %52519 = or i1 %52516, %52518
  %52520 = load i32, i32* %47, align 4
  %52521 = icmp eq i32 %52393, %52520
  %52522 = or i1 %52519, %52521
  %52523 = load i32, i32* %48, align 4
  %52524 = icmp eq i32 %52393, %52523
  %52525 = or i1 %52522, %52524
  %52526 = load i32, i32* %49, align 4
  %52527 = icmp eq i32 %52393, %52526
  %52528 = or i1 %52525, %52527
  %52529 = load i32, i32* %50, align 4
  %52530 = icmp eq i32 %52393, %52529
  %52531 = or i1 %52528, %52530
  %52532 = load i32, i32* %51, align 4
  %52533 = icmp eq i32 %52393, %52532
  %52534 = or i1 %52531, %52533
  %52535 = load i32, i32* %52, align 4
  %52536 = icmp eq i32 %52393, %52535
  %52537 = or i1 %52534, %52536
  %52538 = load i32, i32* %53, align 4
  %52539 = icmp eq i32 %52393, %52538
  %52540 = or i1 %52537, %52539
  %52541 = load i32, i32* %54, align 4
  %52542 = icmp eq i32 %52393, %52541
  %52543 = or i1 %52540, %52542
  %52544 = load i32, i32* %55, align 4
  %52545 = icmp eq i32 %52393, %52544
  %52546 = or i1 %52543, %52545
  %52547 = load i32, i32* %56, align 4
  %52548 = icmp eq i32 %52393, %52547
  %52549 = or i1 %52546, %52548
  %52550 = load i32, i32* %57, align 4
  %52551 = icmp eq i32 %52393, %52550
  %52552 = or i1 %52549, %52551
  %52553 = load i32, i32* %58, align 4
  %52554 = icmp eq i32 %52393, %52553
  %52555 = or i1 %52552, %52554
  %52556 = load i32, i32* %59, align 4
  %52557 = icmp eq i32 %52393, %52556
  %52558 = or i1 %52555, %52557
  %52559 = load i32, i32* %60, align 4
  %52560 = icmp eq i32 %52393, %52559
  %52561 = or i1 %52558, %52560
  %52562 = load i32, i32* %61, align 4
  %52563 = icmp eq i32 %52393, %52562
  %52564 = or i1 %52561, %52563
  %52565 = load i32, i32* %62, align 4
  %52566 = icmp eq i32 %52393, %52565
  %52567 = or i1 %52564, %52566
  %52568 = getelementptr i8, i8 addrspace(1)* %4, i32 193
  %52569 = zext i1 %52567 to i8
  store i8 %52569, i8 addrspace(1)* %52568, align 1, !nosanitize !3
  %52570 = load i256, i256* %52392, align 4
  %52571 = add i256 %52373, %52570, !pc !761, !intsan !10
  %52572 = icmp ult i256 %52571, %52373
  %52573 = icmp eq i1 %52572, false
  %52574 = icmp eq i1 %52573, false
  %52575 = trunc i256 16949 to i64
  %jump.check231 = icmp ne i1 %52574, false
  %52576 = load i64, i64* %STACK_DEP_PTR, align 4
  %52577 = add i64 %52576, 1
  store i64 %52577, i64* %STACK_DEP_PTR, align 4
  %52578 = load i64, i64* %STACK_DEP_PTR, align 4
  %52579 = getelementptr i256, i256* %STACK, i64 %52578
  store i256 %52373, i256* %52579, align 4
  %52580 = load i64, i64* %STACK_DEP_PTR, align 4
  %52581 = add i64 %52580, 1
  store i64 %52581, i64* %STACK_DEP_PTR, align 4
  %52582 = load i64, i64* %STACK_DEP_PTR, align 4
  %52583 = getelementptr i256, i256* %STACK, i64 %52582
  store i256 %52368, i256* %52583, align 4
  %52584 = load i64, i64* %STACK_DEP_PTR, align 4
  %52585 = add i64 %52584, 1
  store i64 %52585, i64* %STACK_DEP_PTR, align 4
  %52586 = load i64, i64* %STACK_DEP_PTR, align 4
  %52587 = getelementptr i256, i256* %STACK, i64 %52586
  store i256 %52363, i256* %52587, align 4
  %52588 = load i64, i64* %STACK_DEP_PTR, align 4
  %52589 = add i64 %52588, 1
  store i64 %52589, i64* %STACK_DEP_PTR, align 4
  %52590 = load i64, i64* %STACK_DEP_PTR, align 4
  %52591 = getelementptr i256, i256* %STACK, i64 %52590
  store i256 %52358, i256* %52591, align 4
  %52592 = load i64, i64* %STACK_DEP_PTR, align 4
  %52593 = add i64 %52592, 1
  store i64 %52593, i64* %STACK_DEP_PTR, align 4
  %52594 = load i64, i64* %STACK_DEP_PTR, align 4
  %52595 = getelementptr i256, i256* %STACK, i64 %52594
  store i256 %52353, i256* %52595, align 4
  br i1 %jump.check231, label %.16949, label %.16922, !EVMBB !4

.16922:                                           ; preds = %52344
  %52596 = load i64, i64* %STACK_DEP_PTR, align 4
  %52597 = getelementptr i256, i256* %STACK, i64 %52596
  %52598 = load i256, i256* %52597, align 4
  %52599 = load i64, i64* %STACK_DEP_PTR, align 4
  %52600 = sub i64 %52599, 1
  store i64 %52600, i64* %STACK_DEP_PTR, align 4
  %52601 = load i64, i64* %STACK_DEP_PTR, align 4
  %52602 = getelementptr i256, i256* %STACK, i64 %52601
  %52603 = load i256, i256* %52602, align 4
  %52604 = load i64, i64* %STACK_DEP_PTR, align 4
  %52605 = sub i64 %52604, 1
  store i64 %52605, i64* %STACK_DEP_PTR, align 4
  %52606 = load i64, i64* %STACK_DEP_PTR, align 4
  %52607 = getelementptr i256, i256* %STACK, i64 %52606
  %52608 = load i256, i256* %52607, align 4
  %52609 = load i64, i64* %STACK_DEP_PTR, align 4
  %52610 = sub i64 %52609, 1
  store i64 %52610, i64* %STACK_DEP_PTR, align 4
  %52611 = load i64, i64* %STACK_DEP_PTR, align 4
  %52612 = getelementptr i256, i256* %STACK, i64 %52611
  %52613 = load i256, i256* %52612, align 4
  %52614 = load i64, i64* %STACK_DEP_PTR, align 4
  %52615 = sub i64 %52614, 1
  store i64 %52615, i64* %STACK_DEP_PTR, align 4
  %52616 = load i64, i64* %STACK_DEP_PTR, align 4
  %52617 = getelementptr i256, i256* %STACK, i64 %52616
  %52618 = load i256, i256* %52617, align 4
  %52619 = load i64, i64* %STACK_DEP_PTR, align 4
  %52620 = sub i64 %52619, 1
  store i64 %52620, i64* %STACK_DEP_PTR, align 4
  %52621 = trunc i256 0 to i64
  %52622 = alloca i256, align 8
  store i256 %52613, i256* %52622, align 4
  %52623 = bitcast i256* %52622 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52621, i8* %52623, i64 32)
  %52624 = add i256 32, 0, !pc !762, !intsan !10
  %52625 = trunc i256 %52624 to i64
  %52626 = alloca i256, align 8
  store i256 4, i256* %52626, align 4
  %52627 = bitcast i256* %52626 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %52625, i8* %52627, i64 32)
  %52628 = add i256 32, %52624, !pc !763, !intsan !10
  %52629 = trunc i256 0 to i32
  %52630 = trunc i256 %52628 to i32
  %52631 = getelementptr inbounds i8, i8* %MEMORY, i32 %52629
  %52632 = alloca i256, align 8
  %52633 = bitcast i256* %52632 to i8*
  call void @__device_sha3(i8* %52631, i32 %52630, i8* %52633)
  %52634 = load i256, i256* %52632, align 4
  %52635 = add i256 1, %52634, !pc !764, !intsan !10
  %52636 = alloca i256, align 8
  store i256 %52635, i256* %52636, align 4
  %52637 = alloca i256, align 8
  call void @__device_sload(i256* %52636, i256* %52637)
  %52638 = call i32 @__hashword(i256* %52636)
  %52639 = load i32, i32* %5, align 4
  %52640 = icmp eq i32 %52638, %52639
  %52641 = or i1 false, %52640
  %52642 = load i32, i32* %6, align 4
  %52643 = icmp eq i32 %52638, %52642
  %52644 = or i1 %52641, %52643
  %52645 = load i32, i32* %7, align 4
  %52646 = icmp eq i32 %52638, %52645
  %52647 = or i1 %52644, %52646
  %52648 = load i32, i32* %8, align 4
  %52649 = icmp eq i32 %52638, %52648
  %52650 = or i1 %52647, %52649
  %52651 = load i32, i32* %9, align 4
  %52652 = icmp eq i32 %52638, %52651
  %52653 = or i1 %52650, %52652
  %52654 = load i32, i32* %10, align 4
  %52655 = icmp eq i32 %52638, %52654
  %52656 = or i1 %52653, %52655
  %52657 = load i32, i32* %11, align 4
  %52658 = icmp eq i32 %52638, %52657
  %52659 = or i1 %52656, %52658
  %52660 = load i32, i32* %12, align 4
  %52661 = icmp eq i32 %52638, %52660
  %52662 = or i1 %52659, %52661
  %52663 = load i32, i32* %13, align 4
  %52664 = icmp eq i32 %52638, %52663
  %52665 = or i1 %52662, %52664
  %52666 = load i32, i32* %14, align 4
  %52667 = icmp eq i32 %52638, %52666
  %52668 = or i1 %52665, %52667
  %52669 = load i32, i32* %15, align 4
  %52670 = icmp eq i32 %52638, %52669
  %52671 = or i1 %52668, %52670
  %52672 = load i32, i32* %16, align 4
  %52673 = icmp eq i32 %52638, %52672
  %52674 = or i1 %52671, %52673
  %52675 = load i32, i32* %17, align 4
  %52676 = icmp eq i32 %52638, %52675
  %52677 = or i1 %52674, %52676
  %52678 = load i32, i32* %18, align 4
  %52679 = icmp eq i32 %52638, %52678
  %52680 = or i1 %52677, %52679
  %52681 = load i32, i32* %19, align 4
  %52682 = icmp eq i32 %52638, %52681
  %52683 = or i1 %52680, %52682
  %52684 = load i32, i32* %20, align 4
  %52685 = icmp eq i32 %52638, %52684
  %52686 = or i1 %52683, %52685
  %52687 = load i32, i32* %21, align 4
  %52688 = icmp eq i32 %52638, %52687
  %52689 = or i1 %52686, %52688
  %52690 = load i32, i32* %22, align 4
  %52691 = icmp eq i32 %52638, %52690
  %52692 = or i1 %52689, %52691
  %52693 = load i32, i32* %23, align 4
  %52694 = icmp eq i32 %52638, %52693
  %52695 = or i1 %52692, %52694
  %52696 = load i32, i32* %24, align 4
  %52697 = icmp eq i32 %52638, %52696
  %52698 = or i1 %52695, %52697
  %52699 = load i32, i32* %25, align 4
  %52700 = icmp eq i32 %52638, %52699
  %52701 = or i1 %52698, %52700
  %52702 = load i32, i32* %26, align 4
  %52703 = icmp eq i32 %52638, %52702
  %52704 = or i1 %52701, %52703
  %52705 = load i32, i32* %27, align 4
  %52706 = icmp eq i32 %52638, %52705
  %52707 = or i1 %52704, %52706
  %52708 = load i32, i32* %28, align 4
  %52709 = icmp eq i32 %52638, %52708
  %52710 = or i1 %52707, %52709
  %52711 = load i32, i32* %29, align 4
  %52712 = icmp eq i32 %52638, %52711
  %52713 = or i1 %52710, %52712
  %52714 = load i32, i32* %30, align 4
  %52715 = icmp eq i32 %52638, %52714
  %52716 = or i1 %52713, %52715
  %52717 = load i32, i32* %31, align 4
  %52718 = icmp eq i32 %52638, %52717
  %52719 = or i1 %52716, %52718
  %52720 = load i32, i32* %32, align 4
  %52721 = icmp eq i32 %52638, %52720
  %52722 = or i1 %52719, %52721
  %52723 = load i32, i32* %33, align 4
  %52724 = icmp eq i32 %52638, %52723
  %52725 = or i1 %52722, %52724
  %52726 = load i32, i32* %34, align 4
  %52727 = icmp eq i32 %52638, %52726
  %52728 = or i1 %52725, %52727
  %52729 = load i32, i32* %35, align 4
  %52730 = icmp eq i32 %52638, %52729
  %52731 = or i1 %52728, %52730
  %52732 = load i32, i32* %36, align 4
  %52733 = icmp eq i32 %52638, %52732
  %52734 = or i1 %52731, %52733
  %52735 = load i32, i32* %37, align 4
  %52736 = icmp eq i32 %52638, %52735
  %52737 = or i1 %52734, %52736
  %52738 = load i32, i32* %38, align 4
  %52739 = icmp eq i32 %52638, %52738
  %52740 = or i1 %52737, %52739
  %52741 = load i32, i32* %39, align 4
  %52742 = icmp eq i32 %52638, %52741
  %52743 = or i1 %52740, %52742
  %52744 = load i32, i32* %40, align 4
  %52745 = icmp eq i32 %52638, %52744
  %52746 = or i1 %52743, %52745
  %52747 = load i32, i32* %41, align 4
  %52748 = icmp eq i32 %52638, %52747
  %52749 = or i1 %52746, %52748
  %52750 = load i32, i32* %42, align 4
  %52751 = icmp eq i32 %52638, %52750
  %52752 = or i1 %52749, %52751
  %52753 = load i32, i32* %43, align 4
  %52754 = icmp eq i32 %52638, %52753
  %52755 = or i1 %52752, %52754
  %52756 = load i32, i32* %44, align 4
  %52757 = icmp eq i32 %52638, %52756
  %52758 = or i1 %52755, %52757
  %52759 = load i32, i32* %45, align 4
  %52760 = icmp eq i32 %52638, %52759
  %52761 = or i1 %52758, %52760
  %52762 = load i32, i32* %46, align 4
  %52763 = icmp eq i32 %52638, %52762
  %52764 = or i1 %52761, %52763
  %52765 = load i32, i32* %47, align 4
  %52766 = icmp eq i32 %52638, %52765
  %52767 = or i1 %52764, %52766
  %52768 = load i32, i32* %48, align 4
  %52769 = icmp eq i32 %52638, %52768
  %52770 = or i1 %52767, %52769
  %52771 = load i32, i32* %49, align 4
  %52772 = icmp eq i32 %52638, %52771
  %52773 = or i1 %52770, %52772
  %52774 = load i32, i32* %50, align 4
  %52775 = icmp eq i32 %52638, %52774
  %52776 = or i1 %52773, %52775
  %52777 = load i32, i32* %51, align 4
  %52778 = icmp eq i32 %52638, %52777
  %52779 = or i1 %52776, %52778
  %52780 = load i32, i32* %52, align 4
  %52781 = icmp eq i32 %52638, %52780
  %52782 = or i1 %52779, %52781
  %52783 = load i32, i32* %53, align 4
  %52784 = icmp eq i32 %52638, %52783
  %52785 = or i1 %52782, %52784
  %52786 = load i32, i32* %54, align 4
  %52787 = icmp eq i32 %52638, %52786
  %52788 = or i1 %52785, %52787
  %52789 = load i32, i32* %55, align 4
  %52790 = icmp eq i32 %52638, %52789
  %52791 = or i1 %52788, %52790
  %52792 = load i32, i32* %56, align 4
  %52793 = icmp eq i32 %52638, %52792
  %52794 = or i1 %52791, %52793
  %52795 = load i32, i32* %57, align 4
  %52796 = icmp eq i32 %52638, %52795
  %52797 = or i1 %52794, %52796
  %52798 = load i32, i32* %58, align 4
  %52799 = icmp eq i32 %52638, %52798
  %52800 = or i1 %52797, %52799
  %52801 = load i32, i32* %59, align 4
  %52802 = icmp eq i32 %52638, %52801
  %52803 = or i1 %52800, %52802
  %52804 = load i32, i32* %60, align 4
  %52805 = icmp eq i32 %52638, %52804
  %52806 = or i1 %52803, %52805
  %52807 = load i32, i32* %61, align 4
  %52808 = icmp eq i32 %52638, %52807
  %52809 = or i1 %52806, %52808
  %52810 = load i32, i32* %62, align 4
  %52811 = icmp eq i32 %52638, %52810
  %52812 = or i1 %52809, %52811
  %52813 = getelementptr i8, i8 addrspace(1)* %4, i32 194
  %52814 = zext i1 %52812 to i8
  store i8 %52814, i8 addrspace(1)* %52813, align 1, !nosanitize !3
  %52815 = load i256, i256* %52637, align 4
  %52816 = add i256 %52618, %52815, !pc !765, !intsan !10
  %52817 = load i64, i64* %STACK_DEP_PTR, align 4
  %52818 = add i64 %52817, 1
  store i64 %52818, i64* %STACK_DEP_PTR, align 4
  %52819 = load i64, i64* %STACK_DEP_PTR, align 4
  %52820 = getelementptr i256, i256* %STACK, i64 %52819
  store i256 %52816, i256* %52820, align 4
  %52821 = load i64, i64* %STACK_DEP_PTR, align 4
  %52822 = add i64 %52821, 1
  store i64 %52822, i64* %STACK_DEP_PTR, align 4
  %52823 = load i64, i64* %STACK_DEP_PTR, align 4
  %52824 = getelementptr i256, i256* %STACK, i64 %52823
  store i256 %52613, i256* %52824, align 4
  %52825 = load i64, i64* %STACK_DEP_PTR, align 4
  %52826 = add i64 %52825, 1
  store i64 %52826, i64* %STACK_DEP_PTR, align 4
  %52827 = load i64, i64* %STACK_DEP_PTR, align 4
  %52828 = getelementptr i256, i256* %STACK, i64 %52827
  store i256 %52608, i256* %52828, align 4
  %52829 = load i64, i64* %STACK_DEP_PTR, align 4
  %52830 = add i64 %52829, 1
  store i64 %52830, i64* %STACK_DEP_PTR, align 4
  %52831 = load i64, i64* %STACK_DEP_PTR, align 4
  %52832 = getelementptr i256, i256* %STACK, i64 %52831
  store i256 %52603, i256* %52832, align 4
  %52833 = load i64, i64* %STACK_DEP_PTR, align 4
  %52834 = add i64 %52833, 1
  store i64 %52834, i64* %STACK_DEP_PTR, align 4
  %52835 = load i64, i64* %STACK_DEP_PTR, align 4
  %52836 = getelementptr i256, i256* %STACK, i64 %52835
  store i256 %52598, i256* %52836, align 4
  br label %.16949

.16949:                                           ; preds = %.16922, %52344, %JumpTable
  %52837 = load i64, i64* %remaing_gas, align 4
  %52838 = icmp ugt i64 416, %52837
  br i1 %52838, label %Abort, label %52839

52839:                                            ; preds = %.16949
  %52840 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %52841 = xor i32 %52840, 3225
  %52842 = urem i32 %52841, 4096
  %52843 = getelementptr i8, i8 addrspace(1)* %4, i32 %52842
  %52844 = load i8, i8 addrspace(1)* %52843, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %52843, align 1, !nosanitize !3
  store i32 1612, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %52845 = sub i64 %52837, 416
  store i64 %52845, i64* %remaing_gas, align 4
  %52846 = load i64, i64* %STACK_DEP_PTR, align 4
  %52847 = getelementptr i256, i256* %STACK, i64 %52846
  %52848 = load i256, i256* %52847, align 4
  %52849 = load i64, i64* %STACK_DEP_PTR, align 4
  %52850 = sub i64 %52849, 1
  store i64 %52850, i64* %STACK_DEP_PTR, align 4
  %52851 = load i64, i64* %STACK_DEP_PTR, align 4
  %52852 = getelementptr i256, i256* %STACK, i64 %52851
  %52853 = load i256, i256* %52852, align 4
  %52854 = load i64, i64* %STACK_DEP_PTR, align 4
  %52855 = sub i64 %52854, 1
  store i64 %52855, i64* %STACK_DEP_PTR, align 4
  %52856 = load i64, i64* %STACK_DEP_PTR, align 4
  %52857 = getelementptr i256, i256* %STACK, i64 %52856
  %52858 = load i256, i256* %52857, align 4
  %52859 = load i64, i64* %STACK_DEP_PTR, align 4
  %52860 = sub i64 %52859, 1
  store i64 %52860, i64* %STACK_DEP_PTR, align 4
  %52861 = load i64, i64* %STACK_DEP_PTR, align 4
  %52862 = getelementptr i256, i256* %STACK, i64 %52861
  %52863 = load i256, i256* %52862, align 4
  %52864 = load i64, i64* %STACK_DEP_PTR, align 4
  %52865 = sub i64 %52864, 1
  store i64 %52865, i64* %STACK_DEP_PTR, align 4
  %52866 = add i256 1, %52863, !pc !766, !intsan !10
  %52867 = trunc i256 16483 to i64
  %52868 = load i64, i64* %STACK_DEP_PTR, align 4
  %52869 = add i64 %52868, 1
  store i64 %52869, i64* %STACK_DEP_PTR, align 4
  %52870 = load i64, i64* %STACK_DEP_PTR, align 4
  %52871 = getelementptr i256, i256* %STACK, i64 %52870
  store i256 %52866, i256* %52871, align 4
  %52872 = load i64, i64* %STACK_DEP_PTR, align 4
  %52873 = add i64 %52872, 1
  store i64 %52873, i64* %STACK_DEP_PTR, align 4
  %52874 = load i64, i64* %STACK_DEP_PTR, align 4
  %52875 = getelementptr i256, i256* %STACK, i64 %52874
  store i256 %52858, i256* %52875, align 4
  %52876 = load i64, i64* %STACK_DEP_PTR, align 4
  %52877 = add i64 %52876, 1
  store i64 %52877, i64* %STACK_DEP_PTR, align 4
  %52878 = load i64, i64* %STACK_DEP_PTR, align 4
  %52879 = getelementptr i256, i256* %STACK, i64 %52878
  store i256 %52853, i256* %52879, align 4
  %52880 = load i64, i64* %STACK_DEP_PTR, align 4
  %52881 = add i64 %52880, 1
  store i64 %52881, i64* %STACK_DEP_PTR, align 4
  %52882 = load i64, i64* %STACK_DEP_PTR, align 4
  %52883 = getelementptr i256, i256* %STACK, i64 %52882
  store i256 %52848, i256* %52883, align 4
  br label %.16483, !EVMBB !4

.16962:                                           ; preds = %50637, %JumpTable
  %52884 = load i64, i64* %STACK_DEP_PTR, align 4
  %52885 = getelementptr i256, i256* %STACK, i64 %52884
  %52886 = load i256, i256* %52885, align 4
  %52887 = load i64, i64* %STACK_DEP_PTR, align 4
  %52888 = sub i64 %52887, 1
  store i64 %52888, i64* %STACK_DEP_PTR, align 4
  %52889 = load i64, i64* %STACK_DEP_PTR, align 4
  %52890 = getelementptr i256, i256* %STACK, i64 %52889
  %52891 = load i256, i256* %52890, align 4
  %52892 = load i64, i64* %STACK_DEP_PTR, align 4
  %52893 = sub i64 %52892, 1
  store i64 %52893, i64* %STACK_DEP_PTR, align 4
  %52894 = load i64, i64* %STACK_DEP_PTR, align 4
  %52895 = getelementptr i256, i256* %STACK, i64 %52894
  %52896 = load i256, i256* %52895, align 4
  %52897 = load i64, i64* %STACK_DEP_PTR, align 4
  %52898 = sub i64 %52897, 1
  store i64 %52898, i64* %STACK_DEP_PTR, align 4
  %52899 = load i64, i64* %STACK_DEP_PTR, align 4
  %52900 = getelementptr i256, i256* %STACK, i64 %52899
  %52901 = load i256, i256* %52900, align 4
  %52902 = load i64, i64* %STACK_DEP_PTR, align 4
  %52903 = sub i64 %52902, 1
  store i64 %52903, i64* %STACK_DEP_PTR, align 4
  %52904 = load i64, i64* %STACK_DEP_PTR, align 4
  %52905 = getelementptr i256, i256* %STACK, i64 %52904
  %52906 = load i256, i256* %52905, align 4
  %52907 = load i64, i64* %STACK_DEP_PTR, align 4
  %52908 = sub i64 %52907, 1
  store i64 %52908, i64* %STACK_DEP_PTR, align 4
  %52909 = alloca i256, align 8
  store i256 13, i256* %52909, align 4
  %52910 = alloca i256, align 8
  store i256 0, i256* %52910, align 4
  call void @__device_sstore(i256* %52909, i256* %52910)
  %52911 = call i32 @__hashword(i256* %52909)
  store i32 %52911, i32* %52, align 4, !nosanitize !3
  %52912 = alloca i256, align 8
  store i256 14, i256* %52912, align 4
  %52913 = alloca i256, align 8
  store i256 0, i256* %52913, align 4
  call void @__device_sstore(i256* %52912, i256* %52913)
  %52914 = call i32 @__hashword(i256* %52912)
  store i32 %52914, i32* %53, align 4, !nosanitize !3
  %52915 = alloca i256, align 8
  store i256 6, i256* %52915, align 4
  %52916 = alloca i256, align 8
  store i256 %52906, i256* %52916, align 4
  call void @__device_sstore(i256* %52915, i256* %52916)
  %52917 = call i32 @__hashword(i256* %52915)
  store i32 %52917, i32* %54, align 4, !nosanitize !3
  %52918 = alloca i256, align 8
  store i256 15, i256* %52918, align 4
  %52919 = alloca i256, align 8
  call void @__device_sload(i256* %52918, i256* %52919)
  %52920 = call i32 @__hashword(i256* %52918)
  %52921 = load i32, i32* %5, align 4
  %52922 = icmp eq i32 %52920, %52921
  %52923 = or i1 false, %52922
  %52924 = load i32, i32* %6, align 4
  %52925 = icmp eq i32 %52920, %52924
  %52926 = or i1 %52923, %52925
  %52927 = load i32, i32* %7, align 4
  %52928 = icmp eq i32 %52920, %52927
  %52929 = or i1 %52926, %52928
  %52930 = load i32, i32* %8, align 4
  %52931 = icmp eq i32 %52920, %52930
  %52932 = or i1 %52929, %52931
  %52933 = load i32, i32* %9, align 4
  %52934 = icmp eq i32 %52920, %52933
  %52935 = or i1 %52932, %52934
  %52936 = load i32, i32* %10, align 4
  %52937 = icmp eq i32 %52920, %52936
  %52938 = or i1 %52935, %52937
  %52939 = load i32, i32* %11, align 4
  %52940 = icmp eq i32 %52920, %52939
  %52941 = or i1 %52938, %52940
  %52942 = load i32, i32* %12, align 4
  %52943 = icmp eq i32 %52920, %52942
  %52944 = or i1 %52941, %52943
  %52945 = load i32, i32* %13, align 4
  %52946 = icmp eq i32 %52920, %52945
  %52947 = or i1 %52944, %52946
  %52948 = load i32, i32* %14, align 4
  %52949 = icmp eq i32 %52920, %52948
  %52950 = or i1 %52947, %52949
  %52951 = load i32, i32* %15, align 4
  %52952 = icmp eq i32 %52920, %52951
  %52953 = or i1 %52950, %52952
  %52954 = load i32, i32* %16, align 4
  %52955 = icmp eq i32 %52920, %52954
  %52956 = or i1 %52953, %52955
  %52957 = load i32, i32* %17, align 4
  %52958 = icmp eq i32 %52920, %52957
  %52959 = or i1 %52956, %52958
  %52960 = load i32, i32* %18, align 4
  %52961 = icmp eq i32 %52920, %52960
  %52962 = or i1 %52959, %52961
  %52963 = load i32, i32* %19, align 4
  %52964 = icmp eq i32 %52920, %52963
  %52965 = or i1 %52962, %52964
  %52966 = load i32, i32* %20, align 4
  %52967 = icmp eq i32 %52920, %52966
  %52968 = or i1 %52965, %52967
  %52969 = load i32, i32* %21, align 4
  %52970 = icmp eq i32 %52920, %52969
  %52971 = or i1 %52968, %52970
  %52972 = load i32, i32* %22, align 4
  %52973 = icmp eq i32 %52920, %52972
  %52974 = or i1 %52971, %52973
  %52975 = load i32, i32* %23, align 4
  %52976 = icmp eq i32 %52920, %52975
  %52977 = or i1 %52974, %52976
  %52978 = load i32, i32* %24, align 4
  %52979 = icmp eq i32 %52920, %52978
  %52980 = or i1 %52977, %52979
  %52981 = load i32, i32* %25, align 4
  %52982 = icmp eq i32 %52920, %52981
  %52983 = or i1 %52980, %52982
  %52984 = load i32, i32* %26, align 4
  %52985 = icmp eq i32 %52920, %52984
  %52986 = or i1 %52983, %52985
  %52987 = load i32, i32* %27, align 4
  %52988 = icmp eq i32 %52920, %52987
  %52989 = or i1 %52986, %52988
  %52990 = load i32, i32* %28, align 4
  %52991 = icmp eq i32 %52920, %52990
  %52992 = or i1 %52989, %52991
  %52993 = load i32, i32* %29, align 4
  %52994 = icmp eq i32 %52920, %52993
  %52995 = or i1 %52992, %52994
  %52996 = load i32, i32* %30, align 4
  %52997 = icmp eq i32 %52920, %52996
  %52998 = or i1 %52995, %52997
  %52999 = load i32, i32* %31, align 4
  %53000 = icmp eq i32 %52920, %52999
  %53001 = or i1 %52998, %53000
  %53002 = load i32, i32* %32, align 4
  %53003 = icmp eq i32 %52920, %53002
  %53004 = or i1 %53001, %53003
  %53005 = load i32, i32* %33, align 4
  %53006 = icmp eq i32 %52920, %53005
  %53007 = or i1 %53004, %53006
  %53008 = load i32, i32* %34, align 4
  %53009 = icmp eq i32 %52920, %53008
  %53010 = or i1 %53007, %53009
  %53011 = load i32, i32* %35, align 4
  %53012 = icmp eq i32 %52920, %53011
  %53013 = or i1 %53010, %53012
  %53014 = load i32, i32* %36, align 4
  %53015 = icmp eq i32 %52920, %53014
  %53016 = or i1 %53013, %53015
  %53017 = load i32, i32* %37, align 4
  %53018 = icmp eq i32 %52920, %53017
  %53019 = or i1 %53016, %53018
  %53020 = load i32, i32* %38, align 4
  %53021 = icmp eq i32 %52920, %53020
  %53022 = or i1 %53019, %53021
  %53023 = load i32, i32* %39, align 4
  %53024 = icmp eq i32 %52920, %53023
  %53025 = or i1 %53022, %53024
  %53026 = load i32, i32* %40, align 4
  %53027 = icmp eq i32 %52920, %53026
  %53028 = or i1 %53025, %53027
  %53029 = load i32, i32* %41, align 4
  %53030 = icmp eq i32 %52920, %53029
  %53031 = or i1 %53028, %53030
  %53032 = load i32, i32* %42, align 4
  %53033 = icmp eq i32 %52920, %53032
  %53034 = or i1 %53031, %53033
  %53035 = load i32, i32* %43, align 4
  %53036 = icmp eq i32 %52920, %53035
  %53037 = or i1 %53034, %53036
  %53038 = load i32, i32* %44, align 4
  %53039 = icmp eq i32 %52920, %53038
  %53040 = or i1 %53037, %53039
  %53041 = load i32, i32* %45, align 4
  %53042 = icmp eq i32 %52920, %53041
  %53043 = or i1 %53040, %53042
  %53044 = load i32, i32* %46, align 4
  %53045 = icmp eq i32 %52920, %53044
  %53046 = or i1 %53043, %53045
  %53047 = load i32, i32* %47, align 4
  %53048 = icmp eq i32 %52920, %53047
  %53049 = or i1 %53046, %53048
  %53050 = load i32, i32* %48, align 4
  %53051 = icmp eq i32 %52920, %53050
  %53052 = or i1 %53049, %53051
  %53053 = load i32, i32* %49, align 4
  %53054 = icmp eq i32 %52920, %53053
  %53055 = or i1 %53052, %53054
  %53056 = load i32, i32* %50, align 4
  %53057 = icmp eq i32 %52920, %53056
  %53058 = or i1 %53055, %53057
  %53059 = load i32, i32* %51, align 4
  %53060 = icmp eq i32 %52920, %53059
  %53061 = or i1 %53058, %53060
  %53062 = load i32, i32* %52, align 4
  %53063 = icmp eq i32 %52920, %53062
  %53064 = or i1 %53061, %53063
  %53065 = load i32, i32* %53, align 4
  %53066 = icmp eq i32 %52920, %53065
  %53067 = or i1 %53064, %53066
  %53068 = load i32, i32* %54, align 4
  %53069 = icmp eq i32 %52920, %53068
  %53070 = or i1 %53067, %53069
  %53071 = load i32, i32* %55, align 4
  %53072 = icmp eq i32 %52920, %53071
  %53073 = or i1 %53070, %53072
  %53074 = load i32, i32* %56, align 4
  %53075 = icmp eq i32 %52920, %53074
  %53076 = or i1 %53073, %53075
  %53077 = load i32, i32* %57, align 4
  %53078 = icmp eq i32 %52920, %53077
  %53079 = or i1 %53076, %53078
  %53080 = load i32, i32* %58, align 4
  %53081 = icmp eq i32 %52920, %53080
  %53082 = or i1 %53079, %53081
  %53083 = load i32, i32* %59, align 4
  %53084 = icmp eq i32 %52920, %53083
  %53085 = or i1 %53082, %53084
  %53086 = load i32, i32* %60, align 4
  %53087 = icmp eq i32 %52920, %53086
  %53088 = or i1 %53085, %53087
  %53089 = load i32, i32* %61, align 4
  %53090 = icmp eq i32 %52920, %53089
  %53091 = or i1 %53088, %53090
  %53092 = load i32, i32* %62, align 4
  %53093 = icmp eq i32 %52920, %53092
  %53094 = or i1 %53091, %53093
  %53095 = getelementptr i8, i8 addrspace(1)* %4, i32 195
  %53096 = zext i1 %53094 to i8
  store i8 %53096, i8 addrspace(1)* %53095, align 1, !nosanitize !3
  %53097 = load i256, i256* %52919, align 4
  %53098 = mul i256 255, 1, !pc !767, !intsan !45
  %53099 = xor i256 %53098, -1
  %53100 = and i256 %53099, %53097
  %53101 = icmp eq i256 1, 0
  %53102 = icmp eq i1 %53101, false
  %53103 = zext i1 %53102 to i256
  %53104 = mul i256 %53103, 1, !pc !768, !intsan !45
  %53105 = or i256 %53104, %53100
  %53106 = alloca i256, align 8
  store i256 15, i256* %53106, align 4
  %53107 = alloca i256, align 8
  store i256 %53105, i256* %53107, align 4
  call void @__device_sstore(i256* %53106, i256* %53107)
  %53108 = call i32 @__hashword(i256* %53106)
  store i32 %53108, i32* %55, align 4, !nosanitize !3
  %53109 = load i64, i64* %STACK_DEP_PTR, align 4
  %53110 = add i64 %53109, 1
  store i64 %53110, i64* %STACK_DEP_PTR, align 4
  %53111 = load i64, i64* %STACK_DEP_PTR, align 4
  %53112 = getelementptr i256, i256* %STACK, i64 %53111
  store i256 %52906, i256* %53112, align 4
  %53113 = load i64, i64* %STACK_DEP_PTR, align 4
  %53114 = add i64 %53113, 1
  store i64 %53114, i64* %STACK_DEP_PTR, align 4
  %53115 = load i64, i64* %STACK_DEP_PTR, align 4
  %53116 = getelementptr i256, i256* %STACK, i64 %53115
  store i256 %52901, i256* %53116, align 4
  %53117 = load i64, i64* %STACK_DEP_PTR, align 4
  %53118 = add i64 %53117, 1
  store i64 %53118, i64* %STACK_DEP_PTR, align 4
  %53119 = load i64, i64* %STACK_DEP_PTR, align 4
  %53120 = getelementptr i256, i256* %STACK, i64 %53119
  store i256 %52896, i256* %53120, align 4
  %53121 = load i64, i64* %STACK_DEP_PTR, align 4
  %53122 = add i64 %53121, 1
  store i64 %53122, i64* %STACK_DEP_PTR, align 4
  %53123 = load i64, i64* %STACK_DEP_PTR, align 4
  %53124 = getelementptr i256, i256* %STACK, i64 %53123
  store i256 %52891, i256* %53124, align 4
  %53125 = load i64, i64* %STACK_DEP_PTR, align 4
  %53126 = add i64 %53125, 1
  store i64 %53126, i64* %STACK_DEP_PTR, align 4
  %53127 = load i64, i64* %STACK_DEP_PTR, align 4
  %53128 = getelementptr i256, i256* %STACK, i64 %53127
  store i256 %52886, i256* %53128, align 4
  br label %.17009

.17009:                                           ; preds = %.16962, %50402, %JumpTable
  %53129 = load i64, i64* %remaing_gas, align 4
  %53130 = icmp ugt i64 320, %53129
  br i1 %53130, label %Abort, label %53131

53131:                                            ; preds = %.17009
  %53132 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53133 = xor i32 %53132, 2380
  %53134 = urem i32 %53133, 4096
  %53135 = getelementptr i8, i8 addrspace(1)* %4, i32 %53134
  %53136 = load i8, i8 addrspace(1)* %53135, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53135, align 1, !nosanitize !3
  store i32 1190, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53137 = sub i64 %53129, 320
  store i64 %53137, i64* %remaing_gas, align 4
  %53138 = load i64, i64* %STACK_DEP_PTR, align 4
  %53139 = getelementptr i256, i256* %STACK, i64 %53138
  %53140 = load i256, i256* %53139, align 4
  %53141 = load i64, i64* %STACK_DEP_PTR, align 4
  %53142 = sub i64 %53141, 1
  store i64 %53142, i64* %STACK_DEP_PTR, align 4
  %53143 = load i64, i64* %STACK_DEP_PTR, align 4
  %53144 = getelementptr i256, i256* %STACK, i64 %53143
  %53145 = load i256, i256* %53144, align 4
  %53146 = load i64, i64* %STACK_DEP_PTR, align 4
  %53147 = sub i64 %53146, 1
  store i64 %53147, i64* %STACK_DEP_PTR, align 4
  %53148 = load i64, i64* %STACK_DEP_PTR, align 4
  %53149 = getelementptr i256, i256* %STACK, i64 %53148
  %53150 = load i256, i256* %53149, align 4
  %53151 = load i64, i64* %STACK_DEP_PTR, align 4
  %53152 = sub i64 %53151, 1
  store i64 %53152, i64* %STACK_DEP_PTR, align 4
  %53153 = load i64, i64* %STACK_DEP_PTR, align 4
  %53154 = getelementptr i256, i256* %STACK, i64 %53153
  %53155 = load i256, i256* %53154, align 4
  %53156 = load i64, i64* %STACK_DEP_PTR, align 4
  %53157 = sub i64 %53156, 1
  store i64 %53157, i64* %STACK_DEP_PTR, align 4
  %53158 = load i64, i64* %STACK_DEP_PTR, align 4
  %53159 = getelementptr i256, i256* %STACK, i64 %53158
  %53160 = load i256, i256* %53159, align 4
  %53161 = load i64, i64* %STACK_DEP_PTR, align 4
  %53162 = sub i64 %53161, 1
  store i64 %53162, i64* %STACK_DEP_PTR, align 4
  %53163 = load i64, i64* %STACK_DEP_PTR, align 4
  %53164 = getelementptr i256, i256* %STACK, i64 %53163
  %53165 = load i256, i256* %53164, align 4
  %53166 = load i64, i64* %STACK_DEP_PTR, align 4
  %53167 = sub i64 %53166, 1
  store i64 %53167, i64* %STACK_DEP_PTR, align 4
  %53168 = trunc i256 %53165 to i64
  store i64 %53168, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.17016:                                           ; preds = %31194, %JumpTable
  %53169 = load i64, i64* %remaing_gas, align 4
  %53170 = icmp ugt i64 160, %53169
  br i1 %53170, label %Abort, label %53171

53171:                                            ; preds = %.17016
  %53172 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53173 = xor i32 %53172, 1401
  %53174 = urem i32 %53173, 4096
  %53175 = getelementptr i8, i8 addrspace(1)* %4, i32 %53174
  %53176 = load i8, i8 addrspace(1)* %53175, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53175, align 1, !nosanitize !3
  store i32 700, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53177 = sub i64 %53169, 160
  store i64 %53177, i64* %remaing_gas, align 4
  %53178 = alloca i256, align 8
  store i256 0, i256* %53178, align 4
  %53179 = alloca i256, align 8
  call void @__device_sload(i256* %53178, i256* %53179)
  %53180 = call i32 @__hashword(i256* %53178)
  %53181 = load i32, i32* %5, align 4
  %53182 = icmp eq i32 %53180, %53181
  %53183 = or i1 false, %53182
  %53184 = load i32, i32* %6, align 4
  %53185 = icmp eq i32 %53180, %53184
  %53186 = or i1 %53183, %53185
  %53187 = load i32, i32* %7, align 4
  %53188 = icmp eq i32 %53180, %53187
  %53189 = or i1 %53186, %53188
  %53190 = load i32, i32* %8, align 4
  %53191 = icmp eq i32 %53180, %53190
  %53192 = or i1 %53189, %53191
  %53193 = load i32, i32* %9, align 4
  %53194 = icmp eq i32 %53180, %53193
  %53195 = or i1 %53192, %53194
  %53196 = load i32, i32* %10, align 4
  %53197 = icmp eq i32 %53180, %53196
  %53198 = or i1 %53195, %53197
  %53199 = load i32, i32* %11, align 4
  %53200 = icmp eq i32 %53180, %53199
  %53201 = or i1 %53198, %53200
  %53202 = load i32, i32* %12, align 4
  %53203 = icmp eq i32 %53180, %53202
  %53204 = or i1 %53201, %53203
  %53205 = load i32, i32* %13, align 4
  %53206 = icmp eq i32 %53180, %53205
  %53207 = or i1 %53204, %53206
  %53208 = load i32, i32* %14, align 4
  %53209 = icmp eq i32 %53180, %53208
  %53210 = or i1 %53207, %53209
  %53211 = load i32, i32* %15, align 4
  %53212 = icmp eq i32 %53180, %53211
  %53213 = or i1 %53210, %53212
  %53214 = load i32, i32* %16, align 4
  %53215 = icmp eq i32 %53180, %53214
  %53216 = or i1 %53213, %53215
  %53217 = load i32, i32* %17, align 4
  %53218 = icmp eq i32 %53180, %53217
  %53219 = or i1 %53216, %53218
  %53220 = load i32, i32* %18, align 4
  %53221 = icmp eq i32 %53180, %53220
  %53222 = or i1 %53219, %53221
  %53223 = load i32, i32* %19, align 4
  %53224 = icmp eq i32 %53180, %53223
  %53225 = or i1 %53222, %53224
  %53226 = load i32, i32* %20, align 4
  %53227 = icmp eq i32 %53180, %53226
  %53228 = or i1 %53225, %53227
  %53229 = load i32, i32* %21, align 4
  %53230 = icmp eq i32 %53180, %53229
  %53231 = or i1 %53228, %53230
  %53232 = load i32, i32* %22, align 4
  %53233 = icmp eq i32 %53180, %53232
  %53234 = or i1 %53231, %53233
  %53235 = load i32, i32* %23, align 4
  %53236 = icmp eq i32 %53180, %53235
  %53237 = or i1 %53234, %53236
  %53238 = load i32, i32* %24, align 4
  %53239 = icmp eq i32 %53180, %53238
  %53240 = or i1 %53237, %53239
  %53241 = load i32, i32* %25, align 4
  %53242 = icmp eq i32 %53180, %53241
  %53243 = or i1 %53240, %53242
  %53244 = load i32, i32* %26, align 4
  %53245 = icmp eq i32 %53180, %53244
  %53246 = or i1 %53243, %53245
  %53247 = load i32, i32* %27, align 4
  %53248 = icmp eq i32 %53180, %53247
  %53249 = or i1 %53246, %53248
  %53250 = load i32, i32* %28, align 4
  %53251 = icmp eq i32 %53180, %53250
  %53252 = or i1 %53249, %53251
  %53253 = load i32, i32* %29, align 4
  %53254 = icmp eq i32 %53180, %53253
  %53255 = or i1 %53252, %53254
  %53256 = load i32, i32* %30, align 4
  %53257 = icmp eq i32 %53180, %53256
  %53258 = or i1 %53255, %53257
  %53259 = load i32, i32* %31, align 4
  %53260 = icmp eq i32 %53180, %53259
  %53261 = or i1 %53258, %53260
  %53262 = load i32, i32* %32, align 4
  %53263 = icmp eq i32 %53180, %53262
  %53264 = or i1 %53261, %53263
  %53265 = load i32, i32* %33, align 4
  %53266 = icmp eq i32 %53180, %53265
  %53267 = or i1 %53264, %53266
  %53268 = load i32, i32* %34, align 4
  %53269 = icmp eq i32 %53180, %53268
  %53270 = or i1 %53267, %53269
  %53271 = load i32, i32* %35, align 4
  %53272 = icmp eq i32 %53180, %53271
  %53273 = or i1 %53270, %53272
  %53274 = load i32, i32* %36, align 4
  %53275 = icmp eq i32 %53180, %53274
  %53276 = or i1 %53273, %53275
  %53277 = load i32, i32* %37, align 4
  %53278 = icmp eq i32 %53180, %53277
  %53279 = or i1 %53276, %53278
  %53280 = load i32, i32* %38, align 4
  %53281 = icmp eq i32 %53180, %53280
  %53282 = or i1 %53279, %53281
  %53283 = load i32, i32* %39, align 4
  %53284 = icmp eq i32 %53180, %53283
  %53285 = or i1 %53282, %53284
  %53286 = load i32, i32* %40, align 4
  %53287 = icmp eq i32 %53180, %53286
  %53288 = or i1 %53285, %53287
  %53289 = load i32, i32* %41, align 4
  %53290 = icmp eq i32 %53180, %53289
  %53291 = or i1 %53288, %53290
  %53292 = load i32, i32* %42, align 4
  %53293 = icmp eq i32 %53180, %53292
  %53294 = or i1 %53291, %53293
  %53295 = load i32, i32* %43, align 4
  %53296 = icmp eq i32 %53180, %53295
  %53297 = or i1 %53294, %53296
  %53298 = load i32, i32* %44, align 4
  %53299 = icmp eq i32 %53180, %53298
  %53300 = or i1 %53297, %53299
  %53301 = load i32, i32* %45, align 4
  %53302 = icmp eq i32 %53180, %53301
  %53303 = or i1 %53300, %53302
  %53304 = load i32, i32* %46, align 4
  %53305 = icmp eq i32 %53180, %53304
  %53306 = or i1 %53303, %53305
  %53307 = load i32, i32* %47, align 4
  %53308 = icmp eq i32 %53180, %53307
  %53309 = or i1 %53306, %53308
  %53310 = load i32, i32* %48, align 4
  %53311 = icmp eq i32 %53180, %53310
  %53312 = or i1 %53309, %53311
  %53313 = load i32, i32* %49, align 4
  %53314 = icmp eq i32 %53180, %53313
  %53315 = or i1 %53312, %53314
  %53316 = load i32, i32* %50, align 4
  %53317 = icmp eq i32 %53180, %53316
  %53318 = or i1 %53315, %53317
  %53319 = load i32, i32* %51, align 4
  %53320 = icmp eq i32 %53180, %53319
  %53321 = or i1 %53318, %53320
  %53322 = load i32, i32* %52, align 4
  %53323 = icmp eq i32 %53180, %53322
  %53324 = or i1 %53321, %53323
  %53325 = load i32, i32* %53, align 4
  %53326 = icmp eq i32 %53180, %53325
  %53327 = or i1 %53324, %53326
  %53328 = load i32, i32* %54, align 4
  %53329 = icmp eq i32 %53180, %53328
  %53330 = or i1 %53327, %53329
  %53331 = load i32, i32* %55, align 4
  %53332 = icmp eq i32 %53180, %53331
  %53333 = or i1 %53330, %53332
  %53334 = load i32, i32* %56, align 4
  %53335 = icmp eq i32 %53180, %53334
  %53336 = or i1 %53333, %53335
  %53337 = load i32, i32* %57, align 4
  %53338 = icmp eq i32 %53180, %53337
  %53339 = or i1 %53336, %53338
  %53340 = load i32, i32* %58, align 4
  %53341 = icmp eq i32 %53180, %53340
  %53342 = or i1 %53339, %53341
  %53343 = load i32, i32* %59, align 4
  %53344 = icmp eq i32 %53180, %53343
  %53345 = or i1 %53342, %53344
  %53346 = load i32, i32* %60, align 4
  %53347 = icmp eq i32 %53180, %53346
  %53348 = or i1 %53345, %53347
  %53349 = load i32, i32* %61, align 4
  %53350 = icmp eq i32 %53180, %53349
  %53351 = or i1 %53348, %53350
  %53352 = load i32, i32* %62, align 4
  %53353 = icmp eq i32 %53180, %53352
  %53354 = or i1 %53351, %53353
  %53355 = getelementptr i8, i8 addrspace(1)* %4, i32 196
  %53356 = zext i1 %53354 to i8
  store i8 %53356, i8 addrspace(1)* %53355, align 1, !nosanitize !3
  %53357 = load i256, i256* %53179, align 4
  %53358 = alloca i256, align 8
  store i256 %53357, i256* %53358, align 4
  %53359 = alloca i256, align 8
  store i256 1, i256* %53359, align 4
  %53360 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %53358, i256* %53359, i256* %53360), !pc !769, !intsan !6
  %53361 = load i256, i256* %53360, align 4
  %53362 = and i256 1461501637330902918203684832716283019655932542975, %53361
  %53363 = and i256 1461501637330902918203684832716283019655932542975, %53362
  %53364 = icmp eq i256 %53363, 0
  %53365 = icmp eq i1 %53364, false
  %53366 = trunc i256 17092 to i64
  %jump.check172 = icmp ne i1 %53365, false
  br i1 %jump.check172, label %.17092, label %.17081, !EVMBB !4

.17081:                                           ; preds = %53171
  %53367 = load i64, i64* %remaing_gas, align 4
  %53368 = icmp ugt i64 120, %53367
  br i1 %53368, label %Abort, label %53369

53369:                                            ; preds = %.17081
  %53370 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53371 = xor i32 %53370, 139
  %53372 = urem i32 %53371, 4096
  %53373 = getelementptr i8, i8 addrspace(1)* %4, i32 %53372
  %53374 = load i8, i8 addrspace(1)* %53373, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53373, align 1, !nosanitize !3
  store i32 69, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53375 = sub i64 %53367, 120
  store i64 %53375, i64* %remaing_gas, align 4
  %53376 = trunc i256 17834 to i64
  %53377 = load i64, i64* %STACK_DEP_PTR, align 4
  %53378 = add i64 %53377, 1
  store i64 %53378, i64* %STACK_DEP_PTR, align 4
  %53379 = load i64, i64* %STACK_DEP_PTR, align 4
  %53380 = getelementptr i256, i256* %STACK, i64 %53379
  store i256 17090, i256* %53380, align 4
  %53381 = load i64, i64* %STACK_DEP_PTR, align 4
  %53382 = add i64 %53381, 1
  store i64 %53382, i64* %STACK_DEP_PTR, align 4
  %53383 = load i64, i64* %STACK_DEP_PTR, align 4
  %53384 = getelementptr i256, i256* %STACK, i64 %53383
  store i256 0, i256* %53384, align 4
  br label %.17834, !EVMBB !4

.17090:                                           ; preds = %JumpTable
  %53385 = load i64, i64* %STACK_DEP_PTR, align 4
  %53386 = getelementptr i256, i256* %STACK, i64 %53385
  %53387 = load i256, i256* %53386, align 4
  %53388 = load i64, i64* %STACK_DEP_PTR, align 4
  %53389 = sub i64 %53388, 1
  store i64 %53389, i64* %STACK_DEP_PTR, align 4
  br label %.17092

.17092:                                           ; preds = %.17090, %53171, %JumpTable
  %53390 = load i64, i64* %remaing_gas, align 4
  %53391 = icmp ugt i64 784, %53390
  br i1 %53391, label %Abort, label %53392

53392:                                            ; preds = %.17092
  %53393 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53394 = xor i32 %53393, 3072
  %53395 = urem i32 %53394, 4096
  %53396 = getelementptr i8, i8 addrspace(1)* %4, i32 %53395
  %53397 = load i8, i8 addrspace(1)* %53396, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53396, align 1, !nosanitize !3
  store i32 1536, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53398 = sub i64 %53390, 784
  store i64 %53398, i64* %remaing_gas, align 4
  %53399 = alloca i256, align 8
  store i256 0, i256* %53399, align 4
  %53400 = alloca i256, align 8
  call void @__device_sload(i256* %53399, i256* %53400)
  %53401 = call i32 @__hashword(i256* %53399)
  %53402 = load i32, i32* %5, align 4
  %53403 = icmp eq i32 %53401, %53402
  %53404 = or i1 false, %53403
  %53405 = load i32, i32* %6, align 4
  %53406 = icmp eq i32 %53401, %53405
  %53407 = or i1 %53404, %53406
  %53408 = load i32, i32* %7, align 4
  %53409 = icmp eq i32 %53401, %53408
  %53410 = or i1 %53407, %53409
  %53411 = load i32, i32* %8, align 4
  %53412 = icmp eq i32 %53401, %53411
  %53413 = or i1 %53410, %53412
  %53414 = load i32, i32* %9, align 4
  %53415 = icmp eq i32 %53401, %53414
  %53416 = or i1 %53413, %53415
  %53417 = load i32, i32* %10, align 4
  %53418 = icmp eq i32 %53401, %53417
  %53419 = or i1 %53416, %53418
  %53420 = load i32, i32* %11, align 4
  %53421 = icmp eq i32 %53401, %53420
  %53422 = or i1 %53419, %53421
  %53423 = load i32, i32* %12, align 4
  %53424 = icmp eq i32 %53401, %53423
  %53425 = or i1 %53422, %53424
  %53426 = load i32, i32* %13, align 4
  %53427 = icmp eq i32 %53401, %53426
  %53428 = or i1 %53425, %53427
  %53429 = load i32, i32* %14, align 4
  %53430 = icmp eq i32 %53401, %53429
  %53431 = or i1 %53428, %53430
  %53432 = load i32, i32* %15, align 4
  %53433 = icmp eq i32 %53401, %53432
  %53434 = or i1 %53431, %53433
  %53435 = load i32, i32* %16, align 4
  %53436 = icmp eq i32 %53401, %53435
  %53437 = or i1 %53434, %53436
  %53438 = load i32, i32* %17, align 4
  %53439 = icmp eq i32 %53401, %53438
  %53440 = or i1 %53437, %53439
  %53441 = load i32, i32* %18, align 4
  %53442 = icmp eq i32 %53401, %53441
  %53443 = or i1 %53440, %53442
  %53444 = load i32, i32* %19, align 4
  %53445 = icmp eq i32 %53401, %53444
  %53446 = or i1 %53443, %53445
  %53447 = load i32, i32* %20, align 4
  %53448 = icmp eq i32 %53401, %53447
  %53449 = or i1 %53446, %53448
  %53450 = load i32, i32* %21, align 4
  %53451 = icmp eq i32 %53401, %53450
  %53452 = or i1 %53449, %53451
  %53453 = load i32, i32* %22, align 4
  %53454 = icmp eq i32 %53401, %53453
  %53455 = or i1 %53452, %53454
  %53456 = load i32, i32* %23, align 4
  %53457 = icmp eq i32 %53401, %53456
  %53458 = or i1 %53455, %53457
  %53459 = load i32, i32* %24, align 4
  %53460 = icmp eq i32 %53401, %53459
  %53461 = or i1 %53458, %53460
  %53462 = load i32, i32* %25, align 4
  %53463 = icmp eq i32 %53401, %53462
  %53464 = or i1 %53461, %53463
  %53465 = load i32, i32* %26, align 4
  %53466 = icmp eq i32 %53401, %53465
  %53467 = or i1 %53464, %53466
  %53468 = load i32, i32* %27, align 4
  %53469 = icmp eq i32 %53401, %53468
  %53470 = or i1 %53467, %53469
  %53471 = load i32, i32* %28, align 4
  %53472 = icmp eq i32 %53401, %53471
  %53473 = or i1 %53470, %53472
  %53474 = load i32, i32* %29, align 4
  %53475 = icmp eq i32 %53401, %53474
  %53476 = or i1 %53473, %53475
  %53477 = load i32, i32* %30, align 4
  %53478 = icmp eq i32 %53401, %53477
  %53479 = or i1 %53476, %53478
  %53480 = load i32, i32* %31, align 4
  %53481 = icmp eq i32 %53401, %53480
  %53482 = or i1 %53479, %53481
  %53483 = load i32, i32* %32, align 4
  %53484 = icmp eq i32 %53401, %53483
  %53485 = or i1 %53482, %53484
  %53486 = load i32, i32* %33, align 4
  %53487 = icmp eq i32 %53401, %53486
  %53488 = or i1 %53485, %53487
  %53489 = load i32, i32* %34, align 4
  %53490 = icmp eq i32 %53401, %53489
  %53491 = or i1 %53488, %53490
  %53492 = load i32, i32* %35, align 4
  %53493 = icmp eq i32 %53401, %53492
  %53494 = or i1 %53491, %53493
  %53495 = load i32, i32* %36, align 4
  %53496 = icmp eq i32 %53401, %53495
  %53497 = or i1 %53494, %53496
  %53498 = load i32, i32* %37, align 4
  %53499 = icmp eq i32 %53401, %53498
  %53500 = or i1 %53497, %53499
  %53501 = load i32, i32* %38, align 4
  %53502 = icmp eq i32 %53401, %53501
  %53503 = or i1 %53500, %53502
  %53504 = load i32, i32* %39, align 4
  %53505 = icmp eq i32 %53401, %53504
  %53506 = or i1 %53503, %53505
  %53507 = load i32, i32* %40, align 4
  %53508 = icmp eq i32 %53401, %53507
  %53509 = or i1 %53506, %53508
  %53510 = load i32, i32* %41, align 4
  %53511 = icmp eq i32 %53401, %53510
  %53512 = or i1 %53509, %53511
  %53513 = load i32, i32* %42, align 4
  %53514 = icmp eq i32 %53401, %53513
  %53515 = or i1 %53512, %53514
  %53516 = load i32, i32* %43, align 4
  %53517 = icmp eq i32 %53401, %53516
  %53518 = or i1 %53515, %53517
  %53519 = load i32, i32* %44, align 4
  %53520 = icmp eq i32 %53401, %53519
  %53521 = or i1 %53518, %53520
  %53522 = load i32, i32* %45, align 4
  %53523 = icmp eq i32 %53401, %53522
  %53524 = or i1 %53521, %53523
  %53525 = load i32, i32* %46, align 4
  %53526 = icmp eq i32 %53401, %53525
  %53527 = or i1 %53524, %53526
  %53528 = load i32, i32* %47, align 4
  %53529 = icmp eq i32 %53401, %53528
  %53530 = or i1 %53527, %53529
  %53531 = load i32, i32* %48, align 4
  %53532 = icmp eq i32 %53401, %53531
  %53533 = or i1 %53530, %53532
  %53534 = load i32, i32* %49, align 4
  %53535 = icmp eq i32 %53401, %53534
  %53536 = or i1 %53533, %53535
  %53537 = load i32, i32* %50, align 4
  %53538 = icmp eq i32 %53401, %53537
  %53539 = or i1 %53536, %53538
  %53540 = load i32, i32* %51, align 4
  %53541 = icmp eq i32 %53401, %53540
  %53542 = or i1 %53539, %53541
  %53543 = load i32, i32* %52, align 4
  %53544 = icmp eq i32 %53401, %53543
  %53545 = or i1 %53542, %53544
  %53546 = load i32, i32* %53, align 4
  %53547 = icmp eq i32 %53401, %53546
  %53548 = or i1 %53545, %53547
  %53549 = load i32, i32* %54, align 4
  %53550 = icmp eq i32 %53401, %53549
  %53551 = or i1 %53548, %53550
  %53552 = load i32, i32* %55, align 4
  %53553 = icmp eq i32 %53401, %53552
  %53554 = or i1 %53551, %53553
  %53555 = load i32, i32* %56, align 4
  %53556 = icmp eq i32 %53401, %53555
  %53557 = or i1 %53554, %53556
  %53558 = load i32, i32* %57, align 4
  %53559 = icmp eq i32 %53401, %53558
  %53560 = or i1 %53557, %53559
  %53561 = load i32, i32* %58, align 4
  %53562 = icmp eq i32 %53401, %53561
  %53563 = or i1 %53560, %53562
  %53564 = load i32, i32* %59, align 4
  %53565 = icmp eq i32 %53401, %53564
  %53566 = or i1 %53563, %53565
  %53567 = load i32, i32* %60, align 4
  %53568 = icmp eq i32 %53401, %53567
  %53569 = or i1 %53566, %53568
  %53570 = load i32, i32* %61, align 4
  %53571 = icmp eq i32 %53401, %53570
  %53572 = or i1 %53569, %53571
  %53573 = load i32, i32* %62, align 4
  %53574 = icmp eq i32 %53401, %53573
  %53575 = or i1 %53572, %53574
  %53576 = getelementptr i8, i8 addrspace(1)* %4, i32 197
  %53577 = zext i1 %53575 to i8
  store i8 %53577, i8 addrspace(1)* %53576, align 1, !nosanitize !3
  %53578 = load i256, i256* %53400, align 4
  %53579 = alloca i256, align 8
  store i256 %53578, i256* %53579, align 4
  %53580 = alloca i256, align 8
  store i256 1, i256* %53580, align 4
  %53581 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %53579, i256* %53580, i256* %53581), !pc !770, !intsan !6
  %53582 = load i256, i256* %53581, align 4
  %53583 = and i256 1461501637330902918203684832716283019655932542975, %53582
  %53584 = and i256 1461501637330902918203684832716283019655932542975, %53583
  %53585 = trunc i256 64 to i64
  %53586 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %53585, i256* %53586)
  %53587 = load i256, i256* %53586, align 4
  %53588 = and i256 4294967295, 952911921
  %53589 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %53588, !pc !771, !intsan !45
  %53590 = trunc i256 %53587 to i64
  %53591 = alloca i256, align 8
  store i256 %53589, i256* %53591, align 4
  %53592 = bitcast i256* %53591 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %53590, i8* %53592, i64 32)
  %53593 = add i256 4, %53587, !pc !772, !intsan !10
  %53594 = trunc i256 64 to i64
  %53595 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %53594, i256* %53595)
  %53596 = load i256, i256* %53595, align 4
  %53597 = sub i256 %53593, %53596, !pc !773, !intsan !8
  %53598 = icmp eq i256 1, 0
  %53599 = icmp eq i1 %53598, false
  %53600 = trunc i256 17225 to i64
  %jump.check175 = icmp ne i1 %53599, false
  %53601 = load i64, i64* %STACK_DEP_PTR, align 4
  %53602 = add i64 %53601, 1
  store i64 %53602, i64* %STACK_DEP_PTR, align 4
  %53603 = load i64, i64* %STACK_DEP_PTR, align 4
  %53604 = getelementptr i256, i256* %STACK, i64 %53603
  store i256 %53584, i256* %53604, align 4
  %53605 = load i64, i64* %STACK_DEP_PTR, align 4
  %53606 = add i64 %53605, 1
  store i64 %53606, i64* %STACK_DEP_PTR, align 4
  %53607 = load i64, i64* %STACK_DEP_PTR, align 4
  %53608 = getelementptr i256, i256* %STACK, i64 %53607
  store i256 952911921, i256* %53608, align 4
  %53609 = load i64, i64* %STACK_DEP_PTR, align 4
  %53610 = add i64 %53609, 1
  store i64 %53610, i64* %STACK_DEP_PTR, align 4
  %53611 = load i64, i64* %STACK_DEP_PTR, align 4
  %53612 = getelementptr i256, i256* %STACK, i64 %53611
  store i256 %53593, i256* %53612, align 4
  %53613 = load i64, i64* %STACK_DEP_PTR, align 4
  %53614 = add i64 %53613, 1
  store i64 %53614, i64* %STACK_DEP_PTR, align 4
  %53615 = load i64, i64* %STACK_DEP_PTR, align 4
  %53616 = getelementptr i256, i256* %STACK, i64 %53615
  store i256 32, i256* %53616, align 4
  %53617 = load i64, i64* %STACK_DEP_PTR, align 4
  %53618 = add i64 %53617, 1
  store i64 %53618, i64* %STACK_DEP_PTR, align 4
  %53619 = load i64, i64* %STACK_DEP_PTR, align 4
  %53620 = getelementptr i256, i256* %STACK, i64 %53619
  store i256 %53596, i256* %53620, align 4
  %53621 = load i64, i64* %STACK_DEP_PTR, align 4
  %53622 = add i64 %53621, 1
  store i64 %53622, i64* %STACK_DEP_PTR, align 4
  %53623 = load i64, i64* %STACK_DEP_PTR, align 4
  %53624 = getelementptr i256, i256* %STACK, i64 %53623
  store i256 %53597, i256* %53624, align 4
  %53625 = load i64, i64* %STACK_DEP_PTR, align 4
  %53626 = add i64 %53625, 1
  store i64 %53626, i64* %STACK_DEP_PTR, align 4
  %53627 = load i64, i64* %STACK_DEP_PTR, align 4
  %53628 = getelementptr i256, i256* %STACK, i64 %53627
  store i256 %53596, i256* %53628, align 4
  %53629 = load i64, i64* %STACK_DEP_PTR, align 4
  %53630 = add i64 %53629, 1
  store i64 %53630, i64* %STACK_DEP_PTR, align 4
  %53631 = load i64, i64* %STACK_DEP_PTR, align 4
  %53632 = getelementptr i256, i256* %STACK, i64 %53631
  store i256 0, i256* %53632, align 4
  %53633 = load i64, i64* %STACK_DEP_PTR, align 4
  %53634 = add i64 %53633, 1
  store i64 %53634, i64* %STACK_DEP_PTR, align 4
  %53635 = load i64, i64* %STACK_DEP_PTR, align 4
  %53636 = getelementptr i256, i256* %STACK, i64 %53635
  store i256 %53584, i256* %53636, align 4
  %53637 = load i64, i64* %STACK_DEP_PTR, align 4
  %53638 = add i64 %53637, 1
  store i64 %53638, i64* %STACK_DEP_PTR, align 4
  %53639 = zext i1 %53598 to i256
  %53640 = load i64, i64* %STACK_DEP_PTR, align 4
  %53641 = getelementptr i256, i256* %STACK, i64 %53640
  store i256 %53639, i256* %53641, align 4
  br i1 %jump.check175, label %.17225, label %.17221, !EVMBB !4

.17221:                                           ; preds = %53392
  %53642 = load i64, i64* %remaing_gas, align 4
  %53643 = icmp ugt i64 40, %53642
  br i1 %53643, label %Abort, label %53644

53644:                                            ; preds = %.17221
  %53645 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53646 = xor i32 %53645, 802
  %53647 = urem i32 %53646, 4096
  %53648 = getelementptr i8, i8 addrspace(1)* %4, i32 %53647
  %53649 = load i8, i8 addrspace(1)* %53648, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53648, align 1, !nosanitize !3
  store i32 401, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53650 = sub i64 %53642, 40
  store i64 %53650, i64* %remaing_gas, align 4
  %53651 = load i64, i64* %STACK_DEP_PTR, align 4
  %53652 = sub i64 %53651, 0
  store i64 %53652, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.17225:                                           ; preds = %53392, %JumpTable
  %53653 = load i64, i64* %remaing_gas, align 4
  %53654 = icmp ugt i64 456, %53653
  br i1 %53654, label %Abort, label %53655

53655:                                            ; preds = %.17225
  %53656 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53657 = xor i32 %53656, 3414
  %53658 = urem i32 %53657, 4096
  %53659 = getelementptr i8, i8 addrspace(1)* %4, i32 %53658
  %53660 = load i8, i8 addrspace(1)* %53659, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53659, align 1, !nosanitize !3
  store i32 1707, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53661 = sub i64 %53653, 456
  store i64 %53661, i64* %remaing_gas, align 4
  %53662 = load i64, i64* %STACK_DEP_PTR, align 4
  %53663 = getelementptr i256, i256* %STACK, i64 %53662
  %53664 = load i256, i256* %53663, align 4
  %53665 = load i64, i64* %STACK_DEP_PTR, align 4
  %53666 = sub i64 %53665, 1
  store i64 %53666, i64* %STACK_DEP_PTR, align 4
  %53667 = load i64, i64* %STACK_DEP_PTR, align 4
  %53668 = getelementptr i256, i256* %STACK, i64 %53667
  %53669 = load i256, i256* %53668, align 4
  %53670 = load i64, i64* %STACK_DEP_PTR, align 4
  %53671 = sub i64 %53670, 1
  store i64 %53671, i64* %STACK_DEP_PTR, align 4
  %53672 = load i64, i64* %STACK_DEP_PTR, align 4
  %53673 = getelementptr i256, i256* %STACK, i64 %53672
  %53674 = load i256, i256* %53673, align 4
  %53675 = load i64, i64* %STACK_DEP_PTR, align 4
  %53676 = sub i64 %53675, 1
  store i64 %53676, i64* %STACK_DEP_PTR, align 4
  %53677 = load i64, i64* %STACK_DEP_PTR, align 4
  %53678 = getelementptr i256, i256* %STACK, i64 %53677
  %53679 = load i256, i256* %53678, align 4
  %53680 = load i64, i64* %STACK_DEP_PTR, align 4
  %53681 = sub i64 %53680, 1
  store i64 %53681, i64* %STACK_DEP_PTR, align 4
  %53682 = load i64, i64* %STACK_DEP_PTR, align 4
  %53683 = getelementptr i256, i256* %STACK, i64 %53682
  %53684 = load i256, i256* %53683, align 4
  %53685 = load i64, i64* %STACK_DEP_PTR, align 4
  %53686 = sub i64 %53685, 1
  store i64 %53686, i64* %STACK_DEP_PTR, align 4
  %53687 = load i64, i64* %STACK_DEP_PTR, align 4
  %53688 = getelementptr i256, i256* %STACK, i64 %53687
  %53689 = load i256, i256* %53688, align 4
  %53690 = load i64, i64* %STACK_DEP_PTR, align 4
  %53691 = sub i64 %53690, 1
  store i64 %53691, i64* %STACK_DEP_PTR, align 4
  %53692 = load i64, i64* %STACK_DEP_PTR, align 4
  %53693 = getelementptr i256, i256* %STACK, i64 %53692
  %53694 = load i256, i256* %53693, align 4
  %53695 = load i64, i64* %STACK_DEP_PTR, align 4
  %53696 = sub i64 %53695, 1
  store i64 %53696, i64* %STACK_DEP_PTR, align 4
  %53697 = trunc i256 %53669 to i160
  %53698 = call i1 @solidity_call(), !pc !774
  %53699 = icmp eq i1 %53698, false
  %53700 = icmp eq i1 %53699, false
  %53701 = trunc i256 17245 to i64
  %jump.check178 = icmp ne i1 %53700, false
  %53702 = load i64, i64* %STACK_DEP_PTR, align 4
  %53703 = add i64 %53702, 1
  store i64 %53703, i64* %STACK_DEP_PTR, align 4
  %53704 = zext i1 %53699 to i256
  %53705 = load i64, i64* %STACK_DEP_PTR, align 4
  %53706 = getelementptr i256, i256* %STACK, i64 %53705
  store i256 %53704, i256* %53706, align 4
  br i1 %jump.check178, label %.17245, label %.17236, !EVMBB !4

.17236:                                           ; preds = %53655
  %53707 = load i64, i64* %remaing_gas, align 4
  %53708 = icmp ugt i64 40, %53707
  br i1 %53708, label %Abort, label %53709

53709:                                            ; preds = %.17236
  %53710 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53711 = xor i32 %53710, 1178
  %53712 = urem i32 %53711, 4096
  %53713 = getelementptr i8, i8 addrspace(1)* %4, i32 %53712
  %53714 = load i8, i8 addrspace(1)* %53713, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53713, align 1, !nosanitize !3
  store i32 589, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53715 = sub i64 %53707, 40
  store i64 %53715, i64* %remaing_gas, align 4
  %53716 = load i64, i64* %STACK_DEP_PTR, align 4
  %53717 = sub i64 %53716, 0
  store i64 %53717, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.17245:                                           ; preds = %53655, %JumpTable
  %53718 = load i64, i64* %remaing_gas, align 4
  %53719 = icmp ugt i64 384, %53718
  br i1 %53719, label %Abort, label %53720

53720:                                            ; preds = %.17245
  %53721 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53722 = xor i32 %53721, 1492
  %53723 = urem i32 %53722, 4096
  %53724 = getelementptr i8, i8 addrspace(1)* %4, i32 %53723
  %53725 = load i8, i8 addrspace(1)* %53724, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53724, align 1, !nosanitize !3
  store i32 746, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53726 = sub i64 %53718, 384
  store i64 %53726, i64* %remaing_gas, align 4
  %53727 = load i64, i64* %STACK_DEP_PTR, align 4
  %53728 = getelementptr i256, i256* %STACK, i64 %53727
  %53729 = load i256, i256* %53728, align 4
  %53730 = load i64, i64* %STACK_DEP_PTR, align 4
  %53731 = sub i64 %53730, 1
  store i64 %53731, i64* %STACK_DEP_PTR, align 4
  %53732 = load i64, i64* %STACK_DEP_PTR, align 4
  %53733 = getelementptr i256, i256* %STACK, i64 %53732
  %53734 = load i256, i256* %53733, align 4
  %53735 = load i64, i64* %STACK_DEP_PTR, align 4
  %53736 = sub i64 %53735, 1
  store i64 %53736, i64* %STACK_DEP_PTR, align 4
  %53737 = load i64, i64* %STACK_DEP_PTR, align 4
  %53738 = getelementptr i256, i256* %STACK, i64 %53737
  %53739 = load i256, i256* %53738, align 4
  %53740 = load i64, i64* %STACK_DEP_PTR, align 4
  %53741 = sub i64 %53740, 1
  store i64 %53741, i64* %STACK_DEP_PTR, align 4
  %53742 = load i64, i64* %STACK_DEP_PTR, align 4
  %53743 = getelementptr i256, i256* %STACK, i64 %53742
  %53744 = load i256, i256* %53743, align 4
  %53745 = load i64, i64* %STACK_DEP_PTR, align 4
  %53746 = sub i64 %53745, 1
  store i64 %53746, i64* %STACK_DEP_PTR, align 4
  %53747 = trunc i256 64 to i64
  %53748 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %53747, i256* %53748)
  %53749 = load i256, i256* %53748, align 4
  %53750 = zext i64 0 to i256
  %53751 = icmp ult i256 %53750, 32
  %53752 = icmp eq i1 %53751, false
  %53753 = trunc i256 17267 to i64
  %jump.check181 = icmp ne i1 %53752, false
  %53754 = load i64, i64* %STACK_DEP_PTR, align 4
  %53755 = add i64 %53754, 1
  store i64 %53755, i64* %STACK_DEP_PTR, align 4
  %53756 = load i64, i64* %STACK_DEP_PTR, align 4
  %53757 = getelementptr i256, i256* %STACK, i64 %53756
  store i256 %53749, i256* %53757, align 4
  %53758 = load i64, i64* %STACK_DEP_PTR, align 4
  %53759 = add i64 %53758, 1
  store i64 %53759, i64* %STACK_DEP_PTR, align 4
  %53760 = zext i64 0 to i256
  %53761 = load i64, i64* %STACK_DEP_PTR, align 4
  %53762 = getelementptr i256, i256* %STACK, i64 %53761
  store i256 %53760, i256* %53762, align 4
  br i1 %jump.check181, label %.17267, label %.17263, !EVMBB !4

.17263:                                           ; preds = %53720
  %53763 = load i64, i64* %remaing_gas, align 4
  %53764 = icmp ugt i64 40, %53763
  br i1 %53764, label %Abort, label %53765

53765:                                            ; preds = %.17263
  %53766 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53767 = xor i32 %53766, 536
  %53768 = urem i32 %53767, 4096
  %53769 = getelementptr i8, i8 addrspace(1)* %4, i32 %53768
  %53770 = load i8, i8 addrspace(1)* %53769, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53769, align 1, !nosanitize !3
  store i32 268, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53771 = sub i64 %53763, 40
  store i64 %53771, i64* %remaing_gas, align 4
  %53772 = load i64, i64* %STACK_DEP_PTR, align 4
  %53773 = sub i64 %53772, 0
  store i64 %53773, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.17267:                                           ; preds = %53720, %JumpTable
  %53774 = load i64, i64* %remaing_gas, align 4
  %53775 = icmp ugt i64 1232, %53774
  br i1 %53775, label %Abort, label %53776

53776:                                            ; preds = %.17267
  %53777 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53778 = xor i32 %53777, 1489
  %53779 = urem i32 %53778, 4096
  %53780 = getelementptr i8, i8 addrspace(1)* %4, i32 %53779
  %53781 = load i8, i8 addrspace(1)* %53780, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %53780, align 1, !nosanitize !3
  store i32 744, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %53782 = sub i64 %53774, 1232
  store i64 %53782, i64* %remaing_gas, align 4
  %53783 = load i64, i64* %STACK_DEP_PTR, align 4
  %53784 = getelementptr i256, i256* %STACK, i64 %53783
  %53785 = load i256, i256* %53784, align 4
  %53786 = load i64, i64* %STACK_DEP_PTR, align 4
  %53787 = sub i64 %53786, 1
  store i64 %53787, i64* %STACK_DEP_PTR, align 4
  %53788 = load i64, i64* %STACK_DEP_PTR, align 4
  %53789 = getelementptr i256, i256* %STACK, i64 %53788
  %53790 = load i256, i256* %53789, align 4
  %53791 = load i64, i64* %STACK_DEP_PTR, align 4
  %53792 = sub i64 %53791, 1
  store i64 %53792, i64* %STACK_DEP_PTR, align 4
  %53793 = load i64, i64* %STACK_DEP_PTR, align 4
  %53794 = getelementptr i256, i256* %STACK, i64 %53793
  %53795 = load i256, i256* %53794, align 4
  %53796 = load i64, i64* %STACK_DEP_PTR, align 4
  %53797 = sub i64 %53796, 1
  store i64 %53797, i64* %STACK_DEP_PTR, align 4
  %53798 = add i256 %53790, %53785, !pc !775, !intsan !10
  %53799 = trunc i256 %53790 to i64
  %53800 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %53799, i256* %53800)
  %53801 = load i256, i256* %53800, align 4
  %53802 = add i256 32, %53790, !pc !776, !intsan !10
  %53803 = alloca i256, align 8
  store i256 1, i256* %53803, align 4
  %53804 = alloca i256, align 8
  call void @__device_sload(i256* %53803, i256* %53804)
  %53805 = call i32 @__hashword(i256* %53803)
  %53806 = load i32, i32* %5, align 4
  %53807 = icmp eq i32 %53805, %53806
  %53808 = or i1 false, %53807
  %53809 = load i32, i32* %6, align 4
  %53810 = icmp eq i32 %53805, %53809
  %53811 = or i1 %53808, %53810
  %53812 = load i32, i32* %7, align 4
  %53813 = icmp eq i32 %53805, %53812
  %53814 = or i1 %53811, %53813
  %53815 = load i32, i32* %8, align 4
  %53816 = icmp eq i32 %53805, %53815
  %53817 = or i1 %53814, %53816
  %53818 = load i32, i32* %9, align 4
  %53819 = icmp eq i32 %53805, %53818
  %53820 = or i1 %53817, %53819
  %53821 = load i32, i32* %10, align 4
  %53822 = icmp eq i32 %53805, %53821
  %53823 = or i1 %53820, %53822
  %53824 = load i32, i32* %11, align 4
  %53825 = icmp eq i32 %53805, %53824
  %53826 = or i1 %53823, %53825
  %53827 = load i32, i32* %12, align 4
  %53828 = icmp eq i32 %53805, %53827
  %53829 = or i1 %53826, %53828
  %53830 = load i32, i32* %13, align 4
  %53831 = icmp eq i32 %53805, %53830
  %53832 = or i1 %53829, %53831
  %53833 = load i32, i32* %14, align 4
  %53834 = icmp eq i32 %53805, %53833
  %53835 = or i1 %53832, %53834
  %53836 = load i32, i32* %15, align 4
  %53837 = icmp eq i32 %53805, %53836
  %53838 = or i1 %53835, %53837
  %53839 = load i32, i32* %16, align 4
  %53840 = icmp eq i32 %53805, %53839
  %53841 = or i1 %53838, %53840
  %53842 = load i32, i32* %17, align 4
  %53843 = icmp eq i32 %53805, %53842
  %53844 = or i1 %53841, %53843
  %53845 = load i32, i32* %18, align 4
  %53846 = icmp eq i32 %53805, %53845
  %53847 = or i1 %53844, %53846
  %53848 = load i32, i32* %19, align 4
  %53849 = icmp eq i32 %53805, %53848
  %53850 = or i1 %53847, %53849
  %53851 = load i32, i32* %20, align 4
  %53852 = icmp eq i32 %53805, %53851
  %53853 = or i1 %53850, %53852
  %53854 = load i32, i32* %21, align 4
  %53855 = icmp eq i32 %53805, %53854
  %53856 = or i1 %53853, %53855
  %53857 = load i32, i32* %22, align 4
  %53858 = icmp eq i32 %53805, %53857
  %53859 = or i1 %53856, %53858
  %53860 = load i32, i32* %23, align 4
  %53861 = icmp eq i32 %53805, %53860
  %53862 = or i1 %53859, %53861
  %53863 = load i32, i32* %24, align 4
  %53864 = icmp eq i32 %53805, %53863
  %53865 = or i1 %53862, %53864
  %53866 = load i32, i32* %25, align 4
  %53867 = icmp eq i32 %53805, %53866
  %53868 = or i1 %53865, %53867
  %53869 = load i32, i32* %26, align 4
  %53870 = icmp eq i32 %53805, %53869
  %53871 = or i1 %53868, %53870
  %53872 = load i32, i32* %27, align 4
  %53873 = icmp eq i32 %53805, %53872
  %53874 = or i1 %53871, %53873
  %53875 = load i32, i32* %28, align 4
  %53876 = icmp eq i32 %53805, %53875
  %53877 = or i1 %53874, %53876
  %53878 = load i32, i32* %29, align 4
  %53879 = icmp eq i32 %53805, %53878
  %53880 = or i1 %53877, %53879
  %53881 = load i32, i32* %30, align 4
  %53882 = icmp eq i32 %53805, %53881
  %53883 = or i1 %53880, %53882
  %53884 = load i32, i32* %31, align 4
  %53885 = icmp eq i32 %53805, %53884
  %53886 = or i1 %53883, %53885
  %53887 = load i32, i32* %32, align 4
  %53888 = icmp eq i32 %53805, %53887
  %53889 = or i1 %53886, %53888
  %53890 = load i32, i32* %33, align 4
  %53891 = icmp eq i32 %53805, %53890
  %53892 = or i1 %53889, %53891
  %53893 = load i32, i32* %34, align 4
  %53894 = icmp eq i32 %53805, %53893
  %53895 = or i1 %53892, %53894
  %53896 = load i32, i32* %35, align 4
  %53897 = icmp eq i32 %53805, %53896
  %53898 = or i1 %53895, %53897
  %53899 = load i32, i32* %36, align 4
  %53900 = icmp eq i32 %53805, %53899
  %53901 = or i1 %53898, %53900
  %53902 = load i32, i32* %37, align 4
  %53903 = icmp eq i32 %53805, %53902
  %53904 = or i1 %53901, %53903
  %53905 = load i32, i32* %38, align 4
  %53906 = icmp eq i32 %53805, %53905
  %53907 = or i1 %53904, %53906
  %53908 = load i32, i32* %39, align 4
  %53909 = icmp eq i32 %53805, %53908
  %53910 = or i1 %53907, %53909
  %53911 = load i32, i32* %40, align 4
  %53912 = icmp eq i32 %53805, %53911
  %53913 = or i1 %53910, %53912
  %53914 = load i32, i32* %41, align 4
  %53915 = icmp eq i32 %53805, %53914
  %53916 = or i1 %53913, %53915
  %53917 = load i32, i32* %42, align 4
  %53918 = icmp eq i32 %53805, %53917
  %53919 = or i1 %53916, %53918
  %53920 = load i32, i32* %43, align 4
  %53921 = icmp eq i32 %53805, %53920
  %53922 = or i1 %53919, %53921
  %53923 = load i32, i32* %44, align 4
  %53924 = icmp eq i32 %53805, %53923
  %53925 = or i1 %53922, %53924
  %53926 = load i32, i32* %45, align 4
  %53927 = icmp eq i32 %53805, %53926
  %53928 = or i1 %53925, %53927
  %53929 = load i32, i32* %46, align 4
  %53930 = icmp eq i32 %53805, %53929
  %53931 = or i1 %53928, %53930
  %53932 = load i32, i32* %47, align 4
  %53933 = icmp eq i32 %53805, %53932
  %53934 = or i1 %53931, %53933
  %53935 = load i32, i32* %48, align 4
  %53936 = icmp eq i32 %53805, %53935
  %53937 = or i1 %53934, %53936
  %53938 = load i32, i32* %49, align 4
  %53939 = icmp eq i32 %53805, %53938
  %53940 = or i1 %53937, %53939
  %53941 = load i32, i32* %50, align 4
  %53942 = icmp eq i32 %53805, %53941
  %53943 = or i1 %53940, %53942
  %53944 = load i32, i32* %51, align 4
  %53945 = icmp eq i32 %53805, %53944
  %53946 = or i1 %53943, %53945
  %53947 = load i32, i32* %52, align 4
  %53948 = icmp eq i32 %53805, %53947
  %53949 = or i1 %53946, %53948
  %53950 = load i32, i32* %53, align 4
  %53951 = icmp eq i32 %53805, %53950
  %53952 = or i1 %53949, %53951
  %53953 = load i32, i32* %54, align 4
  %53954 = icmp eq i32 %53805, %53953
  %53955 = or i1 %53952, %53954
  %53956 = load i32, i32* %55, align 4
  %53957 = icmp eq i32 %53805, %53956
  %53958 = or i1 %53955, %53957
  %53959 = load i32, i32* %56, align 4
  %53960 = icmp eq i32 %53805, %53959
  %53961 = or i1 %53958, %53960
  %53962 = load i32, i32* %57, align 4
  %53963 = icmp eq i32 %53805, %53962
  %53964 = or i1 %53961, %53963
  %53965 = load i32, i32* %58, align 4
  %53966 = icmp eq i32 %53805, %53965
  %53967 = or i1 %53964, %53966
  %53968 = load i32, i32* %59, align 4
  %53969 = icmp eq i32 %53805, %53968
  %53970 = or i1 %53967, %53969
  %53971 = load i32, i32* %60, align 4
  %53972 = icmp eq i32 %53805, %53971
  %53973 = or i1 %53970, %53972
  %53974 = load i32, i32* %61, align 4
  %53975 = icmp eq i32 %53805, %53974
  %53976 = or i1 %53973, %53975
  %53977 = load i32, i32* %62, align 4
  %53978 = icmp eq i32 %53805, %53977
  %53979 = or i1 %53976, %53978
  %53980 = getelementptr i8, i8 addrspace(1)* %4, i32 198
  %53981 = zext i1 %53979 to i8
  store i8 %53981, i8 addrspace(1)* %53980, align 1, !nosanitize !3
  %53982 = load i256, i256* %53804, align 4
  %53983 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !777, !intsan !45
  %53984 = xor i256 %53983, -1
  %53985 = and i256 %53984, %53982
  %53986 = and i256 1461501637330902918203684832716283019655932542975, %53801
  %53987 = mul i256 %53986, 1, !pc !778, !intsan !45
  %53988 = or i256 %53987, %53985
  %53989 = alloca i256, align 8
  store i256 1, i256* %53989, align 4
  %53990 = alloca i256, align 8
  store i256 %53988, i256* %53990, align 4
  call void @__device_sstore(i256* %53989, i256* %53990)
  %53991 = call i32 @__hashword(i256* %53989)
  store i32 %53991, i32* %24, align 4, !nosanitize !3
  %53992 = alloca i256, align 8
  store i256 1, i256* %53992, align 4
  %53993 = alloca i256, align 8
  call void @__device_sload(i256* %53992, i256* %53993)
  %53994 = call i32 @__hashword(i256* %53992)
  %53995 = load i32, i32* %5, align 4
  %53996 = icmp eq i32 %53994, %53995
  %53997 = or i1 false, %53996
  %53998 = load i32, i32* %6, align 4
  %53999 = icmp eq i32 %53994, %53998
  %54000 = or i1 %53997, %53999
  %54001 = load i32, i32* %7, align 4
  %54002 = icmp eq i32 %53994, %54001
  %54003 = or i1 %54000, %54002
  %54004 = load i32, i32* %8, align 4
  %54005 = icmp eq i32 %53994, %54004
  %54006 = or i1 %54003, %54005
  %54007 = load i32, i32* %9, align 4
  %54008 = icmp eq i32 %53994, %54007
  %54009 = or i1 %54006, %54008
  %54010 = load i32, i32* %10, align 4
  %54011 = icmp eq i32 %53994, %54010
  %54012 = or i1 %54009, %54011
  %54013 = load i32, i32* %11, align 4
  %54014 = icmp eq i32 %53994, %54013
  %54015 = or i1 %54012, %54014
  %54016 = load i32, i32* %12, align 4
  %54017 = icmp eq i32 %53994, %54016
  %54018 = or i1 %54015, %54017
  %54019 = load i32, i32* %13, align 4
  %54020 = icmp eq i32 %53994, %54019
  %54021 = or i1 %54018, %54020
  %54022 = load i32, i32* %14, align 4
  %54023 = icmp eq i32 %53994, %54022
  %54024 = or i1 %54021, %54023
  %54025 = load i32, i32* %15, align 4
  %54026 = icmp eq i32 %53994, %54025
  %54027 = or i1 %54024, %54026
  %54028 = load i32, i32* %16, align 4
  %54029 = icmp eq i32 %53994, %54028
  %54030 = or i1 %54027, %54029
  %54031 = load i32, i32* %17, align 4
  %54032 = icmp eq i32 %53994, %54031
  %54033 = or i1 %54030, %54032
  %54034 = load i32, i32* %18, align 4
  %54035 = icmp eq i32 %53994, %54034
  %54036 = or i1 %54033, %54035
  %54037 = load i32, i32* %19, align 4
  %54038 = icmp eq i32 %53994, %54037
  %54039 = or i1 %54036, %54038
  %54040 = load i32, i32* %20, align 4
  %54041 = icmp eq i32 %53994, %54040
  %54042 = or i1 %54039, %54041
  %54043 = load i32, i32* %21, align 4
  %54044 = icmp eq i32 %53994, %54043
  %54045 = or i1 %54042, %54044
  %54046 = load i32, i32* %22, align 4
  %54047 = icmp eq i32 %53994, %54046
  %54048 = or i1 %54045, %54047
  %54049 = load i32, i32* %23, align 4
  %54050 = icmp eq i32 %53994, %54049
  %54051 = or i1 %54048, %54050
  %54052 = load i32, i32* %24, align 4
  %54053 = icmp eq i32 %53994, %54052
  %54054 = or i1 %54051, %54053
  %54055 = load i32, i32* %25, align 4
  %54056 = icmp eq i32 %53994, %54055
  %54057 = or i1 %54054, %54056
  %54058 = load i32, i32* %26, align 4
  %54059 = icmp eq i32 %53994, %54058
  %54060 = or i1 %54057, %54059
  %54061 = load i32, i32* %27, align 4
  %54062 = icmp eq i32 %53994, %54061
  %54063 = or i1 %54060, %54062
  %54064 = load i32, i32* %28, align 4
  %54065 = icmp eq i32 %53994, %54064
  %54066 = or i1 %54063, %54065
  %54067 = load i32, i32* %29, align 4
  %54068 = icmp eq i32 %53994, %54067
  %54069 = or i1 %54066, %54068
  %54070 = load i32, i32* %30, align 4
  %54071 = icmp eq i32 %53994, %54070
  %54072 = or i1 %54069, %54071
  %54073 = load i32, i32* %31, align 4
  %54074 = icmp eq i32 %53994, %54073
  %54075 = or i1 %54072, %54074
  %54076 = load i32, i32* %32, align 4
  %54077 = icmp eq i32 %53994, %54076
  %54078 = or i1 %54075, %54077
  %54079 = load i32, i32* %33, align 4
  %54080 = icmp eq i32 %53994, %54079
  %54081 = or i1 %54078, %54080
  %54082 = load i32, i32* %34, align 4
  %54083 = icmp eq i32 %53994, %54082
  %54084 = or i1 %54081, %54083
  %54085 = load i32, i32* %35, align 4
  %54086 = icmp eq i32 %53994, %54085
  %54087 = or i1 %54084, %54086
  %54088 = load i32, i32* %36, align 4
  %54089 = icmp eq i32 %53994, %54088
  %54090 = or i1 %54087, %54089
  %54091 = load i32, i32* %37, align 4
  %54092 = icmp eq i32 %53994, %54091
  %54093 = or i1 %54090, %54092
  %54094 = load i32, i32* %38, align 4
  %54095 = icmp eq i32 %53994, %54094
  %54096 = or i1 %54093, %54095
  %54097 = load i32, i32* %39, align 4
  %54098 = icmp eq i32 %53994, %54097
  %54099 = or i1 %54096, %54098
  %54100 = load i32, i32* %40, align 4
  %54101 = icmp eq i32 %53994, %54100
  %54102 = or i1 %54099, %54101
  %54103 = load i32, i32* %41, align 4
  %54104 = icmp eq i32 %53994, %54103
  %54105 = or i1 %54102, %54104
  %54106 = load i32, i32* %42, align 4
  %54107 = icmp eq i32 %53994, %54106
  %54108 = or i1 %54105, %54107
  %54109 = load i32, i32* %43, align 4
  %54110 = icmp eq i32 %53994, %54109
  %54111 = or i1 %54108, %54110
  %54112 = load i32, i32* %44, align 4
  %54113 = icmp eq i32 %53994, %54112
  %54114 = or i1 %54111, %54113
  %54115 = load i32, i32* %45, align 4
  %54116 = icmp eq i32 %53994, %54115
  %54117 = or i1 %54114, %54116
  %54118 = load i32, i32* %46, align 4
  %54119 = icmp eq i32 %53994, %54118
  %54120 = or i1 %54117, %54119
  %54121 = load i32, i32* %47, align 4
  %54122 = icmp eq i32 %53994, %54121
  %54123 = or i1 %54120, %54122
  %54124 = load i32, i32* %48, align 4
  %54125 = icmp eq i32 %53994, %54124
  %54126 = or i1 %54123, %54125
  %54127 = load i32, i32* %49, align 4
  %54128 = icmp eq i32 %53994, %54127
  %54129 = or i1 %54126, %54128
  %54130 = load i32, i32* %50, align 4
  %54131 = icmp eq i32 %53994, %54130
  %54132 = or i1 %54129, %54131
  %54133 = load i32, i32* %51, align 4
  %54134 = icmp eq i32 %53994, %54133
  %54135 = or i1 %54132, %54134
  %54136 = load i32, i32* %52, align 4
  %54137 = icmp eq i32 %53994, %54136
  %54138 = or i1 %54135, %54137
  %54139 = load i32, i32* %53, align 4
  %54140 = icmp eq i32 %53994, %54139
  %54141 = or i1 %54138, %54140
  %54142 = load i32, i32* %54, align 4
  %54143 = icmp eq i32 %53994, %54142
  %54144 = or i1 %54141, %54143
  %54145 = load i32, i32* %55, align 4
  %54146 = icmp eq i32 %53994, %54145
  %54147 = or i1 %54144, %54146
  %54148 = load i32, i32* %56, align 4
  %54149 = icmp eq i32 %53994, %54148
  %54150 = or i1 %54147, %54149
  %54151 = load i32, i32* %57, align 4
  %54152 = icmp eq i32 %53994, %54151
  %54153 = or i1 %54150, %54152
  %54154 = load i32, i32* %58, align 4
  %54155 = icmp eq i32 %53994, %54154
  %54156 = or i1 %54153, %54155
  %54157 = load i32, i32* %59, align 4
  %54158 = icmp eq i32 %53994, %54157
  %54159 = or i1 %54156, %54158
  %54160 = load i32, i32* %60, align 4
  %54161 = icmp eq i32 %53994, %54160
  %54162 = or i1 %54159, %54161
  %54163 = load i32, i32* %61, align 4
  %54164 = icmp eq i32 %53994, %54163
  %54165 = or i1 %54162, %54164
  %54166 = load i32, i32* %62, align 4
  %54167 = icmp eq i32 %53994, %54166
  %54168 = or i1 %54165, %54167
  %54169 = getelementptr i8, i8 addrspace(1)* %4, i32 199
  %54170 = zext i1 %54168 to i8
  store i8 %54170, i8 addrspace(1)* %54169, align 1, !nosanitize !3
  %54171 = load i256, i256* %53993, align 4
  %54172 = alloca i256, align 8
  store i256 %54171, i256* %54172, align 4
  %54173 = alloca i256, align 8
  store i256 1, i256* %54173, align 4
  %54174 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %54172, i256* %54173, i256* %54174), !pc !779, !intsan !6
  %54175 = load i256, i256* %54174, align 4
  %54176 = and i256 1461501637330902918203684832716283019655932542975, %54175
  %54177 = and i256 1461501637330902918203684832716283019655932542975, %54176
  %54178 = trunc i256 64 to i64
  %54179 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %54178, i256* %54179)
  %54180 = load i256, i256* %54179, align 4
  %54181 = and i256 4294967295, 3903137837
  %54182 = mul i256 26959946667150639794667015087019630673637144422540572481103610249216, %54181, !pc !780, !intsan !45
  %54183 = trunc i256 %54180 to i64
  %54184 = alloca i256, align 8
  store i256 %54182, i256* %54184, align 4
  %54185 = bitcast i256* %54184 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54183, i8* %54185, i64 32)
  %54186 = add i256 4, %54180, !pc !781, !intsan !10
  %54187 = xor i256 0, -1
  %54188 = and i256 %54187, %53795
  %54189 = xor i256 0, -1
  %54190 = and i256 %54189, %54188
  %54191 = trunc i256 %54186 to i64
  %54192 = alloca i256, align 8
  store i256 %54190, i256* %54192, align 4
  %54193 = bitcast i256* %54192 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54191, i8* %54193, i64 32)
  %54194 = add i256 32, %54186, !pc !782, !intsan !10
  %54195 = trunc i256 64 to i64
  %54196 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %54195, i256* %54196)
  %54197 = load i256, i256* %54196, align 4
  %54198 = sub i256 %54194, %54197, !pc !783, !intsan !8
  %54199 = icmp eq i256 1, 0
  %54200 = icmp eq i1 %54199, false
  %54201 = trunc i256 17501 to i64
  %jump.check182 = icmp ne i1 %54200, false
  %54202 = load i64, i64* %STACK_DEP_PTR, align 4
  %54203 = add i64 %54202, 1
  store i64 %54203, i64* %STACK_DEP_PTR, align 4
  %54204 = load i64, i64* %STACK_DEP_PTR, align 4
  %54205 = getelementptr i256, i256* %STACK, i64 %54204
  store i256 %53795, i256* %54205, align 4
  %54206 = load i64, i64* %STACK_DEP_PTR, align 4
  %54207 = add i64 %54206, 1
  store i64 %54207, i64* %STACK_DEP_PTR, align 4
  %54208 = load i64, i64* %STACK_DEP_PTR, align 4
  %54209 = getelementptr i256, i256* %STACK, i64 %54208
  store i256 %54177, i256* %54209, align 4
  %54210 = load i64, i64* %STACK_DEP_PTR, align 4
  %54211 = add i64 %54210, 1
  store i64 %54211, i64* %STACK_DEP_PTR, align 4
  %54212 = load i64, i64* %STACK_DEP_PTR, align 4
  %54213 = getelementptr i256, i256* %STACK, i64 %54212
  store i256 3903137837, i256* %54213, align 4
  %54214 = load i64, i64* %STACK_DEP_PTR, align 4
  %54215 = add i64 %54214, 1
  store i64 %54215, i64* %STACK_DEP_PTR, align 4
  %54216 = load i64, i64* %STACK_DEP_PTR, align 4
  %54217 = getelementptr i256, i256* %STACK, i64 %54216
  store i256 %54194, i256* %54217, align 4
  %54218 = load i64, i64* %STACK_DEP_PTR, align 4
  %54219 = add i64 %54218, 1
  store i64 %54219, i64* %STACK_DEP_PTR, align 4
  %54220 = load i64, i64* %STACK_DEP_PTR, align 4
  %54221 = getelementptr i256, i256* %STACK, i64 %54220
  store i256 0, i256* %54221, align 4
  %54222 = load i64, i64* %STACK_DEP_PTR, align 4
  %54223 = add i64 %54222, 1
  store i64 %54223, i64* %STACK_DEP_PTR, align 4
  %54224 = load i64, i64* %STACK_DEP_PTR, align 4
  %54225 = getelementptr i256, i256* %STACK, i64 %54224
  store i256 %54197, i256* %54225, align 4
  %54226 = load i64, i64* %STACK_DEP_PTR, align 4
  %54227 = add i64 %54226, 1
  store i64 %54227, i64* %STACK_DEP_PTR, align 4
  %54228 = load i64, i64* %STACK_DEP_PTR, align 4
  %54229 = getelementptr i256, i256* %STACK, i64 %54228
  store i256 %54198, i256* %54229, align 4
  %54230 = load i64, i64* %STACK_DEP_PTR, align 4
  %54231 = add i64 %54230, 1
  store i64 %54231, i64* %STACK_DEP_PTR, align 4
  %54232 = load i64, i64* %STACK_DEP_PTR, align 4
  %54233 = getelementptr i256, i256* %STACK, i64 %54232
  store i256 %54197, i256* %54233, align 4
  %54234 = load i64, i64* %STACK_DEP_PTR, align 4
  %54235 = add i64 %54234, 1
  store i64 %54235, i64* %STACK_DEP_PTR, align 4
  %54236 = load i64, i64* %STACK_DEP_PTR, align 4
  %54237 = getelementptr i256, i256* %STACK, i64 %54236
  store i256 0, i256* %54237, align 4
  %54238 = load i64, i64* %STACK_DEP_PTR, align 4
  %54239 = add i64 %54238, 1
  store i64 %54239, i64* %STACK_DEP_PTR, align 4
  %54240 = load i64, i64* %STACK_DEP_PTR, align 4
  %54241 = getelementptr i256, i256* %STACK, i64 %54240
  store i256 %54177, i256* %54241, align 4
  %54242 = load i64, i64* %STACK_DEP_PTR, align 4
  %54243 = add i64 %54242, 1
  store i64 %54243, i64* %STACK_DEP_PTR, align 4
  %54244 = zext i1 %54199 to i256
  %54245 = load i64, i64* %STACK_DEP_PTR, align 4
  %54246 = getelementptr i256, i256* %STACK, i64 %54245
  store i256 %54244, i256* %54246, align 4
  br i1 %jump.check182, label %.17501, label %.17497, !EVMBB !4

.17497:                                           ; preds = %53776
  %54247 = load i64, i64* %remaing_gas, align 4
  %54248 = icmp ugt i64 40, %54247
  br i1 %54248, label %Abort, label %54249

54249:                                            ; preds = %.17497
  %54250 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54251 = xor i32 %54250, 1278
  %54252 = urem i32 %54251, 4096
  %54253 = getelementptr i8, i8 addrspace(1)* %4, i32 %54252
  %54254 = load i8, i8 addrspace(1)* %54253, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54253, align 1, !nosanitize !3
  store i32 639, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54255 = sub i64 %54247, 40
  store i64 %54255, i64* %remaing_gas, align 4
  %54256 = load i64, i64* %STACK_DEP_PTR, align 4
  %54257 = sub i64 %54256, 0
  store i64 %54257, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.17501:                                           ; preds = %53776, %JumpTable
  %54258 = load i64, i64* %remaing_gas, align 4
  %54259 = icmp ugt i64 456, %54258
  br i1 %54259, label %Abort, label %54260

54260:                                            ; preds = %.17501
  %54261 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54262 = xor i32 %54261, 3044
  %54263 = urem i32 %54262, 4096
  %54264 = getelementptr i8, i8 addrspace(1)* %4, i32 %54263
  %54265 = load i8, i8 addrspace(1)* %54264, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54264, align 1, !nosanitize !3
  store i32 1522, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54266 = sub i64 %54258, 456
  store i64 %54266, i64* %remaing_gas, align 4
  %54267 = load i64, i64* %STACK_DEP_PTR, align 4
  %54268 = getelementptr i256, i256* %STACK, i64 %54267
  %54269 = load i256, i256* %54268, align 4
  %54270 = load i64, i64* %STACK_DEP_PTR, align 4
  %54271 = sub i64 %54270, 1
  store i64 %54271, i64* %STACK_DEP_PTR, align 4
  %54272 = load i64, i64* %STACK_DEP_PTR, align 4
  %54273 = getelementptr i256, i256* %STACK, i64 %54272
  %54274 = load i256, i256* %54273, align 4
  %54275 = load i64, i64* %STACK_DEP_PTR, align 4
  %54276 = sub i64 %54275, 1
  store i64 %54276, i64* %STACK_DEP_PTR, align 4
  %54277 = load i64, i64* %STACK_DEP_PTR, align 4
  %54278 = getelementptr i256, i256* %STACK, i64 %54277
  %54279 = load i256, i256* %54278, align 4
  %54280 = load i64, i64* %STACK_DEP_PTR, align 4
  %54281 = sub i64 %54280, 1
  store i64 %54281, i64* %STACK_DEP_PTR, align 4
  %54282 = load i64, i64* %STACK_DEP_PTR, align 4
  %54283 = getelementptr i256, i256* %STACK, i64 %54282
  %54284 = load i256, i256* %54283, align 4
  %54285 = load i64, i64* %STACK_DEP_PTR, align 4
  %54286 = sub i64 %54285, 1
  store i64 %54286, i64* %STACK_DEP_PTR, align 4
  %54287 = load i64, i64* %STACK_DEP_PTR, align 4
  %54288 = getelementptr i256, i256* %STACK, i64 %54287
  %54289 = load i256, i256* %54288, align 4
  %54290 = load i64, i64* %STACK_DEP_PTR, align 4
  %54291 = sub i64 %54290, 1
  store i64 %54291, i64* %STACK_DEP_PTR, align 4
  %54292 = load i64, i64* %STACK_DEP_PTR, align 4
  %54293 = getelementptr i256, i256* %STACK, i64 %54292
  %54294 = load i256, i256* %54293, align 4
  %54295 = load i64, i64* %STACK_DEP_PTR, align 4
  %54296 = sub i64 %54295, 1
  store i64 %54296, i64* %STACK_DEP_PTR, align 4
  %54297 = load i64, i64* %STACK_DEP_PTR, align 4
  %54298 = getelementptr i256, i256* %STACK, i64 %54297
  %54299 = load i256, i256* %54298, align 4
  %54300 = load i64, i64* %STACK_DEP_PTR, align 4
  %54301 = sub i64 %54300, 1
  store i64 %54301, i64* %STACK_DEP_PTR, align 4
  %54302 = trunc i256 %54274 to i160
  %54303 = call i1 @solidity_call(), !pc !784
  %54304 = icmp eq i1 %54303, false
  %54305 = icmp eq i1 %54304, false
  %54306 = trunc i256 17521 to i64
  %jump.check183 = icmp ne i1 %54305, false
  %54307 = load i64, i64* %STACK_DEP_PTR, align 4
  %54308 = add i64 %54307, 1
  store i64 %54308, i64* %STACK_DEP_PTR, align 4
  %54309 = zext i1 %54304 to i256
  %54310 = load i64, i64* %STACK_DEP_PTR, align 4
  %54311 = getelementptr i256, i256* %STACK, i64 %54310
  store i256 %54309, i256* %54311, align 4
  br i1 %jump.check183, label %.17521, label %.17512, !EVMBB !4

.17512:                                           ; preds = %54260
  %54312 = load i64, i64* %remaing_gas, align 4
  %54313 = icmp ugt i64 40, %54312
  br i1 %54313, label %Abort, label %54314

54314:                                            ; preds = %.17512
  %54315 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54316 = xor i32 %54315, 3545
  %54317 = urem i32 %54316, 4096
  %54318 = getelementptr i8, i8 addrspace(1)* %4, i32 %54317
  %54319 = load i8, i8 addrspace(1)* %54318, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54318, align 1, !nosanitize !3
  store i32 1772, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54320 = sub i64 %54312, 40
  store i64 %54320, i64* %remaing_gas, align 4
  %54321 = load i64, i64* %STACK_DEP_PTR, align 4
  %54322 = sub i64 %54321, 0
  store i64 %54322, i64* %STACK_DEP_PTR, align 4
  br label %Abort, !EVMBB !4

.17521:                                           ; preds = %54260, %JumpTable
  %54323 = load i64, i64* %remaing_gas, align 4
  %54324 = icmp ugt i64 320, %54323
  br i1 %54324, label %Abort, label %54325

54325:                                            ; preds = %.17521
  %54326 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54327 = xor i32 %54326, 4045
  %54328 = urem i32 %54327, 4096
  %54329 = getelementptr i8, i8 addrspace(1)* %4, i32 %54328
  %54330 = load i8, i8 addrspace(1)* %54329, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54329, align 1, !nosanitize !3
  store i32 2022, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54331 = sub i64 %54323, 320
  store i64 %54331, i64* %remaing_gas, align 4
  %54332 = load i64, i64* %STACK_DEP_PTR, align 4
  %54333 = getelementptr i256, i256* %STACK, i64 %54332
  %54334 = load i256, i256* %54333, align 4
  %54335 = load i64, i64* %STACK_DEP_PTR, align 4
  %54336 = sub i64 %54335, 1
  store i64 %54336, i64* %STACK_DEP_PTR, align 4
  %54337 = load i64, i64* %STACK_DEP_PTR, align 4
  %54338 = getelementptr i256, i256* %STACK, i64 %54337
  %54339 = load i256, i256* %54338, align 4
  %54340 = load i64, i64* %STACK_DEP_PTR, align 4
  %54341 = sub i64 %54340, 1
  store i64 %54341, i64* %STACK_DEP_PTR, align 4
  %54342 = load i64, i64* %STACK_DEP_PTR, align 4
  %54343 = getelementptr i256, i256* %STACK, i64 %54342
  %54344 = load i256, i256* %54343, align 4
  %54345 = load i64, i64* %STACK_DEP_PTR, align 4
  %54346 = sub i64 %54345, 1
  store i64 %54346, i64* %STACK_DEP_PTR, align 4
  %54347 = load i64, i64* %STACK_DEP_PTR, align 4
  %54348 = getelementptr i256, i256* %STACK, i64 %54347
  %54349 = load i256, i256* %54348, align 4
  %54350 = load i64, i64* %STACK_DEP_PTR, align 4
  %54351 = sub i64 %54350, 1
  store i64 %54351, i64* %STACK_DEP_PTR, align 4
  %54352 = load i64, i64* %STACK_DEP_PTR, align 4
  %54353 = getelementptr i256, i256* %STACK, i64 %54352
  %54354 = load i256, i256* %54353, align 4
  %54355 = load i64, i64* %STACK_DEP_PTR, align 4
  %54356 = sub i64 %54355, 1
  store i64 %54356, i64* %STACK_DEP_PTR, align 4
  %54357 = load i64, i64* %STACK_DEP_PTR, align 4
  %54358 = getelementptr i256, i256* %STACK, i64 %54357
  %54359 = load i256, i256* %54358, align 4
  %54360 = load i64, i64* %STACK_DEP_PTR, align 4
  %54361 = sub i64 %54360, 1
  store i64 %54361, i64* %STACK_DEP_PTR, align 4
  %54362 = trunc i256 %54359 to i64
  store i64 %54362, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.17528:                                           ; preds = %35670, %JumpTable
  %54363 = load i64, i64* %remaing_gas, align 4
  %54364 = icmp ugt i64 1160, %54363
  br i1 %54364, label %Abort, label %54365

54365:                                            ; preds = %.17528
  %54366 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54367 = xor i32 %54366, 3653
  %54368 = urem i32 %54367, 4096
  %54369 = getelementptr i8, i8 addrspace(1)* %4, i32 %54368
  %54370 = load i8, i8 addrspace(1)* %54369, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54369, align 1, !nosanitize !3
  store i32 1826, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54371 = sub i64 %54363, 1160
  store i64 %54371, i64* %remaing_gas, align 4
  %54372 = load i64, i64* %STACK_DEP_PTR, align 4
  %54373 = getelementptr i256, i256* %STACK, i64 %54372
  %54374 = load i256, i256* %54373, align 4
  %54375 = load i64, i64* %STACK_DEP_PTR, align 4
  %54376 = sub i64 %54375, 1
  store i64 %54376, i64* %STACK_DEP_PTR, align 4
  %54377 = load i64, i64* %STACK_DEP_PTR, align 4
  %54378 = getelementptr i256, i256* %STACK, i64 %54377
  %54379 = load i256, i256* %54378, align 4
  %54380 = load i64, i64* %STACK_DEP_PTR, align 4
  %54381 = sub i64 %54380, 1
  store i64 %54381, i64* %STACK_DEP_PTR, align 4
  %54382 = load i256, i256* %0, align 4
  %54383 = and i256 1461501637330902918203684832716283019655932542975, %54382
  %54384 = and i256 1461501637330902918203684832716283019655932542975, %54383
  %54385 = trunc i256 0 to i64
  %54386 = alloca i256, align 8
  store i256 %54384, i256* %54386, align 4
  %54387 = bitcast i256* %54386 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54385, i8* %54387, i64 32)
  %54388 = add i256 32, 0, !pc !785, !intsan !10
  %54389 = trunc i256 %54388 to i64
  %54390 = alloca i256, align 8
  store i256 3, i256* %54390, align 4
  %54391 = bitcast i256* %54390 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54389, i8* %54391, i64 32)
  %54392 = add i256 32, %54388, !pc !786, !intsan !10
  %54393 = trunc i256 0 to i32
  %54394 = trunc i256 %54392 to i32
  %54395 = getelementptr inbounds i8, i8* %MEMORY, i32 %54393
  %54396 = alloca i256, align 8
  %54397 = bitcast i256* %54396 to i8*
  call void @__device_sha3(i8* %54395, i32 %54394, i8* %54397)
  %54398 = load i256, i256* %54396, align 4
  %54399 = alloca i256, align 8
  store i256 %54398, i256* %54399, align 4
  %54400 = alloca i256, align 8
  store i256 %54374, i256* %54400, align 4
  call void @__device_sstore(i256* %54399, i256* %54400)
  %54401 = call i32 @__hashword(i256* %54399)
  store i32 %54401, i32* %56, align 4, !nosanitize !3
  %54402 = load i256, i256* %0, align 4
  %54403 = trunc i256 0 to i64
  %54404 = alloca i256, align 8
  store i256 %54374, i256* %54404, align 4
  %54405 = bitcast i256* %54404 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54403, i8* %54405, i64 32)
  %54406 = add i256 32, 0, !pc !787, !intsan !10
  %54407 = trunc i256 %54406 to i64
  %54408 = alloca i256, align 8
  store i256 4, i256* %54408, align 4
  %54409 = bitcast i256* %54408 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54407, i8* %54409, i64 32)
  %54410 = add i256 32, %54406, !pc !788, !intsan !10
  %54411 = trunc i256 0 to i32
  %54412 = trunc i256 %54410 to i32
  %54413 = getelementptr inbounds i8, i8* %MEMORY, i32 %54411
  %54414 = alloca i256, align 8
  %54415 = bitcast i256* %54414 to i8*
  call void @__device_sha3(i8* %54413, i32 %54412, i8* %54415)
  %54416 = load i256, i256* %54414, align 4
  %54417 = add i256 0, %54416, !pc !789, !intsan !10
  %54418 = alloca i256, align 8
  store i256 %54417, i256* %54418, align 4
  %54419 = alloca i256, align 8
  call void @__device_sload(i256* %54418, i256* %54419)
  %54420 = call i32 @__hashword(i256* %54418)
  %54421 = load i32, i32* %5, align 4
  %54422 = icmp eq i32 %54420, %54421
  %54423 = or i1 false, %54422
  %54424 = load i32, i32* %6, align 4
  %54425 = icmp eq i32 %54420, %54424
  %54426 = or i1 %54423, %54425
  %54427 = load i32, i32* %7, align 4
  %54428 = icmp eq i32 %54420, %54427
  %54429 = or i1 %54426, %54428
  %54430 = load i32, i32* %8, align 4
  %54431 = icmp eq i32 %54420, %54430
  %54432 = or i1 %54429, %54431
  %54433 = load i32, i32* %9, align 4
  %54434 = icmp eq i32 %54420, %54433
  %54435 = or i1 %54432, %54434
  %54436 = load i32, i32* %10, align 4
  %54437 = icmp eq i32 %54420, %54436
  %54438 = or i1 %54435, %54437
  %54439 = load i32, i32* %11, align 4
  %54440 = icmp eq i32 %54420, %54439
  %54441 = or i1 %54438, %54440
  %54442 = load i32, i32* %12, align 4
  %54443 = icmp eq i32 %54420, %54442
  %54444 = or i1 %54441, %54443
  %54445 = load i32, i32* %13, align 4
  %54446 = icmp eq i32 %54420, %54445
  %54447 = or i1 %54444, %54446
  %54448 = load i32, i32* %14, align 4
  %54449 = icmp eq i32 %54420, %54448
  %54450 = or i1 %54447, %54449
  %54451 = load i32, i32* %15, align 4
  %54452 = icmp eq i32 %54420, %54451
  %54453 = or i1 %54450, %54452
  %54454 = load i32, i32* %16, align 4
  %54455 = icmp eq i32 %54420, %54454
  %54456 = or i1 %54453, %54455
  %54457 = load i32, i32* %17, align 4
  %54458 = icmp eq i32 %54420, %54457
  %54459 = or i1 %54456, %54458
  %54460 = load i32, i32* %18, align 4
  %54461 = icmp eq i32 %54420, %54460
  %54462 = or i1 %54459, %54461
  %54463 = load i32, i32* %19, align 4
  %54464 = icmp eq i32 %54420, %54463
  %54465 = or i1 %54462, %54464
  %54466 = load i32, i32* %20, align 4
  %54467 = icmp eq i32 %54420, %54466
  %54468 = or i1 %54465, %54467
  %54469 = load i32, i32* %21, align 4
  %54470 = icmp eq i32 %54420, %54469
  %54471 = or i1 %54468, %54470
  %54472 = load i32, i32* %22, align 4
  %54473 = icmp eq i32 %54420, %54472
  %54474 = or i1 %54471, %54473
  %54475 = load i32, i32* %23, align 4
  %54476 = icmp eq i32 %54420, %54475
  %54477 = or i1 %54474, %54476
  %54478 = load i32, i32* %24, align 4
  %54479 = icmp eq i32 %54420, %54478
  %54480 = or i1 %54477, %54479
  %54481 = load i32, i32* %25, align 4
  %54482 = icmp eq i32 %54420, %54481
  %54483 = or i1 %54480, %54482
  %54484 = load i32, i32* %26, align 4
  %54485 = icmp eq i32 %54420, %54484
  %54486 = or i1 %54483, %54485
  %54487 = load i32, i32* %27, align 4
  %54488 = icmp eq i32 %54420, %54487
  %54489 = or i1 %54486, %54488
  %54490 = load i32, i32* %28, align 4
  %54491 = icmp eq i32 %54420, %54490
  %54492 = or i1 %54489, %54491
  %54493 = load i32, i32* %29, align 4
  %54494 = icmp eq i32 %54420, %54493
  %54495 = or i1 %54492, %54494
  %54496 = load i32, i32* %30, align 4
  %54497 = icmp eq i32 %54420, %54496
  %54498 = or i1 %54495, %54497
  %54499 = load i32, i32* %31, align 4
  %54500 = icmp eq i32 %54420, %54499
  %54501 = or i1 %54498, %54500
  %54502 = load i32, i32* %32, align 4
  %54503 = icmp eq i32 %54420, %54502
  %54504 = or i1 %54501, %54503
  %54505 = load i32, i32* %33, align 4
  %54506 = icmp eq i32 %54420, %54505
  %54507 = or i1 %54504, %54506
  %54508 = load i32, i32* %34, align 4
  %54509 = icmp eq i32 %54420, %54508
  %54510 = or i1 %54507, %54509
  %54511 = load i32, i32* %35, align 4
  %54512 = icmp eq i32 %54420, %54511
  %54513 = or i1 %54510, %54512
  %54514 = load i32, i32* %36, align 4
  %54515 = icmp eq i32 %54420, %54514
  %54516 = or i1 %54513, %54515
  %54517 = load i32, i32* %37, align 4
  %54518 = icmp eq i32 %54420, %54517
  %54519 = or i1 %54516, %54518
  %54520 = load i32, i32* %38, align 4
  %54521 = icmp eq i32 %54420, %54520
  %54522 = or i1 %54519, %54521
  %54523 = load i32, i32* %39, align 4
  %54524 = icmp eq i32 %54420, %54523
  %54525 = or i1 %54522, %54524
  %54526 = load i32, i32* %40, align 4
  %54527 = icmp eq i32 %54420, %54526
  %54528 = or i1 %54525, %54527
  %54529 = load i32, i32* %41, align 4
  %54530 = icmp eq i32 %54420, %54529
  %54531 = or i1 %54528, %54530
  %54532 = load i32, i32* %42, align 4
  %54533 = icmp eq i32 %54420, %54532
  %54534 = or i1 %54531, %54533
  %54535 = load i32, i32* %43, align 4
  %54536 = icmp eq i32 %54420, %54535
  %54537 = or i1 %54534, %54536
  %54538 = load i32, i32* %44, align 4
  %54539 = icmp eq i32 %54420, %54538
  %54540 = or i1 %54537, %54539
  %54541 = load i32, i32* %45, align 4
  %54542 = icmp eq i32 %54420, %54541
  %54543 = or i1 %54540, %54542
  %54544 = load i32, i32* %46, align 4
  %54545 = icmp eq i32 %54420, %54544
  %54546 = or i1 %54543, %54545
  %54547 = load i32, i32* %47, align 4
  %54548 = icmp eq i32 %54420, %54547
  %54549 = or i1 %54546, %54548
  %54550 = load i32, i32* %48, align 4
  %54551 = icmp eq i32 %54420, %54550
  %54552 = or i1 %54549, %54551
  %54553 = load i32, i32* %49, align 4
  %54554 = icmp eq i32 %54420, %54553
  %54555 = or i1 %54552, %54554
  %54556 = load i32, i32* %50, align 4
  %54557 = icmp eq i32 %54420, %54556
  %54558 = or i1 %54555, %54557
  %54559 = load i32, i32* %51, align 4
  %54560 = icmp eq i32 %54420, %54559
  %54561 = or i1 %54558, %54560
  %54562 = load i32, i32* %52, align 4
  %54563 = icmp eq i32 %54420, %54562
  %54564 = or i1 %54561, %54563
  %54565 = load i32, i32* %53, align 4
  %54566 = icmp eq i32 %54420, %54565
  %54567 = or i1 %54564, %54566
  %54568 = load i32, i32* %54, align 4
  %54569 = icmp eq i32 %54420, %54568
  %54570 = or i1 %54567, %54569
  %54571 = load i32, i32* %55, align 4
  %54572 = icmp eq i32 %54420, %54571
  %54573 = or i1 %54570, %54572
  %54574 = load i32, i32* %56, align 4
  %54575 = icmp eq i32 %54420, %54574
  %54576 = or i1 %54573, %54575
  %54577 = load i32, i32* %57, align 4
  %54578 = icmp eq i32 %54420, %54577
  %54579 = or i1 %54576, %54578
  %54580 = load i32, i32* %58, align 4
  %54581 = icmp eq i32 %54420, %54580
  %54582 = or i1 %54579, %54581
  %54583 = load i32, i32* %59, align 4
  %54584 = icmp eq i32 %54420, %54583
  %54585 = or i1 %54582, %54584
  %54586 = load i32, i32* %60, align 4
  %54587 = icmp eq i32 %54420, %54586
  %54588 = or i1 %54585, %54587
  %54589 = load i32, i32* %61, align 4
  %54590 = icmp eq i32 %54420, %54589
  %54591 = or i1 %54588, %54590
  %54592 = load i32, i32* %62, align 4
  %54593 = icmp eq i32 %54420, %54592
  %54594 = or i1 %54591, %54593
  %54595 = getelementptr i8, i8 addrspace(1)* %4, i32 200
  %54596 = zext i1 %54594 to i8
  store i8 %54596, i8 addrspace(1)* %54595, align 1, !nosanitize !3
  %54597 = load i256, i256* %54419, align 4
  %54598 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !790, !intsan !45
  %54599 = xor i256 %54598, -1
  %54600 = and i256 %54599, %54597
  %54601 = and i256 1461501637330902918203684832716283019655932542975, %54402
  %54602 = mul i256 %54601, 1, !pc !791, !intsan !45
  %54603 = or i256 %54602, %54600
  %54604 = alloca i256, align 8
  store i256 %54417, i256* %54604, align 4
  %54605 = alloca i256, align 8
  store i256 %54603, i256* %54605, align 4
  call void @__device_sstore(i256* %54604, i256* %54605)
  %54606 = call i32 @__hashword(i256* %54604)
  store i32 %54606, i32* %57, align 4, !nosanitize !3
  %54607 = load i256, i256* %1, align 4
  %54608 = trunc i256 0 to i64
  %54609 = alloca i256, align 8
  store i256 %54374, i256* %54609, align 4
  %54610 = bitcast i256* %54609 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54608, i8* %54610, i64 32)
  %54611 = add i256 32, 0, !pc !792, !intsan !10
  %54612 = trunc i256 %54611 to i64
  %54613 = alloca i256, align 8
  store i256 4, i256* %54613, align 4
  %54614 = bitcast i256* %54613 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54612, i8* %54614, i64 32)
  %54615 = add i256 32, %54611, !pc !793, !intsan !10
  %54616 = trunc i256 0 to i32
  %54617 = trunc i256 %54615 to i32
  %54618 = getelementptr inbounds i8, i8* %MEMORY, i32 %54616
  %54619 = alloca i256, align 8
  %54620 = bitcast i256* %54619 to i8*
  call void @__device_sha3(i8* %54618, i32 %54617, i8* %54620)
  %54621 = load i256, i256* %54619, align 4
  %54622 = add i256 1, %54621, !pc !794, !intsan !10
  %54623 = alloca i256, align 8
  store i256 %54622, i256* %54623, align 4
  %54624 = alloca i256, align 8
  store i256 %54607, i256* %54624, align 4
  call void @__device_sstore(i256* %54623, i256* %54624)
  %54625 = call i32 @__hashword(i256* %54623)
  store i32 %54625, i32* %58, align 4, !nosanitize !3
  %54626 = load i256, i256* %1, align 4
  %54627 = alloca i256, align 8
  store i256 6, i256* %54627, align 4
  %54628 = alloca i256, align 8
  call void @__device_sload(i256* %54627, i256* %54628)
  %54629 = call i32 @__hashword(i256* %54627)
  %54630 = load i32, i32* %5, align 4
  %54631 = icmp eq i32 %54629, %54630
  %54632 = or i1 false, %54631
  %54633 = load i32, i32* %6, align 4
  %54634 = icmp eq i32 %54629, %54633
  %54635 = or i1 %54632, %54634
  %54636 = load i32, i32* %7, align 4
  %54637 = icmp eq i32 %54629, %54636
  %54638 = or i1 %54635, %54637
  %54639 = load i32, i32* %8, align 4
  %54640 = icmp eq i32 %54629, %54639
  %54641 = or i1 %54638, %54640
  %54642 = load i32, i32* %9, align 4
  %54643 = icmp eq i32 %54629, %54642
  %54644 = or i1 %54641, %54643
  %54645 = load i32, i32* %10, align 4
  %54646 = icmp eq i32 %54629, %54645
  %54647 = or i1 %54644, %54646
  %54648 = load i32, i32* %11, align 4
  %54649 = icmp eq i32 %54629, %54648
  %54650 = or i1 %54647, %54649
  %54651 = load i32, i32* %12, align 4
  %54652 = icmp eq i32 %54629, %54651
  %54653 = or i1 %54650, %54652
  %54654 = load i32, i32* %13, align 4
  %54655 = icmp eq i32 %54629, %54654
  %54656 = or i1 %54653, %54655
  %54657 = load i32, i32* %14, align 4
  %54658 = icmp eq i32 %54629, %54657
  %54659 = or i1 %54656, %54658
  %54660 = load i32, i32* %15, align 4
  %54661 = icmp eq i32 %54629, %54660
  %54662 = or i1 %54659, %54661
  %54663 = load i32, i32* %16, align 4
  %54664 = icmp eq i32 %54629, %54663
  %54665 = or i1 %54662, %54664
  %54666 = load i32, i32* %17, align 4
  %54667 = icmp eq i32 %54629, %54666
  %54668 = or i1 %54665, %54667
  %54669 = load i32, i32* %18, align 4
  %54670 = icmp eq i32 %54629, %54669
  %54671 = or i1 %54668, %54670
  %54672 = load i32, i32* %19, align 4
  %54673 = icmp eq i32 %54629, %54672
  %54674 = or i1 %54671, %54673
  %54675 = load i32, i32* %20, align 4
  %54676 = icmp eq i32 %54629, %54675
  %54677 = or i1 %54674, %54676
  %54678 = load i32, i32* %21, align 4
  %54679 = icmp eq i32 %54629, %54678
  %54680 = or i1 %54677, %54679
  %54681 = load i32, i32* %22, align 4
  %54682 = icmp eq i32 %54629, %54681
  %54683 = or i1 %54680, %54682
  %54684 = load i32, i32* %23, align 4
  %54685 = icmp eq i32 %54629, %54684
  %54686 = or i1 %54683, %54685
  %54687 = load i32, i32* %24, align 4
  %54688 = icmp eq i32 %54629, %54687
  %54689 = or i1 %54686, %54688
  %54690 = load i32, i32* %25, align 4
  %54691 = icmp eq i32 %54629, %54690
  %54692 = or i1 %54689, %54691
  %54693 = load i32, i32* %26, align 4
  %54694 = icmp eq i32 %54629, %54693
  %54695 = or i1 %54692, %54694
  %54696 = load i32, i32* %27, align 4
  %54697 = icmp eq i32 %54629, %54696
  %54698 = or i1 %54695, %54697
  %54699 = load i32, i32* %28, align 4
  %54700 = icmp eq i32 %54629, %54699
  %54701 = or i1 %54698, %54700
  %54702 = load i32, i32* %29, align 4
  %54703 = icmp eq i32 %54629, %54702
  %54704 = or i1 %54701, %54703
  %54705 = load i32, i32* %30, align 4
  %54706 = icmp eq i32 %54629, %54705
  %54707 = or i1 %54704, %54706
  %54708 = load i32, i32* %31, align 4
  %54709 = icmp eq i32 %54629, %54708
  %54710 = or i1 %54707, %54709
  %54711 = load i32, i32* %32, align 4
  %54712 = icmp eq i32 %54629, %54711
  %54713 = or i1 %54710, %54712
  %54714 = load i32, i32* %33, align 4
  %54715 = icmp eq i32 %54629, %54714
  %54716 = or i1 %54713, %54715
  %54717 = load i32, i32* %34, align 4
  %54718 = icmp eq i32 %54629, %54717
  %54719 = or i1 %54716, %54718
  %54720 = load i32, i32* %35, align 4
  %54721 = icmp eq i32 %54629, %54720
  %54722 = or i1 %54719, %54721
  %54723 = load i32, i32* %36, align 4
  %54724 = icmp eq i32 %54629, %54723
  %54725 = or i1 %54722, %54724
  %54726 = load i32, i32* %37, align 4
  %54727 = icmp eq i32 %54629, %54726
  %54728 = or i1 %54725, %54727
  %54729 = load i32, i32* %38, align 4
  %54730 = icmp eq i32 %54629, %54729
  %54731 = or i1 %54728, %54730
  %54732 = load i32, i32* %39, align 4
  %54733 = icmp eq i32 %54629, %54732
  %54734 = or i1 %54731, %54733
  %54735 = load i32, i32* %40, align 4
  %54736 = icmp eq i32 %54629, %54735
  %54737 = or i1 %54734, %54736
  %54738 = load i32, i32* %41, align 4
  %54739 = icmp eq i32 %54629, %54738
  %54740 = or i1 %54737, %54739
  %54741 = load i32, i32* %42, align 4
  %54742 = icmp eq i32 %54629, %54741
  %54743 = or i1 %54740, %54742
  %54744 = load i32, i32* %43, align 4
  %54745 = icmp eq i32 %54629, %54744
  %54746 = or i1 %54743, %54745
  %54747 = load i32, i32* %44, align 4
  %54748 = icmp eq i32 %54629, %54747
  %54749 = or i1 %54746, %54748
  %54750 = load i32, i32* %45, align 4
  %54751 = icmp eq i32 %54629, %54750
  %54752 = or i1 %54749, %54751
  %54753 = load i32, i32* %46, align 4
  %54754 = icmp eq i32 %54629, %54753
  %54755 = or i1 %54752, %54754
  %54756 = load i32, i32* %47, align 4
  %54757 = icmp eq i32 %54629, %54756
  %54758 = or i1 %54755, %54757
  %54759 = load i32, i32* %48, align 4
  %54760 = icmp eq i32 %54629, %54759
  %54761 = or i1 %54758, %54760
  %54762 = load i32, i32* %49, align 4
  %54763 = icmp eq i32 %54629, %54762
  %54764 = or i1 %54761, %54763
  %54765 = load i32, i32* %50, align 4
  %54766 = icmp eq i32 %54629, %54765
  %54767 = or i1 %54764, %54766
  %54768 = load i32, i32* %51, align 4
  %54769 = icmp eq i32 %54629, %54768
  %54770 = or i1 %54767, %54769
  %54771 = load i32, i32* %52, align 4
  %54772 = icmp eq i32 %54629, %54771
  %54773 = or i1 %54770, %54772
  %54774 = load i32, i32* %53, align 4
  %54775 = icmp eq i32 %54629, %54774
  %54776 = or i1 %54773, %54775
  %54777 = load i32, i32* %54, align 4
  %54778 = icmp eq i32 %54629, %54777
  %54779 = or i1 %54776, %54778
  %54780 = load i32, i32* %55, align 4
  %54781 = icmp eq i32 %54629, %54780
  %54782 = or i1 %54779, %54781
  %54783 = load i32, i32* %56, align 4
  %54784 = icmp eq i32 %54629, %54783
  %54785 = or i1 %54782, %54784
  %54786 = load i32, i32* %57, align 4
  %54787 = icmp eq i32 %54629, %54786
  %54788 = or i1 %54785, %54787
  %54789 = load i32, i32* %58, align 4
  %54790 = icmp eq i32 %54629, %54789
  %54791 = or i1 %54788, %54790
  %54792 = load i32, i32* %59, align 4
  %54793 = icmp eq i32 %54629, %54792
  %54794 = or i1 %54791, %54793
  %54795 = load i32, i32* %60, align 4
  %54796 = icmp eq i32 %54629, %54795
  %54797 = or i1 %54794, %54796
  %54798 = load i32, i32* %61, align 4
  %54799 = icmp eq i32 %54629, %54798
  %54800 = or i1 %54797, %54799
  %54801 = load i32, i32* %62, align 4
  %54802 = icmp eq i32 %54629, %54801
  %54803 = or i1 %54800, %54802
  %54804 = getelementptr i8, i8 addrspace(1)* %4, i32 201
  %54805 = zext i1 %54803 to i8
  store i8 %54805, i8 addrspace(1)* %54804, align 1, !nosanitize !3
  %54806 = load i256, i256* %54628, align 4
  %54807 = add i256 %54806, %54626, !pc !795, !intsan !10
  %54808 = alloca i256, align 8
  store i256 6, i256* %54808, align 4
  %54809 = alloca i256, align 8
  store i256 %54807, i256* %54809, align 4
  call void @__device_sstore(i256* %54808, i256* %54809)
  %54810 = call i32 @__hashword(i256* %54808)
  store i32 %54810, i32* %59, align 4, !nosanitize !3
  %54811 = load i256, i256* %0, align 4
  %54812 = load i256, i256* %1, align 4
  %54813 = trunc i256 64 to i64
  %54814 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %54813, i256* %54814)
  %54815 = load i256, i256* %54814, align 4
  %54816 = and i256 1461501637330902918203684832716283019655932542975, %54811
  %54817 = and i256 1461501637330902918203684832716283019655932542975, %54816
  %54818 = trunc i256 %54815 to i64
  %54819 = alloca i256, align 8
  store i256 %54817, i256* %54819, align 4
  %54820 = bitcast i256* %54819 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54818, i8* %54820, i64 32)
  %54821 = add i256 32, %54815, !pc !796, !intsan !10
  %54822 = trunc i256 %54821 to i64
  %54823 = alloca i256, align 8
  store i256 %54812, i256* %54823, align 4
  %54824 = bitcast i256* %54823 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %54822, i8* %54824, i64 32)
  %54825 = add i256 32, %54821, !pc !797, !intsan !10
  %54826 = trunc i256 64 to i64
  %54827 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %54826, i256* %54827)
  %54828 = load i256, i256* %54827, align 4
  %54829 = sub i256 %54825, %54828, !pc !798, !intsan !8
  %54830 = trunc i256 -41322251175725153435834052271036829262563037177322314355431578395316373192476 to i64
  call void @addBugSet(i64 %54830)
  %54831 = trunc i256 %54379 to i64
  store i64 %54831, i64* %JMP_TARGET_PTR, align 4
  br label %JumpTable, !EVMBB !4

.17834:                                           ; preds = %53369, %49406, %43967, %36479, %JumpTable
  %54832 = load i64, i64* %remaing_gas, align 4
  %54833 = icmp ugt i64 216, %54832
  br i1 %54833, label %Abort, label %54834

54834:                                            ; preds = %.17834
  %54835 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54836 = xor i32 %54835, 3491
  %54837 = urem i32 %54836, 4096
  %54838 = getelementptr i8, i8 addrspace(1)* %4, i32 %54837
  %54839 = load i8, i8 addrspace(1)* %54838, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54838, align 1, !nosanitize !3
  store i32 1745, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54840 = sub i64 %54832, 216
  store i64 %54840, i64* %remaing_gas, align 4
  %54841 = trunc i256 18991 to i64
  %54842 = load i64, i64* %STACK_DEP_PTR, align 4
  %54843 = add i64 %54842, 1
  store i64 %54843, i64* %STACK_DEP_PTR, align 4
  %54844 = load i64, i64* %STACK_DEP_PTR, align 4
  %54845 = getelementptr i256, i256* %STACK, i64 %54844
  store i256 0, i256* %54845, align 4
  %54846 = load i64, i64* %STACK_DEP_PTR, align 4
  %54847 = add i64 %54846, 1
  store i64 %54847, i64* %STACK_DEP_PTR, align 4
  %54848 = load i64, i64* %STACK_DEP_PTR, align 4
  %54849 = getelementptr i256, i256* %STACK, i64 %54848
  store i256 0, i256* %54849, align 4
  %54850 = load i64, i64* %STACK_DEP_PTR, align 4
  %54851 = add i64 %54850, 1
  store i64 %54851, i64* %STACK_DEP_PTR, align 4
  %54852 = load i64, i64* %STACK_DEP_PTR, align 4
  %54853 = getelementptr i256, i256* %STACK, i64 %54852
  store i256 17866, i256* %54853, align 4
  %54854 = load i64, i64* %STACK_DEP_PTR, align 4
  %54855 = add i64 %54854, 1
  store i64 %54855, i64* %STACK_DEP_PTR, align 4
  %54856 = load i64, i64* %STACK_DEP_PTR, align 4
  %54857 = getelementptr i256, i256* %STACK, i64 %54856
  store i256 166879805866326139730078904348178637806357513965, i256* %54857, align 4
  br label %.18991, !EVMBB !4

.17866:                                           ; preds = %JumpTable
  %54858 = load i64, i64* %remaing_gas, align 4
  %54859 = icmp ugt i64 144, %54858
  br i1 %54859, label %Abort, label %54860

54860:                                            ; preds = %.17866
  %54861 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54862 = xor i32 %54861, 401
  %54863 = urem i32 %54862, 4096
  %54864 = getelementptr i8, i8 addrspace(1)* %4, i32 %54863
  %54865 = load i8, i8 addrspace(1)* %54864, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54864, align 1, !nosanitize !3
  store i32 200, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54866 = sub i64 %54858, 144
  store i64 %54866, i64* %remaing_gas, align 4
  %54867 = load i64, i64* %STACK_DEP_PTR, align 4
  %54868 = getelementptr i256, i256* %STACK, i64 %54867
  %54869 = load i256, i256* %54868, align 4
  %54870 = load i64, i64* %STACK_DEP_PTR, align 4
  %54871 = sub i64 %54870, 1
  store i64 %54871, i64* %STACK_DEP_PTR, align 4
  %54872 = load i64, i64* %STACK_DEP_PTR, align 4
  %54873 = getelementptr i256, i256* %STACK, i64 %54872
  %54874 = load i256, i256* %54873, align 4
  %54875 = load i64, i64* %STACK_DEP_PTR, align 4
  %54876 = sub i64 %54875, 1
  store i64 %54876, i64* %STACK_DEP_PTR, align 4
  %54877 = icmp ugt i256 %54869, %54874
  %54878 = icmp eq i1 %54877, false
  %54879 = trunc i256 17965 to i64
  %jump.check83 = icmp ne i1 %54878, false
  br i1 %jump.check83, label %.17965, label %.17873, !EVMBB !4

.17873:                                           ; preds = %54860
  %54880 = load i64, i64* %remaing_gas, align 4
  %54881 = icmp ugt i64 248, %54880
  br i1 %54881, label %Abort, label %54882

54882:                                            ; preds = %.17873
  %54883 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54884 = xor i32 %54883, 2502
  %54885 = urem i32 %54884, 4096
  %54886 = getelementptr i8, i8 addrspace(1)* %4, i32 %54885
  %54887 = load i8, i8 addrspace(1)* %54886, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %54886, align 1, !nosanitize !3
  store i32 1251, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %54888 = sub i64 %54880, 248
  store i64 %54888, i64* %remaing_gas, align 4
  %54889 = load i64, i64* %STACK_DEP_PTR, align 4
  %54890 = getelementptr i256, i256* %STACK, i64 %54889
  %54891 = load i256, i256* %54890, align 4
  %54892 = load i64, i64* %STACK_DEP_PTR, align 4
  %54893 = sub i64 %54892, 1
  store i64 %54893, i64* %STACK_DEP_PTR, align 4
  %54894 = alloca i256, align 8
  store i256 0, i256* %54894, align 4
  %54895 = alloca i256, align 8
  call void @__device_sload(i256* %54894, i256* %54895)
  %54896 = call i32 @__hashword(i256* %54894)
  %54897 = load i32, i32* %5, align 4
  %54898 = icmp eq i32 %54896, %54897
  %54899 = or i1 false, %54898
  %54900 = load i32, i32* %6, align 4
  %54901 = icmp eq i32 %54896, %54900
  %54902 = or i1 %54899, %54901
  %54903 = load i32, i32* %7, align 4
  %54904 = icmp eq i32 %54896, %54903
  %54905 = or i1 %54902, %54904
  %54906 = load i32, i32* %8, align 4
  %54907 = icmp eq i32 %54896, %54906
  %54908 = or i1 %54905, %54907
  %54909 = load i32, i32* %9, align 4
  %54910 = icmp eq i32 %54896, %54909
  %54911 = or i1 %54908, %54910
  %54912 = load i32, i32* %10, align 4
  %54913 = icmp eq i32 %54896, %54912
  %54914 = or i1 %54911, %54913
  %54915 = load i32, i32* %11, align 4
  %54916 = icmp eq i32 %54896, %54915
  %54917 = or i1 %54914, %54916
  %54918 = load i32, i32* %12, align 4
  %54919 = icmp eq i32 %54896, %54918
  %54920 = or i1 %54917, %54919
  %54921 = load i32, i32* %13, align 4
  %54922 = icmp eq i32 %54896, %54921
  %54923 = or i1 %54920, %54922
  %54924 = load i32, i32* %14, align 4
  %54925 = icmp eq i32 %54896, %54924
  %54926 = or i1 %54923, %54925
  %54927 = load i32, i32* %15, align 4
  %54928 = icmp eq i32 %54896, %54927
  %54929 = or i1 %54926, %54928
  %54930 = load i32, i32* %16, align 4
  %54931 = icmp eq i32 %54896, %54930
  %54932 = or i1 %54929, %54931
  %54933 = load i32, i32* %17, align 4
  %54934 = icmp eq i32 %54896, %54933
  %54935 = or i1 %54932, %54934
  %54936 = load i32, i32* %18, align 4
  %54937 = icmp eq i32 %54896, %54936
  %54938 = or i1 %54935, %54937
  %54939 = load i32, i32* %19, align 4
  %54940 = icmp eq i32 %54896, %54939
  %54941 = or i1 %54938, %54940
  %54942 = load i32, i32* %20, align 4
  %54943 = icmp eq i32 %54896, %54942
  %54944 = or i1 %54941, %54943
  %54945 = load i32, i32* %21, align 4
  %54946 = icmp eq i32 %54896, %54945
  %54947 = or i1 %54944, %54946
  %54948 = load i32, i32* %22, align 4
  %54949 = icmp eq i32 %54896, %54948
  %54950 = or i1 %54947, %54949
  %54951 = load i32, i32* %23, align 4
  %54952 = icmp eq i32 %54896, %54951
  %54953 = or i1 %54950, %54952
  %54954 = load i32, i32* %24, align 4
  %54955 = icmp eq i32 %54896, %54954
  %54956 = or i1 %54953, %54955
  %54957 = load i32, i32* %25, align 4
  %54958 = icmp eq i32 %54896, %54957
  %54959 = or i1 %54956, %54958
  %54960 = load i32, i32* %26, align 4
  %54961 = icmp eq i32 %54896, %54960
  %54962 = or i1 %54959, %54961
  %54963 = load i32, i32* %27, align 4
  %54964 = icmp eq i32 %54896, %54963
  %54965 = or i1 %54962, %54964
  %54966 = load i32, i32* %28, align 4
  %54967 = icmp eq i32 %54896, %54966
  %54968 = or i1 %54965, %54967
  %54969 = load i32, i32* %29, align 4
  %54970 = icmp eq i32 %54896, %54969
  %54971 = or i1 %54968, %54970
  %54972 = load i32, i32* %30, align 4
  %54973 = icmp eq i32 %54896, %54972
  %54974 = or i1 %54971, %54973
  %54975 = load i32, i32* %31, align 4
  %54976 = icmp eq i32 %54896, %54975
  %54977 = or i1 %54974, %54976
  %54978 = load i32, i32* %32, align 4
  %54979 = icmp eq i32 %54896, %54978
  %54980 = or i1 %54977, %54979
  %54981 = load i32, i32* %33, align 4
  %54982 = icmp eq i32 %54896, %54981
  %54983 = or i1 %54980, %54982
  %54984 = load i32, i32* %34, align 4
  %54985 = icmp eq i32 %54896, %54984
  %54986 = or i1 %54983, %54985
  %54987 = load i32, i32* %35, align 4
  %54988 = icmp eq i32 %54896, %54987
  %54989 = or i1 %54986, %54988
  %54990 = load i32, i32* %36, align 4
  %54991 = icmp eq i32 %54896, %54990
  %54992 = or i1 %54989, %54991
  %54993 = load i32, i32* %37, align 4
  %54994 = icmp eq i32 %54896, %54993
  %54995 = or i1 %54992, %54994
  %54996 = load i32, i32* %38, align 4
  %54997 = icmp eq i32 %54896, %54996
  %54998 = or i1 %54995, %54997
  %54999 = load i32, i32* %39, align 4
  %55000 = icmp eq i32 %54896, %54999
  %55001 = or i1 %54998, %55000
  %55002 = load i32, i32* %40, align 4
  %55003 = icmp eq i32 %54896, %55002
  %55004 = or i1 %55001, %55003
  %55005 = load i32, i32* %41, align 4
  %55006 = icmp eq i32 %54896, %55005
  %55007 = or i1 %55004, %55006
  %55008 = load i32, i32* %42, align 4
  %55009 = icmp eq i32 %54896, %55008
  %55010 = or i1 %55007, %55009
  %55011 = load i32, i32* %43, align 4
  %55012 = icmp eq i32 %54896, %55011
  %55013 = or i1 %55010, %55012
  %55014 = load i32, i32* %44, align 4
  %55015 = icmp eq i32 %54896, %55014
  %55016 = or i1 %55013, %55015
  %55017 = load i32, i32* %45, align 4
  %55018 = icmp eq i32 %54896, %55017
  %55019 = or i1 %55016, %55018
  %55020 = load i32, i32* %46, align 4
  %55021 = icmp eq i32 %54896, %55020
  %55022 = or i1 %55019, %55021
  %55023 = load i32, i32* %47, align 4
  %55024 = icmp eq i32 %54896, %55023
  %55025 = or i1 %55022, %55024
  %55026 = load i32, i32* %48, align 4
  %55027 = icmp eq i32 %54896, %55026
  %55028 = or i1 %55025, %55027
  %55029 = load i32, i32* %49, align 4
  %55030 = icmp eq i32 %54896, %55029
  %55031 = or i1 %55028, %55030
  %55032 = load i32, i32* %50, align 4
  %55033 = icmp eq i32 %54896, %55032
  %55034 = or i1 %55031, %55033
  %55035 = load i32, i32* %51, align 4
  %55036 = icmp eq i32 %54896, %55035
  %55037 = or i1 %55034, %55036
  %55038 = load i32, i32* %52, align 4
  %55039 = icmp eq i32 %54896, %55038
  %55040 = or i1 %55037, %55039
  %55041 = load i32, i32* %53, align 4
  %55042 = icmp eq i32 %54896, %55041
  %55043 = or i1 %55040, %55042
  %55044 = load i32, i32* %54, align 4
  %55045 = icmp eq i32 %54896, %55044
  %55046 = or i1 %55043, %55045
  %55047 = load i32, i32* %55, align 4
  %55048 = icmp eq i32 %54896, %55047
  %55049 = or i1 %55046, %55048
  %55050 = load i32, i32* %56, align 4
  %55051 = icmp eq i32 %54896, %55050
  %55052 = or i1 %55049, %55051
  %55053 = load i32, i32* %57, align 4
  %55054 = icmp eq i32 %54896, %55053
  %55055 = or i1 %55052, %55054
  %55056 = load i32, i32* %58, align 4
  %55057 = icmp eq i32 %54896, %55056
  %55058 = or i1 %55055, %55057
  %55059 = load i32, i32* %59, align 4
  %55060 = icmp eq i32 %54896, %55059
  %55061 = or i1 %55058, %55060
  %55062 = load i32, i32* %60, align 4
  %55063 = icmp eq i32 %54896, %55062
  %55064 = or i1 %55061, %55063
  %55065 = load i32, i32* %61, align 4
  %55066 = icmp eq i32 %54896, %55065
  %55067 = or i1 %55064, %55066
  %55068 = load i32, i32* %62, align 4
  %55069 = icmp eq i32 %54896, %55068
  %55070 = or i1 %55067, %55069
  %55071 = getelementptr i8, i8 addrspace(1)* %4, i32 202
  %55072 = zext i1 %55070 to i8
  store i8 %55072, i8 addrspace(1)* %55071, align 1, !nosanitize !3
  %55073 = load i256, i256* %54895, align 4
  %55074 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !799, !intsan !45
  %55075 = xor i256 %55074, -1
  %55076 = and i256 %55075, %55073
  %55077 = and i256 1461501637330902918203684832716283019655932542975, 166879805866326139730078904348178637806357513965
  %55078 = mul i256 %55077, 1, !pc !800, !intsan !45
  %55079 = or i256 %55078, %55076
  %55080 = alloca i256, align 8
  store i256 0, i256* %55080, align 4
  %55081 = alloca i256, align 8
  store i256 %55079, i256* %55081, align 4
  call void @__device_sstore(i256* %55080, i256* %55081)
  %55082 = call i32 @__hashword(i256* %55080)
  store i32 %55082, i32* %25, align 4, !nosanitize !3
  %55083 = trunc i256 18230 to i64
  %55084 = load i64, i64* %STACK_DEP_PTR, align 4
  %55085 = add i64 %55084, 1
  store i64 %55085, i64* %STACK_DEP_PTR, align 4
  %55086 = load i64, i64* %STACK_DEP_PTR, align 4
  %55087 = getelementptr i256, i256* %STACK, i64 %55086
  store i256 1, i256* %55087, align 4
  br label %.18230, !EVMBB !4

.17965:                                           ; preds = %54860, %JumpTable
  %55088 = load i64, i64* %remaing_gas, align 4
  %55089 = icmp ugt i64 168, %55088
  br i1 %55089, label %Abort, label %55090

55090:                                            ; preds = %.17965
  %55091 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55092 = xor i32 %55091, 3073
  %55093 = urem i32 %55092, 4096
  %55094 = getelementptr i8, i8 addrspace(1)* %4, i32 %55093
  %55095 = load i8, i8 addrspace(1)* %55094, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55094, align 1, !nosanitize !3
  store i32 1536, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55096 = sub i64 %55088, 168
  store i64 %55096, i64* %remaing_gas, align 4
  %55097 = trunc i256 18991 to i64
  %55098 = load i64, i64* %STACK_DEP_PTR, align 4
  %55099 = add i64 %55098, 1
  store i64 %55099, i64* %STACK_DEP_PTR, align 4
  %55100 = load i64, i64* %STACK_DEP_PTR, align 4
  %55101 = getelementptr i256, i256* %STACK, i64 %55100
  store i256 0, i256* %55101, align 4
  %55102 = load i64, i64* %STACK_DEP_PTR, align 4
  %55103 = add i64 %55102, 1
  store i64 %55103, i64* %STACK_DEP_PTR, align 4
  %55104 = load i64, i64* %STACK_DEP_PTR, align 4
  %55105 = getelementptr i256, i256* %STACK, i64 %55104
  store i256 17996, i256* %55105, align 4
  %55106 = load i64, i64* %STACK_DEP_PTR, align 4
  %55107 = add i64 %55106, 1
  store i64 %55107, i64* %STACK_DEP_PTR, align 4
  %55108 = load i64, i64* %STACK_DEP_PTR, align 4
  %55109 = getelementptr i256, i256* %STACK, i64 %55108
  store i256 1097422988916857156046675838961943218895050702321, i256* %55109, align 4
  br label %.18991, !EVMBB !4

.17996:                                           ; preds = %JumpTable
  %55110 = load i64, i64* %remaing_gas, align 4
  %55111 = icmp ugt i64 144, %55110
  br i1 %55111, label %Abort, label %55112

55112:                                            ; preds = %.17996
  %55113 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55114 = xor i32 %55113, 511
  %55115 = urem i32 %55114, 4096
  %55116 = getelementptr i8, i8 addrspace(1)* %4, i32 %55115
  %55117 = load i8, i8 addrspace(1)* %55116, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55116, align 1, !nosanitize !3
  store i32 255, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55118 = sub i64 %55110, 144
  store i64 %55118, i64* %remaing_gas, align 4
  %55119 = load i64, i64* %STACK_DEP_PTR, align 4
  %55120 = getelementptr i256, i256* %STACK, i64 %55119
  %55121 = load i256, i256* %55120, align 4
  %55122 = load i64, i64* %STACK_DEP_PTR, align 4
  %55123 = sub i64 %55122, 1
  store i64 %55123, i64* %STACK_DEP_PTR, align 4
  %55124 = load i64, i64* %STACK_DEP_PTR, align 4
  %55125 = getelementptr i256, i256* %STACK, i64 %55124
  %55126 = load i256, i256* %55125, align 4
  %55127 = load i64, i64* %STACK_DEP_PTR, align 4
  %55128 = sub i64 %55127, 1
  store i64 %55128, i64* %STACK_DEP_PTR, align 4
  %55129 = icmp ugt i256 %55121, %55126
  %55130 = icmp eq i1 %55129, false
  %55131 = trunc i256 18095 to i64
  %jump.check232 = icmp ne i1 %55130, false
  br i1 %jump.check232, label %.18095, label %.18003, !EVMBB !4

.18003:                                           ; preds = %55112
  %55132 = load i64, i64* %remaing_gas, align 4
  %55133 = icmp ugt i64 248, %55132
  br i1 %55133, label %Abort, label %55134

55134:                                            ; preds = %.18003
  %55135 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55136 = xor i32 %55135, 3785
  %55137 = urem i32 %55136, 4096
  %55138 = getelementptr i8, i8 addrspace(1)* %4, i32 %55137
  %55139 = load i8, i8 addrspace(1)* %55138, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55138, align 1, !nosanitize !3
  store i32 1892, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55140 = sub i64 %55132, 248
  store i64 %55140, i64* %remaing_gas, align 4
  %55141 = load i64, i64* %STACK_DEP_PTR, align 4
  %55142 = getelementptr i256, i256* %STACK, i64 %55141
  %55143 = load i256, i256* %55142, align 4
  %55144 = load i64, i64* %STACK_DEP_PTR, align 4
  %55145 = sub i64 %55144, 1
  store i64 %55145, i64* %STACK_DEP_PTR, align 4
  %55146 = alloca i256, align 8
  store i256 0, i256* %55146, align 4
  %55147 = alloca i256, align 8
  call void @__device_sload(i256* %55146, i256* %55147)
  %55148 = call i32 @__hashword(i256* %55146)
  %55149 = load i32, i32* %5, align 4
  %55150 = icmp eq i32 %55148, %55149
  %55151 = or i1 false, %55150
  %55152 = load i32, i32* %6, align 4
  %55153 = icmp eq i32 %55148, %55152
  %55154 = or i1 %55151, %55153
  %55155 = load i32, i32* %7, align 4
  %55156 = icmp eq i32 %55148, %55155
  %55157 = or i1 %55154, %55156
  %55158 = load i32, i32* %8, align 4
  %55159 = icmp eq i32 %55148, %55158
  %55160 = or i1 %55157, %55159
  %55161 = load i32, i32* %9, align 4
  %55162 = icmp eq i32 %55148, %55161
  %55163 = or i1 %55160, %55162
  %55164 = load i32, i32* %10, align 4
  %55165 = icmp eq i32 %55148, %55164
  %55166 = or i1 %55163, %55165
  %55167 = load i32, i32* %11, align 4
  %55168 = icmp eq i32 %55148, %55167
  %55169 = or i1 %55166, %55168
  %55170 = load i32, i32* %12, align 4
  %55171 = icmp eq i32 %55148, %55170
  %55172 = or i1 %55169, %55171
  %55173 = load i32, i32* %13, align 4
  %55174 = icmp eq i32 %55148, %55173
  %55175 = or i1 %55172, %55174
  %55176 = load i32, i32* %14, align 4
  %55177 = icmp eq i32 %55148, %55176
  %55178 = or i1 %55175, %55177
  %55179 = load i32, i32* %15, align 4
  %55180 = icmp eq i32 %55148, %55179
  %55181 = or i1 %55178, %55180
  %55182 = load i32, i32* %16, align 4
  %55183 = icmp eq i32 %55148, %55182
  %55184 = or i1 %55181, %55183
  %55185 = load i32, i32* %17, align 4
  %55186 = icmp eq i32 %55148, %55185
  %55187 = or i1 %55184, %55186
  %55188 = load i32, i32* %18, align 4
  %55189 = icmp eq i32 %55148, %55188
  %55190 = or i1 %55187, %55189
  %55191 = load i32, i32* %19, align 4
  %55192 = icmp eq i32 %55148, %55191
  %55193 = or i1 %55190, %55192
  %55194 = load i32, i32* %20, align 4
  %55195 = icmp eq i32 %55148, %55194
  %55196 = or i1 %55193, %55195
  %55197 = load i32, i32* %21, align 4
  %55198 = icmp eq i32 %55148, %55197
  %55199 = or i1 %55196, %55198
  %55200 = load i32, i32* %22, align 4
  %55201 = icmp eq i32 %55148, %55200
  %55202 = or i1 %55199, %55201
  %55203 = load i32, i32* %23, align 4
  %55204 = icmp eq i32 %55148, %55203
  %55205 = or i1 %55202, %55204
  %55206 = load i32, i32* %24, align 4
  %55207 = icmp eq i32 %55148, %55206
  %55208 = or i1 %55205, %55207
  %55209 = load i32, i32* %25, align 4
  %55210 = icmp eq i32 %55148, %55209
  %55211 = or i1 %55208, %55210
  %55212 = load i32, i32* %26, align 4
  %55213 = icmp eq i32 %55148, %55212
  %55214 = or i1 %55211, %55213
  %55215 = load i32, i32* %27, align 4
  %55216 = icmp eq i32 %55148, %55215
  %55217 = or i1 %55214, %55216
  %55218 = load i32, i32* %28, align 4
  %55219 = icmp eq i32 %55148, %55218
  %55220 = or i1 %55217, %55219
  %55221 = load i32, i32* %29, align 4
  %55222 = icmp eq i32 %55148, %55221
  %55223 = or i1 %55220, %55222
  %55224 = load i32, i32* %30, align 4
  %55225 = icmp eq i32 %55148, %55224
  %55226 = or i1 %55223, %55225
  %55227 = load i32, i32* %31, align 4
  %55228 = icmp eq i32 %55148, %55227
  %55229 = or i1 %55226, %55228
  %55230 = load i32, i32* %32, align 4
  %55231 = icmp eq i32 %55148, %55230
  %55232 = or i1 %55229, %55231
  %55233 = load i32, i32* %33, align 4
  %55234 = icmp eq i32 %55148, %55233
  %55235 = or i1 %55232, %55234
  %55236 = load i32, i32* %34, align 4
  %55237 = icmp eq i32 %55148, %55236
  %55238 = or i1 %55235, %55237
  %55239 = load i32, i32* %35, align 4
  %55240 = icmp eq i32 %55148, %55239
  %55241 = or i1 %55238, %55240
  %55242 = load i32, i32* %36, align 4
  %55243 = icmp eq i32 %55148, %55242
  %55244 = or i1 %55241, %55243
  %55245 = load i32, i32* %37, align 4
  %55246 = icmp eq i32 %55148, %55245
  %55247 = or i1 %55244, %55246
  %55248 = load i32, i32* %38, align 4
  %55249 = icmp eq i32 %55148, %55248
  %55250 = or i1 %55247, %55249
  %55251 = load i32, i32* %39, align 4
  %55252 = icmp eq i32 %55148, %55251
  %55253 = or i1 %55250, %55252
  %55254 = load i32, i32* %40, align 4
  %55255 = icmp eq i32 %55148, %55254
  %55256 = or i1 %55253, %55255
  %55257 = load i32, i32* %41, align 4
  %55258 = icmp eq i32 %55148, %55257
  %55259 = or i1 %55256, %55258
  %55260 = load i32, i32* %42, align 4
  %55261 = icmp eq i32 %55148, %55260
  %55262 = or i1 %55259, %55261
  %55263 = load i32, i32* %43, align 4
  %55264 = icmp eq i32 %55148, %55263
  %55265 = or i1 %55262, %55264
  %55266 = load i32, i32* %44, align 4
  %55267 = icmp eq i32 %55148, %55266
  %55268 = or i1 %55265, %55267
  %55269 = load i32, i32* %45, align 4
  %55270 = icmp eq i32 %55148, %55269
  %55271 = or i1 %55268, %55270
  %55272 = load i32, i32* %46, align 4
  %55273 = icmp eq i32 %55148, %55272
  %55274 = or i1 %55271, %55273
  %55275 = load i32, i32* %47, align 4
  %55276 = icmp eq i32 %55148, %55275
  %55277 = or i1 %55274, %55276
  %55278 = load i32, i32* %48, align 4
  %55279 = icmp eq i32 %55148, %55278
  %55280 = or i1 %55277, %55279
  %55281 = load i32, i32* %49, align 4
  %55282 = icmp eq i32 %55148, %55281
  %55283 = or i1 %55280, %55282
  %55284 = load i32, i32* %50, align 4
  %55285 = icmp eq i32 %55148, %55284
  %55286 = or i1 %55283, %55285
  %55287 = load i32, i32* %51, align 4
  %55288 = icmp eq i32 %55148, %55287
  %55289 = or i1 %55286, %55288
  %55290 = load i32, i32* %52, align 4
  %55291 = icmp eq i32 %55148, %55290
  %55292 = or i1 %55289, %55291
  %55293 = load i32, i32* %53, align 4
  %55294 = icmp eq i32 %55148, %55293
  %55295 = or i1 %55292, %55294
  %55296 = load i32, i32* %54, align 4
  %55297 = icmp eq i32 %55148, %55296
  %55298 = or i1 %55295, %55297
  %55299 = load i32, i32* %55, align 4
  %55300 = icmp eq i32 %55148, %55299
  %55301 = or i1 %55298, %55300
  %55302 = load i32, i32* %56, align 4
  %55303 = icmp eq i32 %55148, %55302
  %55304 = or i1 %55301, %55303
  %55305 = load i32, i32* %57, align 4
  %55306 = icmp eq i32 %55148, %55305
  %55307 = or i1 %55304, %55306
  %55308 = load i32, i32* %58, align 4
  %55309 = icmp eq i32 %55148, %55308
  %55310 = or i1 %55307, %55309
  %55311 = load i32, i32* %59, align 4
  %55312 = icmp eq i32 %55148, %55311
  %55313 = or i1 %55310, %55312
  %55314 = load i32, i32* %60, align 4
  %55315 = icmp eq i32 %55148, %55314
  %55316 = or i1 %55313, %55315
  %55317 = load i32, i32* %61, align 4
  %55318 = icmp eq i32 %55148, %55317
  %55319 = or i1 %55316, %55318
  %55320 = load i32, i32* %62, align 4
  %55321 = icmp eq i32 %55148, %55320
  %55322 = or i1 %55319, %55321
  %55323 = getelementptr i8, i8 addrspace(1)* %4, i32 203
  %55324 = zext i1 %55322 to i8
  store i8 %55324, i8 addrspace(1)* %55323, align 1, !nosanitize !3
  %55325 = load i256, i256* %55147, align 4
  %55326 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !801, !intsan !45
  %55327 = xor i256 %55326, -1
  %55328 = and i256 %55327, %55325
  %55329 = and i256 1461501637330902918203684832716283019655932542975, 1097422988916857156046675838961943218895050702321
  %55330 = mul i256 %55329, 1, !pc !802, !intsan !45
  %55331 = or i256 %55330, %55328
  %55332 = alloca i256, align 8
  store i256 0, i256* %55332, align 4
  %55333 = alloca i256, align 8
  store i256 %55331, i256* %55333, align 4
  call void @__device_sstore(i256* %55332, i256* %55333)
  %55334 = call i32 @__hashword(i256* %55332)
  store i32 %55334, i32* %60, align 4, !nosanitize !3
  %55335 = trunc i256 18230 to i64
  %55336 = load i64, i64* %STACK_DEP_PTR, align 4
  %55337 = add i64 %55336, 1
  store i64 %55337, i64* %STACK_DEP_PTR, align 4
  %55338 = load i64, i64* %STACK_DEP_PTR, align 4
  %55339 = getelementptr i256, i256* %STACK, i64 %55338
  store i256 1, i256* %55339, align 4
  br label %.18230, !EVMBB !4

.18095:                                           ; preds = %55112, %JumpTable
  %55340 = load i64, i64* %remaing_gas, align 4
  %55341 = icmp ugt i64 168, %55340
  br i1 %55341, label %Abort, label %55342

55342:                                            ; preds = %.18095
  %55343 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55344 = xor i32 %55343, 2602
  %55345 = urem i32 %55344, 4096
  %55346 = getelementptr i8, i8 addrspace(1)* %4, i32 %55345
  %55347 = load i8, i8 addrspace(1)* %55346, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55346, align 1, !nosanitize !3
  store i32 1301, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55348 = sub i64 %55340, 168
  store i64 %55348, i64* %remaing_gas, align 4
  %55349 = trunc i256 18991 to i64
  %55350 = load i64, i64* %STACK_DEP_PTR, align 4
  %55351 = add i64 %55350, 1
  store i64 %55351, i64* %STACK_DEP_PTR, align 4
  %55352 = load i64, i64* %STACK_DEP_PTR, align 4
  %55353 = getelementptr i256, i256* %STACK, i64 %55352
  store i256 0, i256* %55353, align 4
  %55354 = load i64, i64* %STACK_DEP_PTR, align 4
  %55355 = add i64 %55354, 1
  store i64 %55355, i64* %STACK_DEP_PTR, align 4
  %55356 = load i64, i64* %STACK_DEP_PTR, align 4
  %55357 = getelementptr i256, i256* %STACK, i64 %55356
  store i256 18126, i256* %55357, align 4
  %55358 = load i64, i64* %STACK_DEP_PTR, align 4
  %55359 = add i64 %55358, 1
  store i64 %55359, i64* %STACK_DEP_PTR, align 4
  %55360 = load i64, i64* %STACK_DEP_PTR, align 4
  %55361 = getelementptr i256, i256* %STACK, i64 %55360
  store i256 467773401235755137097289008257078260350600581034, i256* %55361, align 4
  br label %.18991, !EVMBB !4

.18126:                                           ; preds = %JumpTable
  %55362 = load i64, i64* %remaing_gas, align 4
  %55363 = icmp ugt i64 144, %55362
  br i1 %55363, label %Abort, label %55364

55364:                                            ; preds = %.18126
  %55365 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55366 = xor i32 %55365, 1241
  %55367 = urem i32 %55366, 4096
  %55368 = getelementptr i8, i8 addrspace(1)* %4, i32 %55367
  %55369 = load i8, i8 addrspace(1)* %55368, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55368, align 1, !nosanitize !3
  store i32 620, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55370 = sub i64 %55362, 144
  store i64 %55370, i64* %remaing_gas, align 4
  %55371 = load i64, i64* %STACK_DEP_PTR, align 4
  %55372 = getelementptr i256, i256* %STACK, i64 %55371
  %55373 = load i256, i256* %55372, align 4
  %55374 = load i64, i64* %STACK_DEP_PTR, align 4
  %55375 = sub i64 %55374, 1
  store i64 %55375, i64* %STACK_DEP_PTR, align 4
  %55376 = load i64, i64* %STACK_DEP_PTR, align 4
  %55377 = getelementptr i256, i256* %STACK, i64 %55376
  %55378 = load i256, i256* %55377, align 4
  %55379 = load i64, i64* %STACK_DEP_PTR, align 4
  %55380 = sub i64 %55379, 1
  store i64 %55380, i64* %STACK_DEP_PTR, align 4
  %55381 = icmp ugt i256 %55373, %55378
  %55382 = icmp eq i1 %55381, false
  %55383 = trunc i256 18225 to i64
  %jump.check233 = icmp ne i1 %55382, false
  br i1 %jump.check233, label %.18225, label %.18133, !EVMBB !4

.18133:                                           ; preds = %55364
  %55384 = load i64, i64* %remaing_gas, align 4
  %55385 = icmp ugt i64 248, %55384
  br i1 %55385, label %Abort, label %55386

55386:                                            ; preds = %.18133
  %55387 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55388 = xor i32 %55387, 3605
  %55389 = urem i32 %55388, 4096
  %55390 = getelementptr i8, i8 addrspace(1)* %4, i32 %55389
  %55391 = load i8, i8 addrspace(1)* %55390, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55390, align 1, !nosanitize !3
  store i32 1802, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55392 = sub i64 %55384, 248
  store i64 %55392, i64* %remaing_gas, align 4
  %55393 = load i64, i64* %STACK_DEP_PTR, align 4
  %55394 = getelementptr i256, i256* %STACK, i64 %55393
  %55395 = load i256, i256* %55394, align 4
  %55396 = load i64, i64* %STACK_DEP_PTR, align 4
  %55397 = sub i64 %55396, 1
  store i64 %55397, i64* %STACK_DEP_PTR, align 4
  %55398 = alloca i256, align 8
  store i256 0, i256* %55398, align 4
  %55399 = alloca i256, align 8
  call void @__device_sload(i256* %55398, i256* %55399)
  %55400 = call i32 @__hashword(i256* %55398)
  %55401 = load i32, i32* %5, align 4
  %55402 = icmp eq i32 %55400, %55401
  %55403 = or i1 false, %55402
  %55404 = load i32, i32* %6, align 4
  %55405 = icmp eq i32 %55400, %55404
  %55406 = or i1 %55403, %55405
  %55407 = load i32, i32* %7, align 4
  %55408 = icmp eq i32 %55400, %55407
  %55409 = or i1 %55406, %55408
  %55410 = load i32, i32* %8, align 4
  %55411 = icmp eq i32 %55400, %55410
  %55412 = or i1 %55409, %55411
  %55413 = load i32, i32* %9, align 4
  %55414 = icmp eq i32 %55400, %55413
  %55415 = or i1 %55412, %55414
  %55416 = load i32, i32* %10, align 4
  %55417 = icmp eq i32 %55400, %55416
  %55418 = or i1 %55415, %55417
  %55419 = load i32, i32* %11, align 4
  %55420 = icmp eq i32 %55400, %55419
  %55421 = or i1 %55418, %55420
  %55422 = load i32, i32* %12, align 4
  %55423 = icmp eq i32 %55400, %55422
  %55424 = or i1 %55421, %55423
  %55425 = load i32, i32* %13, align 4
  %55426 = icmp eq i32 %55400, %55425
  %55427 = or i1 %55424, %55426
  %55428 = load i32, i32* %14, align 4
  %55429 = icmp eq i32 %55400, %55428
  %55430 = or i1 %55427, %55429
  %55431 = load i32, i32* %15, align 4
  %55432 = icmp eq i32 %55400, %55431
  %55433 = or i1 %55430, %55432
  %55434 = load i32, i32* %16, align 4
  %55435 = icmp eq i32 %55400, %55434
  %55436 = or i1 %55433, %55435
  %55437 = load i32, i32* %17, align 4
  %55438 = icmp eq i32 %55400, %55437
  %55439 = or i1 %55436, %55438
  %55440 = load i32, i32* %18, align 4
  %55441 = icmp eq i32 %55400, %55440
  %55442 = or i1 %55439, %55441
  %55443 = load i32, i32* %19, align 4
  %55444 = icmp eq i32 %55400, %55443
  %55445 = or i1 %55442, %55444
  %55446 = load i32, i32* %20, align 4
  %55447 = icmp eq i32 %55400, %55446
  %55448 = or i1 %55445, %55447
  %55449 = load i32, i32* %21, align 4
  %55450 = icmp eq i32 %55400, %55449
  %55451 = or i1 %55448, %55450
  %55452 = load i32, i32* %22, align 4
  %55453 = icmp eq i32 %55400, %55452
  %55454 = or i1 %55451, %55453
  %55455 = load i32, i32* %23, align 4
  %55456 = icmp eq i32 %55400, %55455
  %55457 = or i1 %55454, %55456
  %55458 = load i32, i32* %24, align 4
  %55459 = icmp eq i32 %55400, %55458
  %55460 = or i1 %55457, %55459
  %55461 = load i32, i32* %25, align 4
  %55462 = icmp eq i32 %55400, %55461
  %55463 = or i1 %55460, %55462
  %55464 = load i32, i32* %26, align 4
  %55465 = icmp eq i32 %55400, %55464
  %55466 = or i1 %55463, %55465
  %55467 = load i32, i32* %27, align 4
  %55468 = icmp eq i32 %55400, %55467
  %55469 = or i1 %55466, %55468
  %55470 = load i32, i32* %28, align 4
  %55471 = icmp eq i32 %55400, %55470
  %55472 = or i1 %55469, %55471
  %55473 = load i32, i32* %29, align 4
  %55474 = icmp eq i32 %55400, %55473
  %55475 = or i1 %55472, %55474
  %55476 = load i32, i32* %30, align 4
  %55477 = icmp eq i32 %55400, %55476
  %55478 = or i1 %55475, %55477
  %55479 = load i32, i32* %31, align 4
  %55480 = icmp eq i32 %55400, %55479
  %55481 = or i1 %55478, %55480
  %55482 = load i32, i32* %32, align 4
  %55483 = icmp eq i32 %55400, %55482
  %55484 = or i1 %55481, %55483
  %55485 = load i32, i32* %33, align 4
  %55486 = icmp eq i32 %55400, %55485
  %55487 = or i1 %55484, %55486
  %55488 = load i32, i32* %34, align 4
  %55489 = icmp eq i32 %55400, %55488
  %55490 = or i1 %55487, %55489
  %55491 = load i32, i32* %35, align 4
  %55492 = icmp eq i32 %55400, %55491
  %55493 = or i1 %55490, %55492
  %55494 = load i32, i32* %36, align 4
  %55495 = icmp eq i32 %55400, %55494
  %55496 = or i1 %55493, %55495
  %55497 = load i32, i32* %37, align 4
  %55498 = icmp eq i32 %55400, %55497
  %55499 = or i1 %55496, %55498
  %55500 = load i32, i32* %38, align 4
  %55501 = icmp eq i32 %55400, %55500
  %55502 = or i1 %55499, %55501
  %55503 = load i32, i32* %39, align 4
  %55504 = icmp eq i32 %55400, %55503
  %55505 = or i1 %55502, %55504
  %55506 = load i32, i32* %40, align 4
  %55507 = icmp eq i32 %55400, %55506
  %55508 = or i1 %55505, %55507
  %55509 = load i32, i32* %41, align 4
  %55510 = icmp eq i32 %55400, %55509
  %55511 = or i1 %55508, %55510
  %55512 = load i32, i32* %42, align 4
  %55513 = icmp eq i32 %55400, %55512
  %55514 = or i1 %55511, %55513
  %55515 = load i32, i32* %43, align 4
  %55516 = icmp eq i32 %55400, %55515
  %55517 = or i1 %55514, %55516
  %55518 = load i32, i32* %44, align 4
  %55519 = icmp eq i32 %55400, %55518
  %55520 = or i1 %55517, %55519
  %55521 = load i32, i32* %45, align 4
  %55522 = icmp eq i32 %55400, %55521
  %55523 = or i1 %55520, %55522
  %55524 = load i32, i32* %46, align 4
  %55525 = icmp eq i32 %55400, %55524
  %55526 = or i1 %55523, %55525
  %55527 = load i32, i32* %47, align 4
  %55528 = icmp eq i32 %55400, %55527
  %55529 = or i1 %55526, %55528
  %55530 = load i32, i32* %48, align 4
  %55531 = icmp eq i32 %55400, %55530
  %55532 = or i1 %55529, %55531
  %55533 = load i32, i32* %49, align 4
  %55534 = icmp eq i32 %55400, %55533
  %55535 = or i1 %55532, %55534
  %55536 = load i32, i32* %50, align 4
  %55537 = icmp eq i32 %55400, %55536
  %55538 = or i1 %55535, %55537
  %55539 = load i32, i32* %51, align 4
  %55540 = icmp eq i32 %55400, %55539
  %55541 = or i1 %55538, %55540
  %55542 = load i32, i32* %52, align 4
  %55543 = icmp eq i32 %55400, %55542
  %55544 = or i1 %55541, %55543
  %55545 = load i32, i32* %53, align 4
  %55546 = icmp eq i32 %55400, %55545
  %55547 = or i1 %55544, %55546
  %55548 = load i32, i32* %54, align 4
  %55549 = icmp eq i32 %55400, %55548
  %55550 = or i1 %55547, %55549
  %55551 = load i32, i32* %55, align 4
  %55552 = icmp eq i32 %55400, %55551
  %55553 = or i1 %55550, %55552
  %55554 = load i32, i32* %56, align 4
  %55555 = icmp eq i32 %55400, %55554
  %55556 = or i1 %55553, %55555
  %55557 = load i32, i32* %57, align 4
  %55558 = icmp eq i32 %55400, %55557
  %55559 = or i1 %55556, %55558
  %55560 = load i32, i32* %58, align 4
  %55561 = icmp eq i32 %55400, %55560
  %55562 = or i1 %55559, %55561
  %55563 = load i32, i32* %59, align 4
  %55564 = icmp eq i32 %55400, %55563
  %55565 = or i1 %55562, %55564
  %55566 = load i32, i32* %60, align 4
  %55567 = icmp eq i32 %55400, %55566
  %55568 = or i1 %55565, %55567
  %55569 = load i32, i32* %61, align 4
  %55570 = icmp eq i32 %55400, %55569
  %55571 = or i1 %55568, %55570
  %55572 = load i32, i32* %62, align 4
  %55573 = icmp eq i32 %55400, %55572
  %55574 = or i1 %55571, %55573
  %55575 = getelementptr i8, i8 addrspace(1)* %4, i32 204
  %55576 = zext i1 %55574 to i8
  store i8 %55576, i8 addrspace(1)* %55575, align 1, !nosanitize !3
  %55577 = load i256, i256* %55399, align 4
  %55578 = mul i256 1461501637330902918203684832716283019655932542975, 1, !pc !803, !intsan !45
  %55579 = xor i256 %55578, -1
  %55580 = and i256 %55579, %55577
  %55581 = and i256 1461501637330902918203684832716283019655932542975, 467773401235755137097289008257078260350600581034
  %55582 = mul i256 %55581, 1, !pc !804, !intsan !45
  %55583 = or i256 %55582, %55580
  %55584 = alloca i256, align 8
  store i256 0, i256* %55584, align 4
  %55585 = alloca i256, align 8
  store i256 %55583, i256* %55585, align 4
  call void @__device_sstore(i256* %55584, i256* %55585)
  %55586 = call i32 @__hashword(i256* %55584)
  store i32 %55586, i32* %61, align 4, !nosanitize !3
  %55587 = trunc i256 18230 to i64
  %55588 = load i64, i64* %STACK_DEP_PTR, align 4
  %55589 = add i64 %55588, 1
  store i64 %55589, i64* %STACK_DEP_PTR, align 4
  %55590 = load i64, i64* %STACK_DEP_PTR, align 4
  %55591 = getelementptr i256, i256* %STACK, i64 %55590
  store i256 1, i256* %55591, align 4
  br label %.18230, !EVMBB !4

.18225:                                           ; preds = %55364, %JumpTable
  %55592 = load i64, i64* %STACK_DEP_PTR, align 4
  %55593 = getelementptr i256, i256* %STACK, i64 %55592
  %55594 = load i256, i256* %55593, align 4
  %55595 = load i64, i64* %STACK_DEP_PTR, align 4
  %55596 = sub i64 %55595, 1
  store i64 %55596, i64* %STACK_DEP_PTR, align 4
  %55597 = load i64, i64* %STACK_DEP_PTR, align 4
  %55598 = add i64 %55597, 1
  store i64 %55598, i64* %STACK_DEP_PTR, align 4
  %55599 = load i64, i64* %STACK_DEP_PTR, align 4
  %55600 = getelementptr i256, i256* %STACK, i64 %55599
  store i256 0, i256* %55600, align 4
  br label %.18230

.18230:                                           ; preds = %.18225, %55386, %55134, %54882, %JumpTable
  %55601 = load i64, i64* %remaing_gas, align 4
  %55602 = icmp ugt i64 224, %55601
  br i1 %55602, label %Abort, label %55603

55603:                                            ; preds = %.18230
  %55604 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55605 = xor i32 %55604, 2817
  %55606 = urem i32 %55605, 4096
  %55607 = getelementptr i8, i8 addrspace(1)* %4, i32 %55606
  %55608 = load i8, i8 addrspace(1)* %55607, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55607, align 1, !nosanitize !3
  store i32 1408, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55609 = sub i64 %55601, 224
  store i64 %55609, i64* %remaing_gas, align 4
  %55610 = load i64, i64* %STACK_DEP_PTR, align 4
  %55611 = getelementptr i256, i256* %STACK, i64 %55610
  %55612 = load i256, i256* %55611, align 4
  %55613 = load i64, i64* %STACK_DEP_PTR, align 4
  %55614 = sub i64 %55613, 1
  store i64 %55614, i64* %STACK_DEP_PTR, align 4
  %55615 = load i64, i64* %STACK_DEP_PTR, align 4
  %55616 = getelementptr i256, i256* %STACK, i64 %55615
  %55617 = load i256, i256* %55616, align 4
  %55618 = load i64, i64* %STACK_DEP_PTR, align 4
  %55619 = sub i64 %55618, 1
  store i64 %55619, i64* %STACK_DEP_PTR, align 4
  %55620 = load i64, i64* %STACK_DEP_PTR, align 4
  %55621 = getelementptr i256, i256* %STACK, i64 %55620
  %55622 = load i256, i256* %55621, align 4
  %55623 = load i64, i64* %STACK_DEP_PTR, align 4
  %55624 = sub i64 %55623, 1
  store i64 %55624, i64* %STACK_DEP_PTR, align 4
  %55625 = trunc i256 %55622 to i64
  store i64 %55625, i64* %JMP_TARGET_PTR, align 4
  %55626 = load i64, i64* %STACK_DEP_PTR, align 4
  %55627 = add i64 %55626, 1
  store i64 %55627, i64* %STACK_DEP_PTR, align 4
  %55628 = load i64, i64* %STACK_DEP_PTR, align 4
  %55629 = getelementptr i256, i256* %STACK, i64 %55628
  store i256 %55612, i256* %55629, align 4
  br label %JumpTable, !EVMBB !4

.18235:                                           ; preds = %45003, %JumpTable
  %55630 = load i64, i64* %STACK_DEP_PTR, align 4
  %55631 = getelementptr i256, i256* %STACK, i64 %55630
  %55632 = load i256, i256* %55631, align 4
  %55633 = load i64, i64* %STACK_DEP_PTR, align 4
  %55634 = sub i64 %55633, 1
  store i64 %55634, i64* %STACK_DEP_PTR, align 4
  %55635 = load i64, i64* %STACK_DEP_PTR, align 4
  %55636 = getelementptr i256, i256* %STACK, i64 %55635
  %55637 = load i256, i256* %55636, align 4
  %55638 = load i64, i64* %STACK_DEP_PTR, align 4
  %55639 = sub i64 %55638, 1
  store i64 %55639, i64* %STACK_DEP_PTR, align 4
  %55640 = load i64, i64* %STACK_DEP_PTR, align 4
  %55641 = add i64 %55640, 1
  store i64 %55641, i64* %STACK_DEP_PTR, align 4
  %55642 = load i64, i64* %STACK_DEP_PTR, align 4
  %55643 = getelementptr i256, i256* %STACK, i64 %55642
  store i256 %55637, i256* %55643, align 4
  %55644 = load i64, i64* %STACK_DEP_PTR, align 4
  %55645 = add i64 %55644, 1
  store i64 %55645, i64* %STACK_DEP_PTR, align 4
  %55646 = load i64, i64* %STACK_DEP_PTR, align 4
  %55647 = getelementptr i256, i256* %STACK, i64 %55646
  store i256 %55632, i256* %55647, align 4
  %55648 = load i64, i64* %STACK_DEP_PTR, align 4
  %55649 = add i64 %55648, 1
  store i64 %55649, i64* %STACK_DEP_PTR, align 4
  %55650 = load i64, i64* %STACK_DEP_PTR, align 4
  %55651 = getelementptr i256, i256* %STACK, i64 %55650
  store i256 0, i256* %55651, align 4
  %55652 = load i64, i64* %STACK_DEP_PTR, align 4
  %55653 = add i64 %55652, 1
  store i64 %55653, i64* %STACK_DEP_PTR, align 4
  %55654 = load i64, i64* %STACK_DEP_PTR, align 4
  %55655 = getelementptr i256, i256* %STACK, i64 %55654
  store i256 %55637, i256* %55655, align 4
  %55656 = load i64, i64* %STACK_DEP_PTR, align 4
  %55657 = add i64 %55656, 1
  store i64 %55657, i64* %STACK_DEP_PTR, align 4
  %55658 = load i64, i64* %STACK_DEP_PTR, align 4
  %55659 = getelementptr i256, i256* %STACK, i64 %55658
  store i256 0, i256* %55659, align 4
  %55660 = load i64, i64* %STACK_DEP_PTR, align 4
  %55661 = add i64 %55660, 1
  store i64 %55661, i64* %STACK_DEP_PTR, align 4
  %55662 = load i64, i64* %STACK_DEP_PTR, align 4
  %55663 = getelementptr i256, i256* %STACK, i64 %55662
  store i256 0, i256* %55663, align 4
  %55664 = load i64, i64* %STACK_DEP_PTR, align 4
  %55665 = add i64 %55664, 1
  store i64 %55665, i64* %STACK_DEP_PTR, align 4
  %55666 = load i64, i64* %STACK_DEP_PTR, align 4
  %55667 = getelementptr i256, i256* %STACK, i64 %55666
  store i256 0, i256* %55667, align 4
  br label %.18260

.18260:                                           ; preds = %56402, %.18235, %JumpTable
  %55668 = load i64, i64* %remaing_gas, align 4
  %55669 = icmp ugt i64 464, %55668
  br i1 %55669, label %Abort, label %55670

55670:                                            ; preds = %.18260
  %55671 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55672 = xor i32 %55671, 1091
  %55673 = urem i32 %55672, 4096
  %55674 = getelementptr i8, i8 addrspace(1)* %4, i32 %55673
  %55675 = load i8, i8 addrspace(1)* %55674, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55674, align 1, !nosanitize !3
  store i32 545, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55676 = sub i64 %55668, 464
  store i64 %55676, i64* %remaing_gas, align 4
  %55677 = load i64, i64* %STACK_DEP_PTR, align 4
  %55678 = getelementptr i256, i256* %STACK, i64 %55677
  %55679 = load i256, i256* %55678, align 4
  %55680 = load i64, i64* %STACK_DEP_PTR, align 4
  %55681 = sub i64 %55680, 1
  store i64 %55681, i64* %STACK_DEP_PTR, align 4
  %55682 = load i64, i64* %STACK_DEP_PTR, align 4
  %55683 = getelementptr i256, i256* %STACK, i64 %55682
  %55684 = load i256, i256* %55683, align 4
  %55685 = load i64, i64* %STACK_DEP_PTR, align 4
  %55686 = sub i64 %55685, 1
  store i64 %55686, i64* %STACK_DEP_PTR, align 4
  %55687 = load i64, i64* %STACK_DEP_PTR, align 4
  %55688 = getelementptr i256, i256* %STACK, i64 %55687
  %55689 = load i256, i256* %55688, align 4
  %55690 = load i64, i64* %STACK_DEP_PTR, align 4
  %55691 = sub i64 %55690, 1
  store i64 %55691, i64* %STACK_DEP_PTR, align 4
  %55692 = load i64, i64* %STACK_DEP_PTR, align 4
  %55693 = getelementptr i256, i256* %STACK, i64 %55692
  %55694 = load i256, i256* %55693, align 4
  %55695 = load i64, i64* %STACK_DEP_PTR, align 4
  %55696 = sub i64 %55695, 1
  store i64 %55696, i64* %STACK_DEP_PTR, align 4
  %55697 = trunc i256 %55694 to i64
  %55698 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %55697, i256* %55698)
  %55699 = load i256, i256* %55698, align 4
  %55700 = icmp ult i256 %55679, %55699
  %55701 = icmp eq i1 %55700, false
  %55702 = trunc i256 18960 to i64
  %jump.check234 = icmp ne i1 %55701, false
  %55703 = load i64, i64* %STACK_DEP_PTR, align 4
  %55704 = add i64 %55703, 1
  store i64 %55704, i64* %STACK_DEP_PTR, align 4
  %55705 = load i64, i64* %STACK_DEP_PTR, align 4
  %55706 = getelementptr i256, i256* %STACK, i64 %55705
  store i256 %55694, i256* %55706, align 4
  %55707 = load i64, i64* %STACK_DEP_PTR, align 4
  %55708 = add i64 %55707, 1
  store i64 %55708, i64* %STACK_DEP_PTR, align 4
  %55709 = load i64, i64* %STACK_DEP_PTR, align 4
  %55710 = getelementptr i256, i256* %STACK, i64 %55709
  store i256 %55689, i256* %55710, align 4
  %55711 = load i64, i64* %STACK_DEP_PTR, align 4
  %55712 = add i64 %55711, 1
  store i64 %55712, i64* %STACK_DEP_PTR, align 4
  %55713 = load i64, i64* %STACK_DEP_PTR, align 4
  %55714 = getelementptr i256, i256* %STACK, i64 %55713
  store i256 %55684, i256* %55714, align 4
  %55715 = load i64, i64* %STACK_DEP_PTR, align 4
  %55716 = add i64 %55715, 1
  store i64 %55716, i64* %STACK_DEP_PTR, align 4
  %55717 = load i64, i64* %STACK_DEP_PTR, align 4
  %55718 = getelementptr i256, i256* %STACK, i64 %55717
  store i256 %55679, i256* %55718, align 4
  br i1 %jump.check234, label %.18960, label %.18270, !EVMBB !4

.18270:                                           ; preds = %55670
  %55719 = load i64, i64* %remaing_gas, align 4
  %55720 = icmp ugt i64 624, %55719
  br i1 %55720, label %Abort, label %55721

55721:                                            ; preds = %.18270
  %55722 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55723 = xor i32 %55722, 1583
  %55724 = urem i32 %55723, 4096
  %55725 = getelementptr i8, i8 addrspace(1)* %4, i32 %55724
  %55726 = load i8, i8 addrspace(1)* %55725, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55725, align 1, !nosanitize !3
  store i32 791, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55727 = sub i64 %55719, 624
  store i64 %55727, i64* %remaing_gas, align 4
  %55728 = load i64, i64* %STACK_DEP_PTR, align 4
  %55729 = getelementptr i256, i256* %STACK, i64 %55728
  %55730 = load i256, i256* %55729, align 4
  %55731 = load i64, i64* %STACK_DEP_PTR, align 4
  %55732 = sub i64 %55731, 1
  store i64 %55732, i64* %STACK_DEP_PTR, align 4
  %55733 = load i64, i64* %STACK_DEP_PTR, align 4
  %55734 = getelementptr i256, i256* %STACK, i64 %55733
  %55735 = load i256, i256* %55734, align 4
  %55736 = load i64, i64* %STACK_DEP_PTR, align 4
  %55737 = sub i64 %55736, 1
  store i64 %55737, i64* %STACK_DEP_PTR, align 4
  %55738 = load i64, i64* %STACK_DEP_PTR, align 4
  %55739 = getelementptr i256, i256* %STACK, i64 %55738
  %55740 = load i256, i256* %55739, align 4
  %55741 = load i64, i64* %STACK_DEP_PTR, align 4
  %55742 = sub i64 %55741, 1
  store i64 %55742, i64* %STACK_DEP_PTR, align 4
  %55743 = load i64, i64* %STACK_DEP_PTR, align 4
  %55744 = getelementptr i256, i256* %STACK, i64 %55743
  %55745 = load i256, i256* %55744, align 4
  %55746 = load i64, i64* %STACK_DEP_PTR, align 4
  %55747 = sub i64 %55746, 1
  store i64 %55747, i64* %STACK_DEP_PTR, align 4
  %55748 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, 48, !pc !805, !intsan !45
  %55749 = trunc i256 %55745 to i64
  %55750 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %55749, i256* %55750)
  %55751 = load i256, i256* %55750, align 4
  %55752 = icmp ult i256 %55730, %55751
  %55753 = icmp eq i1 %55752, false
  %55754 = icmp eq i1 %55753, false
  %55755 = trunc i256 18319 to i64
  %jump.check235 = icmp ne i1 %55754, false
  %55756 = load i64, i64* %STACK_DEP_PTR, align 4
  %55757 = add i64 %55756, 1
  store i64 %55757, i64* %STACK_DEP_PTR, align 4
  %55758 = load i64, i64* %STACK_DEP_PTR, align 4
  %55759 = getelementptr i256, i256* %STACK, i64 %55758
  store i256 %55745, i256* %55759, align 4
  %55760 = load i64, i64* %STACK_DEP_PTR, align 4
  %55761 = add i64 %55760, 1
  store i64 %55761, i64* %STACK_DEP_PTR, align 4
  %55762 = load i64, i64* %STACK_DEP_PTR, align 4
  %55763 = getelementptr i256, i256* %STACK, i64 %55762
  store i256 %55740, i256* %55763, align 4
  %55764 = load i64, i64* %STACK_DEP_PTR, align 4
  %55765 = add i64 %55764, 1
  store i64 %55765, i64* %STACK_DEP_PTR, align 4
  %55766 = load i64, i64* %STACK_DEP_PTR, align 4
  %55767 = getelementptr i256, i256* %STACK, i64 %55766
  store i256 %55735, i256* %55767, align 4
  %55768 = load i64, i64* %STACK_DEP_PTR, align 4
  %55769 = add i64 %55768, 1
  store i64 %55769, i64* %STACK_DEP_PTR, align 4
  %55770 = load i64, i64* %STACK_DEP_PTR, align 4
  %55771 = getelementptr i256, i256* %STACK, i64 %55770
  store i256 %55730, i256* %55771, align 4
  %55772 = load i64, i64* %STACK_DEP_PTR, align 4
  %55773 = add i64 %55772, 1
  store i64 %55773, i64* %STACK_DEP_PTR, align 4
  %55774 = load i64, i64* %STACK_DEP_PTR, align 4
  %55775 = getelementptr i256, i256* %STACK, i64 %55774
  store i256 %55748, i256* %55775, align 4
  %55776 = load i64, i64* %STACK_DEP_PTR, align 4
  %55777 = add i64 %55776, 1
  store i64 %55777, i64* %STACK_DEP_PTR, align 4
  %55778 = load i64, i64* %STACK_DEP_PTR, align 4
  %55779 = getelementptr i256, i256* %STACK, i64 %55778
  store i256 %55745, i256* %55779, align 4
  %55780 = load i64, i64* %STACK_DEP_PTR, align 4
  %55781 = add i64 %55780, 1
  store i64 %55781, i64* %STACK_DEP_PTR, align 4
  %55782 = load i64, i64* %STACK_DEP_PTR, align 4
  %55783 = getelementptr i256, i256* %STACK, i64 %55782
  store i256 %55730, i256* %55783, align 4
  br i1 %jump.check235, label %.18319, label %.18318, !EVMBB !4

.18318:                                           ; preds = %55721
  %55784 = load i64, i64* %remaing_gas, align 4
  %55785 = icmp ugt i64 16, %55784
  br i1 %55785, label %Abort, label %55786

55786:                                            ; preds = %.18318
  %55787 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55788 = xor i32 %55787, 2286
  %55789 = urem i32 %55788, 4096
  %55790 = getelementptr i8, i8 addrspace(1)* %4, i32 %55789
  %55791 = load i8, i8 addrspace(1)* %55790, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55790, align 1, !nosanitize !3
  store i32 1143, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55792 = sub i64 %55784, 16
  store i64 %55792, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.18319:                                           ; preds = %55721, %JumpTable
  %55793 = load i64, i64* %remaing_gas, align 4
  %55794 = icmp ugt i64 384, %55793
  br i1 %55794, label %Abort, label %55795

55795:                                            ; preds = %.18319
  %55796 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55797 = xor i32 %55796, 277
  %55798 = urem i32 %55797, 4096
  %55799 = getelementptr i8, i8 addrspace(1)* %4, i32 %55798
  %55800 = load i8, i8 addrspace(1)* %55799, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55799, align 1, !nosanitize !3
  store i32 138, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55801 = sub i64 %55793, 384
  store i64 %55801, i64* %remaing_gas, align 4
  %55802 = load i64, i64* %STACK_DEP_PTR, align 4
  %55803 = getelementptr i256, i256* %STACK, i64 %55802
  %55804 = load i256, i256* %55803, align 4
  %55805 = load i64, i64* %STACK_DEP_PTR, align 4
  %55806 = sub i64 %55805, 1
  store i64 %55806, i64* %STACK_DEP_PTR, align 4
  %55807 = load i64, i64* %STACK_DEP_PTR, align 4
  %55808 = getelementptr i256, i256* %STACK, i64 %55807
  %55809 = load i256, i256* %55808, align 4
  %55810 = load i64, i64* %STACK_DEP_PTR, align 4
  %55811 = sub i64 %55810, 1
  store i64 %55811, i64* %STACK_DEP_PTR, align 4
  %55812 = load i64, i64* %STACK_DEP_PTR, align 4
  %55813 = getelementptr i256, i256* %STACK, i64 %55812
  %55814 = load i256, i256* %55813, align 4
  %55815 = load i64, i64* %STACK_DEP_PTR, align 4
  %55816 = sub i64 %55815, 1
  store i64 %55816, i64* %STACK_DEP_PTR, align 4
  %55817 = add i256 32, %55809, !pc !806, !intsan !10
  %55818 = add i256 %55817, %55804, !pc !807, !intsan !10
  %55819 = trunc i256 %55818 to i64
  %55820 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %55819, i256* %55820)
  %55821 = load i256, i256* %55820, align 4
  %55822 = alloca i256, align 8
  store i256 %55821, i256* %55822, align 4
  %55823 = alloca i256, align 8
  store i256 452312848583266388373324160190187140051835877600158453279131187530910662656, i256* %55823, align 4
  %55824 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %55822, i256* %55823, i256* %55824), !pc !808, !intsan !6
  %55825 = load i256, i256* %55824, align 4
  %55826 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, %55825, !pc !809, !intsan !45
  %55827 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %55828 = and i256 %55827, %55826
  %55829 = icmp ult i256 %55828, %55814
  %55830 = icmp eq i1 %55829, false
  %55831 = icmp eq i1 %55830, false
  %55832 = trunc i256 18599 to i64
  %jump.check236 = icmp ne i1 %55831, false
  %55833 = load i64, i64* %STACK_DEP_PTR, align 4
  %55834 = add i64 %55833, 1
  store i64 %55834, i64* %STACK_DEP_PTR, align 4
  %55835 = zext i1 %55830 to i256
  %55836 = load i64, i64* %STACK_DEP_PTR, align 4
  %55837 = getelementptr i256, i256* %STACK, i64 %55836
  store i256 %55835, i256* %55837, align 4
  br i1 %jump.check236, label %.18599, label %.18437, !EVMBB !4

.18437:                                           ; preds = %55795
  %55838 = load i64, i64* %remaing_gas, align 4
  %55839 = icmp ugt i64 672, %55838
  br i1 %55839, label %Abort, label %55840

55840:                                            ; preds = %.18437
  %55841 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55842 = xor i32 %55841, 258
  %55843 = urem i32 %55842, 4096
  %55844 = getelementptr i8, i8 addrspace(1)* %4, i32 %55843
  %55845 = load i8, i8 addrspace(1)* %55844, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55844, align 1, !nosanitize !3
  store i32 129, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55846 = sub i64 %55838, 672
  store i64 %55846, i64* %remaing_gas, align 4
  %55847 = load i64, i64* %STACK_DEP_PTR, align 4
  %55848 = getelementptr i256, i256* %STACK, i64 %55847
  %55849 = load i256, i256* %55848, align 4
  %55850 = load i64, i64* %STACK_DEP_PTR, align 4
  %55851 = sub i64 %55850, 1
  store i64 %55851, i64* %STACK_DEP_PTR, align 4
  %55852 = load i64, i64* %STACK_DEP_PTR, align 4
  %55853 = getelementptr i256, i256* %STACK, i64 %55852
  %55854 = load i256, i256* %55853, align 4
  %55855 = load i64, i64* %STACK_DEP_PTR, align 4
  %55856 = sub i64 %55855, 1
  store i64 %55856, i64* %STACK_DEP_PTR, align 4
  %55857 = load i64, i64* %STACK_DEP_PTR, align 4
  %55858 = getelementptr i256, i256* %STACK, i64 %55857
  %55859 = load i256, i256* %55858, align 4
  %55860 = load i64, i64* %STACK_DEP_PTR, align 4
  %55861 = sub i64 %55860, 1
  store i64 %55861, i64* %STACK_DEP_PTR, align 4
  %55862 = load i64, i64* %STACK_DEP_PTR, align 4
  %55863 = getelementptr i256, i256* %STACK, i64 %55862
  %55864 = load i256, i256* %55863, align 4
  %55865 = load i64, i64* %STACK_DEP_PTR, align 4
  %55866 = sub i64 %55865, 1
  store i64 %55866, i64* %STACK_DEP_PTR, align 4
  %55867 = load i64, i64* %STACK_DEP_PTR, align 4
  %55868 = getelementptr i256, i256* %STACK, i64 %55867
  %55869 = load i256, i256* %55868, align 4
  %55870 = load i64, i64* %STACK_DEP_PTR, align 4
  %55871 = sub i64 %55870, 1
  store i64 %55871, i64* %STACK_DEP_PTR, align 4
  %55872 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, 57, !pc !810, !intsan !45
  %55873 = trunc i256 %55869 to i64
  %55874 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %55873, i256* %55874)
  %55875 = load i256, i256* %55874, align 4
  %55876 = icmp ult i256 %55854, %55875
  %55877 = icmp eq i1 %55876, false
  %55878 = icmp eq i1 %55877, false
  %55879 = trunc i256 18487 to i64
  %jump.check237 = icmp ne i1 %55878, false
  %55880 = load i64, i64* %STACK_DEP_PTR, align 4
  %55881 = add i64 %55880, 1
  store i64 %55881, i64* %STACK_DEP_PTR, align 4
  %55882 = load i64, i64* %STACK_DEP_PTR, align 4
  %55883 = getelementptr i256, i256* %STACK, i64 %55882
  store i256 %55869, i256* %55883, align 4
  %55884 = load i64, i64* %STACK_DEP_PTR, align 4
  %55885 = add i64 %55884, 1
  store i64 %55885, i64* %STACK_DEP_PTR, align 4
  %55886 = load i64, i64* %STACK_DEP_PTR, align 4
  %55887 = getelementptr i256, i256* %STACK, i64 %55886
  store i256 %55864, i256* %55887, align 4
  %55888 = load i64, i64* %STACK_DEP_PTR, align 4
  %55889 = add i64 %55888, 1
  store i64 %55889, i64* %STACK_DEP_PTR, align 4
  %55890 = load i64, i64* %STACK_DEP_PTR, align 4
  %55891 = getelementptr i256, i256* %STACK, i64 %55890
  store i256 %55859, i256* %55891, align 4
  %55892 = load i64, i64* %STACK_DEP_PTR, align 4
  %55893 = add i64 %55892, 1
  store i64 %55893, i64* %STACK_DEP_PTR, align 4
  %55894 = load i64, i64* %STACK_DEP_PTR, align 4
  %55895 = getelementptr i256, i256* %STACK, i64 %55894
  store i256 %55854, i256* %55895, align 4
  %55896 = load i64, i64* %STACK_DEP_PTR, align 4
  %55897 = add i64 %55896, 1
  store i64 %55897, i64* %STACK_DEP_PTR, align 4
  %55898 = load i64, i64* %STACK_DEP_PTR, align 4
  %55899 = getelementptr i256, i256* %STACK, i64 %55898
  store i256 %55872, i256* %55899, align 4
  %55900 = load i64, i64* %STACK_DEP_PTR, align 4
  %55901 = add i64 %55900, 1
  store i64 %55901, i64* %STACK_DEP_PTR, align 4
  %55902 = load i64, i64* %STACK_DEP_PTR, align 4
  %55903 = getelementptr i256, i256* %STACK, i64 %55902
  store i256 %55869, i256* %55903, align 4
  %55904 = load i64, i64* %STACK_DEP_PTR, align 4
  %55905 = add i64 %55904, 1
  store i64 %55905, i64* %STACK_DEP_PTR, align 4
  %55906 = load i64, i64* %STACK_DEP_PTR, align 4
  %55907 = getelementptr i256, i256* %STACK, i64 %55906
  store i256 %55854, i256* %55907, align 4
  br i1 %jump.check237, label %.18487, label %.18486, !EVMBB !4

.18486:                                           ; preds = %55840
  %55908 = load i64, i64* %remaing_gas, align 4
  %55909 = icmp ugt i64 16, %55908
  br i1 %55909, label %Abort, label %55910

55910:                                            ; preds = %.18486
  %55911 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55912 = xor i32 %55911, 1415
  %55913 = urem i32 %55912, 4096
  %55914 = getelementptr i8, i8 addrspace(1)* %4, i32 %55913
  %55915 = load i8, i8 addrspace(1)* %55914, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55914, align 1, !nosanitize !3
  store i32 707, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55916 = sub i64 %55908, 16
  store i64 %55916, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.18487:                                           ; preds = %55840, %JumpTable
  %55917 = load i64, i64* %STACK_DEP_PTR, align 4
  %55918 = getelementptr i256, i256* %STACK, i64 %55917
  %55919 = load i256, i256* %55918, align 4
  %55920 = load i64, i64* %STACK_DEP_PTR, align 4
  %55921 = sub i64 %55920, 1
  store i64 %55921, i64* %STACK_DEP_PTR, align 4
  %55922 = load i64, i64* %STACK_DEP_PTR, align 4
  %55923 = getelementptr i256, i256* %STACK, i64 %55922
  %55924 = load i256, i256* %55923, align 4
  %55925 = load i64, i64* %STACK_DEP_PTR, align 4
  %55926 = sub i64 %55925, 1
  store i64 %55926, i64* %STACK_DEP_PTR, align 4
  %55927 = load i64, i64* %STACK_DEP_PTR, align 4
  %55928 = getelementptr i256, i256* %STACK, i64 %55927
  %55929 = load i256, i256* %55928, align 4
  %55930 = load i64, i64* %STACK_DEP_PTR, align 4
  %55931 = sub i64 %55930, 1
  store i64 %55931, i64* %STACK_DEP_PTR, align 4
  %55932 = add i256 32, %55924, !pc !811, !intsan !10
  %55933 = add i256 %55932, %55919, !pc !812, !intsan !10
  %55934 = trunc i256 %55933 to i64
  %55935 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %55934, i256* %55935)
  %55936 = load i256, i256* %55935, align 4
  %55937 = alloca i256, align 8
  store i256 %55936, i256* %55937, align 4
  %55938 = alloca i256, align 8
  store i256 452312848583266388373324160190187140051835877600158453279131187530910662656, i256* %55938, align 4
  %55939 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %55937, i256* %55938, i256* %55939), !pc !813, !intsan !6
  %55940 = load i256, i256* %55939, align 4
  %55941 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, %55940, !pc !814, !intsan !45
  %55942 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %55943 = and i256 %55942, %55941
  %55944 = icmp ugt i256 %55943, %55929
  %55945 = icmp eq i1 %55944, false
  %55946 = load i64, i64* %STACK_DEP_PTR, align 4
  %55947 = add i64 %55946, 1
  store i64 %55947, i64* %STACK_DEP_PTR, align 4
  %55948 = zext i1 %55945 to i256
  %55949 = load i64, i64* %STACK_DEP_PTR, align 4
  %55950 = getelementptr i256, i256* %STACK, i64 %55949
  store i256 %55948, i256* %55950, align 4
  br label %.18599

.18599:                                           ; preds = %.18487, %55795, %JumpTable
  %55951 = load i64, i64* %remaing_gas, align 4
  %55952 = icmp ugt i64 88, %55951
  br i1 %55952, label %Abort, label %55953

55953:                                            ; preds = %.18599
  %55954 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55955 = xor i32 %55954, 2657
  %55956 = urem i32 %55955, 4096
  %55957 = getelementptr i8, i8 addrspace(1)* %4, i32 %55956
  %55958 = load i8, i8 addrspace(1)* %55957, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55957, align 1, !nosanitize !3
  store i32 1328, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55959 = sub i64 %55951, 88
  store i64 %55959, i64* %remaing_gas, align 4
  %55960 = load i64, i64* %STACK_DEP_PTR, align 4
  %55961 = getelementptr i256, i256* %STACK, i64 %55960
  %55962 = load i256, i256* %55961, align 4
  %55963 = load i64, i64* %STACK_DEP_PTR, align 4
  %55964 = sub i64 %55963, 1
  store i64 %55964, i64* %STACK_DEP_PTR, align 4
  %55965 = icmp eq i256 %55962, 0
  %55966 = trunc i256 18776 to i64
  %jump.check238 = icmp ne i1 %55965, false
  br i1 %jump.check238, label %.18776, label %.18605, !EVMBB !4

.18605:                                           ; preds = %55953
  %55967 = load i64, i64* %remaing_gas, align 4
  %55968 = icmp ugt i64 232, %55967
  br i1 %55968, label %Abort, label %55969

55969:                                            ; preds = %.18605
  %55970 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55971 = xor i32 %55970, 1660
  %55972 = urem i32 %55971, 4096
  %55973 = getelementptr i8, i8 addrspace(1)* %4, i32 %55972
  %55974 = load i8, i8 addrspace(1)* %55973, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %55973, align 1, !nosanitize !3
  store i32 830, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %55975 = sub i64 %55967, 232
  store i64 %55975, i64* %remaing_gas, align 4
  %55976 = load i64, i64* %STACK_DEP_PTR, align 4
  %55977 = getelementptr i256, i256* %STACK, i64 %55976
  %55978 = load i256, i256* %55977, align 4
  %55979 = load i64, i64* %STACK_DEP_PTR, align 4
  %55980 = sub i64 %55979, 1
  store i64 %55980, i64* %STACK_DEP_PTR, align 4
  %55981 = load i64, i64* %STACK_DEP_PTR, align 4
  %55982 = getelementptr i256, i256* %STACK, i64 %55981
  %55983 = load i256, i256* %55982, align 4
  %55984 = load i64, i64* %STACK_DEP_PTR, align 4
  %55985 = sub i64 %55984, 1
  store i64 %55985, i64* %STACK_DEP_PTR, align 4
  %55986 = icmp eq i256 %55983, 0
  %55987 = trunc i256 18634 to i64
  %jump.check239 = icmp ne i1 %55986, false
  %55988 = load i64, i64* %STACK_DEP_PTR, align 4
  %55989 = add i64 %55988, 1
  store i64 %55989, i64* %STACK_DEP_PTR, align 4
  %55990 = load i64, i64* %STACK_DEP_PTR, align 4
  %55991 = getelementptr i256, i256* %STACK, i64 %55990
  store i256 %55983, i256* %55991, align 4
  %55992 = load i64, i64* %STACK_DEP_PTR, align 4
  %55993 = add i64 %55992, 1
  store i64 %55993, i64* %STACK_DEP_PTR, align 4
  %55994 = load i64, i64* %STACK_DEP_PTR, align 4
  %55995 = getelementptr i256, i256* %STACK, i64 %55994
  store i256 %55978, i256* %55995, align 4
  br i1 %jump.check239, label %.18634, label %.18611, !EVMBB !4

.18611:                                           ; preds = %55969
  %55996 = load i64, i64* %remaing_gas, align 4
  %55997 = icmp ugt i64 624, %55996
  br i1 %55997, label %Abort, label %55998

55998:                                            ; preds = %.18611
  %55999 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56000 = xor i32 %55999, 1555
  %56001 = urem i32 %56000, 4096
  %56002 = getelementptr i8, i8 addrspace(1)* %4, i32 %56001
  %56003 = load i8, i8 addrspace(1)* %56002, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56002, align 1, !nosanitize !3
  store i32 777, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56004 = sub i64 %55996, 624
  store i64 %56004, i64* %remaing_gas, align 4
  %56005 = load i64, i64* %STACK_DEP_PTR, align 4
  %56006 = getelementptr i256, i256* %STACK, i64 %56005
  %56007 = load i256, i256* %56006, align 4
  %56008 = load i64, i64* %STACK_DEP_PTR, align 4
  %56009 = sub i64 %56008, 1
  store i64 %56009, i64* %STACK_DEP_PTR, align 4
  %56010 = load i64, i64* %STACK_DEP_PTR, align 4
  %56011 = getelementptr i256, i256* %STACK, i64 %56010
  %56012 = load i256, i256* %56011, align 4
  %56013 = load i64, i64* %STACK_DEP_PTR, align 4
  %56014 = sub i64 %56013, 1
  store i64 %56014, i64* %STACK_DEP_PTR, align 4
  %56015 = load i64, i64* %STACK_DEP_PTR, align 4
  %56016 = getelementptr i256, i256* %STACK, i64 %56015
  %56017 = load i256, i256* %56016, align 4
  %56018 = load i64, i64* %STACK_DEP_PTR, align 4
  %56019 = sub i64 %56018, 1
  store i64 %56019, i64* %STACK_DEP_PTR, align 4
  %56020 = load i64, i64* %STACK_DEP_PTR, align 4
  %56021 = getelementptr i256, i256* %STACK, i64 %56020
  %56022 = load i256, i256* %56021, align 4
  %56023 = load i64, i64* %STACK_DEP_PTR, align 4
  %56024 = sub i64 %56023, 1
  store i64 %56024, i64* %STACK_DEP_PTR, align 4
  %56025 = load i64, i64* %STACK_DEP_PTR, align 4
  %56026 = getelementptr i256, i256* %STACK, i64 %56025
  %56027 = load i256, i256* %56026, align 4
  %56028 = load i64, i64* %STACK_DEP_PTR, align 4
  %56029 = sub i64 %56028, 1
  store i64 %56029, i64* %STACK_DEP_PTR, align 4
  %56030 = load i64, i64* %STACK_DEP_PTR, align 4
  %56031 = getelementptr i256, i256* %STACK, i64 %56030
  %56032 = load i256, i256* %56031, align 4
  %56033 = load i64, i64* %STACK_DEP_PTR, align 4
  %56034 = sub i64 %56033, 1
  store i64 %56034, i64* %STACK_DEP_PTR, align 4
  %56035 = icmp eq i256 %56032, 0
  %56036 = icmp eq i1 %56035, false
  %56037 = trunc i256 18624 to i64
  %jump.check240 = icmp ne i1 %56036, false
  %56038 = load i64, i64* %STACK_DEP_PTR, align 4
  %56039 = add i64 %56038, 1
  store i64 %56039, i64* %STACK_DEP_PTR, align 4
  %56040 = load i64, i64* %STACK_DEP_PTR, align 4
  %56041 = getelementptr i256, i256* %STACK, i64 %56040
  store i256 %56032, i256* %56041, align 4
  %56042 = load i64, i64* %STACK_DEP_PTR, align 4
  %56043 = add i64 %56042, 1
  store i64 %56043, i64* %STACK_DEP_PTR, align 4
  %56044 = load i64, i64* %STACK_DEP_PTR, align 4
  %56045 = getelementptr i256, i256* %STACK, i64 %56044
  store i256 %56027, i256* %56045, align 4
  %56046 = load i64, i64* %STACK_DEP_PTR, align 4
  %56047 = add i64 %56046, 1
  store i64 %56047, i64* %STACK_DEP_PTR, align 4
  %56048 = load i64, i64* %STACK_DEP_PTR, align 4
  %56049 = getelementptr i256, i256* %STACK, i64 %56048
  store i256 %56022, i256* %56049, align 4
  %56050 = load i64, i64* %STACK_DEP_PTR, align 4
  %56051 = add i64 %56050, 1
  store i64 %56051, i64* %STACK_DEP_PTR, align 4
  %56052 = load i64, i64* %STACK_DEP_PTR, align 4
  %56053 = getelementptr i256, i256* %STACK, i64 %56052
  store i256 %56017, i256* %56053, align 4
  %56054 = load i64, i64* %STACK_DEP_PTR, align 4
  %56055 = add i64 %56054, 1
  store i64 %56055, i64* %STACK_DEP_PTR, align 4
  %56056 = load i64, i64* %STACK_DEP_PTR, align 4
  %56057 = getelementptr i256, i256* %STACK, i64 %56056
  store i256 %56012, i256* %56057, align 4
  %56058 = load i64, i64* %STACK_DEP_PTR, align 4
  %56059 = add i64 %56058, 1
  store i64 %56059, i64* %STACK_DEP_PTR, align 4
  %56060 = load i64, i64* %STACK_DEP_PTR, align 4
  %56061 = getelementptr i256, i256* %STACK, i64 %56060
  store i256 %56007, i256* %56061, align 4
  br i1 %jump.check240, label %.18624, label %.18620, !EVMBB !4

.18620:                                           ; preds = %55998
  %56062 = load i64, i64* %remaing_gas, align 4
  %56063 = icmp ugt i64 24, %56062
  br i1 %56063, label %Abort, label %56064

56064:                                            ; preds = %.18620
  %56065 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56066 = xor i32 %56065, 1634
  %56067 = urem i32 %56066, 4096
  %56068 = getelementptr i8, i8 addrspace(1)* %4, i32 %56067
  %56069 = load i8, i8 addrspace(1)* %56068, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56068, align 1, !nosanitize !3
  store i32 817, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56070 = sub i64 %56062, 24
  store i64 %56070, i64* %remaing_gas, align 4
  %56071 = trunc i256 18960 to i64
  br label %.18960, !EVMBB !4

.18624:                                           ; preds = %55998, %JumpTable
  %56072 = load i64, i64* %STACK_DEP_PTR, align 4
  %56073 = getelementptr i256, i256* %STACK, i64 %56072
  %56074 = load i256, i256* %56073, align 4
  %56075 = load i64, i64* %STACK_DEP_PTR, align 4
  %56076 = sub i64 %56075, 1
  store i64 %56076, i64* %STACK_DEP_PTR, align 4
  %56077 = load i64, i64* %STACK_DEP_PTR, align 4
  %56078 = getelementptr i256, i256* %STACK, i64 %56077
  %56079 = load i256, i256* %56078, align 4
  %56080 = load i64, i64* %STACK_DEP_PTR, align 4
  %56081 = sub i64 %56080, 1
  store i64 %56081, i64* %STACK_DEP_PTR, align 4
  %56082 = load i64, i64* %STACK_DEP_PTR, align 4
  %56083 = getelementptr i256, i256* %STACK, i64 %56082
  %56084 = load i256, i256* %56083, align 4
  %56085 = load i64, i64* %STACK_DEP_PTR, align 4
  %56086 = sub i64 %56085, 1
  store i64 %56086, i64* %STACK_DEP_PTR, align 4
  %56087 = load i64, i64* %STACK_DEP_PTR, align 4
  %56088 = getelementptr i256, i256* %STACK, i64 %56087
  %56089 = load i256, i256* %56088, align 4
  %56090 = load i64, i64* %STACK_DEP_PTR, align 4
  %56091 = sub i64 %56090, 1
  store i64 %56091, i64* %STACK_DEP_PTR, align 4
  %56092 = load i64, i64* %STACK_DEP_PTR, align 4
  %56093 = getelementptr i256, i256* %STACK, i64 %56092
  %56094 = load i256, i256* %56093, align 4
  %56095 = load i64, i64* %STACK_DEP_PTR, align 4
  %56096 = sub i64 %56095, 1
  store i64 %56096, i64* %STACK_DEP_PTR, align 4
  %56097 = load i64, i64* %STACK_DEP_PTR, align 4
  %56098 = getelementptr i256, i256* %STACK, i64 %56097
  %56099 = load i256, i256* %56098, align 4
  %56100 = load i64, i64* %STACK_DEP_PTR, align 4
  %56101 = sub i64 %56100, 1
  store i64 %56101, i64* %STACK_DEP_PTR, align 4
  %56102 = sub i256 %56099, 1, !pc !815, !intsan !8
  %56103 = load i64, i64* %STACK_DEP_PTR, align 4
  %56104 = add i64 %56103, 1
  store i64 %56104, i64* %STACK_DEP_PTR, align 4
  %56105 = load i64, i64* %STACK_DEP_PTR, align 4
  %56106 = getelementptr i256, i256* %STACK, i64 %56105
  store i256 %56102, i256* %56106, align 4
  %56107 = load i64, i64* %STACK_DEP_PTR, align 4
  %56108 = add i64 %56107, 1
  store i64 %56108, i64* %STACK_DEP_PTR, align 4
  %56109 = load i64, i64* %STACK_DEP_PTR, align 4
  %56110 = getelementptr i256, i256* %STACK, i64 %56109
  store i256 %56094, i256* %56110, align 4
  %56111 = load i64, i64* %STACK_DEP_PTR, align 4
  %56112 = add i64 %56111, 1
  store i64 %56112, i64* %STACK_DEP_PTR, align 4
  %56113 = load i64, i64* %STACK_DEP_PTR, align 4
  %56114 = getelementptr i256, i256* %STACK, i64 %56113
  store i256 %56089, i256* %56114, align 4
  %56115 = load i64, i64* %STACK_DEP_PTR, align 4
  %56116 = add i64 %56115, 1
  store i64 %56116, i64* %STACK_DEP_PTR, align 4
  %56117 = load i64, i64* %STACK_DEP_PTR, align 4
  %56118 = getelementptr i256, i256* %STACK, i64 %56117
  store i256 %56084, i256* %56118, align 4
  %56119 = load i64, i64* %STACK_DEP_PTR, align 4
  %56120 = add i64 %56119, 1
  store i64 %56120, i64* %STACK_DEP_PTR, align 4
  %56121 = load i64, i64* %STACK_DEP_PTR, align 4
  %56122 = getelementptr i256, i256* %STACK, i64 %56121
  store i256 %56079, i256* %56122, align 4
  %56123 = load i64, i64* %STACK_DEP_PTR, align 4
  %56124 = add i64 %56123, 1
  store i64 %56124, i64* %STACK_DEP_PTR, align 4
  %56125 = load i64, i64* %STACK_DEP_PTR, align 4
  %56126 = getelementptr i256, i256* %STACK, i64 %56125
  store i256 %56074, i256* %56126, align 4
  br label %.18634

.18634:                                           ; preds = %.18624, %55969, %JumpTable
  %56127 = load i64, i64* %remaing_gas, align 4
  %56128 = icmp ugt i64 624, %56127
  br i1 %56128, label %Abort, label %56129

56129:                                            ; preds = %.18634
  %56130 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56131 = xor i32 %56130, 2462
  %56132 = urem i32 %56131, 4096
  %56133 = getelementptr i8, i8 addrspace(1)* %4, i32 %56132
  %56134 = load i8, i8 addrspace(1)* %56133, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56133, align 1, !nosanitize !3
  store i32 1231, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56135 = sub i64 %56127, 624
  store i64 %56135, i64* %remaing_gas, align 4
  %56136 = load i64, i64* %STACK_DEP_PTR, align 4
  %56137 = getelementptr i256, i256* %STACK, i64 %56136
  %56138 = load i256, i256* %56137, align 4
  %56139 = load i64, i64* %STACK_DEP_PTR, align 4
  %56140 = sub i64 %56139, 1
  store i64 %56140, i64* %STACK_DEP_PTR, align 4
  %56141 = load i64, i64* %STACK_DEP_PTR, align 4
  %56142 = getelementptr i256, i256* %STACK, i64 %56141
  %56143 = load i256, i256* %56142, align 4
  %56144 = load i64, i64* %STACK_DEP_PTR, align 4
  %56145 = sub i64 %56144, 1
  store i64 %56145, i64* %STACK_DEP_PTR, align 4
  %56146 = load i64, i64* %STACK_DEP_PTR, align 4
  %56147 = getelementptr i256, i256* %STACK, i64 %56146
  %56148 = load i256, i256* %56147, align 4
  %56149 = load i64, i64* %STACK_DEP_PTR, align 4
  %56150 = sub i64 %56149, 1
  store i64 %56150, i64* %STACK_DEP_PTR, align 4
  %56151 = load i64, i64* %STACK_DEP_PTR, align 4
  %56152 = getelementptr i256, i256* %STACK, i64 %56151
  %56153 = load i256, i256* %56152, align 4
  %56154 = load i64, i64* %STACK_DEP_PTR, align 4
  %56155 = sub i64 %56154, 1
  store i64 %56155, i64* %STACK_DEP_PTR, align 4
  %56156 = mul i256 %56148, 10, !pc !816, !intsan !45
  %56157 = trunc i256 %56153 to i64
  %56158 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %56157, i256* %56158)
  %56159 = load i256, i256* %56158, align 4
  %56160 = icmp ult i256 %56138, %56159
  %56161 = icmp eq i1 %56160, false
  %56162 = icmp eq i1 %56161, false
  %56163 = trunc i256 18656 to i64
  %jump.check241 = icmp ne i1 %56162, false
  %56164 = load i64, i64* %STACK_DEP_PTR, align 4
  %56165 = add i64 %56164, 1
  store i64 %56165, i64* %STACK_DEP_PTR, align 4
  %56166 = load i64, i64* %STACK_DEP_PTR, align 4
  %56167 = getelementptr i256, i256* %STACK, i64 %56166
  store i256 %56153, i256* %56167, align 4
  %56168 = load i64, i64* %STACK_DEP_PTR, align 4
  %56169 = add i64 %56168, 1
  store i64 %56169, i64* %STACK_DEP_PTR, align 4
  %56170 = load i64, i64* %STACK_DEP_PTR, align 4
  %56171 = getelementptr i256, i256* %STACK, i64 %56170
  store i256 %56156, i256* %56171, align 4
  %56172 = load i64, i64* %STACK_DEP_PTR, align 4
  %56173 = add i64 %56172, 1
  store i64 %56173, i64* %STACK_DEP_PTR, align 4
  %56174 = load i64, i64* %STACK_DEP_PTR, align 4
  %56175 = getelementptr i256, i256* %STACK, i64 %56174
  store i256 %56143, i256* %56175, align 4
  %56176 = load i64, i64* %STACK_DEP_PTR, align 4
  %56177 = add i64 %56176, 1
  store i64 %56177, i64* %STACK_DEP_PTR, align 4
  %56178 = load i64, i64* %STACK_DEP_PTR, align 4
  %56179 = getelementptr i256, i256* %STACK, i64 %56178
  store i256 %56138, i256* %56179, align 4
  %56180 = load i64, i64* %STACK_DEP_PTR, align 4
  %56181 = add i64 %56180, 1
  store i64 %56181, i64* %STACK_DEP_PTR, align 4
  %56182 = load i64, i64* %STACK_DEP_PTR, align 4
  %56183 = getelementptr i256, i256* %STACK, i64 %56182
  store i256 48, i256* %56183, align 4
  %56184 = load i64, i64* %STACK_DEP_PTR, align 4
  %56185 = add i64 %56184, 1
  store i64 %56185, i64* %STACK_DEP_PTR, align 4
  %56186 = load i64, i64* %STACK_DEP_PTR, align 4
  %56187 = getelementptr i256, i256* %STACK, i64 %56186
  store i256 %56153, i256* %56187, align 4
  %56188 = load i64, i64* %STACK_DEP_PTR, align 4
  %56189 = add i64 %56188, 1
  store i64 %56189, i64* %STACK_DEP_PTR, align 4
  %56190 = load i64, i64* %STACK_DEP_PTR, align 4
  %56191 = getelementptr i256, i256* %STACK, i64 %56190
  store i256 %56138, i256* %56191, align 4
  br i1 %jump.check241, label %.18656, label %.18655, !EVMBB !4

.18655:                                           ; preds = %56129
  %56192 = load i64, i64* %remaing_gas, align 4
  %56193 = icmp ugt i64 16, %56192
  br i1 %56193, label %Abort, label %56194

56194:                                            ; preds = %.18655
  %56195 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56196 = xor i32 %56195, 873
  %56197 = urem i32 %56196, 4096
  %56198 = getelementptr i8, i8 addrspace(1)* %4, i32 %56197
  %56199 = load i8, i8 addrspace(1)* %56198, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56198, align 1, !nosanitize !3
  store i32 436, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56200 = sub i64 %56192, 16
  store i64 %56200, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.18656:                                           ; preds = %56129, %JumpTable
  %56201 = load i64, i64* %remaing_gas, align 4
  %56202 = icmp ugt i64 640, %56201
  br i1 %56202, label %Abort, label %56203

56203:                                            ; preds = %.18656
  %56204 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56205 = xor i32 %56204, 2812
  %56206 = urem i32 %56205, 4096
  %56207 = getelementptr i8, i8 addrspace(1)* %4, i32 %56206
  %56208 = load i8, i8 addrspace(1)* %56207, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56207, align 1, !nosanitize !3
  store i32 1406, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56209 = sub i64 %56201, 640
  store i64 %56209, i64* %remaing_gas, align 4
  %56210 = load i64, i64* %STACK_DEP_PTR, align 4
  %56211 = getelementptr i256, i256* %STACK, i64 %56210
  %56212 = load i256, i256* %56211, align 4
  %56213 = load i64, i64* %STACK_DEP_PTR, align 4
  %56214 = sub i64 %56213, 1
  store i64 %56214, i64* %STACK_DEP_PTR, align 4
  %56215 = load i64, i64* %STACK_DEP_PTR, align 4
  %56216 = getelementptr i256, i256* %STACK, i64 %56215
  %56217 = load i256, i256* %56216, align 4
  %56218 = load i64, i64* %STACK_DEP_PTR, align 4
  %56219 = sub i64 %56218, 1
  store i64 %56219, i64* %STACK_DEP_PTR, align 4
  %56220 = load i64, i64* %STACK_DEP_PTR, align 4
  %56221 = getelementptr i256, i256* %STACK, i64 %56220
  %56222 = load i256, i256* %56221, align 4
  %56223 = load i64, i64* %STACK_DEP_PTR, align 4
  %56224 = sub i64 %56223, 1
  store i64 %56224, i64* %STACK_DEP_PTR, align 4
  %56225 = load i64, i64* %STACK_DEP_PTR, align 4
  %56226 = getelementptr i256, i256* %STACK, i64 %56225
  %56227 = load i256, i256* %56226, align 4
  %56228 = load i64, i64* %STACK_DEP_PTR, align 4
  %56229 = sub i64 %56228, 1
  store i64 %56229, i64* %STACK_DEP_PTR, align 4
  %56230 = load i64, i64* %STACK_DEP_PTR, align 4
  %56231 = getelementptr i256, i256* %STACK, i64 %56230
  %56232 = load i256, i256* %56231, align 4
  %56233 = load i64, i64* %STACK_DEP_PTR, align 4
  %56234 = sub i64 %56233, 1
  store i64 %56234, i64* %STACK_DEP_PTR, align 4
  %56235 = load i64, i64* %STACK_DEP_PTR, align 4
  %56236 = getelementptr i256, i256* %STACK, i64 %56235
  %56237 = load i256, i256* %56236, align 4
  %56238 = load i64, i64* %STACK_DEP_PTR, align 4
  %56239 = sub i64 %56238, 1
  store i64 %56239, i64* %STACK_DEP_PTR, align 4
  %56240 = add i256 32, %56217, !pc !817, !intsan !10
  %56241 = add i256 %56240, %56212, !pc !818, !intsan !10
  %56242 = trunc i256 %56241 to i64
  %56243 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %56242, i256* %56243)
  %56244 = load i256, i256* %56243, align 4
  %56245 = alloca i256, align 8
  store i256 %56244, i256* %56245, align 4
  %56246 = alloca i256, align 8
  store i256 452312848583266388373324160190187140051835877600158453279131187530910662656, i256* %56246, align 4
  %56247 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %56245, i256* %56246, i256* %56247), !pc !819, !intsan !6
  %56248 = load i256, i256* %56247, align 4
  %56249 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, %56248, !pc !820, !intsan !45
  %56250 = alloca i256, align 8
  store i256 %56249, i256* %56250, align 4
  %56251 = alloca i256, align 8
  store i256 452312848583266388373324160190187140051835877600158453279131187530910662656, i256* %56251, align 4
  %56252 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %56250, i256* %56251, i256* %56252), !pc !821, !intsan !6
  %56253 = load i256, i256* %56252, align 4
  %56254 = sub i256 %56253, %56222, !pc !822, !intsan !8
  %56255 = add i256 %56237, %56254, !pc !823, !intsan !10
  %56256 = trunc i256 18947 to i64
  %56257 = load i64, i64* %STACK_DEP_PTR, align 4
  %56258 = add i64 %56257, 1
  store i64 %56258, i64* %STACK_DEP_PTR, align 4
  %56259 = load i64, i64* %STACK_DEP_PTR, align 4
  %56260 = getelementptr i256, i256* %STACK, i64 %56259
  store i256 %56255, i256* %56260, align 4
  %56261 = load i64, i64* %STACK_DEP_PTR, align 4
  %56262 = add i64 %56261, 1
  store i64 %56262, i64* %STACK_DEP_PTR, align 4
  %56263 = load i64, i64* %STACK_DEP_PTR, align 4
  %56264 = getelementptr i256, i256* %STACK, i64 %56263
  store i256 %56232, i256* %56264, align 4
  %56265 = load i64, i64* %STACK_DEP_PTR, align 4
  %56266 = add i64 %56265, 1
  store i64 %56266, i64* %STACK_DEP_PTR, align 4
  %56267 = load i64, i64* %STACK_DEP_PTR, align 4
  %56268 = getelementptr i256, i256* %STACK, i64 %56267
  store i256 %56227, i256* %56268, align 4
  br label %.18947, !EVMBB !4

.18776:                                           ; preds = %55953, %JumpTable
  %56269 = load i64, i64* %remaing_gas, align 4
  %56270 = icmp ugt i64 624, %56269
  br i1 %56270, label %Abort, label %56271

56271:                                            ; preds = %.18776
  %56272 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56273 = xor i32 %56272, 3954
  %56274 = urem i32 %56273, 4096
  %56275 = getelementptr i8, i8 addrspace(1)* %4, i32 %56274
  %56276 = load i8, i8 addrspace(1)* %56275, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56275, align 1, !nosanitize !3
  store i32 1977, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56277 = sub i64 %56269, 624
  store i64 %56277, i64* %remaing_gas, align 4
  %56278 = load i64, i64* %STACK_DEP_PTR, align 4
  %56279 = getelementptr i256, i256* %STACK, i64 %56278
  %56280 = load i256, i256* %56279, align 4
  %56281 = load i64, i64* %STACK_DEP_PTR, align 4
  %56282 = sub i64 %56281, 1
  store i64 %56282, i64* %STACK_DEP_PTR, align 4
  %56283 = load i64, i64* %STACK_DEP_PTR, align 4
  %56284 = getelementptr i256, i256* %STACK, i64 %56283
  %56285 = load i256, i256* %56284, align 4
  %56286 = load i64, i64* %STACK_DEP_PTR, align 4
  %56287 = sub i64 %56286, 1
  store i64 %56287, i64* %STACK_DEP_PTR, align 4
  %56288 = load i64, i64* %STACK_DEP_PTR, align 4
  %56289 = getelementptr i256, i256* %STACK, i64 %56288
  %56290 = load i256, i256* %56289, align 4
  %56291 = load i64, i64* %STACK_DEP_PTR, align 4
  %56292 = sub i64 %56291, 1
  store i64 %56292, i64* %STACK_DEP_PTR, align 4
  %56293 = load i64, i64* %STACK_DEP_PTR, align 4
  %56294 = getelementptr i256, i256* %STACK, i64 %56293
  %56295 = load i256, i256* %56294, align 4
  %56296 = load i64, i64* %STACK_DEP_PTR, align 4
  %56297 = sub i64 %56296, 1
  store i64 %56297, i64* %STACK_DEP_PTR, align 4
  %56298 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, 46, !pc !824, !intsan !45
  %56299 = trunc i256 %56295 to i64
  %56300 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %56299, i256* %56300)
  %56301 = load i256, i256* %56300, align 4
  %56302 = icmp ult i256 %56280, %56301
  %56303 = icmp eq i1 %56302, false
  %56304 = icmp eq i1 %56303, false
  %56305 = trunc i256 18826 to i64
  %jump.check242 = icmp ne i1 %56304, false
  %56306 = load i64, i64* %STACK_DEP_PTR, align 4
  %56307 = add i64 %56306, 1
  store i64 %56307, i64* %STACK_DEP_PTR, align 4
  %56308 = load i64, i64* %STACK_DEP_PTR, align 4
  %56309 = getelementptr i256, i256* %STACK, i64 %56308
  store i256 %56295, i256* %56309, align 4
  %56310 = load i64, i64* %STACK_DEP_PTR, align 4
  %56311 = add i64 %56310, 1
  store i64 %56311, i64* %STACK_DEP_PTR, align 4
  %56312 = load i64, i64* %STACK_DEP_PTR, align 4
  %56313 = getelementptr i256, i256* %STACK, i64 %56312
  store i256 %56290, i256* %56313, align 4
  %56314 = load i64, i64* %STACK_DEP_PTR, align 4
  %56315 = add i64 %56314, 1
  store i64 %56315, i64* %STACK_DEP_PTR, align 4
  %56316 = load i64, i64* %STACK_DEP_PTR, align 4
  %56317 = getelementptr i256, i256* %STACK, i64 %56316
  store i256 %56285, i256* %56317, align 4
  %56318 = load i64, i64* %STACK_DEP_PTR, align 4
  %56319 = add i64 %56318, 1
  store i64 %56319, i64* %STACK_DEP_PTR, align 4
  %56320 = load i64, i64* %STACK_DEP_PTR, align 4
  %56321 = getelementptr i256, i256* %STACK, i64 %56320
  store i256 %56280, i256* %56321, align 4
  %56322 = load i64, i64* %STACK_DEP_PTR, align 4
  %56323 = add i64 %56322, 1
  store i64 %56323, i64* %STACK_DEP_PTR, align 4
  %56324 = load i64, i64* %STACK_DEP_PTR, align 4
  %56325 = getelementptr i256, i256* %STACK, i64 %56324
  store i256 %56298, i256* %56325, align 4
  %56326 = load i64, i64* %STACK_DEP_PTR, align 4
  %56327 = add i64 %56326, 1
  store i64 %56327, i64* %STACK_DEP_PTR, align 4
  %56328 = load i64, i64* %STACK_DEP_PTR, align 4
  %56329 = getelementptr i256, i256* %STACK, i64 %56328
  store i256 %56295, i256* %56329, align 4
  %56330 = load i64, i64* %STACK_DEP_PTR, align 4
  %56331 = add i64 %56330, 1
  store i64 %56331, i64* %STACK_DEP_PTR, align 4
  %56332 = load i64, i64* %STACK_DEP_PTR, align 4
  %56333 = getelementptr i256, i256* %STACK, i64 %56332
  store i256 %56280, i256* %56333, align 4
  br i1 %jump.check242, label %.18826, label %.18825, !EVMBB !4

.18825:                                           ; preds = %56271
  %56334 = load i64, i64* %remaing_gas, align 4
  %56335 = icmp ugt i64 16, %56334
  br i1 %56335, label %Abort, label %56336

56336:                                            ; preds = %.18825
  %56337 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56338 = xor i32 %56337, 1409
  %56339 = urem i32 %56338, 4096
  %56340 = getelementptr i8, i8 addrspace(1)* %4, i32 %56339
  %56341 = load i8, i8 addrspace(1)* %56340, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56340, align 1, !nosanitize !3
  store i32 704, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56342 = sub i64 %56334, 16
  store i64 %56342, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.18826:                                           ; preds = %56271, %JumpTable
  %56343 = load i64, i64* %remaing_gas, align 4
  %56344 = icmp ugt i64 320, %56343
  br i1 %56344, label %Abort, label %56345

56345:                                            ; preds = %.18826
  %56346 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56347 = xor i32 %56346, 205
  %56348 = urem i32 %56347, 4096
  %56349 = getelementptr i8, i8 addrspace(1)* %4, i32 %56348
  %56350 = load i8, i8 addrspace(1)* %56349, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56349, align 1, !nosanitize !3
  store i32 102, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56351 = sub i64 %56343, 320
  store i64 %56351, i64* %remaing_gas, align 4
  %56352 = load i64, i64* %STACK_DEP_PTR, align 4
  %56353 = getelementptr i256, i256* %STACK, i64 %56352
  %56354 = load i256, i256* %56353, align 4
  %56355 = load i64, i64* %STACK_DEP_PTR, align 4
  %56356 = sub i64 %56355, 1
  store i64 %56356, i64* %STACK_DEP_PTR, align 4
  %56357 = load i64, i64* %STACK_DEP_PTR, align 4
  %56358 = getelementptr i256, i256* %STACK, i64 %56357
  %56359 = load i256, i256* %56358, align 4
  %56360 = load i64, i64* %STACK_DEP_PTR, align 4
  %56361 = sub i64 %56360, 1
  store i64 %56361, i64* %STACK_DEP_PTR, align 4
  %56362 = load i64, i64* %STACK_DEP_PTR, align 4
  %56363 = getelementptr i256, i256* %STACK, i64 %56362
  %56364 = load i256, i256* %56363, align 4
  %56365 = load i64, i64* %STACK_DEP_PTR, align 4
  %56366 = sub i64 %56365, 1
  store i64 %56366, i64* %STACK_DEP_PTR, align 4
  %56367 = add i256 32, %56359, !pc !825, !intsan !10
  %56368 = add i256 %56367, %56354, !pc !826, !intsan !10
  %56369 = trunc i256 %56368 to i64
  %56370 = alloca i256, align 8
  call void @__device_mload(i8* %MEMORY, i64 %56369, i256* %56370)
  %56371 = load i256, i256* %56370, align 4
  %56372 = alloca i256, align 8
  store i256 %56371, i256* %56372, align 4
  %56373 = alloca i256, align 8
  store i256 452312848583266388373324160190187140051835877600158453279131187530910662656, i256* %56373, align 4
  %56374 = alloca i256, align 8
  call void @evm.udiv.i256(i256* %56372, i256* %56373, i256* %56374), !pc !827, !intsan !6
  %56375 = load i256, i256* %56374, align 4
  %56376 = mul i256 452312848583266388373324160190187140051835877600158453279131187530910662656, %56375, !pc !828, !intsan !45
  %56377 = xor i256 452312848583266388373324160190187140051835877600158453279131187530910662655, -1
  %56378 = and i256 %56377, %56376
  %56379 = icmp eq i256 %56378, %56364
  %56380 = icmp eq i1 %56379, false
  %56381 = trunc i256 18946 to i64
  %jump.check243 = icmp ne i1 %56380, false
  br i1 %jump.check243, label %.18946, label %.18942, !EVMBB !4

.18942:                                           ; preds = %56345
  %56382 = load i64, i64* %STACK_DEP_PTR, align 4
  %56383 = getelementptr i256, i256* %STACK, i64 %56382
  %56384 = load i256, i256* %56383, align 4
  %56385 = load i64, i64* %STACK_DEP_PTR, align 4
  %56386 = sub i64 %56385, 1
  store i64 %56386, i64* %STACK_DEP_PTR, align 4
  %56387 = load i64, i64* %STACK_DEP_PTR, align 4
  %56388 = getelementptr i256, i256* %STACK, i64 %56387
  %56389 = load i256, i256* %56388, align 4
  %56390 = load i64, i64* %STACK_DEP_PTR, align 4
  %56391 = sub i64 %56390, 1
  store i64 %56391, i64* %STACK_DEP_PTR, align 4
  %56392 = load i64, i64* %STACK_DEP_PTR, align 4
  %56393 = add i64 %56392, 1
  store i64 %56393, i64* %STACK_DEP_PTR, align 4
  %56394 = load i64, i64* %STACK_DEP_PTR, align 4
  %56395 = getelementptr i256, i256* %STACK, i64 %56394
  store i256 1, i256* %56395, align 4
  %56396 = load i64, i64* %STACK_DEP_PTR, align 4
  %56397 = add i64 %56396, 1
  store i64 %56397, i64* %STACK_DEP_PTR, align 4
  %56398 = load i64, i64* %STACK_DEP_PTR, align 4
  %56399 = getelementptr i256, i256* %STACK, i64 %56398
  store i256 %56384, i256* %56399, align 4
  br label %.18946

.18946:                                           ; preds = %.18942, %56345, %JumpTable
  br label %.18947

.18947:                                           ; preds = %.18946, %56203, %JumpTable
  %56400 = load i64, i64* %remaing_gas, align 4
  %56401 = icmp ugt i64 128, %56400
  br i1 %56401, label %Abort, label %56402

56402:                                            ; preds = %.18947
  %56403 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56404 = xor i32 %56403, 1137
  %56405 = urem i32 %56404, 4096
  %56406 = getelementptr i8, i8 addrspace(1)* %4, i32 %56405
  %56407 = load i8, i8 addrspace(1)* %56406, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56406, align 1, !nosanitize !3
  store i32 568, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56408 = sub i64 %56400, 128
  store i64 %56408, i64* %remaing_gas, align 4
  %56409 = load i64, i64* %STACK_DEP_PTR, align 4
  %56410 = getelementptr i256, i256* %STACK, i64 %56409
  %56411 = load i256, i256* %56410, align 4
  %56412 = load i64, i64* %STACK_DEP_PTR, align 4
  %56413 = sub i64 %56412, 1
  store i64 %56413, i64* %STACK_DEP_PTR, align 4
  %56414 = add i256 1, %56411, !pc !829, !intsan !10
  %56415 = trunc i256 18260 to i64
  %56416 = load i64, i64* %STACK_DEP_PTR, align 4
  %56417 = add i64 %56416, 1
  store i64 %56417, i64* %STACK_DEP_PTR, align 4
  %56418 = load i64, i64* %STACK_DEP_PTR, align 4
  %56419 = getelementptr i256, i256* %STACK, i64 %56418
  store i256 %56414, i256* %56419, align 4
  br label %.18260, !EVMBB !4

.18960:                                           ; preds = %56064, %55670, %JumpTable
  %56420 = load i64, i64* %remaing_gas, align 4
  %56421 = icmp ugt i64 624, %56420
  br i1 %56421, label %Abort, label %56422

56422:                                            ; preds = %.18960
  %56423 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56424 = xor i32 %56423, 357
  %56425 = urem i32 %56424, 4096
  %56426 = getelementptr i8, i8 addrspace(1)* %4, i32 %56425
  %56427 = load i8, i8 addrspace(1)* %56426, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56426, align 1, !nosanitize !3
  store i32 178, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56428 = sub i64 %56420, 624
  store i64 %56428, i64* %remaing_gas, align 4
  %56429 = load i64, i64* %STACK_DEP_PTR, align 4
  %56430 = getelementptr i256, i256* %STACK, i64 %56429
  %56431 = load i256, i256* %56430, align 4
  %56432 = load i64, i64* %STACK_DEP_PTR, align 4
  %56433 = sub i64 %56432, 1
  store i64 %56433, i64* %STACK_DEP_PTR, align 4
  %56434 = load i64, i64* %STACK_DEP_PTR, align 4
  %56435 = getelementptr i256, i256* %STACK, i64 %56434
  %56436 = load i256, i256* %56435, align 4
  %56437 = load i64, i64* %STACK_DEP_PTR, align 4
  %56438 = sub i64 %56437, 1
  store i64 %56438, i64* %STACK_DEP_PTR, align 4
  %56439 = load i64, i64* %STACK_DEP_PTR, align 4
  %56440 = getelementptr i256, i256* %STACK, i64 %56439
  %56441 = load i256, i256* %56440, align 4
  %56442 = load i64, i64* %STACK_DEP_PTR, align 4
  %56443 = sub i64 %56442, 1
  store i64 %56443, i64* %STACK_DEP_PTR, align 4
  %56444 = load i64, i64* %STACK_DEP_PTR, align 4
  %56445 = getelementptr i256, i256* %STACK, i64 %56444
  %56446 = load i256, i256* %56445, align 4
  %56447 = load i64, i64* %STACK_DEP_PTR, align 4
  %56448 = sub i64 %56447, 1
  store i64 %56448, i64* %STACK_DEP_PTR, align 4
  %56449 = load i64, i64* %STACK_DEP_PTR, align 4
  %56450 = getelementptr i256, i256* %STACK, i64 %56449
  %56451 = load i256, i256* %56450, align 4
  %56452 = load i64, i64* %STACK_DEP_PTR, align 4
  %56453 = sub i64 %56452, 1
  store i64 %56453, i64* %STACK_DEP_PTR, align 4
  %56454 = load i64, i64* %STACK_DEP_PTR, align 4
  %56455 = getelementptr i256, i256* %STACK, i64 %56454
  %56456 = load i256, i256* %56455, align 4
  %56457 = load i64, i64* %STACK_DEP_PTR, align 4
  %56458 = sub i64 %56457, 1
  store i64 %56458, i64* %STACK_DEP_PTR, align 4
  %56459 = icmp ugt i256 %56456, 0
  %56460 = icmp eq i1 %56459, false
  %56461 = trunc i256 18978 to i64
  %jump.check244 = icmp ne i1 %56460, false
  %56462 = load i64, i64* %STACK_DEP_PTR, align 4
  %56463 = add i64 %56462, 1
  store i64 %56463, i64* %STACK_DEP_PTR, align 4
  %56464 = load i64, i64* %STACK_DEP_PTR, align 4
  %56465 = getelementptr i256, i256* %STACK, i64 %56464
  store i256 %56456, i256* %56465, align 4
  %56466 = load i64, i64* %STACK_DEP_PTR, align 4
  %56467 = add i64 %56466, 1
  store i64 %56467, i64* %STACK_DEP_PTR, align 4
  %56468 = load i64, i64* %STACK_DEP_PTR, align 4
  %56469 = getelementptr i256, i256* %STACK, i64 %56468
  store i256 %56451, i256* %56469, align 4
  %56470 = load i64, i64* %STACK_DEP_PTR, align 4
  %56471 = add i64 %56470, 1
  store i64 %56471, i64* %STACK_DEP_PTR, align 4
  %56472 = load i64, i64* %STACK_DEP_PTR, align 4
  %56473 = getelementptr i256, i256* %STACK, i64 %56472
  store i256 %56446, i256* %56473, align 4
  %56474 = load i64, i64* %STACK_DEP_PTR, align 4
  %56475 = add i64 %56474, 1
  store i64 %56475, i64* %STACK_DEP_PTR, align 4
  %56476 = load i64, i64* %STACK_DEP_PTR, align 4
  %56477 = getelementptr i256, i256* %STACK, i64 %56476
  store i256 %56441, i256* %56477, align 4
  %56478 = load i64, i64* %STACK_DEP_PTR, align 4
  %56479 = add i64 %56478, 1
  store i64 %56479, i64* %STACK_DEP_PTR, align 4
  %56480 = load i64, i64* %STACK_DEP_PTR, align 4
  %56481 = getelementptr i256, i256* %STACK, i64 %56480
  store i256 %56436, i256* %56481, align 4
  %56482 = load i64, i64* %STACK_DEP_PTR, align 4
  %56483 = add i64 %56482, 1
  store i64 %56483, i64* %STACK_DEP_PTR, align 4
  %56484 = load i64, i64* %STACK_DEP_PTR, align 4
  %56485 = getelementptr i256, i256* %STACK, i64 %56484
  store i256 %56431, i256* %56485, align 4
  br i1 %jump.check244, label %.18978, label %.18970, !EVMBB !4

.18970:                                           ; preds = %56422
  %56486 = load i64, i64* %STACK_DEP_PTR, align 4
  %56487 = getelementptr i256, i256* %STACK, i64 %56486
  %56488 = load i256, i256* %56487, align 4
  %56489 = load i64, i64* %STACK_DEP_PTR, align 4
  %56490 = sub i64 %56489, 1
  store i64 %56490, i64* %STACK_DEP_PTR, align 4
  %56491 = load i64, i64* %STACK_DEP_PTR, align 4
  %56492 = getelementptr i256, i256* %STACK, i64 %56491
  %56493 = load i256, i256* %56492, align 4
  %56494 = load i64, i64* %STACK_DEP_PTR, align 4
  %56495 = sub i64 %56494, 1
  store i64 %56495, i64* %STACK_DEP_PTR, align 4
  %56496 = load i64, i64* %STACK_DEP_PTR, align 4
  %56497 = getelementptr i256, i256* %STACK, i64 %56496
  %56498 = load i256, i256* %56497, align 4
  %56499 = load i64, i64* %STACK_DEP_PTR, align 4
  %56500 = sub i64 %56499, 1
  store i64 %56500, i64* %STACK_DEP_PTR, align 4
  %56501 = load i64, i64* %STACK_DEP_PTR, align 4
  %56502 = getelementptr i256, i256* %STACK, i64 %56501
  %56503 = load i256, i256* %56502, align 4
  %56504 = load i64, i64* %STACK_DEP_PTR, align 4
  %56505 = sub i64 %56504, 1
  store i64 %56505, i64* %STACK_DEP_PTR, align 4
  %56506 = load i64, i64* %STACK_DEP_PTR, align 4
  %56507 = getelementptr i256, i256* %STACK, i64 %56506
  %56508 = load i256, i256* %56507, align 4
  %56509 = load i64, i64* %STACK_DEP_PTR, align 4
  %56510 = sub i64 %56509, 1
  store i64 %56510, i64* %STACK_DEP_PTR, align 4
  %56511 = load i64, i64* %STACK_DEP_PTR, align 4
  %56512 = getelementptr i256, i256* %STACK, i64 %56511
  %56513 = load i256, i256* %56512, align 4
  %56514 = load i64, i64* %STACK_DEP_PTR, align 4
  %56515 = sub i64 %56514, 1
  store i64 %56515, i64* %STACK_DEP_PTR, align 4
  %56516 = alloca i256, align 8
  store i256 10, i256* %56516, align 4
  %56517 = alloca i256, align 8
  store i256 %56513, i256* %56517, align 4
  %56518 = alloca i256, align 8
  call void @__power_word(i256* %56516, i256* %56517, i256* %56518)
  %56519 = load volatile i256, i256* %56518, align 4
  %56520 = mul i256 %56498, %56519, !pc !830, !intsan !45
  %56521 = load i64, i64* %STACK_DEP_PTR, align 4
  %56522 = add i64 %56521, 1
  store i64 %56522, i64* %STACK_DEP_PTR, align 4
  %56523 = load i64, i64* %STACK_DEP_PTR, align 4
  %56524 = getelementptr i256, i256* %STACK, i64 %56523
  store i256 %56513, i256* %56524, align 4
  %56525 = load i64, i64* %STACK_DEP_PTR, align 4
  %56526 = add i64 %56525, 1
  store i64 %56526, i64* %STACK_DEP_PTR, align 4
  %56527 = load i64, i64* %STACK_DEP_PTR, align 4
  %56528 = getelementptr i256, i256* %STACK, i64 %56527
  store i256 %56508, i256* %56528, align 4
  %56529 = load i64, i64* %STACK_DEP_PTR, align 4
  %56530 = add i64 %56529, 1
  store i64 %56530, i64* %STACK_DEP_PTR, align 4
  %56531 = load i64, i64* %STACK_DEP_PTR, align 4
  %56532 = getelementptr i256, i256* %STACK, i64 %56531
  store i256 %56503, i256* %56532, align 4
  %56533 = load i64, i64* %STACK_DEP_PTR, align 4
  %56534 = add i64 %56533, 1
  store i64 %56534, i64* %STACK_DEP_PTR, align 4
  %56535 = load i64, i64* %STACK_DEP_PTR, align 4
  %56536 = getelementptr i256, i256* %STACK, i64 %56535
  store i256 %56520, i256* %56536, align 4
  %56537 = load i64, i64* %STACK_DEP_PTR, align 4
  %56538 = add i64 %56537, 1
  store i64 %56538, i64* %STACK_DEP_PTR, align 4
  %56539 = load i64, i64* %STACK_DEP_PTR, align 4
  %56540 = getelementptr i256, i256* %STACK, i64 %56539
  store i256 %56493, i256* %56540, align 4
  %56541 = load i64, i64* %STACK_DEP_PTR, align 4
  %56542 = add i64 %56541, 1
  store i64 %56542, i64* %STACK_DEP_PTR, align 4
  %56543 = load i64, i64* %STACK_DEP_PTR, align 4
  %56544 = getelementptr i256, i256* %STACK, i64 %56543
  store i256 %56488, i256* %56544, align 4
  br label %.18978

.18978:                                           ; preds = %.18970, %56422, %JumpTable
  %56545 = load i64, i64* %remaing_gas, align 4
  %56546 = icmp ugt i64 464, %56545
  br i1 %56546, label %Abort, label %56547

56547:                                            ; preds = %.18978
  %56548 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56549 = xor i32 %56548, 3750
  %56550 = urem i32 %56549, 4096
  %56551 = getelementptr i8, i8 addrspace(1)* %4, i32 %56550
  %56552 = load i8, i8 addrspace(1)* %56551, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56551, align 1, !nosanitize !3
  store i32 1875, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56553 = sub i64 %56545, 464
  store i64 %56553, i64* %remaing_gas, align 4
  %56554 = load i64, i64* %STACK_DEP_PTR, align 4
  %56555 = getelementptr i256, i256* %STACK, i64 %56554
  %56556 = load i256, i256* %56555, align 4
  %56557 = load i64, i64* %STACK_DEP_PTR, align 4
  %56558 = sub i64 %56557, 1
  store i64 %56558, i64* %STACK_DEP_PTR, align 4
  %56559 = load i64, i64* %STACK_DEP_PTR, align 4
  %56560 = getelementptr i256, i256* %STACK, i64 %56559
  %56561 = load i256, i256* %56560, align 4
  %56562 = load i64, i64* %STACK_DEP_PTR, align 4
  %56563 = sub i64 %56562, 1
  store i64 %56563, i64* %STACK_DEP_PTR, align 4
  %56564 = load i64, i64* %STACK_DEP_PTR, align 4
  %56565 = getelementptr i256, i256* %STACK, i64 %56564
  %56566 = load i256, i256* %56565, align 4
  %56567 = load i64, i64* %STACK_DEP_PTR, align 4
  %56568 = sub i64 %56567, 1
  store i64 %56568, i64* %STACK_DEP_PTR, align 4
  %56569 = load i64, i64* %STACK_DEP_PTR, align 4
  %56570 = getelementptr i256, i256* %STACK, i64 %56569
  %56571 = load i256, i256* %56570, align 4
  %56572 = load i64, i64* %STACK_DEP_PTR, align 4
  %56573 = sub i64 %56572, 1
  store i64 %56573, i64* %STACK_DEP_PTR, align 4
  %56574 = load i64, i64* %STACK_DEP_PTR, align 4
  %56575 = getelementptr i256, i256* %STACK, i64 %56574
  %56576 = load i256, i256* %56575, align 4
  %56577 = load i64, i64* %STACK_DEP_PTR, align 4
  %56578 = sub i64 %56577, 1
  store i64 %56578, i64* %STACK_DEP_PTR, align 4
  %56579 = load i64, i64* %STACK_DEP_PTR, align 4
  %56580 = getelementptr i256, i256* %STACK, i64 %56579
  %56581 = load i256, i256* %56580, align 4
  %56582 = load i64, i64* %STACK_DEP_PTR, align 4
  %56583 = sub i64 %56582, 1
  store i64 %56583, i64* %STACK_DEP_PTR, align 4
  %56584 = load i64, i64* %STACK_DEP_PTR, align 4
  %56585 = getelementptr i256, i256* %STACK, i64 %56584
  %56586 = load i256, i256* %56585, align 4
  %56587 = load i64, i64* %STACK_DEP_PTR, align 4
  %56588 = sub i64 %56587, 1
  store i64 %56588, i64* %STACK_DEP_PTR, align 4
  %56589 = load i64, i64* %STACK_DEP_PTR, align 4
  %56590 = getelementptr i256, i256* %STACK, i64 %56589
  %56591 = load i256, i256* %56590, align 4
  %56592 = load i64, i64* %STACK_DEP_PTR, align 4
  %56593 = sub i64 %56592, 1
  store i64 %56593, i64* %STACK_DEP_PTR, align 4
  %56594 = trunc i256 %56591 to i64
  store i64 %56594, i64* %JMP_TARGET_PTR, align 4
  %56595 = load i64, i64* %STACK_DEP_PTR, align 4
  %56596 = add i64 %56595, 1
  store i64 %56596, i64* %STACK_DEP_PTR, align 4
  %56597 = load i64, i64* %STACK_DEP_PTR, align 4
  %56598 = getelementptr i256, i256* %STACK, i64 %56597
  store i256 %56566, i256* %56598, align 4
  br label %JumpTable, !EVMBB !4

.18991:                                           ; preds = %55342, %55090, %54834, %JumpTable
  %56599 = load i64, i64* %remaing_gas, align 4
  %56600 = icmp ugt i64 176, %56599
  br i1 %56600, label %Abort, label %56601

56601:                                            ; preds = %.18991
  %56602 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56603 = xor i32 %56602, 1086
  %56604 = urem i32 %56603, 4096
  %56605 = getelementptr i8, i8 addrspace(1)* %4, i32 %56604
  %56606 = load i8, i8 addrspace(1)* %56605, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56605, align 1, !nosanitize !3
  store i32 543, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56607 = sub i64 %56599, 176
  store i64 %56607, i64* %remaing_gas, align 4
  %56608 = load i64, i64* %STACK_DEP_PTR, align 4
  %56609 = getelementptr i256, i256* %STACK, i64 %56608
  %56610 = load i256, i256* %56609, align 4
  %56611 = load i64, i64* %STACK_DEP_PTR, align 4
  %56612 = sub i64 %56611, 1
  store i64 %56612, i64* %STACK_DEP_PTR, align 4
  %56613 = load i64, i64* %STACK_DEP_PTR, align 4
  %56614 = getelementptr i256, i256* %STACK, i64 %56613
  %56615 = load i256, i256* %56614, align 4
  %56616 = load i64, i64* %STACK_DEP_PTR, align 4
  %56617 = sub i64 %56616, 1
  store i64 %56617, i64* %STACK_DEP_PTR, align 4
  %56618 = trunc i256 %56615 to i64
  store i64 %56618, i64* %JMP_TARGET_PTR, align 4
  %56619 = load i64, i64* %STACK_DEP_PTR, align 4
  %56620 = add i64 %56619, 1
  store i64 %56620, i64* %STACK_DEP_PTR, align 4
  %56621 = load i64, i64* %STACK_DEP_PTR, align 4
  %56622 = getelementptr i256, i256* %STACK, i64 %56621
  store i256 1, i256* %56622, align 4
  br label %JumpTable, !EVMBB !4

.19003:                                           ; preds = %JumpTable
  %56623 = load i64, i64* %remaing_gas, align 4
  %56624 = icmp ugt i64 480, %56623
  br i1 %56624, label %Abort, label %56625

56625:                                            ; preds = %.19003
  %56626 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56627 = xor i32 %56626, 4011
  %56628 = urem i32 %56627, 4096
  %56629 = getelementptr i8, i8 addrspace(1)* %4, i32 %56628
  %56630 = load i8, i8 addrspace(1)* %56629, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56629, align 1, !nosanitize !3
  store i32 2005, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56631 = sub i64 %56623, 480
  store i64 %56631, i64* %remaing_gas, align 4
  %56632 = load i64, i64* %STACK_DEP_PTR, align 4
  %56633 = getelementptr i256, i256* %STACK, i64 %56632
  %56634 = load i256, i256* %56633, align 4
  %56635 = load i64, i64* %STACK_DEP_PTR, align 4
  %56636 = sub i64 %56635, 1
  store i64 %56636, i64* %STACK_DEP_PTR, align 4
  %56637 = load i64, i64* %STACK_DEP_PTR, align 4
  %56638 = getelementptr i256, i256* %STACK, i64 %56637
  %56639 = load i256, i256* %56638, align 4
  %56640 = load i64, i64* %STACK_DEP_PTR, align 4
  %56641 = sub i64 %56640, 1
  store i64 %56641, i64* %STACK_DEP_PTR, align 4
  %56642 = load i64, i64* %STACK_DEP_PTR, align 4
  %56643 = getelementptr i256, i256* %STACK, i64 %56642
  %56644 = load i256, i256* %56643, align 4
  %56645 = load i64, i64* %STACK_DEP_PTR, align 4
  %56646 = sub i64 %56645, 1
  store i64 %56646, i64* %STACK_DEP_PTR, align 4
  %56647 = load i64, i64* %STACK_DEP_PTR, align 4
  %56648 = getelementptr i256, i256* %STACK, i64 %56647
  %56649 = load i256, i256* %56648, align 4
  %56650 = load i64, i64* %STACK_DEP_PTR, align 4
  %56651 = sub i64 %56650, 1
  store i64 %56651, i64* %STACK_DEP_PTR, align 4
  %56652 = load i64, i64* %STACK_DEP_PTR, align 4
  %56653 = getelementptr i256, i256* %STACK, i64 %56652
  %56654 = load i256, i256* %56653, align 4
  %56655 = load i64, i64* %STACK_DEP_PTR, align 4
  %56656 = sub i64 %56655, 1
  store i64 %56656, i64* %STACK_DEP_PTR, align 4
  %56657 = load i64, i64* %STACK_DEP_PTR, align 4
  %56658 = getelementptr i256, i256* %STACK, i64 %56657
  %56659 = load i256, i256* %56658, align 4
  %56660 = load i64, i64* %STACK_DEP_PTR, align 4
  %56661 = sub i64 %56660, 1
  store i64 %56661, i64* %STACK_DEP_PTR, align 4
  %56662 = alloca i256, align 8
  store i256 %56634, i256* %56662, align 4
  %56663 = alloca i256, align 8
  store i256 %56639, i256* %56663, align 4
  call void @__device_sstore(i256* %56662, i256* %56663)
  %56664 = call i32 @__hashword(i256* %56662)
  store i32 %56664, i32* %62, align 4, !nosanitize !3
  %56665 = trunc i256 %56644 to i64
  %56666 = alloca i256, align 8
  store i256 %56649, i256* %56666, align 4
  %56667 = bitcast i256* %56666 to i8*
  call void @__device_mstore(i8* %MEMORY, i64 %56665, i8* %56667, i64 32)
  %56668 = load i64, i64* %STACK_DEP_PTR, align 4
  %56669 = add i64 %56668, 1
  store i64 %56669, i64* %STACK_DEP_PTR, align 4
  %56670 = load i64, i64* %STACK_DEP_PTR, align 4
  %56671 = getelementptr i256, i256* %STACK, i64 %56670
  store i256 %56659, i256* %56671, align 4
  %56672 = load i64, i64* %STACK_DEP_PTR, align 4
  %56673 = add i64 %56672, 1
  store i64 %56673, i64* %STACK_DEP_PTR, align 4
  %56674 = load i64, i64* %STACK_DEP_PTR, align 4
  %56675 = getelementptr i256, i256* %STACK, i64 %56674
  store i256 %56654, i256* %56675, align 4
  br label %Abort, !EVMBB !4

.19009:                                           ; preds = %JumpTable
  %56676 = load i64, i64* %remaing_gas, align 4
  %56677 = icmp ugt i64 16, %56676
  br i1 %56677, label %Abort, label %56678

56678:                                            ; preds = %.19009
  %56679 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56680 = xor i32 %56679, 3145
  %56681 = urem i32 %56680, 4096
  %56682 = getelementptr i8, i8 addrspace(1)* %4, i32 %56681
  %56683 = load i8, i8 addrspace(1)* %56682, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56682, align 1, !nosanitize !3
  store i32 1572, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56684 = sub i64 %56676, 16
  store i64 %56684, i64* %remaing_gas, align 4
  br label %Abort, !EVMBB !4

.19303:                                           ; No predecessors!
  %56685 = load i64, i64* %remaing_gas, align 4
  %56686 = icmp ugt i64 80, %56685
  br i1 %56686, label %Abort, label %56687

56687:                                            ; preds = %.19303
  %56688 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56689 = xor i32 %56688, 1487
  %56690 = urem i32 %56689, 4096
  %56691 = getelementptr i8, i8 addrspace(1)* %4, i32 %56690
  %56692 = load i8, i8 addrspace(1)* %56691, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56691, align 1, !nosanitize !3
  store i32 743, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56693 = sub i64 %56685, 80
  store i64 %56693, i64* %remaing_gas, align 4
  %56694 = load i64, i64* %STACK_DEP_PTR, align 4
  %56695 = getelementptr i256, i256* %STACK, i64 %56694
  %56696 = load i256, i256* %56695, align 4
  %56697 = load i64, i64* %STACK_DEP_PTR, align 4
  %56698 = sub i64 %56697, 1
  store i64 %56698, i64* %STACK_DEP_PTR, align 4
  %56699 = trunc i32 19439 to i64
  %jump.check245 = icmp ne i256 %56696, 0
  br i1 %jump.check245, label %Abort, label %.19305, !EVMBB !4

.19305:                                           ; preds = %56687
  %56700 = load i64, i64* %remaing_gas, align 4
  %56701 = icmp ugt i64 976, %56700
  br i1 %56701, label %Abort, label %56702

56702:                                            ; preds = %.19305
  %56703 = load i32, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56704 = xor i32 %56703, 2417
  %56705 = urem i32 %56704, 4096
  %56706 = getelementptr i8, i8 addrspace(1)* %4, i32 %56705
  %56707 = load i8, i8 addrspace(1)* %56706, align 1, !nosanitize !3
  store i8 1, i8 addrspace(1)* %56706, align 1, !nosanitize !3
  store i32 1208, i32* %__afl_prev_loc, align 4, !nosanitize !3
  %56708 = sub i64 %56700, 976
  store i64 %56708, i64* %remaing_gas, align 4
  %56709 = load i64, i64* %STACK_DEP_PTR, align 4
  %56710 = getelementptr i256, i256* %STACK, i64 %56709
  %56711 = load i256, i256* %56710, align 4
  %56712 = load i64, i64* %STACK_DEP_PTR, align 4
  %56713 = sub i64 %56712, 1
  store i64 %56713, i64* %STACK_DEP_PTR, align 4
  %56714 = load i64, i64* %STACK_DEP_PTR, align 4
  %56715 = getelementptr i256, i256* %STACK, i64 %56714
  %56716 = load i256, i256* %56715, align 4
  %56717 = load i64, i64* %STACK_DEP_PTR, align 4
  %56718 = sub i64 %56717, 1
  store i64 %56718, i64* %STACK_DEP_PTR, align 4
  %56719 = load i64, i64* %STACK_DEP_PTR, align 4
  %56720 = getelementptr i256, i256* %STACK, i64 %56719
  %56721 = load i256, i256* %56720, align 4
  %56722 = load i64, i64* %STACK_DEP_PTR, align 4
  %56723 = sub i64 %56722, 1
  store i64 %56723, i64* %STACK_DEP_PTR, align 4
  %56724 = load i64, i64* %STACK_DEP_PTR, align 4
  %56725 = getelementptr i256, i256* %STACK, i64 %56724
  %56726 = load i256, i256* %56725, align 4
  %56727 = load i64, i64* %STACK_DEP_PTR, align 4
  %56728 = sub i64 %56727, 1
  store i64 %56728, i64* %STACK_DEP_PTR, align 4
  %56729 = load i64, i64* %STACK_DEP_PTR, align 4
  %56730 = getelementptr i256, i256* %STACK, i64 %56729
  %56731 = load i256, i256* %56730, align 4
  %56732 = load i64, i64* %STACK_DEP_PTR, align 4
  %56733 = sub i64 %56732, 1
  store i64 %56733, i64* %STACK_DEP_PTR, align 4
  %56734 = load i64, i64* %STACK_DEP_PTR, align 4
  %56735 = getelementptr i256, i256* %STACK, i64 %56734
  %56736 = load i256, i256* %56735, align 4
  %56737 = load i64, i64* %STACK_DEP_PTR, align 4
  %56738 = sub i64 %56737, 1
  store i64 %56738, i64* %STACK_DEP_PTR, align 4
  %56739 = load i64, i64* %STACK_DEP_PTR, align 4
  %56740 = getelementptr i256, i256* %STACK, i64 %56739
  %56741 = load i256, i256* %56740, align 4
  %56742 = load i64, i64* %STACK_DEP_PTR, align 4
  %56743 = sub i64 %56742, 1
  store i64 %56743, i64* %STACK_DEP_PTR, align 4
  %56744 = load i64, i64* %STACK_DEP_PTR, align 4
  %56745 = getelementptr i256, i256* %STACK, i64 %56744
  %56746 = load i256, i256* %56745, align 4
  %56747 = load i64, i64* %STACK_DEP_PTR, align 4
  %56748 = sub i64 %56747, 1
  store i64 %56748, i64* %STACK_DEP_PTR, align 4
  %56749 = load i64, i64* %STACK_DEP_PTR, align 4
  %56750 = add i64 %56749, 1
  store i64 %56750, i64* %STACK_DEP_PTR, align 4
  %56751 = load i64, i64* %STACK_DEP_PTR, align 4
  %56752 = getelementptr i256, i256* %STACK, i64 %56751
  store i256 %56746, i256* %56752, align 4
  %56753 = load i64, i64* %STACK_DEP_PTR, align 4
  %56754 = add i64 %56753, 1
  store i64 %56754, i64* %STACK_DEP_PTR, align 4
  %56755 = load i64, i64* %STACK_DEP_PTR, align 4
  %56756 = getelementptr i256, i256* %STACK, i64 %56755
  store i256 %56741, i256* %56756, align 4
  %56757 = load i64, i64* %STACK_DEP_PTR, align 4
  %56758 = add i64 %56757, 1
  store i64 %56758, i64* %STACK_DEP_PTR, align 4
  %56759 = load i64, i64* %STACK_DEP_PTR, align 4
  %56760 = getelementptr i256, i256* %STACK, i64 %56759
  store i256 %56736, i256* %56760, align 4
  %56761 = load i64, i64* %STACK_DEP_PTR, align 4
  %56762 = add i64 %56761, 1
  store i64 %56762, i64* %STACK_DEP_PTR, align 4
  %56763 = load i64, i64* %STACK_DEP_PTR, align 4
  %56764 = getelementptr i256, i256* %STACK, i64 %56763
  store i256 %56731, i256* %56764, align 4
  %56765 = load i64, i64* %STACK_DEP_PTR, align 4
  %56766 = add i64 %56765, 1
  store i64 %56766, i64* %STACK_DEP_PTR, align 4
  %56767 = load i64, i64* %STACK_DEP_PTR, align 4
  %56768 = getelementptr i256, i256* %STACK, i64 %56767
  store i256 %56726, i256* %56768, align 4
  %56769 = load i64, i64* %STACK_DEP_PTR, align 4
  %56770 = add i64 %56769, 1
  store i64 %56770, i64* %STACK_DEP_PTR, align 4
  %56771 = load i64, i64* %STACK_DEP_PTR, align 4
  %56772 = getelementptr i256, i256* %STACK, i64 %56771
  store i256 %56721, i256* %56772, align 4
  %56773 = load i64, i64* %STACK_DEP_PTR, align 4
  %56774 = add i64 %56773, 1
  store i64 %56774, i64* %STACK_DEP_PTR, align 4
  %56775 = load i64, i64* %STACK_DEP_PTR, align 4
  %56776 = getelementptr i256, i256* %STACK, i64 %56775
  store i256 %56716, i256* %56776, align 4
  %56777 = load i64, i64* %STACK_DEP_PTR, align 4
  %56778 = add i64 %56777, 1
  store i64 %56778, i64* %STACK_DEP_PTR, align 4
  %56779 = load i64, i64* %STACK_DEP_PTR, align 4
  %56780 = getelementptr i256, i256* %STACK, i64 %56779
  store i256 159955360787605753402264203559824668022, i256* %56780, align 4
  %56781 = load i64, i64* %STACK_DEP_PTR, align 4
  %56782 = add i64 %56781, 1
  store i64 %56782, i64* %STACK_DEP_PTR, align 4
  %56783 = load i64, i64* %STACK_DEP_PTR, align 4
  %56784 = getelementptr i256, i256* %STACK, i64 %56783
  store i256 27453, i256* %56784, align 4
  %56785 = load i64, i64* %STACK_DEP_PTR, align 4
  %56786 = add i64 %56785, 1
  store i64 %56786, i64* %STACK_DEP_PTR, align 4
  %56787 = load i64, i64* %STACK_DEP_PTR, align 4
  %56788 = getelementptr i256, i256* %STACK, i64 %56787
  store i256 304605075877851273647341071130343538454271475524790543591481478372612969, i256* %56788, align 4
  %56789 = load i64, i64* %STACK_DEP_PTR, align 4
  %56790 = add i64 %56789, 1
  store i64 %56790, i64* %STACK_DEP_PTR, align 4
  %56791 = load i64, i64* %STACK_DEP_PTR, align 4
  %56792 = getelementptr i256, i256* %STACK, i64 %56791
  store i256 435644819828, i256* %56792, align 4
  %56793 = load i64, i64* %STACK_DEP_PTR, align 4
  %56794 = add i64 %56793, 1
  store i64 %56794, i64* %STACK_DEP_PTR, align 4
  %56795 = load i64, i64* %STACK_DEP_PTR, align 4
  %56796 = getelementptr i256, i256* %STACK, i64 %56795
  store i256 149646951034717963387135531333868995886460778107270324874206496, i256* %56796, align 4
  br label %Abort, !EVMBB !4

JumpTable:                                        ; preds = %56547, %54365, %49168, %47350, %45038, %43725, %38981, %36253, %33923, %28453, %26250, %24629, %23112, %21732, %21391, %20503, %18888, %14521, %14390, %6194, %5927, %31221, %54325, %30552, %31241, %30776, %27083, %30070, %29260, %29474, %27372, %27786, %22649, %50362, %25523, %25084, %24881, %24678, %46245, %44964, %23323, %55603, %56601, %19156, %34680, %18948, %12598, %13289, %11923, %9641, %10712, %10926, %10459, %53131, %7506
  %56797 = load i64, i64* %JMP_TARGET_PTR, align 4
  switch i64 %56797, label %Abort [
    i64 505, label %.505
    i64 515, label %.515
    i64 3091, label %.3091
    i64 538, label %.538
    i64 527, label %.527
    i64 3122, label %.3122
    i64 661, label %.661
    i64 550, label %.550
    i64 4087, label %.4087
    i64 3255, label %.3255
    i64 704, label %.704
    i64 673, label %.673
    i64 4175, label %.4175
    i64 4164, label %.4164
    i64 3275, label %.3275
    i64 714, label %.714
    i64 4367, label %.4367
    i64 4358, label %.4358
    i64 13000, label %.13000
    i64 3297, label %.3297
    i64 801, label %.801
    i64 726, label %.726
    i64 4394, label %.4394
    i64 4209, label %.4209
    i64 16448, label %.16448
    i64 3488, label %.3488
    i64 824, label %.824
    i64 813, label %.813
    i64 4443, label %.4443
    i64 4412, label %.4412
    i64 4359, label %.4359
    i64 17009, label %.17009
    i64 3508, label %.3508
    i64 867, label %.867
    i64 836, label %.836
    i64 4555, label %.4555
    i64 4547, label %.4547
    i64 4426, label %.4426
    i64 581, label %.581
    i64 13014, label %.13014
    i64 3530, label %.3530
    i64 954, label %.954
    i64 879, label %.879
    i64 4720, label %.4720
    i64 4647, label %.4647
    i64 11521, label %.11521
    i64 4440, label %.4440
    i64 11418, label %.11418
    i64 3563, label %.3563
    i64 1001, label %.1001
    i64 966, label %.966
    i64 4726, label %.4726
    i64 845, label %.845
    i64 822, label %.822
    i64 3579, label %.3579
    i64 1068, label %.1068
    i64 1013, label %.1013
    i64 4838, label %.4838
    i64 4830, label %.4830
    i64 3591, label %.3591
    i64 1091, label %.1091
    i64 1080, label %.1080
    i64 5238, label %.5238
    i64 4915, label %.4915
    i64 11532, label %.11532
    i64 3614, label %.3614
    i64 1210, label %.1210
    i64 1103, label %.1103
    i64 5641, label %.5641
    i64 5330, label %.5330
    i64 4988, label %.4988
    i64 11551, label %.11551
    i64 3637, label %.3637
    i64 1399, label %.1399
    i64 1222, label %.1222
    i64 5836, label %.5836
    i64 5736, label %.5736
    i64 5388, label %.5388
    i64 5015, label %.5015
    i64 11563, label %.11563
    i64 4077, label %.4077
    i64 1446, label %.1446
    i64 1411, label %.1411
    i64 5903, label %.5903
    i64 5893, label %.5893
    i64 1066, label %.1066
    i64 999, label %.999
    i64 11577, label %.11577
    i64 11875, label %.11875
    i64 1573, label %.1573
    i64 1458, label %.1458
    i64 7030, label %.7030
    i64 14033, label %.14033
    i64 11585, label %.11585
    i64 11954, label %.11954
    i64 1616, label %.1616
    i64 1585, label %.1585
    i64 7049, label %.7049
    i64 1420, label %.1420
    i64 14110, label %.14110
    i64 13089, label %.13089
    i64 17834, label %.17834
    i64 12087, label %.12087
    i64 1683, label %.1683
    i64 1628, label %.1628
    i64 7136, label %.7136
    i64 1489, label %.1489
    i64 14243, label %.14243
    i64 13938, label %.13938
    i64 18991, label %.18991
    i64 12107, label %.12107
    i64 1775, label %.1775
    i64 1695, label %.1695
    i64 7318, label %.7318
    i64 14263, label %.14263
    i64 13178, label %.13178
    i64 17866, label %.17866
    i64 12129, label %.12129
    i64 1854, label %.1854
    i64 1787, label %.1787
    i64 7683, label %.7683
    i64 7347, label %.7347
    i64 14285, label %.14285
    i64 13753, label %.13753
    i64 17965, label %.17965
    i64 1921, label %.1921
    i64 1866, label %.1866
    i64 7777, label %.7777
    i64 7439, label %.7439
    i64 14500, label %.14500
    i64 14584, label %.14584
    i64 18230, label %.18230
    i64 2015, label %.2015
    i64 1933, label %.1933
    i64 8000, label %.8000
    i64 7869, label %.7869
    i64 14520, label %.14520
    i64 14642, label %.14642
    i64 11952, label %.11952
    i64 2058, label %.2058
    i64 2027, label %.2027
    i64 8183, label %.8183
    i64 8092, label %.8092
    i64 7951, label %.7951
    i64 14542, label %.14542
    i64 15310, label %.15310
    i64 14722, label %.14722
    i64 2101, label %.2101
    i64 2070, label %.2070
    i64 8233, label %.8233
    i64 1942, label %.1942
    i64 8119, label %.8119
    i64 15876, label %.15876
    i64 5913, label %.5913
    i64 13782, label %.13782
    i64 15202, label %.15202
    i64 2144, label %.2144
    i64 2113, label %.2113
    i64 8716, label %.8716
    i64 8371, label %.8371
    i64 15952, label %.15952
    i64 5970, label %.5970
    i64 15201, label %.15201
    i64 2231, label %.2231
    i64 2156, label %.2156
    i64 8722, label %.8722
    i64 2079, label %.2079
    i64 8391, label %.8391
    i64 16085, label %.16085
    i64 6091, label %.6091
    i64 15200, label %.15200
    i64 2304, label %.2304
    i64 2243, label %.2243
    i64 8728, label %.8728
    i64 2122, label %.2122
    i64 8413, label %.8413
    i64 16105, label %.16105
    i64 6136, label %.6136
    i64 2347, label %.2347
    i64 2316, label %.2316
    i64 8752, label %.8752
    i64 2209, label %.2209
    i64 8604, label %.8604
    i64 16127, label %.16127
    i64 14564, label %.14564
    i64 2390, label %.2390
    i64 2359, label %.2359
    i64 8787, label %.8787
    i64 8767, label %.8767
    i64 8624, label %.8624
    i64 16421, label %.16421
    i64 18235, label %.18235
    i64 2457, label %.2457
    i64 2402, label %.2402
    i64 8890, label %.8890
    i64 8881, label %.8881
    i64 2274, label %.2274
    i64 8646, label %.8646
    i64 16441, label %.16441
    i64 2544, label %.2544
    i64 2469, label %.2469
    i64 9337, label %.9337
    i64 9026, label %.9026
    i64 7997, label %.7997
    i64 2554, label %.2554
    i64 9778, label %.9778
    i64 9740, label %.9740
    i64 9429, label %.9429
    i64 9046, label %.9046
    i64 1852, label %.1852
    i64 2577, label %.2577
    i64 2566, label %.2566
    i64 9804, label %.9804
    i64 2478, label %.2478
    i64 9487, label %.9487
    i64 9068, label %.9068
    i64 2704, label %.2704
    i64 2589, label %.2589
    i64 10020, label %.10020
    i64 9818, label %.9818
    i64 2455, label %.2455
    i64 9259, label %.9259
    i64 2747, label %.2747
    i64 2716, label %.2716
    i64 10185, label %.10185
    i64 10112, label %.10112
    i64 9895, label %.9895
    i64 9279, label %.9279
    i64 2792, label %.2792
    i64 2759, label %.2759
    i64 10259, label %.10259
    i64 2624, label %.2624
    i64 2575, label %.2575
    i64 9301, label %.9301
    i64 2879, label %.2879
    i64 2804, label %.2804
    i64 10265, label %.10265
    i64 2725, label %.2725
    i64 2368, label %.2368
    i64 2928, label %.2928
    i64 2891, label %.2891
    i64 10470, label %.10470
    i64 10357, label %.10357
    i64 2971, label %.2971
    i64 2940, label %.2940
    i64 10508, label %.10508
    i64 2813, label %.2813
    i64 10379, label %.10379
    i64 2994, label %.2994
    i64 2983, label %.2983
    i64 10612, label %.10612
    i64 10600, label %.10600
    i64 10394, label %.10394
    i64 3081, label %.3081
    i64 3006, label %.3006
    i64 10625, label %.10625
    i64 2949, label %.2949
    i64 17016, label %.17016
    i64 2790, label %.2790
    i64 11593, label %.11593
    i64 10722, label %.10722
    i64 17092, label %.17092
    i64 11621, label %.11621
    i64 10795, label %.10795
    i64 17225, label %.17225
    i64 11635, label %.11635
    i64 10822, label %.10822
    i64 17245, label %.17245
    i64 11713, label %.11713
    i64 10845, label %.10845
    i64 17267, label %.17267
    i64 17501, label %.17501
    i64 17521, label %.17521
    i64 10609, label %.10609
    i64 2926, label %.2926
    i64 513, label %.513
    i64 536, label %.536
    i64 682, label %.682
    i64 712, label %.712
    i64 779, label %.779
    i64 932, label %.932
    i64 1089, label %.1089
    i64 1208, label %.1208
    i64 1397, label %.1397
    i64 1594, label %.1594
    i64 1681, label %.1681
    i64 1704, label %.1704
    i64 1919, label %.1919
    i64 2036, label %.2036
    i64 2325, label %.2325
    i64 2552, label %.2552
    i64 2992, label %.2992
    i64 3059, label %.3059
    i64 3089, label %.3089
    i64 3848, label %.3848
    i64 4082, label %.4082
    i64 4173, label %.4173
    i64 5746, label %.5746
    i64 5819, label %.5819
    i64 5832, label %.5832
    i64 5899, label %.5899
    i64 6149, label %.6149
    i64 6167, label %.6167
    i64 6209, label %.6209
    i64 6354, label %.6354
    i64 6359, label %.6359
    i64 6371, label %.6371
    i64 6383, label %.6383
    i64 6436, label %.6436
    i64 6489, label %.6489
    i64 6503, label %.6503
    i64 6694, label %.6694
    i64 6848, label %.6848
    i64 6871, label %.6871
    i64 7011, label %.7011
    i64 7016, label %.7016
    i64 7017, label %.7017
    i64 7019, label %.7019
    i64 7150, label %.7150
    i64 7224, label %.7224
    i64 7287, label %.7287
    i64 7297, label %.7297
    i64 7310, label %.7310
    i64 7444, label %.7444
    i64 7506, label %.7506
    i64 7706, label %.7706
    i64 7716, label %.7716
    i64 8128, label %.8128
    i64 8690, label %.8690
    i64 8703, label %.8703
    i64 8809, label %.8809
    i64 8874, label %.8874
    i64 8886, label %.8886
    i64 9903, label %.9903
    i64 10876, label %.10876
    i64 10982, label %.10982
    i64 10995, label %.10995
    i64 11012, label %.11012
    i64 11258, label %.11258
    i64 11403, label %.11403
    i64 11408, label %.11408
    i64 11413, label %.11413
    i64 11721, label %.11721
    i64 11734, label %.11734
    i64 11742, label %.11742
    i64 11761, label %.11761
    i64 11826, label %.11826
    i64 11827, label %.11827
    i64 11856, label %.11856
    i64 11872, label %.11872
    i64 12360, label %.12360
    i64 12387, label %.12387
    i64 12432, label %.12432
    i64 12464, label %.12464
    i64 12484, label %.12484
    i64 12506, label %.12506
    i64 12557, label %.12557
    i64 12721, label %.12721
    i64 12748, label %.12748
    i64 12793, label %.12793
    i64 12823, label %.12823
    i64 12850, label %.12850
    i64 12895, label %.12895
    i64 12929, label %.12929
    i64 12949, label %.12949
    i64 12972, label %.12972
    i64 12992, label %.12992
    i64 13826, label %.13826
    i64 14010, label %.14010
    i64 14026, label %.14026
    i64 14108, label %.14108
    i64 14577, label %.14577
    i64 15314, label %.15314
    i64 15354, label %.15354
    i64 15490, label %.15490
    i64 15517, label %.15517
    i64 15527, label %.15527
    i64 15550, label %.15550
    i64 15556, label %.15556
    i64 15700, label %.15700
    i64 15735, label %.15735
    i64 15750, label %.15750
    i64 15760, label %.15760
    i64 15801, label %.15801
    i64 15868, label %.15868
    i64 15869, label %.15869
    i64 15950, label %.15950
    i64 16483, label %.16483
    i64 16560, label %.16560
    i64 16571, label %.16571
    i64 16659, label %.16659
    i64 16816, label %.16816
    i64 16888, label %.16888
    i64 16949, label %.16949
    i64 16962, label %.16962
    i64 17090, label %.17090
    i64 17528, label %.17528
    i64 17996, label %.17996
    i64 18095, label %.18095
    i64 18126, label %.18126
    i64 18225, label %.18225
    i64 18260, label %.18260
    i64 18319, label %.18319
    i64 18487, label %.18487
    i64 18599, label %.18599
    i64 18624, label %.18624
    i64 18634, label %.18634
    i64 18656, label %.18656
    i64 18776, label %.18776
    i64 18826, label %.18826
    i64 18946, label %.18946
    i64 18947, label %.18947
    i64 18960, label %.18960
    i64 18978, label %.18978
    i64 19003, label %.19003
    i64 19009, label %.19009
  ]

Abort:                                            ; preds = %.19305, %.19303, %.19009, %.19003, %.18991, %.18978, %.18960, %.18947, %.18826, %.18825, %.18776, %.18656, %.18655, %.18634, %.18620, %.18611, %.18605, %.18599, %.18486, %.18437, %.18319, %.18318, %.18270, %.18260, %.18230, %.18133, %.18126, %.18095, %.18003, %.17996, %.17965, %.17873, %.17866, %.17834, %.17528, %.17521, %.17512, %.17501, %.17497, %.17267, %.17263, %.17245, %.17236, %.17225, %.17221, %.17092, %.17081, %.17016, %.17009, %.16949, %.16888, %.16665, %.16659, %.16571, %.16560, %.16495, %.16483, %.16448, %.16441, %.16432, %.16421, %.16417, %.16127, %.16123, %.16105, %.16096, %.16085, %.16081, %.15952, %.15941, %.15876, %.15869, %.15801, %.15800, %.15760, %.15756, %.15750, %.15735, %.15700, %.15575, %.15556, %.15550, %.15523, %.15517, %.15490, %.15354, %.15353, %.15331, %.15314, %.15310, %.14971, %.14777, %.14722, %.14674, %.14642, %.14594, %.14584, %.14577, %.14564, %.14542, %.14538, %.14520, %.14511, %.14500, %.14496, %.14285, %.14281, %.14263, %.14254, %.14243, %.14239, %.14110, %.14099, %.14033, %.14026, %.14022, %.14010, %.13826, %.13782, %.13753, %.13178, %.13177, %.13125, %.13089, %.13014, %.13000, %.12992, %.12968, %.12949, %.12940, %.12929, %.12925, %.12895, %.12850, %.12832, %.12823, %.12748, %.12730, %.12721, %.12546, %.12506, %.12502, %.12484, %.12475, %.12464, %.12460, %.12432, %.12387, %.12369, %.12360, %.12125, %.12107, %.12098, %.12087, %.12083, %.11954, %.11943, %.11875, %.11872, %.11868, %.11856, %.11827, %.11761, %.11754, %.11742, %.11734, %.11730, %.11721, %.11713, %.11709, %.11635, %.11631, %.11621, %.11617, %.11593, %.11585, %.11569, %.11563, %.11551, %.11532, %.11521, %.11418, %.11413, %.11408, %.11403, %.11118, %.11022, %.11012, %.11011, %.10995, %.10982, %.10888, %.10876, %.10841, %.10822, %.10818, %.10795, %.10791, %.10722, %.10718, %.10625, %.10612, %.10609, %.10600, %.10596, %.10508, %.10470, %.10394, %.10390, %.10379, %.10375, %.10357, %.10353, %.10265, %.10259, %.10185, %.10112, %.10108, %.10020, %.9903, %.9895, %.9891, %.9818, %.9814, %.9804, %.9800, %.9778, %.9740, %.9487, %.9483, %.9429, %.9425, %.9337, %.9301, %.9297, %.9279, %.9270, %.9259, %.9255, %.9068, %.9064, %.9046, %.9037, %.9026, %.9022, %.8890, %.8886, %.8874, %.8809, %.8802, %.8787, %.8767, %.8766, %.8752, %.8728, %.8722, %.8716, %.8703, %.8702, %.8690, %.8646, %.8642, %.8624, %.8615, %.8604, %.8600, %.8413, %.8409, %.8391, %.8382, %.8371, %.8367, %.8233, %.8183, %.8128, %.8119, %.8115, %.8092, %.8088, %.8000, %.7997, %.7951, %.7947, %.7869, %.7865, %.7777, %.7716, %.7706, %.7683, %.7506, %.7456, %.7444, %.7435, %.7347, %.7343, %.7318, %.7310, %.7297, %.7287, %.7224, %.7162, %.7150, %.7049, %.7030, %.7019, %.7011, %.6871, %.6848, %.6694, %.6503, %.6495, %.6489, %.6436, %.6435, %.6383, %.6382, %.6371, %.6359, %.6354, %.6215, %.6209, %.6167, %.6149, %.6136, %.6132, %.6091, %.6087, %.5970, %.5966, %.5913, %.5903, %.5899, %.5893, %.5836, %.5832, %.5819, %.5756, %.5746, %.5732, %.5641, %.5388, %.5384, %.5330, %.5326, %.5238, %.5015, %.5011, %.4988, %.4984, %.4915, %.4911, %.4838, %.4830, %.4829, %.4726, %.4720, %.4647, %.4643, %.4555, %.4547, %.4546, %.4443, %.4440, %.4418, %.4412, %.4394, %.4367, %.4359, %.4209, %.4208, %.4195, %.4175, %.4173, %.4164, %.4160, %.4087, %.4082, %.4077, %.3848, %.3643, %.3637, %.3614, %.3613, %.3591, %.3590, %.3579, %.3563, %.3559, %.3530, %.3526, %.3508, %.3499, %.3488, %.3484, %.3297, %.3293, %.3275, %.3266, %.3255, %.3251, %.3122, %.3118, %.3091, %.3089, %.3081, %.3059, %.3006, %.3002, %.2994, %.2992, %.2983, %.2979, %.2971, %.2949, %.2940, %.2936, %.2928, %.2926, %.2891, %.2887, %.2879, %.2813, %.2804, %.2800, %.2792, %.2790, %.2759, %.2755, %.2747, %.2725, %.2716, %.2712, %.2704, %.2624, %.2589, %.2585, %.2577, %.2575, %.2566, %.2562, %.2554, %.2552, %.2544, %.2478, %.2469, %.2465, %.2457, %.2455, %.2402, %.2398, %.2390, %.2368, %.2359, %.2355, %.2347, %.2325, %.2316, %.2312, %.2304, %.2274, %.2243, %.2239, %.2231, %.2209, %.2156, %.2152, %.2144, %.2122, %.2113, %.2109, %.2101, %.2079, %.2070, %.2066, %.2058, %.2036, %.2027, %.2023, %.2015, %.1942, %.1933, %.1929, %.1921, %.1919, %.1866, %.1862, %.1854, %.1852, %.1787, %.1783, %.1775, %.1704, %.1695, %.1691, %.1683, %.1681, %.1628, %.1624, %.1616, %.1594, %.1585, %.1581, %.1573, %.1489, %.1458, %.1454, %.1446, %.1420, %.1411, %.1407, %.1399, %.1397, %.1222, %.1218, %.1210, %.1208, %.1103, %.1099, %.1091, %.1089, %.1080, %.1076, %.1068, %.1066, %.1013, %.1009, %.1001, %.999, %.966, %.962, %.954, %.932, %.879, %.875, %.867, %.845, %.836, %.832, %.824, %.822, %.813, %.809, %.801, %.779, %.726, %.722, %.714, %.712, %.704, %.682, %.673, %.669, %.661, %.581, %.550, %.546, %.538, %.536, %.527, %.523, %.515, %.513, %.505, %.494, %.483, %.472, %.461, %.450, %.439, %.428, %.417, %.406, %.395, %.384, %.373, %.362, %.351, %.340, %.329, %.318, %.307, %.296, %.285, %.274, %.263, %.252, %.241, %.230, %.219, %.208, %.197, %.186, %.175, %.164, %.153, %.142, %.131, %.120, %.109, %.98, %.87, %.76, %.65, %.13, %.0, %56687, %56702, %56678, %56625, %56336, %56194, %55910, %55786, %48546, %48279, %47116, %46362, %43716, %40161, %38939, %38880, %38817, %37802, %37748, %37685, %36244, %35209, %33914, %33179, %25514, %24620, %16417, %16159, %11914, %10450, %6649, %JumpTable, %5063, %4995, %54314, %54249, %53765, %32272, %35167, %53709, %32069, %34948, %53644, %31863, %34924, %31653, %3744, %30541, %31185, %3689, %30509, %3618, %30474, %3549, %3476, %27072, %3409, %27016, %28430, %29251, %3338, %26951, %28212, %3233, %26660, %27361, %28190, %3178, %26604, %27329, %26539, %3082, %50351, %24514, %3014, %50286, %24458, %2943, %49802, %24393, %2872, %15123, %49746, %24102, %2785, %14852, %49681, %24046, %2701, %14585, %23981, %2630, %23076, %2559, %44953, %22609, %22870, %2488, %44897, %22576, %2406, %44832, %20950, %2338, %44365, %20738, %2269, %36877, %44309, %2135, %36821, %44244, %2067, %36756, %1996, %1888, %1812, %5918, %12589, %13278, %13912, %1669, %12383, %13246, %1563, %12175, %1508, %1440, %1370, %4906, %10703, %1286, %4839, %1215, %4783, %1160, %4718, %1076, %4427, %4371, %6166, %982, %4306, %879, %4043, %824
  call void @free(i8* %MEMORY)
  call void @free(i8* %63)
  ret i32 0

Exit:                                             ; preds = %3826, %3787, %3719, %3153, %2902, %2518, %2381, %2165, %2110, %2026, %1787, %1644, %1538, %1329, %1119, %1051, %1012, %854, %799, %3593, %3451, %3648, %3506, %2973, %3368, %3208, %3277, %3057, %3112, %2313, %2827, %2744, %2660, %2589, %2436, %1930, %1842, %1415, %1483, %1190, %1245, %921
  call void @free(i8* %MEMORY)
  call void @free(i8* %63)
  ret i32 1
}

; Function Attrs: nounwind
declare noalias i8* @malloc(i64) #1

declare void @__device_mstore(i8*, i64, i8*, i64)

declare void @__device_calldataload(i8*, i8*, i64)

; Function Attrs: nounwind readnone
define internal void @evm.udivrem.i256(i256* %x_ptr, i256* %y_ptr, i256* %q_Ptr, i256* %r_ptr) #0 {
Entry:
  %0 = load i256, i256* %x_ptr, align 4
  %1 = load i256, i256* %y_ptr, align 4
  %2 = icmp ule i256 %1, %0
  br i1 %2, label %Main, label %Return

Main:                                             ; preds = %Entry
  %y.lz = call i256 @llvm.ctlz.i256(i256 %1, i1 false)
  %r.lz = call i256 @llvm.ctlz.i256(i256 %0, i1 false)
  %i0 = sub nuw i256 %y.lz, %r.lz
  br label %beforeloopY

beforeloopY:                                      ; preds = %LoopY, %Main
  %i0.phi = phi i256 [ %i0, %Main ], [ %4, %LoopY ]
  %y0 = phi i256 [ %1, %Main ], [ %3, %LoopY ]
  %i0.nonzero = icmp ne i256 %i0.phi, 0
  br i1 %i0.nonzero, label %LoopY, label %Loop

LoopY:                                            ; preds = %beforeloopY
  %3 = shl i256 %y0, 1
  %4 = sub i256 %i0.phi, 1
  br label %beforeloopY

Loop:                                             ; preds = %Continue, %beforeloopY
  %y.phi = phi i256 [ %y0, %beforeloopY ], [ %11, %Continue ]
  %r.phi = phi i256 [ %0, %beforeloopY ], [ %r1, %Continue ]
  %i.phi = phi i256 [ %i0, %beforeloopY ], [ %9, %Continue ]
  %q.phi = phi i256 [ 0, %beforeloopY ], [ %10, %Continue ]
  %5 = sub nuw i256 %r.phi, %y.phi
  %6 = or i256 %q.phi, 1
  %7 = icmp uge i256 %r.phi, %y.phi
  %r1 = select i1 %7, i256 %5, i256 %r.phi
  %q = select i1 %7, i256 %6, i256 %q.phi
  %8 = icmp eq i256 %i.phi, 0
  br i1 %8, label %Return, label %Continue

Continue:                                         ; preds = %Loop
  %9 = sub nuw i256 %i.phi, 1
  %10 = shl i256 %q, 1
  %11 = lshr i256 %y.phi, 1
  br label %Loop

Return:                                           ; preds = %Loop, %Entry
  %q.ret = phi i256 [ 0, %Entry ], [ %q, %Loop ]
  %r.ret = phi i256 [ %0, %Entry ], [ %r1, %Loop ]
  store i256 %q.ret, i256* %q_Ptr, align 4
  store i256 %r.ret, i256* %r_ptr, align 4
  ret void
}

; Function Attrs: nofree nosync nounwind readnone speculatable willreturn
declare i256 @llvm.ctlz.i256(i256, i1 immarg) #2

; Function Attrs: nounwind
define internal void @evm.udiv.i256(i256* %_x_ptr, i256* %_y_ptr, i256* %_q_ptr) #1 {
  %1 = alloca i256, align 8
  call void @evm.udivrem.i256(i256* %_x_ptr, i256* %_y_ptr, i256* %_q_ptr, i256* %1)
  ret void
}

declare void @__device_sload(i256*, i256*)

declare void @__device_mload(i8*, i64, i256*)

declare void @__device_sha3(i8*, i32, i8*)

; Function Attrs: nounwind
define internal i1 @solidity_call() #1 {
entry:
  ret i1 true
}

declare void @__device_sstore(i256*, i256*)

declare void @addBugSet(i64)

declare void @__device_calldatacpy(i8*, i64, i8*, i64, i64)

; Function Attrs: argmemonly nofree nounwind willreturn
declare void @llvm.memcpy.p0i8.p4i8.i32(i8* noalias nocapture writeonly, i8 addrspace(4)* noalias nocapture readonly, i32, i1 immarg) #3

declare void @__power_word(i256*, i256*, i256*)

; Function Attrs: nounwind
declare void @free(i8* nocapture) #1

declare void @main_contract(i8 addrspace(1)*, i32)

declare i32 @__hashword(i256*)

attributes #0 = { nounwind readnone }
attributes #1 = { nounwind }
attributes #2 = { nofree nosync nounwind readnone speculatable willreturn }
attributes #3 = { argmemonly nofree nounwind willreturn }

!nvvm.annotations = !{!0, !1, !2}

!0 = !{void (i64 addrspace(1)*)* @updateBits, !"kernel", i32 1}
!1 = !{void (i8 addrspace(1)*, i32)* @parallel_mutate, !"kernel", i32 1}
!2 = !{void (i8 addrspace(1)*, i32)* @main_contract, !"kernel", i32 1}
!3 = !{}
!4 = !{!"BB"}
!5 = !{i32 47}
!6 = !{!"udiv"}
!7 = !{i32 559}
!8 = !{!"sub"}
!9 = !{i32 561}
!10 = !{!"add"}
!11 = !{i32 569}
!12 = !{i32 635}
!13 = !{i32 641}
!14 = !{i32 647}
!15 = !{i32 658}
!16 = !{i32 692}
!17 = !{i32 701}
!18 = !{i32 735}
!19 = !{i32 737}
!20 = !{i32 767}
!21 = !{i32 789}
!22 = !{i32 798}
!23 = !{i32 855}
!24 = !{i32 864}
!25 = !{i32 888}
!26 = !{i32 890}
!27 = !{i32 920}
!28 = !{i32 942}
!29 = !{i32 951}
!30 = !{i32 975}
!31 = !{i32 977}
!32 = !{i32 987}
!33 = !{i32 1022}
!34 = !{i32 1024}
!35 = !{i32 1054}
!36 = !{i32 1112}
!37 = !{i32 1114}
!38 = !{i32 1126}
!39 = !{i32 1136}
!40 = !{i32 1139}
!41 = !{i32 1145}
!42 = !{i32 1151}
!43 = !{i32 1156}
!44 = !{i32 1157}
!45 = !{!"mul"}
!46 = !{i32 1160}
!47 = !{i32 1166}
!48 = !{i32 1180}
!49 = !{i32 1188}
!50 = !{i32 1231}
!51 = !{i32 1233}
!52 = !{i32 1245}
!53 = !{i32 1255}
!54 = !{i32 1258}
!55 = !{i32 1264}
!56 = !{i32 1270}
!57 = !{i32 1275}
!58 = !{i32 1276}
!59 = !{i32 1279}
!60 = !{i32 1285}
!61 = !{i32 1299}
!62 = !{i32 1307}
!63 = !{i32 1325}
!64 = !{i32 1328}
!65 = !{i32 1334}
!66 = !{i32 1340}
!67 = !{i32 1345}
!68 = !{i32 1346}
!69 = !{i32 1349}
!70 = !{i32 1355}
!71 = !{i32 1369}
!72 = !{i32 1377}
!73 = !{i32 1434}
!74 = !{i32 1443}
!75 = !{i32 1467}
!76 = !{i32 1469}
!77 = !{i32 1477}
!78 = !{i32 1543}
!79 = !{i32 1549}
!80 = !{i32 1559}
!81 = !{i32 1570}
!82 = !{i32 1604}
!83 = !{i32 1613}
!84 = !{i32 1637}
!85 = !{i32 1639}
!86 = !{i32 1669}
!87 = !{i32 1714}
!88 = !{i32 1720}
!89 = !{i32 1726}
!90 = !{i32 1732}
!91 = !{i32 1738}
!92 = !{i32 1744}
!93 = !{i32 1750}
!94 = !{i32 1756}
!95 = !{i32 1772}
!96 = !{i32 1796}
!97 = !{i32 1798}
!98 = !{i32 1840}
!99 = !{i32 1875}
!100 = !{i32 1877}
!101 = !{i32 1907}
!102 = !{i32 1996}
!103 = !{i32 2002}
!104 = !{i32 2012}
!105 = !{i32 2046}
!106 = !{i32 2055}
!107 = !{i32 2089}
!108 = !{i32 2098}
!109 = !{i32 2132}
!110 = !{i32 2141}
!111 = !{i32 2165}
!112 = !{i32 2167}
!113 = !{i32 2197}
!114 = !{i32 2219}
!115 = !{i32 2228}
!116 = !{i32 2252}
!117 = !{i32 2254}
!118 = !{i32 2262}
!119 = !{i32 2292}
!120 = !{i32 2301}
!121 = !{i32 2335}
!122 = !{i32 2344}
!123 = !{i32 2378}
!124 = !{i32 2387}
!125 = !{i32 2411}
!126 = !{i32 2413}
!127 = !{i32 2443}
!128 = !{i32 2532}
!129 = !{i32 2541}
!130 = !{i32 2598}
!131 = !{i32 2600}
!132 = !{i32 2612}
!133 = !{i32 2678}
!134 = !{i32 2684}
!135 = !{i32 2690}
!136 = !{i32 2701}
!137 = !{i32 2735}
!138 = !{i32 2744}
!139 = !{i32 2768}
!140 = !{i32 2770}
!141 = !{i32 2778}
!142 = !{i32 2867}
!143 = !{i32 2876}
!144 = !{i32 2900}
!145 = !{i32 2902}
!146 = !{i32 2914}
!147 = !{i32 2959}
!148 = !{i32 2968}
!149 = !{i32 3015}
!150 = !{i32 3017}
!151 = !{i32 3047}
!152 = !{i32 3069}
!153 = !{i32 3078}
!154 = !{i32 3109}
!155 = !{i32 3134}
!156 = !{i32 3224}
!157 = !{i32 3229}
!158 = !{i32 3237}
!159 = !{i32 3258}
!160 = !{i32 3299}
!161 = !{i32 3307}
!162 = !{i32 3349}
!163 = !{i32 3390}
!164 = !{i32 3395}
!165 = !{i32 3400}
!166 = !{i32 3406}
!167 = !{i32 3409}
!168 = !{i32 3418}
!169 = !{i32 3458}
!170 = !{i32 3470}
!171 = !{i32 3491}
!172 = !{i32 3532}
!173 = !{i32 3540}
!174 = !{i32 3566}
!175 = !{i32 3582}
!176 = !{i32 3592}
!177 = !{i32 3602}
!178 = !{i32 3603}
!179 = !{i32 3605}
!180 = !{i32 3615}
!181 = !{i32 3731}
!182 = !{i32 3737}
!183 = !{i32 3747}
!184 = !{i32 3759}
!185 = !{i32 3770}
!186 = !{i32 3815}
!187 = !{i32 3827}
!188 = !{i32 3843}
!189 = !{i32 3858}
!190 = !{i32 3890}
!191 = !{i32 3896}
!192 = !{i32 3919}
!193 = !{i32 3925}
!194 = !{i32 3932}
!195 = !{i32 3937}
!196 = !{i32 3968}
!197 = !{i32 3995}
!198 = !{i32 4003}
!199 = !{i32 4008}
!200 = !{i32 4013}
!201 = !{i32 4018}
!202 = !{i32 4032}
!203 = !{i32 4044}
!204 = !{i32 4054}
!205 = !{i32 4143}
!206 = !{i32 4149}
!207 = !{i32 4219}
!208 = !{i32 4240}
!209 = !{i32 4246}
!210 = !{i32 4252}
!211 = !{i32 4263}
!212 = !{i32 4303}
!213 = !{i32 4309}
!214 = !{i32 4315}
!215 = !{i32 4334}
!216 = !{i32 4340}
!217 = !{i32 4346}
!218 = !{i32 4392}
!219 = !{i32 4410}
!220 = !{i32 4436}
!221 = !{i32 4437}
!222 = !{i32 4509}
!223 = !{i32 4515}
!224 = !{i32 4524}
!225 = !{i32 4530}
!226 = !{i32 4536}
!227 = !{i32 4538}
!228 = !{i32 4548}
!229 = !{i32 4591}
!230 = !{i32 4663}
!231 = !{i32 4670}
!232 = !{i32 4716}
!233 = !{i32 4792}
!234 = !{i32 4798}
!235 = !{i32 4807}
!236 = !{i32 4813}
!237 = !{i32 4819}
!238 = !{i32 4821}
!239 = !{i32 4831}
!240 = !{i32 4894}
!241 = !{i32 4900}
!242 = !{i32 4922}
!243 = !{i32 4933}
!244 = !{i32 5001}
!245 = !{i32 5074}
!246 = !{i32 5080}
!247 = !{i32 5089}
!248 = !{i32 5095}
!249 = !{i32 5101}
!250 = !{i32 5113}
!251 = !{i32 5120}
!252 = !{i32 5213}
!253 = !{i32 5223}
!254 = !{i32 5233}
!255 = !{i32 5274}
!256 = !{i32 5422}
!257 = !{i32 5449}
!258 = !{i32 5499}
!259 = !{i32 5576}
!260 = !{i32 5626}
!261 = !{i32 5636}
!262 = !{i32 5680}
!263 = !{i32 5769}
!264 = !{i32 5775}
!265 = !{i32 5781}
!266 = !{i32 5792}
!267 = !{i32 5824}
!268 = !{i32 5854}
!269 = !{i32 5861}
!270 = !{i32 5863}
!271 = !{i32 5876}
!272 = !{i32 5880}
!273 = !{i32 5887}
!274 = !{i32 6013}
!275 = !{i32 6019}
!276 = !{i32 6025}
!277 = !{i32 6036}
!278 = !{i32 6112}
!279 = !{i32 6118}
!280 = !{i32 6124}
!281 = !{i32 6194}
!282 = !{i32 6200}
!283 = !{i32 6206}
!284 = !{i32 6236}
!285 = !{i32 6242}
!286 = !{i32 6248}
!287 = !{i32 6273}
!288 = !{i32 6279}
!289 = !{i32 6285}
!290 = !{i32 6296}
!291 = !{i32 6336}
!292 = !{i32 6342}
!293 = !{i32 6348}
!294 = !{i32 6374}
!295 = !{i32 6384}
!296 = !{i32 6394}
!297 = !{i32 6395}
!298 = !{i32 6413}
!299 = !{i32 6419}
!300 = !{i32 6425}
!301 = !{i32 6427}
!302 = !{i32 6437}
!303 = !{i32 6473}
!304 = !{i32 6479}
!305 = !{i32 6485}
!306 = !{i32 6524}
!307 = !{i32 6530}
!308 = !{i32 6536}
!309 = !{i32 6561}
!310 = !{i32 6567}
!311 = !{i32 6578}
!312 = !{i32 6587}
!313 = !{i32 6598}
!314 = !{i32 6669}
!315 = !{i32 6673}
!316 = !{i32 6679}
!317 = !{i32 6683}
!318 = !{i32 6715}
!319 = !{i32 6721}
!320 = !{i32 6732}
!321 = !{i32 6741}
!322 = !{i32 6752}
!323 = !{i32 6823}
!324 = !{i32 6827}
!325 = !{i32 6833}
!326 = !{i32 6837}
!327 = !{i32 6862}
!328 = !{i32 6893}
!329 = !{i32 6899}
!330 = !{i32 6905}
!331 = !{i32 6930}
!332 = !{i32 6936}
!333 = !{i32 6942}
!334 = !{i32 6953}
!335 = !{i32 6993}
!336 = !{i32 6999}
!337 = !{i32 7005}
!338 = !{i32 7043}
!339 = !{i32 7073}
!340 = !{i32 7084}
!341 = !{i32 7111}
!342 = !{i32 7117}
!343 = !{i32 7128}
!344 = !{i32 7174}
!345 = !{i32 7180}
!346 = !{i32 7186}
!347 = !{i32 7197}
!348 = !{i32 7237}
!349 = !{i32 7243}
!350 = !{i32 7249}
!351 = !{i32 7260}
!352 = !{i32 7302}
!353 = !{i32 7333}
!354 = !{i32 7383}
!355 = !{i32 7465}
!356 = !{i32 7471}
!357 = !{i32 7477}
!358 = !{i32 7489}
!359 = !{i32 7498}
!360 = !{i32 7513}
!361 = !{i32 7545}
!362 = !{i32 7546}
!363 = !{i32 7555}
!364 = !{i32 7560}
!365 = !{i32 7591}
!366 = !{i32 7618}
!367 = !{i32 7626}
!368 = !{i32 7631}
!369 = !{i32 7677}
!370 = !{i32 7742}
!371 = !{i32 7813}
!372 = !{i32 7905}
!373 = !{i32 7990}
!374 = !{i32 8036}
!375 = !{i32 8105}
!376 = !{i32 8135}
!377 = !{i32 8166}
!378 = !{i32 8174}
!379 = !{i32 8189}
!380 = !{i32 8200}
!381 = !{i32 8227}
!382 = !{i32 8250}
!383 = !{i32 8340}
!384 = !{i32 8345}
!385 = !{i32 8353}
!386 = !{i32 8374}
!387 = !{i32 8415}
!388 = !{i32 8423}
!389 = !{i32 8465}
!390 = !{i32 8506}
!391 = !{i32 8511}
!392 = !{i32 8516}
!393 = !{i32 8522}
!394 = !{i32 8525}
!395 = !{i32 8534}
!396 = !{i32 8574}
!397 = !{i32 8586}
!398 = !{i32 8607}
!399 = !{i32 8648}
!400 = !{i32 8656}
!401 = !{i32 8674}
!402 = !{i32 8675}
!403 = !{i32 8679}
!404 = !{i32 8693}
!405 = !{i32 8694}
!406 = !{i32 8704}
!407 = !{i32 8709}
!408 = !{i32 8777}
!409 = !{i32 8824}
!410 = !{i32 8830}
!411 = !{i32 8836}
!412 = !{i32 8847}
!413 = !{i32 8905}
!414 = !{i32 8995}
!415 = !{i32 9000}
!416 = !{i32 9008}
!417 = !{i32 9029}
!418 = !{i32 9070}
!419 = !{i32 9078}
!420 = !{i32 9120}
!421 = !{i32 9161}
!422 = !{i32 9166}
!423 = !{i32 9171}
!424 = !{i32 9177}
!425 = !{i32 9180}
!426 = !{i32 9189}
!427 = !{i32 9229}
!428 = !{i32 9241}
!429 = !{i32 9262}
!430 = !{i32 9303}
!431 = !{i32 9311}
!432 = !{i32 9331}
!433 = !{i32 9373}
!434 = !{i32 9521}
!435 = !{i32 9548}
!436 = !{i32 9598}
!437 = !{i32 9675}
!438 = !{i32 9725}
!439 = !{i32 9735}
!440 = !{i32 9753}
!441 = !{i32 9791}
!442 = !{i32 9874}
!443 = !{i32 9880}
!444 = !{i32 9962}
!445 = !{i32 9968}
!446 = !{i32 9977}
!447 = !{i32 9983}
!448 = !{i32 9989}
!449 = !{i32 9995}
!450 = !{i32 10011}
!451 = !{i32 10056}
!452 = !{i32 10128}
!453 = !{i32 10135}
!454 = !{i32 10181}
!455 = !{i32 10209}
!456 = !{i32 10220}
!457 = !{i32 10247}
!458 = !{i32 10253}
!459 = !{i32 10301}
!460 = !{i32 10368}
!461 = !{i32 10448}
!462 = !{i32 10454}
!463 = !{i32 10464}
!464 = !{i32 10483}
!465 = !{i32 10544}
!466 = !{i32 10666}
!467 = !{i32 10729}
!468 = !{i32 10740}
!469 = !{i32 10808}
!470 = !{i32 10823}
!471 = !{i32 10832}
!472 = !{i32 10834}
!473 = !{i32 10901}
!474 = !{i32 10907}
!475 = !{i32 10913}
!476 = !{i32 10924}
!477 = !{i32 10940}
!478 = !{i32 10953}
!479 = !{i32 10959}
!480 = !{i32 10965}
!481 = !{i32 10977}
!482 = !{i32 10987}
!483 = !{i32 11003}
!484 = !{i32 11013}
!485 = !{i32 11026}
!486 = !{i32 11037}
!487 = !{i32 11089}
!488 = !{i32 11101}
!489 = !{i32 11106}
!490 = !{i32 11155}
!491 = !{i32 11166}
!492 = !{i32 11242}
!493 = !{i32 11251}
!494 = !{i32 11296}
!495 = !{i32 11307}
!496 = !{i32 11384}
!497 = !{i32 11390}
!498 = !{i32 11400}
!499 = !{i32 11482}
!500 = !{i32 11488}
!501 = !{i32 11497}
!502 = !{i32 11503}
!503 = !{i32 11509}
!504 = !{i32 11538}
!505 = !{i32 11549}
!506 = !{i32 11561}
!507 = !{i32 11581}
!508 = !{i32 11582}
!509 = !{i32 11608}
!510 = !{i32 11691}
!511 = !{i32 11697}
!512 = !{i32 11776}
!513 = !{i32 11782}
!514 = !{i32 11788}
!515 = !{i32 11799}
!516 = !{i32 11840}
!517 = !{i32 11892}
!518 = !{i32 11966}
!519 = !{i32 12056}
!520 = !{i32 12061}
!521 = !{i32 12069}
!522 = !{i32 12090}
!523 = !{i32 12131}
!524 = !{i32 12139}
!525 = !{i32 12179}
!526 = !{i32 12206}
!527 = !{i32 12223}
!528 = !{i32 12315}
!529 = !{i32 12320}
!530 = !{i32 12325}
!531 = !{i32 12331}
!532 = !{i32 12334}
!533 = !{i32 12345}
!534 = !{i32 12353}
!535 = !{i32 12371}
!536 = !{i32 12375}
!537 = !{i32 12380}
!538 = !{i32 12396}
!539 = !{i32 12409}
!540 = !{i32 12417}
!541 = !{i32 12422}
!542 = !{i32 12429}
!543 = !{i32 12446}
!544 = !{i32 12467}
!545 = !{i32 12508}
!546 = !{i32 12516}
!547 = !{i32 12528}
!548 = !{i32 12538}
!549 = !{i32 12550}
!550 = !{i32 12570}
!551 = !{i32 12666}
!552 = !{i32 12671}
!553 = !{i32 12678}
!554 = !{i32 12682}
!555 = !{i32 12686}
!556 = !{i32 12692}
!557 = !{i32 12695}
!558 = !{i32 12706}
!559 = !{i32 12714}
!560 = !{i32 12732}
!561 = !{i32 12736}
!562 = !{i32 12741}
!563 = !{i32 12757}
!564 = !{i32 12770}
!565 = !{i32 12778}
!566 = !{i32 12783}
!567 = !{i32 12790}
!568 = !{i32 12797}
!569 = !{i32 12808}
!570 = !{i32 12816}
!571 = !{i32 12834}
!572 = !{i32 12838}
!573 = !{i32 12843}
!574 = !{i32 12859}
!575 = !{i32 12872}
!576 = !{i32 12880}
!577 = !{i32 12885}
!578 = !{i32 12892}
!579 = !{i32 12912}
!580 = !{i32 12932}
!581 = !{i32 12974}
!582 = !{i32 12982}
!583 = !{i32 13068}
!584 = !{i32 13074}
!585 = !{i32 13101}
!586 = !{i32 13107}
!587 = !{i32 13113}
!588 = !{i32 13134}
!589 = !{i32 13140}
!590 = !{i32 13146}
!591 = !{i32 13155}
!592 = !{i32 13169}
!593 = !{i32 13179}
!594 = !{i32 13184}
!595 = !{i32 13196}
!596 = !{i32 13202}
!597 = !{i32 13210}
!598 = !{i32 13241}
!599 = !{i32 13249}
!600 = !{i32 13257}
!601 = !{i32 13269}
!602 = !{i32 13329}
!603 = !{i32 13335}
!604 = !{i32 13365}
!605 = !{i32 13371}
!606 = !{i32 13385}
!607 = !{i32 13396}
!608 = !{i32 13467}
!609 = !{i32 13473}
!610 = !{i32 13491}
!611 = !{i32 13497}
!612 = !{i32 13504}
!613 = !{i32 13515}
!614 = !{i32 13541}
!615 = !{i32 13572}
!616 = !{i32 13599}
!617 = !{i32 13607}
!618 = !{i32 13612}
!619 = !{i32 13617}
!620 = !{i32 13628}
!621 = !{i32 13635}
!622 = !{i32 13647}
!623 = !{i32 13654}
!624 = !{i32 13673}
!625 = !{i32 13679}
!626 = !{i32 13687}
!627 = !{i32 13718}
!628 = !{i32 13726}
!629 = !{i32 13734}
!630 = !{i32 13746}
!631 = !{i32 13767}
!632 = !{i32 13798}
!633 = !{i32 13915}
!634 = !{i32 13921}
!635 = !{i32 13931}
!636 = !{i32 13954}
!637 = !{i32 13961}
!638 = !{i32 14007}
!639 = !{i32 14048}
!640 = !{i32 14122}
!641 = !{i32 14212}
!642 = !{i32 14217}
!643 = !{i32 14225}
!644 = !{i32 14246}
!645 = !{i32 14287}
!646 = !{i32 14295}
!647 = !{i32 14335}
!648 = !{i32 14362}
!649 = !{i32 14379}
!650 = !{i32 14469}
!651 = !{i32 14474}
!652 = !{i32 14482}
!653 = !{i32 14503}
!654 = !{i32 14544}
!655 = !{i32 14552}
!656 = !{i32 14635}
!657 = !{i32 14715}
!658 = !{i32 14760}
!659 = !{i32 14765}
!660 = !{i32 14865}
!661 = !{i32 14871}
!662 = !{i32 14881}
!663 = !{i32 14896}
!664 = !{i32 14983}
!665 = !{i32 15042}
!666 = !{i32 15047}
!667 = !{i32 15104}
!668 = !{i32 15181}
!669 = !{i32 15187}
!670 = !{i32 15197}
!671 = !{i32 15291}
!672 = !{i32 15297}
!673 = !{i32 15307}
!674 = !{i32 15324}
!675 = !{i32 15339}
!676 = !{i32 15343}
!677 = !{i32 15345}
!678 = !{i32 15355}
!679 = !{i32 15394}
!680 = !{i32 15451}
!681 = !{i32 15457}
!682 = !{i32 15463}
!683 = !{i32 15474}
!684 = !{i32 15483}
!685 = !{i32 15498}
!686 = !{i32 15509}
!687 = !{i32 15515}
!688 = !{i32 15531}
!689 = !{i32 15534}
!690 = !{i32 15542}
!691 = !{i32 15567}
!692 = !{i32 15611}
!693 = !{i32 15667}
!694 = !{i32 15673}
!695 = !{i32 15683}
!696 = !{i32 15692}
!697 = !{i32 15707}
!698 = !{i32 15712}
!699 = !{i32 15723}
!700 = !{i32 15728}
!701 = !{i32 15733}
!702 = !{i32 15747}
!703 = !{i32 15766}
!704 = !{i32 15768}
!705 = !{i32 15772}
!706 = !{i32 15783}
!707 = !{i32 15789}
!708 = !{i32 15791}
!709 = !{i32 15792}
!710 = !{i32 15802}
!711 = !{i32 15810}
!712 = !{i32 15822}
!713 = !{i32 15840}
!714 = !{i32 15890}
!715 = !{i32 15964}
!716 = !{i32 16054}
!717 = !{i32 16059}
!718 = !{i32 16067}
!719 = !{i32 16088}
!720 = !{i32 16129}
!721 = !{i32 16137}
!722 = !{i32 16177}
!723 = !{i32 16204}
!724 = !{i32 16221}
!725 = !{i32 16312}
!726 = !{i32 16317}
!727 = !{i32 16392}
!728 = !{i32 16403}
!729 = !{i32 16424}
!730 = !{i32 16469}
!731 = !{i32 16504}
!732 = !{i32 16510}
!733 = !{i32 16516}
!734 = !{i32 16527}
!735 = !{i32 16583}
!736 = !{i32 16589}
!737 = !{i32 16595}
!738 = !{i32 16607}
!739 = !{i32 16613}
!740 = !{i32 16619}
!741 = !{i32 16621}
!742 = !{i32 16642}
!743 = !{i32 16648}
!744 = !{i32 16654}
!745 = !{i32 16656}
!746 = !{i32 16667}
!747 = !{i32 16677}
!748 = !{i32 16683}
!749 = !{i32 16689}
!750 = !{i32 16695}
!751 = !{i32 16739}
!752 = !{i32 16793}
!753 = !{i32 16799}
!754 = !{i32 16809}
!755 = !{i32 16832}
!756 = !{i32 16839}
!757 = !{i32 16885}
!758 = !{i32 16899}
!759 = !{i32 16905}
!760 = !{i32 16911}
!761 = !{i32 16914}
!762 = !{i32 16931}
!763 = !{i32 16937}
!764 = !{i32 16943}
!765 = !{i32 16946}
!766 = !{i32 16954}
!767 = !{i32 16997}
!768 = !{i32 17004}
!769 = !{i32 17030}
!770 = !{i32 17104}
!771 = !{i32 17194}
!772 = !{i32 17199}
!773 = !{i32 17207}
!774 = !{i32 17228}
!775 = !{i32 17269}
!776 = !{i32 17277}
!777 = !{i32 17317}
!778 = !{i32 17344}
!779 = !{i32 17361}
!780 = !{i32 17452}
!781 = !{i32 17457}
!782 = !{i32 17472}
!783 = !{i32 17483}
!784 = !{i32 17504}
!785 = !{i32 17583}
!786 = !{i32 17589}
!787 = !{i32 17607}
!788 = !{i32 17613}
!789 = !{i32 17619}
!790 = !{i32 17650}
!791 = !{i32 17677}
!792 = !{i32 17692}
!793 = !{i32 17698}
!794 = !{i32 17704}
!795 = !{i32 17717}
!796 = !{i32 17813}
!797 = !{i32 17819}
!798 = !{i32 17829}
!799 = !{i32 17925}
!800 = !{i32 17952}
!801 = !{i32 18055}
!802 = !{i32 18082}
!803 = !{i32 18185}
!804 = !{i32 18212}
!805 = !{i32 18305}
!806 = !{i32 18323}
!807 = !{i32 18324}
!808 = !{i32 18360}
!809 = !{i32 18394}
!810 = !{i32 18473}
!811 = !{i32 18491}
!812 = !{i32 18492}
!813 = !{i32 18528}
!814 = !{i32 18562}
!815 = !{i32 18630}
!816 = !{i32 18638}
!817 = !{i32 18660}
!818 = !{i32 18661}
!819 = !{i32 18697}
!820 = !{i32 18731}
!821 = !{i32 18766}
!822 = !{i32 18767}
!823 = !{i32 18769}
!824 = !{i32 18812}
!825 = !{i32 18830}
!826 = !{i32 18831}
!827 = !{i32 18867}
!828 = !{i32 18901}
!829 = !{i32 18952}
!830 = !{i32 18975}
